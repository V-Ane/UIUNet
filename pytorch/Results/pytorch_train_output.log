nohup: ignoring input
---
train images:  1052
train labels:  1052
---
---
---
test images:  452
test labels:  452
---
---
---define optimizer...
---start training...
l0: 0.558183, l1: 0.520699, l2: 1.041400, l3: 0.456741, l4: 0.490323, l5: 0.764164, l6: 0.571799

[epoch:   1/1000, batch:     4/ 1052, ite: 1] train loss: 4.403309, tar: 0.558183 
l0: 1.085473, l1: 0.334280, l2: 0.753807, l3: 0.283495, l4: 0.242250, l5: 0.393906, l6: 0.088934

[epoch:   1/1000, batch:     8/ 1052, ite: 2] train loss: 3.792727, tar: 0.821828 
l0: 1.361749, l1: 0.194451, l2: 0.536773, l3: 0.176868, l4: 0.079185, l5: 0.044779, l6: 0.025016

[epoch:   1/1000, batch:    12/ 1052, ite: 3] train loss: 3.334758, tar: 1.001801 
l0: 1.321026, l1: 0.134865, l2: 0.391474, l3: 0.121720, l4: 0.057660, l5: 0.015759, l6: 0.032048

[epoch:   1/1000, batch:    16/ 1052, ite: 4] train loss: 3.019706, tar: 1.081608 
l0: 1.138480, l1: 0.073189, l2: 0.296231, l3: 0.127361, l4: 0.063024, l5: 0.008591, l6: 0.039322

[epoch:   1/1000, batch:    20/ 1052, ite: 5] train loss: 2.765005, tar: 1.092982 
l0: 0.959958, l1: 0.046455, l2: 0.250175, l3: 0.133819, l4: 0.068797, l5: 0.006757, l6: 0.093666

[epoch:   1/1000, batch:    24/ 1052, ite: 6] train loss: 2.564108, tar: 1.070812 
l0: 0.815370, l1: 0.033742, l2: 0.218557, l3: 0.110238, l4: 0.078452, l5: 0.006093, l6: 0.118440

[epoch:   1/1000, batch:    28/ 1052, ite: 7] train loss: 2.395078, tar: 1.034320 
l0: 0.745476, l1: 0.021550, l2: 0.202452, l3: 0.097702, l4: 0.085487, l5: 0.009938, l6: 0.080176

[epoch:   1/1000, batch:    32/ 1052, ite: 8] train loss: 2.251041, tar: 0.998214 
l0: 0.579091, l1: 0.017731, l2: 0.190964, l3: 0.109464, l4: 0.111108, l5: 0.055725, l6: 0.148601

[epoch:   1/1000, batch:    36/ 1052, ite: 9] train loss: 2.135668, tar: 0.951645 
l0: 0.540629, l1: 0.010711, l2: 0.179582, l3: 0.088581, l4: 0.095735, l5: 0.004115, l6: 0.137148

[epoch:   1/1000, batch:    40/ 1052, ite: 10] train loss: 2.027751, tar: 0.910544 
l0: 0.528508, l1: 0.009186, l2: 0.172712, l3: 0.065093, l4: 0.082548, l5: 0.008387, l6: 0.110157

[epoch:   1/1000, batch:    44/ 1052, ite: 11] train loss: 1.932191, tar: 0.875813 
l0: 0.479301, l1: 0.007855, l2: 0.149205, l3: 0.056722, l4: 0.076068, l5: 0.009239, l6: 0.104423

[epoch:   1/1000, batch:    48/ 1052, ite: 12] train loss: 1.844743, tar: 0.842770 
l0: 0.417380, l1: 0.009584, l2: 0.153154, l3: 0.062756, l4: 0.084738, l5: 0.021000, l6: 0.095209

[epoch:   1/1000, batch:    52/ 1052, ite: 13] train loss: 1.767749, tar: 0.810048 
l0: 0.368251, l1: 0.008049, l2: 0.142909, l3: 0.055198, l4: 0.074021, l5: 0.014184, l6: 0.098606

[epoch:   1/1000, batch:    56/ 1052, ite: 14] train loss: 1.695854, tar: 0.778491 
l0: 0.315375, l1: 0.004987, l2: 0.130510, l3: 0.058873, l4: 0.075182, l5: 0.009984, l6: 0.121354

[epoch:   1/1000, batch:    60/ 1052, ite: 15] train loss: 1.630548, tar: 0.747617 
l0: 0.334171, l1: 0.014432, l2: 0.110014, l3: 0.047980, l4: 0.053323, l5: 0.033171, l6: 0.058055

[epoch:   1/1000, batch:    64/ 1052, ite: 16] train loss: 1.569335, tar: 0.721776 
l0: 0.260524, l1: 0.010200, l2: 0.105386, l3: 0.058026, l4: 0.067529, l5: 0.019371, l6: 0.087458

[epoch:   1/1000, batch:    68/ 1052, ite: 17] train loss: 1.512815, tar: 0.694644 
l0: 0.260304, l1: 0.010166, l2: 0.091373, l3: 0.042969, l4: 0.045654, l5: 0.022975, l6: 0.062595

[epoch:   1/1000, batch:    72/ 1052, ite: 18] train loss: 1.458550, tar: 0.670514 
l0: 0.278150, l1: 0.010617, l2: 0.084934, l3: 0.038764, l4: 0.033728, l5: 0.021714, l6: 0.032460

[epoch:   1/1000, batch:    76/ 1052, ite: 19] train loss: 1.408119, tar: 0.649863 
l0: 0.214500, l1: 0.001868, l2: 0.079767, l3: 0.038293, l4: 0.037341, l5: 0.004809, l6: 0.043970

[epoch:   1/1000, batch:    80/ 1052, ite: 20] train loss: 1.358740, tar: 0.628095 
l0: 0.043964, l1: 0.009978, l2: 0.023665, l3: 0.012358, l4: 0.012101, l5: 0.034062, l6: 0.013584

[epoch:   1/1000, batch:   160/ 1052, ite: 40] train loss: 0.799120, tar: 0.360738 
l0: 0.021125, l1: 0.010048, l2: 0.012302, l3: 0.008696, l4: 0.008842, l5: 0.025862, l6: 0.008439

[epoch:   1/1000, batch:   240/ 1052, ite: 60] train loss: 0.570381, tar: 0.250205 
l0: 0.012826, l1: 0.010172, l2: 0.009893, l3: 0.007493, l4: 0.008170, l5: 0.014318, l6: 0.009875

[epoch:   1/1000, batch:   320/ 1052, ite: 80] train loss: 0.446625, tar: 0.192058 
l0: 0.009488, l1: 0.004276, l2: 0.006453, l3: 0.004102, l4: 0.003949, l5: 0.005946, l6: 0.004466

[epoch:   1/1000, batch:   400/ 1052, ite: 100] train loss: 0.375176, tar: 0.156662 
l0: 0.018998, l1: 0.012527, l2: 0.009052, l3: 0.007119, l4: 0.007523, l5: 0.008477, l6: 0.007840

[epoch:   1/1000, batch:   480/ 1052, ite: 120] train loss: 0.327193, tar: 0.132608 
l0: 0.007780, l1: 0.009338, l2: 0.006947, l3: 0.005993, l4: 0.008016, l5: 0.011915, l6: 0.008501

[epoch:   1/1000, batch:   560/ 1052, ite: 140] train loss: 0.289961, tar: 0.115131 
l0: 0.008022, l1: 0.004920, l2: 0.005825, l3: 0.008080, l4: 0.007420, l5: 0.038147, l6: 0.007036

[epoch:   1/1000, batch:   640/ 1052, ite: 160] train loss: 0.262972, tar: 0.101904 
l0: 0.007105, l1: 0.004566, l2: 0.006303, l3: 0.006832, l4: 0.007493, l5: 0.029119, l6: 0.007934

[epoch:   1/1000, batch:   720/ 1052, ite: 180] train loss: 0.240412, tar: 0.091489 
l0: 0.006340, l1: 0.003503, l2: 0.006365, l3: 0.007578, l4: 0.007675, l5: 0.073177, l6: 0.007986

[epoch:   1/1000, batch:   800/ 1052, ite: 200] train loss: 0.222564, tar: 0.083113 
l0: 0.006300, l1: 0.006946, l2: 0.004858, l3: 0.005859, l4: 0.006762, l5: 0.039379, l6: 0.006800

[epoch:   1/1000, batch:   880/ 1052, ite: 220] train loss: 0.207417, tar: 0.076122 
l0: 0.005816, l1: 0.004133, l2: 0.003973, l3: 0.004890, l4: 0.005615, l5: 0.010218, l6: 0.006650

[epoch:   1/1000, batch:   960/ 1052, ite: 240] train loss: 0.195096, tar: 0.070240 
l0: 0.015002, l1: 0.003600, l2: 0.005587, l3: 0.005537, l4: 0.008207, l5: 0.067034, l6: 0.011789

[epoch:   1/1000, batch:  1040/ 1052, ite: 260] train loss: 0.184496, tar: 0.065303 
[Epoch 1/1000] Test loss: 0.073, Test target loss: 0.016
l0: 0.003272, l1: 0.001850, l2: 0.002539, l3: 0.002240, l4: 0.002638, l5: 0.011601, l6: 0.003289

[epoch:   2/1000, batch:    68/ 1052, ite: 280] train loss: 0.174916, tar: 0.061028 
l0: 0.003972, l1: 0.006052, l2: 0.003689, l3: 0.003421, l4: 0.003759, l5: 0.008188, l6: 0.003704

[epoch:   2/1000, batch:   148/ 1052, ite: 300] train loss: 0.166508, tar: 0.057269 
l0: 0.003292, l1: 0.004439, l2: 0.003013, l3: 0.002590, l4: 0.003139, l5: 0.013201, l6: 0.003966

[epoch:   2/1000, batch:   228/ 1052, ite: 320] train loss: 0.159890, tar: 0.054036 
l0: 0.005875, l1: 0.003247, l2: 0.002857, l3: 0.002301, l4: 0.005437, l5: 0.036135, l6: 0.007323

[epoch:   2/1000, batch:   308/ 1052, ite: 340] train loss: 0.153893, tar: 0.051179 
l0: 0.008356, l1: 0.006094, l2: 0.005171, l3: 0.005986, l4: 0.003969, l5: 0.014014, l6: 0.007716

[epoch:   2/1000, batch:   388/ 1052, ite: 360] train loss: 0.148650, tar: 0.048678 
l0: 0.003894, l1: 0.002000, l2: 0.002835, l3: 0.002338, l4: 0.003131, l5: 0.011082, l6: 0.004666

[epoch:   2/1000, batch:   468/ 1052, ite: 380] train loss: 0.144044, tar: 0.046449 
l0: 0.010273, l1: 0.004251, l2: 0.004995, l3: 0.007516, l4: 0.005583, l5: 0.123968, l6: 0.016101

[epoch:   2/1000, batch:   548/ 1052, ite: 400] train loss: 0.139153, tar: 0.044335 
l0: 0.004859, l1: 0.001452, l2: 0.002419, l3: 0.001399, l4: 0.001539, l5: 0.009110, l6: 0.002339

[epoch:   2/1000, batch:   628/ 1052, ite: 420] train loss: 0.134498, tar: 0.042452 
l0: 0.004812, l1: 0.002870, l2: 0.002994, l3: 0.002126, l4: 0.003273, l5: 0.025514, l6: 0.007453

[epoch:   2/1000, batch:   708/ 1052, ite: 440] train loss: 0.130247, tar: 0.040712 
l0: 0.001985, l1: 0.000520, l2: 0.001358, l3: 0.001049, l4: 0.001324, l5: 0.011394, l6: 0.002934

[epoch:   2/1000, batch:   788/ 1052, ite: 460] train loss: 0.126071, tar: 0.039093 
l0: 0.003964, l1: 0.001525, l2: 0.001934, l3: 0.002703, l4: 0.002275, l5: 0.011980, l6: 0.006066

[epoch:   2/1000, batch:   868/ 1052, ite: 480] train loss: 0.122292, tar: 0.037624 
l0: 0.005987, l1: 0.009701, l2: 0.004862, l3: 0.006341, l4: 0.007528, l5: 0.047862, l6: 0.009792

[epoch:   2/1000, batch:   948/ 1052, ite: 500] train loss: 0.119084, tar: 0.036308 
l0: 0.002712, l1: 0.003833, l2: 0.003058, l3: 0.002243, l4: 0.002294, l5: 0.006287, l6: 0.002778

[epoch:   2/1000, batch:  1028/ 1052, ite: 520] train loss: 0.115937, tar: 0.035084 
[Epoch 2/1000] Test loss: 0.045, Test target loss: 0.011
l0: 0.002080, l1: 0.001289, l2: 0.001758, l3: 0.001507, l4: 0.002107, l5: 0.006972, l6: 0.003962

[epoch:   3/1000, batch:    56/ 1052, ite: 540] train loss: 0.112938, tar: 0.033910 
l0: 0.008430, l1: 0.012490, l2: 0.005534, l3: 0.005336, l4: 0.005593, l5: 0.023049, l6: 0.007242

[epoch:   3/1000, batch:   136/ 1052, ite: 560] train loss: 0.110468, tar: 0.032853 
l0: 0.002580, l1: 0.000990, l2: 0.001477, l3: 0.001807, l4: 0.001891, l5: 0.007835, l6: 0.002680

[epoch:   3/1000, batch:   216/ 1052, ite: 580] train loss: 0.107697, tar: 0.031855 
l0: 0.003746, l1: 0.001472, l2: 0.002278, l3: 0.002327, l4: 0.002510, l5: 0.003902, l6: 0.004535

[epoch:   3/1000, batch:   296/ 1052, ite: 600] train loss: 0.105234, tar: 0.030934 
l0: 0.002218, l1: 0.001734, l2: 0.001859, l3: 0.001986, l4: 0.002281, l5: 0.002875, l6: 0.002834

[epoch:   3/1000, batch:   376/ 1052, ite: 620] train loss: 0.102862, tar: 0.030074 
l0: 0.002473, l1: 0.002102, l2: 0.002484, l3: 0.002471, l4: 0.002506, l5: 0.003600, l6: 0.004074

[epoch:   3/1000, batch:   456/ 1052, ite: 640] train loss: 0.100660, tar: 0.029266 
l0: 0.004073, l1: 0.003619, l2: 0.002993, l3: 0.003362, l4: 0.005187, l5: 0.004027, l6: 0.006096

[epoch:   3/1000, batch:   536/ 1052, ite: 660] train loss: 0.098360, tar: 0.028480 
l0: 0.001841, l1: 0.001656, l2: 0.001446, l3: 0.001263, l4: 0.001521, l5: 0.001829, l6: 0.003690

[epoch:   3/1000, batch:   616/ 1052, ite: 680] train loss: 0.096090, tar: 0.027718 
l0: 0.001567, l1: 0.001571, l2: 0.001370, l3: 0.001177, l4: 0.001340, l5: 0.001729, l6: 0.002801

[epoch:   3/1000, batch:   696/ 1052, ite: 700] train loss: 0.093935, tar: 0.027006 
l0: 0.004300, l1: 0.003093, l2: 0.001768, l3: 0.002364, l4: 0.002646, l5: 0.004087, l6: 0.002972

[epoch:   3/1000, batch:   776/ 1052, ite: 720] train loss: 0.091906, tar: 0.026338 
l0: 0.004207, l1: 0.004884, l2: 0.003572, l3: 0.002771, l4: 0.003000, l5: 0.006777, l6: 0.006307

[epoch:   3/1000, batch:   856/ 1052, ite: 740] train loss: 0.089984, tar: 0.025697 
l0: 0.003302, l1: 0.003109, l2: 0.003063, l3: 0.003430, l4: 0.004657, l5: 0.004567, l6: 0.005576

[epoch:   3/1000, batch:   936/ 1052, ite: 760] train loss: 0.088035, tar: 0.025079 
l0: 0.001276, l1: 0.000590, l2: 0.000863, l3: 0.000873, l4: 0.001095, l5: 0.001573, l6: 0.002729

[epoch:   3/1000, batch:  1016/ 1052, ite: 780] train loss: 0.086112, tar: 0.024481 
[Epoch 3/1000] Test loss: 0.027, Test target loss: 0.011
l0: 0.001003, l1: 0.001388, l2: 0.001232, l3: 0.001175, l4: 0.001030, l5: 0.001436, l6: 0.002138

[epoch:   4/1000, batch:    44/ 1052, ite: 800] train loss: 0.084363, tar: 0.023922 
l0: 0.004777, l1: 0.012940, l2: 0.006139, l3: 0.005851, l4: 0.004576, l5: 0.006396, l6: 0.007566

[epoch:   4/1000, batch:   124/ 1052, ite: 820] train loss: 0.082975, tar: 0.023421 
l0: 0.001270, l1: 0.000887, l2: 0.001247, l3: 0.001585, l4: 0.001809, l5: 0.001470, l6: 0.003040

[epoch:   4/1000, batch:   204/ 1052, ite: 840] train loss: 0.081605, tar: 0.022940 
l0: 0.005042, l1: 0.013971, l2: 0.005998, l3: 0.005671, l4: 0.007949, l5: 0.007459, l6: 0.007167

[epoch:   4/1000, batch:   284/ 1052, ite: 860] train loss: 0.080228, tar: 0.022472 
l0: 0.003124, l1: 0.003748, l2: 0.003121, l3: 0.002868, l4: 0.003840, l5: 0.004261, l6: 0.005107

[epoch:   4/1000, batch:   364/ 1052, ite: 880] train loss: 0.078835, tar: 0.022020 
l0: 0.003106, l1: 0.001249, l2: 0.002410, l3: 0.001942, l4: 0.001590, l5: 0.001862, l6: 0.003642

[epoch:   4/1000, batch:   444/ 1052, ite: 900] train loss: 0.077623, tar: 0.021603 
l0: 0.005079, l1: 0.011213, l2: 0.005821, l3: 0.004840, l4: 0.004140, l5: 0.004386, l6: 0.006342

[epoch:   4/1000, batch:   524/ 1052, ite: 920] train loss: 0.076364, tar: 0.021183 
l0: 0.002420, l1: 0.001316, l2: 0.001458, l3: 0.001307, l4: 0.001801, l5: 0.002437, l6: 0.004252

[epoch:   4/1000, batch:   604/ 1052, ite: 940] train loss: 0.075164, tar: 0.020800 
l0: 0.001717, l1: 0.001450, l2: 0.001076, l3: 0.001047, l4: 0.001399, l5: 0.001911, l6: 0.002840

[epoch:   4/1000, batch:   684/ 1052, ite: 960] train loss: 0.073945, tar: 0.020415 
l0: 0.003203, l1: 0.006741, l2: 0.003922, l3: 0.004351, l4: 0.003584, l5: 0.005492, l6: 0.005742

[epoch:   4/1000, batch:   764/ 1052, ite: 980] train loss: 0.073007, tar: 0.020073 
l0: 0.001669, l1: 0.000651, l2: 0.001792, l3: 0.001262, l4: 0.000798, l5: 0.001169, l6: 0.001937

[epoch:   4/1000, batch:   844/ 1052, ite: 1000] train loss: 0.071929, tar: 0.019715 
l0: 0.002380, l1: 0.003570, l2: 0.002644, l3: 0.003088, l4: 0.003443, l5: 0.007161, l6: 0.004000

[epoch:   4/1000, batch:   924/ 1052, ite: 1020] train loss: 0.070809, tar: 0.019366 
l0: 0.001208, l1: 0.000760, l2: 0.000990, l3: 0.001100, l4: 0.001187, l5: 0.001433, l6: 0.002062

[epoch:   4/1000, batch:  1004/ 1052, ite: 1040] train loss: 0.069743, tar: 0.019033 
[Epoch 4/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.002588, l1: 0.001386, l2: 0.001685, l3: 0.001196, l4: 0.001514, l5: 0.001858, l6: 0.003496

[epoch:   5/1000, batch:    32/ 1052, ite: 1060] train loss: 0.068750, tar: 0.018723 
l0: 0.001078, l1: 0.000579, l2: 0.001300, l3: 0.000789, l4: 0.001050, l5: 0.001350, l6: 0.001987

[epoch:   5/1000, batch:   112/ 1052, ite: 1080] train loss: 0.067790, tar: 0.018417 
l0: 0.001825, l1: 0.002010, l2: 0.001089, l3: 0.001066, l4: 0.001515, l5: 0.002552, l6: 0.002381

[epoch:   5/1000, batch:   192/ 1052, ite: 1100] train loss: 0.066826, tar: 0.018119 
l0: 0.001996, l1: 0.001044, l2: 0.001330, l3: 0.000936, l4: 0.001038, l5: 0.001798, l6: 0.002015

[epoch:   5/1000, batch:   272/ 1052, ite: 1120] train loss: 0.065957, tar: 0.017835 
l0: 0.001912, l1: 0.002026, l2: 0.001545, l3: 0.001497, l4: 0.001815, l5: 0.002703, l6: 0.003807

[epoch:   5/1000, batch:   352/ 1052, ite: 1140] train loss: 0.065101, tar: 0.017559 
l0: 0.001037, l1: 0.000905, l2: 0.000762, l3: 0.000734, l4: 0.001023, l5: 0.001331, l6: 0.001487

[epoch:   5/1000, batch:   432/ 1052, ite: 1160] train loss: 0.064184, tar: 0.017283 
l0: 0.001391, l1: 0.001432, l2: 0.001349, l3: 0.001344, l4: 0.001822, l5: 0.002352, l6: 0.003775

[epoch:   5/1000, batch:   512/ 1052, ite: 1180] train loss: 0.063366, tar: 0.017021 
l0: 0.001229, l1: 0.001120, l2: 0.000898, l3: 0.001031, l4: 0.001182, l5: 0.001789, l6: 0.002194

[epoch:   5/1000, batch:   592/ 1052, ite: 1200] train loss: 0.062516, tar: 0.016762 
l0: 0.001654, l1: 0.000496, l2: 0.000641, l3: 0.000664, l4: 0.000849, l5: 0.001145, l6: 0.002032

[epoch:   5/1000, batch:   672/ 1052, ite: 1220] train loss: 0.061803, tar: 0.016527 
l0: 0.002755, l1: 0.004949, l2: 0.002870, l3: 0.002244, l4: 0.002365, l5: 0.002632, l6: 0.002597

[epoch:   5/1000, batch:   752/ 1052, ite: 1240] train loss: 0.061014, tar: 0.016285 
l0: 0.001613, l1: 0.000857, l2: 0.000973, l3: 0.001365, l4: 0.001320, l5: 0.001649, l6: 0.003015

[epoch:   5/1000, batch:   832/ 1052, ite: 1260] train loss: 0.060327, tar: 0.016061 
l0: 0.002349, l1: 0.002055, l2: 0.001360, l3: 0.001379, l4: 0.001874, l5: 0.002677, l6: 0.003406

[epoch:   5/1000, batch:   912/ 1052, ite: 1280] train loss: 0.059653, tar: 0.015845 
l0: 0.001439, l1: 0.001904, l2: 0.001736, l3: 0.001719, l4: 0.001957, l5: 0.002826, l6: 0.003993

[epoch:   5/1000, batch:   992/ 1052, ite: 1300] train loss: 0.058996, tar: 0.015630 
[Epoch 5/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.001933, l1: 0.002070, l2: 0.001719, l3: 0.002087, l4: 0.001949, l5: 0.001915, l6: 0.003705

[epoch:   6/1000, batch:    20/ 1052, ite: 1320] train loss: 0.058361, tar: 0.015426 
l0: 0.000852, l1: 0.000659, l2: 0.000824, l3: 0.000704, l4: 0.001180, l5: 0.001179, l6: 0.002022

[epoch:   6/1000, batch:   100/ 1052, ite: 1340] train loss: 0.057684, tar: 0.015220 
l0: 0.001299, l1: 0.002216, l2: 0.001257, l3: 0.001213, l4: 0.001649, l5: 0.001453, l6: 0.002422

[epoch:   6/1000, batch:   180/ 1052, ite: 1360] train loss: 0.057025, tar: 0.015018 
l0: 0.003545, l1: 0.008541, l2: 0.004023, l3: 0.004135, l4: 0.004123, l5: 0.005485, l6: 0.005417

[epoch:   6/1000, batch:   260/ 1052, ite: 1380] train loss: 0.056424, tar: 0.014827 
l0: 0.000989, l1: 0.000546, l2: 0.000783, l3: 0.000765, l4: 0.001014, l5: 0.001486, l6: 0.002917

[epoch:   6/1000, batch:   340/ 1052, ite: 1400] train loss: 0.055804, tar: 0.014637 
l0: 0.002280, l1: 0.004412, l2: 0.002558, l3: 0.002120, l4: 0.003187, l5: 0.003549, l6: 0.005236

[epoch:   6/1000, batch:   420/ 1052, ite: 1420] train loss: 0.055214, tar: 0.014455 
l0: 0.001717, l1: 0.002235, l2: 0.001719, l3: 0.001892, l4: 0.002011, l5: 0.002744, l6: 0.003514

[epoch:   6/1000, batch:   500/ 1052, ite: 1440] train loss: 0.054633, tar: 0.014277 
l0: 0.000818, l1: 0.000696, l2: 0.001182, l3: 0.001348, l4: 0.001623, l5: 0.001673, l6: 0.002786

[epoch:   6/1000, batch:   580/ 1052, ite: 1460] train loss: 0.054054, tar: 0.014100 
l0: 0.001935, l1: 0.000749, l2: 0.001303, l3: 0.001034, l4: 0.001557, l5: 0.002213, l6: 0.002828

[epoch:   6/1000, batch:   660/ 1052, ite: 1480] train loss: 0.053488, tar: 0.013927 
l0: 0.000677, l1: 0.000539, l2: 0.000608, l3: 0.000839, l4: 0.000713, l5: 0.000958, l6: 0.001214

[epoch:   6/1000, batch:   740/ 1052, ite: 1500] train loss: 0.053025, tar: 0.013769 
l0: 0.001633, l1: 0.001700, l2: 0.001790, l3: 0.001044, l4: 0.001252, l5: 0.001987, l6: 0.002240

[epoch:   6/1000, batch:   820/ 1052, ite: 1520] train loss: 0.052526, tar: 0.013611 
l0: 0.002685, l1: 0.001645, l2: 0.001725, l3: 0.001720, l4: 0.002670, l5: 0.004038, l6: 0.003742

[epoch:   6/1000, batch:   900/ 1052, ite: 1540] train loss: 0.052056, tar: 0.013458 
l0: 0.009250, l1: 0.022670, l2: 0.009569, l3: 0.009019, l4: 0.010061, l5: 0.010069, l6: 0.009003

[epoch:   6/1000, batch:   980/ 1052, ite: 1560] train loss: 0.051589, tar: 0.013309 
[Epoch 6/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.001431, l1: 0.000924, l2: 0.001259, l3: 0.001394, l4: 0.001785, l5: 0.002689, l6: 0.003433

[epoch:   7/1000, batch:     8/ 1052, ite: 1580] train loss: 0.051100, tar: 0.013162 
l0: 0.000512, l1: 0.000487, l2: 0.000451, l3: 0.000483, l4: 0.000634, l5: 0.001008, l6: 0.001711

[epoch:   7/1000, batch:    88/ 1052, ite: 1600] train loss: 0.050603, tar: 0.013013 
l0: 0.000846, l1: 0.000745, l2: 0.000767, l3: 0.000883, l4: 0.001034, l5: 0.001343, l6: 0.002329

[epoch:   7/1000, batch:   168/ 1052, ite: 1620] train loss: 0.050144, tar: 0.012871 
l0: 0.001118, l1: 0.000444, l2: 0.000807, l3: 0.000718, l4: 0.000877, l5: 0.001484, l6: 0.002685

[epoch:   7/1000, batch:   248/ 1052, ite: 1640] train loss: 0.049686, tar: 0.012731 
l0: 0.001205, l1: 0.000539, l2: 0.000750, l3: 0.001017, l4: 0.001002, l5: 0.001342, l6: 0.001357

[epoch:   7/1000, batch:   328/ 1052, ite: 1660] train loss: 0.049270, tar: 0.012598 
l0: 0.000603, l1: 0.000482, l2: 0.000645, l3: 0.000571, l4: 0.000808, l5: 0.001068, l6: 0.001853

[epoch:   7/1000, batch:   408/ 1052, ite: 1680] train loss: 0.048805, tar: 0.012463 
l0: 0.002507, l1: 0.001629, l2: 0.001465, l3: 0.001602, l4: 0.002128, l5: 0.003065, l6: 0.004860

[epoch:   7/1000, batch:   488/ 1052, ite: 1700] train loss: 0.048550, tar: 0.012352 
l0: 0.000939, l1: 0.001175, l2: 0.001004, l3: 0.000969, l4: 0.001008, l5: 0.001284, l6: 0.002222

[epoch:   7/1000, batch:   568/ 1052, ite: 1720] train loss: 0.048134, tar: 0.012224 
l0: 0.000742, l1: 0.000639, l2: 0.000616, l3: 0.000604, l4: 0.000895, l5: 0.001139, l6: 0.001690

[epoch:   7/1000, batch:   648/ 1052, ite: 1740] train loss: 0.047715, tar: 0.012097 
l0: 0.001887, l1: 0.001283, l2: 0.001429, l3: 0.001360, l4: 0.001580, l5: 0.002865, l6: 0.002874

[epoch:   7/1000, batch:   728/ 1052, ite: 1760] train loss: 0.047365, tar: 0.011979 
l0: 0.001087, l1: 0.000740, l2: 0.000959, l3: 0.001128, l4: 0.001618, l5: 0.003172, l6: 0.003096

[epoch:   7/1000, batch:   808/ 1052, ite: 1780] train loss: 0.047037, tar: 0.011870 
l0: 0.000797, l1: 0.000386, l2: 0.000630, l3: 0.000638, l4: 0.001002, l5: 0.001430, l6: 0.002327

[epoch:   7/1000, batch:   888/ 1052, ite: 1800] train loss: 0.046651, tar: 0.011754 
l0: 0.001460, l1: 0.001766, l2: 0.001212, l3: 0.001296, l4: 0.001543, l5: 0.002220, l6: 0.003042

[epoch:   7/1000, batch:   968/ 1052, ite: 1820] train loss: 0.046268, tar: 0.011638 
l0: 0.000521, l1: 0.000369, l2: 0.000887, l3: 0.000536, l4: 0.000826, l5: 0.001236, l6: 0.001456

[epoch:   7/1000, batch:  1048/ 1052, ite: 1840] train loss: 0.045927, tar: 0.011529 
[Epoch 7/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.001019, l1: 0.000835, l2: 0.000940, l3: 0.000994, l4: 0.001183, l5: 0.001763, l6: 0.002964

[epoch:   8/1000, batch:    76/ 1052, ite: 1860] train loss: 0.045558, tar: 0.011417 
l0: 0.000797, l1: 0.000576, l2: 0.001704, l3: 0.001019, l4: 0.001046, l5: 0.001129, l6: 0.001657

[epoch:   8/1000, batch:   156/ 1052, ite: 1880] train loss: 0.045193, tar: 0.011307 
l0: 0.000737, l1: 0.000595, l2: 0.000694, l3: 0.000802, l4: 0.001032, l5: 0.001795, l6: 0.001765

[epoch:   8/1000, batch:   236/ 1052, ite: 1900] train loss: 0.044905, tar: 0.011207 
l0: 0.001132, l1: 0.001245, l2: 0.001111, l3: 0.001268, l4: 0.001454, l5: 0.002338, l6: 0.002507

[epoch:   8/1000, batch:   316/ 1052, ite: 1920] train loss: 0.044576, tar: 0.011107 
l0: 0.001142, l1: 0.000951, l2: 0.000740, l3: 0.000784, l4: 0.000939, l5: 0.001319, l6: 0.002212

[epoch:   8/1000, batch:   396/ 1052, ite: 1940] train loss: 0.044274, tar: 0.011010 
l0: 0.002569, l1: 0.001538, l2: 0.001670, l3: 0.001339, l4: 0.001100, l5: 0.001364, l6: 0.001233

[epoch:   8/1000, batch:   476/ 1052, ite: 1960] train loss: 0.044015, tar: 0.010917 
l0: 0.001820, l1: 0.001634, l2: 0.001164, l3: 0.001050, l4: 0.000980, l5: 0.000956, l6: 0.001519

[epoch:   8/1000, batch:   556/ 1052, ite: 1980] train loss: 0.043715, tar: 0.010825 
l0: 0.001136, l1: 0.000565, l2: 0.000868, l3: 0.000839, l4: 0.001282, l5: 0.001745, l6: 0.003124

[epoch:   8/1000, batch:   636/ 1052, ite: 2000] train loss: 0.043385, tar: 0.010728 
l0: 0.001866, l1: 0.002306, l2: 0.001766, l3: 0.002110, l4: 0.002601, l5: 0.005596, l6: 0.004808

[epoch:   8/1000, batch:   716/ 1052, ite: 2020] train loss: 0.043070, tar: 0.010635 
l0: 0.002033, l1: 0.003284, l2: 0.004026, l3: 0.004070, l4: 0.001980, l5: 0.002948, l6: 0.002978

[epoch:   8/1000, batch:   796/ 1052, ite: 2040] train loss: 0.042743, tar: 0.010540 
l0: 0.001593, l1: 0.001038, l2: 0.001351, l3: 0.001664, l4: 0.001651, l5: 0.001768, l6: 0.003232

[epoch:   8/1000, batch:   876/ 1052, ite: 2060] train loss: 0.042453, tar: 0.010450 
l0: 0.001957, l1: 0.001538, l2: 0.001030, l3: 0.001073, l4: 0.001391, l5: 0.001513, l6: 0.002118

[epoch:   8/1000, batch:   956/ 1052, ite: 2080] train loss: 0.042193, tar: 0.010367 
l0: 0.000553, l1: 0.000425, l2: 0.000648, l3: 0.000656, l4: 0.001021, l5: 0.001587, l6: 0.002728

[epoch:   8/1000, batch:  1036/ 1052, ite: 2100] train loss: 0.041907, tar: 0.010280 
[Epoch 8/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.001397, l1: 0.002379, l2: 0.001514, l3: 0.001320, l4: 0.001208, l5: 0.001688, l6: 0.003087

[epoch:   9/1000, batch:    64/ 1052, ite: 2120] train loss: 0.041618, tar: 0.010194 
l0: 0.000920, l1: 0.001404, l2: 0.000858, l3: 0.000901, l4: 0.000980, l5: 0.001804, l6: 0.001842

[epoch:   9/1000, batch:   144/ 1052, ite: 2140] train loss: 0.041332, tar: 0.010109 
l0: 0.001285, l1: 0.001369, l2: 0.001160, l3: 0.001389, l4: 0.001656, l5: 0.002353, l6: 0.003208

[epoch:   9/1000, batch:   224/ 1052, ite: 2160] train loss: 0.041059, tar: 0.010027 
l0: 0.000858, l1: 0.000589, l2: 0.000826, l3: 0.000977, l4: 0.001512, l5: 0.002514, l6: 0.002767

[epoch:   9/1000, batch:   304/ 1052, ite: 2180] train loss: 0.040788, tar: 0.009946 
l0: 0.000386, l1: 0.000341, l2: 0.000468, l3: 0.000381, l4: 0.000509, l5: 0.000706, l6: 0.001389

[epoch:   9/1000, batch:   384/ 1052, ite: 2200] train loss: 0.040501, tar: 0.009864 
l0: 0.001175, l1: 0.000961, l2: 0.001195, l3: 0.001135, l4: 0.001722, l5: 0.002031, l6: 0.003510

[epoch:   9/1000, batch:   464/ 1052, ite: 2220] train loss: 0.040254, tar: 0.009787 
l0: 0.001316, l1: 0.001746, l2: 0.001455, l3: 0.001699, l4: 0.001780, l5: 0.002666, l6: 0.003865

[epoch:   9/1000, batch:   544/ 1052, ite: 2240] train loss: 0.040010, tar: 0.009711 
l0: 0.000968, l1: 0.000539, l2: 0.000782, l3: 0.000766, l4: 0.000968, l5: 0.001173, l6: 0.003100

[epoch:   9/1000, batch:   624/ 1052, ite: 2260] train loss: 0.039797, tar: 0.009642 
l0: 0.000711, l1: 0.000377, l2: 0.001188, l3: 0.000943, l4: 0.000754, l5: 0.001067, l6: 0.002148

[epoch:   9/1000, batch:   704/ 1052, ite: 2280] train loss: 0.039621, tar: 0.009576 
l0: 0.001993, l1: 0.001859, l2: 0.001369, l3: 0.001219, l4: 0.001862, l5: 0.003539, l6: 0.004471

[epoch:   9/1000, batch:   784/ 1052, ite: 2300] train loss: 0.039399, tar: 0.009506 
l0: 0.001129, l1: 0.000709, l2: 0.001129, l3: 0.001424, l4: 0.001704, l5: 0.002927, l6: 0.003904

[epoch:   9/1000, batch:   864/ 1052, ite: 2320] train loss: 0.039179, tar: 0.009436 
l0: 0.000785, l1: 0.000744, l2: 0.000997, l3: 0.000868, l4: 0.000927, l5: 0.001229, l6: 0.001204

[epoch:   9/1000, batch:   944/ 1052, ite: 2340] train loss: 0.038964, tar: 0.009368 
l0: 0.001085, l1: 0.001299, l2: 0.001014, l3: 0.001066, l4: 0.001122, l5: 0.001936, l6: 0.002763

[epoch:   9/1000, batch:  1024/ 1052, ite: 2360] train loss: 0.038716, tar: 0.009297 
[Epoch 9/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000371, l1: 0.000277, l2: 0.000427, l3: 0.000515, l4: 0.000590, l5: 0.000825, l6: 0.001611

[epoch:  10/1000, batch:    52/ 1052, ite: 2380] train loss: 0.038469, tar: 0.009228 
l0: 0.001142, l1: 0.000810, l2: 0.001047, l3: 0.000980, l4: 0.001480, l5: 0.002496, l6: 0.002840

[epoch:  10/1000, batch:   132/ 1052, ite: 2400] train loss: 0.038231, tar: 0.009159 
l0: 0.001046, l1: 0.000751, l2: 0.000709, l3: 0.000640, l4: 0.000742, l5: 0.001270, l6: 0.002439

[epoch:  10/1000, batch:   212/ 1052, ite: 2420] train loss: 0.038022, tar: 0.009095 
l0: 0.000924, l1: 0.000899, l2: 0.001046, l3: 0.001044, l4: 0.001323, l5: 0.001643, l6: 0.002704

[epoch:  10/1000, batch:   292/ 1052, ite: 2440] train loss: 0.037799, tar: 0.009029 
l0: 0.001370, l1: 0.001621, l2: 0.000883, l3: 0.000708, l4: 0.000989, l5: 0.001277, l6: 0.001227

[epoch:  10/1000, batch:   372/ 1052, ite: 2460] train loss: 0.037597, tar: 0.008968 
l0: 0.000843, l1: 0.000478, l2: 0.000684, l3: 0.000745, l4: 0.001165, l5: 0.001798, l6: 0.003005

[epoch:  10/1000, batch:   452/ 1052, ite: 2480] train loss: 0.037402, tar: 0.008906 
l0: 0.002860, l1: 0.002976, l2: 0.002628, l3: 0.003000, l4: 0.002596, l5: 0.002484, l6: 0.002605

[epoch:  10/1000, batch:   532/ 1052, ite: 2500] train loss: 0.037217, tar: 0.008849 
l0: 0.000974, l1: 0.000979, l2: 0.001079, l3: 0.001280, l4: 0.001636, l5: 0.002956, l6: 0.003028

[epoch:  10/1000, batch:   612/ 1052, ite: 2520] train loss: 0.037009, tar: 0.008787 
l0: 0.001027, l1: 0.001147, l2: 0.001025, l3: 0.001399, l4: 0.001735, l5: 0.002098, l6: 0.003482

[epoch:  10/1000, batch:   692/ 1052, ite: 2540] train loss: 0.036803, tar: 0.008727 
l0: 0.002360, l1: 0.002206, l2: 0.002281, l3: 0.002081, l4: 0.002476, l5: 0.004110, l6: 0.005304

[epoch:  10/1000, batch:   772/ 1052, ite: 2560] train loss: 0.036661, tar: 0.008675 
l0: 0.000805, l1: 0.000657, l2: 0.000886, l3: 0.000893, l4: 0.001080, l5: 0.002097, l6: 0.002816

[epoch:  10/1000, batch:   852/ 1052, ite: 2580] train loss: 0.036472, tar: 0.008620 
l0: 0.000707, l1: 0.000829, l2: 0.000746, l3: 0.000762, l4: 0.000922, l5: 0.001196, l6: 0.001878

[epoch:  10/1000, batch:   932/ 1052, ite: 2600] train loss: 0.036271, tar: 0.008562 
l0: 0.001542, l1: 0.001001, l2: 0.001036, l3: 0.001230, l4: 0.001390, l5: 0.001875, l6: 0.003144

[epoch:  10/1000, batch:  1012/ 1052, ite: 2620] train loss: 0.036106, tar: 0.008508 
[Epoch 10/1000] Test loss: 0.013, Test target loss: 0.001
l0: 0.000848, l1: 0.000766, l2: 0.000804, l3: 0.000809, l4: 0.001086, l5: 0.001385, l6: 0.003231

[epoch:  11/1000, batch:    40/ 1052, ite: 2640] train loss: 0.035919, tar: 0.008451 
l0: 0.001212, l1: 0.000984, l2: 0.000793, l3: 0.001172, l4: 0.001156, l5: 0.001517, l6: 0.001758

[epoch:  11/1000, batch:   120/ 1052, ite: 2660] train loss: 0.035726, tar: 0.008396 
l0: 0.001003, l1: 0.001056, l2: 0.000679, l3: 0.000825, l4: 0.000853, l5: 0.001271, l6: 0.001618

[epoch:  11/1000, batch:   200/ 1052, ite: 2680] train loss: 0.035544, tar: 0.008342 
l0: 0.000994, l1: 0.000481, l2: 0.000977, l3: 0.000937, l4: 0.001308, l5: 0.002296, l6: 0.002816

[epoch:  11/1000, batch:   280/ 1052, ite: 2700] train loss: 0.035364, tar: 0.008289 
l0: 0.001331, l1: 0.001111, l2: 0.001277, l3: 0.001405, l4: 0.001922, l5: 0.002862, l6: 0.004483

[epoch:  11/1000, batch:   360/ 1052, ite: 2720] train loss: 0.035191, tar: 0.008237 
l0: 0.001177, l1: 0.000801, l2: 0.001071, l3: 0.001162, l4: 0.001719, l5: 0.002597, l6: 0.004685

[epoch:  11/1000, batch:   440/ 1052, ite: 2740] train loss: 0.035006, tar: 0.008184 
l0: 0.001228, l1: 0.001147, l2: 0.000886, l3: 0.001008, l4: 0.001037, l5: 0.001609, l6: 0.002537

[epoch:  11/1000, batch:   520/ 1052, ite: 2760] train loss: 0.034843, tar: 0.008133 
l0: 0.001835, l1: 0.001632, l2: 0.001386, l3: 0.001349, l4: 0.001765, l5: 0.004429, l6: 0.004222

[epoch:  11/1000, batch:   600/ 1052, ite: 2780] train loss: 0.034682, tar: 0.008085 
l0: 0.001344, l1: 0.000865, l2: 0.000735, l3: 0.000848, l4: 0.001253, l5: 0.001703, l6: 0.002881

[epoch:  11/1000, batch:   680/ 1052, ite: 2800] train loss: 0.034506, tar: 0.008034 
l0: 0.000930, l1: 0.001471, l2: 0.001359, l3: 0.001474, l4: 0.001698, l5: 0.001866, l6: 0.001758

[epoch:  11/1000, batch:   760/ 1052, ite: 2820] train loss: 0.034343, tar: 0.007985 
l0: 0.001299, l1: 0.000805, l2: 0.000941, l3: 0.000912, l4: 0.001300, l5: 0.001914, l6: 0.002406

[epoch:  11/1000, batch:   840/ 1052, ite: 2840] train loss: 0.034186, tar: 0.007938 
l0: 0.001118, l1: 0.000763, l2: 0.000755, l3: 0.000851, l4: 0.001181, l5: 0.002168, l6: 0.002431

[epoch:  11/1000, batch:   920/ 1052, ite: 2860] train loss: 0.034071, tar: 0.007897 
l0: 0.001477, l1: 0.002233, l2: 0.001733, l3: 0.002020, l4: 0.002144, l5: 0.002239, l6: 0.003198

[epoch:  11/1000, batch:  1000/ 1052, ite: 2880] train loss: 0.033923, tar: 0.007851 
[Epoch 11/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.001526, l1: 0.001508, l2: 0.001496, l3: 0.001465, l4: 0.003189, l5: 0.003421, l6: 0.003280

[epoch:  12/1000, batch:    28/ 1052, ite: 2900] train loss: 0.033812, tar: 0.007810 
l0: 0.000654, l1: 0.000526, l2: 0.000629, l3: 0.000778, l4: 0.001088, l5: 0.001477, l6: 0.002251

[epoch:  12/1000, batch:   108/ 1052, ite: 2920] train loss: 0.033679, tar: 0.007767 
l0: 0.001268, l1: 0.001844, l2: 0.001528, l3: 0.001559, l4: 0.002119, l5: 0.002277, l6: 0.002603

[epoch:  12/1000, batch:   188/ 1052, ite: 2940] train loss: 0.033522, tar: 0.007722 
l0: 0.002486, l1: 0.002606, l2: 0.002119, l3: 0.001966, l4: 0.002012, l5: 0.002757, l6: 0.003487

[epoch:  12/1000, batch:   268/ 1052, ite: 2960] train loss: 0.033416, tar: 0.007682 
l0: 0.000547, l1: 0.000418, l2: 0.000558, l3: 0.000517, l4: 0.000691, l5: 0.000999, l6: 0.001722

[epoch:  12/1000, batch:   348/ 1052, ite: 2980] train loss: 0.033278, tar: 0.007641 
l0: 0.001672, l1: 0.001050, l2: 0.001776, l3: 0.002069, l4: 0.002227, l5: 0.002445, l6: 0.004194

[epoch:  12/1000, batch:   428/ 1052, ite: 3000] train loss: 0.033146, tar: 0.007599 
l0: 0.003175, l1: 0.002332, l2: 0.001709, l3: 0.001352, l4: 0.001387, l5: 0.001787, l6: 0.001841

[epoch:  12/1000, batch:   508/ 1052, ite: 3020] train loss: 0.033015, tar: 0.007559 
l0: 0.001425, l1: 0.001753, l2: 0.001634, l3: 0.002134, l4: 0.002664, l5: 0.003700, l6: 0.004223

[epoch:  12/1000, batch:   588/ 1052, ite: 3040] train loss: 0.032882, tar: 0.007518 
l0: 0.001937, l1: 0.002941, l2: 0.002195, l3: 0.001820, l4: 0.002092, l5: 0.003326, l6: 0.004090

[epoch:  12/1000, batch:   668/ 1052, ite: 3060] train loss: 0.032734, tar: 0.007476 
l0: 0.000855, l1: 0.000434, l2: 0.001097, l3: 0.001114, l4: 0.001145, l5: 0.001405, l6: 0.001836

[epoch:  12/1000, batch:   748/ 1052, ite: 3080] train loss: 0.032591, tar: 0.007434 
l0: 0.000903, l1: 0.000675, l2: 0.000835, l3: 0.001039, l4: 0.001775, l5: 0.002250, l6: 0.003124

[epoch:  12/1000, batch:   828/ 1052, ite: 3100] train loss: 0.032451, tar: 0.007393 
l0: 0.001305, l1: 0.001457, l2: 0.001258, l3: 0.001611, l4: 0.001752, l5: 0.001795, l6: 0.002304

[epoch:  12/1000, batch:   908/ 1052, ite: 3120] train loss: 0.032315, tar: 0.007353 
l0: 0.001476, l1: 0.000643, l2: 0.000889, l3: 0.000798, l4: 0.001137, l5: 0.001701, l6: 0.002344

[epoch:  12/1000, batch:   988/ 1052, ite: 3140] train loss: 0.032224, tar: 0.007320 
[Epoch 12/1000] Test loss: 0.013, Test target loss: 0.001
l0: 0.001788, l1: 0.002326, l2: 0.001559, l3: 0.001683, l4: 0.002207, l5: 0.005933, l6: 0.004730

[epoch:  13/1000, batch:    16/ 1052, ite: 3160] train loss: 0.032101, tar: 0.007283 
l0: 0.000773, l1: 0.000522, l2: 0.000922, l3: 0.000710, l4: 0.000773, l5: 0.001459, l6: 0.001815

[epoch:  13/1000, batch:    96/ 1052, ite: 3180] train loss: 0.031978, tar: 0.007245 
l0: 0.000921, l1: 0.000889, l2: 0.001121, l3: 0.001261, l4: 0.001578, l5: 0.001648, l6: 0.002918

[epoch:  13/1000, batch:   176/ 1052, ite: 3200] train loss: 0.031841, tar: 0.007206 
l0: 0.000750, l1: 0.000795, l2: 0.000689, l3: 0.000678, l4: 0.000755, l5: 0.001200, l6: 0.001853

[epoch:  13/1000, batch:   256/ 1052, ite: 3220] train loss: 0.031718, tar: 0.007169 
l0: 0.001547, l1: 0.002200, l2: 0.001514, l3: 0.001657, l4: 0.002163, l5: 0.002128, l6: 0.003075

[epoch:  13/1000, batch:   336/ 1052, ite: 3240] train loss: 0.031603, tar: 0.007133 
l0: 0.001919, l1: 0.002883, l2: 0.001741, l3: 0.002118, l4: 0.002454, l5: 0.003843, l6: 0.004378

[epoch:  13/1000, batch:   416/ 1052, ite: 3260] train loss: 0.031487, tar: 0.007098 
l0: 0.000642, l1: 0.000480, l2: 0.000554, l3: 0.000588, l4: 0.000800, l5: 0.001169, l6: 0.001494

[epoch:  13/1000, batch:   496/ 1052, ite: 3280] train loss: 0.031359, tar: 0.007061 
l0: 0.001704, l1: 0.001914, l2: 0.002005, l3: 0.003008, l4: 0.002595, l5: 0.002292, l6: 0.002438

[epoch:  13/1000, batch:   576/ 1052, ite: 3300] train loss: 0.031240, tar: 0.007026 
l0: 0.000915, l1: 0.001029, l2: 0.000867, l3: 0.000971, l4: 0.001058, l5: 0.001447, l6: 0.001863

[epoch:  13/1000, batch:   656/ 1052, ite: 3320] train loss: 0.031123, tar: 0.006990 
l0: 0.002151, l1: 0.001017, l2: 0.001403, l3: 0.001678, l4: 0.001853, l5: 0.001858, l6: 0.002600

[epoch:  13/1000, batch:   736/ 1052, ite: 3340] train loss: 0.031060, tar: 0.006964 
l0: 0.002272, l1: 0.002348, l2: 0.002896, l3: 0.002412, l4: 0.002143, l5: 0.002150, l6: 0.003466

[epoch:  13/1000, batch:   816/ 1052, ite: 3360] train loss: 0.030950, tar: 0.006931 
l0: 0.001021, l1: 0.000652, l2: 0.000517, l3: 0.000428, l4: 0.000653, l5: 0.000771, l6: 0.001378

[epoch:  13/1000, batch:   896/ 1052, ite: 3380] train loss: 0.030844, tar: 0.006899 
l0: 0.000414, l1: 0.000267, l2: 0.000535, l3: 0.000615, l4: 0.000649, l5: 0.001099, l6: 0.001569

[epoch:  13/1000, batch:   976/ 1052, ite: 3400] train loss: 0.030727, tar: 0.006865 
[Epoch 13/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.001581, l1: 0.001711, l2: 0.001414, l3: 0.001182, l4: 0.001547, l5: 0.002114, l6: 0.003336

[epoch:  14/1000, batch:     4/ 1052, ite: 3420] train loss: 0.030613, tar: 0.006832 
l0: 0.000860, l1: 0.000713, l2: 0.000835, l3: 0.000682, l4: 0.000760, l5: 0.001209, l6: 0.001124

[epoch:  14/1000, batch:    84/ 1052, ite: 3440] train loss: 0.030510, tar: 0.006800 
l0: 0.000926, l1: 0.000713, l2: 0.000775, l3: 0.000865, l4: 0.001080, l5: 0.001459, l6: 0.002984

[epoch:  14/1000, batch:   164/ 1052, ite: 3460] train loss: 0.030391, tar: 0.006767 
l0: 0.000589, l1: 0.000487, l2: 0.000513, l3: 0.000556, l4: 0.000895, l5: 0.001297, l6: 0.002063

[epoch:  14/1000, batch:   244/ 1052, ite: 3480] train loss: 0.030264, tar: 0.006733 
l0: 0.000885, l1: 0.000748, l2: 0.000709, l3: 0.000671, l4: 0.000935, l5: 0.001714, l6: 0.002067

[epoch:  14/1000, batch:   324/ 1052, ite: 3500] train loss: 0.030148, tar: 0.006700 
l0: 0.000841, l1: 0.000598, l2: 0.000700, l3: 0.000908, l4: 0.001120, l5: 0.002134, l6: 0.002699

[epoch:  14/1000, batch:   404/ 1052, ite: 3520] train loss: 0.030021, tar: 0.006666 
l0: 0.002527, l1: 0.002884, l2: 0.002185, l3: 0.001689, l4: 0.003422, l5: 0.004223, l6: 0.005690

[epoch:  14/1000, batch:   484/ 1052, ite: 3540] train loss: 0.029906, tar: 0.006634 
l0: 0.001565, l1: 0.001053, l2: 0.001037, l3: 0.001495, l4: 0.002078, l5: 0.002512, l6: 0.003638

[epoch:  14/1000, batch:   564/ 1052, ite: 3560] train loss: 0.029806, tar: 0.006604 
l0: 0.000646, l1: 0.000525, l2: 0.000404, l3: 0.000523, l4: 0.000886, l5: 0.001293, l6: 0.001679

[epoch:  14/1000, batch:   644/ 1052, ite: 3580] train loss: 0.029701, tar: 0.006574 
l0: 0.000519, l1: 0.000562, l2: 0.000450, l3: 0.000650, l4: 0.000965, l5: 0.001554, l6: 0.002505

[epoch:  14/1000, batch:   724/ 1052, ite: 3600] train loss: 0.029593, tar: 0.006542 
l0: 0.000493, l1: 0.000251, l2: 0.000360, l3: 0.000444, l4: 0.000600, l5: 0.000804, l6: 0.001395

[epoch:  14/1000, batch:   804/ 1052, ite: 3620] train loss: 0.029479, tar: 0.006511 
l0: 0.001201, l1: 0.000733, l2: 0.001221, l3: 0.001088, l4: 0.001237, l5: 0.002513, l6: 0.003148

[epoch:  14/1000, batch:   884/ 1052, ite: 3640] train loss: 0.029397, tar: 0.006484 
l0: 0.001172, l1: 0.001533, l2: 0.002385, l3: 0.001112, l4: 0.001027, l5: 0.001416, l6: 0.002168

[epoch:  14/1000, batch:   964/ 1052, ite: 3660] train loss: 0.029361, tar: 0.006462 
l0: 0.001001, l1: 0.001030, l2: 0.000933, l3: 0.000827, l4: 0.000964, l5: 0.001052, l6: 0.001780

[epoch:  14/1000, batch:  1044/ 1052, ite: 3680] train loss: 0.029260, tar: 0.006434 
[Epoch 14/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.001551, l1: 0.001069, l2: 0.001476, l3: 0.001760, l4: 0.001420, l5: 0.001978, l6: 0.003175

[epoch:  15/1000, batch:    72/ 1052, ite: 3700] train loss: 0.029171, tar: 0.006406 
l0: 0.000809, l1: 0.001119, l2: 0.000903, l3: 0.000879, l4: 0.001186, l5: 0.001683, l6: 0.002144

[epoch:  15/1000, batch:   152/ 1052, ite: 3720] train loss: 0.029068, tar: 0.006377 
l0: 0.003866, l1: 0.006170, l2: 0.005085, l3: 0.005206, l4: 0.004741, l5: 0.005658, l6: 0.005893

[epoch:  15/1000, batch:   232/ 1052, ite: 3740] train loss: 0.028967, tar: 0.006349 
l0: 0.001021, l1: 0.000501, l2: 0.000564, l3: 0.000717, l4: 0.000718, l5: 0.001075, l6: 0.001060

[epoch:  15/1000, batch:   312/ 1052, ite: 3760] train loss: 0.028870, tar: 0.006322 
l0: 0.003018, l1: 0.003589, l2: 0.003687, l3: 0.004182, l4: 0.004818, l5: 0.005117, l6: 0.005903

[epoch:  15/1000, batch:   392/ 1052, ite: 3780] train loss: 0.028779, tar: 0.006295 
l0: 0.001191, l1: 0.001075, l2: 0.001114, l3: 0.001412, l4: 0.001697, l5: 0.004232, l6: 0.002972

[epoch:  15/1000, batch:   472/ 1052, ite: 3800] train loss: 0.028685, tar: 0.006268 
l0: 0.002734, l1: 0.002886, l2: 0.002326, l3: 0.002512, l4: 0.005234, l5: 0.006208, l6: 0.007746

[epoch:  15/1000, batch:   552/ 1052, ite: 3820] train loss: 0.028605, tar: 0.006242 
l0: 0.000852, l1: 0.001171, l2: 0.001272, l3: 0.001216, l4: 0.000951, l5: 0.001364, l6: 0.001655

[epoch:  15/1000, batch:   632/ 1052, ite: 3840] train loss: 0.028516, tar: 0.006216 
l0: 0.000550, l1: 0.000363, l2: 0.000440, l3: 0.000528, l4: 0.000901, l5: 0.001094, l6: 0.001798

[epoch:  15/1000, batch:   712/ 1052, ite: 3860] train loss: 0.028416, tar: 0.006189 
l0: 0.001030, l1: 0.001037, l2: 0.000812, l3: 0.000870, l4: 0.001304, l5: 0.002010, l6: 0.002871

[epoch:  15/1000, batch:   792/ 1052, ite: 3880] train loss: 0.028316, tar: 0.006162 
l0: 0.000671, l1: 0.000911, l2: 0.000878, l3: 0.000912, l4: 0.001054, l5: 0.001192, l6: 0.002291

[epoch:  15/1000, batch:   872/ 1052, ite: 3900] train loss: 0.028222, tar: 0.006135 
l0: 0.001005, l1: 0.000840, l2: 0.000810, l3: 0.000759, l4: 0.001027, l5: 0.001234, l6: 0.002285

[epoch:  15/1000, batch:   952/ 1052, ite: 3920] train loss: 0.028131, tar: 0.006109 
l0: 0.000908, l1: 0.000445, l2: 0.000733, l3: 0.000809, l4: 0.000880, l5: 0.001066, l6: 0.001626

[epoch:  15/1000, batch:  1032/ 1052, ite: 3940] train loss: 0.028090, tar: 0.006091 
[Epoch 15/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000740, l1: 0.000952, l2: 0.000756, l3: 0.000796, l4: 0.000689, l5: 0.000877, l6: 0.001333

[epoch:  16/1000, batch:    60/ 1052, ite: 3960] train loss: 0.028001, tar: 0.006066 
l0: 0.001672, l1: 0.001718, l2: 0.001930, l3: 0.002383, l4: 0.002154, l5: 0.003824, l6: 0.003593

[epoch:  16/1000, batch:   140/ 1052, ite: 3980] train loss: 0.027930, tar: 0.006042 
l0: 0.000342, l1: 0.000394, l2: 0.000387, l3: 0.000424, l4: 0.000827, l5: 0.001043, l6: 0.000969

[epoch:  16/1000, batch:   220/ 1052, ite: 4000] train loss: 0.027830, tar: 0.006016 
l0: 0.000902, l1: 0.000961, l2: 0.000939, l3: 0.001004, l4: 0.001173, l5: 0.001726, l6: 0.002697

[epoch:  16/1000, batch:   300/ 1052, ite: 4020] train loss: 0.027740, tar: 0.005990 
l0: 0.000653, l1: 0.000551, l2: 0.000638, l3: 0.000677, l4: 0.000955, l5: 0.001424, l6: 0.001757

[epoch:  16/1000, batch:   380/ 1052, ite: 4040] train loss: 0.027645, tar: 0.005965 
l0: 0.001338, l1: 0.001129, l2: 0.001440, l3: 0.001401, l4: 0.001455, l5: 0.001819, l6: 0.002425

[epoch:  16/1000, batch:   460/ 1052, ite: 4060] train loss: 0.027563, tar: 0.005941 
l0: 0.001568, l1: 0.001797, l2: 0.001472, l3: 0.001729, l4: 0.001681, l5: 0.002816, l6: 0.003441

[epoch:  16/1000, batch:   540/ 1052, ite: 4080] train loss: 0.027494, tar: 0.005918 
l0: 0.001383, l1: 0.001063, l2: 0.001304, l3: 0.001428, l4: 0.002083, l5: 0.003040, l6: 0.004275

[epoch:  16/1000, batch:   620/ 1052, ite: 4100] train loss: 0.027416, tar: 0.005895 
l0: 0.000572, l1: 0.000545, l2: 0.000627, l3: 0.000444, l4: 0.000790, l5: 0.001365, l6: 0.001982

[epoch:  16/1000, batch:   700/ 1052, ite: 4120] train loss: 0.027364, tar: 0.005875 
l0: 0.001435, l1: 0.002024, l2: 0.001474, l3: 0.001651, l4: 0.001837, l5: 0.002442, l6: 0.002750

[epoch:  16/1000, batch:   780/ 1052, ite: 4140] train loss: 0.027290, tar: 0.005853 
l0: 0.000470, l1: 0.000356, l2: 0.000501, l3: 0.000528, l4: 0.000720, l5: 0.001372, l6: 0.001436

[epoch:  16/1000, batch:   860/ 1052, ite: 4160] train loss: 0.027211, tar: 0.005830 
l0: 0.003400, l1: 0.003378, l2: 0.003104, l3: 0.003490, l4: 0.005929, l5: 0.006207, l6: 0.009151

[epoch:  16/1000, batch:   940/ 1052, ite: 4180] train loss: 0.027128, tar: 0.005806 
l0: 0.001971, l1: 0.001993, l2: 0.004506, l3: 0.004276, l4: 0.003651, l5: 0.003709, l6: 0.005003

[epoch:  16/1000, batch:  1020/ 1052, ite: 4200] train loss: 0.027049, tar: 0.005783 
[Epoch 16/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000541, l1: 0.000367, l2: 0.000714, l3: 0.001001, l4: 0.001071, l5: 0.001323, l6: 0.002197

[epoch:  17/1000, batch:    48/ 1052, ite: 4220] train loss: 0.026974, tar: 0.005760 
l0: 0.001309, l1: 0.001260, l2: 0.001407, l3: 0.001392, l4: 0.001965, l5: 0.002062, l6: 0.002674

[epoch:  17/1000, batch:   128/ 1052, ite: 4240] train loss: 0.026903, tar: 0.005740 
l0: 0.001104, l1: 0.001192, l2: 0.001023, l3: 0.001114, l4: 0.001453, l5: 0.001499, l6: 0.002274

[epoch:  17/1000, batch:   208/ 1052, ite: 4260] train loss: 0.026853, tar: 0.005721 
l0: 0.000903, l1: 0.000629, l2: 0.001288, l3: 0.001000, l4: 0.001047, l5: 0.001387, l6: 0.002206

[epoch:  17/1000, batch:   288/ 1052, ite: 4280] train loss: 0.026779, tar: 0.005699 
l0: 0.000827, l1: 0.000872, l2: 0.001165, l3: 0.001078, l4: 0.000969, l5: 0.001326, l6: 0.003352

[epoch:  17/1000, batch:   368/ 1052, ite: 4300] train loss: 0.026712, tar: 0.005678 
l0: 0.001026, l1: 0.000733, l2: 0.000779, l3: 0.000963, l4: 0.001292, l5: 0.002109, l6: 0.003166

[epoch:  17/1000, batch:   448/ 1052, ite: 4320] train loss: 0.026671, tar: 0.005661 
l0: 0.000842, l1: 0.000687, l2: 0.000775, l3: 0.000892, l4: 0.001160, l5: 0.002275, l6: 0.002961

[epoch:  17/1000, batch:   528/ 1052, ite: 4340] train loss: 0.026604, tar: 0.005641 
l0: 0.000699, l1: 0.000554, l2: 0.000693, l3: 0.000834, l4: 0.001074, l5: 0.001427, l6: 0.002256

[epoch:  17/1000, batch:   608/ 1052, ite: 4360] train loss: 0.026532, tar: 0.005620 
l0: 0.000883, l1: 0.001112, l2: 0.000903, l3: 0.000811, l4: 0.001048, l5: 0.001523, l6: 0.002139

[epoch:  17/1000, batch:   688/ 1052, ite: 4380] train loss: 0.026456, tar: 0.005599 
l0: 0.000634, l1: 0.000403, l2: 0.000570, l3: 0.000704, l4: 0.000851, l5: 0.001326, l6: 0.002309

[epoch:  17/1000, batch:   768/ 1052, ite: 4400] train loss: 0.026380, tar: 0.005577 
l0: 0.001567, l1: 0.001680, l2: 0.001597, l3: 0.001929, l4: 0.002004, l5: 0.002868, l6: 0.004305

[epoch:  17/1000, batch:   848/ 1052, ite: 4420] train loss: 0.026296, tar: 0.005556 
l0: 0.001154, l1: 0.001480, l2: 0.001262, l3: 0.000952, l4: 0.001157, l5: 0.001512, l6: 0.003410

[epoch:  17/1000, batch:   928/ 1052, ite: 4440] train loss: 0.026222, tar: 0.005535 
l0: 0.001620, l1: 0.001960, l2: 0.001766, l3: 0.001611, l4: 0.002012, l5: 0.002438, l6: 0.003239

[epoch:  17/1000, batch:  1008/ 1052, ite: 4460] train loss: 0.026144, tar: 0.005514 
[Epoch 17/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.001373, l1: 0.001339, l2: 0.001502, l3: 0.001640, l4: 0.002262, l5: 0.003603, l6: 0.003576

[epoch:  18/1000, batch:    36/ 1052, ite: 4480] train loss: 0.026069, tar: 0.005493 
l0: 0.000426, l1: 0.000283, l2: 0.000333, l3: 0.000415, l4: 0.000673, l5: 0.001150, l6: 0.001633

[epoch:  18/1000, batch:   116/ 1052, ite: 4500] train loss: 0.025989, tar: 0.005472 
l0: 0.003179, l1: 0.003294, l2: 0.003710, l3: 0.002859, l4: 0.003649, l5: 0.004903, l6: 0.006225

[epoch:  18/1000, batch:   196/ 1052, ite: 4520] train loss: 0.025965, tar: 0.005459 
l0: 0.000568, l1: 0.000404, l2: 0.000735, l3: 0.000669, l4: 0.000596, l5: 0.001261, l6: 0.001764

[epoch:  18/1000, batch:   276/ 1052, ite: 4540] train loss: 0.025907, tar: 0.005441 
l0: 0.001111, l1: 0.000756, l2: 0.001217, l3: 0.001390, l4: 0.001690, l5: 0.002398, l6: 0.002161

[epoch:  18/1000, batch:   356/ 1052, ite: 4560] train loss: 0.025844, tar: 0.005422 
l0: 0.001252, l1: 0.001286, l2: 0.001294, l3: 0.001191, l4: 0.001327, l5: 0.002009, l6: 0.002443

[epoch:  18/1000, batch:   436/ 1052, ite: 4580] train loss: 0.025782, tar: 0.005403 
l0: 0.000434, l1: 0.000431, l2: 0.000603, l3: 0.000498, l4: 0.000601, l5: 0.000980, l6: 0.001528

[epoch:  18/1000, batch:   516/ 1052, ite: 4600] train loss: 0.025714, tar: 0.005384 
l0: 0.002344, l1: 0.002431, l2: 0.002759, l3: 0.003108, l4: 0.002845, l5: 0.004803, l6: 0.004990

[epoch:  18/1000, batch:   596/ 1052, ite: 4620] train loss: 0.025656, tar: 0.005367 
l0: 0.000857, l1: 0.000967, l2: 0.001134, l3: 0.001484, l4: 0.001944, l5: 0.001899, l6: 0.002748

[epoch:  18/1000, batch:   676/ 1052, ite: 4640] train loss: 0.025587, tar: 0.005348 
l0: 0.000860, l1: 0.000621, l2: 0.000973, l3: 0.000976, l4: 0.001222, l5: 0.001539, l6: 0.002857

[epoch:  18/1000, batch:   756/ 1052, ite: 4660] train loss: 0.025516, tar: 0.005328 
l0: 0.000997, l1: 0.001037, l2: 0.000791, l3: 0.001300, l4: 0.001616, l5: 0.001886, l6: 0.002460

[epoch:  18/1000, batch:   836/ 1052, ite: 4680] train loss: 0.025448, tar: 0.005310 
l0: 0.001008, l1: 0.001122, l2: 0.000828, l3: 0.001034, l4: 0.001008, l5: 0.001460, l6: 0.002621

[epoch:  18/1000, batch:   916/ 1052, ite: 4700] train loss: 0.025388, tar: 0.005292 
l0: 0.000532, l1: 0.000388, l2: 0.000984, l3: 0.000491, l4: 0.001798, l5: 0.002410, l6: 0.001627

[epoch:  18/1000, batch:   996/ 1052, ite: 4720] train loss: 0.025326, tar: 0.005274 
[Epoch 18/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000703, l1: 0.000631, l2: 0.000566, l3: 0.000698, l4: 0.000954, l5: 0.001323, l6: 0.002418

[epoch:  19/1000, batch:    24/ 1052, ite: 4740] train loss: 0.025262, tar: 0.005255 
l0: 0.000624, l1: 0.000760, l2: 0.000644, l3: 0.000728, l4: 0.000874, l5: 0.001351, l6: 0.002132

[epoch:  19/1000, batch:   104/ 1052, ite: 4760] train loss: 0.025196, tar: 0.005237 
l0: 0.000438, l1: 0.000333, l2: 0.000385, l3: 0.000434, l4: 0.000722, l5: 0.001040, l6: 0.002351

[epoch:  19/1000, batch:   184/ 1052, ite: 4780] train loss: 0.025123, tar: 0.005218 
l0: 0.000503, l1: 0.000432, l2: 0.000503, l3: 0.000684, l4: 0.000603, l5: 0.001351, l6: 0.001840

[epoch:  19/1000, batch:   264/ 1052, ite: 4800] train loss: 0.025052, tar: 0.005199 
l0: 0.003299, l1: 0.004064, l2: 0.003771, l3: 0.004224, l4: 0.004031, l5: 0.005959, l6: 0.006334

[epoch:  19/1000, batch:   344/ 1052, ite: 4820] train loss: 0.025008, tar: 0.005183 
l0: 0.001374, l1: 0.001271, l2: 0.002071, l3: 0.001550, l4: 0.001953, l5: 0.001667, l6: 0.001727

[epoch:  19/1000, batch:   424/ 1052, ite: 4840] train loss: 0.024969, tar: 0.005168 
l0: 0.000790, l1: 0.000637, l2: 0.000778, l3: 0.001182, l4: 0.001586, l5: 0.001885, l6: 0.002449

[epoch:  19/1000, batch:   504/ 1052, ite: 4860] train loss: 0.024921, tar: 0.005152 
l0: 0.001591, l1: 0.001650, l2: 0.001472, l3: 0.001538, l4: 0.001918, l5: 0.002753, l6: 0.004985

[epoch:  19/1000, batch:   584/ 1052, ite: 4880] train loss: 0.024867, tar: 0.005136 
l0: 0.000570, l1: 0.000668, l2: 0.000588, l3: 0.000686, l4: 0.000805, l5: 0.001170, l6: 0.001322

[epoch:  19/1000, batch:   664/ 1052, ite: 4900] train loss: 0.024813, tar: 0.005119 
l0: 0.000748, l1: 0.000566, l2: 0.000650, l3: 0.000852, l4: 0.000842, l5: 0.001711, l6: 0.003058

[epoch:  19/1000, batch:   744/ 1052, ite: 4920] train loss: 0.024752, tar: 0.005102 
l0: 0.000487, l1: 0.000348, l2: 0.000574, l3: 0.000402, l4: 0.000625, l5: 0.001385, l6: 0.001676

[epoch:  19/1000, batch:   824/ 1052, ite: 4940] train loss: 0.024693, tar: 0.005086 
l0: 0.001769, l1: 0.001170, l2: 0.001309, l3: 0.002031, l4: 0.001792, l5: 0.002466, l6: 0.004692

[epoch:  19/1000, batch:   904/ 1052, ite: 4960] train loss: 0.024661, tar: 0.005073 
l0: 0.000703, l1: 0.000535, l2: 0.000525, l3: 0.000643, l4: 0.000890, l5: 0.001049, l6: 0.001513

[epoch:  19/1000, batch:   984/ 1052, ite: 4980] train loss: 0.024608, tar: 0.005057 
[Epoch 19/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000462, l1: 0.000409, l2: 0.000422, l3: 0.000473, l4: 0.000861, l5: 0.001381, l6: 0.001554

[epoch:  20/1000, batch:    12/ 1052, ite: 5000] train loss: 0.024553, tar: 0.005041 
l0: 0.001508, l1: 0.001502, l2: 0.001362, l3: 0.001585, l4: 0.001823, l5: 0.002833, l6: 0.004035

[epoch:  20/1000, batch:    92/ 1052, ite: 5020] train loss: 0.024512, tar: 0.005027 
l0: 0.001395, l1: 0.001141, l2: 0.001284, l3: 0.001612, l4: 0.001918, l5: 0.002533, l6: 0.004108

[epoch:  20/1000, batch:   172/ 1052, ite: 5040] train loss: 0.024492, tar: 0.005015 
l0: 0.001068, l1: 0.001190, l2: 0.001209, l3: 0.001139, l4: 0.001350, l5: 0.001531, l6: 0.002725

[epoch:  20/1000, batch:   252/ 1052, ite: 5060] train loss: 0.024431, tar: 0.004999 
l0: 0.000622, l1: 0.000598, l2: 0.000599, l3: 0.000683, l4: 0.000902, l5: 0.001375, l6: 0.002514

[epoch:  20/1000, batch:   332/ 1052, ite: 5080] train loss: 0.024382, tar: 0.004984 
l0: 0.001500, l1: 0.001681, l2: 0.001660, l3: 0.001483, l4: 0.001671, l5: 0.002713, l6: 0.004185

[epoch:  20/1000, batch:   412/ 1052, ite: 5100] train loss: 0.024329, tar: 0.004968 
l0: 0.001376, l1: 0.001624, l2: 0.001286, l3: 0.001266, l4: 0.001624, l5: 0.002163, l6: 0.002946

[epoch:  20/1000, batch:   492/ 1052, ite: 5120] train loss: 0.024267, tar: 0.004952 
l0: 0.001283, l1: 0.001721, l2: 0.001629, l3: 0.001609, l4: 0.001904, l5: 0.002887, l6: 0.002861

[epoch:  20/1000, batch:   572/ 1052, ite: 5140] train loss: 0.024213, tar: 0.004937 
l0: 0.000513, l1: 0.000491, l2: 0.000466, l3: 0.000608, l4: 0.000867, l5: 0.001125, l6: 0.001990

[epoch:  20/1000, batch:   652/ 1052, ite: 5160] train loss: 0.024151, tar: 0.004920 
l0: 0.000362, l1: 0.000425, l2: 0.000386, l3: 0.000459, l4: 0.000601, l5: 0.001116, l6: 0.001508

[epoch:  20/1000, batch:   732/ 1052, ite: 5180] train loss: 0.024092, tar: 0.004905 
l0: 0.000556, l1: 0.000459, l2: 0.000529, l3: 0.000706, l4: 0.000871, l5: 0.001123, l6: 0.002315

[epoch:  20/1000, batch:   812/ 1052, ite: 5200] train loss: 0.024043, tar: 0.004890 
l0: 0.001023, l1: 0.001095, l2: 0.001029, l3: 0.001069, l4: 0.001437, l5: 0.002160, l6: 0.003045

[epoch:  20/1000, batch:   892/ 1052, ite: 5220] train loss: 0.023991, tar: 0.004875 
l0: 0.001059, l1: 0.001235, l2: 0.000909, l3: 0.001120, l4: 0.001175, l5: 0.001591, l6: 0.002820

[epoch:  20/1000, batch:   972/ 1052, ite: 5240] train loss: 0.023937, tar: 0.004860 
l0: 0.000725, l1: 0.000607, l2: 0.000846, l3: 0.001008, l4: 0.001384, l5: 0.001716, l6: 0.002505

[epoch:  20/1000, batch:  1052/ 1052, ite: 5260] train loss: 0.023888, tar: 0.004845 
[Epoch 20/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.001006, l1: 0.001420, l2: 0.001184, l3: 0.001561, l4: 0.001687, l5: 0.002006, l6: 0.002197

[epoch:  21/1000, batch:    80/ 1052, ite: 5280] train loss: 0.023837, tar: 0.004831 
l0: 0.000922, l1: 0.000882, l2: 0.000862, l3: 0.001069, l4: 0.001382, l5: 0.001640, l6: 0.003323

[epoch:  21/1000, batch:   160/ 1052, ite: 5300] train loss: 0.023785, tar: 0.004816 
l0: 0.000888, l1: 0.000887, l2: 0.000997, l3: 0.001048, l4: 0.001431, l5: 0.002071, l6: 0.002257

[epoch:  21/1000, batch:   240/ 1052, ite: 5320] train loss: 0.023732, tar: 0.004801 
l0: 0.001141, l1: 0.000857, l2: 0.001095, l3: 0.001075, l4: 0.001611, l5: 0.002966, l6: 0.004240

[epoch:  21/1000, batch:   320/ 1052, ite: 5340] train loss: 0.023674, tar: 0.004786 
l0: 0.000948, l1: 0.000737, l2: 0.000838, l3: 0.000987, l4: 0.001426, l5: 0.001821, l6: 0.002973

[epoch:  21/1000, batch:   400/ 1052, ite: 5360] train loss: 0.023625, tar: 0.004772 
l0: 0.000678, l1: 0.000620, l2: 0.000583, l3: 0.000711, l4: 0.001112, l5: 0.001879, l6: 0.002297

[epoch:  21/1000, batch:   480/ 1052, ite: 5380] train loss: 0.023573, tar: 0.004757 
l0: 0.001129, l1: 0.001126, l2: 0.001025, l3: 0.001034, l4: 0.001391, l5: 0.002077, l6: 0.003391

[epoch:  21/1000, batch:   560/ 1052, ite: 5400] train loss: 0.023542, tar: 0.004746 
l0: 0.001008, l1: 0.001048, l2: 0.000876, l3: 0.001068, l4: 0.001104, l5: 0.001416, l6: 0.002346

[epoch:  21/1000, batch:   640/ 1052, ite: 5420] train loss: 0.023491, tar: 0.004732 
l0: 0.000756, l1: 0.000812, l2: 0.000628, l3: 0.000741, l4: 0.000930, l5: 0.001479, l6: 0.002714

[epoch:  21/1000, batch:   720/ 1052, ite: 5440] train loss: 0.023437, tar: 0.004718 
l0: 0.000546, l1: 0.000503, l2: 0.000634, l3: 0.000773, l4: 0.001116, l5: 0.001238, l6: 0.002344

[epoch:  21/1000, batch:   800/ 1052, ite: 5460] train loss: 0.023390, tar: 0.004704 
l0: 0.000949, l1: 0.000857, l2: 0.001137, l3: 0.001218, l4: 0.001379, l5: 0.002000, l6: 0.002867

[epoch:  21/1000, batch:   880/ 1052, ite: 5480] train loss: 0.023338, tar: 0.004690 
l0: 0.000384, l1: 0.000515, l2: 0.000428, l3: 0.000580, l4: 0.000589, l5: 0.001054, l6: 0.001756

[epoch:  21/1000, batch:   960/ 1052, ite: 5500] train loss: 0.023283, tar: 0.004675 
l0: 0.002411, l1: 0.002500, l2: 0.002834, l3: 0.002600, l4: 0.003239, l5: 0.003896, l6: 0.005786

[epoch:  21/1000, batch:  1040/ 1052, ite: 5520] train loss: 0.023241, tar: 0.004662 
[Epoch 21/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.001226, l1: 0.001221, l2: 0.001139, l3: 0.001286, l4: 0.001431, l5: 0.002833, l6: 0.003397

[epoch:  22/1000, batch:    68/ 1052, ite: 5540] train loss: 0.023187, tar: 0.004648 
l0: 0.000310, l1: 0.000346, l2: 0.000332, l3: 0.000373, l4: 0.000505, l5: 0.000731, l6: 0.001326

[epoch:  22/1000, batch:   148/ 1052, ite: 5560] train loss: 0.023138, tar: 0.004635 
l0: 0.009353, l1: 0.011721, l2: 0.015900, l3: 0.014697, l4: 0.014576, l5: 0.014435, l6: 0.014484

[epoch:  22/1000, batch:   228/ 1052, ite: 5580] train loss: 0.023109, tar: 0.004623 
l0: 0.000424, l1: 0.000375, l2: 0.000396, l3: 0.000422, l4: 0.000660, l5: 0.000922, l6: 0.001699

[epoch:  22/1000, batch:   308/ 1052, ite: 5600] train loss: 0.023056, tar: 0.004610 
l0: 0.000385, l1: 0.000427, l2: 0.000473, l3: 0.000513, l4: 0.000683, l5: 0.000697, l6: 0.001339

[epoch:  22/1000, batch:   388/ 1052, ite: 5620] train loss: 0.023010, tar: 0.004597 
l0: 0.000340, l1: 0.000319, l2: 0.000565, l3: 0.000505, l4: 0.000588, l5: 0.000939, l6: 0.001444

[epoch:  22/1000, batch:   468/ 1052, ite: 5640] train loss: 0.022968, tar: 0.004584 
l0: 0.000346, l1: 0.000359, l2: 0.000431, l3: 0.000576, l4: 0.000704, l5: 0.000836, l6: 0.001292

[epoch:  22/1000, batch:   548/ 1052, ite: 5660] train loss: 0.022919, tar: 0.004571 
l0: 0.000929, l1: 0.000807, l2: 0.000970, l3: 0.001215, l4: 0.001421, l5: 0.001929, l6: 0.002718

[epoch:  22/1000, batch:   628/ 1052, ite: 5680] train loss: 0.022882, tar: 0.004559 
l0: 0.000886, l1: 0.000686, l2: 0.000714, l3: 0.000791, l4: 0.001118, l5: 0.002374, l6: 0.003662

[epoch:  22/1000, batch:   708/ 1052, ite: 5700] train loss: 0.022840, tar: 0.004546 
l0: 0.001160, l1: 0.000990, l2: 0.001308, l3: 0.001593, l4: 0.002155, l5: 0.002413, l6: 0.003788

[epoch:  22/1000, batch:   788/ 1052, ite: 5720] train loss: 0.022794, tar: 0.004534 
l0: 0.001167, l1: 0.001370, l2: 0.001431, l3: 0.001345, l4: 0.001867, l5: 0.002427, l6: 0.003823

[epoch:  22/1000, batch:   868/ 1052, ite: 5740] train loss: 0.022749, tar: 0.004521 
l0: 0.000618, l1: 0.000691, l2: 0.000591, l3: 0.000678, l4: 0.000821, l5: 0.001163, l6: 0.001929

[epoch:  22/1000, batch:   948/ 1052, ite: 5760] train loss: 0.022699, tar: 0.004508 
l0: 0.000342, l1: 0.000266, l2: 0.000266, l3: 0.000322, l4: 0.000614, l5: 0.000796, l6: 0.000865

[epoch:  22/1000, batch:  1028/ 1052, ite: 5780] train loss: 0.022647, tar: 0.004495 
[Epoch 22/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000838, l1: 0.000742, l2: 0.000802, l3: 0.001003, l4: 0.001217, l5: 0.001630, l6: 0.002173

[epoch:  23/1000, batch:    56/ 1052, ite: 5800] train loss: 0.022597, tar: 0.004482 
l0: 0.000921, l1: 0.000746, l2: 0.000740, l3: 0.000785, l4: 0.001274, l5: 0.002282, l6: 0.003982

[epoch:  23/1000, batch:   136/ 1052, ite: 5820] train loss: 0.022549, tar: 0.004470 
l0: 0.001741, l1: 0.001755, l2: 0.001744, l3: 0.001664, l4: 0.002785, l5: 0.003830, l6: 0.006618

[epoch:  23/1000, batch:   216/ 1052, ite: 5840] train loss: 0.022505, tar: 0.004457 
l0: 0.000668, l1: 0.000784, l2: 0.000574, l3: 0.000746, l4: 0.001007, l5: 0.001099, l6: 0.001586

[epoch:  23/1000, batch:   296/ 1052, ite: 5860] train loss: 0.022452, tar: 0.004444 
l0: 0.000999, l1: 0.000793, l2: 0.001059, l3: 0.001347, l4: 0.001948, l5: 0.002915, l6: 0.003411

[epoch:  23/1000, batch:   376/ 1052, ite: 5880] train loss: 0.022401, tar: 0.004431 
l0: 0.000870, l1: 0.000709, l2: 0.000869, l3: 0.000901, l4: 0.001574, l5: 0.001987, l6: 0.002286

[epoch:  23/1000, batch:   456/ 1052, ite: 5900] train loss: 0.022380, tar: 0.004422 
l0: 0.000728, l1: 0.000724, l2: 0.000599, l3: 0.000767, l4: 0.001090, l5: 0.001701, l6: 0.002481

[epoch:  23/1000, batch:   536/ 1052, ite: 5920] train loss: 0.022333, tar: 0.004409 
l0: 0.000544, l1: 0.000511, l2: 0.000521, l3: 0.000856, l4: 0.000860, l5: 0.001386, l6: 0.001626

[epoch:  23/1000, batch:   616/ 1052, ite: 5940] train loss: 0.022295, tar: 0.004398 
l0: 0.001034, l1: 0.000996, l2: 0.001027, l3: 0.000992, l4: 0.001189, l5: 0.001682, l6: 0.003162

[epoch:  23/1000, batch:   696/ 1052, ite: 5960] train loss: 0.022251, tar: 0.004386 
l0: 0.000357, l1: 0.000387, l2: 0.000397, l3: 0.000515, l4: 0.000621, l5: 0.000984, l6: 0.001353

[epoch:  23/1000, batch:   776/ 1052, ite: 5980] train loss: 0.022211, tar: 0.004375 
l0: 0.001131, l1: 0.001235, l2: 0.001183, l3: 0.001220, l4: 0.001323, l5: 0.002055, l6: 0.003910

[epoch:  23/1000, batch:   856/ 1052, ite: 6000] train loss: 0.022171, tar: 0.004364 
l0: 0.000482, l1: 0.000404, l2: 0.000441, l3: 0.000560, l4: 0.000882, l5: 0.001090, l6: 0.001506

[epoch:  23/1000, batch:   936/ 1052, ite: 6020] train loss: 0.022133, tar: 0.004353 
l0: 0.000947, l1: 0.000987, l2: 0.000942, l3: 0.000996, l4: 0.001228, l5: 0.001929, l6: 0.002873

[epoch:  23/1000, batch:  1016/ 1052, ite: 6040] train loss: 0.022096, tar: 0.004342 
[Epoch 23/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000291, l1: 0.000246, l2: 0.000272, l3: 0.000352, l4: 0.000687, l5: 0.001023, l6: 0.001549

[epoch:  24/1000, batch:    44/ 1052, ite: 6060] train loss: 0.022070, tar: 0.004332 
l0: 0.000861, l1: 0.000742, l2: 0.000848, l3: 0.000985, l4: 0.001206, l5: 0.002281, l6: 0.003263

[epoch:  24/1000, batch:   124/ 1052, ite: 6080] train loss: 0.022030, tar: 0.004321 
l0: 0.001072, l1: 0.001145, l2: 0.001089, l3: 0.001099, l4: 0.001569, l5: 0.001944, l6: 0.002659

[epoch:  24/1000, batch:   204/ 1052, ite: 6100] train loss: 0.021992, tar: 0.004310 
l0: 0.000850, l1: 0.000949, l2: 0.001016, l3: 0.000946, l4: 0.001742, l5: 0.002218, l6: 0.002487

[epoch:  24/1000, batch:   284/ 1052, ite: 6120] train loss: 0.021952, tar: 0.004299 
l0: 0.000598, l1: 0.000642, l2: 0.000714, l3: 0.001028, l4: 0.001034, l5: 0.001188, l6: 0.002058

[epoch:  24/1000, batch:   364/ 1052, ite: 6140] train loss: 0.021909, tar: 0.004287 
l0: 0.001213, l1: 0.000901, l2: 0.001262, l3: 0.001336, l4: 0.002186, l5: 0.003719, l6: 0.003782

[epoch:  24/1000, batch:   444/ 1052, ite: 6160] train loss: 0.021874, tar: 0.004277 
l0: 0.001075, l1: 0.000961, l2: 0.002114, l3: 0.001853, l4: 0.002063, l5: 0.002198, l6: 0.003174

[epoch:  24/1000, batch:   524/ 1052, ite: 6180] train loss: 0.021859, tar: 0.004268 
l0: 0.000374, l1: 0.000335, l2: 0.000388, l3: 0.000530, l4: 0.000663, l5: 0.001545, l6: 0.001571

[epoch:  24/1000, batch:   604/ 1052, ite: 6200] train loss: 0.021821, tar: 0.004257 
l0: 0.000706, l1: 0.000705, l2: 0.000813, l3: 0.000955, l4: 0.000912, l5: 0.001447, l6: 0.002090

[epoch:  24/1000, batch:   684/ 1052, ite: 6220] train loss: 0.021788, tar: 0.004247 
l0: 0.000829, l1: 0.000904, l2: 0.001098, l3: 0.001168, l4: 0.001153, l5: 0.001570, l6: 0.002248

[epoch:  24/1000, batch:   764/ 1052, ite: 6240] train loss: 0.021751, tar: 0.004236 
l0: 0.000757, l1: 0.000720, l2: 0.000820, l3: 0.001048, l4: 0.001202, l5: 0.001744, l6: 0.002799

[epoch:  24/1000, batch:   844/ 1052, ite: 6260] train loss: 0.021719, tar: 0.004226 
l0: 0.002270, l1: 0.002403, l2: 0.002857, l3: 0.003294, l4: 0.003161, l5: 0.003497, l6: 0.004792

[epoch:  24/1000, batch:   924/ 1052, ite: 6280] train loss: 0.021684, tar: 0.004216 
l0: 0.000782, l1: 0.000589, l2: 0.000829, l3: 0.001379, l4: 0.001337, l5: 0.002172, l6: 0.003053

[epoch:  24/1000, batch:  1004/ 1052, ite: 6300] train loss: 0.021650, tar: 0.004206 
[Epoch 24/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000564, l1: 0.000448, l2: 0.000604, l3: 0.000630, l4: 0.000839, l5: 0.001187, l6: 0.002375

[epoch:  25/1000, batch:    32/ 1052, ite: 6320] train loss: 0.021608, tar: 0.004195 
l0: 0.001019, l1: 0.000993, l2: 0.001414, l3: 0.001495, l4: 0.001788, l5: 0.002330, l6: 0.003750

[epoch:  25/1000, batch:   112/ 1052, ite: 6340] train loss: 0.021571, tar: 0.004185 
l0: 0.001013, l1: 0.001418, l2: 0.001557, l3: 0.001842, l4: 0.001506, l5: 0.001301, l6: 0.002118

[epoch:  25/1000, batch:   192/ 1052, ite: 6360] train loss: 0.021537, tar: 0.004175 
l0: 0.001045, l1: 0.001090, l2: 0.000997, l3: 0.001397, l4: 0.001840, l5: 0.002490, l6: 0.003199

[epoch:  25/1000, batch:   272/ 1052, ite: 6380] train loss: 0.021499, tar: 0.004164 
l0: 0.000520, l1: 0.000516, l2: 0.000545, l3: 0.000519, l4: 0.000655, l5: 0.001350, l6: 0.002303

[epoch:  25/1000, batch:   352/ 1052, ite: 6400] train loss: 0.021458, tar: 0.004153 
l0: 0.000336, l1: 0.000325, l2: 0.000300, l3: 0.000366, l4: 0.000449, l5: 0.000848, l6: 0.001192

[epoch:  25/1000, batch:   432/ 1052, ite: 6420] train loss: 0.021423, tar: 0.004144 
l0: 0.001257, l1: 0.001228, l2: 0.001185, l3: 0.001191, l4: 0.001334, l5: 0.001948, l6: 0.003409

[epoch:  25/1000, batch:   512/ 1052, ite: 6440] train loss: 0.021393, tar: 0.004134 
l0: 0.000882, l1: 0.000694, l2: 0.000748, l3: 0.001035, l4: 0.001496, l5: 0.002054, l6: 0.002309

[epoch:  25/1000, batch:   592/ 1052, ite: 6460] train loss: 0.021356, tar: 0.004124 
l0: 0.000362, l1: 0.000394, l2: 0.000375, l3: 0.000358, l4: 0.000487, l5: 0.000963, l6: 0.001920

[epoch:  25/1000, batch:   672/ 1052, ite: 6480] train loss: 0.021319, tar: 0.004114 
l0: 0.000314, l1: 0.000364, l2: 0.000363, l3: 0.000381, l4: 0.000552, l5: 0.000795, l6: 0.001788

[epoch:  25/1000, batch:   752/ 1052, ite: 6500] train loss: 0.021276, tar: 0.004103 
l0: 0.000393, l1: 0.000459, l2: 0.000425, l3: 0.000410, l4: 0.000583, l5: 0.000781, l6: 0.001583

[epoch:  25/1000, batch:   832/ 1052, ite: 6520] train loss: 0.021237, tar: 0.004093 
l0: 0.003812, l1: 0.004875, l2: 0.003408, l3: 0.002947, l4: 0.003469, l5: 0.004242, l6: 0.004116

[epoch:  25/1000, batch:   912/ 1052, ite: 6540] train loss: 0.021201, tar: 0.004083 
l0: 0.000541, l1: 0.000535, l2: 0.000599, l3: 0.000662, l4: 0.000916, l5: 0.001296, l6: 0.002708

[epoch:  25/1000, batch:   992/ 1052, ite: 6560] train loss: 0.021164, tar: 0.004073 
[Epoch 25/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000558, l1: 0.000621, l2: 0.000659, l3: 0.000916, l4: 0.000983, l5: 0.001328, l6: 0.002107

[epoch:  26/1000, batch:    20/ 1052, ite: 6580] train loss: 0.021142, tar: 0.004065 
l0: 0.001807, l1: 0.002075, l2: 0.002575, l3: 0.002795, l4: 0.001956, l5: 0.002182, l6: 0.003062

[epoch:  26/1000, batch:   100/ 1052, ite: 6600] train loss: 0.021117, tar: 0.004057 
l0: 0.001928, l1: 0.002022, l2: 0.003196, l3: 0.003635, l4: 0.002967, l5: 0.002983, l6: 0.004025

[epoch:  26/1000, batch:   180/ 1052, ite: 6620] train loss: 0.021093, tar: 0.004048 
l0: 0.000459, l1: 0.000530, l2: 0.000654, l3: 0.000538, l4: 0.000677, l5: 0.000880, l6: 0.001414

[epoch:  26/1000, batch:   260/ 1052, ite: 6640] train loss: 0.021060, tar: 0.004039 
l0: 0.000818, l1: 0.000920, l2: 0.000861, l3: 0.000764, l4: 0.000851, l5: 0.001311, l6: 0.002304

[epoch:  26/1000, batch:   340/ 1052, ite: 6660] train loss: 0.021030, tar: 0.004030 
l0: 0.000593, l1: 0.000640, l2: 0.000800, l3: 0.000839, l4: 0.001151, l5: 0.001759, l6: 0.002435

[epoch:  26/1000, batch:   420/ 1052, ite: 6680] train loss: 0.020996, tar: 0.004021 
l0: 0.000401, l1: 0.000478, l2: 0.000374, l3: 0.000432, l4: 0.000604, l5: 0.001044, l6: 0.001169

[epoch:  26/1000, batch:   500/ 1052, ite: 6700] train loss: 0.020959, tar: 0.004011 
l0: 0.000907, l1: 0.000740, l2: 0.001466, l3: 0.001420, l4: 0.001944, l5: 0.002710, l6: 0.002630

[epoch:  26/1000, batch:   580/ 1052, ite: 6720] train loss: 0.020933, tar: 0.004002 
l0: 0.000692, l1: 0.000603, l2: 0.000604, l3: 0.000849, l4: 0.001157, l5: 0.001983, l6: 0.003306

[epoch:  26/1000, batch:   660/ 1052, ite: 6740] train loss: 0.020899, tar: 0.003993 
l0: 0.000465, l1: 0.000434, l2: 0.000474, l3: 0.000685, l4: 0.000769, l5: 0.001140, l6: 0.002043

[epoch:  26/1000, batch:   740/ 1052, ite: 6760] train loss: 0.020862, tar: 0.003983 
l0: 0.002776, l1: 0.002551, l2: 0.002567, l3: 0.002816, l4: 0.003979, l5: 0.004865, l6: 0.005894

[epoch:  26/1000, batch:   820/ 1052, ite: 6780] train loss: 0.020829, tar: 0.003974 
l0: 0.000693, l1: 0.000524, l2: 0.000626, l3: 0.000860, l4: 0.001502, l5: 0.002236, l6: 0.002568

[epoch:  26/1000, batch:   900/ 1052, ite: 6800] train loss: 0.020800, tar: 0.003966 
l0: 0.000779, l1: 0.000647, l2: 0.000803, l3: 0.000923, l4: 0.001510, l5: 0.001878, l6: 0.002450

[epoch:  26/1000, batch:   980/ 1052, ite: 6820] train loss: 0.020764, tar: 0.003956 
[Epoch 26/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000754, l1: 0.000781, l2: 0.000976, l3: 0.001039, l4: 0.001189, l5: 0.001782, l6: 0.002285

[epoch:  27/1000, batch:     8/ 1052, ite: 6840] train loss: 0.020752, tar: 0.003949 
l0: 0.000873, l1: 0.000947, l2: 0.000893, l3: 0.001202, l4: 0.001469, l5: 0.001869, l6: 0.003471

[epoch:  27/1000, batch:    88/ 1052, ite: 6860] train loss: 0.020721, tar: 0.003941 
l0: 0.000306, l1: 0.000275, l2: 0.000312, l3: 0.000368, l4: 0.000633, l5: 0.000918, l6: 0.001529

[epoch:  27/1000, batch:   168/ 1052, ite: 6880] train loss: 0.020690, tar: 0.003932 
l0: 0.000727, l1: 0.000735, l2: 0.000817, l3: 0.000890, l4: 0.000995, l5: 0.001939, l6: 0.003184

[epoch:  27/1000, batch:   248/ 1052, ite: 6900] train loss: 0.020659, tar: 0.003923 
l0: 0.000603, l1: 0.000483, l2: 0.000632, l3: 0.000670, l4: 0.000903, l5: 0.001519, l6: 0.003342

[epoch:  27/1000, batch:   328/ 1052, ite: 6920] train loss: 0.020626, tar: 0.003914 
l0: 0.000642, l1: 0.000626, l2: 0.000689, l3: 0.000628, l4: 0.000929, l5: 0.002469, l6: 0.002130

[epoch:  27/1000, batch:   408/ 1052, ite: 6940] train loss: 0.020603, tar: 0.003907 
l0: 0.000599, l1: 0.000580, l2: 0.000608, l3: 0.000587, l4: 0.000966, l5: 0.001508, l6: 0.002118

[epoch:  27/1000, batch:   488/ 1052, ite: 6960] train loss: 0.020571, tar: 0.003898 
l0: 0.000583, l1: 0.000729, l2: 0.000791, l3: 0.000717, l4: 0.000706, l5: 0.001013, l6: 0.001900

[epoch:  27/1000, batch:   568/ 1052, ite: 6980] train loss: 0.020552, tar: 0.003890 
l0: 0.000785, l1: 0.000817, l2: 0.000727, l3: 0.001303, l4: 0.001214, l5: 0.001270, l6: 0.002239

[epoch:  27/1000, batch:   648/ 1052, ite: 7000] train loss: 0.020529, tar: 0.003883 
l0: 0.000788, l1: 0.001335, l2: 0.000901, l3: 0.000925, l4: 0.001267, l5: 0.001659, l6: 0.002354

[epoch:  27/1000, batch:   728/ 1052, ite: 7020] train loss: 0.020523, tar: 0.003877 
l0: 0.001039, l1: 0.001306, l2: 0.001281, l3: 0.000966, l4: 0.000806, l5: 0.001338, l6: 0.001174

[epoch:  27/1000, batch:   808/ 1052, ite: 7040] train loss: 0.020500, tar: 0.003869 
l0: 0.000513, l1: 0.000489, l2: 0.001023, l3: 0.001094, l4: 0.001328, l5: 0.001195, l6: 0.001755

[epoch:  27/1000, batch:   888/ 1052, ite: 7060] train loss: 0.020474, tar: 0.003861 
l0: 0.000437, l1: 0.000486, l2: 0.000556, l3: 0.000653, l4: 0.000866, l5: 0.000883, l6: 0.001932

[epoch:  27/1000, batch:   968/ 1052, ite: 7080] train loss: 0.020445, tar: 0.003853 
l0: 0.000956, l1: 0.000915, l2: 0.000919, l3: 0.001001, l4: 0.001511, l5: 0.002371, l6: 0.003350

[epoch:  27/1000, batch:  1048/ 1052, ite: 7100] train loss: 0.020411, tar: 0.003844 
[Epoch 27/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000796, l1: 0.000783, l2: 0.000755, l3: 0.000779, l4: 0.001000, l5: 0.001940, l6: 0.003032

[epoch:  28/1000, batch:    76/ 1052, ite: 7120] train loss: 0.020375, tar: 0.003836 
l0: 0.001063, l1: 0.000972, l2: 0.001004, l3: 0.001225, l4: 0.001821, l5: 0.002348, l6: 0.003210

[epoch:  28/1000, batch:   156/ 1052, ite: 7140] train loss: 0.020340, tar: 0.003827 
l0: 0.001768, l1: 0.001407, l2: 0.002584, l3: 0.002604, l4: 0.003980, l5: 0.003250, l6: 0.004493

[epoch:  28/1000, batch:   236/ 1052, ite: 7160] train loss: 0.020313, tar: 0.003819 
l0: 0.001259, l1: 0.001253, l2: 0.001200, l3: 0.001246, l4: 0.001510, l5: 0.002011, l6: 0.003383

[epoch:  28/1000, batch:   316/ 1052, ite: 7180] train loss: 0.020281, tar: 0.003810 
l0: 0.000422, l1: 0.000445, l2: 0.000491, l3: 0.000485, l4: 0.000626, l5: 0.001102, l6: 0.001682

[epoch:  28/1000, batch:   396/ 1052, ite: 7200] train loss: 0.020246, tar: 0.003802 
l0: 0.000443, l1: 0.000399, l2: 0.000476, l3: 0.000474, l4: 0.000623, l5: 0.001071, l6: 0.001612

[epoch:  28/1000, batch:   476/ 1052, ite: 7220] train loss: 0.020215, tar: 0.003794 
l0: 0.000916, l1: 0.000800, l2: 0.000918, l3: 0.001188, l4: 0.001446, l5: 0.002528, l6: 0.002158

[epoch:  28/1000, batch:   556/ 1052, ite: 7240] train loss: 0.020184, tar: 0.003785 
l0: 0.000716, l1: 0.000784, l2: 0.001258, l3: 0.001341, l4: 0.001222, l5: 0.001014, l6: 0.001797

[epoch:  28/1000, batch:   636/ 1052, ite: 7260] train loss: 0.020156, tar: 0.003777 
l0: 0.001154, l1: 0.001216, l2: 0.001312, l3: 0.001283, l4: 0.001506, l5: 0.001762, l6: 0.002986

[epoch:  28/1000, batch:   716/ 1052, ite: 7280] train loss: 0.020127, tar: 0.003769 
l0: 0.000718, l1: 0.000800, l2: 0.000619, l3: 0.000623, l4: 0.000875, l5: 0.000984, l6: 0.001771

[epoch:  28/1000, batch:   796/ 1052, ite: 7300] train loss: 0.020124, tar: 0.003765 
l0: 0.002190, l1: 0.002250, l2: 0.002213, l3: 0.001976, l4: 0.002361, l5: 0.004120, l6: 0.005538

[epoch:  28/1000, batch:   876/ 1052, ite: 7320] train loss: 0.020096, tar: 0.003757 
l0: 0.000467, l1: 0.000486, l2: 0.000504, l3: 0.000520, l4: 0.000564, l5: 0.001105, l6: 0.001962

[epoch:  28/1000, batch:   956/ 1052, ite: 7340] train loss: 0.020082, tar: 0.003751 
l0: 0.001210, l1: 0.001035, l2: 0.001311, l3: 0.001605, l4: 0.001640, l5: 0.003122, l6: 0.003503

[epoch:  28/1000, batch:  1036/ 1052, ite: 7360] train loss: 0.020072, tar: 0.003745 
[Epoch 28/1000] Test loss: 0.013, Test target loss: 0.001
l0: 0.000760, l1: 0.000904, l2: 0.000987, l3: 0.000957, l4: 0.001094, l5: 0.001190, l6: 0.001953

[epoch:  29/1000, batch:    64/ 1052, ite: 7380] train loss: 0.020045, tar: 0.003737 
l0: 0.000361, l1: 0.000390, l2: 0.000331, l3: 0.000375, l4: 0.000504, l5: 0.001009, l6: 0.001207

[epoch:  29/1000, batch:   144/ 1052, ite: 7400] train loss: 0.020017, tar: 0.003730 
l0: 0.000697, l1: 0.000559, l2: 0.000728, l3: 0.000668, l4: 0.000988, l5: 0.002347, l6: 0.003250

[epoch:  29/1000, batch:   224/ 1052, ite: 7420] train loss: 0.019993, tar: 0.003722 
l0: 0.000672, l1: 0.000648, l2: 0.000609, l3: 0.000829, l4: 0.001079, l5: 0.001589, l6: 0.001958

[epoch:  29/1000, batch:   304/ 1052, ite: 7440] train loss: 0.019980, tar: 0.003716 
l0: 0.000463, l1: 0.000435, l2: 0.000558, l3: 0.000604, l4: 0.000714, l5: 0.000916, l6: 0.001637

[epoch:  29/1000, batch:   384/ 1052, ite: 7460] train loss: 0.019953, tar: 0.003709 
l0: 0.001111, l1: 0.001065, l2: 0.001016, l3: 0.001483, l4: 0.001881, l5: 0.001809, l6: 0.002766

[epoch:  29/1000, batch:   464/ 1052, ite: 7480] train loss: 0.019929, tar: 0.003702 
l0: 0.001005, l1: 0.000854, l2: 0.000920, l3: 0.001020, l4: 0.001679, l5: 0.002733, l6: 0.004698

[epoch:  29/1000, batch:   544/ 1052, ite: 7500] train loss: 0.019902, tar: 0.003694 
l0: 0.001152, l1: 0.001230, l2: 0.001131, l3: 0.001422, l4: 0.001698, l5: 0.001899, l6: 0.003228

[epoch:  29/1000, batch:   624/ 1052, ite: 7520] train loss: 0.019876, tar: 0.003687 
l0: 0.001533, l1: 0.001733, l2: 0.001585, l3: 0.001844, l4: 0.001680, l5: 0.002468, l6: 0.004358

[epoch:  29/1000, batch:   704/ 1052, ite: 7540] train loss: 0.019852, tar: 0.003679 
l0: 0.000432, l1: 0.000485, l2: 0.000476, l3: 0.000517, l4: 0.000767, l5: 0.001232, l6: 0.001954

[epoch:  29/1000, batch:   784/ 1052, ite: 7560] train loss: 0.019824, tar: 0.003672 
l0: 0.000425, l1: 0.000451, l2: 0.000779, l3: 0.000689, l4: 0.001101, l5: 0.001081, l6: 0.001373

[epoch:  29/1000, batch:   864/ 1052, ite: 7580] train loss: 0.019805, tar: 0.003665 
l0: 0.000922, l1: 0.000989, l2: 0.001211, l3: 0.001214, l4: 0.001389, l5: 0.001362, l6: 0.001891

[epoch:  29/1000, batch:   944/ 1052, ite: 7600] train loss: 0.019785, tar: 0.003659 
l0: 0.004201, l1: 0.005324, l2: 0.002223, l3: 0.003600, l4: 0.002255, l5: 0.002777, l6: 0.007125

[epoch:  29/1000, batch:  1024/ 1052, ite: 7620] train loss: 0.019761, tar: 0.003652 
[Epoch 29/1000] Test loss: 0.012, Test target loss: 0.001
l0: 0.000655, l1: 0.000615, l2: 0.001164, l3: 0.000755, l4: 0.000903, l5: 0.001249, l6: 0.002342

[epoch:  30/1000, batch:    52/ 1052, ite: 7640] train loss: 0.019736, tar: 0.003645 
l0: 0.000493, l1: 0.000474, l2: 0.000490, l3: 0.000599, l4: 0.001057, l5: 0.001494, l6: 0.001859

[epoch:  30/1000, batch:   132/ 1052, ite: 7660] train loss: 0.019715, tar: 0.003638 
l0: 0.000809, l1: 0.000882, l2: 0.000847, l3: 0.000888, l4: 0.001033, l5: 0.001609, l6: 0.002175

[epoch:  30/1000, batch:   212/ 1052, ite: 7680] train loss: 0.019686, tar: 0.003631 
l0: 0.000626, l1: 0.000665, l2: 0.000641, l3: 0.000736, l4: 0.000897, l5: 0.001634, l6: 0.002257

[epoch:  30/1000, batch:   292/ 1052, ite: 7700] train loss: 0.019660, tar: 0.003624 
l0: 0.000843, l1: 0.000801, l2: 0.000812, l3: 0.000861, l4: 0.001332, l5: 0.001970, l6: 0.002647

[epoch:  30/1000, batch:   372/ 1052, ite: 7720] train loss: 0.019636, tar: 0.003617 
l0: 0.000456, l1: 0.000563, l2: 0.000576, l3: 0.000483, l4: 0.000660, l5: 0.001055, l6: 0.001534

[epoch:  30/1000, batch:   452/ 1052, ite: 7740] train loss: 0.019611, tar: 0.003610 
l0: 0.000578, l1: 0.000721, l2: 0.000490, l3: 0.000614, l4: 0.001009, l5: 0.001404, l6: 0.001915

[epoch:  30/1000, batch:   532/ 1052, ite: 7760] train loss: 0.019601, tar: 0.003605 
l0: 0.000759, l1: 0.000820, l2: 0.000757, l3: 0.000905, l4: 0.001038, l5: 0.001407, l6: 0.002832

[epoch:  30/1000, batch:   612/ 1052, ite: 7780] train loss: 0.019575, tar: 0.003598 
l0: 0.000650, l1: 0.000658, l2: 0.000696, l3: 0.000803, l4: 0.000965, l5: 0.001173, l6: 0.002262

[epoch:  30/1000, batch:   692/ 1052, ite: 7800] train loss: 0.019556, tar: 0.003592 
l0: 0.000396, l1: 0.000323, l2: 0.001376, l3: 0.001774, l4: 0.000922, l5: 0.001471, l6: 0.001455

[epoch:  30/1000, batch:   772/ 1052, ite: 7820] train loss: 0.019529, tar: 0.003585 
l0: 0.001048, l1: 0.000970, l2: 0.000919, l3: 0.001058, l4: 0.001444, l5: 0.001887, l6: 0.002284

[epoch:  30/1000, batch:   852/ 1052, ite: 7840] train loss: 0.019501, tar: 0.003577 
l0: 0.000441, l1: 0.000364, l2: 0.000445, l3: 0.000578, l4: 0.000872, l5: 0.001219, l6: 0.002118

[epoch:  30/1000, batch:   932/ 1052, ite: 7860] train loss: 0.019471, tar: 0.003570 
l0: 0.001004, l1: 0.001038, l2: 0.001497, l3: 0.001642, l4: 0.001810, l5: 0.002724, l6: 0.002098

[epoch:  30/1000, batch:  1012/ 1052, ite: 7880] train loss: 0.019477, tar: 0.003566 
[Epoch 30/1000] Test loss: 0.018, Test target loss: 0.002
l0: 0.001027, l1: 0.000939, l2: 0.001041, l3: 0.001359, l4: 0.001904, l5: 0.002144, l6: 0.003897

[epoch:  31/1000, batch:    40/ 1052, ite: 7900] train loss: 0.019472, tar: 0.003561 
l0: 0.000568, l1: 0.000550, l2: 0.000617, l3: 0.000683, l4: 0.001100, l5: 0.001777, l6: 0.002463

[epoch:  31/1000, batch:   120/ 1052, ite: 7920] train loss: 0.019450, tar: 0.003555 
l0: 0.000524, l1: 0.000460, l2: 0.000561, l3: 0.000705, l4: 0.000941, l5: 0.001410, l6: 0.002728

[epoch:  31/1000, batch:   200/ 1052, ite: 7940] train loss: 0.019430, tar: 0.003549 
l0: 0.002140, l1: 0.002202, l2: 0.002089, l3: 0.002435, l4: 0.002326, l5: 0.003347, l6: 0.004293

[epoch:  31/1000, batch:   280/ 1052, ite: 7960] train loss: 0.019413, tar: 0.003543 
l0: 0.000519, l1: 0.000509, l2: 0.000708, l3: 0.000983, l4: 0.001358, l5: 0.001125, l6: 0.001571

[epoch:  31/1000, batch:   360/ 1052, ite: 7980] train loss: 0.019392, tar: 0.003536 
l0: 0.000891, l1: 0.000780, l2: 0.001229, l3: 0.001495, l4: 0.002239, l5: 0.002981, l6: 0.004060

[epoch:  31/1000, batch:   440/ 1052, ite: 8000] train loss: 0.019373, tar: 0.003530 
l0: 0.000760, l1: 0.000802, l2: 0.000902, l3: 0.000847, l4: 0.000848, l5: 0.001271, l6: 0.002317

[epoch:  31/1000, batch:   520/ 1052, ite: 8020] train loss: 0.019353, tar: 0.003524 
l0: 0.000433, l1: 0.000384, l2: 0.000655, l3: 0.000878, l4: 0.001044, l5: 0.001272, l6: 0.002142

[epoch:  31/1000, batch:   600/ 1052, ite: 8040] train loss: 0.019325, tar: 0.003517 
l0: 0.001494, l1: 0.001646, l2: 0.001647, l3: 0.001772, l4: 0.001709, l5: 0.002335, l6: 0.003785

[epoch:  31/1000, batch:   680/ 1052, ite: 8060] train loss: 0.019302, tar: 0.003510 
l0: 0.000680, l1: 0.000681, l2: 0.000647, l3: 0.000736, l4: 0.001194, l5: 0.001601, l6: 0.002817

[epoch:  31/1000, batch:   760/ 1052, ite: 8080] train loss: 0.019280, tar: 0.003504 
l0: 0.000457, l1: 0.000448, l2: 0.000728, l3: 0.000767, l4: 0.000740, l5: 0.001036, l6: 0.001581

[epoch:  31/1000, batch:   840/ 1052, ite: 8100] train loss: 0.019256, tar: 0.003497 
l0: 0.001401, l1: 0.001346, l2: 0.001253, l3: 0.001264, l4: 0.002035, l5: 0.004034, l6: 0.004311

[epoch:  31/1000, batch:   920/ 1052, ite: 8120] train loss: 0.019241, tar: 0.003492 
l0: 0.001011, l1: 0.001143, l2: 0.001164, l3: 0.000952, l4: 0.001235, l5: 0.001778, l6: 0.003203

[epoch:  31/1000, batch:  1000/ 1052, ite: 8140] train loss: 0.019218, tar: 0.003486 
[Epoch 31/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000810, l1: 0.000897, l2: 0.000811, l3: 0.000894, l4: 0.001263, l5: 0.002006, l6: 0.002782

[epoch:  32/1000, batch:    28/ 1052, ite: 8160] train loss: 0.019221, tar: 0.003482 
l0: 0.002162, l1: 0.002676, l2: 0.003023, l3: 0.002932, l4: 0.001886, l5: 0.002398, l6: 0.003726

[epoch:  32/1000, batch:   108/ 1052, ite: 8180] train loss: 0.019205, tar: 0.003477 
l0: 0.001169, l1: 0.001301, l2: 0.001877, l3: 0.001712, l4: 0.002147, l5: 0.001486, l6: 0.001892

[epoch:  32/1000, batch:   188/ 1052, ite: 8200] train loss: 0.019188, tar: 0.003471 
l0: 0.000571, l1: 0.000592, l2: 0.000620, l3: 0.000668, l4: 0.000860, l5: 0.001278, l6: 0.001661

[epoch:  32/1000, batch:   268/ 1052, ite: 8220] train loss: 0.019164, tar: 0.003465 
l0: 0.000601, l1: 0.000541, l2: 0.000681, l3: 0.000825, l4: 0.001178, l5: 0.002215, l6: 0.002887

[epoch:  32/1000, batch:   348/ 1052, ite: 8240] train loss: 0.019138, tar: 0.003459 
l0: 0.001367, l1: 0.001451, l2: 0.001446, l3: 0.001547, l4: 0.001559, l5: 0.002002, l6: 0.002539

[epoch:  32/1000, batch:   428/ 1052, ite: 8260] train loss: 0.019115, tar: 0.003452 
l0: 0.000595, l1: 0.000594, l2: 0.000608, l3: 0.000713, l4: 0.001102, l5: 0.001862, l6: 0.002464

[epoch:  32/1000, batch:   508/ 1052, ite: 8280] train loss: 0.019093, tar: 0.003446 
l0: 0.000356, l1: 0.000339, l2: 0.000334, l3: 0.000466, l4: 0.000616, l5: 0.000841, l6: 0.001659

[epoch:  32/1000, batch:   588/ 1052, ite: 8300] train loss: 0.019080, tar: 0.003441 
l0: 0.004431, l1: 0.003897, l2: 0.007688, l3: 0.007012, l4: 0.006199, l5: 0.005635, l6: 0.006647

[epoch:  32/1000, batch:   668/ 1052, ite: 8320] train loss: 0.019061, tar: 0.003435 
l0: 0.000750, l1: 0.000679, l2: 0.000821, l3: 0.001020, l4: 0.001296, l5: 0.002021, l6: 0.003427

[epoch:  32/1000, batch:   748/ 1052, ite: 8340] train loss: 0.019040, tar: 0.003429 
l0: 0.000575, l1: 0.000544, l2: 0.000611, l3: 0.000622, l4: 0.001036, l5: 0.001704, l6: 0.003035

[epoch:  32/1000, batch:   828/ 1052, ite: 8360] train loss: 0.019021, tar: 0.003424 
l0: 0.000794, l1: 0.000736, l2: 0.000776, l3: 0.000918, l4: 0.001081, l5: 0.001644, l6: 0.003287

[epoch:  32/1000, batch:   908/ 1052, ite: 8380] train loss: 0.018998, tar: 0.003417 
l0: 0.000911, l1: 0.000950, l2: 0.001025, l3: 0.001004, l4: 0.001263, l5: 0.001430, l6: 0.002616

[epoch:  32/1000, batch:   988/ 1052, ite: 8400] train loss: 0.018971, tar: 0.003411 
[Epoch 32/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.002328, l1: 0.002609, l2: 0.002025, l3: 0.002628, l4: 0.002701, l5: 0.003067, l6: 0.003385

[epoch:  33/1000, batch:    16/ 1052, ite: 8420] train loss: 0.018950, tar: 0.003405 
l0: 0.001724, l1: 0.002006, l2: 0.001847, l3: 0.001690, l4: 0.001957, l5: 0.002833, l6: 0.005131

[epoch:  33/1000, batch:    96/ 1052, ite: 8440] train loss: 0.018931, tar: 0.003400 
l0: 0.000603, l1: 0.000559, l2: 0.000576, l3: 0.000674, l4: 0.000955, l5: 0.001218, l6: 0.002283

[epoch:  33/1000, batch:   176/ 1052, ite: 8460] train loss: 0.018908, tar: 0.003394 
l0: 0.001062, l1: 0.001054, l2: 0.001522, l3: 0.001473, l4: 0.001340, l5: 0.002021, l6: 0.002301

[epoch:  33/1000, batch:   256/ 1052, ite: 8480] train loss: 0.018886, tar: 0.003388 
l0: 0.000589, l1: 0.000613, l2: 0.000532, l3: 0.000642, l4: 0.000897, l5: 0.001377, l6: 0.002082

[epoch:  33/1000, batch:   336/ 1052, ite: 8500] train loss: 0.018861, tar: 0.003382 
l0: 0.000643, l1: 0.000625, l2: 0.000687, l3: 0.000796, l4: 0.001229, l5: 0.001690, l6: 0.003314

[epoch:  33/1000, batch:   416/ 1052, ite: 8520] train loss: 0.018839, tar: 0.003376 
l0: 0.000330, l1: 0.000289, l2: 0.000347, l3: 0.000423, l4: 0.000737, l5: 0.001347, l6: 0.001659

[epoch:  33/1000, batch:   496/ 1052, ite: 8540] train loss: 0.018814, tar: 0.003369 
l0: 0.000607, l1: 0.000643, l2: 0.000671, l3: 0.000655, l4: 0.001017, l5: 0.001457, l6: 0.002600

[epoch:  33/1000, batch:   576/ 1052, ite: 8560] train loss: 0.018791, tar: 0.003363 
l0: 0.001746, l1: 0.001433, l2: 0.002080, l3: 0.002620, l4: 0.002378, l5: 0.002893, l6: 0.005002

[epoch:  33/1000, batch:   656/ 1052, ite: 8580] train loss: 0.018767, tar: 0.003357 
l0: 0.000465, l1: 0.000462, l2: 0.000539, l3: 0.000599, l4: 0.000746, l5: 0.001160, l6: 0.001980

[epoch:  33/1000, batch:   736/ 1052, ite: 8600] train loss: 0.018760, tar: 0.003353 
l0: 0.000845, l1: 0.000721, l2: 0.001263, l3: 0.001604, l4: 0.001730, l5: 0.001521, l6: 0.001880

[epoch:  33/1000, batch:   816/ 1052, ite: 8620] train loss: 0.018738, tar: 0.003347 
l0: 0.003095, l1: 0.002671, l2: 0.003227, l3: 0.004210, l4: 0.004988, l5: 0.005261, l6: 0.006597

[epoch:  33/1000, batch:   896/ 1052, ite: 8640] train loss: 0.018716, tar: 0.003341 
l0: 0.002095, l1: 0.002638, l2: 0.001370, l3: 0.001551, l4: 0.001770, l5: 0.002385, l6: 0.003706

[epoch:  33/1000, batch:   976/ 1052, ite: 8660] train loss: 0.018692, tar: 0.003335 
[Epoch 33/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000775, l1: 0.000959, l2: 0.000799, l3: 0.000729, l4: 0.001013, l5: 0.001184, l6: 0.001550

[epoch:  34/1000, batch:     4/ 1052, ite: 8680] train loss: 0.018674, tar: 0.003330 
l0: 0.000877, l1: 0.001017, l2: 0.000991, l3: 0.001323, l4: 0.001407, l5: 0.001764, l6: 0.002755

[epoch:  34/1000, batch:    84/ 1052, ite: 8700] train loss: 0.018649, tar: 0.003324 
l0: 0.000454, l1: 0.000478, l2: 0.000536, l3: 0.000550, l4: 0.000645, l5: 0.001135, l6: 0.001737

[epoch:  34/1000, batch:   164/ 1052, ite: 8720] train loss: 0.018624, tar: 0.003318 
l0: 0.001224, l1: 0.000998, l2: 0.001211, l3: 0.001345, l4: 0.002000, l5: 0.002836, l6: 0.003590

[epoch:  34/1000, batch:   244/ 1052, ite: 8740] train loss: 0.018604, tar: 0.003312 
l0: 0.000369, l1: 0.000401, l2: 0.000449, l3: 0.000445, l4: 0.000507, l5: 0.000968, l6: 0.001404

[epoch:  34/1000, batch:   324/ 1052, ite: 8760] train loss: 0.018586, tar: 0.003307 
l0: 0.001010, l1: 0.001026, l2: 0.001271, l3: 0.001228, l4: 0.001273, l5: 0.001798, l6: 0.002492

[epoch:  34/1000, batch:   404/ 1052, ite: 8780] train loss: 0.018576, tar: 0.003303 
l0: 0.000392, l1: 0.000410, l2: 0.000431, l3: 0.000428, l4: 0.000702, l5: 0.001203, l6: 0.001623

[epoch:  34/1000, batch:   484/ 1052, ite: 8800] train loss: 0.018555, tar: 0.003298 
l0: 0.000651, l1: 0.000607, l2: 0.001064, l3: 0.001207, l4: 0.001531, l5: 0.001781, l6: 0.002513

[epoch:  34/1000, batch:   564/ 1052, ite: 8820] train loss: 0.018535, tar: 0.003292 
l0: 0.001044, l1: 0.001124, l2: 0.000990, l3: 0.001339, l4: 0.001773, l5: 0.002378, l6: 0.002643

[epoch:  34/1000, batch:   644/ 1052, ite: 8840] train loss: 0.018516, tar: 0.003287 
l0: 0.000751, l1: 0.000695, l2: 0.000739, l3: 0.000911, l4: 0.001220, l5: 0.001574, l6: 0.003385

[epoch:  34/1000, batch:   724/ 1052, ite: 8860] train loss: 0.018498, tar: 0.003282 
l0: 0.000582, l1: 0.000516, l2: 0.000614, l3: 0.000674, l4: 0.001010, l5: 0.001670, l6: 0.001863

[epoch:  34/1000, batch:   804/ 1052, ite: 8880] train loss: 0.018478, tar: 0.003276 
l0: 0.000396, l1: 0.000403, l2: 0.000603, l3: 0.000501, l4: 0.000570, l5: 0.000955, l6: 0.001536

[epoch:  34/1000, batch:   884/ 1052, ite: 8900] train loss: 0.018456, tar: 0.003271 
l0: 0.000500, l1: 0.000599, l2: 0.000576, l3: 0.000710, l4: 0.000740, l5: 0.001129, l6: 0.001481

[epoch:  34/1000, batch:   964/ 1052, ite: 8920] train loss: 0.018434, tar: 0.003265 
l0: 0.000651, l1: 0.000615, l2: 0.000796, l3: 0.000715, l4: 0.000912, l5: 0.001435, l6: 0.002292

[epoch:  34/1000, batch:  1044/ 1052, ite: 8940] train loss: 0.018415, tar: 0.003260 
[Epoch 34/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000496, l1: 0.000458, l2: 0.000565, l3: 0.000615, l4: 0.001035, l5: 0.001756, l6: 0.002181

[epoch:  35/1000, batch:    72/ 1052, ite: 8960] train loss: 0.018394, tar: 0.003254 
l0: 0.000416, l1: 0.000391, l2: 0.000481, l3: 0.000491, l4: 0.000726, l5: 0.001678, l6: 0.001864

[epoch:  35/1000, batch:   152/ 1052, ite: 8980] train loss: 0.018371, tar: 0.003249 
l0: 0.000508, l1: 0.000529, l2: 0.000562, l3: 0.001070, l4: 0.001280, l5: 0.001990, l6: 0.001959

[epoch:  35/1000, batch:   232/ 1052, ite: 9000] train loss: 0.018347, tar: 0.003243 
l0: 0.000655, l1: 0.000617, l2: 0.000664, l3: 0.000672, l4: 0.001114, l5: 0.001772, l6: 0.002680

[epoch:  35/1000, batch:   312/ 1052, ite: 9020] train loss: 0.018327, tar: 0.003237 
l0: 0.000936, l1: 0.000966, l2: 0.001000, l3: 0.001244, l4: 0.001096, l5: 0.001540, l6: 0.003258

[epoch:  35/1000, batch:   392/ 1052, ite: 9040] train loss: 0.018307, tar: 0.003232 
l0: 0.000879, l1: 0.000919, l2: 0.001266, l3: 0.001193, l4: 0.001142, l5: 0.001441, l6: 0.002036

[epoch:  35/1000, batch:   472/ 1052, ite: 9060] train loss: 0.018284, tar: 0.003227 
l0: 0.001614, l1: 0.001366, l2: 0.002067, l3: 0.002523, l4: 0.003238, l5: 0.002336, l6: 0.002939

[epoch:  35/1000, batch:   552/ 1052, ite: 9080] train loss: 0.018269, tar: 0.003222 
l0: 0.000972, l1: 0.000971, l2: 0.001208, l3: 0.001498, l4: 0.001437, l5: 0.002187, l6: 0.003264

[epoch:  35/1000, batch:   632/ 1052, ite: 9100] train loss: 0.018250, tar: 0.003217 
l0: 0.000520, l1: 0.000513, l2: 0.000562, l3: 0.000634, l4: 0.000793, l5: 0.001450, l6: 0.002226

[epoch:  35/1000, batch:   712/ 1052, ite: 9120] train loss: 0.018230, tar: 0.003212 
l0: 0.000650, l1: 0.000615, l2: 0.000753, l3: 0.000665, l4: 0.001096, l5: 0.001961, l6: 0.002723

[epoch:  35/1000, batch:   792/ 1052, ite: 9140] train loss: 0.018207, tar: 0.003206 
l0: 0.001385, l1: 0.001222, l2: 0.001292, l3: 0.001967, l4: 0.002356, l5: 0.003031, l6: 0.004202

[epoch:  35/1000, batch:   872/ 1052, ite: 9160] train loss: 0.018200, tar: 0.003202 
l0: 0.001221, l1: 0.001334, l2: 0.001283, l3: 0.001538, l4: 0.001627, l5: 0.002033, l6: 0.004081

[epoch:  35/1000, batch:   952/ 1052, ite: 9180] train loss: 0.018179, tar: 0.003197 
l0: 0.000496, l1: 0.000526, l2: 0.000649, l3: 0.001133, l4: 0.000919, l5: 0.001275, l6: 0.001879

[epoch:  35/1000, batch:  1032/ 1052, ite: 9200] train loss: 0.018157, tar: 0.003191 
[Epoch 35/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000429, l1: 0.000444, l2: 0.000491, l3: 0.000471, l4: 0.000568, l5: 0.001194, l6: 0.001241

[epoch:  36/1000, batch:    60/ 1052, ite: 9220] train loss: 0.018136, tar: 0.003186 
l0: 0.001320, l1: 0.001287, l2: 0.001954, l3: 0.001895, l4: 0.001864, l5: 0.002514, l6: 0.003766

[epoch:  36/1000, batch:   140/ 1052, ite: 9240] train loss: 0.018118, tar: 0.003181 
l0: 0.000916, l1: 0.000888, l2: 0.001002, l3: 0.001249, l4: 0.001569, l5: 0.002513, l6: 0.003766

[epoch:  36/1000, batch:   220/ 1052, ite: 9260] train loss: 0.018098, tar: 0.003176 
l0: 0.000837, l1: 0.000799, l2: 0.000919, l3: 0.000881, l4: 0.001990, l5: 0.001882, l6: 0.002598

[epoch:  36/1000, batch:   300/ 1052, ite: 9280] train loss: 0.018091, tar: 0.003173 
l0: 0.000858, l1: 0.000992, l2: 0.000890, l3: 0.000891, l4: 0.001283, l5: 0.001462, l6: 0.001528

[epoch:  36/1000, batch:   380/ 1052, ite: 9300] train loss: 0.018073, tar: 0.003168 
l0: 0.000878, l1: 0.000826, l2: 0.001212, l3: 0.001278, l4: 0.001576, l5: 0.002033, l6: 0.003032

[epoch:  36/1000, batch:   460/ 1052, ite: 9320] train loss: 0.018058, tar: 0.003163 
l0: 0.000344, l1: 0.000356, l2: 0.000427, l3: 0.000411, l4: 0.000730, l5: 0.000754, l6: 0.001438

[epoch:  36/1000, batch:   540/ 1052, ite: 9340] train loss: 0.018039, tar: 0.003158 
l0: 0.000724, l1: 0.000702, l2: 0.000734, l3: 0.000965, l4: 0.001152, l5: 0.001736, l6: 0.002125

[epoch:  36/1000, batch:   620/ 1052, ite: 9360] train loss: 0.018019, tar: 0.003154 
l0: 0.001671, l1: 0.002427, l2: 0.002219, l3: 0.001929, l4: 0.002199, l5: 0.002385, l6: 0.002876

[epoch:  36/1000, batch:   700/ 1052, ite: 9380] train loss: 0.018006, tar: 0.003150 
l0: 0.000707, l1: 0.000728, l2: 0.000675, l3: 0.000914, l4: 0.000781, l5: 0.001167, l6: 0.001797

[epoch:  36/1000, batch:   780/ 1052, ite: 9400] train loss: 0.017985, tar: 0.003144 
l0: 0.002765, l1: 0.002838, l2: 0.002039, l3: 0.002389, l4: 0.004119, l5: 0.003332, l6: 0.005596

[epoch:  36/1000, batch:   860/ 1052, ite: 9420] train loss: 0.017968, tar: 0.003140 
l0: 0.000476, l1: 0.000572, l2: 0.000427, l3: 0.000457, l4: 0.000858, l5: 0.000975, l6: 0.001714

[epoch:  36/1000, batch:   940/ 1052, ite: 9440] train loss: 0.017947, tar: 0.003135 
l0: 0.000757, l1: 0.000696, l2: 0.000889, l3: 0.001243, l4: 0.001565, l5: 0.001999, l6: 0.003743

[epoch:  36/1000, batch:  1020/ 1052, ite: 9460] train loss: 0.017938, tar: 0.003131 
[Epoch 36/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000268, l1: 0.000330, l2: 0.000320, l3: 0.000249, l4: 0.000498, l5: 0.000822, l6: 0.000953

[epoch:  37/1000, batch:    48/ 1052, ite: 9480] train loss: 0.017917, tar: 0.003126 
l0: 0.000845, l1: 0.000784, l2: 0.001394, l3: 0.001346, l4: 0.001754, l5: 0.001990, l6: 0.003091

[epoch:  37/1000, batch:   128/ 1052, ite: 9500] train loss: 0.017904, tar: 0.003122 
l0: 0.000311, l1: 0.000286, l2: 0.000368, l3: 0.000475, l4: 0.000812, l5: 0.001180, l6: 0.001097

[epoch:  37/1000, batch:   208/ 1052, ite: 9520] train loss: 0.017886, tar: 0.003117 
l0: 0.000357, l1: 0.000452, l2: 0.000534, l3: 0.000388, l4: 0.000990, l5: 0.000845, l6: 0.001742

[epoch:  37/1000, batch:   288/ 1052, ite: 9540] train loss: 0.017878, tar: 0.003113 
l0: 0.000798, l1: 0.000791, l2: 0.000854, l3: 0.000952, l4: 0.001131, l5: 0.002066, l6: 0.003589

[epoch:  37/1000, batch:   368/ 1052, ite: 9560] train loss: 0.017865, tar: 0.003109 
l0: 0.000485, l1: 0.000514, l2: 0.000434, l3: 0.000523, l4: 0.000696, l5: 0.001015, l6: 0.001511

[epoch:  37/1000, batch:   448/ 1052, ite: 9580] train loss: 0.017851, tar: 0.003105 
l0: 0.000625, l1: 0.000668, l2: 0.000748, l3: 0.000809, l4: 0.001330, l5: 0.001701, l6: 0.002556

[epoch:  37/1000, batch:   528/ 1052, ite: 9600] train loss: 0.017833, tar: 0.003100 
l0: 0.000689, l1: 0.000676, l2: 0.000843, l3: 0.000745, l4: 0.000906, l5: 0.001359, l6: 0.001710

[epoch:  37/1000, batch:   608/ 1052, ite: 9620] train loss: 0.017818, tar: 0.003096 
l0: 0.002100, l1: 0.002171, l2: 0.002546, l3: 0.002295, l4: 0.002316, l5: 0.002380, l6: 0.005518

[epoch:  37/1000, batch:   688/ 1052, ite: 9640] train loss: 0.017797, tar: 0.003091 
l0: 0.000717, l1: 0.000705, l2: 0.000782, l3: 0.000781, l4: 0.001029, l5: 0.001523, l6: 0.001983

[epoch:  37/1000, batch:   768/ 1052, ite: 9660] train loss: 0.017778, tar: 0.003086 
l0: 0.000619, l1: 0.000630, l2: 0.000655, l3: 0.000796, l4: 0.001004, l5: 0.001200, l6: 0.001766

[epoch:  37/1000, batch:   848/ 1052, ite: 9680] train loss: 0.017757, tar: 0.003081 
l0: 0.000289, l1: 0.000311, l2: 0.000825, l3: 0.000632, l4: 0.000520, l5: 0.000507, l6: 0.001247

[epoch:  37/1000, batch:   928/ 1052, ite: 9700] train loss: 0.017739, tar: 0.003077 
l0: 0.003677, l1: 0.003966, l2: 0.004007, l3: 0.003521, l4: 0.003283, l5: 0.003674, l6: 0.005917

[epoch:  37/1000, batch:  1008/ 1052, ite: 9720] train loss: 0.017721, tar: 0.003072 
[Epoch 37/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000657, l1: 0.000635, l2: 0.000733, l3: 0.000754, l4: 0.001016, l5: 0.001608, l6: 0.002719

[epoch:  38/1000, batch:    36/ 1052, ite: 9740] train loss: 0.017705, tar: 0.003068 
l0: 0.000781, l1: 0.000767, l2: 0.000717, l3: 0.000882, l4: 0.001310, l5: 0.001739, l6: 0.003082

[epoch:  38/1000, batch:   116/ 1052, ite: 9760] train loss: 0.017684, tar: 0.003063 
l0: 0.000598, l1: 0.000585, l2: 0.000620, l3: 0.000744, l4: 0.001050, l5: 0.001280, l6: 0.002643

[epoch:  38/1000, batch:   196/ 1052, ite: 9780] train loss: 0.017664, tar: 0.003058 
l0: 0.000299, l1: 0.000265, l2: 0.000429, l3: 0.000495, l4: 0.000552, l5: 0.000766, l6: 0.001369

[epoch:  38/1000, batch:   276/ 1052, ite: 9800] train loss: 0.017643, tar: 0.003053 
l0: 0.000556, l1: 0.000581, l2: 0.000578, l3: 0.000660, l4: 0.000763, l5: 0.001652, l6: 0.002418

[epoch:  38/1000, batch:   356/ 1052, ite: 9820] train loss: 0.017625, tar: 0.003048 
l0: 0.001225, l1: 0.001291, l2: 0.001215, l3: 0.001784, l4: 0.001524, l5: 0.002342, l6: 0.002902

[epoch:  38/1000, batch:   436/ 1052, ite: 9840] train loss: 0.017608, tar: 0.003044 
l0: 0.001068, l1: 0.001075, l2: 0.001056, l3: 0.001198, l4: 0.001186, l5: 0.001773, l6: 0.002733

[epoch:  38/1000, batch:   516/ 1052, ite: 9860] train loss: 0.017588, tar: 0.003039 
l0: 0.000518, l1: 0.000798, l2: 0.000415, l3: 0.000406, l4: 0.000554, l5: 0.000635, l6: 0.001001

[epoch:  38/1000, batch:   596/ 1052, ite: 9880] train loss: 0.017572, tar: 0.003035 
l0: 0.001195, l1: 0.001190, l2: 0.001090, l3: 0.001053, l4: 0.001579, l5: 0.002476, l6: 0.004187

[epoch:  38/1000, batch:   676/ 1052, ite: 9900] train loss: 0.017551, tar: 0.003030 
l0: 0.000468, l1: 0.000492, l2: 0.000493, l3: 0.000515, l4: 0.000890, l5: 0.001221, l6: 0.002348

[epoch:  38/1000, batch:   756/ 1052, ite: 9920] train loss: 0.017534, tar: 0.003025 
l0: 0.000728, l1: 0.000702, l2: 0.000768, l3: 0.000780, l4: 0.001071, l5: 0.001667, l6: 0.002968

[epoch:  38/1000, batch:   836/ 1052, ite: 9940] train loss: 0.017520, tar: 0.003021 
l0: 0.000498, l1: 0.000502, l2: 0.000529, l3: 0.000636, l4: 0.000746, l5: 0.000842, l6: 0.001591

[epoch:  38/1000, batch:   916/ 1052, ite: 9960] train loss: 0.017505, tar: 0.003017 
l0: 0.000738, l1: 0.001193, l2: 0.000722, l3: 0.000731, l4: 0.000774, l5: 0.001135, l6: 0.001397

[epoch:  38/1000, batch:   996/ 1052, ite: 9980] train loss: 0.017502, tar: 0.003015 
[Epoch 38/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000950, l1: 0.000907, l2: 0.001092, l3: 0.001110, l4: 0.001322, l5: 0.001836, l6: 0.001938

[epoch:  39/1000, batch:    24/ 1052, ite: 10000] train loss: 0.017490, tar: 0.003011 
l0: 0.000534, l1: 0.000626, l2: 0.000529, l3: 0.000598, l4: 0.000951, l5: 0.001367, l6: 0.001523

[epoch:  39/1000, batch:   104/ 1052, ite: 10020] train loss: 0.017478, tar: 0.003008 
l0: 0.000327, l1: 0.000355, l2: 0.000340, l3: 0.000364, l4: 0.000635, l5: 0.001010, l6: 0.001468

[epoch:  39/1000, batch:   184/ 1052, ite: 10040] train loss: 0.017463, tar: 0.003004 
l0: 0.000465, l1: 0.000454, l2: 0.000469, l3: 0.000685, l4: 0.000902, l5: 0.001613, l6: 0.002407

[epoch:  39/1000, batch:   264/ 1052, ite: 10060] train loss: 0.017451, tar: 0.003000 
l0: 0.000377, l1: 0.000350, l2: 0.000558, l3: 0.000641, l4: 0.000746, l5: 0.000990, l6: 0.001642

[epoch:  39/1000, batch:   344/ 1052, ite: 10080] train loss: 0.017435, tar: 0.002996 
l0: 0.000773, l1: 0.000759, l2: 0.001828, l3: 0.002377, l4: 0.001974, l5: 0.002002, l6: 0.002797

[epoch:  39/1000, batch:   424/ 1052, ite: 10100] train loss: 0.017422, tar: 0.002991 
l0: 0.000674, l1: 0.000653, l2: 0.000700, l3: 0.000873, l4: 0.000961, l5: 0.001615, l6: 0.002447

[epoch:  39/1000, batch:   504/ 1052, ite: 10120] train loss: 0.017412, tar: 0.002988 
l0: 0.003051, l1: 0.002750, l2: 0.004235, l3: 0.004759, l4: 0.003203, l5: 0.004851, l6: 0.006430

[epoch:  39/1000, batch:   584/ 1052, ite: 10140] train loss: 0.017403, tar: 0.002984 
l0: 0.003008, l1: 0.003734, l2: 0.002525, l3: 0.002410, l4: 0.002216, l5: 0.003831, l6: 0.004737

[epoch:  39/1000, batch:   664/ 1052, ite: 10160] train loss: 0.017397, tar: 0.002981 
l0: 0.000494, l1: 0.000523, l2: 0.000572, l3: 0.000607, l4: 0.000715, l5: 0.001212, l6: 0.001649

[epoch:  39/1000, batch:   744/ 1052, ite: 10180] train loss: 0.017380, tar: 0.002977 
l0: 0.001242, l1: 0.001208, l2: 0.001336, l3: 0.001505, l4: 0.001453, l5: 0.002426, l6: 0.003363

[epoch:  39/1000, batch:   824/ 1052, ite: 10200] train loss: 0.017361, tar: 0.002973 
l0: 0.001381, l1: 0.001399, l2: 0.001412, l3: 0.001826, l4: 0.002236, l5: 0.001893, l6: 0.002979

[epoch:  39/1000, batch:   904/ 1052, ite: 10220] train loss: 0.017351, tar: 0.002969 
l0: 0.000521, l1: 0.000541, l2: 0.000505, l3: 0.000434, l4: 0.000709, l5: 0.001674, l6: 0.001688

[epoch:  39/1000, batch:   984/ 1052, ite: 10240] train loss: 0.017334, tar: 0.002965 
[Epoch 39/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000447, l1: 0.000449, l2: 0.000479, l3: 0.000560, l4: 0.000622, l5: 0.001173, l6: 0.002319

[epoch:  40/1000, batch:    12/ 1052, ite: 10260] train loss: 0.017320, tar: 0.002961 
l0: 0.000596, l1: 0.000596, l2: 0.000610, l3: 0.000653, l4: 0.000900, l5: 0.001165, l6: 0.002276

[epoch:  40/1000, batch:    92/ 1052, ite: 10280] train loss: 0.017307, tar: 0.002957 
l0: 0.000847, l1: 0.000775, l2: 0.001007, l3: 0.001051, l4: 0.001065, l5: 0.001738, l6: 0.002687

[epoch:  40/1000, batch:   172/ 1052, ite: 10300] train loss: 0.017292, tar: 0.002953 
l0: 0.000607, l1: 0.000546, l2: 0.000670, l3: 0.000852, l4: 0.001166, l5: 0.001648, l6: 0.002662

[epoch:  40/1000, batch:   252/ 1052, ite: 10320] train loss: 0.017275, tar: 0.002949 
l0: 0.000653, l1: 0.000650, l2: 0.000695, l3: 0.000752, l4: 0.000856, l5: 0.001364, l6: 0.002146

[epoch:  40/1000, batch:   332/ 1052, ite: 10340] train loss: 0.017258, tar: 0.002945 
l0: 0.002201, l1: 0.001956, l2: 0.003668, l3: 0.002462, l4: 0.002946, l5: 0.003675, l6: 0.005578

[epoch:  40/1000, batch:   412/ 1052, ite: 10360] train loss: 0.017247, tar: 0.002941 
l0: 0.000456, l1: 0.000418, l2: 0.000446, l3: 0.000633, l4: 0.000881, l5: 0.001423, l6: 0.002188

[epoch:  40/1000, batch:   492/ 1052, ite: 10380] train loss: 0.017231, tar: 0.002937 
l0: 0.001240, l1: 0.001203, l2: 0.001157, l3: 0.001320, l4: 0.001708, l5: 0.002772, l6: 0.004387

[epoch:  40/1000, batch:   572/ 1052, ite: 10400] train loss: 0.017215, tar: 0.002933 
l0: 0.000407, l1: 0.000728, l2: 0.000301, l3: 0.000498, l4: 0.000481, l5: 0.000648, l6: 0.000882

[epoch:  40/1000, batch:   652/ 1052, ite: 10420] train loss: 0.017197, tar: 0.002928 
l0: 0.000817, l1: 0.000792, l2: 0.000767, l3: 0.000976, l4: 0.001097, l5: 0.001451, l6: 0.003110

[epoch:  40/1000, batch:   732/ 1052, ite: 10440] train loss: 0.017177, tar: 0.002924 
l0: 0.000338, l1: 0.000372, l2: 0.000367, l3: 0.000463, l4: 0.000771, l5: 0.000855, l6: 0.001921

[epoch:  40/1000, batch:   812/ 1052, ite: 10460] train loss: 0.017160, tar: 0.002920 
l0: 0.000748, l1: 0.000713, l2: 0.000774, l3: 0.000948, l4: 0.001003, l5: 0.001840, l6: 0.002881

[epoch:  40/1000, batch:   892/ 1052, ite: 10480] train loss: 0.017142, tar: 0.002915 
l0: 0.001078, l1: 0.001119, l2: 0.001259, l3: 0.001186, l4: 0.001261, l5: 0.002186, l6: 0.003768

[epoch:  40/1000, batch:   972/ 1052, ite: 10500] train loss: 0.017137, tar: 0.002913 
l0: 0.001034, l1: 0.000995, l2: 0.001032, l3: 0.001192, l4: 0.001605, l5: 0.002514, l6: 0.003408

[epoch:  40/1000, batch:  1052/ 1052, ite: 10520] train loss: 0.017120, tar: 0.002908 
[Epoch 40/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000492, l1: 0.000517, l2: 0.000456, l3: 0.000599, l4: 0.000976, l5: 0.001654, l6: 0.002194

[epoch:  41/1000, batch:    80/ 1052, ite: 10540] train loss: 0.008223, tar: 0.000738 
l0: 0.000315, l1: 0.000305, l2: 0.000323, l3: 0.000404, l4: 0.000565, l5: 0.001058, l6: 0.001512

[epoch:  41/1000, batch:   160/ 1052, ite: 10560] train loss: 0.007597, tar: 0.000669 
l0: 0.000566, l1: 0.000531, l2: 0.000620, l3: 0.000746, l4: 0.000780, l5: 0.001250, l6: 0.003024

[epoch:  41/1000, batch:   240/ 1052, ite: 10580] train loss: 0.007836, tar: 0.000693 
l0: 0.000242, l1: 0.000236, l2: 0.000231, l3: 0.000326, l4: 0.000529, l5: 0.000878, l6: 0.001693

[epoch:  41/1000, batch:   320/ 1052, ite: 10600] train loss: 0.007896, tar: 0.000707 
l0: 0.000907, l1: 0.000866, l2: 0.000961, l3: 0.001125, l4: 0.001398, l5: 0.001575, l6: 0.002871

[epoch:  41/1000, batch:   400/ 1052, ite: 10620] train loss: 0.007928, tar: 0.000703 
l0: 0.001081, l1: 0.001097, l2: 0.001116, l3: 0.001321, l4: 0.002202, l5: 0.002104, l6: 0.002474

[epoch:  41/1000, batch:   480/ 1052, ite: 10640] train loss: 0.007899, tar: 0.000692 
l0: 0.000488, l1: 0.000517, l2: 0.000551, l3: 0.000609, l4: 0.000689, l5: 0.001000, l6: 0.001852

[epoch:  41/1000, batch:   560/ 1052, ite: 10660] train loss: 0.008129, tar: 0.000714 
l0: 0.000595, l1: 0.000583, l2: 0.000590, l3: 0.000829, l4: 0.000803, l5: 0.001111, l6: 0.001510

[epoch:  41/1000, batch:   640/ 1052, ite: 10680] train loss: 0.007982, tar: 0.000698 
l0: 0.001111, l1: 0.001190, l2: 0.001227, l3: 0.001296, l4: 0.001652, l5: 0.002485, l6: 0.004098

[epoch:  41/1000, batch:   720/ 1052, ite: 10700] train loss: 0.008453, tar: 0.000754 
l0: 0.000907, l1: 0.000950, l2: 0.000960, l3: 0.000988, l4: 0.001062, l5: 0.001619, l6: 0.002802

[epoch:  41/1000, batch:   800/ 1052, ite: 10720] train loss: 0.009334, tar: 0.000857 
l0: 0.001444, l1: 0.001302, l2: 0.001455, l3: 0.002266, l4: 0.001977, l5: 0.003175, l6: 0.003683

[epoch:  41/1000, batch:   880/ 1052, ite: 10740] train loss: 0.009407, tar: 0.000863 
l0: 0.000388, l1: 0.000506, l2: 0.000375, l3: 0.000371, l4: 0.000543, l5: 0.000603, l6: 0.001273

[epoch:  41/1000, batch:   960/ 1052, ite: 10760] train loss: 0.009267, tar: 0.000845 
l0: 0.000786, l1: 0.000850, l2: 0.000985, l3: 0.001267, l4: 0.001500, l5: 0.001390, l6: 0.001994

[epoch:  41/1000, batch:  1040/ 1052, ite: 10780] train loss: 0.009266, tar: 0.000842 
[Epoch 41/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.001299, l1: 0.001309, l2: 0.001250, l3: 0.001375, l4: 0.001517, l5: 0.002569, l6: 0.003086

[epoch:  42/1000, batch:    68/ 1052, ite: 10800] train loss: 0.009200, tar: 0.000834 
l0: 0.000491, l1: 0.000576, l2: 0.000451, l3: 0.000475, l4: 0.000500, l5: 0.000759, l6: 0.001341

[epoch:  42/1000, batch:   148/ 1052, ite: 10820] train loss: 0.009202, tar: 0.000837 
l0: 0.000846, l1: 0.000922, l2: 0.000846, l3: 0.000955, l4: 0.001039, l5: 0.001490, l6: 0.002573

[epoch:  42/1000, batch:   228/ 1052, ite: 10840] train loss: 0.009152, tar: 0.000832 
l0: 0.000846, l1: 0.000824, l2: 0.001007, l3: 0.001186, l4: 0.001138, l5: 0.001211, l6: 0.002773

[epoch:  42/1000, batch:   308/ 1052, ite: 10860] train loss: 0.009372, tar: 0.000859 
l0: 0.000693, l1: 0.000691, l2: 0.000747, l3: 0.000814, l4: 0.001007, l5: 0.001571, l6: 0.002864

[epoch:  42/1000, batch:   388/ 1052, ite: 10880] train loss: 0.009411, tar: 0.000862 
l0: 0.000555, l1: 0.000561, l2: 0.000599, l3: 0.000675, l4: 0.000797, l5: 0.001101, l6: 0.002263

[epoch:  42/1000, batch:   468/ 1052, ite: 10900] train loss: 0.009427, tar: 0.000860 
l0: 0.000533, l1: 0.000536, l2: 0.000657, l3: 0.000764, l4: 0.000910, l5: 0.000949, l6: 0.001277

[epoch:  42/1000, batch:   548/ 1052, ite: 10920] train loss: 0.009458, tar: 0.000862 
l0: 0.000739, l1: 0.000729, l2: 0.000870, l3: 0.000803, l4: 0.001192, l5: 0.001973, l6: 0.003423

[epoch:  42/1000, batch:   628/ 1052, ite: 10940] train loss: 0.009492, tar: 0.000863 
l0: 0.000595, l1: 0.000564, l2: 0.000614, l3: 0.000693, l4: 0.000982, l5: 0.001684, l6: 0.003102

[epoch:  42/1000, batch:   708/ 1052, ite: 10960] train loss: 0.009448, tar: 0.000856 
l0: 0.001709, l1: 0.001763, l2: 0.002009, l3: 0.002497, l4: 0.002739, l5: 0.003384, l6: 0.004795

[epoch:  42/1000, batch:   788/ 1052, ite: 10980] train loss: 0.009454, tar: 0.000858 
l0: 0.000491, l1: 0.000446, l2: 0.000458, l3: 0.000663, l4: 0.000771, l5: 0.001479, l6: 0.001935

[epoch:  42/1000, batch:   868/ 1052, ite: 11000] train loss: 0.009373, tar: 0.000847 
l0: 0.000387, l1: 0.000353, l2: 0.000396, l3: 0.000541, l4: 0.000714, l5: 0.001389, l6: 0.002340

[epoch:  42/1000, batch:   948/ 1052, ite: 11020] train loss: 0.009341, tar: 0.000842 
l0: 0.000444, l1: 0.000429, l2: 0.000438, l3: 0.000524, l4: 0.000700, l5: 0.001131, l6: 0.001926

[epoch:  42/1000, batch:  1028/ 1052, ite: 11040] train loss: 0.009295, tar: 0.000838 
[Epoch 42/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000649, l1: 0.000668, l2: 0.000640, l3: 0.000797, l4: 0.001003, l5: 0.001213, l6: 0.001724

[epoch:  43/1000, batch:    56/ 1052, ite: 11060] train loss: 0.009255, tar: 0.000834 
l0: 0.000392, l1: 0.000375, l2: 0.000385, l3: 0.000448, l4: 0.000600, l5: 0.001058, l6: 0.001618

[epoch:  43/1000, batch:   136/ 1052, ite: 11080] train loss: 0.009217, tar: 0.000829 
l0: 0.000380, l1: 0.000341, l2: 0.000639, l3: 0.001282, l4: 0.001155, l5: 0.001142, l6: 0.002303

[epoch:  43/1000, batch:   216/ 1052, ite: 11100] train loss: 0.009155, tar: 0.000821 
l0: 0.000534, l1: 0.000561, l2: 0.000567, l3: 0.000747, l4: 0.000837, l5: 0.001328, l6: 0.001390

[epoch:  43/1000, batch:   296/ 1052, ite: 11120] train loss: 0.009153, tar: 0.000820 
l0: 0.000620, l1: 0.000681, l2: 0.000693, l3: 0.000604, l4: 0.001178, l5: 0.001422, l6: 0.001954

[epoch:  43/1000, batch:   376/ 1052, ite: 11140] train loss: 0.009131, tar: 0.000817 
l0: 0.000757, l1: 0.000709, l2: 0.000831, l3: 0.000919, l4: 0.001450, l5: 0.001527, l6: 0.002409

[epoch:  43/1000, batch:   456/ 1052, ite: 11160] train loss: 0.009063, tar: 0.000809 
l0: 0.000796, l1: 0.000754, l2: 0.000836, l3: 0.001069, l4: 0.001557, l5: 0.002101, l6: 0.003702

[epoch:  43/1000, batch:   536/ 1052, ite: 11180] train loss: 0.009032, tar: 0.000806 
l0: 0.000673, l1: 0.000694, l2: 0.000693, l3: 0.000743, l4: 0.000970, l5: 0.001496, l6: 0.002885

[epoch:  43/1000, batch:   616/ 1052, ite: 11200] train loss: 0.009052, tar: 0.000807 
l0: 0.000281, l1: 0.000299, l2: 0.000276, l3: 0.000299, l4: 0.000416, l5: 0.000840, l6: 0.000990

[epoch:  43/1000, batch:   696/ 1052, ite: 11220] train loss: 0.009176, tar: 0.000822 
l0: 0.001053, l1: 0.001070, l2: 0.001020, l3: 0.001163, l4: 0.001447, l5: 0.001842, l6: 0.002769

[epoch:  43/1000, batch:   776/ 1052, ite: 11240] train loss: 0.009163, tar: 0.000820 
l0: 0.000741, l1: 0.000720, l2: 0.000874, l3: 0.000984, l4: 0.001331, l5: 0.001995, l6: 0.002588

[epoch:  43/1000, batch:   856/ 1052, ite: 11260] train loss: 0.009168, tar: 0.000821 
l0: 0.000785, l1: 0.000801, l2: 0.000990, l3: 0.001031, l4: 0.001208, l5: 0.001726, l6: 0.002728

[epoch:  43/1000, batch:   936/ 1052, ite: 11280] train loss: 0.009193, tar: 0.000823 
l0: 0.000797, l1: 0.000831, l2: 0.000881, l3: 0.001013, l4: 0.001069, l5: 0.001476, l6: 0.002719

[epoch:  43/1000, batch:  1016/ 1052, ite: 11300] train loss: 0.009142, tar: 0.000818 
[Epoch 43/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000977, l1: 0.000986, l2: 0.001592, l3: 0.001677, l4: 0.001667, l5: 0.001522, l6: 0.002849

[epoch:  44/1000, batch:    44/ 1052, ite: 11320] train loss: 0.009179, tar: 0.000825 
l0: 0.001096, l1: 0.001086, l2: 0.001160, l3: 0.001330, l4: 0.001569, l5: 0.002617, l6: 0.002479

[epoch:  44/1000, batch:   124/ 1052, ite: 11340] train loss: 0.009175, tar: 0.000824 
l0: 0.000811, l1: 0.000828, l2: 0.000897, l3: 0.000944, l4: 0.001419, l5: 0.001696, l6: 0.002367

[epoch:  44/1000, batch:   204/ 1052, ite: 11360] train loss: 0.009147, tar: 0.000822 
l0: 0.000620, l1: 0.000645, l2: 0.000813, l3: 0.000979, l4: 0.001054, l5: 0.002023, l6: 0.001819

[epoch:  44/1000, batch:   284/ 1052, ite: 11380] train loss: 0.009152, tar: 0.000823 
l0: 0.000800, l1: 0.000873, l2: 0.000697, l3: 0.000886, l4: 0.001138, l5: 0.001424, l6: 0.002083

[epoch:  44/1000, batch:   364/ 1052, ite: 11400] train loss: 0.009162, tar: 0.000823 
l0: 0.000610, l1: 0.000647, l2: 0.000637, l3: 0.000663, l4: 0.000809, l5: 0.001171, l6: 0.002270

[epoch:  44/1000, batch:   444/ 1052, ite: 11420] train loss: 0.009144, tar: 0.000819 
l0: 0.000361, l1: 0.000387, l2: 0.000361, l3: 0.000393, l4: 0.000651, l5: 0.001216, l6: 0.002209

[epoch:  44/1000, batch:   524/ 1052, ite: 11440] train loss: 0.009150, tar: 0.000818 
l0: 0.000636, l1: 0.000641, l2: 0.000577, l3: 0.000737, l4: 0.000964, l5: 0.001864, l6: 0.002231

[epoch:  44/1000, batch:   604/ 1052, ite: 11460] train loss: 0.009244, tar: 0.000828 
l0: 0.000631, l1: 0.000644, l2: 0.000772, l3: 0.000778, l4: 0.000929, l5: 0.001725, l6: 0.003365

[epoch:  44/1000, batch:   684/ 1052, ite: 11480] train loss: 0.009213, tar: 0.000826 
l0: 0.000447, l1: 0.000442, l2: 0.000613, l3: 0.000658, l4: 0.000786, l5: 0.000692, l6: 0.001491

[epoch:  44/1000, batch:   764/ 1052, ite: 11500] train loss: 0.009200, tar: 0.000827 
l0: 0.001265, l1: 0.001432, l2: 0.000980, l3: 0.001278, l4: 0.001753, l5: 0.002362, l6: 0.003301

[epoch:  44/1000, batch:   844/ 1052, ite: 11520] train loss: 0.009196, tar: 0.000827 
l0: 0.000453, l1: 0.000462, l2: 0.000503, l3: 0.000668, l4: 0.000820, l5: 0.000838, l6: 0.001486

[epoch:  44/1000, batch:   924/ 1052, ite: 11540] train loss: 0.009174, tar: 0.000824 
l0: 0.001023, l1: 0.001008, l2: 0.001132, l3: 0.001430, l4: 0.001906, l5: 0.002596, l6: 0.003512

[epoch:  44/1000, batch:  1004/ 1052, ite: 11560] train loss: 0.009196, tar: 0.000826 
[Epoch 44/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000493, l1: 0.000532, l2: 0.000550, l3: 0.000598, l4: 0.000797, l5: 0.000727, l6: 0.001317

[epoch:  45/1000, batch:    32/ 1052, ite: 11580] train loss: 0.009167, tar: 0.000822 
l0: 0.000949, l1: 0.001295, l2: 0.000794, l3: 0.000697, l4: 0.000775, l5: 0.001066, l6: 0.001283

[epoch:  45/1000, batch:   112/ 1052, ite: 11600] train loss: 0.009144, tar: 0.000820 
l0: 0.001068, l1: 0.001278, l2: 0.000803, l3: 0.000800, l4: 0.001020, l5: 0.001354, l6: 0.001872

[epoch:  45/1000, batch:   192/ 1052, ite: 11620] train loss: 0.009160, tar: 0.000821 
l0: 0.000358, l1: 0.000364, l2: 0.000385, l3: 0.000677, l4: 0.000746, l5: 0.001156, l6: 0.001058

[epoch:  45/1000, batch:   272/ 1052, ite: 11640] train loss: 0.009145, tar: 0.000819 
l0: 0.000539, l1: 0.000555, l2: 0.000534, l3: 0.000602, l4: 0.000686, l5: 0.001367, l6: 0.002240

[epoch:  45/1000, batch:   352/ 1052, ite: 11660] train loss: 0.009128, tar: 0.000817 
l0: 0.000534, l1: 0.000567, l2: 0.000552, l3: 0.000613, l4: 0.000837, l5: 0.001261, l6: 0.002304

[epoch:  45/1000, batch:   432/ 1052, ite: 11680] train loss: 0.009136, tar: 0.000817 
l0: 0.000426, l1: 0.000442, l2: 0.000572, l3: 0.000605, l4: 0.000662, l5: 0.000765, l6: 0.001729

[epoch:  45/1000, batch:   512/ 1052, ite: 11700] train loss: 0.009175, tar: 0.000821 
l0: 0.000704, l1: 0.000752, l2: 0.000678, l3: 0.000834, l4: 0.000998, l5: 0.001920, l6: 0.002698

[epoch:  45/1000, batch:   592/ 1052, ite: 11720] train loss: 0.009181, tar: 0.000822 
l0: 0.001062, l1: 0.001113, l2: 0.001068, l3: 0.001234, l4: 0.001544, l5: 0.002282, l6: 0.003540

[epoch:  45/1000, batch:   672/ 1052, ite: 11740] train loss: 0.009179, tar: 0.000823 
l0: 0.000897, l1: 0.000895, l2: 0.000874, l3: 0.001098, l4: 0.001377, l5: 0.002015, l6: 0.002376

[epoch:  45/1000, batch:   752/ 1052, ite: 11760] train loss: 0.009155, tar: 0.000820 
l0: 0.000313, l1: 0.000321, l2: 0.000342, l3: 0.000339, l4: 0.000612, l5: 0.000736, l6: 0.001383

[epoch:  45/1000, batch:   832/ 1052, ite: 11780] train loss: 0.009163, tar: 0.000821 
l0: 0.000292, l1: 0.000328, l2: 0.000681, l3: 0.000398, l4: 0.000487, l5: 0.000769, l6: 0.001330

[epoch:  45/1000, batch:   912/ 1052, ite: 11800] train loss: 0.009159, tar: 0.000821 
l0: 0.000452, l1: 0.000484, l2: 0.000508, l3: 0.000525, l4: 0.000575, l5: 0.001019, l6: 0.001606

[epoch:  45/1000, batch:   992/ 1052, ite: 11820] train loss: 0.009164, tar: 0.000821 
[Epoch 45/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000913, l1: 0.000948, l2: 0.000966, l3: 0.001075, l4: 0.001298, l5: 0.001664, l6: 0.002216

[epoch:  46/1000, batch:    20/ 1052, ite: 11840] train loss: 0.009191, tar: 0.000825 
l0: 0.002016, l1: 0.002056, l2: 0.002155, l3: 0.002376, l4: 0.003406, l5: 0.003473, l6: 0.005458

[epoch:  46/1000, batch:   100/ 1052, ite: 11860] train loss: 0.009205, tar: 0.000826 
l0: 0.000664, l1: 0.000614, l2: 0.000731, l3: 0.000790, l4: 0.001481, l5: 0.001812, l6: 0.002506

[epoch:  46/1000, batch:   180/ 1052, ite: 11880] train loss: 0.009198, tar: 0.000825 
l0: 0.002250, l1: 0.002188, l2: 0.002316, l3: 0.002629, l4: 0.003422, l5: 0.004283, l6: 0.007696

[epoch:  46/1000, batch:   260/ 1052, ite: 11900] train loss: 0.009195, tar: 0.000825 
l0: 0.000582, l1: 0.000570, l2: 0.000647, l3: 0.000804, l4: 0.000844, l5: 0.001762, l6: 0.002446

[epoch:  46/1000, batch:   340/ 1052, ite: 11920] train loss: 0.009186, tar: 0.000824 
l0: 0.000428, l1: 0.000430, l2: 0.000406, l3: 0.000438, l4: 0.000661, l5: 0.001068, l6: 0.001416

[epoch:  46/1000, batch:   420/ 1052, ite: 11940] train loss: 0.009159, tar: 0.000822 
l0: 0.000452, l1: 0.000471, l2: 0.000436, l3: 0.000446, l4: 0.000626, l5: 0.000922, l6: 0.001184

[epoch:  46/1000, batch:   500/ 1052, ite: 11960] train loss: 0.009138, tar: 0.000820 
l0: 0.001049, l1: 0.001112, l2: 0.001232, l3: 0.001133, l4: 0.001176, l5: 0.001429, l6: 0.002483

[epoch:  46/1000, batch:   580/ 1052, ite: 11980] train loss: 0.009133, tar: 0.000820 
l0: 0.000597, l1: 0.000626, l2: 0.000578, l3: 0.000650, l4: 0.000856, l5: 0.001511, l6: 0.002472

[epoch:  46/1000, batch:   660/ 1052, ite: 12000] train loss: 0.009132, tar: 0.000819 
l0: 0.001088, l1: 0.001115, l2: 0.001124, l3: 0.001237, l4: 0.001518, l5: 0.002712, l6: 0.003754

[epoch:  46/1000, batch:   740/ 1052, ite: 12020] train loss: 0.009119, tar: 0.000818 
l0: 0.000819, l1: 0.000812, l2: 0.000859, l3: 0.000943, l4: 0.001015, l5: 0.002160, l6: 0.003285

[epoch:  46/1000, batch:   820/ 1052, ite: 12040] train loss: 0.009216, tar: 0.000833 
l0: 0.000539, l1: 0.000529, l2: 0.000650, l3: 0.000683, l4: 0.000975, l5: 0.001344, l6: 0.002799

[epoch:  46/1000, batch:   900/ 1052, ite: 12060] train loss: 0.009198, tar: 0.000831 
l0: 0.000363, l1: 0.000346, l2: 0.000376, l3: 0.000450, l4: 0.000591, l5: 0.001273, l6: 0.002295

[epoch:  46/1000, batch:   980/ 1052, ite: 12080] train loss: 0.009203, tar: 0.000831 
[Epoch 46/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000454, l1: 0.000461, l2: 0.000487, l3: 0.000509, l4: 0.000720, l5: 0.001178, l6: 0.001192

[epoch:  47/1000, batch:     8/ 1052, ite: 12100] train loss: 0.009185, tar: 0.000830 
l0: 0.000506, l1: 0.000501, l2: 0.000604, l3: 0.000609, l4: 0.000711, l5: 0.000963, l6: 0.001871

[epoch:  47/1000, batch:    88/ 1052, ite: 12120] train loss: 0.009186, tar: 0.000829 
l0: 0.000598, l1: 0.000530, l2: 0.000636, l3: 0.000775, l4: 0.000888, l5: 0.001727, l6: 0.002172

[epoch:  47/1000, batch:   168/ 1052, ite: 12140] train loss: 0.009160, tar: 0.000826 
l0: 0.001171, l1: 0.001206, l2: 0.001382, l3: 0.001314, l4: 0.001663, l5: 0.002511, l6: 0.003064

[epoch:  47/1000, batch:   248/ 1052, ite: 12160] train loss: 0.009158, tar: 0.000826 
l0: 0.000487, l1: 0.000498, l2: 0.000496, l3: 0.000490, l4: 0.000638, l5: 0.001299, l6: 0.001871

[epoch:  47/1000, batch:   328/ 1052, ite: 12180] train loss: 0.009196, tar: 0.000830 
l0: 0.000509, l1: 0.000518, l2: 0.000547, l3: 0.000618, l4: 0.000882, l5: 0.001704, l6: 0.002374

[epoch:  47/1000, batch:   408/ 1052, ite: 12200] train loss: 0.009194, tar: 0.000830 
l0: 0.001947, l1: 0.002125, l2: 0.001840, l3: 0.001826, l4: 0.002046, l5: 0.002926, l6: 0.004611

[epoch:  47/1000, batch:   488/ 1052, ite: 12220] train loss: 0.009178, tar: 0.000829 
l0: 0.000757, l1: 0.000702, l2: 0.000720, l3: 0.001039, l4: 0.001320, l5: 0.001967, l6: 0.002857

[epoch:  47/1000, batch:   568/ 1052, ite: 12240] train loss: 0.009163, tar: 0.000828 
l0: 0.000435, l1: 0.000410, l2: 0.000455, l3: 0.000527, l4: 0.000703, l5: 0.001343, l6: 0.001523

[epoch:  47/1000, batch:   648/ 1052, ite: 12260] train loss: 0.009145, tar: 0.000827 
l0: 0.000352, l1: 0.000331, l2: 0.000408, l3: 0.000465, l4: 0.000631, l5: 0.001236, l6: 0.002045

[epoch:  47/1000, batch:   728/ 1052, ite: 12280] train loss: 0.009144, tar: 0.000827 
l0: 0.000489, l1: 0.000546, l2: 0.000518, l3: 0.000630, l4: 0.000582, l5: 0.001391, l6: 0.002730

[epoch:  47/1000, batch:   808/ 1052, ite: 12300] train loss: 0.009141, tar: 0.000827 
l0: 0.000774, l1: 0.000761, l2: 0.000880, l3: 0.000916, l4: 0.001102, l5: 0.001772, l6: 0.002499

[epoch:  47/1000, batch:   888/ 1052, ite: 12320] train loss: 0.009132, tar: 0.000825 
l0: 0.000910, l1: 0.001078, l2: 0.001024, l3: 0.001011, l4: 0.000844, l5: 0.001061, l6: 0.001255

[epoch:  47/1000, batch:   968/ 1052, ite: 12340] train loss: 0.009122, tar: 0.000825 
l0: 0.000813, l1: 0.000770, l2: 0.001296, l3: 0.001221, l4: 0.001108, l5: 0.001247, l6: 0.001752

[epoch:  47/1000, batch:  1048/ 1052, ite: 12360] train loss: 0.009111, tar: 0.000823 
[Epoch 47/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000572, l1: 0.000545, l2: 0.000548, l3: 0.000604, l4: 0.000941, l5: 0.001772, l6: 0.002977

[epoch:  48/1000, batch:    76/ 1052, ite: 12380] train loss: 0.009099, tar: 0.000821 
l0: 0.000592, l1: 0.000665, l2: 0.000539, l3: 0.000685, l4: 0.000841, l5: 0.001486, l6: 0.002420

[epoch:  48/1000, batch:   156/ 1052, ite: 12400] train loss: 0.009082, tar: 0.000819 
l0: 0.000211, l1: 0.000203, l2: 0.000231, l3: 0.000247, l4: 0.000500, l5: 0.000741, l6: 0.001393

[epoch:  48/1000, batch:   236/ 1052, ite: 12420] train loss: 0.009074, tar: 0.000818 
l0: 0.000452, l1: 0.000517, l2: 0.000500, l3: 0.000550, l4: 0.000678, l5: 0.001133, l6: 0.002031

[epoch:  48/1000, batch:   316/ 1052, ite: 12440] train loss: 0.009053, tar: 0.000815 
l0: 0.000271, l1: 0.000282, l2: 0.000302, l3: 0.000298, l4: 0.000564, l5: 0.000839, l6: 0.001799

[epoch:  48/1000, batch:   396/ 1052, ite: 12460] train loss: 0.009085, tar: 0.000820 
l0: 0.000466, l1: 0.000458, l2: 0.000517, l3: 0.000589, l4: 0.000752, l5: 0.001271, l6: 0.002240

[epoch:  48/1000, batch:   476/ 1052, ite: 12480] train loss: 0.009079, tar: 0.000819 
l0: 0.000337, l1: 0.000328, l2: 0.000345, l3: 0.000476, l4: 0.000700, l5: 0.001144, l6: 0.001898

[epoch:  48/1000, batch:   556/ 1052, ite: 12500] train loss: 0.009072, tar: 0.000818 
l0: 0.000978, l1: 0.001097, l2: 0.001040, l3: 0.001086, l4: 0.001022, l5: 0.001758, l6: 0.002335

[epoch:  48/1000, batch:   636/ 1052, ite: 12520] train loss: 0.009086, tar: 0.000819 
l0: 0.000481, l1: 0.000487, l2: 0.000500, l3: 0.000592, l4: 0.000798, l5: 0.001136, l6: 0.001927

[epoch:  48/1000, batch:   716/ 1052, ite: 12540] train loss: 0.009089, tar: 0.000820 
l0: 0.001300, l1: 0.001390, l2: 0.001162, l3: 0.001225, l4: 0.001572, l5: 0.002270, l6: 0.003276

[epoch:  48/1000, batch:   796/ 1052, ite: 12560] train loss: 0.009076, tar: 0.000819 
l0: 0.002929, l1: 0.003153, l2: 0.002948, l3: 0.002856, l4: 0.003278, l5: 0.005659, l6: 0.006938

[epoch:  48/1000, batch:   876/ 1052, ite: 12580] train loss: 0.009080, tar: 0.000819 
l0: 0.000974, l1: 0.001055, l2: 0.000964, l3: 0.001031, l4: 0.001288, l5: 0.001690, l6: 0.003392

[epoch:  48/1000, batch:   956/ 1052, ite: 12600] train loss: 0.009068, tar: 0.000818 
l0: 0.000456, l1: 0.000444, l2: 0.000450, l3: 0.000529, l4: 0.000720, l5: 0.001402, l6: 0.002247

[epoch:  48/1000, batch:  1036/ 1052, ite: 12620] train loss: 0.009065, tar: 0.000818 
[Epoch 48/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.001265, l1: 0.001396, l2: 0.001359, l3: 0.001275, l4: 0.001273, l5: 0.001478, l6: 0.002842

[epoch:  49/1000, batch:    64/ 1052, ite: 12640] train loss: 0.009053, tar: 0.000817 
l0: 0.000824, l1: 0.000814, l2: 0.000831, l3: 0.001152, l4: 0.001249, l5: 0.001124, l6: 0.001706

[epoch:  49/1000, batch:   144/ 1052, ite: 12660] train loss: 0.009050, tar: 0.000817 
l0: 0.000594, l1: 0.000531, l2: 0.000655, l3: 0.000809, l4: 0.001161, l5: 0.002183, l6: 0.002965

[epoch:  49/1000, batch:   224/ 1052, ite: 12680] train loss: 0.009038, tar: 0.000815 
l0: 0.000810, l1: 0.000822, l2: 0.001033, l3: 0.000888, l4: 0.001249, l5: 0.001642, l6: 0.002283

[epoch:  49/1000, batch:   304/ 1052, ite: 12700] train loss: 0.009035, tar: 0.000815 
l0: 0.000700, l1: 0.000710, l2: 0.000830, l3: 0.000845, l4: 0.001086, l5: 0.001404, l6: 0.002347

[epoch:  49/1000, batch:   384/ 1052, ite: 12720] train loss: 0.009038, tar: 0.000815 
l0: 0.001389, l1: 0.001445, l2: 0.001355, l3: 0.001487, l4: 0.001553, l5: 0.002162, l6: 0.004086

[epoch:  49/1000, batch:   464/ 1052, ite: 12740] train loss: 0.009038, tar: 0.000814 
l0: 0.000768, l1: 0.000788, l2: 0.000927, l3: 0.000846, l4: 0.001181, l5: 0.001536, l6: 0.001710

[epoch:  49/1000, batch:   544/ 1052, ite: 12760] train loss: 0.009024, tar: 0.000813 
l0: 0.000632, l1: 0.000643, l2: 0.000726, l3: 0.000770, l4: 0.000946, l5: 0.001284, l6: 0.001841

[epoch:  49/1000, batch:   624/ 1052, ite: 12780] train loss: 0.009001, tar: 0.000811 
l0: 0.000464, l1: 0.000472, l2: 0.000546, l3: 0.000548, l4: 0.000751, l5: 0.001151, l6: 0.002318

[epoch:  49/1000, batch:   704/ 1052, ite: 12800] train loss: 0.009000, tar: 0.000812 
l0: 0.000702, l1: 0.000737, l2: 0.000783, l3: 0.000834, l4: 0.001043, l5: 0.001474, l6: 0.001569

[epoch:  49/1000, batch:   784/ 1052, ite: 12820] train loss: 0.009005, tar: 0.000812 
l0: 0.000287, l1: 0.000301, l2: 0.000287, l3: 0.000307, l4: 0.000471, l5: 0.000608, l6: 0.001460

[epoch:  49/1000, batch:   864/ 1052, ite: 12840] train loss: 0.009008, tar: 0.000812 
l0: 0.000616, l1: 0.000567, l2: 0.000808, l3: 0.001142, l4: 0.001164, l5: 0.001549, l6: 0.001738

[epoch:  49/1000, batch:   944/ 1052, ite: 12860] train loss: 0.009051, tar: 0.000817 
l0: 0.000271, l1: 0.000278, l2: 0.000382, l3: 0.000350, l4: 0.000515, l5: 0.001157, l6: 0.001448

[epoch:  49/1000, batch:  1024/ 1052, ite: 12880] train loss: 0.009046, tar: 0.000816 
[Epoch 49/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000529, l1: 0.000665, l2: 0.000567, l3: 0.000418, l4: 0.000648, l5: 0.001208, l6: 0.001733

[epoch:  50/1000, batch:    52/ 1052, ite: 12900] train loss: 0.009045, tar: 0.000816 
l0: 0.000785, l1: 0.000819, l2: 0.000824, l3: 0.000975, l4: 0.001018, l5: 0.001901, l6: 0.004101

[epoch:  50/1000, batch:   132/ 1052, ite: 12920] train loss: 0.009031, tar: 0.000815 
l0: 0.000707, l1: 0.000760, l2: 0.000764, l3: 0.000941, l4: 0.001341, l5: 0.001675, l6: 0.002485

[epoch:  50/1000, batch:   212/ 1052, ite: 12940] train loss: 0.009028, tar: 0.000814 
l0: 0.000965, l1: 0.000960, l2: 0.000847, l3: 0.000980, l4: 0.001578, l5: 0.002521, l6: 0.003187

[epoch:  50/1000, batch:   292/ 1052, ite: 12960] train loss: 0.009029, tar: 0.000814 
l0: 0.001836, l1: 0.001948, l2: 0.002144, l3: 0.002000, l4: 0.001948, l5: 0.002540, l6: 0.003091

[epoch:  50/1000, batch:   372/ 1052, ite: 12980] train loss: 0.009014, tar: 0.000813 
l0: 0.000605, l1: 0.000600, l2: 0.000550, l3: 0.000679, l4: 0.000839, l5: 0.001283, l6: 0.002528

[epoch:  50/1000, batch:   452/ 1052, ite: 13000] train loss: 0.009006, tar: 0.000812 
l0: 0.000342, l1: 0.000350, l2: 0.000407, l3: 0.000458, l4: 0.000614, l5: 0.000755, l6: 0.000964

[epoch:  50/1000, batch:   532/ 1052, ite: 13020] train loss: 0.008992, tar: 0.000811 
l0: 0.000390, l1: 0.000377, l2: 0.000416, l3: 0.000569, l4: 0.000845, l5: 0.001584, l6: 0.002617

[epoch:  50/1000, batch:   612/ 1052, ite: 13040] train loss: 0.008991, tar: 0.000811 
l0: 0.000655, l1: 0.000667, l2: 0.000812, l3: 0.000829, l4: 0.001108, l5: 0.001273, l6: 0.002915

[epoch:  50/1000, batch:   692/ 1052, ite: 13060] train loss: 0.009027, tar: 0.000814 
l0: 0.000647, l1: 0.000687, l2: 0.000649, l3: 0.000721, l4: 0.000823, l5: 0.001222, l6: 0.002457

[epoch:  50/1000, batch:   772/ 1052, ite: 13080] train loss: 0.009018, tar: 0.000813 
l0: 0.000337, l1: 0.000352, l2: 0.000661, l3: 0.000489, l4: 0.000531, l5: 0.000999, l6: 0.001437

[epoch:  50/1000, batch:   852/ 1052, ite: 13100] train loss: 0.009019, tar: 0.000813 
l0: 0.000452, l1: 0.000516, l2: 0.000382, l3: 0.000437, l4: 0.000555, l5: 0.000759, l6: 0.001150

[epoch:  50/1000, batch:   932/ 1052, ite: 13120] train loss: 0.009008, tar: 0.000812 
l0: 0.000574, l1: 0.000574, l2: 0.002131, l3: 0.001490, l4: 0.001134, l5: 0.001771, l6: 0.002484

[epoch:  50/1000, batch:  1012/ 1052, ite: 13140] train loss: 0.009020, tar: 0.000814 
[Epoch 50/1000] Test loss: 0.013, Test target loss: 0.001
l0: 0.000955, l1: 0.000859, l2: 0.000944, l3: 0.001221, l4: 0.001791, l5: 0.002597, l6: 0.003484

[epoch:  51/1000, batch:    40/ 1052, ite: 13160] train loss: 0.009025, tar: 0.000814 
l0: 0.001073, l1: 0.001156, l2: 0.000800, l3: 0.001025, l4: 0.001158, l5: 0.001687, l6: 0.002323

[epoch:  51/1000, batch:   120/ 1052, ite: 13180] train loss: 0.009031, tar: 0.000815 
l0: 0.000329, l1: 0.000313, l2: 0.000353, l3: 0.000432, l4: 0.000706, l5: 0.001253, l6: 0.001175

[epoch:  51/1000, batch:   200/ 1052, ite: 13200] train loss: 0.009042, tar: 0.000816 
l0: 0.001602, l1: 0.001532, l2: 0.002043, l3: 0.002576, l4: 0.002538, l5: 0.002725, l6: 0.003658

[epoch:  51/1000, batch:   280/ 1052, ite: 13220] train loss: 0.009040, tar: 0.000816 
l0: 0.000484, l1: 0.000475, l2: 0.000510, l3: 0.000518, l4: 0.000777, l5: 0.001563, l6: 0.001802

[epoch:  51/1000, batch:   360/ 1052, ite: 13240] train loss: 0.009037, tar: 0.000815 
l0: 0.001739, l1: 0.001648, l2: 0.002208, l3: 0.003176, l4: 0.003009, l5: 0.004353, l6: 0.006943

[epoch:  51/1000, batch:   440/ 1052, ite: 13260] train loss: 0.009039, tar: 0.000815 
l0: 0.000708, l1: 0.000714, l2: 0.000849, l3: 0.000993, l4: 0.001304, l5: 0.001786, l6: 0.002247

[epoch:  51/1000, batch:   520/ 1052, ite: 13280] train loss: 0.009031, tar: 0.000814 
l0: 0.000487, l1: 0.000489, l2: 0.000546, l3: 0.000592, l4: 0.000698, l5: 0.001019, l6: 0.001607

[epoch:  51/1000, batch:   600/ 1052, ite: 13300] train loss: 0.009029, tar: 0.000814 
l0: 0.000519, l1: 0.000556, l2: 0.000530, l3: 0.000527, l4: 0.000675, l5: 0.001210, l6: 0.001456

[epoch:  51/1000, batch:   680/ 1052, ite: 13320] train loss: 0.009025, tar: 0.000813 
l0: 0.000703, l1: 0.000694, l2: 0.000604, l3: 0.000759, l4: 0.001209, l5: 0.001700, l6: 0.002457

[epoch:  51/1000, batch:   760/ 1052, ite: 13340] train loss: 0.009028, tar: 0.000814 
l0: 0.000832, l1: 0.000825, l2: 0.000896, l3: 0.000980, l4: 0.001063, l5: 0.002058, l6: 0.002742

[epoch:  51/1000, batch:   840/ 1052, ite: 13360] train loss: 0.009014, tar: 0.000813 
l0: 0.000268, l1: 0.000258, l2: 0.000269, l3: 0.000330, l4: 0.000461, l5: 0.000920, l6: 0.001678

[epoch:  51/1000, batch:   920/ 1052, ite: 13380] train loss: 0.009003, tar: 0.000811 
l0: 0.001515, l1: 0.001730, l2: 0.000953, l3: 0.001792, l4: 0.001252, l5: 0.002138, l6: 0.002798

[epoch:  51/1000, batch:  1000/ 1052, ite: 13400] train loss: 0.008996, tar: 0.000811 
[Epoch 51/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000743, l1: 0.000752, l2: 0.000734, l3: 0.001048, l4: 0.001388, l5: 0.002066, l6: 0.002775

[epoch:  52/1000, batch:    28/ 1052, ite: 13420] train loss: 0.009042, tar: 0.000817 
l0: 0.000407, l1: 0.000433, l2: 0.000544, l3: 0.000408, l4: 0.000562, l5: 0.001052, l6: 0.001473

[epoch:  52/1000, batch:   108/ 1052, ite: 13440] train loss: 0.009054, tar: 0.000818 
l0: 0.001085, l1: 0.001115, l2: 0.001132, l3: 0.001247, l4: 0.001388, l5: 0.002154, l6: 0.002926

[epoch:  52/1000, batch:   188/ 1052, ite: 13460] train loss: 0.009045, tar: 0.000817 
l0: 0.000818, l1: 0.000809, l2: 0.000854, l3: 0.000939, l4: 0.001159, l5: 0.001591, l6: 0.002468

[epoch:  52/1000, batch:   268/ 1052, ite: 13480] train loss: 0.009045, tar: 0.000818 
l0: 0.000536, l1: 0.000560, l2: 0.000580, l3: 0.000641, l4: 0.000633, l5: 0.001306, l6: 0.002330

[epoch:  52/1000, batch:   348/ 1052, ite: 13500] train loss: 0.009034, tar: 0.000816 
l0: 0.000312, l1: 0.000322, l2: 0.000381, l3: 0.000359, l4: 0.000537, l5: 0.000685, l6: 0.001394

[epoch:  52/1000, batch:   428/ 1052, ite: 13520] train loss: 0.009037, tar: 0.000817 
l0: 0.000719, l1: 0.000778, l2: 0.000714, l3: 0.000981, l4: 0.001156, l5: 0.001689, l6: 0.001955

[epoch:  52/1000, batch:   508/ 1052, ite: 13540] train loss: 0.009039, tar: 0.000818 
l0: 0.000516, l1: 0.000549, l2: 0.000455, l3: 0.000486, l4: 0.000922, l5: 0.001174, l6: 0.001736

[epoch:  52/1000, batch:   588/ 1052, ite: 13560] train loss: 0.009036, tar: 0.000817 
l0: 0.000378, l1: 0.000399, l2: 0.000354, l3: 0.000447, l4: 0.000572, l5: 0.000978, l6: 0.001171

[epoch:  52/1000, batch:   668/ 1052, ite: 13580] train loss: 0.009036, tar: 0.000818 
l0: 0.000828, l1: 0.000787, l2: 0.000909, l3: 0.000948, l4: 0.001427, l5: 0.001853, l6: 0.001907

[epoch:  52/1000, batch:   748/ 1052, ite: 13600] train loss: 0.009031, tar: 0.000817 
l0: 0.000656, l1: 0.000628, l2: 0.000714, l3: 0.000968, l4: 0.001328, l5: 0.002030, l6: 0.003772

[epoch:  52/1000, batch:   828/ 1052, ite: 13620] train loss: 0.009029, tar: 0.000818 
l0: 0.001538, l1: 0.001340, l2: 0.001794, l3: 0.001831, l4: 0.002300, l5: 0.003451, l6: 0.003424

[epoch:  52/1000, batch:   908/ 1052, ite: 13640] train loss: 0.009027, tar: 0.000817 
l0: 0.000874, l1: 0.000784, l2: 0.001097, l3: 0.001053, l4: 0.002133, l5: 0.001973, l6: 0.002826

[epoch:  52/1000, batch:   988/ 1052, ite: 13660] train loss: 0.009024, tar: 0.000817 
[Epoch 52/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000651, l1: 0.000611, l2: 0.000682, l3: 0.000843, l4: 0.001090, l5: 0.001724, l6: 0.003144

[epoch:  53/1000, batch:    16/ 1052, ite: 13680] train loss: 0.009019, tar: 0.000817 
l0: 0.000505, l1: 0.000537, l2: 0.000555, l3: 0.000695, l4: 0.001205, l5: 0.001426, l6: 0.002460

[epoch:  53/1000, batch:    96/ 1052, ite: 13700] train loss: 0.009014, tar: 0.000816 
l0: 0.000545, l1: 0.000490, l2: 0.000588, l3: 0.000797, l4: 0.001043, l5: 0.001882, l6: 0.003077

[epoch:  53/1000, batch:   176/ 1052, ite: 13720] train loss: 0.009008, tar: 0.000815 
l0: 0.000622, l1: 0.000601, l2: 0.000647, l3: 0.000828, l4: 0.001042, l5: 0.001846, l6: 0.002999

[epoch:  53/1000, batch:   256/ 1052, ite: 13740] train loss: 0.009000, tar: 0.000814 
l0: 0.000381, l1: 0.000394, l2: 0.000386, l3: 0.000493, l4: 0.000602, l5: 0.001177, l6: 0.002145

[epoch:  53/1000, batch:   336/ 1052, ite: 13760] train loss: 0.008994, tar: 0.000814 
l0: 0.000894, l1: 0.000911, l2: 0.000897, l3: 0.000932, l4: 0.001267, l5: 0.002188, l6: 0.003848

[epoch:  53/1000, batch:   416/ 1052, ite: 13780] train loss: 0.008991, tar: 0.000813 
l0: 0.000353, l1: 0.000336, l2: 0.000357, l3: 0.000428, l4: 0.000699, l5: 0.001219, l6: 0.001844

[epoch:  53/1000, batch:   496/ 1052, ite: 13800] train loss: 0.008986, tar: 0.000813 
l0: 0.000666, l1: 0.000676, l2: 0.000673, l3: 0.000833, l4: 0.001287, l5: 0.002023, l6: 0.002499

[epoch:  53/1000, batch:   576/ 1052, ite: 13820] train loss: 0.008985, tar: 0.000813 
l0: 0.000904, l1: 0.000918, l2: 0.001085, l3: 0.001128, l4: 0.001190, l5: 0.002007, l6: 0.003364

[epoch:  53/1000, batch:   656/ 1052, ite: 13840] train loss: 0.009001, tar: 0.000815 
l0: 0.000933, l1: 0.000924, l2: 0.001056, l3: 0.001475, l4: 0.001580, l5: 0.002047, l6: 0.003543

[epoch:  53/1000, batch:   736/ 1052, ite: 13860] train loss: 0.009036, tar: 0.000818 
l0: 0.000311, l1: 0.000285, l2: 0.000359, l3: 0.000516, l4: 0.000508, l5: 0.000730, l6: 0.001494

[epoch:  53/1000, batch:   816/ 1052, ite: 13880] train loss: 0.009034, tar: 0.000818 
l0: 0.000497, l1: 0.000592, l2: 0.000480, l3: 0.000494, l4: 0.000743, l5: 0.000998, l6: 0.002015

[epoch:  53/1000, batch:   896/ 1052, ite: 13900] train loss: 0.009053, tar: 0.000820 
l0: 0.001339, l1: 0.001511, l2: 0.001226, l3: 0.001263, l4: 0.001270, l5: 0.001808, l6: 0.002694

[epoch:  53/1000, batch:   976/ 1052, ite: 13920] train loss: 0.009049, tar: 0.000820 
[Epoch 53/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000375, l1: 0.000390, l2: 0.000449, l3: 0.000548, l4: 0.000686, l5: 0.001130, l6: 0.001285

[epoch:  54/1000, batch:     4/ 1052, ite: 13940] train loss: 0.009043, tar: 0.000819 
l0: 0.000929, l1: 0.000925, l2: 0.000972, l3: 0.001254, l4: 0.001346, l5: 0.001954, l6: 0.003536

[epoch:  54/1000, batch:    84/ 1052, ite: 13960] train loss: 0.009040, tar: 0.000818 
l0: 0.000868, l1: 0.000847, l2: 0.000842, l3: 0.001053, l4: 0.001207, l5: 0.001926, l6: 0.002569

[epoch:  54/1000, batch:   164/ 1052, ite: 13980] train loss: 0.009034, tar: 0.000818 
l0: 0.000468, l1: 0.000496, l2: 0.000531, l3: 0.000556, l4: 0.000677, l5: 0.000763, l6: 0.001502

[epoch:  54/1000, batch:   244/ 1052, ite: 14000] train loss: 0.009030, tar: 0.000817 
l0: 0.000734, l1: 0.000845, l2: 0.000634, l3: 0.000662, l4: 0.000861, l5: 0.001636, l6: 0.002230

[epoch:  54/1000, batch:   324/ 1052, ite: 14020] train loss: 0.009025, tar: 0.000817 
l0: 0.000371, l1: 0.000357, l2: 0.000377, l3: 0.000476, l4: 0.000680, l5: 0.001278, l6: 0.001559

[epoch:  54/1000, batch:   404/ 1052, ite: 14040] train loss: 0.009018, tar: 0.000816 
l0: 0.000696, l1: 0.000648, l2: 0.000956, l3: 0.001205, l4: 0.001328, l5: 0.002345, l6: 0.003409

[epoch:  54/1000, batch:   484/ 1052, ite: 14060] train loss: 0.009015, tar: 0.000815 
l0: 0.000942, l1: 0.000963, l2: 0.000912, l3: 0.001112, l4: 0.001409, l5: 0.002387, l6: 0.003881

[epoch:  54/1000, batch:   564/ 1052, ite: 14080] train loss: 0.009017, tar: 0.000815 
l0: 0.001188, l1: 0.001258, l2: 0.001103, l3: 0.000948, l4: 0.001181, l5: 0.002750, l6: 0.003256

[epoch:  54/1000, batch:   644/ 1052, ite: 14100] train loss: 0.009012, tar: 0.000815 
l0: 0.001229, l1: 0.001270, l2: 0.001186, l3: 0.001600, l4: 0.001735, l5: 0.002280, l6: 0.002594

[epoch:  54/1000, batch:   724/ 1052, ite: 14120] train loss: 0.009014, tar: 0.000815 
l0: 0.000407, l1: 0.000420, l2: 0.000484, l3: 0.000577, l4: 0.000624, l5: 0.001232, l6: 0.001985

[epoch:  54/1000, batch:   804/ 1052, ite: 14140] train loss: 0.009007, tar: 0.000814 
l0: 0.000666, l1: 0.000720, l2: 0.000763, l3: 0.000849, l4: 0.000774, l5: 0.001299, l6: 0.002198

[epoch:  54/1000, batch:   884/ 1052, ite: 14160] train loss: 0.009028, tar: 0.000818 
l0: 0.000371, l1: 0.000419, l2: 0.000495, l3: 0.000499, l4: 0.000617, l5: 0.000917, l6: 0.001550

[epoch:  54/1000, batch:   964/ 1052, ite: 14180] train loss: 0.009024, tar: 0.000817 
l0: 0.000352, l1: 0.000357, l2: 0.000379, l3: 0.000476, l4: 0.000527, l5: 0.000903, l6: 0.001729

[epoch:  54/1000, batch:  1044/ 1052, ite: 14200] train loss: 0.009026, tar: 0.000817 
[Epoch 54/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000717, l1: 0.000710, l2: 0.000834, l3: 0.000704, l4: 0.001022, l5: 0.001444, l6: 0.002263

[epoch:  55/1000, batch:    72/ 1052, ite: 14220] train loss: 0.009014, tar: 0.000816 
l0: 0.001159, l1: 0.001160, l2: 0.001271, l3: 0.001330, l4: 0.001535, l5: 0.002437, l6: 0.003533

[epoch:  55/1000, batch:   152/ 1052, ite: 14240] train loss: 0.009010, tar: 0.000815 
l0: 0.000542, l1: 0.000518, l2: 0.000497, l3: 0.000553, l4: 0.000653, l5: 0.001272, l6: 0.001978

[epoch:  55/1000, batch:   232/ 1052, ite: 14260] train loss: 0.009008, tar: 0.000815 
l0: 0.001301, l1: 0.001257, l2: 0.001506, l3: 0.001628, l4: 0.002170, l5: 0.002901, l6: 0.003730

[epoch:  55/1000, batch:   312/ 1052, ite: 14280] train loss: 0.009000, tar: 0.000814 
l0: 0.000415, l1: 0.000399, l2: 0.000407, l3: 0.000466, l4: 0.000684, l5: 0.001286, l6: 0.002190

[epoch:  55/1000, batch:   392/ 1052, ite: 14300] train loss: 0.008989, tar: 0.000813 
l0: 0.000507, l1: 0.000477, l2: 0.000540, l3: 0.000760, l4: 0.001150, l5: 0.001638, l6: 0.002701

[epoch:  55/1000, batch:   472/ 1052, ite: 14320] train loss: 0.008979, tar: 0.000812 
l0: 0.000606, l1: 0.000626, l2: 0.000611, l3: 0.000614, l4: 0.000875, l5: 0.001551, l6: 0.002370

[epoch:  55/1000, batch:   552/ 1052, ite: 14340] train loss: 0.008971, tar: 0.000811 
l0: 0.000382, l1: 0.000418, l2: 0.000411, l3: 0.000404, l4: 0.000542, l5: 0.000820, l6: 0.001752

[epoch:  55/1000, batch:   632/ 1052, ite: 14360] train loss: 0.008963, tar: 0.000810 
l0: 0.001013, l1: 0.000953, l2: 0.001325, l3: 0.001230, l4: 0.001780, l5: 0.003597, l6: 0.005495

[epoch:  55/1000, batch:   712/ 1052, ite: 14380] train loss: 0.008957, tar: 0.000809 
l0: 0.000422, l1: 0.000419, l2: 0.000600, l3: 0.000605, l4: 0.000752, l5: 0.001439, l6: 0.001831

[epoch:  55/1000, batch:   792/ 1052, ite: 14400] train loss: 0.008971, tar: 0.000811 
l0: 0.000382, l1: 0.000398, l2: 0.000444, l3: 0.000516, l4: 0.000686, l5: 0.001227, l6: 0.001939

[epoch:  55/1000, batch:   872/ 1052, ite: 14420] train loss: 0.008973, tar: 0.000811 
l0: 0.000836, l1: 0.000863, l2: 0.000866, l3: 0.000938, l4: 0.001136, l5: 0.001653, l6: 0.002675

[epoch:  55/1000, batch:   952/ 1052, ite: 14440] train loss: 0.008973, tar: 0.000811 
l0: 0.000817, l1: 0.000873, l2: 0.000971, l3: 0.001107, l4: 0.001311, l5: 0.001982, l6: 0.003392

[epoch:  55/1000, batch:  1032/ 1052, ite: 14460] train loss: 0.008975, tar: 0.000811 
[Epoch 55/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000644, l1: 0.000669, l2: 0.000594, l3: 0.000744, l4: 0.000944, l5: 0.001170, l6: 0.001809

[epoch:  56/1000, batch:    60/ 1052, ite: 14480] train loss: 0.008965, tar: 0.000810 
l0: 0.000531, l1: 0.000549, l2: 0.000545, l3: 0.000756, l4: 0.000819, l5: 0.001767, l6: 0.002371

[epoch:  56/1000, batch:   140/ 1052, ite: 14500] train loss: 0.008967, tar: 0.000810 
l0: 0.000417, l1: 0.000377, l2: 0.000515, l3: 0.000796, l4: 0.000852, l5: 0.001634, l6: 0.002035

[epoch:  56/1000, batch:   220/ 1052, ite: 14520] train loss: 0.008964, tar: 0.000809 
l0: 0.001418, l1: 0.001609, l2: 0.001352, l3: 0.001535, l4: 0.001717, l5: 0.001941, l6: 0.003608

[epoch:  56/1000, batch:   300/ 1052, ite: 14540] train loss: 0.008964, tar: 0.000809 
l0: 0.000315, l1: 0.000301, l2: 0.000356, l3: 0.000393, l4: 0.000558, l5: 0.000964, l6: 0.001346

[epoch:  56/1000, batch:   380/ 1052, ite: 14560] train loss: 0.008953, tar: 0.000808 
l0: 0.000957, l1: 0.001161, l2: 0.001106, l3: 0.001117, l4: 0.001213, l5: 0.001225, l6: 0.001833

[epoch:  56/1000, batch:   460/ 1052, ite: 14580] train loss: 0.008957, tar: 0.000809 
l0: 0.000744, l1: 0.000698, l2: 0.000758, l3: 0.001091, l4: 0.001217, l5: 0.001213, l6: 0.001936

[epoch:  56/1000, batch:   540/ 1052, ite: 14600] train loss: 0.008954, tar: 0.000809 
l0: 0.000587, l1: 0.000599, l2: 0.000611, l3: 0.000875, l4: 0.001048, l5: 0.001316, l6: 0.001997

[epoch:  56/1000, batch:   620/ 1052, ite: 14620] train loss: 0.008991, tar: 0.000814 
l0: 0.000856, l1: 0.000873, l2: 0.000904, l3: 0.001091, l4: 0.001213, l5: 0.001856, l6: 0.003090

[epoch:  56/1000, batch:   700/ 1052, ite: 14640] train loss: 0.008992, tar: 0.000814 
l0: 0.000308, l1: 0.000312, l2: 0.000301, l3: 0.000350, l4: 0.000585, l5: 0.001027, l6: 0.001478

[epoch:  56/1000, batch:   780/ 1052, ite: 14660] train loss: 0.008984, tar: 0.000813 
l0: 0.000355, l1: 0.000340, l2: 0.000363, l3: 0.000386, l4: 0.000699, l5: 0.001341, l6: 0.001913

[epoch:  56/1000, batch:   860/ 1052, ite: 14680] train loss: 0.008984, tar: 0.000813 
l0: 0.000339, l1: 0.000361, l2: 0.000366, l3: 0.000412, l4: 0.000518, l5: 0.000635, l6: 0.001784

[epoch:  56/1000, batch:   940/ 1052, ite: 14700] train loss: 0.008976, tar: 0.000812 
l0: 0.000916, l1: 0.000882, l2: 0.001141, l3: 0.001164, l4: 0.000937, l5: 0.001618, l6: 0.003473

[epoch:  56/1000, batch:  1020/ 1052, ite: 14720] train loss: 0.008976, tar: 0.000812 
[Epoch 56/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000810, l1: 0.000797, l2: 0.000980, l3: 0.001270, l4: 0.001510, l5: 0.001800, l6: 0.002564

[epoch:  57/1000, batch:    48/ 1052, ite: 14740] train loss: 0.008972, tar: 0.000811 
l0: 0.000413, l1: 0.000422, l2: 0.000401, l3: 0.000393, l4: 0.000476, l5: 0.000785, l6: 0.001277

[epoch:  57/1000, batch:   128/ 1052, ite: 14760] train loss: 0.008970, tar: 0.000811 
l0: 0.000335, l1: 0.000303, l2: 0.000400, l3: 0.000500, l4: 0.000634, l5: 0.001287, l6: 0.001612

[epoch:  57/1000, batch:   208/ 1052, ite: 14780] train loss: 0.008961, tar: 0.000810 
l0: 0.000593, l1: 0.000580, l2: 0.000601, l3: 0.000663, l4: 0.000908, l5: 0.001506, l6: 0.003041

[epoch:  57/1000, batch:   288/ 1052, ite: 14800] train loss: 0.008959, tar: 0.000809 
l0: 0.000365, l1: 0.000360, l2: 0.000404, l3: 0.000460, l4: 0.000727, l5: 0.001035, l6: 0.002054

[epoch:  57/1000, batch:   368/ 1052, ite: 14820] train loss: 0.008952, tar: 0.000809 
l0: 0.000747, l1: 0.000796, l2: 0.000894, l3: 0.000877, l4: 0.001054, l5: 0.001786, l6: 0.002499

[epoch:  57/1000, batch:   448/ 1052, ite: 14840] train loss: 0.008967, tar: 0.000810 
l0: 0.000775, l1: 0.000801, l2: 0.000806, l3: 0.000860, l4: 0.001027, l5: 0.001381, l6: 0.002547

[epoch:  57/1000, batch:   528/ 1052, ite: 14860] train loss: 0.008965, tar: 0.000810 
l0: 0.000226, l1: 0.000236, l2: 0.000233, l3: 0.000272, l4: 0.000404, l5: 0.000721, l6: 0.000909

[epoch:  57/1000, batch:   608/ 1052, ite: 14880] train loss: 0.008956, tar: 0.000809 
l0: 0.000480, l1: 0.000475, l2: 0.000538, l3: 0.000487, l4: 0.000679, l5: 0.001019, l6: 0.001219

[epoch:  57/1000, batch:   688/ 1052, ite: 14900] train loss: 0.008952, tar: 0.000809 
l0: 0.002297, l1: 0.002367, l2: 0.002412, l3: 0.002788, l4: 0.003291, l5: 0.003311, l6: 0.004320

[epoch:  57/1000, batch:   768/ 1052, ite: 14920] train loss: 0.008949, tar: 0.000808 
l0: 0.000591, l1: 0.000581, l2: 0.000648, l3: 0.000642, l4: 0.000789, l5: 0.001896, l6: 0.002238

[epoch:  57/1000, batch:   848/ 1052, ite: 14940] train loss: 0.008943, tar: 0.000808 
l0: 0.000504, l1: 0.000663, l2: 0.000478, l3: 0.000533, l4: 0.000695, l5: 0.001467, l6: 0.002290

[epoch:  57/1000, batch:   928/ 1052, ite: 14960] train loss: 0.008940, tar: 0.000808 
l0: 0.000561, l1: 0.000549, l2: 0.000600, l3: 0.000658, l4: 0.001130, l5: 0.001965, l6: 0.002734

[epoch:  57/1000, batch:  1008/ 1052, ite: 14980] train loss: 0.008932, tar: 0.000807 
[Epoch 57/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000474, l1: 0.000465, l2: 0.000468, l3: 0.000496, l4: 0.000756, l5: 0.000849, l6: 0.002119

[epoch:  58/1000, batch:    36/ 1052, ite: 15000] train loss: 0.008927, tar: 0.000806 
l0: 0.000702, l1: 0.000727, l2: 0.000887, l3: 0.000888, l4: 0.001160, l5: 0.001925, l6: 0.003179

[epoch:  58/1000, batch:   116/ 1052, ite: 15020] train loss: 0.008922, tar: 0.000806 
l0: 0.000606, l1: 0.000604, l2: 0.000629, l3: 0.000688, l4: 0.000935, l5: 0.001680, l6: 0.001579

[epoch:  58/1000, batch:   196/ 1052, ite: 15040] train loss: 0.008923, tar: 0.000806 
l0: 0.000368, l1: 0.000374, l2: 0.000392, l3: 0.000490, l4: 0.000595, l5: 0.000894, l6: 0.001553

[epoch:  58/1000, batch:   276/ 1052, ite: 15060] train loss: 0.008917, tar: 0.000805 
l0: 0.000868, l1: 0.000818, l2: 0.000836, l3: 0.000904, l4: 0.001357, l5: 0.001991, l6: 0.003078

[epoch:  58/1000, batch:   356/ 1052, ite: 15080] train loss: 0.008927, tar: 0.000806 
l0: 0.000847, l1: 0.000868, l2: 0.000926, l3: 0.000794, l4: 0.001111, l5: 0.002104, l6: 0.002553

[epoch:  58/1000, batch:   436/ 1052, ite: 15100] train loss: 0.008924, tar: 0.000806 
l0: 0.000383, l1: 0.000386, l2: 0.000368, l3: 0.000382, l4: 0.000691, l5: 0.001325, l6: 0.001568

[epoch:  58/1000, batch:   516/ 1052, ite: 15120] train loss: 0.008921, tar: 0.000805 
l0: 0.000357, l1: 0.000333, l2: 0.000361, l3: 0.000427, l4: 0.000671, l5: 0.000952, l6: 0.001822

[epoch:  58/1000, batch:   596/ 1052, ite: 15140] train loss: 0.008915, tar: 0.000805 
l0: 0.000851, l1: 0.000774, l2: 0.000859, l3: 0.000993, l4: 0.001311, l5: 0.001930, l6: 0.003434

[epoch:  58/1000, batch:   676/ 1052, ite: 15160] train loss: 0.008910, tar: 0.000804 
l0: 0.000263, l1: 0.000244, l2: 0.000297, l3: 0.000364, l4: 0.000544, l5: 0.000570, l6: 0.001016

[epoch:  58/1000, batch:   756/ 1052, ite: 15180] train loss: 0.008904, tar: 0.000803 
l0: 0.000604, l1: 0.000910, l2: 0.000596, l3: 0.000926, l4: 0.001026, l5: 0.001466, l6: 0.002394

[epoch:  58/1000, batch:   836/ 1052, ite: 15200] train loss: 0.008903, tar: 0.000803 
l0: 0.000628, l1: 0.000661, l2: 0.000683, l3: 0.000595, l4: 0.000602, l5: 0.001003, l6: 0.001149

[epoch:  58/1000, batch:   916/ 1052, ite: 15220] train loss: 0.008900, tar: 0.000803 
l0: 0.000438, l1: 0.000461, l2: 0.000448, l3: 0.000430, l4: 0.000588, l5: 0.000673, l6: 0.001216

[epoch:  58/1000, batch:   996/ 1052, ite: 15240] train loss: 0.008893, tar: 0.000802 
[Epoch 58/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000738, l1: 0.000710, l2: 0.000693, l3: 0.000698, l4: 0.000996, l5: 0.001979, l6: 0.002778

[epoch:  59/1000, batch:    24/ 1052, ite: 15260] train loss: 0.008888, tar: 0.000802 
l0: 0.000251, l1: 0.000247, l2: 0.000281, l3: 0.000410, l4: 0.000523, l5: 0.000837, l6: 0.001023

[epoch:  59/1000, batch:   104/ 1052, ite: 15280] train loss: 0.008887, tar: 0.000801 
l0: 0.000312, l1: 0.000313, l2: 0.000317, l3: 0.000338, l4: 0.000559, l5: 0.001120, l6: 0.002301

[epoch:  59/1000, batch:   184/ 1052, ite: 15300] train loss: 0.008882, tar: 0.000800 
l0: 0.000414, l1: 0.000423, l2: 0.000496, l3: 0.000549, l4: 0.000778, l5: 0.001403, l6: 0.002362

[epoch:  59/1000, batch:   264/ 1052, ite: 15320] train loss: 0.008881, tar: 0.000800 
l0: 0.000447, l1: 0.000460, l2: 0.000479, l3: 0.000520, l4: 0.000721, l5: 0.001044, l6: 0.002400

[epoch:  59/1000, batch:   344/ 1052, ite: 15340] train loss: 0.008878, tar: 0.000800 
l0: 0.000774, l1: 0.000787, l2: 0.000818, l3: 0.000866, l4: 0.001091, l5: 0.001901, l6: 0.003830

[epoch:  59/1000, batch:   424/ 1052, ite: 15360] train loss: 0.008878, tar: 0.000800 
l0: 0.001183, l1: 0.001148, l2: 0.001211, l3: 0.001516, l4: 0.002500, l5: 0.002805, l6: 0.006086

[epoch:  59/1000, batch:   504/ 1052, ite: 15380] train loss: 0.008878, tar: 0.000800 
l0: 0.000738, l1: 0.000767, l2: 0.000835, l3: 0.000762, l4: 0.000961, l5: 0.001460, l6: 0.002336

[epoch:  59/1000, batch:   584/ 1052, ite: 15400] train loss: 0.008874, tar: 0.000800 
l0: 0.000589, l1: 0.000587, l2: 0.000612, l3: 0.000705, l4: 0.000982, l5: 0.001742, l6: 0.002742

[epoch:  59/1000, batch:   664/ 1052, ite: 15420] train loss: 0.008866, tar: 0.000798 
l0: 0.000734, l1: 0.000722, l2: 0.000851, l3: 0.000924, l4: 0.001054, l5: 0.001705, l6: 0.002722

[epoch:  59/1000, batch:   744/ 1052, ite: 15440] train loss: 0.008865, tar: 0.000799 
l0: 0.000292, l1: 0.000303, l2: 0.000294, l3: 0.000330, l4: 0.000619, l5: 0.001081, l6: 0.001529

[epoch:  59/1000, batch:   824/ 1052, ite: 15460] train loss: 0.008859, tar: 0.000798 
l0: 0.001001, l1: 0.001032, l2: 0.000937, l3: 0.000957, l4: 0.000943, l5: 0.002054, l6: 0.002136

[epoch:  59/1000, batch:   904/ 1052, ite: 15480] train loss: 0.008872, tar: 0.000800 
l0: 0.000237, l1: 0.000241, l2: 0.000287, l3: 0.000338, l4: 0.000522, l5: 0.000629, l6: 0.001712

[epoch:  59/1000, batch:   984/ 1052, ite: 15500] train loss: 0.008864, tar: 0.000799 
[Epoch 59/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000682, l1: 0.000792, l2: 0.000712, l3: 0.000546, l4: 0.000733, l5: 0.000875, l6: 0.001579

[epoch:  60/1000, batch:    12/ 1052, ite: 15520] train loss: 0.008860, tar: 0.000798 
l0: 0.000686, l1: 0.000666, l2: 0.000609, l3: 0.000782, l4: 0.001172, l5: 0.002166, l6: 0.002584

[epoch:  60/1000, batch:    92/ 1052, ite: 15540] train loss: 0.008860, tar: 0.000799 
l0: 0.000721, l1: 0.000765, l2: 0.000686, l3: 0.000811, l4: 0.000984, l5: 0.001893, l6: 0.002165

[epoch:  60/1000, batch:   172/ 1052, ite: 15560] train loss: 0.008862, tar: 0.000799 
l0: 0.000560, l1: 0.000573, l2: 0.000568, l3: 0.000591, l4: 0.000866, l5: 0.001366, l6: 0.001895

[epoch:  60/1000, batch:   252/ 1052, ite: 15580] train loss: 0.008857, tar: 0.000799 
l0: 0.000400, l1: 0.000376, l2: 0.000478, l3: 0.000652, l4: 0.000784, l5: 0.001241, l6: 0.001802

[epoch:  60/1000, batch:   332/ 1052, ite: 15600] train loss: 0.008872, tar: 0.000800 
l0: 0.000556, l1: 0.000597, l2: 0.000540, l3: 0.000558, l4: 0.000862, l5: 0.001446, l6: 0.001882

[epoch:  60/1000, batch:   412/ 1052, ite: 15620] train loss: 0.008871, tar: 0.000800 
l0: 0.000678, l1: 0.000657, l2: 0.000633, l3: 0.000641, l4: 0.000840, l5: 0.001236, l6: 0.001840

[epoch:  60/1000, batch:   492/ 1052, ite: 15640] train loss: 0.008874, tar: 0.000801 
l0: 0.000254, l1: 0.000252, l2: 0.000268, l3: 0.000407, l4: 0.000560, l5: 0.000725, l6: 0.001058

[epoch:  60/1000, batch:   572/ 1052, ite: 15660] train loss: 0.008867, tar: 0.000800 
l0: 0.001201, l1: 0.001243, l2: 0.001226, l3: 0.001150, l4: 0.001592, l5: 0.002193, l6: 0.002923

[epoch:  60/1000, batch:   652/ 1052, ite: 15680] train loss: 0.008859, tar: 0.000799 
l0: 0.000484, l1: 0.000573, l2: 0.000519, l3: 0.000506, l4: 0.000480, l5: 0.000864, l6: 0.001290

[epoch:  60/1000, batch:   732/ 1052, ite: 15700] train loss: 0.008854, tar: 0.000798 
l0: 0.000491, l1: 0.000483, l2: 0.000504, l3: 0.000676, l4: 0.000804, l5: 0.001194, l6: 0.001723

[epoch:  60/1000, batch:   812/ 1052, ite: 15720] train loss: 0.008850, tar: 0.000798 
l0: 0.000626, l1: 0.000624, l2: 0.000750, l3: 0.000803, l4: 0.000972, l5: 0.001296, l6: 0.002816

[epoch:  60/1000, batch:   892/ 1052, ite: 15740] train loss: 0.008843, tar: 0.000797 
l0: 0.000520, l1: 0.000581, l2: 0.000490, l3: 0.000469, l4: 0.000441, l5: 0.000707, l6: 0.000875

[epoch:  60/1000, batch:   972/ 1052, ite: 15760] train loss: 0.008836, tar: 0.000796 
l0: 0.001318, l1: 0.001365, l2: 0.001318, l3: 0.001399, l4: 0.001780, l5: 0.001925, l6: 0.003184

[epoch:  60/1000, batch:  1052/ 1052, ite: 15780] train loss: 0.008831, tar: 0.000796 
[Epoch 60/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000306, l1: 0.000311, l2: 0.000289, l3: 0.000398, l4: 0.000524, l5: 0.000924, l6: 0.001967

[epoch:  61/1000, batch:    80/ 1052, ite: 15800] train loss: 0.008821, tar: 0.000794 
l0: 0.000387, l1: 0.000383, l2: 0.000407, l3: 0.000459, l4: 0.000659, l5: 0.001112, l6: 0.001382

[epoch:  61/1000, batch:   160/ 1052, ite: 15820] train loss: 0.008818, tar: 0.000794 
l0: 0.000353, l1: 0.000353, l2: 0.000372, l3: 0.000442, l4: 0.000592, l5: 0.000957, l6: 0.001991

[epoch:  61/1000, batch:   240/ 1052, ite: 15840] train loss: 0.008824, tar: 0.000795 
l0: 0.000463, l1: 0.000531, l2: 0.000495, l3: 0.000559, l4: 0.000752, l5: 0.001364, l6: 0.002180

[epoch:  61/1000, batch:   320/ 1052, ite: 15860] train loss: 0.008819, tar: 0.000794 
l0: 0.001264, l1: 0.001178, l2: 0.001631, l3: 0.001571, l4: 0.001494, l5: 0.001910, l6: 0.001813

[epoch:  61/1000, batch:   400/ 1052, ite: 15880] train loss: 0.008819, tar: 0.000795 
l0: 0.000458, l1: 0.000536, l2: 0.000475, l3: 0.000426, l4: 0.000610, l5: 0.000791, l6: 0.001499

[epoch:  61/1000, batch:   480/ 1052, ite: 15900] train loss: 0.008817, tar: 0.000794 
l0: 0.000513, l1: 0.000673, l2: 0.000484, l3: 0.000531, l4: 0.000694, l5: 0.000889, l6: 0.001480

[epoch:  61/1000, batch:   560/ 1052, ite: 15920] train loss: 0.008813, tar: 0.000794 
l0: 0.000578, l1: 0.000582, l2: 0.000557, l3: 0.000713, l4: 0.000916, l5: 0.001122, l6: 0.002274

[epoch:  61/1000, batch:   640/ 1052, ite: 15940] train loss: 0.008808, tar: 0.000793 
l0: 0.001007, l1: 0.000990, l2: 0.000926, l3: 0.001154, l4: 0.001253, l5: 0.001595, l6: 0.002682

[epoch:  61/1000, batch:   720/ 1052, ite: 15960] train loss: 0.008808, tar: 0.000793 
l0: 0.001432, l1: 0.001339, l2: 0.001542, l3: 0.001738, l4: 0.002029, l5: 0.003712, l6: 0.004687

[epoch:  61/1000, batch:   800/ 1052, ite: 15980] train loss: 0.008814, tar: 0.000794 
l0: 0.000452, l1: 0.000456, l2: 0.000478, l3: 0.000585, l4: 0.000785, l5: 0.001057, l6: 0.001731

[epoch:  61/1000, batch:   880/ 1052, ite: 16000] train loss: 0.008815, tar: 0.000794 
l0: 0.000666, l1: 0.000624, l2: 0.000757, l3: 0.000834, l4: 0.001151, l5: 0.001469, l6: 0.003161

[epoch:  61/1000, batch:   960/ 1052, ite: 16020] train loss: 0.008812, tar: 0.000793 
l0: 0.000832, l1: 0.000786, l2: 0.000814, l3: 0.000986, l4: 0.001248, l5: 0.001517, l6: 0.002259

[epoch:  61/1000, batch:  1040/ 1052, ite: 16040] train loss: 0.008810, tar: 0.000793 
[Epoch 61/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000498, l1: 0.000511, l2: 0.000503, l3: 0.000615, l4: 0.000826, l5: 0.000926, l6: 0.001241

[epoch:  62/1000, batch:    68/ 1052, ite: 16060] train loss: 0.008803, tar: 0.000793 
l0: 0.000323, l1: 0.000330, l2: 0.000341, l3: 0.000389, l4: 0.000421, l5: 0.000885, l6: 0.001438

[epoch:  62/1000, batch:   148/ 1052, ite: 16080] train loss: 0.008802, tar: 0.000792 
l0: 0.000265, l1: 0.000259, l2: 0.000246, l3: 0.000302, l4: 0.000448, l5: 0.000703, l6: 0.001434

[epoch:  62/1000, batch:   228/ 1052, ite: 16100] train loss: 0.008799, tar: 0.000792 
l0: 0.001824, l1: 0.001914, l2: 0.001836, l3: 0.002092, l4: 0.002079, l5: 0.002404, l6: 0.003678

[epoch:  62/1000, batch:   308/ 1052, ite: 16120] train loss: 0.008795, tar: 0.000792 
l0: 0.001377, l1: 0.001463, l2: 0.001547, l3: 0.001445, l4: 0.001580, l5: 0.001363, l6: 0.002065

[epoch:  62/1000, batch:   388/ 1052, ite: 16140] train loss: 0.008793, tar: 0.000792 
l0: 0.000416, l1: 0.000423, l2: 0.000441, l3: 0.000533, l4: 0.000629, l5: 0.001046, l6: 0.001641

[epoch:  62/1000, batch:   468/ 1052, ite: 16160] train loss: 0.008788, tar: 0.000791 
l0: 0.000598, l1: 0.000622, l2: 0.000571, l3: 0.000570, l4: 0.000944, l5: 0.001226, l6: 0.002561

[epoch:  62/1000, batch:   548/ 1052, ite: 16180] train loss: 0.008781, tar: 0.000790 
l0: 0.000702, l1: 0.000715, l2: 0.000583, l3: 0.000784, l4: 0.000985, l5: 0.001468, l6: 0.002202

[epoch:  62/1000, batch:   628/ 1052, ite: 16200] train loss: 0.008781, tar: 0.000790 
l0: 0.000378, l1: 0.000371, l2: 0.000452, l3: 0.000440, l4: 0.000552, l5: 0.000964, l6: 0.001459

[epoch:  62/1000, batch:   708/ 1052, ite: 16220] train loss: 0.008775, tar: 0.000790 
l0: 0.000393, l1: 0.000402, l2: 0.000426, l3: 0.000511, l4: 0.000665, l5: 0.001183, l6: 0.001372

[epoch:  62/1000, batch:   788/ 1052, ite: 16240] train loss: 0.008774, tar: 0.000789 
l0: 0.000543, l1: 0.000590, l2: 0.000563, l3: 0.000596, l4: 0.001126, l5: 0.001654, l6: 0.002228

[epoch:  62/1000, batch:   868/ 1052, ite: 16260] train loss: 0.008766, tar: 0.000788 
l0: 0.000390, l1: 0.000386, l2: 0.000408, l3: 0.000444, l4: 0.000703, l5: 0.001217, l6: 0.002211

[epoch:  62/1000, batch:   948/ 1052, ite: 16280] train loss: 0.008760, tar: 0.000788 
l0: 0.000584, l1: 0.000692, l2: 0.001099, l3: 0.001150, l4: 0.000752, l5: 0.001015, l6: 0.002049

[epoch:  62/1000, batch:  1028/ 1052, ite: 16300] train loss: 0.008768, tar: 0.000789 
[Epoch 62/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000831, l1: 0.000918, l2: 0.000751, l3: 0.000948, l4: 0.001132, l5: 0.002047, l6: 0.003123

[epoch:  63/1000, batch:    56/ 1052, ite: 16320] train loss: 0.008774, tar: 0.000789 
l0: 0.000599, l1: 0.000544, l2: 0.000633, l3: 0.001052, l4: 0.001734, l5: 0.002115, l6: 0.002706

[epoch:  63/1000, batch:   136/ 1052, ite: 16340] train loss: 0.008784, tar: 0.000790 
l0: 0.000341, l1: 0.000364, l2: 0.000319, l3: 0.000362, l4: 0.000507, l5: 0.000798, l6: 0.001604

[epoch:  63/1000, batch:   216/ 1052, ite: 16360] train loss: 0.008782, tar: 0.000789 
l0: 0.000442, l1: 0.000468, l2: 0.000480, l3: 0.000519, l4: 0.000745, l5: 0.001420, l6: 0.001296

[epoch:  63/1000, batch:   296/ 1052, ite: 16380] train loss: 0.008782, tar: 0.000789 
l0: 0.000393, l1: 0.000396, l2: 0.000451, l3: 0.000560, l4: 0.000735, l5: 0.001348, l6: 0.001834

[epoch:  63/1000, batch:   376/ 1052, ite: 16400] train loss: 0.008778, tar: 0.000789 
l0: 0.000851, l1: 0.000876, l2: 0.000857, l3: 0.001059, l4: 0.001181, l5: 0.001897, l6: 0.002595

[epoch:  63/1000, batch:   456/ 1052, ite: 16420] train loss: 0.008776, tar: 0.000789 
l0: 0.000459, l1: 0.000445, l2: 0.000523, l3: 0.000593, l4: 0.000811, l5: 0.000914, l6: 0.001694

[epoch:  63/1000, batch:   536/ 1052, ite: 16440] train loss: 0.008771, tar: 0.000788 
l0: 0.001371, l1: 0.001330, l2: 0.001370, l3: 0.001429, l4: 0.002080, l5: 0.003470, l6: 0.003764

[epoch:  63/1000, batch:   616/ 1052, ite: 16460] train loss: 0.008767, tar: 0.000788 
l0: 0.000428, l1: 0.000414, l2: 0.000419, l3: 0.000534, l4: 0.000885, l5: 0.001568, l6: 0.002555

[epoch:  63/1000, batch:   696/ 1052, ite: 16480] train loss: 0.008759, tar: 0.000787 
l0: 0.000883, l1: 0.000938, l2: 0.000912, l3: 0.000886, l4: 0.000872, l5: 0.001339, l6: 0.002677

[epoch:  63/1000, batch:   776/ 1052, ite: 16500] train loss: 0.008755, tar: 0.000787 
l0: 0.000861, l1: 0.000852, l2: 0.000939, l3: 0.001034, l4: 0.001266, l5: 0.001936, l6: 0.002652

[epoch:  63/1000, batch:   856/ 1052, ite: 16520] train loss: 0.008753, tar: 0.000786 
l0: 0.001237, l1: 0.001311, l2: 0.001545, l3: 0.001230, l4: 0.001734, l5: 0.002400, l6: 0.002774

[epoch:  63/1000, batch:   936/ 1052, ite: 16540] train loss: 0.008752, tar: 0.000786 
l0: 0.000569, l1: 0.000536, l2: 0.000567, l3: 0.000678, l4: 0.000937, l5: 0.001236, l6: 0.002367

[epoch:  63/1000, batch:  1016/ 1052, ite: 16560] train loss: 0.008747, tar: 0.000786 
[Epoch 63/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000579, l1: 0.000582, l2: 0.000575, l3: 0.000671, l4: 0.000765, l5: 0.001225, l6: 0.002701

[epoch:  64/1000, batch:    44/ 1052, ite: 16580] train loss: 0.008743, tar: 0.000785 
l0: 0.000509, l1: 0.000492, l2: 0.000485, l3: 0.000539, l4: 0.001002, l5: 0.001278, l6: 0.002407

[epoch:  64/1000, batch:   124/ 1052, ite: 16600] train loss: 0.008739, tar: 0.000785 
l0: 0.000336, l1: 0.000340, l2: 0.000414, l3: 0.000366, l4: 0.000487, l5: 0.000753, l6: 0.001527

[epoch:  64/1000, batch:   204/ 1052, ite: 16620] train loss: 0.008733, tar: 0.000784 
l0: 0.000876, l1: 0.000858, l2: 0.000881, l3: 0.001045, l4: 0.001109, l5: 0.001414, l6: 0.001824

[epoch:  64/1000, batch:   284/ 1052, ite: 16640] train loss: 0.008733, tar: 0.000784 
l0: 0.000847, l1: 0.000921, l2: 0.000973, l3: 0.000930, l4: 0.001117, l5: 0.001740, l6: 0.002800

[epoch:  64/1000, batch:   364/ 1052, ite: 16660] train loss: 0.008730, tar: 0.000784 
l0: 0.000409, l1: 0.000409, l2: 0.000464, l3: 0.000749, l4: 0.000425, l5: 0.000899, l6: 0.001539

[epoch:  64/1000, batch:   444/ 1052, ite: 16680] train loss: 0.008723, tar: 0.000783 
l0: 0.000518, l1: 0.000521, l2: 0.000556, l3: 0.000587, l4: 0.000883, l5: 0.001456, l6: 0.002253

[epoch:  64/1000, batch:   524/ 1052, ite: 16700] train loss: 0.008717, tar: 0.000783 
l0: 0.001354, l1: 0.001486, l2: 0.001420, l3: 0.001330, l4: 0.001626, l5: 0.002170, l6: 0.003538

[epoch:  64/1000, batch:   604/ 1052, ite: 16720] train loss: 0.008717, tar: 0.000782 
l0: 0.000410, l1: 0.000406, l2: 0.000421, l3: 0.000473, l4: 0.000723, l5: 0.001550, l6: 0.001738

[epoch:  64/1000, batch:   684/ 1052, ite: 16740] train loss: 0.008712, tar: 0.000782 
l0: 0.000799, l1: 0.000802, l2: 0.000857, l3: 0.001182, l4: 0.001446, l5: 0.002076, l6: 0.003506

[epoch:  64/1000, batch:   764/ 1052, ite: 16760] train loss: 0.008705, tar: 0.000781 
l0: 0.003448, l1: 0.003356, l2: 0.003862, l3: 0.005429, l4: 0.002105, l5: 0.003520, l6: 0.003958

[epoch:  64/1000, batch:   844/ 1052, ite: 16780] train loss: 0.008704, tar: 0.000781 
l0: 0.000633, l1: 0.000620, l2: 0.000592, l3: 0.000661, l4: 0.001363, l5: 0.001783, l6: 0.002591

[epoch:  64/1000, batch:   924/ 1052, ite: 16800] train loss: 0.008699, tar: 0.000780 
l0: 0.000341, l1: 0.000410, l2: 0.000456, l3: 0.000385, l4: 0.000516, l5: 0.001416, l6: 0.001192

[epoch:  64/1000, batch:  1004/ 1052, ite: 16820] train loss: 0.008713, tar: 0.000782 
[Epoch 64/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.001396, l1: 0.001701, l2: 0.001385, l3: 0.001379, l4: 0.001458, l5: 0.001682, l6: 0.003083

[epoch:  65/1000, batch:    32/ 1052, ite: 16840] train loss: 0.008718, tar: 0.000782 
l0: 0.000819, l1: 0.000885, l2: 0.000782, l3: 0.000819, l4: 0.001069, l5: 0.001471, l6: 0.001919

[epoch:  65/1000, batch:   112/ 1052, ite: 16860] train loss: 0.008721, tar: 0.000783 
l0: 0.002149, l1: 0.002577, l2: 0.002251, l3: 0.002060, l4: 0.002459, l5: 0.003541, l6: 0.005224

[epoch:  65/1000, batch:   192/ 1052, ite: 16880] train loss: 0.008724, tar: 0.000783 
l0: 0.000411, l1: 0.000440, l2: 0.000493, l3: 0.000468, l4: 0.000537, l5: 0.000956, l6: 0.001237

[epoch:  65/1000, batch:   272/ 1052, ite: 16900] train loss: 0.008723, tar: 0.000783 
l0: 0.000500, l1: 0.000516, l2: 0.000514, l3: 0.000625, l4: 0.000740, l5: 0.001156, l6: 0.002204

[epoch:  65/1000, batch:   352/ 1052, ite: 16920] train loss: 0.008719, tar: 0.000782 
l0: 0.000607, l1: 0.000620, l2: 0.000719, l3: 0.000935, l4: 0.001188, l5: 0.001524, l6: 0.002978

[epoch:  65/1000, batch:   432/ 1052, ite: 16940] train loss: 0.008720, tar: 0.000782 
l0: 0.002411, l1: 0.002780, l2: 0.002091, l3: 0.001836, l4: 0.001794, l5: 0.002994, l6: 0.004815

[epoch:  65/1000, batch:   512/ 1052, ite: 16960] train loss: 0.008718, tar: 0.000783 
l0: 0.000429, l1: 0.000490, l2: 0.000420, l3: 0.000401, l4: 0.000594, l5: 0.000995, l6: 0.001989

[epoch:  65/1000, batch:   592/ 1052, ite: 16980] train loss: 0.008727, tar: 0.000784 
l0: 0.000163, l1: 0.000167, l2: 0.000160, l3: 0.000194, l4: 0.000238, l5: 0.000429, l6: 0.000764

[epoch:  65/1000, batch:   672/ 1052, ite: 17000] train loss: 0.008726, tar: 0.000784 
l0: 0.000288, l1: 0.000278, l2: 0.000306, l3: 0.000347, l4: 0.000466, l5: 0.001033, l6: 0.001313

[epoch:  65/1000, batch:   752/ 1052, ite: 17020] train loss: 0.008718, tar: 0.000783 
l0: 0.000826, l1: 0.000753, l2: 0.000864, l3: 0.000918, l4: 0.001220, l5: 0.002217, l6: 0.003738

[epoch:  65/1000, batch:   832/ 1052, ite: 17040] train loss: 0.008715, tar: 0.000783 
l0: 0.000318, l1: 0.000315, l2: 0.000326, l3: 0.000427, l4: 0.000746, l5: 0.001136, l6: 0.001664

[epoch:  65/1000, batch:   912/ 1052, ite: 17060] train loss: 0.008711, tar: 0.000782 
l0: 0.000311, l1: 0.000307, l2: 0.000309, l3: 0.000450, l4: 0.000470, l5: 0.001076, l6: 0.001673

[epoch:  65/1000, batch:   992/ 1052, ite: 17080] train loss: 0.008709, tar: 0.000782 
[Epoch 65/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000369, l1: 0.000402, l2: 0.000377, l3: 0.000355, l4: 0.000564, l5: 0.000819, l6: 0.001330

[epoch:  66/1000, batch:    20/ 1052, ite: 17100] train loss: 0.008706, tar: 0.000782 
l0: 0.000582, l1: 0.000576, l2: 0.000622, l3: 0.000709, l4: 0.001038, l5: 0.001287, l6: 0.002708

[epoch:  66/1000, batch:   100/ 1052, ite: 17120] train loss: 0.008704, tar: 0.000782 
l0: 0.000306, l1: 0.000298, l2: 0.000304, l3: 0.000472, l4: 0.000651, l5: 0.001137, l6: 0.001662

[epoch:  66/1000, batch:   180/ 1052, ite: 17140] train loss: 0.008697, tar: 0.000781 
l0: 0.000373, l1: 0.000418, l2: 0.000417, l3: 0.000434, l4: 0.000654, l5: 0.001050, l6: 0.001519

[epoch:  66/1000, batch:   260/ 1052, ite: 17160] train loss: 0.008710, tar: 0.000783 
l0: 0.000463, l1: 0.000482, l2: 0.000468, l3: 0.000537, l4: 0.000759, l5: 0.001358, l6: 0.002208

[epoch:  66/1000, batch:   340/ 1052, ite: 17180] train loss: 0.008710, tar: 0.000783 
l0: 0.000514, l1: 0.000489, l2: 0.000500, l3: 0.000674, l4: 0.001028, l5: 0.001731, l6: 0.002480

[epoch:  66/1000, batch:   420/ 1052, ite: 17200] train loss: 0.008708, tar: 0.000782 
l0: 0.000290, l1: 0.000296, l2: 0.000308, l3: 0.000394, l4: 0.000484, l5: 0.000961, l6: 0.001298

[epoch:  66/1000, batch:   500/ 1052, ite: 17220] train loss: 0.008700, tar: 0.000781 
l0: 0.000483, l1: 0.000517, l2: 0.000503, l3: 0.000527, l4: 0.000682, l5: 0.000955, l6: 0.001454

[epoch:  66/1000, batch:   580/ 1052, ite: 17240] train loss: 0.008694, tar: 0.000781 
l0: 0.000469, l1: 0.000522, l2: 0.000522, l3: 0.000671, l4: 0.000717, l5: 0.001115, l6: 0.001882

[epoch:  66/1000, batch:   660/ 1052, ite: 17260] train loss: 0.008688, tar: 0.000780 
l0: 0.000361, l1: 0.000312, l2: 0.000443, l3: 0.000582, l4: 0.000879, l5: 0.001146, l6: 0.002068

[epoch:  66/1000, batch:   740/ 1052, ite: 17280] train loss: 0.008683, tar: 0.000779 
l0: 0.000787, l1: 0.000989, l2: 0.000700, l3: 0.000592, l4: 0.000534, l5: 0.000832, l6: 0.001408

[epoch:  66/1000, batch:   820/ 1052, ite: 17300] train loss: 0.008682, tar: 0.000779 
l0: 0.000612, l1: 0.000639, l2: 0.000782, l3: 0.000750, l4: 0.000746, l5: 0.001072, l6: 0.002189

[epoch:  66/1000, batch:   900/ 1052, ite: 17320] train loss: 0.008685, tar: 0.000780 
l0: 0.000252, l1: 0.000255, l2: 0.000262, l3: 0.000309, l4: 0.000352, l5: 0.000578, l6: 0.001275

[epoch:  66/1000, batch:   980/ 1052, ite: 17340] train loss: 0.008680, tar: 0.000779 
[Epoch 66/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000905, l1: 0.000854, l2: 0.000917, l3: 0.001091, l4: 0.001559, l5: 0.002116, l6: 0.002073

[epoch:  67/1000, batch:     8/ 1052, ite: 17360] train loss: 0.008675, tar: 0.000779 
l0: 0.000205, l1: 0.000208, l2: 0.000249, l3: 0.000293, l4: 0.000331, l5: 0.000905, l6: 0.001244

[epoch:  67/1000, batch:    88/ 1052, ite: 17380] train loss: 0.008675, tar: 0.000779 
l0: 0.000733, l1: 0.000740, l2: 0.000766, l3: 0.000797, l4: 0.000936, l5: 0.001486, l6: 0.002337

[epoch:  67/1000, batch:   168/ 1052, ite: 17400] train loss: 0.008669, tar: 0.000778 
l0: 0.000792, l1: 0.000843, l2: 0.000728, l3: 0.000714, l4: 0.000979, l5: 0.001667, l6: 0.003021

[epoch:  67/1000, batch:   248/ 1052, ite: 17420] train loss: 0.008664, tar: 0.000778 
l0: 0.000564, l1: 0.000551, l2: 0.000573, l3: 0.000701, l4: 0.000913, l5: 0.001522, l6: 0.002381

[epoch:  67/1000, batch:   328/ 1052, ite: 17440] train loss: 0.008660, tar: 0.000777 
l0: 0.000418, l1: 0.000436, l2: 0.000462, l3: 0.000484, l4: 0.000683, l5: 0.000919, l6: 0.002242

[epoch:  67/1000, batch:   408/ 1052, ite: 17460] train loss: 0.008655, tar: 0.000777 
l0: 0.000416, l1: 0.000434, l2: 0.000434, l3: 0.000522, l4: 0.000717, l5: 0.001039, l6: 0.001684

[epoch:  67/1000, batch:   488/ 1052, ite: 17480] train loss: 0.008651, tar: 0.000776 
l0: 0.000744, l1: 0.000681, l2: 0.000656, l3: 0.000688, l4: 0.001173, l5: 0.002626, l6: 0.003755

[epoch:  67/1000, batch:   568/ 1052, ite: 17500] train loss: 0.008646, tar: 0.000776 
l0: 0.000431, l1: 0.000419, l2: 0.000443, l3: 0.000527, l4: 0.000820, l5: 0.001007, l6: 0.002128

[epoch:  67/1000, batch:   648/ 1052, ite: 17520] train loss: 0.008641, tar: 0.000775 
l0: 0.000149, l1: 0.000146, l2: 0.000189, l3: 0.000196, l4: 0.000330, l5: 0.000451, l6: 0.000674

[epoch:  67/1000, batch:   728/ 1052, ite: 17540] train loss: 0.008637, tar: 0.000775 
l0: 0.001060, l1: 0.001215, l2: 0.001172, l3: 0.000929, l4: 0.001405, l5: 0.001542, l6: 0.003045

[epoch:  67/1000, batch:   808/ 1052, ite: 17560] train loss: 0.008635, tar: 0.000774 
l0: 0.000350, l1: 0.000355, l2: 0.000426, l3: 0.000498, l4: 0.000674, l5: 0.000853, l6: 0.001306

[epoch:  67/1000, batch:   888/ 1052, ite: 17580] train loss: 0.008639, tar: 0.000775 
l0: 0.000562, l1: 0.000539, l2: 0.000621, l3: 0.001014, l4: 0.001084, l5: 0.002057, l6: 0.002420

[epoch:  67/1000, batch:   968/ 1052, ite: 17600] train loss: 0.008635, tar: 0.000774 
l0: 0.004899, l1: 0.005854, l2: 0.006182, l3: 0.008591, l4: 0.002585, l5: 0.003351, l6: 0.006818

[epoch:  67/1000, batch:  1048/ 1052, ite: 17620] train loss: 0.008645, tar: 0.000775 
[Epoch 67/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.001268, l1: 0.001192, l2: 0.001780, l3: 0.001545, l4: 0.001412, l5: 0.002451, l6: 0.003233

[epoch:  68/1000, batch:    76/ 1052, ite: 17640] train loss: 0.008649, tar: 0.000776 
l0: 0.000681, l1: 0.000705, l2: 0.000753, l3: 0.001162, l4: 0.001332, l5: 0.001329, l6: 0.002470

[epoch:  68/1000, batch:   156/ 1052, ite: 17660] train loss: 0.008657, tar: 0.000777 
l0: 0.000374, l1: 0.000451, l2: 0.000381, l3: 0.000327, l4: 0.000434, l5: 0.000657, l6: 0.000828

[epoch:  68/1000, batch:   236/ 1052, ite: 17680] train loss: 0.008658, tar: 0.000777 
l0: 0.000817, l1: 0.000982, l2: 0.000846, l3: 0.000825, l4: 0.001040, l5: 0.002189, l6: 0.002970

[epoch:  68/1000, batch:   316/ 1052, ite: 17700] train loss: 0.008659, tar: 0.000777 
l0: 0.000287, l1: 0.000293, l2: 0.000272, l3: 0.000299, l4: 0.000396, l5: 0.001022, l6: 0.001309

[epoch:  68/1000, batch:   396/ 1052, ite: 17720] train loss: 0.008657, tar: 0.000777 
l0: 0.000600, l1: 0.000915, l2: 0.000537, l3: 0.000617, l4: 0.000833, l5: 0.001531, l6: 0.002620

[epoch:  68/1000, batch:   476/ 1052, ite: 17740] train loss: 0.008660, tar: 0.000777 
l0: 0.001664, l1: 0.001571, l2: 0.002375, l3: 0.003056, l4: 0.002445, l5: 0.002982, l6: 0.004188

[epoch:  68/1000, batch:   556/ 1052, ite: 17760] train loss: 0.008660, tar: 0.000777 
l0: 0.000756, l1: 0.000855, l2: 0.000729, l3: 0.000773, l4: 0.000909, l5: 0.001196, l6: 0.002316

[epoch:  68/1000, batch:   636/ 1052, ite: 17780] train loss: 0.008658, tar: 0.000777 
l0: 0.000289, l1: 0.000281, l2: 0.000271, l3: 0.000443, l4: 0.000590, l5: 0.000860, l6: 0.001550

[epoch:  68/1000, batch:   716/ 1052, ite: 17800] train loss: 0.008651, tar: 0.000776 
l0: 0.001191, l1: 0.001263, l2: 0.001160, l3: 0.001380, l4: 0.001474, l5: 0.002431, l6: 0.003334

[epoch:  68/1000, batch:   796/ 1052, ite: 17820] train loss: 0.008648, tar: 0.000776 
l0: 0.000308, l1: 0.000312, l2: 0.000347, l3: 0.000365, l4: 0.000548, l5: 0.001107, l6: 0.002171

[epoch:  68/1000, batch:   876/ 1052, ite: 17840] train loss: 0.008646, tar: 0.000776 
l0: 0.000439, l1: 0.000413, l2: 0.000468, l3: 0.000569, l4: 0.000492, l5: 0.000784, l6: 0.001203

[epoch:  68/1000, batch:   956/ 1052, ite: 17860] train loss: 0.008639, tar: 0.000775 
l0: 0.000709, l1: 0.000707, l2: 0.000666, l3: 0.000981, l4: 0.001281, l5: 0.001985, l6: 0.002053

[epoch:  68/1000, batch:  1036/ 1052, ite: 17880] train loss: 0.008634, tar: 0.000774 
[Epoch 68/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000687, l1: 0.000661, l2: 0.000778, l3: 0.001017, l4: 0.001193, l5: 0.002007, l6: 0.004105

[epoch:  69/1000, batch:    64/ 1052, ite: 17900] train loss: 0.008629, tar: 0.000774 
l0: 0.000298, l1: 0.000282, l2: 0.000323, l3: 0.000384, l4: 0.000528, l5: 0.001056, l6: 0.001832

[epoch:  69/1000, batch:   144/ 1052, ite: 17920] train loss: 0.008623, tar: 0.000773 
l0: 0.000568, l1: 0.000571, l2: 0.000569, l3: 0.000667, l4: 0.000872, l5: 0.001856, l6: 0.002611

[epoch:  69/1000, batch:   224/ 1052, ite: 17940] train loss: 0.008618, tar: 0.000772 
l0: 0.000794, l1: 0.000805, l2: 0.000896, l3: 0.000823, l4: 0.000986, l5: 0.001423, l6: 0.002917

[epoch:  69/1000, batch:   304/ 1052, ite: 17960] train loss: 0.008613, tar: 0.000772 
l0: 0.000302, l1: 0.000301, l2: 0.000312, l3: 0.000323, l4: 0.000490, l5: 0.000779, l6: 0.001289

[epoch:  69/1000, batch:   384/ 1052, ite: 17980] train loss: 0.008609, tar: 0.000772 
l0: 0.000421, l1: 0.000448, l2: 0.000454, l3: 0.000519, l4: 0.000676, l5: 0.001446, l6: 0.001912

[epoch:  69/1000, batch:   464/ 1052, ite: 18000] train loss: 0.008605, tar: 0.000771 
l0: 0.000406, l1: 0.000389, l2: 0.000445, l3: 0.000576, l4: 0.000815, l5: 0.001444, l6: 0.002403

[epoch:  69/1000, batch:   544/ 1052, ite: 18020] train loss: 0.008608, tar: 0.000771 
l0: 0.000496, l1: 0.000515, l2: 0.000514, l3: 0.000681, l4: 0.000751, l5: 0.001155, l6: 0.002350

[epoch:  69/1000, batch:   624/ 1052, ite: 18040] train loss: 0.008603, tar: 0.000771 
l0: 0.000248, l1: 0.000250, l2: 0.000239, l3: 0.000256, l4: 0.000452, l5: 0.000730, l6: 0.001238

[epoch:  69/1000, batch:   704/ 1052, ite: 18060] train loss: 0.008598, tar: 0.000770 
l0: 0.000733, l1: 0.000772, l2: 0.000677, l3: 0.000667, l4: 0.000853, l5: 0.001459, l6: 0.002280

[epoch:  69/1000, batch:   784/ 1052, ite: 18080] train loss: 0.008602, tar: 0.000771 
l0: 0.000538, l1: 0.000517, l2: 0.000551, l3: 0.000578, l4: 0.000630, l5: 0.001297, l6: 0.002193

[epoch:  69/1000, batch:   864/ 1052, ite: 18100] train loss: 0.008603, tar: 0.000771 
l0: 0.000746, l1: 0.000716, l2: 0.000715, l3: 0.000876, l4: 0.001194, l5: 0.002090, l6: 0.004073

[epoch:  69/1000, batch:   944/ 1052, ite: 18120] train loss: 0.008604, tar: 0.000771 
l0: 0.000337, l1: 0.000334, l2: 0.000337, l3: 0.000469, l4: 0.000656, l5: 0.001044, l6: 0.001748

[epoch:  69/1000, batch:  1024/ 1052, ite: 18140] train loss: 0.008600, tar: 0.000770 
[Epoch 69/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000610, l1: 0.000566, l2: 0.000586, l3: 0.000718, l4: 0.001170, l5: 0.002070, l6: 0.003688

[epoch:  70/1000, batch:    52/ 1052, ite: 18160] train loss: 0.008598, tar: 0.000770 
l0: 0.001232, l1: 0.001323, l2: 0.001287, l3: 0.001431, l4: 0.001311, l5: 0.001924, l6: 0.003883

[epoch:  70/1000, batch:   132/ 1052, ite: 18180] train loss: 0.008597, tar: 0.000770 
l0: 0.000379, l1: 0.000368, l2: 0.000376, l3: 0.000508, l4: 0.000638, l5: 0.001187, l6: 0.001517

[epoch:  70/1000, batch:   212/ 1052, ite: 18200] train loss: 0.008593, tar: 0.000770 
l0: 0.000666, l1: 0.000613, l2: 0.000688, l3: 0.000802, l4: 0.001083, l5: 0.001592, l6: 0.002075

[epoch:  70/1000, batch:   292/ 1052, ite: 18220] train loss: 0.008589, tar: 0.000769 
l0: 0.000640, l1: 0.000614, l2: 0.000653, l3: 0.000934, l4: 0.001203, l5: 0.002015, l6: 0.002317

[epoch:  70/1000, batch:   372/ 1052, ite: 18240] train loss: 0.008583, tar: 0.000769 
l0: 0.000576, l1: 0.000586, l2: 0.000602, l3: 0.000663, l4: 0.000917, l5: 0.001908, l6: 0.002677

[epoch:  70/1000, batch:   452/ 1052, ite: 18260] train loss: 0.008577, tar: 0.000768 
l0: 0.000405, l1: 0.000432, l2: 0.000506, l3: 0.000514, l4: 0.000614, l5: 0.001420, l6: 0.001582

[epoch:  70/1000, batch:   532/ 1052, ite: 18280] train loss: 0.008587, tar: 0.000769 
l0: 0.000375, l1: 0.000367, l2: 0.000489, l3: 0.000749, l4: 0.001055, l5: 0.001389, l6: 0.001634

[epoch:  70/1000, batch:   612/ 1052, ite: 18300] train loss: 0.008589, tar: 0.000769 
l0: 0.000268, l1: 0.000253, l2: 0.000264, l3: 0.000388, l4: 0.000632, l5: 0.000833, l6: 0.001439

[epoch:  70/1000, batch:   692/ 1052, ite: 18320] train loss: 0.008587, tar: 0.000769 
l0: 0.000745, l1: 0.000811, l2: 0.000907, l3: 0.000833, l4: 0.000774, l5: 0.001469, l6: 0.003063

[epoch:  70/1000, batch:   772/ 1052, ite: 18340] train loss: 0.008586, tar: 0.000769 
l0: 0.000800, l1: 0.000766, l2: 0.000823, l3: 0.000994, l4: 0.000990, l5: 0.001770, l6: 0.002686

[epoch:  70/1000, batch:   852/ 1052, ite: 18360] train loss: 0.008583, tar: 0.000769 
l0: 0.000823, l1: 0.000798, l2: 0.000844, l3: 0.000954, l4: 0.001257, l5: 0.002397, l6: 0.003984

[epoch:  70/1000, batch:   932/ 1052, ite: 18380] train loss: 0.008581, tar: 0.000768 
l0: 0.000611, l1: 0.000609, l2: 0.000566, l3: 0.000655, l4: 0.001035, l5: 0.001904, l6: 0.002775

[epoch:  70/1000, batch:  1012/ 1052, ite: 18400] train loss: 0.008587, tar: 0.000769 
[Epoch 70/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000767, l1: 0.000750, l2: 0.000846, l3: 0.000855, l4: 0.001177, l5: 0.001709, l6: 0.002610

[epoch:  71/1000, batch:    40/ 1052, ite: 18420] train loss: 0.008589, tar: 0.000770 
l0: 0.000353, l1: 0.000332, l2: 0.000365, l3: 0.000450, l4: 0.000575, l5: 0.001395, l6: 0.001978

[epoch:  71/1000, batch:   120/ 1052, ite: 18440] train loss: 0.008589, tar: 0.000770 
l0: 0.001857, l1: 0.001741, l2: 0.002679, l3: 0.001997, l4: 0.003104, l5: 0.002866, l6: 0.003300

[epoch:  71/1000, batch:   200/ 1052, ite: 18460] train loss: 0.008589, tar: 0.000770 
l0: 0.000342, l1: 0.000372, l2: 0.000430, l3: 0.000336, l4: 0.000409, l5: 0.000668, l6: 0.001144

[epoch:  71/1000, batch:   280/ 1052, ite: 18480] train loss: 0.008585, tar: 0.000769 
l0: 0.000406, l1: 0.000393, l2: 0.000390, l3: 0.000439, l4: 0.000633, l5: 0.001045, l6: 0.001867

[epoch:  71/1000, batch:   360/ 1052, ite: 18500] train loss: 0.008586, tar: 0.000769 
l0: 0.000707, l1: 0.000737, l2: 0.000688, l3: 0.000647, l4: 0.000981, l5: 0.001063, l6: 0.001591

[epoch:  71/1000, batch:   440/ 1052, ite: 18520] train loss: 0.008586, tar: 0.000769 
l0: 0.000753, l1: 0.000716, l2: 0.000693, l3: 0.000789, l4: 0.000970, l5: 0.001558, l6: 0.002700

[epoch:  71/1000, batch:   520/ 1052, ite: 18540] train loss: 0.008584, tar: 0.000769 
l0: 0.000415, l1: 0.000422, l2: 0.000449, l3: 0.000419, l4: 0.000600, l5: 0.001003, l6: 0.002152

[epoch:  71/1000, batch:   600/ 1052, ite: 18560] train loss: 0.008581, tar: 0.000769 
l0: 0.001143, l1: 0.001188, l2: 0.001155, l3: 0.001295, l4: 0.001968, l5: 0.002900, l6: 0.004435

[epoch:  71/1000, batch:   680/ 1052, ite: 18580] train loss: 0.008580, tar: 0.000769 
l0: 0.000515, l1: 0.000525, l2: 0.000468, l3: 0.000621, l4: 0.000841, l5: 0.001179, l6: 0.001514

[epoch:  71/1000, batch:   760/ 1052, ite: 18600] train loss: 0.008576, tar: 0.000768 
l0: 0.000344, l1: 0.000336, l2: 0.000332, l3: 0.000360, l4: 0.000406, l5: 0.000663, l6: 0.001475

[epoch:  71/1000, batch:   840/ 1052, ite: 18620] train loss: 0.008574, tar: 0.000768 
l0: 0.000564, l1: 0.000596, l2: 0.000627, l3: 0.000735, l4: 0.000834, l5: 0.001516, l6: 0.001976

[epoch:  71/1000, batch:   920/ 1052, ite: 18640] train loss: 0.008583, tar: 0.000769 
l0: 0.000506, l1: 0.000541, l2: 0.000511, l3: 0.000460, l4: 0.000700, l5: 0.001358, l6: 0.002511

[epoch:  71/1000, batch:  1000/ 1052, ite: 18660] train loss: 0.008580, tar: 0.000769 
[Epoch 71/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000422, l1: 0.000434, l2: 0.000510, l3: 0.000502, l4: 0.000668, l5: 0.001063, l6: 0.001560

[epoch:  72/1000, batch:    28/ 1052, ite: 18680] train loss: 0.008579, tar: 0.000769 
l0: 0.000816, l1: 0.000856, l2: 0.000964, l3: 0.000935, l4: 0.001159, l5: 0.001472, l6: 0.002288

[epoch:  72/1000, batch:   108/ 1052, ite: 18700] train loss: 0.008579, tar: 0.000769 
l0: 0.000332, l1: 0.000309, l2: 0.000340, l3: 0.000401, l4: 0.000552, l5: 0.001123, l6: 0.002145

[epoch:  72/1000, batch:   188/ 1052, ite: 18720] train loss: 0.008573, tar: 0.000768 
l0: 0.000712, l1: 0.000699, l2: 0.000738, l3: 0.000852, l4: 0.001325, l5: 0.002051, l6: 0.003782

[epoch:  72/1000, batch:   268/ 1052, ite: 18740] train loss: 0.008572, tar: 0.000768 
l0: 0.000800, l1: 0.000787, l2: 0.000884, l3: 0.000913, l4: 0.001234, l5: 0.002467, l6: 0.003841

[epoch:  72/1000, batch:   348/ 1052, ite: 18760] train loss: 0.008567, tar: 0.000767 
l0: 0.000825, l1: 0.000871, l2: 0.000946, l3: 0.000951, l4: 0.001155, l5: 0.001615, l6: 0.002057

[epoch:  72/1000, batch:   428/ 1052, ite: 18780] train loss: 0.008567, tar: 0.000767 
l0: 0.000546, l1: 0.000546, l2: 0.000518, l3: 0.000607, l4: 0.000920, l5: 0.001198, l6: 0.002030

[epoch:  72/1000, batch:   508/ 1052, ite: 18800] train loss: 0.008565, tar: 0.000767 
l0: 0.000611, l1: 0.000632, l2: 0.000707, l3: 0.000687, l4: 0.000761, l5: 0.000959, l6: 0.001603

[epoch:  72/1000, batch:   588/ 1052, ite: 18820] train loss: 0.008563, tar: 0.000767 
l0: 0.000207, l1: 0.000230, l2: 0.000195, l3: 0.000258, l4: 0.000399, l5: 0.000634, l6: 0.000633

[epoch:  72/1000, batch:   668/ 1052, ite: 18840] train loss: 0.008559, tar: 0.000766 
l0: 0.000444, l1: 0.000445, l2: 0.000452, l3: 0.000585, l4: 0.000864, l5: 0.001322, l6: 0.001805

[epoch:  72/1000, batch:   748/ 1052, ite: 18860] train loss: 0.008556, tar: 0.000766 
l0: 0.000351, l1: 0.000348, l2: 0.000298, l3: 0.000421, l4: 0.000642, l5: 0.000957, l6: 0.001381

[epoch:  72/1000, batch:   828/ 1052, ite: 18880] train loss: 0.008561, tar: 0.000766 
l0: 0.000356, l1: 0.000344, l2: 0.000357, l3: 0.000415, l4: 0.000549, l5: 0.001234, l6: 0.001787

[epoch:  72/1000, batch:   908/ 1052, ite: 18900] train loss: 0.008557, tar: 0.000766 
l0: 0.000512, l1: 0.000503, l2: 0.000497, l3: 0.000649, l4: 0.000895, l5: 0.001658, l6: 0.003098

[epoch:  72/1000, batch:   988/ 1052, ite: 18920] train loss: 0.008554, tar: 0.000766 
[Epoch 72/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000684, l1: 0.000694, l2: 0.000939, l3: 0.000813, l4: 0.000938, l5: 0.001555, l6: 0.002012

[epoch:  73/1000, batch:    16/ 1052, ite: 18940] train loss: 0.008551, tar: 0.000765 
l0: 0.000235, l1: 0.000249, l2: 0.000264, l3: 0.000286, l4: 0.000450, l5: 0.000799, l6: 0.001225

[epoch:  73/1000, batch:    96/ 1052, ite: 18960] train loss: 0.008545, tar: 0.000765 
l0: 0.000730, l1: 0.000687, l2: 0.000765, l3: 0.000824, l4: 0.001197, l5: 0.002264, l6: 0.003451

[epoch:  73/1000, batch:   176/ 1052, ite: 18980] train loss: 0.008543, tar: 0.000765 
l0: 0.000456, l1: 0.000490, l2: 0.000484, l3: 0.000544, l4: 0.000678, l5: 0.001436, l6: 0.002611

[epoch:  73/1000, batch:   256/ 1052, ite: 19000] train loss: 0.008542, tar: 0.000764 
l0: 0.000630, l1: 0.000578, l2: 0.000524, l3: 0.000605, l4: 0.000793, l5: 0.001595, l6: 0.002052

[epoch:  73/1000, batch:   336/ 1052, ite: 19020] train loss: 0.008540, tar: 0.000764 
l0: 0.000574, l1: 0.000566, l2: 0.000616, l3: 0.000759, l4: 0.000982, l5: 0.001918, l6: 0.002596

[epoch:  73/1000, batch:   416/ 1052, ite: 19040] train loss: 0.008535, tar: 0.000763 
l0: 0.000954, l1: 0.000966, l2: 0.001053, l3: 0.000936, l4: 0.001326, l5: 0.001521, l6: 0.001804

[epoch:  73/1000, batch:   496/ 1052, ite: 19060] train loss: 0.008529, tar: 0.000763 
l0: 0.000645, l1: 0.000654, l2: 0.000647, l3: 0.000700, l4: 0.000945, l5: 0.001558, l6: 0.002881

[epoch:  73/1000, batch:   576/ 1052, ite: 19080] train loss: 0.008528, tar: 0.000763 
l0: 0.000440, l1: 0.000453, l2: 0.000397, l3: 0.000423, l4: 0.000534, l5: 0.000876, l6: 0.001288

[epoch:  73/1000, batch:   656/ 1052, ite: 19100] train loss: 0.008527, tar: 0.000762 
l0: 0.000667, l1: 0.000700, l2: 0.000649, l3: 0.000734, l4: 0.000853, l5: 0.001183, l6: 0.001301

[epoch:  73/1000, batch:   736/ 1052, ite: 19120] train loss: 0.008522, tar: 0.000762 
l0: 0.001114, l1: 0.001110, l2: 0.001092, l3: 0.001395, l4: 0.001675, l5: 0.002348, l6: 0.003457

[epoch:  73/1000, batch:   816/ 1052, ite: 19140] train loss: 0.008518, tar: 0.000761 
l0: 0.000726, l1: 0.000732, l2: 0.000746, l3: 0.000845, l4: 0.000916, l5: 0.001003, l6: 0.002137

[epoch:  73/1000, batch:   896/ 1052, ite: 19160] train loss: 0.008513, tar: 0.000761 
l0: 0.000217, l1: 0.000217, l2: 0.000284, l3: 0.000275, l4: 0.000403, l5: 0.000731, l6: 0.000939

[epoch:  73/1000, batch:   976/ 1052, ite: 19180] train loss: 0.008518, tar: 0.000761 
[Epoch 73/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.001644, l1: 0.001710, l2: 0.001613, l3: 0.001461, l4: 0.001719, l5: 0.002321, l6: 0.004399

[epoch:  74/1000, batch:     4/ 1052, ite: 19200] train loss: 0.008519, tar: 0.000761 
l0: 0.002451, l1: 0.002490, l2: 0.004850, l3: 0.004459, l4: 0.005549, l5: 0.005652, l6: 0.008544

[epoch:  74/1000, batch:    84/ 1052, ite: 19220] train loss: 0.008517, tar: 0.000761 
l0: 0.000807, l1: 0.000771, l2: 0.000881, l3: 0.000843, l4: 0.001071, l5: 0.001894, l6: 0.002651

[epoch:  74/1000, batch:   164/ 1052, ite: 19240] train loss: 0.008517, tar: 0.000762 
l0: 0.000417, l1: 0.000432, l2: 0.000392, l3: 0.000434, l4: 0.000639, l5: 0.000809, l6: 0.001365

[epoch:  74/1000, batch:   244/ 1052, ite: 19260] train loss: 0.008519, tar: 0.000762 
l0: 0.000327, l1: 0.000323, l2: 0.000343, l3: 0.000397, l4: 0.000470, l5: 0.001103, l6: 0.001699

[epoch:  74/1000, batch:   324/ 1052, ite: 19280] train loss: 0.008515, tar: 0.000761 
l0: 0.000673, l1: 0.000717, l2: 0.000637, l3: 0.000803, l4: 0.000870, l5: 0.001754, l6: 0.003043

[epoch:  74/1000, batch:   404/ 1052, ite: 19300] train loss: 0.008512, tar: 0.000761 
l0: 0.000309, l1: 0.000304, l2: 0.000307, l3: 0.000440, l4: 0.000530, l5: 0.000929, l6: 0.001710

[epoch:  74/1000, batch:   484/ 1052, ite: 19320] train loss: 0.008511, tar: 0.000761 
l0: 0.000381, l1: 0.000377, l2: 0.000386, l3: 0.000467, l4: 0.000584, l5: 0.001200, l6: 0.001963

[epoch:  74/1000, batch:   564/ 1052, ite: 19340] train loss: 0.008507, tar: 0.000760 
l0: 0.000256, l1: 0.000256, l2: 0.000285, l3: 0.000309, l4: 0.000428, l5: 0.000951, l6: 0.001723

[epoch:  74/1000, batch:   644/ 1052, ite: 19360] train loss: 0.008501, tar: 0.000760 
l0: 0.000654, l1: 0.000642, l2: 0.000703, l3: 0.000707, l4: 0.001029, l5: 0.001847, l6: 0.003264

[epoch:  74/1000, batch:   724/ 1052, ite: 19380] train loss: 0.008499, tar: 0.000759 
l0: 0.000262, l1: 0.000251, l2: 0.000274, l3: 0.000355, l4: 0.000431, l5: 0.000568, l6: 0.001175

[epoch:  74/1000, batch:   804/ 1052, ite: 19400] train loss: 0.008498, tar: 0.000759 
l0: 0.000692, l1: 0.000656, l2: 0.000721, l3: 0.000715, l4: 0.001061, l5: 0.001385, l6: 0.002739

[epoch:  74/1000, batch:   884/ 1052, ite: 19420] train loss: 0.008494, tar: 0.000759 
l0: 0.001181, l1: 0.001215, l2: 0.001017, l3: 0.001221, l4: 0.001327, l5: 0.002018, l6: 0.003501

[epoch:  74/1000, batch:   964/ 1052, ite: 19440] train loss: 0.008493, tar: 0.000759 
l0: 0.000790, l1: 0.000775, l2: 0.000876, l3: 0.000995, l4: 0.001194, l5: 0.002061, l6: 0.003243

[epoch:  74/1000, batch:  1044/ 1052, ite: 19460] train loss: 0.008491, tar: 0.000758 
[Epoch 74/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000603, l1: 0.000590, l2: 0.000666, l3: 0.000758, l4: 0.001212, l5: 0.001889, l6: 0.001851

[epoch:  75/1000, batch:    72/ 1052, ite: 19480] train loss: 0.008487, tar: 0.000758 
l0: 0.000618, l1: 0.000614, l2: 0.000603, l3: 0.000743, l4: 0.001052, l5: 0.001438, l6: 0.003080

[epoch:  75/1000, batch:   152/ 1052, ite: 19500] train loss: 0.008483, tar: 0.000757 
l0: 0.000362, l1: 0.000375, l2: 0.000405, l3: 0.000458, l4: 0.000595, l5: 0.000878, l6: 0.001104

[epoch:  75/1000, batch:   232/ 1052, ite: 19520] train loss: 0.008481, tar: 0.000757 
l0: 0.000493, l1: 0.000483, l2: 0.000547, l3: 0.000615, l4: 0.000823, l5: 0.001001, l6: 0.001858

[epoch:  75/1000, batch:   312/ 1052, ite: 19540] train loss: 0.008476, tar: 0.000756 
l0: 0.001237, l1: 0.001303, l2: 0.001293, l3: 0.001106, l4: 0.001208, l5: 0.001716, l6: 0.002643

[epoch:  75/1000, batch:   392/ 1052, ite: 19560] train loss: 0.008471, tar: 0.000756 
l0: 0.000350, l1: 0.000355, l2: 0.000360, l3: 0.000421, l4: 0.000437, l5: 0.000889, l6: 0.001209

[epoch:  75/1000, batch:   472/ 1052, ite: 19580] train loss: 0.008469, tar: 0.000756 
l0: 0.000584, l1: 0.000615, l2: 0.000624, l3: 0.000736, l4: 0.001040, l5: 0.001693, l6: 0.002238

[epoch:  75/1000, batch:   552/ 1052, ite: 19600] train loss: 0.008466, tar: 0.000755 
l0: 0.000326, l1: 0.000353, l2: 0.000310, l3: 0.000333, l4: 0.000409, l5: 0.000639, l6: 0.000730

[epoch:  75/1000, batch:   632/ 1052, ite: 19620] train loss: 0.008464, tar: 0.000755 
l0: 0.000621, l1: 0.000613, l2: 0.000585, l3: 0.000688, l4: 0.000823, l5: 0.001126, l6: 0.001811

[epoch:  75/1000, batch:   712/ 1052, ite: 19640] train loss: 0.008463, tar: 0.000755 
l0: 0.000761, l1: 0.000748, l2: 0.000775, l3: 0.001002, l4: 0.001320, l5: 0.001967, l6: 0.002734

[epoch:  75/1000, batch:   792/ 1052, ite: 19660] train loss: 0.008461, tar: 0.000755 
l0: 0.001083, l1: 0.001088, l2: 0.001159, l3: 0.001227, l4: 0.001455, l5: 0.001980, l6: 0.005167

[epoch:  75/1000, batch:   872/ 1052, ite: 19680] train loss: 0.008462, tar: 0.000755 
l0: 0.000812, l1: 0.000783, l2: 0.000776, l3: 0.001204, l4: 0.001293, l5: 0.002819, l6: 0.002789

[epoch:  75/1000, batch:   952/ 1052, ite: 19700] train loss: 0.008461, tar: 0.000755 
l0: 0.000515, l1: 0.000512, l2: 0.000548, l3: 0.000559, l4: 0.000844, l5: 0.001054, l6: 0.002329

[epoch:  75/1000, batch:  1032/ 1052, ite: 19720] train loss: 0.008459, tar: 0.000754 
[Epoch 75/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000437, l1: 0.000453, l2: 0.000468, l3: 0.000424, l4: 0.000451, l5: 0.000589, l6: 0.001191

[epoch:  76/1000, batch:    60/ 1052, ite: 19740] train loss: 0.008456, tar: 0.000754 
l0: 0.000716, l1: 0.000692, l2: 0.000751, l3: 0.000920, l4: 0.001025, l5: 0.001429, l6: 0.003042

[epoch:  76/1000, batch:   140/ 1052, ite: 19760] train loss: 0.008452, tar: 0.000754 
l0: 0.000560, l1: 0.000599, l2: 0.000677, l3: 0.000716, l4: 0.000752, l5: 0.001379, l6: 0.003009

[epoch:  76/1000, batch:   220/ 1052, ite: 19780] train loss: 0.008454, tar: 0.000754 
l0: 0.000743, l1: 0.000737, l2: 0.000885, l3: 0.000810, l4: 0.001070, l5: 0.001449, l6: 0.002328

[epoch:  76/1000, batch:   300/ 1052, ite: 19800] train loss: 0.008451, tar: 0.000753 
l0: 0.000372, l1: 0.000367, l2: 0.000408, l3: 0.000450, l4: 0.000621, l5: 0.001352, l6: 0.002166

[epoch:  76/1000, batch:   380/ 1052, ite: 19820] train loss: 0.008450, tar: 0.000753 
l0: 0.000339, l1: 0.000324, l2: 0.000349, l3: 0.000449, l4: 0.000678, l5: 0.000972, l6: 0.001726

[epoch:  76/1000, batch:   460/ 1052, ite: 19840] train loss: 0.008447, tar: 0.000753 
l0: 0.001102, l1: 0.001202, l2: 0.001558, l3: 0.001670, l4: 0.001853, l5: 0.002044, l6: 0.003233

[epoch:  76/1000, batch:   540/ 1052, ite: 19860] train loss: 0.008447, tar: 0.000753 
l0: 0.000427, l1: 0.000459, l2: 0.000443, l3: 0.000503, l4: 0.000663, l5: 0.000891, l6: 0.001631

[epoch:  76/1000, batch:   620/ 1052, ite: 19880] train loss: 0.008444, tar: 0.000752 
l0: 0.000686, l1: 0.000715, l2: 0.000633, l3: 0.000707, l4: 0.000830, l5: 0.001222, l6: 0.001814

[epoch:  76/1000, batch:   700/ 1052, ite: 19900] train loss: 0.008440, tar: 0.000752 
l0: 0.000573, l1: 0.000571, l2: 0.000580, l3: 0.000851, l4: 0.000931, l5: 0.001272, l6: 0.001892

[epoch:  76/1000, batch:   780/ 1052, ite: 19920] train loss: 0.008446, tar: 0.000753 
l0: 0.000431, l1: 0.000399, l2: 0.000434, l3: 0.000526, l4: 0.000852, l5: 0.001380, l6: 0.001410

[epoch:  76/1000, batch:   860/ 1052, ite: 19940] train loss: 0.008446, tar: 0.000753 
l0: 0.001150, l1: 0.001114, l2: 0.001207, l3: 0.001461, l4: 0.001484, l5: 0.003546, l6: 0.004403

[epoch:  76/1000, batch:   940/ 1052, ite: 19960] train loss: 0.008449, tar: 0.000753 
l0: 0.000238, l1: 0.000248, l2: 0.000240, l3: 0.000276, l4: 0.000387, l5: 0.000719, l6: 0.001281

[epoch:  76/1000, batch:  1020/ 1052, ite: 19980] train loss: 0.008448, tar: 0.000753 
[Epoch 76/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000604, l1: 0.000591, l2: 0.000695, l3: 0.000751, l4: 0.000860, l5: 0.001394, l6: 0.002430

[epoch:  77/1000, batch:    48/ 1052, ite: 20000] train loss: 0.008444, tar: 0.000753 
l0: 0.000443, l1: 0.000452, l2: 0.000473, l3: 0.000510, l4: 0.000655, l5: 0.001084, l6: 0.002537

[epoch:  77/1000, batch:   128/ 1052, ite: 20020] train loss: 0.008440, tar: 0.000752 
l0: 0.000378, l1: 0.000412, l2: 0.000349, l3: 0.000410, l4: 0.000542, l5: 0.001001, l6: 0.001759

[epoch:  77/1000, batch:   208/ 1052, ite: 20040] train loss: 0.008437, tar: 0.000752 
l0: 0.000892, l1: 0.000890, l2: 0.000862, l3: 0.000823, l4: 0.000960, l5: 0.001573, l6: 0.002748

[epoch:  77/1000, batch:   288/ 1052, ite: 20060] train loss: 0.008436, tar: 0.000752 
l0: 0.000329, l1: 0.000322, l2: 0.000325, l3: 0.000399, l4: 0.000569, l5: 0.001289, l6: 0.002017

[epoch:  77/1000, batch:   368/ 1052, ite: 20080] train loss: 0.008433, tar: 0.000751 
l0: 0.000663, l1: 0.000619, l2: 0.000716, l3: 0.000807, l4: 0.000992, l5: 0.001745, l6: 0.002952

[epoch:  77/1000, batch:   448/ 1052, ite: 20100] train loss: 0.008432, tar: 0.000751 
l0: 0.000856, l1: 0.000881, l2: 0.000835, l3: 0.000998, l4: 0.001015, l5: 0.001449, l6: 0.003124

[epoch:  77/1000, batch:   528/ 1052, ite: 20120] train loss: 0.008426, tar: 0.000750 
l0: 0.000256, l1: 0.000260, l2: 0.000269, l3: 0.000262, l4: 0.000500, l5: 0.000860, l6: 0.001322

[epoch:  77/1000, batch:   608/ 1052, ite: 20140] train loss: 0.008423, tar: 0.000750 
l0: 0.000868, l1: 0.000895, l2: 0.000857, l3: 0.001003, l4: 0.001238, l5: 0.002046, l6: 0.003667

[epoch:  77/1000, batch:   688/ 1052, ite: 20160] train loss: 0.008425, tar: 0.000750 
l0: 0.001493, l1: 0.001693, l2: 0.001503, l3: 0.001366, l4: 0.001571, l5: 0.002145, l6: 0.002399

[epoch:  77/1000, batch:   768/ 1052, ite: 20180] train loss: 0.008424, tar: 0.000750 
l0: 0.000530, l1: 0.000545, l2: 0.000569, l3: 0.000711, l4: 0.000883, l5: 0.001650, l6: 0.002617

[epoch:  77/1000, batch:   848/ 1052, ite: 20200] train loss: 0.008424, tar: 0.000750 
l0: 0.000786, l1: 0.000824, l2: 0.000835, l3: 0.000896, l4: 0.001236, l5: 0.002190, l6: 0.003871

[epoch:  77/1000, batch:   928/ 1052, ite: 20220] train loss: 0.008421, tar: 0.000750 
l0: 0.000766, l1: 0.000800, l2: 0.000725, l3: 0.000755, l4: 0.001083, l5: 0.001684, l6: 0.002619

[epoch:  77/1000, batch:  1008/ 1052, ite: 20240] train loss: 0.008418, tar: 0.000749 
[Epoch 77/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000375, l1: 0.000406, l2: 0.000366, l3: 0.000403, l4: 0.000689, l5: 0.001033, l6: 0.001487

[epoch:  78/1000, batch:    36/ 1052, ite: 20260] train loss: 0.008417, tar: 0.000749 
l0: 0.000415, l1: 0.000430, l2: 0.000396, l3: 0.000457, l4: 0.000595, l5: 0.001044, l6: 0.002033

[epoch:  78/1000, batch:   116/ 1052, ite: 20280] train loss: 0.008417, tar: 0.000749 
l0: 0.000386, l1: 0.000373, l2: 0.000425, l3: 0.000496, l4: 0.000926, l5: 0.000996, l6: 0.001994

[epoch:  78/1000, batch:   196/ 1052, ite: 20300] train loss: 0.008416, tar: 0.000749 
l0: 0.000682, l1: 0.000626, l2: 0.000691, l3: 0.000775, l4: 0.001007, l5: 0.001395, l6: 0.002666

[epoch:  78/1000, batch:   276/ 1052, ite: 20320] train loss: 0.008412, tar: 0.000749 
l0: 0.001259, l1: 0.001197, l2: 0.001623, l3: 0.001331, l4: 0.001899, l5: 0.002927, l6: 0.007841

[epoch:  78/1000, batch:   356/ 1052, ite: 20340] train loss: 0.008411, tar: 0.000749 
l0: 0.001317, l1: 0.001218, l2: 0.001290, l3: 0.001510, l4: 0.001819, l5: 0.002279, l6: 0.003608

[epoch:  78/1000, batch:   436/ 1052, ite: 20360] train loss: 0.008414, tar: 0.000749 
l0: 0.000506, l1: 0.000467, l2: 0.000538, l3: 0.000743, l4: 0.000827, l5: 0.001030, l6: 0.001402

[epoch:  78/1000, batch:   516/ 1052, ite: 20380] train loss: 0.008410, tar: 0.000748 
l0: 0.001173, l1: 0.001180, l2: 0.001262, l3: 0.001071, l4: 0.001100, l5: 0.001603, l6: 0.002193

[epoch:  78/1000, batch:   596/ 1052, ite: 20400] train loss: 0.008411, tar: 0.000748 
l0: 0.000988, l1: 0.001093, l2: 0.001033, l3: 0.001136, l4: 0.001112, l5: 0.001451, l6: 0.001729

[epoch:  78/1000, batch:   676/ 1052, ite: 20420] train loss: 0.008407, tar: 0.000748 
l0: 0.001275, l1: 0.001243, l2: 0.001229, l3: 0.001263, l4: 0.001390, l5: 0.002345, l6: 0.004723

[epoch:  78/1000, batch:   756/ 1052, ite: 20440] train loss: 0.008405, tar: 0.000747 
l0: 0.000290, l1: 0.000302, l2: 0.000303, l3: 0.000337, l4: 0.000492, l5: 0.001012, l6: 0.001596

[epoch:  78/1000, batch:   836/ 1052, ite: 20460] train loss: 0.008403, tar: 0.000747 
l0: 0.000553, l1: 0.000541, l2: 0.000637, l3: 0.000604, l4: 0.000801, l5: 0.001804, l6: 0.002204

[epoch:  78/1000, batch:   916/ 1052, ite: 20480] train loss: 0.008400, tar: 0.000747 
l0: 0.000709, l1: 0.000914, l2: 0.000818, l3: 0.000576, l4: 0.000844, l5: 0.001282, l6: 0.000947

[epoch:  78/1000, batch:   996/ 1052, ite: 20500] train loss: 0.008396, tar: 0.000746 
[Epoch 78/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000487, l1: 0.000596, l2: 0.000461, l3: 0.000587, l4: 0.000649, l5: 0.001117, l6: 0.002683

[epoch:  79/1000, batch:    24/ 1052, ite: 20520] train loss: 0.008394, tar: 0.000746 
l0: 0.000820, l1: 0.000811, l2: 0.000797, l3: 0.000848, l4: 0.001008, l5: 0.001206, l6: 0.002512

[epoch:  79/1000, batch:   104/ 1052, ite: 20540] train loss: 0.008391, tar: 0.000746 
l0: 0.000835, l1: 0.000886, l2: 0.000812, l3: 0.000782, l4: 0.001090, l5: 0.001484, l6: 0.002462

[epoch:  79/1000, batch:   184/ 1052, ite: 20560] train loss: 0.008389, tar: 0.000745 
l0: 0.000376, l1: 0.000379, l2: 0.000334, l3: 0.000422, l4: 0.000615, l5: 0.001246, l6: 0.001974

[epoch:  79/1000, batch:   264/ 1052, ite: 20580] train loss: 0.008384, tar: 0.000745 
l0: 0.000365, l1: 0.000376, l2: 0.000330, l3: 0.000368, l4: 0.000411, l5: 0.000797, l6: 0.001653

[epoch:  79/1000, batch:   344/ 1052, ite: 20600] train loss: 0.008382, tar: 0.000745 
l0: 0.000543, l1: 0.000552, l2: 0.000644, l3: 0.000674, l4: 0.000734, l5: 0.001908, l6: 0.002976

[epoch:  79/1000, batch:   424/ 1052, ite: 20620] train loss: 0.008381, tar: 0.000744 
l0: 0.001429, l1: 0.001590, l2: 0.001134, l3: 0.001305, l4: 0.001212, l5: 0.002147, l6: 0.003466

[epoch:  79/1000, batch:   504/ 1052, ite: 20640] train loss: 0.008379, tar: 0.000744 
l0: 0.000446, l1: 0.000449, l2: 0.000436, l3: 0.000489, l4: 0.000837, l5: 0.001042, l6: 0.002175

[epoch:  79/1000, batch:   584/ 1052, ite: 20660] train loss: 0.008375, tar: 0.000744 
l0: 0.000751, l1: 0.000758, l2: 0.000836, l3: 0.000810, l4: 0.000933, l5: 0.001369, l6: 0.002186

[epoch:  79/1000, batch:   664/ 1052, ite: 20680] train loss: 0.008374, tar: 0.000744 
l0: 0.000260, l1: 0.000264, l2: 0.000285, l3: 0.000338, l4: 0.000419, l5: 0.000935, l6: 0.000973

[epoch:  79/1000, batch:   744/ 1052, ite: 20700] train loss: 0.008370, tar: 0.000743 
l0: 0.001314, l1: 0.001328, l2: 0.002722, l3: 0.001296, l4: 0.001224, l5: 0.002915, l6: 0.003316

[epoch:  79/1000, batch:   824/ 1052, ite: 20720] train loss: 0.008371, tar: 0.000743 
l0: 0.000747, l1: 0.000753, l2: 0.000776, l3: 0.000843, l4: 0.001119, l5: 0.001973, l6: 0.002974

[epoch:  79/1000, batch:   904/ 1052, ite: 20740] train loss: 0.008368, tar: 0.000743 
l0: 0.000476, l1: 0.000482, l2: 0.000518, l3: 0.000535, l4: 0.000704, l5: 0.001141, l6: 0.001719

[epoch:  79/1000, batch:   984/ 1052, ite: 20760] train loss: 0.008366, tar: 0.000743 
[Epoch 79/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000286, l1: 0.000281, l2: 0.000283, l3: 0.000364, l4: 0.000490, l5: 0.000925, l6: 0.001472

[epoch:  80/1000, batch:    12/ 1052, ite: 20780] train loss: 0.008367, tar: 0.000743 
l0: 0.000463, l1: 0.000480, l2: 0.000454, l3: 0.000598, l4: 0.000657, l5: 0.000913, l6: 0.001921

[epoch:  80/1000, batch:    92/ 1052, ite: 20800] train loss: 0.008366, tar: 0.000743 
l0: 0.000424, l1: 0.000421, l2: 0.000427, l3: 0.000498, l4: 0.000738, l5: 0.001413, l6: 0.002318

[epoch:  80/1000, batch:   172/ 1052, ite: 20820] train loss: 0.008364, tar: 0.000742 
l0: 0.000424, l1: 0.000429, l2: 0.000430, l3: 0.000450, l4: 0.000616, l5: 0.001182, l6: 0.001818

[epoch:  80/1000, batch:   252/ 1052, ite: 20840] train loss: 0.008363, tar: 0.000742 
l0: 0.000740, l1: 0.000792, l2: 0.000672, l3: 0.000733, l4: 0.000873, l5: 0.001766, l6: 0.001807

[epoch:  80/1000, batch:   332/ 1052, ite: 20860] train loss: 0.008359, tar: 0.000742 
l0: 0.000593, l1: 0.000621, l2: 0.000641, l3: 0.000737, l4: 0.000831, l5: 0.001080, l6: 0.002545

[epoch:  80/1000, batch:   412/ 1052, ite: 20880] train loss: 0.008356, tar: 0.000742 
l0: 0.000288, l1: 0.000298, l2: 0.000263, l3: 0.000353, l4: 0.000529, l5: 0.000704, l6: 0.001233

[epoch:  80/1000, batch:   492/ 1052, ite: 20900] train loss: 0.008354, tar: 0.000741 
l0: 0.000527, l1: 0.000530, l2: 0.000570, l3: 0.000567, l4: 0.000774, l5: 0.001285, l6: 0.001518

[epoch:  80/1000, batch:   572/ 1052, ite: 20920] train loss: 0.008351, tar: 0.000741 
l0: 0.000560, l1: 0.000561, l2: 0.000614, l3: 0.000609, l4: 0.000784, l5: 0.001463, l6: 0.002473

[epoch:  80/1000, batch:   652/ 1052, ite: 20940] train loss: 0.008348, tar: 0.000741 
l0: 0.000383, l1: 0.000415, l2: 0.000380, l3: 0.000449, l4: 0.000611, l5: 0.000877, l6: 0.001611

[epoch:  80/1000, batch:   732/ 1052, ite: 20960] train loss: 0.008346, tar: 0.000741 
l0: 0.000562, l1: 0.000556, l2: 0.000618, l3: 0.000769, l4: 0.001048, l5: 0.001946, l6: 0.002594

[epoch:  80/1000, batch:   812/ 1052, ite: 20980] train loss: 0.008344, tar: 0.000740 
l0: 0.000312, l1: 0.000305, l2: 0.000326, l3: 0.000417, l4: 0.000517, l5: 0.001165, l6: 0.001917

[epoch:  80/1000, batch:   892/ 1052, ite: 21000] train loss: 0.008341, tar: 0.000740 
l0: 0.000408, l1: 0.000421, l2: 0.000424, l3: 0.000433, l4: 0.000718, l5: 0.000925, l6: 0.001742

[epoch:  80/1000, batch:   972/ 1052, ite: 21020] train loss: 0.008343, tar: 0.000740 
l0: 0.001044, l1: 0.001352, l2: 0.000388, l3: 0.000394, l4: 0.000701, l5: 0.000939, l6: 0.001394

[epoch:  80/1000, batch:  1052/ 1052, ite: 21040] train loss: 0.008347, tar: 0.000741 
[Epoch 80/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000835, l1: 0.000818, l2: 0.000789, l3: 0.001187, l4: 0.001532, l5: 0.002082, l6: 0.003475

[epoch:  81/1000, batch:    80/ 1052, ite: 21060] train loss: 0.009103, tar: 0.000876 
l0: 0.001244, l1: 0.001226, l2: 0.001273, l3: 0.001300, l4: 0.001365, l5: 0.001876, l6: 0.002875

[epoch:  81/1000, batch:   160/ 1052, ite: 21080] train loss: 0.008839, tar: 0.000824 
l0: 0.000359, l1: 0.000383, l2: 0.000329, l3: 0.000375, l4: 0.000469, l5: 0.000772, l6: 0.001430

[epoch:  81/1000, batch:   240/ 1052, ite: 21100] train loss: 0.007974, tar: 0.000728 
l0: 0.000408, l1: 0.000399, l2: 0.000368, l3: 0.000461, l4: 0.000640, l5: 0.001523, l6: 0.001676

[epoch:  81/1000, batch:   320/ 1052, ite: 21120] train loss: 0.007930, tar: 0.000715 
l0: 0.000637, l1: 0.000656, l2: 0.000666, l3: 0.000677, l4: 0.000832, l5: 0.001221, l6: 0.001895

[epoch:  81/1000, batch:   400/ 1052, ite: 21140] train loss: 0.008065, tar: 0.000737 
l0: 0.000379, l1: 0.000514, l2: 0.000326, l3: 0.000433, l4: 0.000629, l5: 0.001083, l6: 0.001464

[epoch:  81/1000, batch:   480/ 1052, ite: 21160] train loss: 0.007955, tar: 0.000710 
l0: 0.001121, l1: 0.001146, l2: 0.001186, l3: 0.001202, l4: 0.002221, l5: 0.002859, l6: 0.004820

[epoch:  81/1000, batch:   560/ 1052, ite: 21180] train loss: 0.008384, tar: 0.000757 
l0: 0.000362, l1: 0.000371, l2: 0.000381, l3: 0.000421, l4: 0.000605, l5: 0.001025, l6: 0.001711

[epoch:  81/1000, batch:   640/ 1052, ite: 21200] train loss: 0.008432, tar: 0.000758 
l0: 0.000958, l1: 0.000952, l2: 0.001388, l3: 0.001141, l4: 0.001543, l5: 0.001964, l6: 0.002809

[epoch:  81/1000, batch:   720/ 1052, ite: 21220] train loss: 0.008365, tar: 0.000751 
l0: 0.000649, l1: 0.000635, l2: 0.000646, l3: 0.000743, l4: 0.001011, l5: 0.001664, l6: 0.003313

[epoch:  81/1000, batch:   800/ 1052, ite: 21240] train loss: 0.008133, tar: 0.000729 
l0: 0.000490, l1: 0.000462, l2: 0.000665, l3: 0.000732, l4: 0.000920, l5: 0.001498, l6: 0.001959

[epoch:  81/1000, batch:   880/ 1052, ite: 21260] train loss: 0.008153, tar: 0.000726 
l0: 0.000595, l1: 0.000576, l2: 0.000592, l3: 0.000692, l4: 0.001188, l5: 0.002295, l6: 0.002573

[epoch:  81/1000, batch:   960/ 1052, ite: 21280] train loss: 0.008051, tar: 0.000713 
l0: 0.000692, l1: 0.000685, l2: 0.000754, l3: 0.000926, l4: 0.001368, l5: 0.001591, l6: 0.003291

[epoch:  81/1000, batch:  1040/ 1052, ite: 21300] train loss: 0.008043, tar: 0.000710 
[Epoch 81/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000656, l1: 0.000634, l2: 0.000675, l3: 0.000743, l4: 0.001032, l5: 0.001834, l6: 0.002632

[epoch:  82/1000, batch:    68/ 1052, ite: 21320] train loss: 0.007909, tar: 0.000694 
l0: 0.000835, l1: 0.000861, l2: 0.000835, l3: 0.001001, l4: 0.001331, l5: 0.001676, l6: 0.003295

[epoch:  82/1000, batch:   148/ 1052, ite: 21340] train loss: 0.007987, tar: 0.000698 
l0: 0.000751, l1: 0.000784, l2: 0.000794, l3: 0.000941, l4: 0.001779, l5: 0.001478, l6: 0.002084

[epoch:  82/1000, batch:   228/ 1052, ite: 21360] train loss: 0.007888, tar: 0.000687 
l0: 0.000872, l1: 0.000825, l2: 0.001355, l3: 0.000814, l4: 0.001169, l5: 0.002318, l6: 0.003873

[epoch:  82/1000, batch:   308/ 1052, ite: 21380] train loss: 0.007780, tar: 0.000676 
l0: 0.001297, l1: 0.001260, l2: 0.001249, l3: 0.001611, l4: 0.001961, l5: 0.003003, l6: 0.003261

[epoch:  82/1000, batch:   388/ 1052, ite: 21400] train loss: 0.007744, tar: 0.000672 
l0: 0.000366, l1: 0.000378, l2: 0.000376, l3: 0.000430, l4: 0.000653, l5: 0.001180, l6: 0.001782

[epoch:  82/1000, batch:   468/ 1052, ite: 21420] train loss: 0.007718, tar: 0.000671 
l0: 0.000514, l1: 0.000476, l2: 0.000535, l3: 0.000593, l4: 0.001140, l5: 0.002220, l6: 0.002420

[epoch:  82/1000, batch:   548/ 1052, ite: 21440] train loss: 0.007700, tar: 0.000671 
l0: 0.000506, l1: 0.000506, l2: 0.000529, l3: 0.000584, l4: 0.000896, l5: 0.001322, l6: 0.002121

[epoch:  82/1000, batch:   628/ 1052, ite: 21460] train loss: 0.007664, tar: 0.000666 
l0: 0.000387, l1: 0.000379, l2: 0.000407, l3: 0.000453, l4: 0.000686, l5: 0.000895, l6: 0.001882

[epoch:  82/1000, batch:   708/ 1052, ite: 21480] train loss: 0.007610, tar: 0.000661 
l0: 0.000303, l1: 0.000296, l2: 0.000312, l3: 0.000447, l4: 0.000663, l5: 0.001018, l6: 0.001406

[epoch:  82/1000, batch:   788/ 1052, ite: 21500] train loss: 0.007613, tar: 0.000659 
l0: 0.000380, l1: 0.000411, l2: 0.000437, l3: 0.000452, l4: 0.000586, l5: 0.000812, l6: 0.001375

[epoch:  82/1000, batch:   868/ 1052, ite: 21520] train loss: 0.007627, tar: 0.000660 
l0: 0.000511, l1: 0.000523, l2: 0.000513, l3: 0.000539, l4: 0.000794, l5: 0.001313, l6: 0.002656

[epoch:  82/1000, batch:   948/ 1052, ite: 21540] train loss: 0.007615, tar: 0.000658 
l0: 0.000519, l1: 0.000527, l2: 0.000547, l3: 0.000562, l4: 0.000730, l5: 0.001188, l6: 0.002451

[epoch:  82/1000, batch:  1028/ 1052, ite: 21560] train loss: 0.007585, tar: 0.000654 
[Epoch 82/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000478, l1: 0.000489, l2: 0.000565, l3: 0.000861, l4: 0.000860, l5: 0.001152, l6: 0.001189

[epoch:  83/1000, batch:    56/ 1052, ite: 21580] train loss: 0.007697, tar: 0.000669 
l0: 0.000578, l1: 0.000611, l2: 0.000639, l3: 0.000760, l4: 0.000953, l5: 0.001122, l6: 0.001517

[epoch:  83/1000, batch:   136/ 1052, ite: 21600] train loss: 0.007706, tar: 0.000670 
l0: 0.000767, l1: 0.000782, l2: 0.000853, l3: 0.000889, l4: 0.001153, l5: 0.001578, l6: 0.003105

[epoch:  83/1000, batch:   216/ 1052, ite: 21620] train loss: 0.007740, tar: 0.000671 
l0: 0.000894, l1: 0.000932, l2: 0.001271, l3: 0.001566, l4: 0.003135, l5: 0.002416, l6: 0.003708

[epoch:  83/1000, batch:   296/ 1052, ite: 21640] train loss: 0.007866, tar: 0.000680 
l0: 0.000687, l1: 0.000713, l2: 0.000779, l3: 0.000872, l4: 0.001057, l5: 0.001175, l6: 0.002266

[epoch:  83/1000, batch:   376/ 1052, ite: 21660] train loss: 0.007854, tar: 0.000678 
l0: 0.000500, l1: 0.000514, l2: 0.000526, l3: 0.000623, l4: 0.000705, l5: 0.001396, l6: 0.001731

[epoch:  83/1000, batch:   456/ 1052, ite: 21680] train loss: 0.007854, tar: 0.000679 
l0: 0.001007, l1: 0.001104, l2: 0.001015, l3: 0.001013, l4: 0.001107, l5: 0.001775, l6: 0.003424

[epoch:  83/1000, batch:   536/ 1052, ite: 21700] train loss: 0.007833, tar: 0.000677 
l0: 0.000444, l1: 0.000449, l2: 0.000472, l3: 0.000599, l4: 0.000692, l5: 0.000806, l6: 0.001647

[epoch:  83/1000, batch:   616/ 1052, ite: 21720] train loss: 0.007854, tar: 0.000681 
l0: 0.001043, l1: 0.001121, l2: 0.001250, l3: 0.000866, l4: 0.000820, l5: 0.001366, l6: 0.001429

[epoch:  83/1000, batch:   696/ 1052, ite: 21740] train loss: 0.007822, tar: 0.000678 
l0: 0.001953, l1: 0.002053, l2: 0.002040, l3: 0.002227, l4: 0.002598, l5: 0.004327, l6: 0.005044

[epoch:  83/1000, batch:   776/ 1052, ite: 21760] train loss: 0.007831, tar: 0.000678 
l0: 0.000968, l1: 0.000917, l2: 0.001356, l3: 0.001466, l4: 0.002068, l5: 0.002086, l6: 0.002838

[epoch:  83/1000, batch:   856/ 1052, ite: 21780] train loss: 0.007840, tar: 0.000679 
l0: 0.000441, l1: 0.000469, l2: 0.000515, l3: 0.000529, l4: 0.000645, l5: 0.001203, l6: 0.002124

[epoch:  83/1000, batch:   936/ 1052, ite: 21800] train loss: 0.007805, tar: 0.000674 
l0: 0.000905, l1: 0.001119, l2: 0.000868, l3: 0.001018, l4: 0.000779, l5: 0.001285, l6: 0.002295

[epoch:  83/1000, batch:  1016/ 1052, ite: 21820] train loss: 0.007834, tar: 0.000681 
[Epoch 83/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000788, l1: 0.000748, l2: 0.000789, l3: 0.000821, l4: 0.001181, l5: 0.002243, l6: 0.003243

[epoch:  84/1000, batch:    44/ 1052, ite: 21840] train loss: 0.007812, tar: 0.000678 
l0: 0.000481, l1: 0.000497, l2: 0.000573, l3: 0.000579, l4: 0.000709, l5: 0.001199, l6: 0.001565

[epoch:  84/1000, batch:   124/ 1052, ite: 21860] train loss: 0.007798, tar: 0.000679 
l0: 0.000342, l1: 0.000335, l2: 0.000329, l3: 0.000388, l4: 0.000536, l5: 0.001170, l6: 0.001859

[epoch:  84/1000, batch:   204/ 1052, ite: 21880] train loss: 0.007784, tar: 0.000678 
l0: 0.001162, l1: 0.001140, l2: 0.001135, l3: 0.001189, l4: 0.001510, l5: 0.002263, l6: 0.004166

[epoch:  84/1000, batch:   284/ 1052, ite: 21900] train loss: 0.007778, tar: 0.000676 
l0: 0.000393, l1: 0.000398, l2: 0.000384, l3: 0.000464, l4: 0.000547, l5: 0.001198, l6: 0.001790

[epoch:  84/1000, batch:   364/ 1052, ite: 21920] train loss: 0.007799, tar: 0.000677 
l0: 0.000513, l1: 0.000513, l2: 0.000463, l3: 0.000495, l4: 0.000747, l5: 0.001102, l6: 0.001535

[epoch:  84/1000, batch:   444/ 1052, ite: 21940] train loss: 0.007815, tar: 0.000677 
l0: 0.000329, l1: 0.000336, l2: 0.000330, l3: 0.000362, l4: 0.000862, l5: 0.001062, l6: 0.001983

[epoch:  84/1000, batch:   524/ 1052, ite: 21960] train loss: 0.007789, tar: 0.000674 
l0: 0.000377, l1: 0.000407, l2: 0.000478, l3: 0.000409, l4: 0.000508, l5: 0.001501, l6: 0.001575

[epoch:  84/1000, batch:   604/ 1052, ite: 21980] train loss: 0.007774, tar: 0.000673 
l0: 0.000233, l1: 0.000238, l2: 0.000221, l3: 0.000264, l4: 0.000460, l5: 0.000577, l6: 0.000853

[epoch:  84/1000, batch:   684/ 1052, ite: 22000] train loss: 0.007778, tar: 0.000675 
l0: 0.000424, l1: 0.000413, l2: 0.000498, l3: 0.000488, l4: 0.000728, l5: 0.001138, l6: 0.001983

[epoch:  84/1000, batch:   764/ 1052, ite: 22020] train loss: 0.007746, tar: 0.000671 
l0: 0.000775, l1: 0.000796, l2: 0.000846, l3: 0.000884, l4: 0.000984, l5: 0.001931, l6: 0.002447

[epoch:  84/1000, batch:   844/ 1052, ite: 22040] train loss: 0.007792, tar: 0.000675 
l0: 0.000392, l1: 0.000409, l2: 0.000394, l3: 0.000513, l4: 0.000758, l5: 0.001306, l6: 0.001971

[epoch:  84/1000, batch:   924/ 1052, ite: 22060] train loss: 0.007797, tar: 0.000675 
l0: 0.000644, l1: 0.000679, l2: 0.000697, l3: 0.000816, l4: 0.000711, l5: 0.001225, l6: 0.001884

[epoch:  84/1000, batch:  1004/ 1052, ite: 22080] train loss: 0.007795, tar: 0.000676 
[Epoch 84/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000591, l1: 0.000593, l2: 0.000633, l3: 0.000558, l4: 0.000720, l5: 0.001113, l6: 0.001870

[epoch:  85/1000, batch:    32/ 1052, ite: 22100] train loss: 0.007782, tar: 0.000675 
l0: 0.000367, l1: 0.000373, l2: 0.000373, l3: 0.000377, l4: 0.000625, l5: 0.001163, l6: 0.001622

[epoch:  85/1000, batch:   112/ 1052, ite: 22120] train loss: 0.007767, tar: 0.000674 
l0: 0.000535, l1: 0.000518, l2: 0.000637, l3: 0.000789, l4: 0.001006, l5: 0.001649, l6: 0.002006

[epoch:  85/1000, batch:   192/ 1052, ite: 22140] train loss: 0.007766, tar: 0.000673 
l0: 0.000435, l1: 0.000430, l2: 0.000457, l3: 0.000538, l4: 0.000665, l5: 0.001332, l6: 0.002532

[epoch:  85/1000, batch:   272/ 1052, ite: 22160] train loss: 0.007773, tar: 0.000674 
l0: 0.000312, l1: 0.000316, l2: 0.000451, l3: 0.000381, l4: 0.000503, l5: 0.000753, l6: 0.001143

[epoch:  85/1000, batch:   352/ 1052, ite: 22180] train loss: 0.007761, tar: 0.000672 
l0: 0.000899, l1: 0.000967, l2: 0.000818, l3: 0.001109, l4: 0.001306, l5: 0.002491, l6: 0.003547

[epoch:  85/1000, batch:   432/ 1052, ite: 22200] train loss: 0.007749, tar: 0.000671 
l0: 0.000393, l1: 0.000387, l2: 0.000390, l3: 0.000385, l4: 0.000469, l5: 0.001110, l6: 0.001551

[epoch:  85/1000, batch:   512/ 1052, ite: 22220] train loss: 0.007731, tar: 0.000668 
l0: 0.000520, l1: 0.000510, l2: 0.000534, l3: 0.000527, l4: 0.000856, l5: 0.001021, l6: 0.001937

[epoch:  85/1000, batch:   592/ 1052, ite: 22240] train loss: 0.007698, tar: 0.000665 
l0: 0.000443, l1: 0.000426, l2: 0.000512, l3: 0.000624, l4: 0.000691, l5: 0.001139, l6: 0.002314

[epoch:  85/1000, batch:   672/ 1052, ite: 22260] train loss: 0.007702, tar: 0.000665 
l0: 0.000320, l1: 0.000312, l2: 0.000348, l3: 0.000466, l4: 0.000757, l5: 0.001412, l6: 0.002191

[epoch:  85/1000, batch:   752/ 1052, ite: 22280] train loss: 0.007706, tar: 0.000666 
l0: 0.000546, l1: 0.000534, l2: 0.000564, l3: 0.000650, l4: 0.000878, l5: 0.001431, l6: 0.001478

[epoch:  85/1000, batch:   832/ 1052, ite: 22300] train loss: 0.007695, tar: 0.000664 
l0: 0.000645, l1: 0.000680, l2: 0.000701, l3: 0.000743, l4: 0.001137, l5: 0.001552, l6: 0.002466

[epoch:  85/1000, batch:   912/ 1052, ite: 22320] train loss: 0.007698, tar: 0.000664 
l0: 0.000351, l1: 0.000336, l2: 0.000349, l3: 0.000459, l4: 0.000757, l5: 0.001147, l6: 0.002425

[epoch:  85/1000, batch:   992/ 1052, ite: 22340] train loss: 0.007681, tar: 0.000663 
[Epoch 85/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000397, l1: 0.000410, l2: 0.000394, l3: 0.000518, l4: 0.000786, l5: 0.001034, l6: 0.001141

[epoch:  86/1000, batch:    20/ 1052, ite: 22360] train loss: 0.007710, tar: 0.000667 
l0: 0.001373, l1: 0.001603, l2: 0.001475, l3: 0.001349, l4: 0.001518, l5: 0.002428, l6: 0.003243

[epoch:  86/1000, batch:   100/ 1052, ite: 22380] train loss: 0.007684, tar: 0.000665 
l0: 0.000937, l1: 0.000907, l2: 0.001007, l3: 0.001073, l4: 0.000976, l5: 0.001244, l6: 0.001884

[epoch:  86/1000, batch:   180/ 1052, ite: 22400] train loss: 0.007680, tar: 0.000665 
l0: 0.000408, l1: 0.000407, l2: 0.000417, l3: 0.000466, l4: 0.000687, l5: 0.001317, l6: 0.001844

[epoch:  86/1000, batch:   260/ 1052, ite: 22420] train loss: 0.007658, tar: 0.000662 
l0: 0.000903, l1: 0.000905, l2: 0.001174, l3: 0.000915, l4: 0.001303, l5: 0.001849, l6: 0.002726

[epoch:  86/1000, batch:   340/ 1052, ite: 22440] train loss: 0.007665, tar: 0.000662 
l0: 0.000818, l1: 0.000822, l2: 0.000923, l3: 0.000960, l4: 0.001060, l5: 0.001655, l6: 0.002705

[epoch:  86/1000, batch:   420/ 1052, ite: 22460] train loss: 0.007658, tar: 0.000662 
l0: 0.000602, l1: 0.000615, l2: 0.000643, l3: 0.000736, l4: 0.001083, l5: 0.001898, l6: 0.002807

[epoch:  86/1000, batch:   500/ 1052, ite: 22480] train loss: 0.007663, tar: 0.000662 
l0: 0.000772, l1: 0.000778, l2: 0.000800, l3: 0.000755, l4: 0.001013, l5: 0.001796, l6: 0.003051

[epoch:  86/1000, batch:   580/ 1052, ite: 22500] train loss: 0.007661, tar: 0.000662 
l0: 0.000415, l1: 0.000430, l2: 0.000429, l3: 0.000473, l4: 0.000572, l5: 0.001305, l6: 0.001424

[epoch:  86/1000, batch:   660/ 1052, ite: 22520] train loss: 0.007670, tar: 0.000661 
l0: 0.000507, l1: 0.000551, l2: 0.000562, l3: 0.000508, l4: 0.000663, l5: 0.001276, l6: 0.001382

[epoch:  86/1000, batch:   740/ 1052, ite: 22540] train loss: 0.007675, tar: 0.000662 
l0: 0.000542, l1: 0.000554, l2: 0.000524, l3: 0.000674, l4: 0.000722, l5: 0.001156, l6: 0.001167

[epoch:  86/1000, batch:   820/ 1052, ite: 22560] train loss: 0.007664, tar: 0.000661 
l0: 0.000671, l1: 0.000625, l2: 0.000680, l3: 0.000749, l4: 0.001101, l5: 0.002091, l6: 0.003265

[epoch:  86/1000, batch:   900/ 1052, ite: 22580] train loss: 0.007656, tar: 0.000660 
l0: 0.000856, l1: 0.000810, l2: 0.000915, l3: 0.001016, l4: 0.001562, l5: 0.002451, l6: 0.003052

[epoch:  86/1000, batch:   980/ 1052, ite: 22600] train loss: 0.007653, tar: 0.000659 
[Epoch 86/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000516, l1: 0.000537, l2: 0.000543, l3: 0.000615, l4: 0.000641, l5: 0.000823, l6: 0.001984

[epoch:  87/1000, batch:     8/ 1052, ite: 22620] train loss: 0.007649, tar: 0.000659 
l0: 0.000823, l1: 0.000850, l2: 0.000834, l3: 0.000821, l4: 0.000926, l5: 0.001402, l6: 0.002030

[epoch:  87/1000, batch:    88/ 1052, ite: 22640] train loss: 0.007634, tar: 0.000657 
l0: 0.000490, l1: 0.000469, l2: 0.000513, l3: 0.000567, l4: 0.000662, l5: 0.001218, l6: 0.001484

[epoch:  87/1000, batch:   168/ 1052, ite: 22660] train loss: 0.007627, tar: 0.000656 
l0: 0.000778, l1: 0.000797, l2: 0.000800, l3: 0.000785, l4: 0.001084, l5: 0.001369, l6: 0.002667

[epoch:  87/1000, batch:   248/ 1052, ite: 22680] train loss: 0.007643, tar: 0.000659 
l0: 0.000316, l1: 0.000316, l2: 0.000288, l3: 0.000416, l4: 0.000436, l5: 0.000764, l6: 0.000893

[epoch:  87/1000, batch:   328/ 1052, ite: 22700] train loss: 0.007623, tar: 0.000657 
l0: 0.000371, l1: 0.000391, l2: 0.000378, l3: 0.000431, l4: 0.000484, l5: 0.000966, l6: 0.001855

[epoch:  87/1000, batch:   408/ 1052, ite: 22720] train loss: 0.007616, tar: 0.000656 
l0: 0.000527, l1: 0.000530, l2: 0.000512, l3: 0.000555, l4: 0.000756, l5: 0.001252, l6: 0.002205

[epoch:  87/1000, batch:   488/ 1052, ite: 22740] train loss: 0.007612, tar: 0.000656 
l0: 0.000351, l1: 0.000344, l2: 0.000347, l3: 0.000459, l4: 0.000670, l5: 0.000974, l6: 0.001720

[epoch:  87/1000, batch:   568/ 1052, ite: 22760] train loss: 0.007601, tar: 0.000654 
l0: 0.000437, l1: 0.000410, l2: 0.000446, l3: 0.000530, l4: 0.000918, l5: 0.001450, l6: 0.002456

[epoch:  87/1000, batch:   648/ 1052, ite: 22780] train loss: 0.007596, tar: 0.000654 
l0: 0.000817, l1: 0.000829, l2: 0.000833, l3: 0.000945, l4: 0.001100, l5: 0.001536, l6: 0.002759

[epoch:  87/1000, batch:   728/ 1052, ite: 22800] train loss: 0.007597, tar: 0.000654 
l0: 0.000271, l1: 0.000272, l2: 0.000287, l3: 0.000310, l4: 0.000410, l5: 0.000844, l6: 0.001303

[epoch:  87/1000, batch:   808/ 1052, ite: 22820] train loss: 0.007594, tar: 0.000653 
l0: 0.000407, l1: 0.000407, l2: 0.000432, l3: 0.000448, l4: 0.000507, l5: 0.001041, l6: 0.002063

[epoch:  87/1000, batch:   888/ 1052, ite: 22840] train loss: 0.007581, tar: 0.000652 
l0: 0.000651, l1: 0.000631, l2: 0.000686, l3: 0.000773, l4: 0.001151, l5: 0.002448, l6: 0.003658

[epoch:  87/1000, batch:   968/ 1052, ite: 22860] train loss: 0.007584, tar: 0.000651 
l0: 0.000386, l1: 0.000422, l2: 0.000410, l3: 0.000505, l4: 0.000535, l5: 0.001011, l6: 0.001429

[epoch:  87/1000, batch:  1048/ 1052, ite: 22880] train loss: 0.007571, tar: 0.000650 
[Epoch 87/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000581, l1: 0.000587, l2: 0.000638, l3: 0.000713, l4: 0.000803, l5: 0.001186, l6: 0.001828

[epoch:  88/1000, batch:    76/ 1052, ite: 22900] train loss: 0.007559, tar: 0.000649 
l0: 0.000887, l1: 0.000850, l2: 0.000905, l3: 0.001038, l4: 0.001310, l5: 0.001892, l6: 0.003148

[epoch:  88/1000, batch:   156/ 1052, ite: 22920] train loss: 0.007555, tar: 0.000649 
l0: 0.000878, l1: 0.000734, l2: 0.000714, l3: 0.000876, l4: 0.001378, l5: 0.001762, l6: 0.001985

[epoch:  88/1000, batch:   236/ 1052, ite: 22940] train loss: 0.007558, tar: 0.000649 
l0: 0.000412, l1: 0.000327, l2: 0.000418, l3: 0.000531, l4: 0.000877, l5: 0.001040, l6: 0.002219

[epoch:  88/1000, batch:   316/ 1052, ite: 22960] train loss: 0.007552, tar: 0.000648 
l0: 0.000357, l1: 0.000367, l2: 0.000420, l3: 0.000474, l4: 0.000447, l5: 0.000896, l6: 0.001657

[epoch:  88/1000, batch:   396/ 1052, ite: 22980] train loss: 0.007537, tar: 0.000646 
l0: 0.000307, l1: 0.000324, l2: 0.000329, l3: 0.000312, l4: 0.000754, l5: 0.001210, l6: 0.001797

[epoch:  88/1000, batch:   476/ 1052, ite: 23000] train loss: 0.007531, tar: 0.000645 
l0: 0.000282, l1: 0.000310, l2: 0.000286, l3: 0.000392, l4: 0.000578, l5: 0.000806, l6: 0.001141

[epoch:  88/1000, batch:   556/ 1052, ite: 23020] train loss: 0.007520, tar: 0.000644 
l0: 0.000408, l1: 0.000416, l2: 0.000426, l3: 0.000416, l4: 0.000557, l5: 0.000846, l6: 0.001756

[epoch:  88/1000, batch:   636/ 1052, ite: 23040] train loss: 0.007504, tar: 0.000642 
l0: 0.000427, l1: 0.000424, l2: 0.000434, l3: 0.000595, l4: 0.000847, l5: 0.001280, l6: 0.002838

[epoch:  88/1000, batch:   716/ 1052, ite: 23060] train loss: 0.007517, tar: 0.000643 
l0: 0.000367, l1: 0.000370, l2: 0.000480, l3: 0.000528, l4: 0.000507, l5: 0.000905, l6: 0.001814

[epoch:  88/1000, batch:   796/ 1052, ite: 23080] train loss: 0.007516, tar: 0.000643 
l0: 0.000454, l1: 0.000428, l2: 0.000544, l3: 0.000475, l4: 0.000642, l5: 0.001172, l6: 0.002322

[epoch:  88/1000, batch:   876/ 1052, ite: 23100] train loss: 0.007520, tar: 0.000643 
l0: 0.000232, l1: 0.000231, l2: 0.000256, l3: 0.000352, l4: 0.000356, l5: 0.000904, l6: 0.000925

[epoch:  88/1000, batch:   956/ 1052, ite: 23120] train loss: 0.007512, tar: 0.000643 
l0: 0.000338, l1: 0.000331, l2: 0.000352, l3: 0.000424, l4: 0.000682, l5: 0.001086, l6: 0.001654

[epoch:  88/1000, batch:  1036/ 1052, ite: 23140] train loss: 0.007503, tar: 0.000642 
[Epoch 88/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.001512, l1: 0.001607, l2: 0.001561, l3: 0.001676, l4: 0.001819, l5: 0.002800, l6: 0.003619

[epoch:  89/1000, batch:    64/ 1052, ite: 23160] train loss: 0.007506, tar: 0.000642 
l0: 0.000408, l1: 0.000405, l2: 0.000419, l3: 0.000485, l4: 0.000783, l5: 0.001057, l6: 0.002627

[epoch:  89/1000, batch:   144/ 1052, ite: 23180] train loss: 0.007495, tar: 0.000640 
l0: 0.000303, l1: 0.000313, l2: 0.000367, l3: 0.000419, l4: 0.000528, l5: 0.000940, l6: 0.001365

[epoch:  89/1000, batch:   224/ 1052, ite: 23200] train loss: 0.007483, tar: 0.000639 
l0: 0.000452, l1: 0.000451, l2: 0.000416, l3: 0.000495, l4: 0.000619, l5: 0.000812, l6: 0.001732

[epoch:  89/1000, batch:   304/ 1052, ite: 23220] train loss: 0.007475, tar: 0.000638 
l0: 0.000566, l1: 0.000577, l2: 0.000639, l3: 0.000722, l4: 0.000725, l5: 0.000981, l6: 0.001274

[epoch:  89/1000, batch:   384/ 1052, ite: 23240] train loss: 0.007468, tar: 0.000637 
l0: 0.000390, l1: 0.000395, l2: 0.000431, l3: 0.000526, l4: 0.000698, l5: 0.001197, l6: 0.001403

[epoch:  89/1000, batch:   464/ 1052, ite: 23260] train loss: 0.007463, tar: 0.000637 
l0: 0.000747, l1: 0.000760, l2: 0.000716, l3: 0.000997, l4: 0.001301, l5: 0.002737, l6: 0.004294

[epoch:  89/1000, batch:   544/ 1052, ite: 23280] train loss: 0.007464, tar: 0.000636 
l0: 0.000678, l1: 0.000667, l2: 0.000710, l3: 0.000725, l4: 0.000846, l5: 0.001080, l6: 0.001360

[epoch:  89/1000, batch:   624/ 1052, ite: 23300] train loss: 0.007451, tar: 0.000635 
l0: 0.000640, l1: 0.000645, l2: 0.000654, l3: 0.000729, l4: 0.001090, l5: 0.002252, l6: 0.003129

[epoch:  89/1000, batch:   704/ 1052, ite: 23320] train loss: 0.007441, tar: 0.000634 
l0: 0.001383, l1: 0.001375, l2: 0.001385, l3: 0.001185, l4: 0.001276, l5: 0.001745, l6: 0.002847

[epoch:  89/1000, batch:   784/ 1052, ite: 23340] train loss: 0.007457, tar: 0.000636 
l0: 0.000458, l1: 0.000456, l2: 0.000490, l3: 0.000546, l4: 0.000948, l5: 0.001518, l6: 0.001816

[epoch:  89/1000, batch:   864/ 1052, ite: 23360] train loss: 0.007453, tar: 0.000635 
l0: 0.000778, l1: 0.000776, l2: 0.000805, l3: 0.000805, l4: 0.000882, l5: 0.001364, l6: 0.002358

[epoch:  89/1000, batch:   944/ 1052, ite: 23380] train loss: 0.007453, tar: 0.000635 
l0: 0.000554, l1: 0.000607, l2: 0.000543, l3: 0.000597, l4: 0.000825, l5: 0.001328, l6: 0.001956

[epoch:  89/1000, batch:  1024/ 1052, ite: 23400] train loss: 0.007457, tar: 0.000635 
[Epoch 89/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000615, l1: 0.000611, l2: 0.000644, l3: 0.000663, l4: 0.000785, l5: 0.001367, l6: 0.002304

[epoch:  90/1000, batch:    52/ 1052, ite: 23420] train loss: 0.007456, tar: 0.000635 
l0: 0.000513, l1: 0.000543, l2: 0.000644, l3: 0.000688, l4: 0.000780, l5: 0.001321, l6: 0.002448

[epoch:  90/1000, batch:   132/ 1052, ite: 23440] train loss: 0.007449, tar: 0.000635 
l0: 0.000260, l1: 0.000255, l2: 0.000257, l3: 0.000355, l4: 0.000459, l5: 0.000874, l6: 0.001016

[epoch:  90/1000, batch:   212/ 1052, ite: 23460] train loss: 0.007444, tar: 0.000634 
l0: 0.000653, l1: 0.000668, l2: 0.000681, l3: 0.000828, l4: 0.001224, l5: 0.001224, l6: 0.001612

[epoch:  90/1000, batch:   292/ 1052, ite: 23480] train loss: 0.007446, tar: 0.000634 
l0: 0.000424, l1: 0.000420, l2: 0.000508, l3: 0.000569, l4: 0.000727, l5: 0.001075, l6: 0.002255

[epoch:  90/1000, batch:   372/ 1052, ite: 23500] train loss: 0.007438, tar: 0.000633 
l0: 0.000880, l1: 0.000915, l2: 0.000911, l3: 0.001133, l4: 0.001504, l5: 0.002032, l6: 0.003065

[epoch:  90/1000, batch:   452/ 1052, ite: 23520] train loss: 0.007430, tar: 0.000632 
l0: 0.000474, l1: 0.000477, l2: 0.000509, l3: 0.000592, l4: 0.000655, l5: 0.001657, l6: 0.002481

[epoch:  90/1000, batch:   532/ 1052, ite: 23540] train loss: 0.007415, tar: 0.000630 
l0: 0.000370, l1: 0.000366, l2: 0.000365, l3: 0.000422, l4: 0.000541, l5: 0.001024, l6: 0.002288

[epoch:  90/1000, batch:   612/ 1052, ite: 23560] train loss: 0.007412, tar: 0.000630 
l0: 0.000650, l1: 0.000676, l2: 0.000765, l3: 0.000805, l4: 0.000907, l5: 0.001307, l6: 0.002333

[epoch:  90/1000, batch:   692/ 1052, ite: 23580] train loss: 0.007410, tar: 0.000630 
l0: 0.000334, l1: 0.000362, l2: 0.000362, l3: 0.000405, l4: 0.000611, l5: 0.000997, l6: 0.001373

[epoch:  90/1000, batch:   772/ 1052, ite: 23600] train loss: 0.007415, tar: 0.000630 
l0: 0.000364, l1: 0.000407, l2: 0.000453, l3: 0.000397, l4: 0.000564, l5: 0.000901, l6: 0.001668

[epoch:  90/1000, batch:   852/ 1052, ite: 23620] train loss: 0.007417, tar: 0.000630 
l0: 0.000561, l1: 0.000562, l2: 0.000796, l3: 0.000714, l4: 0.000940, l5: 0.001047, l6: 0.001943

[epoch:  90/1000, batch:   932/ 1052, ite: 23640] train loss: 0.007415, tar: 0.000630 
l0: 0.000616, l1: 0.000627, l2: 0.000689, l3: 0.000747, l4: 0.000745, l5: 0.001611, l6: 0.001870

[epoch:  90/1000, batch:  1012/ 1052, ite: 23660] train loss: 0.007417, tar: 0.000630 
[Epoch 90/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000679, l1: 0.000670, l2: 0.000715, l3: 0.000734, l4: 0.001145, l5: 0.002104, l6: 0.003287

[epoch:  91/1000, batch:    40/ 1052, ite: 23680] train loss: 0.007425, tar: 0.000630 
l0: 0.000534, l1: 0.000546, l2: 0.000583, l3: 0.000576, l4: 0.000693, l5: 0.001377, l6: 0.002992

[epoch:  91/1000, batch:   120/ 1052, ite: 23700] train loss: 0.007416, tar: 0.000629 
l0: 0.000804, l1: 0.000742, l2: 0.000762, l3: 0.000751, l4: 0.000977, l5: 0.001339, l6: 0.002509

[epoch:  91/1000, batch:   200/ 1052, ite: 23720] train loss: 0.007416, tar: 0.000629 
l0: 0.000799, l1: 0.000843, l2: 0.000858, l3: 0.000950, l4: 0.001355, l5: 0.001889, l6: 0.003288

[epoch:  91/1000, batch:   280/ 1052, ite: 23740] train loss: 0.007415, tar: 0.000629 
l0: 0.000648, l1: 0.000678, l2: 0.000652, l3: 0.000676, l4: 0.000931, l5: 0.001165, l6: 0.002243

[epoch:  91/1000, batch:   360/ 1052, ite: 23760] train loss: 0.007407, tar: 0.000628 
l0: 0.000372, l1: 0.000383, l2: 0.000366, l3: 0.000429, l4: 0.000740, l5: 0.001317, l6: 0.001662

[epoch:  91/1000, batch:   440/ 1052, ite: 23780] train loss: 0.007397, tar: 0.000627 
l0: 0.001468, l1: 0.001513, l2: 0.001669, l3: 0.001504, l4: 0.001101, l5: 0.001540, l6: 0.002315

[epoch:  91/1000, batch:   520/ 1052, ite: 23800] train loss: 0.007406, tar: 0.000629 
l0: 0.000843, l1: 0.000810, l2: 0.000848, l3: 0.000905, l4: 0.001103, l5: 0.001716, l6: 0.002194

[epoch:  91/1000, batch:   600/ 1052, ite: 23820] train loss: 0.007399, tar: 0.000628 
l0: 0.000656, l1: 0.000709, l2: 0.000652, l3: 0.000735, l4: 0.000735, l5: 0.001176, l6: 0.001433

[epoch:  91/1000, batch:   680/ 1052, ite: 23840] train loss: 0.007392, tar: 0.000627 
l0: 0.000538, l1: 0.000541, l2: 0.000575, l3: 0.000618, l4: 0.000879, l5: 0.001592, l6: 0.002439

[epoch:  91/1000, batch:   760/ 1052, ite: 23860] train loss: 0.007391, tar: 0.000627 
l0: 0.000332, l1: 0.000351, l2: 0.000326, l3: 0.000352, l4: 0.000453, l5: 0.000945, l6: 0.001590

[epoch:  91/1000, batch:   840/ 1052, ite: 23880] train loss: 0.007390, tar: 0.000627 
l0: 0.000420, l1: 0.000411, l2: 0.000460, l3: 0.000544, l4: 0.000793, l5: 0.001616, l6: 0.001514

[epoch:  91/1000, batch:   920/ 1052, ite: 23900] train loss: 0.007393, tar: 0.000627 
l0: 0.000399, l1: 0.000405, l2: 0.000422, l3: 0.000467, l4: 0.000593, l5: 0.001069, l6: 0.001983

[epoch:  91/1000, batch:  1000/ 1052, ite: 23920] train loss: 0.007390, tar: 0.000626 
[Epoch 91/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000554, l1: 0.000499, l2: 0.000601, l3: 0.000672, l4: 0.000858, l5: 0.001503, l6: 0.001672

[epoch:  92/1000, batch:    28/ 1052, ite: 23940] train loss: 0.007389, tar: 0.000626 
l0: 0.000378, l1: 0.000367, l2: 0.000434, l3: 0.000416, l4: 0.000513, l5: 0.000864, l6: 0.001126

[epoch:  92/1000, batch:   108/ 1052, ite: 23960] train loss: 0.007394, tar: 0.000626 
l0: 0.000401, l1: 0.000391, l2: 0.000448, l3: 0.000537, l4: 0.000786, l5: 0.001278, l6: 0.001882

[epoch:  92/1000, batch:   188/ 1052, ite: 23980] train loss: 0.007392, tar: 0.000626 
l0: 0.000687, l1: 0.000679, l2: 0.000716, l3: 0.000765, l4: 0.000842, l5: 0.001655, l6: 0.002935

[epoch:  92/1000, batch:   268/ 1052, ite: 24000] train loss: 0.007389, tar: 0.000626 
l0: 0.000426, l1: 0.000443, l2: 0.000451, l3: 0.000519, l4: 0.000582, l5: 0.000954, l6: 0.001347

[epoch:  92/1000, batch:   348/ 1052, ite: 24020] train loss: 0.007381, tar: 0.000625 
l0: 0.000548, l1: 0.000541, l2: 0.000701, l3: 0.000923, l4: 0.001023, l5: 0.002474, l6: 0.003156

[epoch:  92/1000, batch:   428/ 1052, ite: 24040] train loss: 0.007377, tar: 0.000625 
l0: 0.000471, l1: 0.000480, l2: 0.000522, l3: 0.000522, l4: 0.000671, l5: 0.001172, l6: 0.002016

[epoch:  92/1000, batch:   508/ 1052, ite: 24060] train loss: 0.007378, tar: 0.000625 
l0: 0.000916, l1: 0.000889, l2: 0.001154, l3: 0.000990, l4: 0.001761, l5: 0.002979, l6: 0.004306

[epoch:  92/1000, batch:   588/ 1052, ite: 24080] train loss: 0.007471, tar: 0.000637 
l0: 0.000694, l1: 0.000679, l2: 0.000625, l3: 0.000931, l4: 0.001268, l5: 0.001435, l6: 0.003049

[epoch:  92/1000, batch:   668/ 1052, ite: 24100] train loss: 0.007485, tar: 0.000639 
l0: 0.000574, l1: 0.000569, l2: 0.000594, l3: 0.000680, l4: 0.000890, l5: 0.001516, l6: 0.002222

[epoch:  92/1000, batch:   748/ 1052, ite: 24120] train loss: 0.007480, tar: 0.000638 
l0: 0.001119, l1: 0.001231, l2: 0.001158, l3: 0.000939, l4: 0.001507, l5: 0.003179, l6: 0.005362

[epoch:  92/1000, batch:   828/ 1052, ite: 24140] train loss: 0.007481, tar: 0.000638 
l0: 0.001288, l1: 0.001388, l2: 0.001159, l3: 0.001294, l4: 0.001691, l5: 0.003085, l6: 0.005006

[epoch:  92/1000, batch:   908/ 1052, ite: 24160] train loss: 0.007485, tar: 0.000639 
l0: 0.000356, l1: 0.000379, l2: 0.000342, l3: 0.000354, l4: 0.000517, l5: 0.000671, l6: 0.001273

[epoch:  92/1000, batch:   988/ 1052, ite: 24180] train loss: 0.007483, tar: 0.000638 
[Epoch 92/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000649, l1: 0.000630, l2: 0.000660, l3: 0.000924, l4: 0.001256, l5: 0.001898, l6: 0.003571

[epoch:  93/1000, batch:    16/ 1052, ite: 24200] train loss: 0.007477, tar: 0.000638 
l0: 0.000418, l1: 0.000433, l2: 0.000394, l3: 0.000490, l4: 0.000610, l5: 0.001191, l6: 0.002217

[epoch:  93/1000, batch:    96/ 1052, ite: 24220] train loss: 0.007483, tar: 0.000638 
l0: 0.000444, l1: 0.000486, l2: 0.000551, l3: 0.000510, l4: 0.000711, l5: 0.001103, l6: 0.001689

[epoch:  93/1000, batch:   176/ 1052, ite: 24240] train loss: 0.007494, tar: 0.000639 
l0: 0.000754, l1: 0.000747, l2: 0.000821, l3: 0.000860, l4: 0.001001, l5: 0.001559, l6: 0.002124

[epoch:  93/1000, batch:   256/ 1052, ite: 24260] train loss: 0.007495, tar: 0.000639 
l0: 0.000347, l1: 0.000364, l2: 0.000381, l3: 0.000511, l4: 0.000689, l5: 0.001311, l6: 0.001339

[epoch:  93/1000, batch:   336/ 1052, ite: 24280] train loss: 0.007503, tar: 0.000640 
l0: 0.000560, l1: 0.000557, l2: 0.000582, l3: 0.000719, l4: 0.000992, l5: 0.001363, l6: 0.001849

[epoch:  93/1000, batch:   416/ 1052, ite: 24300] train loss: 0.007518, tar: 0.000642 
l0: 0.002089, l1: 0.002193, l2: 0.002174, l3: 0.001947, l4: 0.002111, l5: 0.002617, l6: 0.003172

[epoch:  93/1000, batch:   496/ 1052, ite: 24320] train loss: 0.007517, tar: 0.000642 
l0: 0.000439, l1: 0.000451, l2: 0.000519, l3: 0.000553, l4: 0.000511, l5: 0.000956, l6: 0.001311

[epoch:  93/1000, batch:   576/ 1052, ite: 24340] train loss: 0.007507, tar: 0.000641 
l0: 0.000316, l1: 0.000302, l2: 0.000321, l3: 0.000465, l4: 0.000562, l5: 0.000971, l6: 0.001709

[epoch:  93/1000, batch:   656/ 1052, ite: 24360] train loss: 0.007506, tar: 0.000640 
l0: 0.000229, l1: 0.000217, l2: 0.000241, l3: 0.000250, l4: 0.000493, l5: 0.000563, l6: 0.000894

[epoch:  93/1000, batch:   736/ 1052, ite: 24380] train loss: 0.007503, tar: 0.000640 
l0: 0.001484, l1: 0.001625, l2: 0.001591, l3: 0.002274, l4: 0.002068, l5: 0.003255, l6: 0.004279

[epoch:  93/1000, batch:   816/ 1052, ite: 24400] train loss: 0.007510, tar: 0.000641 
l0: 0.000498, l1: 0.000527, l2: 0.000486, l3: 0.000585, l4: 0.000884, l5: 0.001768, l6: 0.002258

[epoch:  93/1000, batch:   896/ 1052, ite: 24420] train loss: 0.007512, tar: 0.000641 
l0: 0.000786, l1: 0.000886, l2: 0.000763, l3: 0.000926, l4: 0.000820, l5: 0.001074, l6: 0.001363

[epoch:  93/1000, batch:   976/ 1052, ite: 24440] train loss: 0.007515, tar: 0.000642 
[Epoch 93/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000446, l1: 0.000452, l2: 0.000446, l3: 0.000576, l4: 0.000816, l5: 0.001323, l6: 0.002300

[epoch:  94/1000, batch:     4/ 1052, ite: 24460] train loss: 0.007514, tar: 0.000642 
l0: 0.000659, l1: 0.000636, l2: 0.000706, l3: 0.000760, l4: 0.001073, l5: 0.002185, l6: 0.002140

[epoch:  94/1000, batch:    84/ 1052, ite: 24480] train loss: 0.007513, tar: 0.000642 
l0: 0.000725, l1: 0.000725, l2: 0.000804, l3: 0.000814, l4: 0.000817, l5: 0.001784, l6: 0.003085

[epoch:  94/1000, batch:   164/ 1052, ite: 24500] train loss: 0.007512, tar: 0.000642 
l0: 0.000383, l1: 0.000389, l2: 0.000380, l3: 0.000432, l4: 0.000506, l5: 0.000993, l6: 0.001515

[epoch:  94/1000, batch:   244/ 1052, ite: 24520] train loss: 0.007509, tar: 0.000641 
l0: 0.000563, l1: 0.000577, l2: 0.000614, l3: 0.000680, l4: 0.000873, l5: 0.001975, l6: 0.002901

[epoch:  94/1000, batch:   324/ 1052, ite: 24540] train loss: 0.007513, tar: 0.000642 
l0: 0.000467, l1: 0.000478, l2: 0.000445, l3: 0.000426, l4: 0.000506, l5: 0.000888, l6: 0.002034

[epoch:  94/1000, batch:   404/ 1052, ite: 24560] train loss: 0.007508, tar: 0.000641 
l0: 0.000724, l1: 0.000727, l2: 0.000751, l3: 0.000835, l4: 0.001083, l5: 0.001644, l6: 0.002203

[epoch:  94/1000, batch:   484/ 1052, ite: 24580] train loss: 0.007510, tar: 0.000642 
l0: 0.000356, l1: 0.000379, l2: 0.000356, l3: 0.000387, l4: 0.000575, l5: 0.001084, l6: 0.001845

[epoch:  94/1000, batch:   564/ 1052, ite: 24600] train loss: 0.007503, tar: 0.000641 
l0: 0.000207, l1: 0.000205, l2: 0.000232, l3: 0.000262, l4: 0.000459, l5: 0.000723, l6: 0.001468

[epoch:  94/1000, batch:   644/ 1052, ite: 24620] train loss: 0.007498, tar: 0.000640 
l0: 0.000694, l1: 0.000678, l2: 0.000730, l3: 0.000755, l4: 0.001032, l5: 0.001481, l6: 0.002083

[epoch:  94/1000, batch:   724/ 1052, ite: 24640] train loss: 0.007495, tar: 0.000640 
l0: 0.000802, l1: 0.000847, l2: 0.000814, l3: 0.000875, l4: 0.001441, l5: 0.001561, l6: 0.002787

[epoch:  94/1000, batch:   804/ 1052, ite: 24660] train loss: 0.007503, tar: 0.000641 
l0: 0.000727, l1: 0.000786, l2: 0.000753, l3: 0.000797, l4: 0.000996, l5: 0.001711, l6: 0.002267

[epoch:  94/1000, batch:   884/ 1052, ite: 24680] train loss: 0.007498, tar: 0.000640 
l0: 0.000627, l1: 0.000837, l2: 0.000653, l3: 0.000610, l4: 0.000739, l5: 0.001212, l6: 0.001778

[epoch:  94/1000, batch:   964/ 1052, ite: 24700] train loss: 0.007499, tar: 0.000641 
l0: 0.000940, l1: 0.000857, l2: 0.001001, l3: 0.001368, l4: 0.001869, l5: 0.002565, l6: 0.003237

[epoch:  94/1000, batch:  1044/ 1052, ite: 24720] train loss: 0.007497, tar: 0.000640 
[Epoch 94/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000479, l1: 0.000483, l2: 0.000515, l3: 0.000523, l4: 0.000674, l5: 0.001107, l6: 0.002223

[epoch:  95/1000, batch:    72/ 1052, ite: 24740] train loss: 0.007496, tar: 0.000640 
l0: 0.001043, l1: 0.001095, l2: 0.001145, l3: 0.001295, l4: 0.001500, l5: 0.002452, l6: 0.002606

[epoch:  95/1000, batch:   152/ 1052, ite: 24760] train loss: 0.007497, tar: 0.000640 
l0: 0.000614, l1: 0.000636, l2: 0.000661, l3: 0.000938, l4: 0.001119, l5: 0.001557, l6: 0.002247

[epoch:  95/1000, batch:   232/ 1052, ite: 24780] train loss: 0.007501, tar: 0.000640 
l0: 0.000281, l1: 0.000277, l2: 0.000315, l3: 0.000421, l4: 0.000562, l5: 0.001165, l6: 0.001641

[epoch:  95/1000, batch:   312/ 1052, ite: 24800] train loss: 0.007495, tar: 0.000640 
l0: 0.001211, l1: 0.001277, l2: 0.001148, l3: 0.001448, l4: 0.001529, l5: 0.002154, l6: 0.003721

[epoch:  95/1000, batch:   392/ 1052, ite: 24820] train loss: 0.007495, tar: 0.000640 
l0: 0.000486, l1: 0.000506, l2: 0.000473, l3: 0.000491, l4: 0.000790, l5: 0.001417, l6: 0.002654

[epoch:  95/1000, batch:   472/ 1052, ite: 24840] train loss: 0.007486, tar: 0.000639 
l0: 0.000271, l1: 0.000268, l2: 0.000333, l3: 0.000306, l4: 0.000473, l5: 0.000602, l6: 0.001390

[epoch:  95/1000, batch:   552/ 1052, ite: 24860] train loss: 0.007482, tar: 0.000638 
l0: 0.000447, l1: 0.000468, l2: 0.000446, l3: 0.000515, l4: 0.000695, l5: 0.000934, l6: 0.001656

[epoch:  95/1000, batch:   632/ 1052, ite: 24880] train loss: 0.007474, tar: 0.000637 
l0: 0.000458, l1: 0.000449, l2: 0.000487, l3: 0.000571, l4: 0.000860, l5: 0.001683, l6: 0.003071

[epoch:  95/1000, batch:   712/ 1052, ite: 24900] train loss: 0.007465, tar: 0.000636 
l0: 0.000932, l1: 0.000973, l2: 0.000969, l3: 0.000952, l4: 0.001229, l5: 0.001811, l6: 0.003070

[epoch:  95/1000, batch:   792/ 1052, ite: 24920] train loss: 0.007459, tar: 0.000636 
l0: 0.000467, l1: 0.000465, l2: 0.000529, l3: 0.000474, l4: 0.000619, l5: 0.001165, l6: 0.002372

[epoch:  95/1000, batch:   872/ 1052, ite: 24940] train loss: 0.007462, tar: 0.000636 
l0: 0.000400, l1: 0.000367, l2: 0.000357, l3: 0.000500, l4: 0.000877, l5: 0.001217, l6: 0.001678

[epoch:  95/1000, batch:   952/ 1052, ite: 24960] train loss: 0.007464, tar: 0.000636 
l0: 0.000653, l1: 0.000647, l2: 0.000716, l3: 0.000765, l4: 0.001003, l5: 0.001553, l6: 0.002922

[epoch:  95/1000, batch:  1032/ 1052, ite: 24980] train loss: 0.007464, tar: 0.000636 
[Epoch 95/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000360, l1: 0.000367, l2: 0.000411, l3: 0.000460, l4: 0.000728, l5: 0.001157, l6: 0.001576

[epoch:  96/1000, batch:    60/ 1052, ite: 25000] train loss: 0.007458, tar: 0.000635 
l0: 0.000644, l1: 0.000646, l2: 0.000678, l3: 0.000668, l4: 0.000881, l5: 0.001490, l6: 0.002515

[epoch:  96/1000, batch:   140/ 1052, ite: 25020] train loss: 0.007457, tar: 0.000635 
l0: 0.000794, l1: 0.000855, l2: 0.000859, l3: 0.000880, l4: 0.001055, l5: 0.001812, l6: 0.002720

[epoch:  96/1000, batch:   220/ 1052, ite: 25040] train loss: 0.007454, tar: 0.000634 
l0: 0.000292, l1: 0.000305, l2: 0.000304, l3: 0.000322, l4: 0.000393, l5: 0.000855, l6: 0.001245

[epoch:  96/1000, batch:   300/ 1052, ite: 25060] train loss: 0.007448, tar: 0.000634 
l0: 0.001157, l1: 0.001368, l2: 0.001034, l3: 0.000987, l4: 0.001650, l5: 0.002193, l6: 0.002693

[epoch:  96/1000, batch:   380/ 1052, ite: 25080] train loss: 0.007445, tar: 0.000634 
l0: 0.000441, l1: 0.000445, l2: 0.000437, l3: 0.000515, l4: 0.000606, l5: 0.000977, l6: 0.001556

[epoch:  96/1000, batch:   460/ 1052, ite: 25100] train loss: 0.007444, tar: 0.000634 
l0: 0.000608, l1: 0.000597, l2: 0.000674, l3: 0.000843, l4: 0.001314, l5: 0.002294, l6: 0.003391

[epoch:  96/1000, batch:   540/ 1052, ite: 25120] train loss: 0.007448, tar: 0.000634 
l0: 0.000729, l1: 0.000734, l2: 0.000841, l3: 0.001072, l4: 0.001194, l5: 0.001962, l6: 0.001984

[epoch:  96/1000, batch:   620/ 1052, ite: 25140] train loss: 0.007443, tar: 0.000633 
l0: 0.000220, l1: 0.000229, l2: 0.000254, l3: 0.000313, l4: 0.000477, l5: 0.000581, l6: 0.001018

[epoch:  96/1000, batch:   700/ 1052, ite: 25160] train loss: 0.007441, tar: 0.000633 
l0: 0.000664, l1: 0.000654, l2: 0.000668, l3: 0.000786, l4: 0.001011, l5: 0.002162, l6: 0.003615

[epoch:  96/1000, batch:   780/ 1052, ite: 25180] train loss: 0.007438, tar: 0.000633 
l0: 0.000295, l1: 0.000295, l2: 0.000289, l3: 0.000480, l4: 0.000788, l5: 0.001288, l6: 0.001921

[epoch:  96/1000, batch:   860/ 1052, ite: 25200] train loss: 0.007436, tar: 0.000633 
l0: 0.000438, l1: 0.000429, l2: 0.000511, l3: 0.000539, l4: 0.000800, l5: 0.001105, l6: 0.002319

[epoch:  96/1000, batch:   940/ 1052, ite: 25220] train loss: 0.007434, tar: 0.000632 
l0: 0.000393, l1: 0.000396, l2: 0.000378, l3: 0.000408, l4: 0.000545, l5: 0.001040, l6: 0.001574

[epoch:  96/1000, batch:  1020/ 1052, ite: 25240] train loss: 0.007430, tar: 0.000632 
[Epoch 96/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000317, l1: 0.000321, l2: 0.000358, l3: 0.000426, l4: 0.000710, l5: 0.001185, l6: 0.001805

[epoch:  97/1000, batch:    48/ 1052, ite: 25260] train loss: 0.007423, tar: 0.000631 
l0: 0.000426, l1: 0.000400, l2: 0.000423, l3: 0.000512, l4: 0.000844, l5: 0.001118, l6: 0.002476

[epoch:  97/1000, batch:   128/ 1052, ite: 25280] train loss: 0.007418, tar: 0.000631 
l0: 0.000346, l1: 0.000344, l2: 0.000356, l3: 0.000388, l4: 0.000578, l5: 0.000764, l6: 0.002565

[epoch:  97/1000, batch:   208/ 1052, ite: 25300] train loss: 0.007410, tar: 0.000630 
l0: 0.000444, l1: 0.000392, l2: 0.000367, l3: 0.000601, l4: 0.000704, l5: 0.000774, l6: 0.001293

[epoch:  97/1000, batch:   288/ 1052, ite: 25320] train loss: 0.007408, tar: 0.000629 
l0: 0.001025, l1: 0.001020, l2: 0.000985, l3: 0.001104, l4: 0.001491, l5: 0.002374, l6: 0.003873

[epoch:  97/1000, batch:   368/ 1052, ite: 25340] train loss: 0.007404, tar: 0.000629 
l0: 0.000602, l1: 0.000616, l2: 0.000584, l3: 0.000763, l4: 0.000962, l5: 0.001748, l6: 0.002074

[epoch:  97/1000, batch:   448/ 1052, ite: 25360] train loss: 0.007403, tar: 0.000629 
l0: 0.000394, l1: 0.000387, l2: 0.000385, l3: 0.000403, l4: 0.000531, l5: 0.001011, l6: 0.001720

[epoch:  97/1000, batch:   528/ 1052, ite: 25380] train loss: 0.007396, tar: 0.000628 
l0: 0.000352, l1: 0.000348, l2: 0.000390, l3: 0.000438, l4: 0.000651, l5: 0.000901, l6: 0.001552

[epoch:  97/1000, batch:   608/ 1052, ite: 25400] train loss: 0.007395, tar: 0.000628 
l0: 0.000564, l1: 0.000547, l2: 0.000614, l3: 0.000663, l4: 0.000841, l5: 0.001101, l6: 0.001584

[epoch:  97/1000, batch:   688/ 1052, ite: 25420] train loss: 0.007402, tar: 0.000628 
l0: 0.000520, l1: 0.000493, l2: 0.000686, l3: 0.000657, l4: 0.000702, l5: 0.001174, l6: 0.001826

[epoch:  97/1000, batch:   768/ 1052, ite: 25440] train loss: 0.007402, tar: 0.000629 
l0: 0.000608, l1: 0.000623, l2: 0.000629, l3: 0.000738, l4: 0.000880, l5: 0.001804, l6: 0.003272

[epoch:  97/1000, batch:   848/ 1052, ite: 25460] train loss: 0.007397, tar: 0.000628 
l0: 0.000681, l1: 0.000649, l2: 0.000711, l3: 0.000880, l4: 0.001145, l5: 0.001847, l6: 0.003427

[epoch:  97/1000, batch:   928/ 1052, ite: 25480] train loss: 0.007393, tar: 0.000628 
l0: 0.000790, l1: 0.000830, l2: 0.000855, l3: 0.000896, l4: 0.001103, l5: 0.002175, l6: 0.003921

[epoch:  97/1000, batch:  1008/ 1052, ite: 25500] train loss: 0.007393, tar: 0.000628 
[Epoch 97/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000192, l1: 0.000190, l2: 0.000185, l3: 0.000211, l4: 0.000348, l5: 0.000656, l6: 0.001032

[epoch:  98/1000, batch:    36/ 1052, ite: 25520] train loss: 0.007394, tar: 0.000628 
l0: 0.000675, l1: 0.000649, l2: 0.000664, l3: 0.001059, l4: 0.001258, l5: 0.001464, l6: 0.003645

[epoch:  98/1000, batch:   116/ 1052, ite: 25540] train loss: 0.007399, tar: 0.000628 
l0: 0.000395, l1: 0.000448, l2: 0.000375, l3: 0.000458, l4: 0.000668, l5: 0.001192, l6: 0.002067

[epoch:  98/1000, batch:   196/ 1052, ite: 25560] train loss: 0.007392, tar: 0.000627 
l0: 0.000393, l1: 0.000389, l2: 0.000407, l3: 0.000561, l4: 0.000781, l5: 0.001393, l6: 0.001890

[epoch:  98/1000, batch:   276/ 1052, ite: 25580] train loss: 0.007393, tar: 0.000627 
l0: 0.000463, l1: 0.000461, l2: 0.000404, l3: 0.000543, l4: 0.000845, l5: 0.001504, l6: 0.001944

[epoch:  98/1000, batch:   356/ 1052, ite: 25600] train loss: 0.007389, tar: 0.000627 
l0: 0.000412, l1: 0.000429, l2: 0.000404, l3: 0.000395, l4: 0.000426, l5: 0.000570, l6: 0.000895

[epoch:  98/1000, batch:   436/ 1052, ite: 25620] train loss: 0.007392, tar: 0.000627 
l0: 0.000556, l1: 0.000564, l2: 0.000574, l3: 0.000577, l4: 0.000710, l5: 0.001200, l6: 0.001823

[epoch:  98/1000, batch:   516/ 1052, ite: 25640] train loss: 0.007389, tar: 0.000626 
l0: 0.000208, l1: 0.000203, l2: 0.000235, l3: 0.000284, l4: 0.000355, l5: 0.000734, l6: 0.001122

[epoch:  98/1000, batch:   596/ 1052, ite: 25660] train loss: 0.007382, tar: 0.000626 
l0: 0.000542, l1: 0.000554, l2: 0.000555, l3: 0.000632, l4: 0.000915, l5: 0.001415, l6: 0.002402

[epoch:  98/1000, batch:   676/ 1052, ite: 25680] train loss: 0.007377, tar: 0.000625 
l0: 0.000662, l1: 0.000632, l2: 0.000684, l3: 0.000705, l4: 0.001008, l5: 0.001406, l6: 0.002580

[epoch:  98/1000, batch:   756/ 1052, ite: 25700] train loss: 0.007372, tar: 0.000625 
l0: 0.002718, l1: 0.002914, l2: 0.002808, l3: 0.002580, l4: 0.002763, l5: 0.004571, l6: 0.006387

[epoch:  98/1000, batch:   836/ 1052, ite: 25720] train loss: 0.007374, tar: 0.000625 
l0: 0.000361, l1: 0.000383, l2: 0.000357, l3: 0.000363, l4: 0.000693, l5: 0.000908, l6: 0.001104

[epoch:  98/1000, batch:   916/ 1052, ite: 25740] train loss: 0.007382, tar: 0.000626 
l0: 0.000616, l1: 0.000585, l2: 0.000601, l3: 0.000635, l4: 0.000870, l5: 0.001294, l6: 0.001957

[epoch:  98/1000, batch:   996/ 1052, ite: 25760] train loss: 0.007385, tar: 0.000626 
[Epoch 98/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000349, l1: 0.000337, l2: 0.000430, l3: 0.000455, l4: 0.000680, l5: 0.001131, l6: 0.001542

[epoch:  99/1000, batch:    24/ 1052, ite: 25780] train loss: 0.007384, tar: 0.000626 
l0: 0.000465, l1: 0.000616, l2: 0.000445, l3: 0.000645, l4: 0.000893, l5: 0.001608, l6: 0.002163

[epoch:  99/1000, batch:   104/ 1052, ite: 25800] train loss: 0.007381, tar: 0.000626 
l0: 0.000478, l1: 0.000526, l2: 0.000520, l3: 0.000617, l4: 0.000760, l5: 0.001227, l6: 0.002034

[epoch:  99/1000, batch:   184/ 1052, ite: 25820] train loss: 0.007376, tar: 0.000625 
l0: 0.001206, l1: 0.001249, l2: 0.001128, l3: 0.001314, l4: 0.001579, l5: 0.002714, l6: 0.005054

[epoch:  99/1000, batch:   264/ 1052, ite: 25840] train loss: 0.007378, tar: 0.000625 
l0: 0.000565, l1: 0.000561, l2: 0.000634, l3: 0.000584, l4: 0.000871, l5: 0.001213, l6: 0.001904

[epoch:  99/1000, batch:   344/ 1052, ite: 25860] train loss: 0.007382, tar: 0.000626 
l0: 0.001128, l1: 0.001203, l2: 0.001264, l3: 0.001257, l4: 0.001505, l5: 0.003168, l6: 0.004103

[epoch:  99/1000, batch:   424/ 1052, ite: 25880] train loss: 0.007383, tar: 0.000626 
l0: 0.000591, l1: 0.000571, l2: 0.000583, l3: 0.000608, l4: 0.000694, l5: 0.001385, l6: 0.001338

[epoch:  99/1000, batch:   504/ 1052, ite: 25900] train loss: 0.007384, tar: 0.000625 
l0: 0.000693, l1: 0.000579, l2: 0.000572, l3: 0.000735, l4: 0.000828, l5: 0.001431, l6: 0.002514

[epoch:  99/1000, batch:   584/ 1052, ite: 25920] train loss: 0.007383, tar: 0.000625 
l0: 0.000622, l1: 0.000631, l2: 0.000669, l3: 0.000772, l4: 0.000890, l5: 0.001498, l6: 0.002767

[epoch:  99/1000, batch:   664/ 1052, ite: 25940] train loss: 0.007385, tar: 0.000625 
l0: 0.000460, l1: 0.000453, l2: 0.000495, l3: 0.000572, l4: 0.000696, l5: 0.001216, l6: 0.002155

[epoch:  99/1000, batch:   744/ 1052, ite: 25960] train loss: 0.007379, tar: 0.000625 
l0: 0.000492, l1: 0.000472, l2: 0.000539, l3: 0.000766, l4: 0.000984, l5: 0.001824, l6: 0.002344

[epoch:  99/1000, batch:   824/ 1052, ite: 25980] train loss: 0.007375, tar: 0.000624 
l0: 0.000274, l1: 0.000272, l2: 0.000299, l3: 0.000338, l4: 0.000526, l5: 0.000749, l6: 0.001311

[epoch:  99/1000, batch:   904/ 1052, ite: 26000] train loss: 0.007372, tar: 0.000623 
l0: 0.000631, l1: 0.000625, l2: 0.000662, l3: 0.000828, l4: 0.001091, l5: 0.001752, l6: 0.002818

[epoch:  99/1000, batch:   984/ 1052, ite: 26020] train loss: 0.007371, tar: 0.000623 
[Epoch 99/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000236, l1: 0.000234, l2: 0.000238, l3: 0.000300, l4: 0.000459, l5: 0.000887, l6: 0.001508

[epoch: 100/1000, batch:    12/ 1052, ite: 26040] train loss: 0.007366, tar: 0.000623 
l0: 0.000853, l1: 0.000858, l2: 0.000830, l3: 0.000947, l4: 0.001415, l5: 0.002198, l6: 0.002980

[epoch: 100/1000, batch:    92/ 1052, ite: 26060] train loss: 0.007366, tar: 0.000623 
l0: 0.000835, l1: 0.000917, l2: 0.000779, l3: 0.000826, l4: 0.001056, l5: 0.001534, l6: 0.002987

[epoch: 100/1000, batch:   172/ 1052, ite: 26080] train loss: 0.007362, tar: 0.000622 
l0: 0.000722, l1: 0.000762, l2: 0.000745, l3: 0.000813, l4: 0.000964, l5: 0.001333, l6: 0.001736

[epoch: 100/1000, batch:   252/ 1052, ite: 26100] train loss: 0.007361, tar: 0.000622 
l0: 0.001010, l1: 0.000991, l2: 0.001032, l3: 0.001045, l4: 0.001416, l5: 0.001795, l6: 0.003111

[epoch: 100/1000, batch:   332/ 1052, ite: 26120] train loss: 0.007362, tar: 0.000622 
l0: 0.000506, l1: 0.000484, l2: 0.000531, l3: 0.000690, l4: 0.000842, l5: 0.001686, l6: 0.003067

[epoch: 100/1000, batch:   412/ 1052, ite: 26140] train loss: 0.007357, tar: 0.000622 
l0: 0.000481, l1: 0.000452, l2: 0.000454, l3: 0.000504, l4: 0.000725, l5: 0.000999, l6: 0.001885

[epoch: 100/1000, batch:   492/ 1052, ite: 26160] train loss: 0.007352, tar: 0.000621 
l0: 0.000223, l1: 0.000234, l2: 0.000272, l3: 0.000296, l4: 0.000389, l5: 0.000784, l6: 0.001416

[epoch: 100/1000, batch:   572/ 1052, ite: 26180] train loss: 0.007352, tar: 0.000621 
l0: 0.000332, l1: 0.000328, l2: 0.000346, l3: 0.000390, l4: 0.000479, l5: 0.000939, l6: 0.001871

[epoch: 100/1000, batch:   652/ 1052, ite: 26200] train loss: 0.007347, tar: 0.000621 
l0: 0.000263, l1: 0.000255, l2: 0.000296, l3: 0.000406, l4: 0.000574, l5: 0.001075, l6: 0.002159

[epoch: 100/1000, batch:   732/ 1052, ite: 26220] train loss: 0.007344, tar: 0.000620 
l0: 0.000297, l1: 0.000318, l2: 0.000279, l3: 0.000235, l4: 0.000418, l5: 0.000927, l6: 0.001595

[epoch: 100/1000, batch:   812/ 1052, ite: 26240] train loss: 0.007347, tar: 0.000620 
l0: 0.001448, l1: 0.001486, l2: 0.001358, l3: 0.001677, l4: 0.003444, l5: 0.004092, l6: 0.004819

[epoch: 100/1000, batch:   892/ 1052, ite: 26260] train loss: 0.007343, tar: 0.000620 
l0: 0.001517, l1: 0.001552, l2: 0.001538, l3: 0.001485, l4: 0.001487, l5: 0.002267, l6: 0.004967

[epoch: 100/1000, batch:   972/ 1052, ite: 26280] train loss: 0.007347, tar: 0.000620 
l0: 0.000773, l1: 0.000737, l2: 0.000790, l3: 0.000970, l4: 0.001477, l5: 0.002158, l6: 0.002895

[epoch: 100/1000, batch:  1052/ 1052, ite: 26300] train loss: 0.007347, tar: 0.000620 
[Epoch 100/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000891, l1: 0.000925, l2: 0.000999, l3: 0.000985, l4: 0.001652, l5: 0.002308, l6: 0.002815

[epoch: 101/1000, batch:    80/ 1052, ite: 26320] train loss: 0.007345, tar: 0.000620 
l0: 0.000610, l1: 0.000595, l2: 0.000627, l3: 0.000827, l4: 0.000981, l5: 0.001383, l6: 0.002362

[epoch: 101/1000, batch:   160/ 1052, ite: 26340] train loss: 0.007344, tar: 0.000620 
l0: 0.000274, l1: 0.000267, l2: 0.000295, l3: 0.000321, l4: 0.000473, l5: 0.000720, l6: 0.001130

[epoch: 101/1000, batch:   240/ 1052, ite: 26360] train loss: 0.007341, tar: 0.000619 
l0: 0.000420, l1: 0.000439, l2: 0.000410, l3: 0.000525, l4: 0.000752, l5: 0.001190, l6: 0.001748

[epoch: 101/1000, batch:   320/ 1052, ite: 26380] train loss: 0.007341, tar: 0.000619 
l0: 0.000807, l1: 0.000853, l2: 0.000872, l3: 0.001118, l4: 0.001251, l5: 0.002283, l6: 0.002780

[epoch: 101/1000, batch:   400/ 1052, ite: 26400] train loss: 0.007342, tar: 0.000619 
l0: 0.000758, l1: 0.000754, l2: 0.000798, l3: 0.000948, l4: 0.001550, l5: 0.002101, l6: 0.002114

[epoch: 101/1000, batch:   480/ 1052, ite: 26420] train loss: 0.007339, tar: 0.000619 
l0: 0.000419, l1: 0.000413, l2: 0.000443, l3: 0.000545, l4: 0.000886, l5: 0.001583, l6: 0.002152

[epoch: 101/1000, batch:   560/ 1052, ite: 26440] train loss: 0.007332, tar: 0.000618 
l0: 0.000144, l1: 0.000163, l2: 0.000144, l3: 0.000197, l4: 0.000338, l5: 0.000569, l6: 0.000961

[epoch: 101/1000, batch:   640/ 1052, ite: 26460] train loss: 0.007341, tar: 0.000620 
l0: 0.000466, l1: 0.000511, l2: 0.000480, l3: 0.000436, l4: 0.000606, l5: 0.000895, l6: 0.001583

[epoch: 101/1000, batch:   720/ 1052, ite: 26480] train loss: 0.007341, tar: 0.000620 
l0: 0.000664, l1: 0.000675, l2: 0.000559, l3: 0.000741, l4: 0.001012, l5: 0.001804, l6: 0.002943

[epoch: 101/1000, batch:   800/ 1052, ite: 26500] train loss: 0.007338, tar: 0.000620 
l0: 0.000696, l1: 0.000707, l2: 0.000862, l3: 0.001107, l4: 0.001379, l5: 0.001373, l6: 0.001858

[epoch: 101/1000, batch:   880/ 1052, ite: 26520] train loss: 0.007342, tar: 0.000620 
l0: 0.000517, l1: 0.000487, l2: 0.000547, l3: 0.000661, l4: 0.000784, l5: 0.001534, l6: 0.002461

[epoch: 101/1000, batch:   960/ 1052, ite: 26540] train loss: 0.007341, tar: 0.000620 
l0: 0.000305, l1: 0.000298, l2: 0.000242, l3: 0.000340, l4: 0.001020, l5: 0.000979, l6: 0.000946

[epoch: 101/1000, batch:  1040/ 1052, ite: 26560] train loss: 0.007341, tar: 0.000620 
[Epoch 101/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000319, l1: 0.000330, l2: 0.000328, l3: 0.000314, l4: 0.000458, l5: 0.001014, l6: 0.002353

[epoch: 102/1000, batch:    68/ 1052, ite: 26580] train loss: 0.007338, tar: 0.000620 
l0: 0.000420, l1: 0.000432, l2: 0.000525, l3: 0.000530, l4: 0.000735, l5: 0.001055, l6: 0.001730

[epoch: 102/1000, batch:   148/ 1052, ite: 26600] train loss: 0.007343, tar: 0.000620 
l0: 0.000681, l1: 0.000683, l2: 0.000675, l3: 0.000818, l4: 0.001084, l5: 0.001769, l6: 0.002046

[epoch: 102/1000, batch:   228/ 1052, ite: 26620] train loss: 0.007343, tar: 0.000620 
l0: 0.000329, l1: 0.000370, l2: 0.000351, l3: 0.000404, l4: 0.000632, l5: 0.001166, l6: 0.001446

[epoch: 102/1000, batch:   308/ 1052, ite: 26640] train loss: 0.007339, tar: 0.000620 
l0: 0.000484, l1: 0.000492, l2: 0.000495, l3: 0.000515, l4: 0.000616, l5: 0.000830, l6: 0.001423

[epoch: 102/1000, batch:   388/ 1052, ite: 26660] train loss: 0.007337, tar: 0.000620 
l0: 0.000379, l1: 0.000353, l2: 0.000377, l3: 0.000414, l4: 0.000551, l5: 0.001141, l6: 0.002287

[epoch: 102/1000, batch:   468/ 1052, ite: 26680] train loss: 0.007333, tar: 0.000619 
l0: 0.000361, l1: 0.000362, l2: 0.000374, l3: 0.000479, l4: 0.000543, l5: 0.001185, l6: 0.001692

[epoch: 102/1000, batch:   548/ 1052, ite: 26700] train loss: 0.007329, tar: 0.000619 
l0: 0.000613, l1: 0.000609, l2: 0.000629, l3: 0.000864, l4: 0.001153, l5: 0.001647, l6: 0.002726

[epoch: 102/1000, batch:   628/ 1052, ite: 26720] train loss: 0.007328, tar: 0.000619 
l0: 0.000401, l1: 0.000393, l2: 0.000419, l3: 0.000471, l4: 0.000770, l5: 0.001715, l6: 0.002726

[epoch: 102/1000, batch:   708/ 1052, ite: 26740] train loss: 0.007326, tar: 0.000619 
l0: 0.000291, l1: 0.000309, l2: 0.000288, l3: 0.000353, l4: 0.000450, l5: 0.000847, l6: 0.001505

[epoch: 102/1000, batch:   788/ 1052, ite: 26760] train loss: 0.007322, tar: 0.000618 
l0: 0.000791, l1: 0.000867, l2: 0.000863, l3: 0.000840, l4: 0.000963, l5: 0.001518, l6: 0.002806

[epoch: 102/1000, batch:   868/ 1052, ite: 26780] train loss: 0.007323, tar: 0.000618 
l0: 0.000534, l1: 0.000534, l2: 0.000554, l3: 0.000698, l4: 0.000850, l5: 0.001551, l6: 0.002681

[epoch: 102/1000, batch:   948/ 1052, ite: 26800] train loss: 0.007324, tar: 0.000618 
l0: 0.000407, l1: 0.000408, l2: 0.000475, l3: 0.000538, l4: 0.000833, l5: 0.001690, l6: 0.002541

[epoch: 102/1000, batch:  1028/ 1052, ite: 26820] train loss: 0.007321, tar: 0.000618 
[Epoch 102/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000755, l1: 0.000788, l2: 0.000760, l3: 0.000809, l4: 0.001135, l5: 0.001621, l6: 0.002642

[epoch: 103/1000, batch:    56/ 1052, ite: 26840] train loss: 0.007321, tar: 0.000618 
l0: 0.000752, l1: 0.000810, l2: 0.000742, l3: 0.000844, l4: 0.000939, l5: 0.001777, l6: 0.002474

[epoch: 103/1000, batch:   136/ 1052, ite: 26860] train loss: 0.007322, tar: 0.000618 
l0: 0.000723, l1: 0.000852, l2: 0.000830, l3: 0.000638, l4: 0.000678, l5: 0.001067, l6: 0.000984

[epoch: 103/1000, batch:   216/ 1052, ite: 26880] train loss: 0.007319, tar: 0.000618 
l0: 0.000354, l1: 0.000362, l2: 0.000385, l3: 0.000509, l4: 0.000754, l5: 0.001093, l6: 0.002151

[epoch: 103/1000, batch:   296/ 1052, ite: 26900] train loss: 0.007314, tar: 0.000617 
l0: 0.000164, l1: 0.000160, l2: 0.000206, l3: 0.000241, l4: 0.000299, l5: 0.000726, l6: 0.000943

[epoch: 103/1000, batch:   376/ 1052, ite: 26920] train loss: 0.007306, tar: 0.000617 
l0: 0.000339, l1: 0.000337, l2: 0.000352, l3: 0.000435, l4: 0.000742, l5: 0.001217, l6: 0.002284

[epoch: 103/1000, batch:   456/ 1052, ite: 26940] train loss: 0.007304, tar: 0.000616 
l0: 0.000407, l1: 0.000422, l2: 0.000428, l3: 0.000429, l4: 0.000574, l5: 0.000801, l6: 0.001326

[epoch: 103/1000, batch:   536/ 1052, ite: 26960] train loss: 0.007308, tar: 0.000617 
l0: 0.000249, l1: 0.000243, l2: 0.000234, l3: 0.000344, l4: 0.000494, l5: 0.000770, l6: 0.000949

[epoch: 103/1000, batch:   616/ 1052, ite: 26980] train loss: 0.007305, tar: 0.000616 
l0: 0.000320, l1: 0.000332, l2: 0.000344, l3: 0.000356, l4: 0.000501, l5: 0.000665, l6: 0.001793

[epoch: 103/1000, batch:   696/ 1052, ite: 27000] train loss: 0.007300, tar: 0.000616 
l0: 0.001114, l1: 0.001168, l2: 0.001261, l3: 0.001316, l4: 0.001598, l5: 0.002261, l6: 0.004781

[epoch: 103/1000, batch:   776/ 1052, ite: 27020] train loss: 0.007301, tar: 0.000616 
l0: 0.001394, l1: 0.001437, l2: 0.001724, l3: 0.001504, l4: 0.001954, l5: 0.002272, l6: 0.003674

[epoch: 103/1000, batch:   856/ 1052, ite: 27040] train loss: 0.007299, tar: 0.000616 
l0: 0.000379, l1: 0.000385, l2: 0.000381, l3: 0.000544, l4: 0.000539, l5: 0.000866, l6: 0.001485

[epoch: 103/1000, batch:   936/ 1052, ite: 27060] train loss: 0.007300, tar: 0.000616 
l0: 0.000753, l1: 0.000752, l2: 0.000777, l3: 0.000965, l4: 0.001474, l5: 0.002506, l6: 0.004437

[epoch: 103/1000, batch:  1016/ 1052, ite: 27080] train loss: 0.007298, tar: 0.000616 
[Epoch 103/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000410, l1: 0.000408, l2: 0.000456, l3: 0.000555, l4: 0.000598, l5: 0.000962, l6: 0.001977

[epoch: 104/1000, batch:    44/ 1052, ite: 27100] train loss: 0.007295, tar: 0.000615 
l0: 0.000873, l1: 0.000871, l2: 0.000903, l3: 0.000840, l4: 0.000815, l5: 0.001436, l6: 0.002620

[epoch: 104/1000, batch:   124/ 1052, ite: 27120] train loss: 0.007294, tar: 0.000615 
l0: 0.000549, l1: 0.000542, l2: 0.000566, l3: 0.000609, l4: 0.000912, l5: 0.001326, l6: 0.001939

[epoch: 104/1000, batch:   204/ 1052, ite: 27140] train loss: 0.007291, tar: 0.000615 
l0: 0.000290, l1: 0.000293, l2: 0.000323, l3: 0.000385, l4: 0.000424, l5: 0.000743, l6: 0.001596

[epoch: 104/1000, batch:   284/ 1052, ite: 27160] train loss: 0.007289, tar: 0.000615 
l0: 0.000987, l1: 0.000959, l2: 0.001049, l3: 0.001173, l4: 0.001853, l5: 0.002271, l6: 0.003130

[epoch: 104/1000, batch:   364/ 1052, ite: 27180] train loss: 0.007287, tar: 0.000614 
l0: 0.000235, l1: 0.000231, l2: 0.000215, l3: 0.000241, l4: 0.000370, l5: 0.000723, l6: 0.000777

[epoch: 104/1000, batch:   444/ 1052, ite: 27200] train loss: 0.007286, tar: 0.000614 
l0: 0.000776, l1: 0.000790, l2: 0.000840, l3: 0.001022, l4: 0.001066, l5: 0.001717, l6: 0.004173

[epoch: 104/1000, batch:   524/ 1052, ite: 27220] train loss: 0.007285, tar: 0.000614 
l0: 0.000541, l1: 0.000563, l2: 0.000553, l3: 0.000604, l4: 0.001002, l5: 0.001711, l6: 0.002710

[epoch: 104/1000, batch:   604/ 1052, ite: 27240] train loss: 0.007286, tar: 0.000614 
l0: 0.000221, l1: 0.000209, l2: 0.000254, l3: 0.000317, l4: 0.000486, l5: 0.000645, l6: 0.000941

[epoch: 104/1000, batch:   684/ 1052, ite: 27260] train loss: 0.007283, tar: 0.000614 
l0: 0.000893, l1: 0.000866, l2: 0.000847, l3: 0.001024, l4: 0.001466, l5: 0.002064, l6: 0.003110

[epoch: 104/1000, batch:   764/ 1052, ite: 27280] train loss: 0.007285, tar: 0.000614 
l0: 0.000451, l1: 0.000431, l2: 0.000511, l3: 0.000592, l4: 0.000883, l5: 0.001382, l6: 0.002374

[epoch: 104/1000, batch:   844/ 1052, ite: 27300] train loss: 0.007283, tar: 0.000614 
l0: 0.000350, l1: 0.000349, l2: 0.000347, l3: 0.000390, l4: 0.000588, l5: 0.001309, l6: 0.001816

[epoch: 104/1000, batch:   924/ 1052, ite: 27320] train loss: 0.007279, tar: 0.000614 
l0: 0.000790, l1: 0.000731, l2: 0.000760, l3: 0.000833, l4: 0.001158, l5: 0.001768, l6: 0.002507

[epoch: 104/1000, batch:  1004/ 1052, ite: 27340] train loss: 0.007277, tar: 0.000613 
[Epoch 104/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000627, l1: 0.000639, l2: 0.000615, l3: 0.000690, l4: 0.001062, l5: 0.001947, l6: 0.003316

[epoch: 105/1000, batch:    32/ 1052, ite: 27360] train loss: 0.007273, tar: 0.000613 
l0: 0.001327, l1: 0.001318, l2: 0.001420, l3: 0.001823, l4: 0.001853, l5: 0.002760, l6: 0.003856

[epoch: 105/1000, batch:   112/ 1052, ite: 27380] train loss: 0.007273, tar: 0.000613 
l0: 0.000300, l1: 0.000308, l2: 0.000313, l3: 0.000345, l4: 0.000450, l5: 0.001138, l6: 0.001949

[epoch: 105/1000, batch:   192/ 1052, ite: 27400] train loss: 0.007270, tar: 0.000612 
l0: 0.000941, l1: 0.000861, l2: 0.000890, l3: 0.001118, l4: 0.000975, l5: 0.001740, l6: 0.004448

[epoch: 105/1000, batch:   272/ 1052, ite: 27420] train loss: 0.007272, tar: 0.000613 
l0: 0.000794, l1: 0.000799, l2: 0.000828, l3: 0.000974, l4: 0.001164, l5: 0.001795, l6: 0.002800

[epoch: 105/1000, batch:   352/ 1052, ite: 27440] train loss: 0.007268, tar: 0.000612 
l0: 0.000382, l1: 0.000387, l2: 0.000406, l3: 0.000441, l4: 0.000613, l5: 0.001158, l6: 0.001662

[epoch: 105/1000, batch:   432/ 1052, ite: 27460] train loss: 0.007267, tar: 0.000612 
l0: 0.000930, l1: 0.000926, l2: 0.000951, l3: 0.001139, l4: 0.001398, l5: 0.001651, l6: 0.002074

[epoch: 105/1000, batch:   512/ 1052, ite: 27480] train loss: 0.007270, tar: 0.000613 
l0: 0.000716, l1: 0.000712, l2: 0.000728, l3: 0.000883, l4: 0.001478, l5: 0.002427, l6: 0.004537

[epoch: 105/1000, batch:   592/ 1052, ite: 27500] train loss: 0.007269, tar: 0.000613 
l0: 0.000560, l1: 0.000585, l2: 0.000670, l3: 0.000534, l4: 0.000707, l5: 0.001297, l6: 0.002065

[epoch: 105/1000, batch:   672/ 1052, ite: 27520] train loss: 0.007276, tar: 0.000613 
l0: 0.000555, l1: 0.000524, l2: 0.000574, l3: 0.000680, l4: 0.000701, l5: 0.001367, l6: 0.001795

[epoch: 105/1000, batch:   752/ 1052, ite: 27540] train loss: 0.007277, tar: 0.000613 
l0: 0.000322, l1: 0.000315, l2: 0.000342, l3: 0.000339, l4: 0.000443, l5: 0.000809, l6: 0.000778

[epoch: 105/1000, batch:   832/ 1052, ite: 27560] train loss: 0.007275, tar: 0.000613 
l0: 0.000478, l1: 0.000488, l2: 0.000504, l3: 0.000447, l4: 0.000653, l5: 0.000982, l6: 0.002559

[epoch: 105/1000, batch:   912/ 1052, ite: 27580] train loss: 0.007272, tar: 0.000613 
l0: 0.001307, l1: 0.001304, l2: 0.001318, l3: 0.001196, l4: 0.001579, l5: 0.001750, l6: 0.002261

[epoch: 105/1000, batch:   992/ 1052, ite: 27600] train loss: 0.007269, tar: 0.000612 
[Epoch 105/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000443, l1: 0.000469, l2: 0.000461, l3: 0.000488, l4: 0.000707, l5: 0.000825, l6: 0.002133

[epoch: 106/1000, batch:    20/ 1052, ite: 27620] train loss: 0.007265, tar: 0.000612 
l0: 0.000356, l1: 0.000342, l2: 0.000408, l3: 0.000460, l4: 0.000677, l5: 0.001016, l6: 0.001488

[epoch: 106/1000, batch:   100/ 1052, ite: 27640] train loss: 0.007267, tar: 0.000612 
l0: 0.000853, l1: 0.001011, l2: 0.000847, l3: 0.000650, l4: 0.000704, l5: 0.001296, l6: 0.002413

[epoch: 106/1000, batch:   180/ 1052, ite: 27660] train loss: 0.007267, tar: 0.000612 
l0: 0.000372, l1: 0.000377, l2: 0.000407, l3: 0.000384, l4: 0.000559, l5: 0.001078, l6: 0.001799

[epoch: 106/1000, batch:   260/ 1052, ite: 27680] train loss: 0.007265, tar: 0.000612 
l0: 0.000607, l1: 0.000594, l2: 0.000727, l3: 0.000756, l4: 0.001050, l5: 0.001909, l6: 0.002814

[epoch: 106/1000, batch:   340/ 1052, ite: 27700] train loss: 0.007265, tar: 0.000612 
l0: 0.000653, l1: 0.000679, l2: 0.000649, l3: 0.000718, l4: 0.000775, l5: 0.001285, l6: 0.002258

[epoch: 106/1000, batch:   420/ 1052, ite: 27720] train loss: 0.007265, tar: 0.000612 
l0: 0.000402, l1: 0.000390, l2: 0.000393, l3: 0.000413, l4: 0.000651, l5: 0.001025, l6: 0.002662

[epoch: 106/1000, batch:   500/ 1052, ite: 27740] train loss: 0.007262, tar: 0.000612 
l0: 0.000419, l1: 0.000411, l2: 0.000433, l3: 0.000511, l4: 0.000692, l5: 0.000990, l6: 0.002226

[epoch: 106/1000, batch:   580/ 1052, ite: 27760] train loss: 0.007263, tar: 0.000612 
l0: 0.000432, l1: 0.000443, l2: 0.000476, l3: 0.000491, l4: 0.000747, l5: 0.001204, l6: 0.002158

[epoch: 106/1000, batch:   660/ 1052, ite: 27780] train loss: 0.007262, tar: 0.000612 
l0: 0.000632, l1: 0.000647, l2: 0.000681, l3: 0.000691, l4: 0.000951, l5: 0.001157, l6: 0.002047

[epoch: 106/1000, batch:   740/ 1052, ite: 27800] train loss: 0.007258, tar: 0.000611 
l0: 0.000310, l1: 0.000301, l2: 0.000311, l3: 0.000350, l4: 0.000545, l5: 0.001274, l6: 0.001835

[epoch: 106/1000, batch:   820/ 1052, ite: 27820] train loss: 0.007254, tar: 0.000611 
l0: 0.000504, l1: 0.000507, l2: 0.000576, l3: 0.000544, l4: 0.000942, l5: 0.001524, l6: 0.002867

[epoch: 106/1000, batch:   900/ 1052, ite: 27840] train loss: 0.007254, tar: 0.000611 
l0: 0.000298, l1: 0.000318, l2: 0.000305, l3: 0.000424, l4: 0.000500, l5: 0.000753, l6: 0.001450

[epoch: 106/1000, batch:   980/ 1052, ite: 27860] train loss: 0.007249, tar: 0.000610 
[Epoch 106/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000482, l1: 0.000512, l2: 0.000525, l3: 0.000462, l4: 0.000666, l5: 0.000949, l6: 0.001802

[epoch: 107/1000, batch:     8/ 1052, ite: 27880] train loss: 0.007248, tar: 0.000610 
l0: 0.000459, l1: 0.000449, l2: 0.000443, l3: 0.000458, l4: 0.000556, l5: 0.000729, l6: 0.001411

[epoch: 107/1000, batch:    88/ 1052, ite: 27900] train loss: 0.007250, tar: 0.000610 
l0: 0.000629, l1: 0.000660, l2: 0.000660, l3: 0.000613, l4: 0.000740, l5: 0.001362, l6: 0.002089

[epoch: 107/1000, batch:   168/ 1052, ite: 27920] train loss: 0.007247, tar: 0.000610 
l0: 0.000613, l1: 0.000599, l2: 0.000680, l3: 0.000887, l4: 0.001246, l5: 0.001521, l6: 0.002056

[epoch: 107/1000, batch:   248/ 1052, ite: 27940] train loss: 0.007245, tar: 0.000609 
l0: 0.000304, l1: 0.000319, l2: 0.000314, l3: 0.000315, l4: 0.000562, l5: 0.001129, l6: 0.001740

[epoch: 107/1000, batch:   328/ 1052, ite: 27960] train loss: 0.007241, tar: 0.000609 
l0: 0.000338, l1: 0.000318, l2: 0.000355, l3: 0.000475, l4: 0.000758, l5: 0.001276, l6: 0.001205

[epoch: 107/1000, batch:   408/ 1052, ite: 27980] train loss: 0.007236, tar: 0.000609 
l0: 0.000258, l1: 0.000255, l2: 0.000280, l3: 0.000308, l4: 0.000524, l5: 0.000882, l6: 0.001333

[epoch: 107/1000, batch:   488/ 1052, ite: 28000] train loss: 0.007236, tar: 0.000608 
l0: 0.000650, l1: 0.000625, l2: 0.000731, l3: 0.000884, l4: 0.001208, l5: 0.002301, l6: 0.003641

[epoch: 107/1000, batch:   568/ 1052, ite: 28020] train loss: 0.007234, tar: 0.000608 
l0: 0.000582, l1: 0.000548, l2: 0.000572, l3: 0.000772, l4: 0.001061, l5: 0.001671, l6: 0.002714

[epoch: 107/1000, batch:   648/ 1052, ite: 28040] train loss: 0.007234, tar: 0.000608 
l0: 0.000225, l1: 0.000232, l2: 0.000240, l3: 0.000255, l4: 0.000515, l5: 0.000891, l6: 0.001200

[epoch: 107/1000, batch:   728/ 1052, ite: 28060] train loss: 0.007234, tar: 0.000608 
l0: 0.000436, l1: 0.000436, l2: 0.000477, l3: 0.000620, l4: 0.000595, l5: 0.001362, l6: 0.002457

[epoch: 107/1000, batch:   808/ 1052, ite: 28080] train loss: 0.007234, tar: 0.000608 
l0: 0.000259, l1: 0.000255, l2: 0.000282, l3: 0.000328, l4: 0.000571, l5: 0.000780, l6: 0.001620

[epoch: 107/1000, batch:   888/ 1052, ite: 28100] train loss: 0.007232, tar: 0.000608 
l0: 0.000397, l1: 0.000377, l2: 0.000378, l3: 0.000453, l4: 0.000630, l5: 0.000958, l6: 0.001206

[epoch: 107/1000, batch:   968/ 1052, ite: 28120] train loss: 0.007228, tar: 0.000608 
l0: 0.000568, l1: 0.000541, l2: 0.000574, l3: 0.000614, l4: 0.000818, l5: 0.001869, l6: 0.003119

[epoch: 107/1000, batch:  1048/ 1052, ite: 28140] train loss: 0.007230, tar: 0.000608 
[Epoch 107/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000509, l1: 0.000529, l2: 0.000510, l3: 0.000609, l4: 0.000717, l5: 0.001056, l6: 0.001675

[epoch: 108/1000, batch:    76/ 1052, ite: 28160] train loss: 0.007228, tar: 0.000608 
l0: 0.000524, l1: 0.000539, l2: 0.000530, l3: 0.000543, l4: 0.000803, l5: 0.001138, l6: 0.001971

[epoch: 108/1000, batch:   156/ 1052, ite: 28180] train loss: 0.007226, tar: 0.000607 
l0: 0.000221, l1: 0.000227, l2: 0.000238, l3: 0.000376, l4: 0.000326, l5: 0.000535, l6: 0.000737

[epoch: 108/1000, batch:   236/ 1052, ite: 28200] train loss: 0.007227, tar: 0.000607 
l0: 0.000639, l1: 0.000604, l2: 0.000660, l3: 0.000981, l4: 0.001373, l5: 0.002049, l6: 0.003123

[epoch: 108/1000, batch:   316/ 1052, ite: 28220] train loss: 0.007229, tar: 0.000608 
l0: 0.000362, l1: 0.000370, l2: 0.000366, l3: 0.000471, l4: 0.000595, l5: 0.000886, l6: 0.001685

[epoch: 108/1000, batch:   396/ 1052, ite: 28240] train loss: 0.007227, tar: 0.000607 
l0: 0.000217, l1: 0.000217, l2: 0.000224, l3: 0.000274, l4: 0.000423, l5: 0.000833, l6: 0.001222

[epoch: 108/1000, batch:   476/ 1052, ite: 28260] train loss: 0.007225, tar: 0.000607 
l0: 0.001131, l1: 0.001107, l2: 0.001108, l3: 0.001236, l4: 0.001553, l5: 0.001937, l6: 0.002579

[epoch: 108/1000, batch:   556/ 1052, ite: 28280] train loss: 0.007225, tar: 0.000607 
l0: 0.000837, l1: 0.000822, l2: 0.000915, l3: 0.000970, l4: 0.001460, l5: 0.002241, l6: 0.003064

[epoch: 108/1000, batch:   636/ 1052, ite: 28300] train loss: 0.007222, tar: 0.000607 
l0: 0.000562, l1: 0.000588, l2: 0.000593, l3: 0.000636, l4: 0.000842, l5: 0.001324, l6: 0.001958

[epoch: 108/1000, batch:   716/ 1052, ite: 28320] train loss: 0.007220, tar: 0.000607 
l0: 0.000876, l1: 0.000893, l2: 0.000910, l3: 0.000939, l4: 0.001144, l5: 0.002162, l6: 0.003112

[epoch: 108/1000, batch:   796/ 1052, ite: 28340] train loss: 0.007221, tar: 0.000607 
l0: 0.000520, l1: 0.000506, l2: 0.000543, l3: 0.000541, l4: 0.000737, l5: 0.001256, l6: 0.002132

[epoch: 108/1000, batch:   876/ 1052, ite: 28360] train loss: 0.007219, tar: 0.000607 
l0: 0.000714, l1: 0.000823, l2: 0.000848, l3: 0.000733, l4: 0.000996, l5: 0.001685, l6: 0.002250

[epoch: 108/1000, batch:   956/ 1052, ite: 28380] train loss: 0.007220, tar: 0.000607 
l0: 0.000712, l1: 0.000729, l2: 0.000777, l3: 0.000819, l4: 0.000844, l5: 0.001095, l6: 0.002074

[epoch: 108/1000, batch:  1036/ 1052, ite: 28400] train loss: 0.007223, tar: 0.000607 
[Epoch 108/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000963, l1: 0.001007, l2: 0.001058, l3: 0.001010, l4: 0.001150, l5: 0.001371, l6: 0.002123

[epoch: 109/1000, batch:    64/ 1052, ite: 28420] train loss: 0.007224, tar: 0.000607 
l0: 0.000712, l1: 0.000739, l2: 0.000690, l3: 0.000717, l4: 0.000850, l5: 0.001173, l6: 0.001735

[epoch: 109/1000, batch:   144/ 1052, ite: 28440] train loss: 0.007222, tar: 0.000607 
l0: 0.000315, l1: 0.000348, l2: 0.000361, l3: 0.000329, l4: 0.000447, l5: 0.000935, l6: 0.001342

[epoch: 109/1000, batch:   224/ 1052, ite: 28460] train loss: 0.007221, tar: 0.000607 
l0: 0.000312, l1: 0.000310, l2: 0.000341, l3: 0.000413, l4: 0.000620, l5: 0.000926, l6: 0.001788

[epoch: 109/1000, batch:   304/ 1052, ite: 28480] train loss: 0.007222, tar: 0.000607 
l0: 0.000583, l1: 0.000627, l2: 0.000569, l3: 0.000670, l4: 0.001253, l5: 0.001675, l6: 0.002834

[epoch: 109/1000, batch:   384/ 1052, ite: 28500] train loss: 0.007219, tar: 0.000607 
l0: 0.007655, l1: 0.007108, l2: 0.008279, l3: 0.010461, l4: 0.007244, l5: 0.012827, l6: 0.011472

[epoch: 109/1000, batch:   464/ 1052, ite: 28520] train loss: 0.007236, tar: 0.000609 
l0: 0.000695, l1: 0.000748, l2: 0.000639, l3: 0.000621, l4: 0.001033, l5: 0.001586, l6: 0.001635

[epoch: 109/1000, batch:   544/ 1052, ite: 28540] train loss: 0.007239, tar: 0.000610 
l0: 0.001379, l1: 0.001468, l2: 0.001457, l3: 0.001532, l4: 0.001623, l5: 0.002074, l6: 0.003446

[epoch: 109/1000, batch:   624/ 1052, ite: 28560] train loss: 0.007241, tar: 0.000610 
l0: 0.000643, l1: 0.000684, l2: 0.000683, l3: 0.000652, l4: 0.000742, l5: 0.001170, l6: 0.001181

[epoch: 109/1000, batch:   704/ 1052, ite: 28580] train loss: 0.007244, tar: 0.000610 
l0: 0.000673, l1: 0.000713, l2: 0.000705, l3: 0.000796, l4: 0.000962, l5: 0.001754, l6: 0.002281

[epoch: 109/1000, batch:   784/ 1052, ite: 28600] train loss: 0.007245, tar: 0.000610 
l0: 0.000358, l1: 0.000385, l2: 0.000359, l3: 0.000424, l4: 0.000591, l5: 0.000989, l6: 0.001539

[epoch: 109/1000, batch:   864/ 1052, ite: 28620] train loss: 0.007244, tar: 0.000610 
l0: 0.001065, l1: 0.001046, l2: 0.001040, l3: 0.001347, l4: 0.002494, l5: 0.002199, l6: 0.002123

[epoch: 109/1000, batch:   944/ 1052, ite: 28640] train loss: 0.007244, tar: 0.000610 
l0: 0.000429, l1: 0.000388, l2: 0.000433, l3: 0.000439, l4: 0.000798, l5: 0.002072, l6: 0.001551

[epoch: 109/1000, batch:  1024/ 1052, ite: 28660] train loss: 0.007245, tar: 0.000610 
[Epoch 109/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000111, l1: 0.000106, l2: 0.000127, l3: 0.000168, l4: 0.000311, l5: 0.000481, l6: 0.000524

[epoch: 110/1000, batch:    52/ 1052, ite: 28680] train loss: 0.007242, tar: 0.000610 
l0: 0.000646, l1: 0.000720, l2: 0.000645, l3: 0.000570, l4: 0.000628, l5: 0.001265, l6: 0.001778

[epoch: 110/1000, batch:   132/ 1052, ite: 28700] train loss: 0.007240, tar: 0.000610 
l0: 0.000729, l1: 0.000734, l2: 0.001770, l3: 0.001014, l4: 0.001222, l5: 0.002451, l6: 0.003512

[epoch: 110/1000, batch:   212/ 1052, ite: 28720] train loss: 0.007241, tar: 0.000610 
l0: 0.000377, l1: 0.000375, l2: 0.000355, l3: 0.000467, l4: 0.000569, l5: 0.001046, l6: 0.001503

[epoch: 110/1000, batch:   292/ 1052, ite: 28740] train loss: 0.007240, tar: 0.000610 
l0: 0.001850, l1: 0.002027, l2: 0.001888, l3: 0.002114, l4: 0.002483, l5: 0.002750, l6: 0.004944

[epoch: 110/1000, batch:   372/ 1052, ite: 28760] train loss: 0.007245, tar: 0.000610 
l0: 0.001321, l1: 0.001362, l2: 0.001040, l3: 0.001285, l4: 0.001560, l5: 0.001613, l6: 0.002206

[epoch: 110/1000, batch:   452/ 1052, ite: 28780] train loss: 0.007247, tar: 0.000611 
l0: 0.000304, l1: 0.000293, l2: 0.000371, l3: 0.000379, l4: 0.000485, l5: 0.000652, l6: 0.001317

[epoch: 110/1000, batch:   532/ 1052, ite: 28800] train loss: 0.007255, tar: 0.000612 
l0: 0.001664, l1: 0.001844, l2: 0.001762, l3: 0.001938, l4: 0.001845, l5: 0.002174, l6: 0.003002

[epoch: 110/1000, batch:   612/ 1052, ite: 28820] train loss: 0.007257, tar: 0.000612 
l0: 0.000494, l1: 0.000468, l2: 0.000507, l3: 0.000528, l4: 0.000656, l5: 0.001111, l6: 0.001949

[epoch: 110/1000, batch:   692/ 1052, ite: 28840] train loss: 0.007255, tar: 0.000612 
l0: 0.000276, l1: 0.000269, l2: 0.000285, l3: 0.000377, l4: 0.000566, l5: 0.000808, l6: 0.001117

[epoch: 110/1000, batch:   772/ 1052, ite: 28860] train loss: 0.007252, tar: 0.000612 
l0: 0.000339, l1: 0.000333, l2: 0.000365, l3: 0.000424, l4: 0.000613, l5: 0.000999, l6: 0.002129

[epoch: 110/1000, batch:   852/ 1052, ite: 28880] train loss: 0.007249, tar: 0.000612 
l0: 0.000774, l1: 0.000809, l2: 0.000805, l3: 0.000741, l4: 0.001060, l5: 0.001907, l6: 0.002143

[epoch: 110/1000, batch:   932/ 1052, ite: 28900] train loss: 0.007247, tar: 0.000611 
l0: 0.000676, l1: 0.000646, l2: 0.000707, l3: 0.000772, l4: 0.001136, l5: 0.001777, l6: 0.002604

[epoch: 110/1000, batch:  1012/ 1052, ite: 28920] train loss: 0.007246, tar: 0.000611 
[Epoch 110/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000648, l1: 0.000647, l2: 0.000651, l3: 0.000744, l4: 0.001074, l5: 0.001652, l6: 0.002269

[epoch: 111/1000, batch:    40/ 1052, ite: 28940] train loss: 0.007246, tar: 0.000611 
l0: 0.000602, l1: 0.000631, l2: 0.000640, l3: 0.000757, l4: 0.001191, l5: 0.001587, l6: 0.002290

[epoch: 111/1000, batch:   120/ 1052, ite: 28960] train loss: 0.007243, tar: 0.000611 
l0: 0.000421, l1: 0.000434, l2: 0.000452, l3: 0.000467, l4: 0.000637, l5: 0.001308, l6: 0.002675

[epoch: 111/1000, batch:   200/ 1052, ite: 28980] train loss: 0.007240, tar: 0.000610 
l0: 0.000396, l1: 0.000416, l2: 0.000420, l3: 0.000435, l4: 0.000600, l5: 0.001445, l6: 0.001949

[epoch: 111/1000, batch:   280/ 1052, ite: 29000] train loss: 0.007239, tar: 0.000610 
l0: 0.000578, l1: 0.000601, l2: 0.000641, l3: 0.000683, l4: 0.000690, l5: 0.001189, l6: 0.001707

[epoch: 111/1000, batch:   360/ 1052, ite: 29020] train loss: 0.007238, tar: 0.000610 
l0: 0.000365, l1: 0.000366, l2: 0.000422, l3: 0.000490, l4: 0.000608, l5: 0.001089, l6: 0.001802

[epoch: 111/1000, batch:   440/ 1052, ite: 29040] train loss: 0.007237, tar: 0.000610 
l0: 0.000830, l1: 0.000826, l2: 0.000918, l3: 0.001325, l4: 0.001391, l5: 0.002166, l6: 0.003833

[epoch: 111/1000, batch:   520/ 1052, ite: 29060] train loss: 0.007238, tar: 0.000610 
l0: 0.000409, l1: 0.000465, l2: 0.000397, l3: 0.000410, l4: 0.000450, l5: 0.000903, l6: 0.001527

[epoch: 111/1000, batch:   600/ 1052, ite: 29080] train loss: 0.007236, tar: 0.000610 
l0: 0.000762, l1: 0.000842, l2: 0.000727, l3: 0.000883, l4: 0.000906, l5: 0.001238, l6: 0.002301

[epoch: 111/1000, batch:   680/ 1052, ite: 29100] train loss: 0.007233, tar: 0.000610 
l0: 0.000301, l1: 0.000283, l2: 0.000317, l3: 0.000415, l4: 0.000586, l5: 0.001226, l6: 0.002180

[epoch: 111/1000, batch:   760/ 1052, ite: 29120] train loss: 0.007231, tar: 0.000609 
l0: 0.000885, l1: 0.000878, l2: 0.000883, l3: 0.000988, l4: 0.001518, l5: 0.002448, l6: 0.005115

[epoch: 111/1000, batch:   840/ 1052, ite: 29140] train loss: 0.007231, tar: 0.000609 
l0: 0.000329, l1: 0.000329, l2: 0.000358, l3: 0.000367, l4: 0.000426, l5: 0.000924, l6: 0.001681

[epoch: 111/1000, batch:   920/ 1052, ite: 29160] train loss: 0.007230, tar: 0.000609 
l0: 0.000368, l1: 0.000356, l2: 0.000352, l3: 0.000414, l4: 0.000537, l5: 0.000787, l6: 0.001488

[epoch: 111/1000, batch:  1000/ 1052, ite: 29180] train loss: 0.007229, tar: 0.000609 
[Epoch 111/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.001008, l1: 0.001191, l2: 0.001288, l3: 0.001248, l4: 0.001446, l5: 0.001427, l6: 0.002604

[epoch: 112/1000, batch:    28/ 1052, ite: 29200] train loss: 0.007236, tar: 0.000610 
l0: 0.000591, l1: 0.000567, l2: 0.000596, l3: 0.000749, l4: 0.001065, l5: 0.001155, l6: 0.002567

[epoch: 112/1000, batch:   108/ 1052, ite: 29220] train loss: 0.007233, tar: 0.000610 
l0: 0.000760, l1: 0.000823, l2: 0.000777, l3: 0.000920, l4: 0.001183, l5: 0.002244, l6: 0.003724

[epoch: 112/1000, batch:   188/ 1052, ite: 29240] train loss: 0.007232, tar: 0.000610 
l0: 0.000327, l1: 0.000323, l2: 0.000324, l3: 0.000368, l4: 0.000508, l5: 0.001002, l6: 0.002058

[epoch: 112/1000, batch:   268/ 1052, ite: 29260] train loss: 0.007230, tar: 0.000609 
l0: 0.000315, l1: 0.000332, l2: 0.000329, l3: 0.000371, l4: 0.000433, l5: 0.000871, l6: 0.001813

[epoch: 112/1000, batch:   348/ 1052, ite: 29280] train loss: 0.007228, tar: 0.000609 
l0: 0.000492, l1: 0.000484, l2: 0.000481, l3: 0.000525, l4: 0.000641, l5: 0.000958, l6: 0.001950

[epoch: 112/1000, batch:   428/ 1052, ite: 29300] train loss: 0.007227, tar: 0.000609 
l0: 0.000298, l1: 0.000290, l2: 0.000321, l3: 0.000383, l4: 0.000518, l5: 0.001113, l6: 0.002085

[epoch: 112/1000, batch:   508/ 1052, ite: 29320] train loss: 0.007226, tar: 0.000609 
l0: 0.000652, l1: 0.000669, l2: 0.000689, l3: 0.000719, l4: 0.000753, l5: 0.000860, l6: 0.001841

[epoch: 112/1000, batch:   588/ 1052, ite: 29340] train loss: 0.007224, tar: 0.000609 
l0: 0.000278, l1: 0.000264, l2: 0.000293, l3: 0.000325, l4: 0.000536, l5: 0.001125, l6: 0.001486

[epoch: 112/1000, batch:   668/ 1052, ite: 29360] train loss: 0.007222, tar: 0.000609 
l0: 0.000347, l1: 0.000387, l2: 0.000391, l3: 0.000365, l4: 0.000434, l5: 0.000861, l6: 0.001392

[epoch: 112/1000, batch:   748/ 1052, ite: 29380] train loss: 0.007221, tar: 0.000608 
l0: 0.000535, l1: 0.000560, l2: 0.000575, l3: 0.000715, l4: 0.000752, l5: 0.001098, l6: 0.002169

[epoch: 112/1000, batch:   828/ 1052, ite: 29400] train loss: 0.007220, tar: 0.000608 
l0: 0.000306, l1: 0.000345, l2: 0.000348, l3: 0.000335, l4: 0.000559, l5: 0.001124, l6: 0.001990

[epoch: 112/1000, batch:   908/ 1052, ite: 29420] train loss: 0.007221, tar: 0.000608 
l0: 0.001607, l1: 0.001645, l2: 0.001590, l3: 0.001670, l4: 0.002562, l5: 0.003790, l6: 0.006042

[epoch: 112/1000, batch:   988/ 1052, ite: 29440] train loss: 0.007223, tar: 0.000608 
[Epoch 112/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000486, l1: 0.000493, l2: 0.000486, l3: 0.000480, l4: 0.000647, l5: 0.000994, l6: 0.001479

[epoch: 113/1000, batch:    16/ 1052, ite: 29460] train loss: 0.007223, tar: 0.000608 
l0: 0.000792, l1: 0.000807, l2: 0.000812, l3: 0.000960, l4: 0.001113, l5: 0.001356, l6: 0.003336

[epoch: 113/1000, batch:    96/ 1052, ite: 29480] train loss: 0.007223, tar: 0.000608 
l0: 0.000531, l1: 0.000526, l2: 0.000564, l3: 0.000655, l4: 0.001117, l5: 0.001577, l6: 0.002431

[epoch: 113/1000, batch:   176/ 1052, ite: 29500] train loss: 0.007221, tar: 0.000608 
l0: 0.000560, l1: 0.000565, l2: 0.000595, l3: 0.000593, l4: 0.000836, l5: 0.001435, l6: 0.003295

[epoch: 113/1000, batch:   256/ 1052, ite: 29520] train loss: 0.007219, tar: 0.000608 
l0: 0.000479, l1: 0.000498, l2: 0.000521, l3: 0.000499, l4: 0.000738, l5: 0.001352, l6: 0.002411

[epoch: 113/1000, batch:   336/ 1052, ite: 29540] train loss: 0.007220, tar: 0.000608 
l0: 0.000417, l1: 0.000440, l2: 0.000464, l3: 0.000590, l4: 0.000884, l5: 0.001816, l6: 0.001961

[epoch: 113/1000, batch:   416/ 1052, ite: 29560] train loss: 0.007219, tar: 0.000608 
l0: 0.000579, l1: 0.000568, l2: 0.000607, l3: 0.000757, l4: 0.000958, l5: 0.001368, l6: 0.002581

[epoch: 113/1000, batch:   496/ 1052, ite: 29580] train loss: 0.007215, tar: 0.000607 
l0: 0.000386, l1: 0.000388, l2: 0.000396, l3: 0.000440, l4: 0.000585, l5: 0.001010, l6: 0.001746

[epoch: 113/1000, batch:   576/ 1052, ite: 29600] train loss: 0.007212, tar: 0.000607 
l0: 0.000564, l1: 0.000549, l2: 0.000585, l3: 0.000653, l4: 0.000954, l5: 0.000994, l6: 0.003024

[epoch: 113/1000, batch:   656/ 1052, ite: 29620] train loss: 0.007212, tar: 0.000607 
l0: 0.001166, l1: 0.001152, l2: 0.001232, l3: 0.001434, l4: 0.001943, l5: 0.003984, l6: 0.005984

[epoch: 113/1000, batch:   736/ 1052, ite: 29640] train loss: 0.007211, tar: 0.000607 
l0: 0.000633, l1: 0.000596, l2: 0.000660, l3: 0.000864, l4: 0.001259, l5: 0.002287, l6: 0.003179

[epoch: 113/1000, batch:   816/ 1052, ite: 29660] train loss: 0.007210, tar: 0.000607 
l0: 0.000421, l1: 0.000425, l2: 0.000414, l3: 0.000461, l4: 0.000736, l5: 0.000767, l6: 0.001530

[epoch: 113/1000, batch:   896/ 1052, ite: 29680] train loss: 0.007211, tar: 0.000607 
l0: 0.000161, l1: 0.000163, l2: 0.000164, l3: 0.000181, l4: 0.000178, l5: 0.000420, l6: 0.000674

[epoch: 113/1000, batch:   976/ 1052, ite: 29700] train loss: 0.007210, tar: 0.000607 
[Epoch 113/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000342, l1: 0.000347, l2: 0.000361, l3: 0.000491, l4: 0.000738, l5: 0.001375, l6: 0.002088

[epoch: 114/1000, batch:     4/ 1052, ite: 29720] train loss: 0.007206, tar: 0.000606 
l0: 0.000278, l1: 0.000284, l2: 0.000290, l3: 0.000363, l4: 0.000437, l5: 0.000871, l6: 0.001765

[epoch: 114/1000, batch:    84/ 1052, ite: 29740] train loss: 0.007203, tar: 0.000606 
l0: 0.000375, l1: 0.000385, l2: 0.000361, l3: 0.000396, l4: 0.000600, l5: 0.001292, l6: 0.001915

[epoch: 114/1000, batch:   164/ 1052, ite: 29760] train loss: 0.007201, tar: 0.000606 
l0: 0.000306, l1: 0.000348, l2: 0.000365, l3: 0.000388, l4: 0.000561, l5: 0.000827, l6: 0.001415

[epoch: 114/1000, batch:   244/ 1052, ite: 29780] train loss: 0.007201, tar: 0.000606 
l0: 0.000310, l1: 0.000298, l2: 0.000334, l3: 0.000378, l4: 0.000685, l5: 0.001285, l6: 0.002014

[epoch: 114/1000, batch:   324/ 1052, ite: 29800] train loss: 0.007201, tar: 0.000606 
l0: 0.000847, l1: 0.000871, l2: 0.000891, l3: 0.000988, l4: 0.001014, l5: 0.001452, l6: 0.002749

[epoch: 114/1000, batch:   404/ 1052, ite: 29820] train loss: 0.007200, tar: 0.000606 
l0: 0.000380, l1: 0.000407, l2: 0.000418, l3: 0.000403, l4: 0.000637, l5: 0.000978, l6: 0.001385

[epoch: 114/1000, batch:   484/ 1052, ite: 29840] train loss: 0.007200, tar: 0.000606 
l0: 0.001381, l1: 0.001451, l2: 0.001374, l3: 0.001453, l4: 0.002020, l5: 0.004518, l6: 0.005841

[epoch: 114/1000, batch:   564/ 1052, ite: 29860] train loss: 0.007199, tar: 0.000606 
l0: 0.000296, l1: 0.000305, l2: 0.000309, l3: 0.000365, l4: 0.000501, l5: 0.000582, l6: 0.000974

[epoch: 114/1000, batch:   644/ 1052, ite: 29880] train loss: 0.007196, tar: 0.000605 
l0: 0.000815, l1: 0.000858, l2: 0.000862, l3: 0.000879, l4: 0.001029, l5: 0.002028, l6: 0.002831

[epoch: 114/1000, batch:   724/ 1052, ite: 29900] train loss: 0.007197, tar: 0.000605 
l0: 0.000657, l1: 0.000677, l2: 0.000720, l3: 0.000692, l4: 0.000860, l5: 0.001474, l6: 0.001982

[epoch: 114/1000, batch:   804/ 1052, ite: 29920] train loss: 0.007195, tar: 0.000605 
l0: 0.000558, l1: 0.000574, l2: 0.000586, l3: 0.000783, l4: 0.001143, l5: 0.001601, l6: 0.002576

[epoch: 114/1000, batch:   884/ 1052, ite: 29940] train loss: 0.007198, tar: 0.000605 
l0: 0.000390, l1: 0.000403, l2: 0.000459, l3: 0.000471, l4: 0.000586, l5: 0.001006, l6: 0.001630

[epoch: 114/1000, batch:   964/ 1052, ite: 29960] train loss: 0.007196, tar: 0.000605 
l0: 0.000513, l1: 0.000606, l2: 0.000598, l3: 0.000715, l4: 0.000769, l5: 0.001376, l6: 0.002247

[epoch: 114/1000, batch:  1044/ 1052, ite: 29980] train loss: 0.007201, tar: 0.000606 
[Epoch 114/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000920, l1: 0.000927, l2: 0.000988, l3: 0.001221, l4: 0.001328, l5: 0.002141, l6: 0.002525

[epoch: 115/1000, batch:    72/ 1052, ite: 30000] train loss: 0.007203, tar: 0.000606 
l0: 0.000519, l1: 0.000508, l2: 0.000518, l3: 0.000617, l4: 0.000829, l5: 0.001384, l6: 0.002627

[epoch: 115/1000, batch:   152/ 1052, ite: 30020] train loss: 0.007203, tar: 0.000606 
l0: 0.000502, l1: 0.000505, l2: 0.000571, l3: 0.000769, l4: 0.000778, l5: 0.001248, l6: 0.001782

[epoch: 115/1000, batch:   232/ 1052, ite: 30040] train loss: 0.007202, tar: 0.000606 
l0: 0.000423, l1: 0.000433, l2: 0.000420, l3: 0.000465, l4: 0.000654, l5: 0.000867, l6: 0.002051

[epoch: 115/1000, batch:   312/ 1052, ite: 30060] train loss: 0.007204, tar: 0.000606 
l0: 0.000670, l1: 0.000684, l2: 0.000771, l3: 0.000762, l4: 0.001161, l5: 0.001745, l6: 0.001956

[epoch: 115/1000, batch:   392/ 1052, ite: 30080] train loss: 0.007202, tar: 0.000606 
l0: 0.002055, l1: 0.002372, l2: 0.002275, l3: 0.001680, l4: 0.002484, l5: 0.003185, l6: 0.005073

[epoch: 115/1000, batch:   472/ 1052, ite: 30100] train loss: 0.007202, tar: 0.000606 
l0: 0.000640, l1: 0.000622, l2: 0.000649, l3: 0.000851, l4: 0.001106, l5: 0.002165, l6: 0.003303

[epoch: 115/1000, batch:   552/ 1052, ite: 30120] train loss: 0.007202, tar: 0.000606 
l0: 0.000321, l1: 0.000310, l2: 0.000338, l3: 0.000432, l4: 0.000764, l5: 0.000968, l6: 0.001842

[epoch: 115/1000, batch:   632/ 1052, ite: 30140] train loss: 0.007204, tar: 0.000606 
l0: 0.000385, l1: 0.000381, l2: 0.000461, l3: 0.000470, l4: 0.000466, l5: 0.000874, l6: 0.001210

[epoch: 115/1000, batch:   712/ 1052, ite: 30160] train loss: 0.007205, tar: 0.000606 
l0: 0.000935, l1: 0.000969, l2: 0.001035, l3: 0.001262, l4: 0.001263, l5: 0.001459, l6: 0.002580

[epoch: 115/1000, batch:   792/ 1052, ite: 30180] train loss: 0.007206, tar: 0.000607 
l0: 0.000655, l1: 0.000628, l2: 0.000699, l3: 0.000939, l4: 0.000989, l5: 0.001233, l6: 0.001670

[epoch: 115/1000, batch:   872/ 1052, ite: 30200] train loss: 0.007205, tar: 0.000606 
l0: 0.000391, l1: 0.000409, l2: 0.000430, l3: 0.000405, l4: 0.000607, l5: 0.000952, l6: 0.001646

[epoch: 115/1000, batch:   952/ 1052, ite: 30220] train loss: 0.007204, tar: 0.000606 
l0: 0.000412, l1: 0.000411, l2: 0.000422, l3: 0.000527, l4: 0.000851, l5: 0.001196, l6: 0.001506

[epoch: 115/1000, batch:  1032/ 1052, ite: 30240] train loss: 0.007203, tar: 0.000606 
[Epoch 115/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000340, l1: 0.000344, l2: 0.000354, l3: 0.000393, l4: 0.000520, l5: 0.001171, l6: 0.001593

[epoch: 116/1000, batch:    60/ 1052, ite: 30260] train loss: 0.007202, tar: 0.000606 
l0: 0.000435, l1: 0.000455, l2: 0.000496, l3: 0.000480, l4: 0.000761, l5: 0.001162, l6: 0.002300

[epoch: 116/1000, batch:   140/ 1052, ite: 30280] train loss: 0.007201, tar: 0.000606 
l0: 0.000307, l1: 0.000317, l2: 0.000294, l3: 0.000347, l4: 0.000691, l5: 0.000922, l6: 0.001527

[epoch: 116/1000, batch:   220/ 1052, ite: 30300] train loss: 0.007199, tar: 0.000606 
l0: 0.001382, l1: 0.001477, l2: 0.001416, l3: 0.001764, l4: 0.001945, l5: 0.002355, l6: 0.004567

[epoch: 116/1000, batch:   300/ 1052, ite: 30320] train loss: 0.007198, tar: 0.000606 
l0: 0.000605, l1: 0.000597, l2: 0.000573, l3: 0.000524, l4: 0.000878, l5: 0.000967, l6: 0.001873

[epoch: 116/1000, batch:   380/ 1052, ite: 30340] train loss: 0.007196, tar: 0.000606 
l0: 0.000531, l1: 0.000542, l2: 0.000568, l3: 0.000590, l4: 0.000745, l5: 0.001216, l6: 0.002032

[epoch: 116/1000, batch:   460/ 1052, ite: 30360] train loss: 0.007194, tar: 0.000605 
l0: 0.000728, l1: 0.000733, l2: 0.000737, l3: 0.000841, l4: 0.000961, l5: 0.002531, l6: 0.003554

[epoch: 116/1000, batch:   540/ 1052, ite: 30380] train loss: 0.007195, tar: 0.000605 
l0: 0.000452, l1: 0.000435, l2: 0.000499, l3: 0.000666, l4: 0.000888, l5: 0.001387, l6: 0.002316

[epoch: 116/1000, batch:   620/ 1052, ite: 30400] train loss: 0.007195, tar: 0.000605 
l0: 0.000639, l1: 0.000645, l2: 0.000664, l3: 0.000712, l4: 0.001061, l5: 0.001753, l6: 0.003387

[epoch: 116/1000, batch:   700/ 1052, ite: 30420] train loss: 0.007195, tar: 0.000605 
l0: 0.000377, l1: 0.000378, l2: 0.000406, l3: 0.000494, l4: 0.000617, l5: 0.001383, l6: 0.001948

[epoch: 116/1000, batch:   780/ 1052, ite: 30440] train loss: 0.007195, tar: 0.000605 
l0: 0.000601, l1: 0.000620, l2: 0.000662, l3: 0.000660, l4: 0.000781, l5: 0.001260, l6: 0.002625

[epoch: 116/1000, batch:   860/ 1052, ite: 30460] train loss: 0.007193, tar: 0.000605 
l0: 0.000410, l1: 0.000388, l2: 0.000453, l3: 0.000580, l4: 0.000994, l5: 0.001253, l6: 0.002203

[epoch: 116/1000, batch:   940/ 1052, ite: 30480] train loss: 0.007192, tar: 0.000605 
l0: 0.000468, l1: 0.000488, l2: 0.000469, l3: 0.000477, l4: 0.000615, l5: 0.001298, l6: 0.001782

[epoch: 116/1000, batch:  1020/ 1052, ite: 30500] train loss: 0.007191, tar: 0.000605 
[Epoch 116/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000591, l1: 0.000587, l2: 0.000634, l3: 0.000622, l4: 0.000821, l5: 0.001296, l6: 0.002089

[epoch: 117/1000, batch:    48/ 1052, ite: 30520] train loss: 0.007191, tar: 0.000605 
l0: 0.000265, l1: 0.000285, l2: 0.000291, l3: 0.000302, l4: 0.000508, l5: 0.000641, l6: 0.000959

[epoch: 117/1000, batch:   128/ 1052, ite: 30540] train loss: 0.007190, tar: 0.000605 
l0: 0.000245, l1: 0.000267, l2: 0.000251, l3: 0.000321, l4: 0.000469, l5: 0.001185, l6: 0.001719

[epoch: 117/1000, batch:   208/ 1052, ite: 30560] train loss: 0.007189, tar: 0.000604 
l0: 0.000376, l1: 0.000382, l2: 0.000402, l3: 0.000488, l4: 0.000512, l5: 0.000898, l6: 0.001810

[epoch: 117/1000, batch:   288/ 1052, ite: 30580] train loss: 0.007187, tar: 0.000604 
l0: 0.000858, l1: 0.000872, l2: 0.000867, l3: 0.000963, l4: 0.001302, l5: 0.002206, l6: 0.003704

[epoch: 117/1000, batch:   368/ 1052, ite: 30600] train loss: 0.007185, tar: 0.000604 
l0: 0.000566, l1: 0.000553, l2: 0.000581, l3: 0.000625, l4: 0.000732, l5: 0.001160, l6: 0.001784

[epoch: 117/1000, batch:   448/ 1052, ite: 30620] train loss: 0.007182, tar: 0.000604 
l0: 0.000473, l1: 0.000464, l2: 0.000482, l3: 0.000547, l4: 0.000722, l5: 0.001448, l6: 0.002642

[epoch: 117/1000, batch:   528/ 1052, ite: 30640] train loss: 0.007180, tar: 0.000603 
l0: 0.000918, l1: 0.000909, l2: 0.000910, l3: 0.000872, l4: 0.001032, l5: 0.001381, l6: 0.001868

[epoch: 117/1000, batch:   608/ 1052, ite: 30660] train loss: 0.007178, tar: 0.000603 
l0: 0.000312, l1: 0.000298, l2: 0.000342, l3: 0.000429, l4: 0.000492, l5: 0.000869, l6: 0.001251

[epoch: 117/1000, batch:   688/ 1052, ite: 30680] train loss: 0.007177, tar: 0.000603 
l0: 0.000293, l1: 0.000283, l2: 0.000302, l3: 0.000362, l4: 0.000510, l5: 0.000865, l6: 0.001227

[epoch: 117/1000, batch:   768/ 1052, ite: 30700] train loss: 0.007176, tar: 0.000603 
l0: 0.000346, l1: 0.000342, l2: 0.000332, l3: 0.000462, l4: 0.000594, l5: 0.001133, l6: 0.001278

[epoch: 117/1000, batch:   848/ 1052, ite: 30720] train loss: 0.007175, tar: 0.000603 
l0: 0.000600, l1: 0.000600, l2: 0.000581, l3: 0.000721, l4: 0.000880, l5: 0.001556, l6: 0.002164

[epoch: 117/1000, batch:   928/ 1052, ite: 30740] train loss: 0.007179, tar: 0.000603 
l0: 0.000477, l1: 0.000474, l2: 0.000494, l3: 0.000706, l4: 0.001056, l5: 0.001131, l6: 0.001449

[epoch: 117/1000, batch:  1008/ 1052, ite: 30760] train loss: 0.007178, tar: 0.000603 
[Epoch 117/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000406, l1: 0.000411, l2: 0.000433, l3: 0.000540, l4: 0.000782, l5: 0.001141, l6: 0.001883

[epoch: 118/1000, batch:    36/ 1052, ite: 30780] train loss: 0.007176, tar: 0.000603 
l0: 0.000457, l1: 0.000434, l2: 0.000468, l3: 0.000708, l4: 0.000996, l5: 0.001735, l6: 0.002130

[epoch: 118/1000, batch:   116/ 1052, ite: 30800] train loss: 0.007173, tar: 0.000603 
l0: 0.000543, l1: 0.000507, l2: 0.000591, l3: 0.000686, l4: 0.001226, l5: 0.001853, l6: 0.002133

[epoch: 118/1000, batch:   196/ 1052, ite: 30820] train loss: 0.007171, tar: 0.000602 
l0: 0.000435, l1: 0.000409, l2: 0.000545, l3: 0.000714, l4: 0.000841, l5: 0.001263, l6: 0.001857

[epoch: 118/1000, batch:   276/ 1052, ite: 30840] train loss: 0.007168, tar: 0.000602 
l0: 0.000800, l1: 0.000822, l2: 0.000888, l3: 0.000861, l4: 0.001018, l5: 0.001237, l6: 0.001849

[epoch: 118/1000, batch:   356/ 1052, ite: 30860] train loss: 0.007170, tar: 0.000602 
l0: 0.000590, l1: 0.000992, l2: 0.000669, l3: 0.000608, l4: 0.000787, l5: 0.001651, l6: 0.002450

[epoch: 118/1000, batch:   436/ 1052, ite: 30880] train loss: 0.007171, tar: 0.000602 
l0: 0.000439, l1: 0.000457, l2: 0.001100, l3: 0.000734, l4: 0.000799, l5: 0.001230, l6: 0.001928

[epoch: 118/1000, batch:   516/ 1052, ite: 30900] train loss: 0.007170, tar: 0.000602 
l0: 0.000449, l1: 0.000449, l2: 0.000487, l3: 0.000556, l4: 0.000898, l5: 0.001721, l6: 0.003038

[epoch: 118/1000, batch:   596/ 1052, ite: 30920] train loss: 0.007170, tar: 0.000602 
l0: 0.000551, l1: 0.000545, l2: 0.000606, l3: 0.000720, l4: 0.001144, l5: 0.001785, l6: 0.002852

[epoch: 118/1000, batch:   676/ 1052, ite: 30940] train loss: 0.007171, tar: 0.000602 
l0: 0.001425, l1: 0.001569, l2: 0.001444, l3: 0.001433, l4: 0.001657, l5: 0.002168, l6: 0.004050

[epoch: 118/1000, batch:   756/ 1052, ite: 30960] train loss: 0.007171, tar: 0.000602 
l0: 0.000680, l1: 0.000655, l2: 0.000698, l3: 0.000839, l4: 0.001120, l5: 0.001425, l6: 0.002008

[epoch: 118/1000, batch:   836/ 1052, ite: 30980] train loss: 0.007172, tar: 0.000602 
l0: 0.000282, l1: 0.000287, l2: 0.000311, l3: 0.000333, l4: 0.000549, l5: 0.000843, l6: 0.001626

[epoch: 118/1000, batch:   916/ 1052, ite: 31000] train loss: 0.007171, tar: 0.000602 
l0: 0.000553, l1: 0.000538, l2: 0.000562, l3: 0.000672, l4: 0.000846, l5: 0.001479, l6: 0.002673

[epoch: 118/1000, batch:   996/ 1052, ite: 31020] train loss: 0.007172, tar: 0.000602 
[Epoch 118/1000] Test loss: 0.007, Test target loss: 0.001
l0: 0.000432, l1: 0.000426, l2: 0.000525, l3: 0.000526, l4: 0.000679, l5: 0.001186, l6: 0.001742

[epoch: 119/1000, batch:    24/ 1052, ite: 31040] train loss: 0.007168, tar: 0.000602 
l0: 0.000632, l1: 0.000639, l2: 0.000670, l3: 0.000644, l4: 0.000947, l5: 0.001501, l6: 0.002648

[epoch: 119/1000, batch:   104/ 1052, ite: 31060] train loss: 0.007169, tar: 0.000602 
l0: 0.000345, l1: 0.000351, l2: 0.000389, l3: 0.000410, l4: 0.000579, l5: 0.000880, l6: 0.001879

[epoch: 119/1000, batch:   184/ 1052, ite: 31080] train loss: 0.007172, tar: 0.000602 
l0: 0.000439, l1: 0.000456, l2: 0.000462, l3: 0.000496, l4: 0.000674, l5: 0.000991, l6: 0.002162

[epoch: 119/1000, batch:   264/ 1052, ite: 31100] train loss: 0.007171, tar: 0.000602 
l0: 0.000325, l1: 0.000332, l2: 0.000358, l3: 0.000353, l4: 0.000537, l5: 0.001000, l6: 0.001364

[epoch: 119/1000, batch:   344/ 1052, ite: 31120] train loss: 0.007169, tar: 0.000602 
l0: 0.000520, l1: 0.000526, l2: 0.000549, l3: 0.000610, l4: 0.000843, l5: 0.001547, l6: 0.002533

[epoch: 119/1000, batch:   424/ 1052, ite: 31140] train loss: 0.007171, tar: 0.000602 
l0: 0.000298, l1: 0.000293, l2: 0.000305, l3: 0.000402, l4: 0.000518, l5: 0.000783, l6: 0.001543

[epoch: 119/1000, batch:   504/ 1052, ite: 31160] train loss: 0.007170, tar: 0.000602 
l0: 0.000676, l1: 0.000680, l2: 0.000745, l3: 0.000744, l4: 0.000961, l5: 0.002058, l6: 0.003708

[epoch: 119/1000, batch:   584/ 1052, ite: 31180] train loss: 0.007170, tar: 0.000602 
l0: 0.000296, l1: 0.000305, l2: 0.000319, l3: 0.000315, l4: 0.000498, l5: 0.000937, l6: 0.001909

[epoch: 119/1000, batch:   664/ 1052, ite: 31200] train loss: 0.007169, tar: 0.000602 
l0: 0.000408, l1: 0.000425, l2: 0.000497, l3: 0.000500, l4: 0.000799, l5: 0.001504, l6: 0.002107

[epoch: 119/1000, batch:   744/ 1052, ite: 31220] train loss: 0.007170, tar: 0.000602 
l0: 0.000732, l1: 0.000724, l2: 0.000783, l3: 0.000845, l4: 0.001423, l5: 0.002484, l6: 0.003713

[epoch: 119/1000, batch:   824/ 1052, ite: 31240] train loss: 0.007170, tar: 0.000602 
l0: 0.000502, l1: 0.000522, l2: 0.000551, l3: 0.000583, l4: 0.000737, l5: 0.001004, l6: 0.002164

[epoch: 119/1000, batch:   904/ 1052, ite: 31260] train loss: 0.007167, tar: 0.000602 
l0: 0.000576, l1: 0.000571, l2: 0.000633, l3: 0.000666, l4: 0.000973, l5: 0.002048, l6: 0.002450

[epoch: 119/1000, batch:   984/ 1052, ite: 31280] train loss: 0.007167, tar: 0.000601 
[Epoch 119/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000243, l1: 0.000251, l2: 0.000271, l3: 0.000334, l4: 0.000431, l5: 0.000780, l6: 0.000995

[epoch: 120/1000, batch:    12/ 1052, ite: 31300] train loss: 0.007164, tar: 0.000601 
l0: 0.000292, l1: 0.000299, l2: 0.000316, l3: 0.000353, l4: 0.000417, l5: 0.000835, l6: 0.001398

[epoch: 120/1000, batch:    92/ 1052, ite: 31320] train loss: 0.007162, tar: 0.000601 
l0: 0.000663, l1: 0.000768, l2: 0.000680, l3: 0.000669, l4: 0.000731, l5: 0.000877, l6: 0.001877

[epoch: 120/1000, batch:   172/ 1052, ite: 31340] train loss: 0.007160, tar: 0.000601 
l0: 0.000426, l1: 0.000412, l2: 0.000442, l3: 0.000604, l4: 0.000710, l5: 0.001380, l6: 0.002175

[epoch: 120/1000, batch:   252/ 1052, ite: 31360] train loss: 0.007158, tar: 0.000601 
l0: 0.000592, l1: 0.000561, l2: 0.000586, l3: 0.000690, l4: 0.001115, l5: 0.001843, l6: 0.002996

[epoch: 120/1000, batch:   332/ 1052, ite: 31380] train loss: 0.007159, tar: 0.000601 
l0: 0.000500, l1: 0.000522, l2: 0.000531, l3: 0.000551, l4: 0.000760, l5: 0.001377, l6: 0.002685

[epoch: 120/1000, batch:   412/ 1052, ite: 31400] train loss: 0.007157, tar: 0.000600 
l0: 0.000755, l1: 0.000796, l2: 0.000774, l3: 0.000795, l4: 0.000804, l5: 0.001302, l6: 0.002877

[epoch: 120/1000, batch:   492/ 1052, ite: 31420] train loss: 0.007157, tar: 0.000600 
l0: 0.000846, l1: 0.000943, l2: 0.000981, l3: 0.000871, l4: 0.001129, l5: 0.002251, l6: 0.003971

[epoch: 120/1000, batch:   572/ 1052, ite: 31440] train loss: 0.007159, tar: 0.000600 
l0: 0.000327, l1: 0.000316, l2: 0.000373, l3: 0.000450, l4: 0.000615, l5: 0.000709, l6: 0.001518

[epoch: 120/1000, batch:   652/ 1052, ite: 31460] train loss: 0.007156, tar: 0.000600 
l0: 0.000547, l1: 0.000523, l2: 0.000555, l3: 0.000739, l4: 0.001139, l5: 0.001724, l6: 0.001976

[epoch: 120/1000, batch:   732/ 1052, ite: 31480] train loss: 0.007158, tar: 0.000600 
l0: 0.000454, l1: 0.000435, l2: 0.000491, l3: 0.000490, l4: 0.000769, l5: 0.001115, l6: 0.001897

[epoch: 120/1000, batch:   812/ 1052, ite: 31500] train loss: 0.007157, tar: 0.000600 
l0: 0.000295, l1: 0.000289, l2: 0.000310, l3: 0.000402, l4: 0.000402, l5: 0.001043, l6: 0.001529

[epoch: 120/1000, batch:   892/ 1052, ite: 31520] train loss: 0.007154, tar: 0.000600 
l0: 0.000203, l1: 0.000198, l2: 0.000219, l3: 0.000275, l4: 0.000357, l5: 0.000567, l6: 0.001220

[epoch: 120/1000, batch:   972/ 1052, ite: 31540] train loss: 0.007152, tar: 0.000600 
l0: 0.000487, l1: 0.000495, l2: 0.000495, l3: 0.000570, l4: 0.001122, l5: 0.001685, l6: 0.003440

[epoch: 120/1000, batch:  1052/ 1052, ite: 31560] train loss: 0.007151, tar: 0.000600 
[Epoch 120/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000419, l1: 0.000447, l2: 0.000462, l3: 0.000516, l4: 0.000671, l5: 0.001284, l6: 0.002278

[epoch: 121/1000, batch:    80/ 1052, ite: 31580] train loss: 0.006078, tar: 0.000459 
l0: 0.001383, l1: 0.001479, l2: 0.001380, l3: 0.001455, l4: 0.001567, l5: 0.001440, l6: 0.003062

[epoch: 121/1000, batch:   160/ 1052, ite: 31600] train loss: 0.006617, tar: 0.000521 
l0: 0.000453, l1: 0.000466, l2: 0.000428, l3: 0.000467, l4: 0.000570, l5: 0.000804, l6: 0.002015

[epoch: 121/1000, batch:   240/ 1052, ite: 31620] train loss: 0.006653, tar: 0.000525 
l0: 0.001289, l1: 0.001441, l2: 0.001306, l3: 0.001231, l4: 0.001642, l5: 0.002913, l6: 0.004852

[epoch: 121/1000, batch:   320/ 1052, ite: 31640] train loss: 0.006658, tar: 0.000520 
l0: 0.000471, l1: 0.000436, l2: 0.000439, l3: 0.000467, l4: 0.000538, l5: 0.000933, l6: 0.001335

[epoch: 121/1000, batch:   400/ 1052, ite: 31660] train loss: 0.006651, tar: 0.000522 
l0: 0.000811, l1: 0.000858, l2: 0.000767, l3: 0.000848, l4: 0.001068, l5: 0.001168, l6: 0.002070

[epoch: 121/1000, batch:   480/ 1052, ite: 31680] train loss: 0.006700, tar: 0.000536 
l0: 0.000404, l1: 0.000390, l2: 0.000422, l3: 0.000489, l4: 0.000628, l5: 0.001149, l6: 0.002180

[epoch: 121/1000, batch:   560/ 1052, ite: 31700] train loss: 0.006605, tar: 0.000527 
l0: 0.000852, l1: 0.000794, l2: 0.000953, l3: 0.001188, l4: 0.000970, l5: 0.002172, l6: 0.002743

[epoch: 121/1000, batch:   640/ 1052, ite: 31720] train loss: 0.006498, tar: 0.000516 
l0: 0.000494, l1: 0.000500, l2: 0.000521, l3: 0.000595, l4: 0.000880, l5: 0.001554, l6: 0.002047

[epoch: 121/1000, batch:   720/ 1052, ite: 31740] train loss: 0.006540, tar: 0.000520 
l0: 0.000253, l1: 0.000257, l2: 0.000285, l3: 0.000299, l4: 0.000350, l5: 0.000865, l6: 0.001549

[epoch: 121/1000, batch:   800/ 1052, ite: 31760] train loss: 0.006495, tar: 0.000518 
l0: 0.000413, l1: 0.000388, l2: 0.000474, l3: 0.000526, l4: 0.000819, l5: 0.001792, l6: 0.002579

[epoch: 121/1000, batch:   880/ 1052, ite: 31780] train loss: 0.006495, tar: 0.000519 
l0: 0.000374, l1: 0.000396, l2: 0.000399, l3: 0.000461, l4: 0.000634, l5: 0.001049, l6: 0.001025

[epoch: 121/1000, batch:   960/ 1052, ite: 31800] train loss: 0.006518, tar: 0.000519 
l0: 0.000480, l1: 0.000505, l2: 0.000530, l3: 0.000631, l4: 0.000761, l5: 0.001369, l6: 0.003192

[epoch: 121/1000, batch:  1040/ 1052, ite: 31820] train loss: 0.006458, tar: 0.000516 
[Epoch 121/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.001069, l1: 0.001164, l2: 0.001032, l3: 0.001126, l4: 0.001335, l5: 0.002185, l6: 0.003771

[epoch: 122/1000, batch:    68/ 1052, ite: 31840] train loss: 0.006652, tar: 0.000540 
l0: 0.000180, l1: 0.000191, l2: 0.000218, l3: 0.000253, l4: 0.000290, l5: 0.000680, l6: 0.001349

[epoch: 122/1000, batch:   148/ 1052, ite: 31860] train loss: 0.006658, tar: 0.000542 
l0: 0.000220, l1: 0.000241, l2: 0.000237, l3: 0.000267, l4: 0.000459, l5: 0.000767, l6: 0.001227

[epoch: 122/1000, batch:   228/ 1052, ite: 31880] train loss: 0.006631, tar: 0.000540 
l0: 0.000353, l1: 0.000339, l2: 0.000374, l3: 0.000458, l4: 0.000659, l5: 0.000807, l6: 0.001138

[epoch: 122/1000, batch:   308/ 1052, ite: 31900] train loss: 0.006639, tar: 0.000540 
l0: 0.000648, l1: 0.000621, l2: 0.000664, l3: 0.000887, l4: 0.000958, l5: 0.001888, l6: 0.002880

[epoch: 122/1000, batch:   388/ 1052, ite: 31920] train loss: 0.006664, tar: 0.000540 
l0: 0.000403, l1: 0.000408, l2: 0.000410, l3: 0.000464, l4: 0.000710, l5: 0.001346, l6: 0.002295

[epoch: 122/1000, batch:   468/ 1052, ite: 31940] train loss: 0.006667, tar: 0.000541 
l0: 0.000398, l1: 0.000410, l2: 0.000400, l3: 0.000492, l4: 0.000739, l5: 0.001480, l6: 0.002297

[epoch: 122/1000, batch:   548/ 1052, ite: 31960] train loss: 0.006711, tar: 0.000545 
l0: 0.000380, l1: 0.000444, l2: 0.000338, l3: 0.000411, l4: 0.000474, l5: 0.000725, l6: 0.000808

[epoch: 122/1000, batch:   628/ 1052, ite: 31980] train loss: 0.006711, tar: 0.000548 
l0: 0.001098, l1: 0.000961, l2: 0.001341, l3: 0.001946, l4: 0.001369, l5: 0.002482, l6: 0.002515

[epoch: 122/1000, batch:   708/ 1052, ite: 32000] train loss: 0.006737, tar: 0.000553 
l0: 0.000339, l1: 0.000344, l2: 0.000442, l3: 0.000383, l4: 0.000663, l5: 0.001047, l6: 0.001650

[epoch: 122/1000, batch:   788/ 1052, ite: 32020] train loss: 0.006715, tar: 0.000552 
l0: 0.001218, l1: 0.001474, l2: 0.001167, l3: 0.001380, l4: 0.001506, l5: 0.002438, l6: 0.004126

[epoch: 122/1000, batch:   868/ 1052, ite: 32040] train loss: 0.006719, tar: 0.000551 
l0: 0.000446, l1: 0.000550, l2: 0.000461, l3: 0.000498, l4: 0.000734, l5: 0.001565, l6: 0.002294

[epoch: 122/1000, batch:   948/ 1052, ite: 32060] train loss: 0.006740, tar: 0.000553 
l0: 0.000914, l1: 0.000876, l2: 0.000854, l3: 0.001046, l4: 0.001830, l5: 0.003216, l6: 0.004372

[epoch: 122/1000, batch:  1028/ 1052, ite: 32080] train loss: 0.006729, tar: 0.000553 
[Epoch 122/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000414, l1: 0.000397, l2: 0.000429, l3: 0.000451, l4: 0.000606, l5: 0.001039, l6: 0.001365

[epoch: 123/1000, batch:    56/ 1052, ite: 32100] train loss: 0.006711, tar: 0.000551 
l0: 0.000272, l1: 0.000279, l2: 0.000315, l3: 0.000347, l4: 0.000595, l5: 0.000797, l6: 0.001332

[epoch: 123/1000, batch:   136/ 1052, ite: 32120] train loss: 0.006769, tar: 0.000556 
l0: 0.000398, l1: 0.000390, l2: 0.000423, l3: 0.000444, l4: 0.000598, l5: 0.001336, l6: 0.002560

[epoch: 123/1000, batch:   216/ 1052, ite: 32140] train loss: 0.006785, tar: 0.000557 
l0: 0.000465, l1: 0.000473, l2: 0.000505, l3: 0.000490, l4: 0.000603, l5: 0.001326, l6: 0.002313

[epoch: 123/1000, batch:   296/ 1052, ite: 32160] train loss: 0.006774, tar: 0.000556 
l0: 0.000318, l1: 0.000305, l2: 0.000323, l3: 0.000408, l4: 0.000510, l5: 0.001355, l6: 0.001963

[epoch: 123/1000, batch:   376/ 1052, ite: 32180] train loss: 0.006758, tar: 0.000556 
l0: 0.000679, l1: 0.000692, l2: 0.000756, l3: 0.000892, l4: 0.000936, l5: 0.000768, l6: 0.001641

[epoch: 123/1000, batch:   456/ 1052, ite: 32200] train loss: 0.006725, tar: 0.000553 
l0: 0.000436, l1: 0.000436, l2: 0.000442, l3: 0.000492, l4: 0.000859, l5: 0.001494, l6: 0.002183

[epoch: 123/1000, batch:   536/ 1052, ite: 32220] train loss: 0.006718, tar: 0.000553 
l0: 0.000581, l1: 0.000540, l2: 0.000586, l3: 0.000752, l4: 0.000882, l5: 0.001707, l6: 0.002891

[epoch: 123/1000, batch:   616/ 1052, ite: 32240] train loss: 0.006710, tar: 0.000551 
l0: 0.000777, l1: 0.000820, l2: 0.000796, l3: 0.000913, l4: 0.001028, l5: 0.001714, l6: 0.002672

[epoch: 123/1000, batch:   696/ 1052, ite: 32260] train loss: 0.006692, tar: 0.000548 
l0: 0.000841, l1: 0.000848, l2: 0.000934, l3: 0.001116, l4: 0.001515, l5: 0.002644, l6: 0.002872

[epoch: 123/1000, batch:   776/ 1052, ite: 32280] train loss: 0.006689, tar: 0.000547 
l0: 0.000583, l1: 0.000523, l2: 0.000601, l3: 0.000678, l4: 0.001123, l5: 0.001702, l6: 0.002099

[epoch: 123/1000, batch:   856/ 1052, ite: 32300] train loss: 0.006702, tar: 0.000547 
l0: 0.000483, l1: 0.000489, l2: 0.000502, l3: 0.000522, l4: 0.000685, l5: 0.001383, l6: 0.002694

[epoch: 123/1000, batch:   936/ 1052, ite: 32320] train loss: 0.006698, tar: 0.000547 
l0: 0.000404, l1: 0.000397, l2: 0.000407, l3: 0.000498, l4: 0.000725, l5: 0.001118, l6: 0.001735

[epoch: 123/1000, batch:  1016/ 1052, ite: 32340] train loss: 0.006681, tar: 0.000545 
[Epoch 123/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000481, l1: 0.000477, l2: 0.000443, l3: 0.000544, l4: 0.000724, l5: 0.001061, l6: 0.001947

[epoch: 124/1000, batch:    44/ 1052, ite: 32360] train loss: 0.006675, tar: 0.000545 
l0: 0.000589, l1: 0.000670, l2: 0.000662, l3: 0.000748, l4: 0.000945, l5: 0.001489, l6: 0.002817

[epoch: 124/1000, batch:   124/ 1052, ite: 32380] train loss: 0.006686, tar: 0.000546 
l0: 0.000377, l1: 0.000353, l2: 0.000388, l3: 0.000495, l4: 0.000703, l5: 0.001148, l6: 0.002016

[epoch: 124/1000, batch:   204/ 1052, ite: 32400] train loss: 0.006688, tar: 0.000548 
l0: 0.000316, l1: 0.000298, l2: 0.000318, l3: 0.000372, l4: 0.000658, l5: 0.000943, l6: 0.001528

[epoch: 124/1000, batch:   284/ 1052, ite: 32420] train loss: 0.006690, tar: 0.000547 
l0: 0.000503, l1: 0.000500, l2: 0.000503, l3: 0.000579, l4: 0.000872, l5: 0.001557, l6: 0.001860

[epoch: 124/1000, batch:   364/ 1052, ite: 32440] train loss: 0.006693, tar: 0.000547 
l0: 0.000485, l1: 0.000495, l2: 0.000536, l3: 0.000640, l4: 0.000741, l5: 0.001269, l6: 0.001677

[epoch: 124/1000, batch:   444/ 1052, ite: 32460] train loss: 0.006732, tar: 0.000551 
l0: 0.000385, l1: 0.000391, l2: 0.000423, l3: 0.000446, l4: 0.000616, l5: 0.001375, l6: 0.001404

[epoch: 124/1000, batch:   524/ 1052, ite: 32480] train loss: 0.006736, tar: 0.000552 
l0: 0.000230, l1: 0.000225, l2: 0.000251, l3: 0.000280, l4: 0.000460, l5: 0.000891, l6: 0.001292

[epoch: 124/1000, batch:   604/ 1052, ite: 32500] train loss: 0.006737, tar: 0.000551 
l0: 0.000273, l1: 0.000266, l2: 0.000332, l3: 0.000335, l4: 0.000456, l5: 0.000805, l6: 0.001452

[epoch: 124/1000, batch:   684/ 1052, ite: 32520] train loss: 0.006714, tar: 0.000549 
l0: 0.000464, l1: 0.000476, l2: 0.000459, l3: 0.000546, l4: 0.000845, l5: 0.001486, l6: 0.001467

[epoch: 124/1000, batch:   764/ 1052, ite: 32540] train loss: 0.006692, tar: 0.000547 
l0: 0.000453, l1: 0.000462, l2: 0.000497, l3: 0.000537, l4: 0.000781, l5: 0.001587, l6: 0.003103

[epoch: 124/1000, batch:   844/ 1052, ite: 32560] train loss: 0.006681, tar: 0.000546 
l0: 0.000657, l1: 0.000679, l2: 0.000682, l3: 0.000699, l4: 0.000867, l5: 0.002019, l6: 0.002310

[epoch: 124/1000, batch:   924/ 1052, ite: 32580] train loss: 0.006676, tar: 0.000545 
l0: 0.000617, l1: 0.000643, l2: 0.000651, l3: 0.000699, l4: 0.000758, l5: 0.001192, l6: 0.001538

[epoch: 124/1000, batch:  1004/ 1052, ite: 32600] train loss: 0.006656, tar: 0.000542 
[Epoch 124/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000377, l1: 0.000429, l2: 0.000411, l3: 0.000347, l4: 0.000390, l5: 0.001178, l6: 0.001131

[epoch: 125/1000, batch:    32/ 1052, ite: 32620] train loss: 0.006649, tar: 0.000541 
l0: 0.000283, l1: 0.000292, l2: 0.000304, l3: 0.000301, l4: 0.000510, l5: 0.000876, l6: 0.001121

[epoch: 125/1000, batch:   112/ 1052, ite: 32640] train loss: 0.006648, tar: 0.000541 
l0: 0.000490, l1: 0.000505, l2: 0.000472, l3: 0.000559, l4: 0.000609, l5: 0.001122, l6: 0.001533

[epoch: 125/1000, batch:   192/ 1052, ite: 32660] train loss: 0.006646, tar: 0.000540 
l0: 0.000975, l1: 0.000988, l2: 0.000964, l3: 0.001093, l4: 0.001233, l5: 0.002404, l6: 0.004970

[epoch: 125/1000, batch:   272/ 1052, ite: 32680] train loss: 0.006648, tar: 0.000540 
l0: 0.000637, l1: 0.000665, l2: 0.000704, l3: 0.000649, l4: 0.000976, l5: 0.001280, l6: 0.002503

[epoch: 125/1000, batch:   352/ 1052, ite: 32700] train loss: 0.006637, tar: 0.000539 
l0: 0.000708, l1: 0.000710, l2: 0.000775, l3: 0.000803, l4: 0.000873, l5: 0.001591, l6: 0.001717

[epoch: 125/1000, batch:   432/ 1052, ite: 32720] train loss: 0.006636, tar: 0.000538 
l0: 0.000727, l1: 0.000733, l2: 0.000752, l3: 0.000804, l4: 0.001075, l5: 0.001823, l6: 0.003152

[epoch: 125/1000, batch:   512/ 1052, ite: 32740] train loss: 0.006634, tar: 0.000539 
l0: 0.000807, l1: 0.000937, l2: 0.000983, l3: 0.000799, l4: 0.001000, l5: 0.001303, l6: 0.002963

[epoch: 125/1000, batch:   592/ 1052, ite: 32760] train loss: 0.006614, tar: 0.000537 
l0: 0.000425, l1: 0.000428, l2: 0.000435, l3: 0.000554, l4: 0.000826, l5: 0.001591, l6: 0.002562

[epoch: 125/1000, batch:   672/ 1052, ite: 32780] train loss: 0.006606, tar: 0.000537 
l0: 0.000452, l1: 0.000460, l2: 0.000449, l3: 0.000519, l4: 0.000707, l5: 0.001310, l6: 0.002695

[epoch: 125/1000, batch:   752/ 1052, ite: 32800] train loss: 0.006609, tar: 0.000536 
l0: 0.000862, l1: 0.000929, l2: 0.000866, l3: 0.000861, l4: 0.000893, l5: 0.001993, l6: 0.003052

[epoch: 125/1000, batch:   832/ 1052, ite: 32820] train loss: 0.006615, tar: 0.000537 
l0: 0.000883, l1: 0.000919, l2: 0.000893, l3: 0.000932, l4: 0.001186, l5: 0.001528, l6: 0.002815

[epoch: 125/1000, batch:   912/ 1052, ite: 32840] train loss: 0.006622, tar: 0.000538 
l0: 0.000623, l1: 0.000628, l2: 0.000595, l3: 0.000671, l4: 0.000893, l5: 0.002063, l6: 0.003533

[epoch: 125/1000, batch:   992/ 1052, ite: 32860] train loss: 0.006621, tar: 0.000537 
[Epoch 125/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.001119, l1: 0.001254, l2: 0.001162, l3: 0.000979, l4: 0.001354, l5: 0.001767, l6: 0.002775

[epoch: 126/1000, batch:    20/ 1052, ite: 32880] train loss: 0.006611, tar: 0.000536 
l0: 0.000438, l1: 0.000480, l2: 0.000405, l3: 0.000432, l4: 0.000650, l5: 0.000980, l6: 0.001382

[epoch: 126/1000, batch:   100/ 1052, ite: 32900] train loss: 0.006607, tar: 0.000535 
l0: 0.000186, l1: 0.000192, l2: 0.000221, l3: 0.000272, l4: 0.000324, l5: 0.000762, l6: 0.000812

[epoch: 126/1000, batch:   180/ 1052, ite: 32920] train loss: 0.006605, tar: 0.000535 
l0: 0.000578, l1: 0.000576, l2: 0.000626, l3: 0.000581, l4: 0.000896, l5: 0.001457, l6: 0.001955

[epoch: 126/1000, batch:   260/ 1052, ite: 32940] train loss: 0.006597, tar: 0.000534 
l0: 0.000520, l1: 0.000535, l2: 0.000528, l3: 0.000662, l4: 0.001075, l5: 0.001783, l6: 0.002573

[epoch: 126/1000, batch:   340/ 1052, ite: 32960] train loss: 0.006607, tar: 0.000536 
l0: 0.000344, l1: 0.000335, l2: 0.000358, l3: 0.000419, l4: 0.000782, l5: 0.001285, l6: 0.002133

[epoch: 126/1000, batch:   420/ 1052, ite: 32980] train loss: 0.006603, tar: 0.000535 
l0: 0.000134, l1: 0.000133, l2: 0.000144, l3: 0.000179, l4: 0.000214, l5: 0.000459, l6: 0.000709

[epoch: 126/1000, batch:   500/ 1052, ite: 33000] train loss: 0.006597, tar: 0.000535 
l0: 0.000245, l1: 0.000253, l2: 0.000288, l3: 0.000308, l4: 0.000513, l5: 0.000840, l6: 0.001359

[epoch: 126/1000, batch:   580/ 1052, ite: 33020] train loss: 0.006588, tar: 0.000534 
l0: 0.000333, l1: 0.000296, l2: 0.000362, l3: 0.000556, l4: 0.000798, l5: 0.001354, l6: 0.001904

[epoch: 126/1000, batch:   660/ 1052, ite: 33040] train loss: 0.006580, tar: 0.000534 
l0: 0.000859, l1: 0.000862, l2: 0.000858, l3: 0.000972, l4: 0.001150, l5: 0.002016, l6: 0.003434

[epoch: 126/1000, batch:   740/ 1052, ite: 33060] train loss: 0.006579, tar: 0.000533 
l0: 0.000378, l1: 0.000386, l2: 0.000386, l3: 0.000426, l4: 0.000726, l5: 0.001044, l6: 0.001735

[epoch: 126/1000, batch:   820/ 1052, ite: 33080] train loss: 0.006574, tar: 0.000533 
l0: 0.000315, l1: 0.000329, l2: 0.000333, l3: 0.000356, l4: 0.000430, l5: 0.000739, l6: 0.001305

[epoch: 126/1000, batch:   900/ 1052, ite: 33100] train loss: 0.006572, tar: 0.000533 
l0: 0.000195, l1: 0.000201, l2: 0.000194, l3: 0.000287, l4: 0.000407, l5: 0.000839, l6: 0.001472

[epoch: 126/1000, batch:   980/ 1052, ite: 33120] train loss: 0.006574, tar: 0.000532 
[Epoch 126/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000326, l1: 0.000323, l2: 0.000327, l3: 0.000381, l4: 0.000606, l5: 0.001226, l6: 0.001885

[epoch: 127/1000, batch:     8/ 1052, ite: 33140] train loss: 0.006571, tar: 0.000532 
l0: 0.000374, l1: 0.000417, l2: 0.000368, l3: 0.000331, l4: 0.000438, l5: 0.000723, l6: 0.001225

[epoch: 127/1000, batch:    88/ 1052, ite: 33160] train loss: 0.006567, tar: 0.000532 
l0: 0.000312, l1: 0.000319, l2: 0.000336, l3: 0.000400, l4: 0.000739, l5: 0.001128, l6: 0.001916

[epoch: 127/1000, batch:   168/ 1052, ite: 33180] train loss: 0.006562, tar: 0.000531 
l0: 0.000288, l1: 0.000269, l2: 0.000322, l3: 0.000402, l4: 0.000679, l5: 0.001004, l6: 0.001571

[epoch: 127/1000, batch:   248/ 1052, ite: 33200] train loss: 0.006556, tar: 0.000530 
l0: 0.000425, l1: 0.000422, l2: 0.000442, l3: 0.000524, l4: 0.000763, l5: 0.000814, l6: 0.001211

[epoch: 127/1000, batch:   328/ 1052, ite: 33220] train loss: 0.006558, tar: 0.000530 
l0: 0.000500, l1: 0.000469, l2: 0.000515, l3: 0.000604, l4: 0.000931, l5: 0.001293, l6: 0.001712

[epoch: 127/1000, batch:   408/ 1052, ite: 33240] train loss: 0.006562, tar: 0.000531 
l0: 0.000258, l1: 0.000259, l2: 0.000290, l3: 0.000277, l4: 0.000420, l5: 0.001002, l6: 0.001301

[epoch: 127/1000, batch:   488/ 1052, ite: 33260] train loss: 0.006549, tar: 0.000530 
l0: 0.000183, l1: 0.000176, l2: 0.000198, l3: 0.000255, l4: 0.000486, l5: 0.000780, l6: 0.000898

[epoch: 127/1000, batch:   568/ 1052, ite: 33280] train loss: 0.006550, tar: 0.000529 
l0: 0.000427, l1: 0.000439, l2: 0.000427, l3: 0.000432, l4: 0.000730, l5: 0.001219, l6: 0.001864

[epoch: 127/1000, batch:   648/ 1052, ite: 33300] train loss: 0.006545, tar: 0.000529 
l0: 0.000529, l1: 0.000532, l2: 0.000538, l3: 0.000559, l4: 0.000830, l5: 0.001329, l6: 0.002289

[epoch: 127/1000, batch:   728/ 1052, ite: 33320] train loss: 0.006555, tar: 0.000530 
l0: 0.000423, l1: 0.000445, l2: 0.000422, l3: 0.000567, l4: 0.000749, l5: 0.001140, l6: 0.002011

[epoch: 127/1000, batch:   808/ 1052, ite: 33340] train loss: 0.006551, tar: 0.000529 
l0: 0.000413, l1: 0.000411, l2: 0.000442, l3: 0.000498, l4: 0.000680, l5: 0.001023, l6: 0.001967

[epoch: 127/1000, batch:   888/ 1052, ite: 33360] train loss: 0.006550, tar: 0.000529 
l0: 0.000339, l1: 0.000340, l2: 0.000375, l3: 0.000452, l4: 0.000646, l5: 0.001058, l6: 0.002096

[epoch: 127/1000, batch:   968/ 1052, ite: 33380] train loss: 0.006546, tar: 0.000529 
l0: 0.000345, l1: 0.000335, l2: 0.000359, l3: 0.000462, l4: 0.000641, l5: 0.001025, l6: 0.001532

[epoch: 127/1000, batch:  1048/ 1052, ite: 33400] train loss: 0.006548, tar: 0.000529 
[Epoch 127/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000262, l1: 0.000254, l2: 0.000268, l3: 0.000378, l4: 0.000545, l5: 0.000970, l6: 0.001235

[epoch: 128/1000, batch:    76/ 1052, ite: 33420] train loss: 0.006543, tar: 0.000528 
l0: 0.000237, l1: 0.000237, l2: 0.000261, l3: 0.000345, l4: 0.000538, l5: 0.000982, l6: 0.001628

[epoch: 128/1000, batch:   156/ 1052, ite: 33440] train loss: 0.006537, tar: 0.000528 
l0: 0.000691, l1: 0.000682, l2: 0.000738, l3: 0.000917, l4: 0.001280, l5: 0.002002, l6: 0.003592

[epoch: 128/1000, batch:   236/ 1052, ite: 33460] train loss: 0.006537, tar: 0.000528 
l0: 0.000303, l1: 0.000311, l2: 0.000287, l3: 0.000309, l4: 0.000514, l5: 0.000839, l6: 0.001453

[epoch: 128/1000, batch:   316/ 1052, ite: 33480] train loss: 0.006530, tar: 0.000527 
l0: 0.000613, l1: 0.000607, l2: 0.000653, l3: 0.000816, l4: 0.000881, l5: 0.001165, l6: 0.001487

[epoch: 128/1000, batch:   396/ 1052, ite: 33500] train loss: 0.006536, tar: 0.000528 
l0: 0.000307, l1: 0.000316, l2: 0.000321, l3: 0.000335, l4: 0.000514, l5: 0.000559, l6: 0.001539

[epoch: 128/1000, batch:   476/ 1052, ite: 33520] train loss: 0.006539, tar: 0.000528 
l0: 0.000624, l1: 0.000650, l2: 0.000585, l3: 0.000744, l4: 0.001143, l5: 0.001933, l6: 0.002338

[epoch: 128/1000, batch:   556/ 1052, ite: 33540] train loss: 0.006531, tar: 0.000527 
l0: 0.000447, l1: 0.000415, l2: 0.000508, l3: 0.000531, l4: 0.000803, l5: 0.001454, l6: 0.001895

[epoch: 128/1000, batch:   636/ 1052, ite: 33560] train loss: 0.006527, tar: 0.000526 
l0: 0.000295, l1: 0.000306, l2: 0.000294, l3: 0.000368, l4: 0.000435, l5: 0.000825, l6: 0.001522

[epoch: 128/1000, batch:   716/ 1052, ite: 33580] train loss: 0.006518, tar: 0.000525 
l0: 0.000407, l1: 0.000407, l2: 0.000474, l3: 0.000452, l4: 0.000764, l5: 0.001247, l6: 0.002039

[epoch: 128/1000, batch:   796/ 1052, ite: 33600] train loss: 0.006520, tar: 0.000526 
l0: 0.000490, l1: 0.000478, l2: 0.000464, l3: 0.000488, l4: 0.000688, l5: 0.001257, l6: 0.002269

[epoch: 128/1000, batch:   876/ 1052, ite: 33620] train loss: 0.006523, tar: 0.000526 
l0: 0.000652, l1: 0.000650, l2: 0.000671, l3: 0.000802, l4: 0.000732, l5: 0.000934, l6: 0.001426

[epoch: 128/1000, batch:   956/ 1052, ite: 33640] train loss: 0.006535, tar: 0.000526 
l0: 0.000214, l1: 0.000206, l2: 0.000230, l3: 0.000267, l4: 0.000461, l5: 0.000551, l6: 0.001179

[epoch: 128/1000, batch:  1036/ 1052, ite: 33660] train loss: 0.006533, tar: 0.000526 
[Epoch 128/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000442, l1: 0.000434, l2: 0.000447, l3: 0.000483, l4: 0.000696, l5: 0.001200, l6: 0.002459

[epoch: 129/1000, batch:    64/ 1052, ite: 33680] train loss: 0.006531, tar: 0.000526 
l0: 0.000493, l1: 0.000488, l2: 0.000472, l3: 0.000644, l4: 0.000983, l5: 0.001355, l6: 0.002117

[epoch: 129/1000, batch:   144/ 1052, ite: 33700] train loss: 0.006530, tar: 0.000526 
l0: 0.000597, l1: 0.000596, l2: 0.000623, l3: 0.000717, l4: 0.000930, l5: 0.002143, l6: 0.002821

[epoch: 129/1000, batch:   224/ 1052, ite: 33720] train loss: 0.006533, tar: 0.000526 
l0: 0.000240, l1: 0.000244, l2: 0.000238, l3: 0.000254, l4: 0.000462, l5: 0.000813, l6: 0.000834

[epoch: 129/1000, batch:   304/ 1052, ite: 33740] train loss: 0.006529, tar: 0.000525 
l0: 0.000192, l1: 0.000203, l2: 0.000191, l3: 0.000162, l4: 0.000268, l5: 0.000537, l6: 0.000642

[epoch: 129/1000, batch:   384/ 1052, ite: 33760] train loss: 0.006521, tar: 0.000525 
l0: 0.000607, l1: 0.000590, l2: 0.000582, l3: 0.000623, l4: 0.000951, l5: 0.001569, l6: 0.002504

[epoch: 129/1000, batch:   464/ 1052, ite: 33780] train loss: 0.006524, tar: 0.000525 
l0: 0.000360, l1: 0.000368, l2: 0.000378, l3: 0.000354, l4: 0.000398, l5: 0.000808, l6: 0.001263

[epoch: 129/1000, batch:   544/ 1052, ite: 33800] train loss: 0.006522, tar: 0.000524 
l0: 0.000324, l1: 0.000324, l2: 0.000358, l3: 0.000427, l4: 0.000474, l5: 0.001144, l6: 0.001726

[epoch: 129/1000, batch:   624/ 1052, ite: 33820] train loss: 0.006524, tar: 0.000524 
l0: 0.000284, l1: 0.000286, l2: 0.000304, l3: 0.000393, l4: 0.000483, l5: 0.000815, l6: 0.001479

[epoch: 129/1000, batch:   704/ 1052, ite: 33840] train loss: 0.006520, tar: 0.000524 
l0: 0.000359, l1: 0.000357, l2: 0.000354, l3: 0.000389, l4: 0.000447, l5: 0.000729, l6: 0.001075

[epoch: 129/1000, batch:   784/ 1052, ite: 33860] train loss: 0.006514, tar: 0.000523 
l0: 0.000602, l1: 0.000569, l2: 0.000637, l3: 0.000896, l4: 0.001246, l5: 0.001877, l6: 0.003427

[epoch: 129/1000, batch:   864/ 1052, ite: 33880] train loss: 0.006517, tar: 0.000523 
l0: 0.000316, l1: 0.000319, l2: 0.000338, l3: 0.000409, l4: 0.000618, l5: 0.000840, l6: 0.001768

[epoch: 129/1000, batch:   944/ 1052, ite: 33900] train loss: 0.006516, tar: 0.000523 
l0: 0.000625, l1: 0.000575, l2: 0.000689, l3: 0.000733, l4: 0.000784, l5: 0.001475, l6: 0.001720

[epoch: 129/1000, batch:  1024/ 1052, ite: 33920] train loss: 0.006520, tar: 0.000524 
[Epoch 129/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000360, l1: 0.000376, l2: 0.000381, l3: 0.000389, l4: 0.000579, l5: 0.000724, l6: 0.001721

[epoch: 130/1000, batch:    52/ 1052, ite: 33940] train loss: 0.006514, tar: 0.000523 
l0: 0.000379, l1: 0.000335, l2: 0.000390, l3: 0.000413, l4: 0.000570, l5: 0.001122, l6: 0.000944

[epoch: 130/1000, batch:   132/ 1052, ite: 33960] train loss: 0.006514, tar: 0.000523 
l0: 0.000198, l1: 0.000197, l2: 0.000209, l3: 0.000252, l4: 0.000509, l5: 0.000687, l6: 0.001036

[epoch: 130/1000, batch:   212/ 1052, ite: 33980] train loss: 0.006516, tar: 0.000523 
l0: 0.000832, l1: 0.000813, l2: 0.001011, l3: 0.001161, l4: 0.001430, l5: 0.001961, l6: 0.003494

[epoch: 130/1000, batch:   292/ 1052, ite: 34000] train loss: 0.006539, tar: 0.000528 
l0: 0.000912, l1: 0.000977, l2: 0.000950, l3: 0.001263, l4: 0.001006, l5: 0.001482, l6: 0.002657

[epoch: 130/1000, batch:   372/ 1052, ite: 34020] train loss: 0.006545, tar: 0.000529 
l0: 0.000334, l1: 0.000326, l2: 0.000386, l3: 0.000502, l4: 0.000681, l5: 0.001082, l6: 0.001825

[epoch: 130/1000, batch:   452/ 1052, ite: 34040] train loss: 0.006545, tar: 0.000529 
l0: 0.000541, l1: 0.000513, l2: 0.000609, l3: 0.000746, l4: 0.000946, l5: 0.001626, l6: 0.002454

[epoch: 130/1000, batch:   532/ 1052, ite: 34060] train loss: 0.006558, tar: 0.000530 
l0: 0.000701, l1: 0.000707, l2: 0.000714, l3: 0.000857, l4: 0.000930, l5: 0.001496, l6: 0.002761

[epoch: 130/1000, batch:   612/ 1052, ite: 34080] train loss: 0.006558, tar: 0.000530 
l0: 0.000272, l1: 0.000272, l2: 0.000278, l3: 0.000300, l4: 0.000399, l5: 0.000674, l6: 0.001252

[epoch: 130/1000, batch:   692/ 1052, ite: 34100] train loss: 0.006558, tar: 0.000530 
l0: 0.000368, l1: 0.000397, l2: 0.000346, l3: 0.000387, l4: 0.000583, l5: 0.000833, l6: 0.001550

[epoch: 130/1000, batch:   772/ 1052, ite: 34120] train loss: 0.006556, tar: 0.000530 
l0: 0.000524, l1: 0.000562, l2: 0.000559, l3: 0.000599, l4: 0.000735, l5: 0.001444, l6: 0.001562

[epoch: 130/1000, batch:   852/ 1052, ite: 34140] train loss: 0.006550, tar: 0.000530 
l0: 0.000297, l1: 0.000301, l2: 0.000382, l3: 0.000695, l4: 0.000821, l5: 0.001415, l6: 0.001127

[epoch: 130/1000, batch:   932/ 1052, ite: 34160] train loss: 0.006602, tar: 0.000536 
l0: 0.000512, l1: 0.000555, l2: 0.000540, l3: 0.000518, l4: 0.000673, l5: 0.001071, l6: 0.001698

[epoch: 130/1000, batch:  1012/ 1052, ite: 34180] train loss: 0.006627, tar: 0.000539 
[Epoch 130/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000582, l1: 0.000568, l2: 0.000634, l3: 0.000687, l4: 0.001000, l5: 0.001218, l6: 0.001961

[epoch: 131/1000, batch:    40/ 1052, ite: 34200] train loss: 0.006628, tar: 0.000539 
l0: 0.001464, l1: 0.001776, l2: 0.001718, l3: 0.001169, l4: 0.002090, l5: 0.001699, l6: 0.002960

[epoch: 131/1000, batch:   120/ 1052, ite: 34220] train loss: 0.006630, tar: 0.000539 
l0: 0.000559, l1: 0.000546, l2: 0.000562, l3: 0.000658, l4: 0.000813, l5: 0.001764, l6: 0.003516

[epoch: 131/1000, batch:   200/ 1052, ite: 34240] train loss: 0.006632, tar: 0.000539 
l0: 0.000462, l1: 0.000452, l2: 0.000480, l3: 0.000561, l4: 0.000931, l5: 0.001852, l6: 0.002567

[epoch: 131/1000, batch:   280/ 1052, ite: 34260] train loss: 0.006635, tar: 0.000539 
l0: 0.001022, l1: 0.001095, l2: 0.001152, l3: 0.001315, l4: 0.001799, l5: 0.001635, l6: 0.003618

[epoch: 131/1000, batch:   360/ 1052, ite: 34280] train loss: 0.006639, tar: 0.000540 
l0: 0.000582, l1: 0.000543, l2: 0.000563, l3: 0.000634, l4: 0.000817, l5: 0.001316, l6: 0.001812

[epoch: 131/1000, batch:   440/ 1052, ite: 34300] train loss: 0.006652, tar: 0.000542 
l0: 0.000560, l1: 0.000719, l2: 0.000511, l3: 0.000913, l4: 0.001488, l5: 0.001458, l6: 0.001372

[epoch: 131/1000, batch:   520/ 1052, ite: 34320] train loss: 0.006651, tar: 0.000542 
l0: 0.001295, l1: 0.001357, l2: 0.001339, l3: 0.001272, l4: 0.001406, l5: 0.002140, l6: 0.003010

[epoch: 131/1000, batch:   600/ 1052, ite: 34340] train loss: 0.006655, tar: 0.000543 
l0: 0.000484, l1: 0.000503, l2: 0.000464, l3: 0.000517, l4: 0.000662, l5: 0.001356, l6: 0.001586

[epoch: 131/1000, batch:   680/ 1052, ite: 34360] train loss: 0.006651, tar: 0.000542 
l0: 0.000620, l1: 0.000639, l2: 0.000641, l3: 0.000675, l4: 0.000845, l5: 0.001497, l6: 0.002395

[epoch: 131/1000, batch:   760/ 1052, ite: 34380] train loss: 0.006648, tar: 0.000542 
l0: 0.000762, l1: 0.000767, l2: 0.000949, l3: 0.000953, l4: 0.001460, l5: 0.002276, l6: 0.003430

[epoch: 131/1000, batch:   840/ 1052, ite: 34400] train loss: 0.006653, tar: 0.000542 
l0: 0.000360, l1: 0.000358, l2: 0.000375, l3: 0.000506, l4: 0.000709, l5: 0.000826, l6: 0.001281

[epoch: 131/1000, batch:   920/ 1052, ite: 34420] train loss: 0.006662, tar: 0.000544 
l0: 0.000448, l1: 0.000464, l2: 0.000482, l3: 0.000469, l4: 0.000632, l5: 0.000848, l6: 0.001924

[epoch: 131/1000, batch:  1000/ 1052, ite: 34440] train loss: 0.006668, tar: 0.000544 
[Epoch 131/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000702, l1: 0.000679, l2: 0.000716, l3: 0.000806, l4: 0.001134, l5: 0.001616, l6: 0.002336

[epoch: 132/1000, batch:    28/ 1052, ite: 34460] train loss: 0.006671, tar: 0.000545 
l0: 0.000786, l1: 0.000770, l2: 0.000838, l3: 0.000704, l4: 0.000930, l5: 0.002642, l6: 0.003327

[epoch: 132/1000, batch:   108/ 1052, ite: 34480] train loss: 0.006668, tar: 0.000544 
l0: 0.000362, l1: 0.000353, l2: 0.000399, l3: 0.000487, l4: 0.000684, l5: 0.001151, l6: 0.001442

[epoch: 132/1000, batch:   188/ 1052, ite: 34500] train loss: 0.006665, tar: 0.000544 
l0: 0.000709, l1: 0.000714, l2: 0.000712, l3: 0.000674, l4: 0.001106, l5: 0.001356, l6: 0.002180

[epoch: 132/1000, batch:   268/ 1052, ite: 34520] train loss: 0.006656, tar: 0.000544 
l0: 0.000941, l1: 0.000926, l2: 0.000982, l3: 0.000988, l4: 0.001178, l5: 0.001996, l6: 0.003189

[epoch: 132/1000, batch:   348/ 1052, ite: 34540] train loss: 0.006660, tar: 0.000544 
l0: 0.000492, l1: 0.000510, l2: 0.000498, l3: 0.000476, l4: 0.000730, l5: 0.000956, l6: 0.001419

[epoch: 132/1000, batch:   428/ 1052, ite: 34560] train loss: 0.006671, tar: 0.000545 
l0: 0.000436, l1: 0.000410, l2: 0.000477, l3: 0.000587, l4: 0.000747, l5: 0.001451, l6: 0.002017

[epoch: 132/1000, batch:   508/ 1052, ite: 34580] train loss: 0.006668, tar: 0.000545 
l0: 0.000254, l1: 0.000242, l2: 0.000260, l3: 0.000309, l4: 0.000438, l5: 0.000859, l6: 0.001592

[epoch: 132/1000, batch:   588/ 1052, ite: 34600] train loss: 0.006668, tar: 0.000545 
l0: 0.000612, l1: 0.000728, l2: 0.000822, l3: 0.000751, l4: 0.000756, l5: 0.001367, l6: 0.002346

[epoch: 132/1000, batch:   668/ 1052, ite: 34620] train loss: 0.006666, tar: 0.000545 
l0: 0.000412, l1: 0.000391, l2: 0.000421, l3: 0.000529, l4: 0.000747, l5: 0.001284, l6: 0.002138

[epoch: 132/1000, batch:   748/ 1052, ite: 34640] train loss: 0.006664, tar: 0.000544 
l0: 0.000242, l1: 0.000232, l2: 0.000257, l3: 0.000345, l4: 0.000423, l5: 0.000797, l6: 0.001272

[epoch: 132/1000, batch:   828/ 1052, ite: 34660] train loss: 0.006659, tar: 0.000544 
l0: 0.000370, l1: 0.000397, l2: 0.000386, l3: 0.000567, l4: 0.000568, l5: 0.000677, l6: 0.000951

[epoch: 132/1000, batch:   908/ 1052, ite: 34680] train loss: 0.006656, tar: 0.000543 
l0: 0.000442, l1: 0.000414, l2: 0.000525, l3: 0.000735, l4: 0.001059, l5: 0.001564, l6: 0.002129

[epoch: 132/1000, batch:   988/ 1052, ite: 34700] train loss: 0.006664, tar: 0.000544 
[Epoch 132/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000660, l1: 0.000672, l2: 0.000737, l3: 0.000725, l4: 0.000819, l5: 0.001525, l6: 0.002323

[epoch: 133/1000, batch:    16/ 1052, ite: 34720] train loss: 0.006661, tar: 0.000544 
l0: 0.000457, l1: 0.001138, l2: 0.000623, l3: 0.000347, l4: 0.000476, l5: 0.001028, l6: 0.001946

[epoch: 133/1000, batch:    96/ 1052, ite: 34740] train loss: 0.006686, tar: 0.000548 
l0: 0.000654, l1: 0.000627, l2: 0.000602, l3: 0.000682, l4: 0.001081, l5: 0.001756, l6: 0.002559

[epoch: 133/1000, batch:   176/ 1052, ite: 34760] train loss: 0.006690, tar: 0.000548 
l0: 0.000289, l1: 0.000291, l2: 0.000294, l3: 0.000313, l4: 0.000412, l5: 0.000729, l6: 0.001298

[epoch: 133/1000, batch:   256/ 1052, ite: 34780] train loss: 0.006695, tar: 0.000549 
l0: 0.000310, l1: 0.000340, l2: 0.000336, l3: 0.000328, l4: 0.000438, l5: 0.000972, l6: 0.002256

[epoch: 133/1000, batch:   336/ 1052, ite: 34800] train loss: 0.006691, tar: 0.000548 
l0: 0.001196, l1: 0.001200, l2: 0.001130, l3: 0.001164, l4: 0.001633, l5: 0.002766, l6: 0.004120

[epoch: 133/1000, batch:   416/ 1052, ite: 34820] train loss: 0.006693, tar: 0.000548 
l0: 0.000570, l1: 0.000547, l2: 0.000600, l3: 0.000703, l4: 0.000830, l5: 0.001854, l6: 0.001501

[epoch: 133/1000, batch:   496/ 1052, ite: 34840] train loss: 0.006690, tar: 0.000548 
l0: 0.000354, l1: 0.000387, l2: 0.000357, l3: 0.000366, l4: 0.000508, l5: 0.000985, l6: 0.001077

[epoch: 133/1000, batch:   576/ 1052, ite: 34860] train loss: 0.006695, tar: 0.000549 
l0: 0.000427, l1: 0.000468, l2: 0.000422, l3: 0.000422, l4: 0.000519, l5: 0.001057, l6: 0.001882

[epoch: 133/1000, batch:   656/ 1052, ite: 34880] train loss: 0.006689, tar: 0.000548 
l0: 0.000346, l1: 0.000358, l2: 0.000401, l3: 0.000449, l4: 0.000567, l5: 0.001401, l6: 0.002387

[epoch: 133/1000, batch:   736/ 1052, ite: 34900] train loss: 0.006686, tar: 0.000547 
l0: 0.000419, l1: 0.000469, l2: 0.000423, l3: 0.000440, l4: 0.000564, l5: 0.000865, l6: 0.001837

[epoch: 133/1000, batch:   816/ 1052, ite: 34920] train loss: 0.006681, tar: 0.000547 
l0: 0.000636, l1: 0.000652, l2: 0.000706, l3: 0.000766, l4: 0.001370, l5: 0.002407, l6: 0.003285

[epoch: 133/1000, batch:   896/ 1052, ite: 34940] train loss: 0.006683, tar: 0.000547 
l0: 0.000683, l1: 0.000698, l2: 0.000688, l3: 0.000836, l4: 0.000890, l5: 0.001504, l6: 0.002141

[epoch: 133/1000, batch:   976/ 1052, ite: 34960] train loss: 0.006688, tar: 0.000548 
[Epoch 133/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000423, l1: 0.000408, l2: 0.000460, l3: 0.000536, l4: 0.000844, l5: 0.000973, l6: 0.001972

[epoch: 134/1000, batch:     4/ 1052, ite: 34980] train loss: 0.006682, tar: 0.000547 
l0: 0.000596, l1: 0.000572, l2: 0.000588, l3: 0.000673, l4: 0.000989, l5: 0.001968, l6: 0.002858

[epoch: 134/1000, batch:    84/ 1052, ite: 35000] train loss: 0.006681, tar: 0.000547 
l0: 0.000270, l1: 0.000290, l2: 0.000268, l3: 0.000303, l4: 0.000515, l5: 0.000776, l6: 0.001232

[epoch: 134/1000, batch:   164/ 1052, ite: 35020] train loss: 0.006683, tar: 0.000547 
l0: 0.000543, l1: 0.000524, l2: 0.000544, l3: 0.000627, l4: 0.001056, l5: 0.001505, l6: 0.002524

[epoch: 134/1000, batch:   244/ 1052, ite: 35040] train loss: 0.006683, tar: 0.000547 
l0: 0.000544, l1: 0.000519, l2: 0.000602, l3: 0.000708, l4: 0.001055, l5: 0.001543, l6: 0.003066

[epoch: 134/1000, batch:   324/ 1052, ite: 35060] train loss: 0.006678, tar: 0.000546 
l0: 0.000669, l1: 0.000642, l2: 0.000758, l3: 0.000900, l4: 0.001072, l5: 0.001165, l6: 0.002059

[epoch: 134/1000, batch:   404/ 1052, ite: 35080] train loss: 0.006680, tar: 0.000547 
l0: 0.000353, l1: 0.000331, l2: 0.000418, l3: 0.000501, l4: 0.000904, l5: 0.001401, l6: 0.002015

[epoch: 134/1000, batch:   484/ 1052, ite: 35100] train loss: 0.006681, tar: 0.000547 
l0: 0.001176, l1: 0.001179, l2: 0.001326, l3: 0.001176, l4: 0.001515, l5: 0.002584, l6: 0.004010

[epoch: 134/1000, batch:   564/ 1052, ite: 35120] train loss: 0.006682, tar: 0.000547 
l0: 0.000218, l1: 0.000224, l2: 0.000221, l3: 0.000248, l4: 0.000362, l5: 0.000663, l6: 0.000950

[epoch: 134/1000, batch:   644/ 1052, ite: 35140] train loss: 0.006674, tar: 0.000546 
l0: 0.000545, l1: 0.000518, l2: 0.000536, l3: 0.000642, l4: 0.000981, l5: 0.001395, l6: 0.002403

[epoch: 134/1000, batch:   724/ 1052, ite: 35160] train loss: 0.006673, tar: 0.000546 
l0: 0.001225, l1: 0.001232, l2: 0.001246, l3: 0.001393, l4: 0.001828, l5: 0.002324, l6: 0.004566

[epoch: 134/1000, batch:   804/ 1052, ite: 35180] train loss: 0.006676, tar: 0.000546 
l0: 0.000624, l1: 0.000605, l2: 0.000622, l3: 0.000752, l4: 0.000814, l5: 0.001136, l6: 0.001638

[epoch: 134/1000, batch:   884/ 1052, ite: 35200] train loss: 0.006671, tar: 0.000545 
l0: 0.000347, l1: 0.000358, l2: 0.000327, l3: 0.000417, l4: 0.000689, l5: 0.001108, l6: 0.001980

[epoch: 134/1000, batch:   964/ 1052, ite: 35220] train loss: 0.006670, tar: 0.000545 
l0: 0.000646, l1: 0.000658, l2: 0.000696, l3: 0.000712, l4: 0.000926, l5: 0.001769, l6: 0.002700

[epoch: 134/1000, batch:  1044/ 1052, ite: 35240] train loss: 0.006671, tar: 0.000545 
[Epoch 134/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000633, l1: 0.000617, l2: 0.000603, l3: 0.000610, l4: 0.001040, l5: 0.001588, l6: 0.002439

[epoch: 135/1000, batch:    72/ 1052, ite: 35260] train loss: 0.006665, tar: 0.000544 
l0: 0.000239, l1: 0.000234, l2: 0.000284, l3: 0.000335, l4: 0.000449, l5: 0.000706, l6: 0.001183

[epoch: 135/1000, batch:   152/ 1052, ite: 35280] train loss: 0.006661, tar: 0.000544 
l0: 0.000573, l1: 0.000574, l2: 0.000626, l3: 0.000669, l4: 0.000986, l5: 0.001463, l6: 0.003094

[epoch: 135/1000, batch:   232/ 1052, ite: 35300] train loss: 0.006665, tar: 0.000544 
l0: 0.000588, l1: 0.000584, l2: 0.000636, l3: 0.000667, l4: 0.000854, l5: 0.001326, l6: 0.002089

[epoch: 135/1000, batch:   312/ 1052, ite: 35320] train loss: 0.006662, tar: 0.000544 
l0: 0.000396, l1: 0.000407, l2: 0.000424, l3: 0.000548, l4: 0.000678, l5: 0.000922, l6: 0.002594

[epoch: 135/1000, batch:   392/ 1052, ite: 35340] train loss: 0.006659, tar: 0.000544 
l0: 0.000708, l1: 0.000727, l2: 0.000676, l3: 0.000711, l4: 0.000904, l5: 0.002229, l6: 0.002324

[epoch: 135/1000, batch:   472/ 1052, ite: 35360] train loss: 0.006654, tar: 0.000543 
l0: 0.001196, l1: 0.001178, l2: 0.001552, l3: 0.001588, l4: 0.001783, l5: 0.001373, l6: 0.001867

[epoch: 135/1000, batch:   552/ 1052, ite: 35380] train loss: 0.006657, tar: 0.000544 
l0: 0.000355, l1: 0.000358, l2: 0.000376, l3: 0.000517, l4: 0.000791, l5: 0.001319, l6: 0.002027

[epoch: 135/1000, batch:   632/ 1052, ite: 35400] train loss: 0.006654, tar: 0.000543 
l0: 0.000979, l1: 0.001015, l2: 0.001028, l3: 0.001136, l4: 0.001656, l5: 0.002944, l6: 0.003515

[epoch: 135/1000, batch:   712/ 1052, ite: 35420] train loss: 0.006662, tar: 0.000544 
l0: 0.000995, l1: 0.001035, l2: 0.001114, l3: 0.001150, l4: 0.001439, l5: 0.002013, l6: 0.002956

[epoch: 135/1000, batch:   792/ 1052, ite: 35440] train loss: 0.006659, tar: 0.000544 
l0: 0.000511, l1: 0.000534, l2: 0.000567, l3: 0.000623, l4: 0.000633, l5: 0.001076, l6: 0.001835

[epoch: 135/1000, batch:   872/ 1052, ite: 35460] train loss: 0.006660, tar: 0.000543 
l0: 0.000684, l1: 0.000693, l2: 0.000666, l3: 0.000703, l4: 0.000698, l5: 0.001299, l6: 0.002168

[epoch: 135/1000, batch:   952/ 1052, ite: 35480] train loss: 0.006655, tar: 0.000543 
l0: 0.000625, l1: 0.000568, l2: 0.000673, l3: 0.000833, l4: 0.001167, l5: 0.001840, l6: 0.002297

[epoch: 135/1000, batch:  1032/ 1052, ite: 35500] train loss: 0.006653, tar: 0.000543 
[Epoch 135/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.001342, l1: 0.001368, l2: 0.001380, l3: 0.001388, l4: 0.001335, l5: 0.002510, l6: 0.003920

[epoch: 136/1000, batch:    60/ 1052, ite: 35520] train loss: 0.006656, tar: 0.000543 
l0: 0.000513, l1: 0.000543, l2: 0.000526, l3: 0.000532, l4: 0.000630, l5: 0.000936, l6: 0.001564

[epoch: 136/1000, batch:   140/ 1052, ite: 35540] train loss: 0.006653, tar: 0.000543 
l0: 0.000776, l1: 0.000793, l2: 0.000833, l3: 0.000828, l4: 0.000908, l5: 0.001391, l6: 0.003057

[epoch: 136/1000, batch:   220/ 1052, ite: 35560] train loss: 0.006652, tar: 0.000542 
l0: 0.000598, l1: 0.000591, l2: 0.000629, l3: 0.000772, l4: 0.000908, l5: 0.001231, l6: 0.001613

[epoch: 136/1000, batch:   300/ 1052, ite: 35580] train loss: 0.006649, tar: 0.000542 
l0: 0.000562, l1: 0.000537, l2: 0.000613, l3: 0.000727, l4: 0.001281, l5: 0.001705, l6: 0.003035

[epoch: 136/1000, batch:   380/ 1052, ite: 35600] train loss: 0.006646, tar: 0.000542 
l0: 0.000371, l1: 0.000377, l2: 0.000377, l3: 0.000451, l4: 0.000632, l5: 0.001094, l6: 0.001917

[epoch: 136/1000, batch:   460/ 1052, ite: 35620] train loss: 0.006641, tar: 0.000541 
l0: 0.000797, l1: 0.000777, l2: 0.000821, l3: 0.000966, l4: 0.001220, l5: 0.002715, l6: 0.004720

[epoch: 136/1000, batch:   540/ 1052, ite: 35640] train loss: 0.006640, tar: 0.000541 
l0: 0.000478, l1: 0.000477, l2: 0.000476, l3: 0.000492, l4: 0.000872, l5: 0.001200, l6: 0.002433

[epoch: 136/1000, batch:   620/ 1052, ite: 35660] train loss: 0.006641, tar: 0.000541 
l0: 0.000791, l1: 0.000769, l2: 0.000786, l3: 0.001017, l4: 0.001557, l5: 0.002220, l6: 0.002876

[epoch: 136/1000, batch:   700/ 1052, ite: 35680] train loss: 0.006642, tar: 0.000541 
l0: 0.000757, l1: 0.000821, l2: 0.000781, l3: 0.000868, l4: 0.000990, l5: 0.001493, l6: 0.002532

[epoch: 136/1000, batch:   780/ 1052, ite: 35700] train loss: 0.006640, tar: 0.000541 
l0: 0.000818, l1: 0.000812, l2: 0.000856, l3: 0.000905, l4: 0.001481, l5: 0.002366, l6: 0.003267

[epoch: 136/1000, batch:   860/ 1052, ite: 35720] train loss: 0.006638, tar: 0.000541 
l0: 0.000306, l1: 0.000309, l2: 0.000335, l3: 0.000334, l4: 0.000430, l5: 0.000827, l6: 0.001210

[epoch: 136/1000, batch:   940/ 1052, ite: 35740] train loss: 0.006638, tar: 0.000540 
l0: 0.000554, l1: 0.000533, l2: 0.000573, l3: 0.000671, l4: 0.000898, l5: 0.001201, l6: 0.002224

[epoch: 136/1000, batch:  1020/ 1052, ite: 35760] train loss: 0.006639, tar: 0.000541 
[Epoch 136/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000341, l1: 0.000324, l2: 0.000322, l3: 0.000408, l4: 0.000582, l5: 0.000629, l6: 0.001349

[epoch: 137/1000, batch:    48/ 1052, ite: 35780] train loss: 0.006635, tar: 0.000540 
l0: 0.001548, l1: 0.001751, l2: 0.001788, l3: 0.001610, l4: 0.001641, l5: 0.002879, l6: 0.004766

[epoch: 137/1000, batch:   128/ 1052, ite: 35800] train loss: 0.006639, tar: 0.000541 
l0: 0.000611, l1: 0.000595, l2: 0.000635, l3: 0.000758, l4: 0.001041, l5: 0.001865, l6: 0.002903

[epoch: 137/1000, batch:   208/ 1052, ite: 35820] train loss: 0.006635, tar: 0.000540 
l0: 0.000623, l1: 0.000693, l2: 0.000573, l3: 0.000617, l4: 0.000782, l5: 0.001505, l6: 0.002262

[epoch: 137/1000, batch:   288/ 1052, ite: 35840] train loss: 0.006633, tar: 0.000540 
l0: 0.000238, l1: 0.000237, l2: 0.000234, l3: 0.000291, l4: 0.000665, l5: 0.000820, l6: 0.001913

[epoch: 137/1000, batch:   368/ 1052, ite: 35860] train loss: 0.006633, tar: 0.000540 
l0: 0.000624, l1: 0.000612, l2: 0.000650, l3: 0.000654, l4: 0.000875, l5: 0.001215, l6: 0.001804

[epoch: 137/1000, batch:   448/ 1052, ite: 35880] train loss: 0.006634, tar: 0.000540 
l0: 0.000648, l1: 0.000660, l2: 0.000772, l3: 0.000698, l4: 0.000928, l5: 0.001869, l6: 0.002830

[epoch: 137/1000, batch:   528/ 1052, ite: 35900] train loss: 0.006631, tar: 0.000540 
l0: 0.000365, l1: 0.000376, l2: 0.000365, l3: 0.000436, l4: 0.000546, l5: 0.001017, l6: 0.001348

[epoch: 137/1000, batch:   608/ 1052, ite: 35920] train loss: 0.006631, tar: 0.000540 
l0: 0.000260, l1: 0.000267, l2: 0.000306, l3: 0.000345, l4: 0.000444, l5: 0.000563, l6: 0.001317

[epoch: 137/1000, batch:   688/ 1052, ite: 35940] train loss: 0.006627, tar: 0.000539 
l0: 0.000368, l1: 0.000393, l2: 0.000373, l3: 0.000426, l4: 0.000570, l5: 0.001066, l6: 0.001364

[epoch: 137/1000, batch:   768/ 1052, ite: 35960] train loss: 0.006629, tar: 0.000539 
l0: 0.000620, l1: 0.000642, l2: 0.000636, l3: 0.000609, l4: 0.001157, l5: 0.001780, l6: 0.003267

[epoch: 137/1000, batch:   848/ 1052, ite: 35980] train loss: 0.006627, tar: 0.000539 
l0: 0.000215, l1: 0.000221, l2: 0.000238, l3: 0.000273, l4: 0.000304, l5: 0.000813, l6: 0.000669

[epoch: 137/1000, batch:   928/ 1052, ite: 36000] train loss: 0.006622, tar: 0.000539 
l0: 0.000489, l1: 0.000474, l2: 0.000496, l3: 0.000635, l4: 0.000667, l5: 0.001060, l6: 0.002121

[epoch: 137/1000, batch:  1008/ 1052, ite: 36020] train loss: 0.006621, tar: 0.000539 
[Epoch 137/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000721, l1: 0.000725, l2: 0.000713, l3: 0.000786, l4: 0.001132, l5: 0.002227, l6: 0.002575

[epoch: 138/1000, batch:    36/ 1052, ite: 36040] train loss: 0.006620, tar: 0.000538 
l0: 0.000489, l1: 0.000523, l2: 0.000493, l3: 0.000554, l4: 0.000696, l5: 0.000886, l6: 0.001470

[epoch: 138/1000, batch:   116/ 1052, ite: 36060] train loss: 0.006626, tar: 0.000540 
l0: 0.000592, l1: 0.000652, l2: 0.000684, l3: 0.000732, l4: 0.000828, l5: 0.001427, l6: 0.001249

[epoch: 138/1000, batch:   196/ 1052, ite: 36080] train loss: 0.006624, tar: 0.000540 
l0: 0.000519, l1: 0.000579, l2: 0.000501, l3: 0.000548, l4: 0.000850, l5: 0.000793, l6: 0.001723

[epoch: 138/1000, batch:   276/ 1052, ite: 36100] train loss: 0.006623, tar: 0.000540 
l0: 0.000746, l1: 0.000697, l2: 0.000784, l3: 0.000926, l4: 0.000996, l5: 0.001340, l6: 0.002333

[epoch: 138/1000, batch:   356/ 1052, ite: 36120] train loss: 0.006623, tar: 0.000540 
l0: 0.000284, l1: 0.000289, l2: 0.000300, l3: 0.000378, l4: 0.000575, l5: 0.001125, l6: 0.001646

[epoch: 138/1000, batch:   436/ 1052, ite: 36140] train loss: 0.006624, tar: 0.000540 
l0: 0.000686, l1: 0.000728, l2: 0.000713, l3: 0.000739, l4: 0.000929, l5: 0.001803, l6: 0.002468

[epoch: 138/1000, batch:   516/ 1052, ite: 36160] train loss: 0.006622, tar: 0.000540 
l0: 0.000520, l1: 0.000530, l2: 0.000578, l3: 0.000699, l4: 0.000875, l5: 0.001734, l6: 0.002878

[epoch: 138/1000, batch:   596/ 1052, ite: 36180] train loss: 0.006620, tar: 0.000539 
l0: 0.000368, l1: 0.000354, l2: 0.000378, l3: 0.000480, l4: 0.000659, l5: 0.001092, l6: 0.001885

[epoch: 138/1000, batch:   676/ 1052, ite: 36200] train loss: 0.006620, tar: 0.000539 
l0: 0.000244, l1: 0.000237, l2: 0.000231, l3: 0.000236, l4: 0.000451, l5: 0.000682, l6: 0.000934

[epoch: 138/1000, batch:   756/ 1052, ite: 36220] train loss: 0.006621, tar: 0.000539 
l0: 0.000689, l1: 0.000655, l2: 0.000690, l3: 0.000772, l4: 0.000846, l5: 0.001425, l6: 0.002984

[epoch: 138/1000, batch:   836/ 1052, ite: 36240] train loss: 0.006623, tar: 0.000539 
l0: 0.000291, l1: 0.000290, l2: 0.000266, l3: 0.000362, l4: 0.000497, l5: 0.000988, l6: 0.001608

[epoch: 138/1000, batch:   916/ 1052, ite: 36260] train loss: 0.006621, tar: 0.000539 
l0: 0.000518, l1: 0.000550, l2: 0.000581, l3: 0.000603, l4: 0.001059, l5: 0.001671, l6: 0.002633

[epoch: 138/1000, batch:   996/ 1052, ite: 36280] train loss: 0.006623, tar: 0.000539 
[Epoch 138/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000465, l1: 0.000437, l2: 0.000494, l3: 0.000547, l4: 0.000786, l5: 0.001242, l6: 0.001898

[epoch: 139/1000, batch:    24/ 1052, ite: 36300] train loss: 0.006619, tar: 0.000539 
l0: 0.000288, l1: 0.000279, l2: 0.000325, l3: 0.000397, l4: 0.000626, l5: 0.001255, l6: 0.001795

[epoch: 139/1000, batch:   104/ 1052, ite: 36320] train loss: 0.006614, tar: 0.000539 
l0: 0.000690, l1: 0.000744, l2: 0.000683, l3: 0.000839, l4: 0.000824, l5: 0.001414, l6: 0.001629

[epoch: 139/1000, batch:   184/ 1052, ite: 36340] train loss: 0.006612, tar: 0.000538 
l0: 0.000410, l1: 0.000432, l2: 0.000412, l3: 0.000507, l4: 0.000613, l5: 0.001219, l6: 0.001588

[epoch: 139/1000, batch:   264/ 1052, ite: 36360] train loss: 0.006608, tar: 0.000538 
l0: 0.000366, l1: 0.000343, l2: 0.000430, l3: 0.000458, l4: 0.000867, l5: 0.001164, l6: 0.001806

[epoch: 139/1000, batch:   344/ 1052, ite: 36380] train loss: 0.006607, tar: 0.000538 
l0: 0.000548, l1: 0.000601, l2: 0.000586, l3: 0.000550, l4: 0.000918, l5: 0.001573, l6: 0.002104

[epoch: 139/1000, batch:   424/ 1052, ite: 36400] train loss: 0.006608, tar: 0.000538 
l0: 0.000298, l1: 0.000478, l2: 0.000358, l3: 0.000354, l4: 0.000485, l5: 0.000644, l6: 0.001444

[epoch: 139/1000, batch:   504/ 1052, ite: 36420] train loss: 0.006605, tar: 0.000538 
l0: 0.000521, l1: 0.000517, l2: 0.000557, l3: 0.000554, l4: 0.000797, l5: 0.001657, l6: 0.002926

[epoch: 139/1000, batch:   584/ 1052, ite: 36440] train loss: 0.006604, tar: 0.000537 
l0: 0.000946, l1: 0.000998, l2: 0.001028, l3: 0.001134, l4: 0.001070, l5: 0.002654, l6: 0.004739

[epoch: 139/1000, batch:   664/ 1052, ite: 36460] train loss: 0.006605, tar: 0.000537 
l0: 0.000166, l1: 0.000162, l2: 0.000177, l3: 0.000238, l4: 0.000351, l5: 0.000655, l6: 0.001413

[epoch: 139/1000, batch:   744/ 1052, ite: 36480] train loss: 0.006605, tar: 0.000537 
l0: 0.000404, l1: 0.000416, l2: 0.000413, l3: 0.000482, l4: 0.000572, l5: 0.001395, l6: 0.002012

[epoch: 139/1000, batch:   824/ 1052, ite: 36500] train loss: 0.006603, tar: 0.000537 
l0: 0.000726, l1: 0.000743, l2: 0.000771, l3: 0.000762, l4: 0.001086, l5: 0.001625, l6: 0.002113

[epoch: 139/1000, batch:   904/ 1052, ite: 36520] train loss: 0.006604, tar: 0.000537 
l0: 0.000519, l1: 0.000528, l2: 0.000531, l3: 0.000644, l4: 0.000812, l5: 0.001112, l6: 0.002046

[epoch: 139/1000, batch:   984/ 1052, ite: 36540] train loss: 0.006607, tar: 0.000537 
[Epoch 139/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000820, l1: 0.000837, l2: 0.000858, l3: 0.000908, l4: 0.001002, l5: 0.001774, l6: 0.003604

[epoch: 140/1000, batch:    12/ 1052, ite: 36560] train loss: 0.006604, tar: 0.000537 
l0: 0.000338, l1: 0.000336, l2: 0.000369, l3: 0.000452, l4: 0.000559, l5: 0.001001, l6: 0.001700

[epoch: 140/1000, batch:    92/ 1052, ite: 36580] train loss: 0.006602, tar: 0.000536 
l0: 0.000617, l1: 0.000628, l2: 0.000611, l3: 0.000737, l4: 0.000961, l5: 0.001141, l6: 0.001866

[epoch: 140/1000, batch:   172/ 1052, ite: 36600] train loss: 0.006602, tar: 0.000536 
l0: 0.000273, l1: 0.000274, l2: 0.000305, l3: 0.000373, l4: 0.000588, l5: 0.001041, l6: 0.001652

[epoch: 140/1000, batch:   252/ 1052, ite: 36620] train loss: 0.006597, tar: 0.000536 
l0: 0.000477, l1: 0.000482, l2: 0.000493, l3: 0.000441, l4: 0.000408, l5: 0.000621, l6: 0.000715

[epoch: 140/1000, batch:   332/ 1052, ite: 36640] train loss: 0.006596, tar: 0.000536 
l0: 0.000470, l1: 0.000452, l2: 0.000447, l3: 0.000519, l4: 0.000969, l5: 0.001665, l6: 0.002018

[epoch: 140/1000, batch:   412/ 1052, ite: 36660] train loss: 0.006595, tar: 0.000536 
l0: 0.000872, l1: 0.000819, l2: 0.000938, l3: 0.001099, l4: 0.001405, l5: 0.002259, l6: 0.003185

[epoch: 140/1000, batch:   492/ 1052, ite: 36680] train loss: 0.006594, tar: 0.000536 
l0: 0.000823, l1: 0.000935, l2: 0.000903, l3: 0.000787, l4: 0.001039, l5: 0.001420, l6: 0.002139

[epoch: 140/1000, batch:   572/ 1052, ite: 36700] train loss: 0.006594, tar: 0.000536 
l0: 0.000320, l1: 0.000338, l2: 0.000302, l3: 0.000371, l4: 0.000588, l5: 0.001050, l6: 0.001140

[epoch: 140/1000, batch:   652/ 1052, ite: 36720] train loss: 0.006594, tar: 0.000536 
l0: 0.000373, l1: 0.000400, l2: 0.000421, l3: 0.000364, l4: 0.000557, l5: 0.000974, l6: 0.001818

[epoch: 140/1000, batch:   732/ 1052, ite: 36740] train loss: 0.006597, tar: 0.000536 
l0: 0.000448, l1: 0.000465, l2: 0.000438, l3: 0.000511, l4: 0.000657, l5: 0.001230, l6: 0.001579

[epoch: 140/1000, batch:   812/ 1052, ite: 36760] train loss: 0.006598, tar: 0.000536 
l0: 0.001052, l1: 0.001051, l2: 0.001243, l3: 0.001278, l4: 0.001479, l5: 0.002144, l6: 0.003097

[epoch: 140/1000, batch:   892/ 1052, ite: 36780] train loss: 0.006596, tar: 0.000536 
l0: 0.000277, l1: 0.000266, l2: 0.000298, l3: 0.000344, l4: 0.000514, l5: 0.001171, l6: 0.001623

[epoch: 140/1000, batch:   972/ 1052, ite: 36800] train loss: 0.006594, tar: 0.000536 
l0: 0.000969, l1: 0.000999, l2: 0.001020, l3: 0.001041, l4: 0.001370, l5: 0.002396, l6: 0.003704

[epoch: 140/1000, batch:  1052/ 1052, ite: 36820] train loss: 0.006594, tar: 0.000536 
[Epoch 140/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000245, l1: 0.000254, l2: 0.000271, l3: 0.000360, l4: 0.000484, l5: 0.000613, l6: 0.001349

[epoch: 141/1000, batch:    80/ 1052, ite: 36840] train loss: 0.006591, tar: 0.000535 
l0: 0.000668, l1: 0.000656, l2: 0.000685, l3: 0.000654, l4: 0.000957, l5: 0.000926, l6: 0.002162

[epoch: 141/1000, batch:   160/ 1052, ite: 36860] train loss: 0.006587, tar: 0.000535 
l0: 0.000249, l1: 0.000241, l2: 0.000247, l3: 0.000355, l4: 0.000543, l5: 0.000730, l6: 0.001159

[epoch: 141/1000, batch:   240/ 1052, ite: 36880] train loss: 0.006587, tar: 0.000535 
l0: 0.000394, l1: 0.000402, l2: 0.000415, l3: 0.000450, l4: 0.000625, l5: 0.001219, l6: 0.002464

[epoch: 141/1000, batch:   320/ 1052, ite: 36900] train loss: 0.006585, tar: 0.000535 
l0: 0.000414, l1: 0.000425, l2: 0.000450, l3: 0.000506, l4: 0.000868, l5: 0.001266, l6: 0.001730

[epoch: 141/1000, batch:   400/ 1052, ite: 36920] train loss: 0.006588, tar: 0.000535 
l0: 0.000271, l1: 0.000283, l2: 0.000293, l3: 0.000322, l4: 0.000378, l5: 0.000727, l6: 0.001320

[epoch: 141/1000, batch:   480/ 1052, ite: 36940] train loss: 0.006584, tar: 0.000535 
l0: 0.000410, l1: 0.000401, l2: 0.000453, l3: 0.000573, l4: 0.001105, l5: 0.001645, l6: 0.001822

[epoch: 141/1000, batch:   560/ 1052, ite: 36960] train loss: 0.006583, tar: 0.000534 
l0: 0.000197, l1: 0.000200, l2: 0.000214, l3: 0.000260, l4: 0.000412, l5: 0.000540, l6: 0.001361

[epoch: 141/1000, batch:   640/ 1052, ite: 36980] train loss: 0.006581, tar: 0.000534 
l0: 0.000716, l1: 0.000747, l2: 0.000719, l3: 0.000724, l4: 0.000940, l5: 0.001562, l6: 0.002758

[epoch: 141/1000, batch:   720/ 1052, ite: 37000] train loss: 0.006582, tar: 0.000534 
l0: 0.001093, l1: 0.001120, l2: 0.001122, l3: 0.001067, l4: 0.001155, l5: 0.002134, l6: 0.002260

[epoch: 141/1000, batch:   800/ 1052, ite: 37020] train loss: 0.006582, tar: 0.000534 
l0: 0.000506, l1: 0.000508, l2: 0.000547, l3: 0.000626, l4: 0.000882, l5: 0.001426, l6: 0.002371

[epoch: 141/1000, batch:   880/ 1052, ite: 37040] train loss: 0.006580, tar: 0.000534 
l0: 0.000495, l1: 0.000533, l2: 0.000522, l3: 0.000505, l4: 0.000462, l5: 0.000801, l6: 0.001256

[epoch: 141/1000, batch:   960/ 1052, ite: 37060] train loss: 0.006586, tar: 0.000535 
l0: 0.001206, l1: 0.001244, l2: 0.001444, l3: 0.001432, l4: 0.002727, l5: 0.002564, l6: 0.004669

[epoch: 141/1000, batch:  1040/ 1052, ite: 37080] train loss: 0.006586, tar: 0.000534 
[Epoch 141/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000447, l1: 0.000447, l2: 0.000437, l3: 0.000445, l4: 0.000661, l5: 0.001353, l6: 0.003155

[epoch: 142/1000, batch:    68/ 1052, ite: 37100] train loss: 0.006584, tar: 0.000534 
l0: 0.000760, l1: 0.000798, l2: 0.000799, l3: 0.000664, l4: 0.000814, l5: 0.001311, l6: 0.002774

[epoch: 142/1000, batch:   148/ 1052, ite: 37120] train loss: 0.006582, tar: 0.000534 
l0: 0.000354, l1: 0.000375, l2: 0.000381, l3: 0.000406, l4: 0.000623, l5: 0.001196, l6: 0.001838

[epoch: 142/1000, batch:   228/ 1052, ite: 37140] train loss: 0.006581, tar: 0.000534 
l0: 0.000447, l1: 0.000442, l2: 0.000565, l3: 0.000585, l4: 0.000701, l5: 0.001108, l6: 0.001336

[epoch: 142/1000, batch:   308/ 1052, ite: 37160] train loss: 0.006581, tar: 0.000534 
l0: 0.000536, l1: 0.000554, l2: 0.000619, l3: 0.000610, l4: 0.000819, l5: 0.001300, l6: 0.002626

[epoch: 142/1000, batch:   388/ 1052, ite: 37180] train loss: 0.006584, tar: 0.000534 
l0: 0.014318, l1: 0.015695, l2: 0.014500, l3: 0.011568, l4: 0.006553, l5: 0.007224, l6: 0.003787

[epoch: 142/1000, batch:   468/ 1052, ite: 37200] train loss: 0.006595, tar: 0.000536 
l0: 0.000347, l1: 0.000381, l2: 0.000416, l3: 0.000491, l4: 0.000526, l5: 0.000968, l6: 0.001306

[epoch: 142/1000, batch:   548/ 1052, ite: 37220] train loss: 0.006597, tar: 0.000537 
l0: 0.000380, l1: 0.000394, l2: 0.000414, l3: 0.000496, l4: 0.000652, l5: 0.001107, l6: 0.001819

[epoch: 142/1000, batch:   628/ 1052, ite: 37240] train loss: 0.006601, tar: 0.000537 
l0: 0.000535, l1: 0.000515, l2: 0.000514, l3: 0.000619, l4: 0.000894, l5: 0.001373, l6: 0.002696

[epoch: 142/1000, batch:   708/ 1052, ite: 37260] train loss: 0.006602, tar: 0.000537 
l0: 0.000419, l1: 0.000411, l2: 0.000398, l3: 0.000521, l4: 0.000758, l5: 0.000937, l6: 0.001872

[epoch: 142/1000, batch:   788/ 1052, ite: 37280] train loss: 0.006602, tar: 0.000537 
l0: 0.000283, l1: 0.000281, l2: 0.000299, l3: 0.000336, l4: 0.000580, l5: 0.001466, l6: 0.001264

[epoch: 142/1000, batch:   868/ 1052, ite: 37300] train loss: 0.006600, tar: 0.000537 
l0: 0.000336, l1: 0.000340, l2: 0.000392, l3: 0.000414, l4: 0.000706, l5: 0.001079, l6: 0.001561

[epoch: 142/1000, batch:   948/ 1052, ite: 37320] train loss: 0.006598, tar: 0.000537 
l0: 0.000512, l1: 0.000512, l2: 0.000545, l3: 0.000561, l4: 0.000627, l5: 0.001238, l6: 0.002401

[epoch: 142/1000, batch:  1028/ 1052, ite: 37340] train loss: 0.006593, tar: 0.000536 
[Epoch 142/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000527, l1: 0.000490, l2: 0.000587, l3: 0.000601, l4: 0.001046, l5: 0.001822, l6: 0.002863

[epoch: 143/1000, batch:    56/ 1052, ite: 37360] train loss: 0.006592, tar: 0.000536 
l0: 0.000316, l1: 0.000320, l2: 0.000312, l3: 0.000410, l4: 0.000531, l5: 0.000852, l6: 0.001503

[epoch: 143/1000, batch:   136/ 1052, ite: 37380] train loss: 0.006589, tar: 0.000536 
l0: 0.000468, l1: 0.000468, l2: 0.000494, l3: 0.000559, l4: 0.000647, l5: 0.001516, l6: 0.002857

[epoch: 143/1000, batch:   216/ 1052, ite: 37400] train loss: 0.006590, tar: 0.000536 
l0: 0.000558, l1: 0.000535, l2: 0.000596, l3: 0.000704, l4: 0.001023, l5: 0.001368, l6: 0.002498

[epoch: 143/1000, batch:   296/ 1052, ite: 37420] train loss: 0.006590, tar: 0.000536 
l0: 0.000336, l1: 0.000361, l2: 0.000370, l3: 0.000364, l4: 0.000526, l5: 0.000767, l6: 0.001164

[epoch: 143/1000, batch:   376/ 1052, ite: 37440] train loss: 0.006589, tar: 0.000535 
l0: 0.000574, l1: 0.000522, l2: 0.000642, l3: 0.000852, l4: 0.001155, l5: 0.001393, l6: 0.002611

[epoch: 143/1000, batch:   456/ 1052, ite: 37460] train loss: 0.006586, tar: 0.000535 
l0: 0.000354, l1: 0.000398, l2: 0.000403, l3: 0.000379, l4: 0.000497, l5: 0.000909, l6: 0.001469

[epoch: 143/1000, batch:   536/ 1052, ite: 37480] train loss: 0.006585, tar: 0.000535 
l0: 0.000360, l1: 0.000356, l2: 0.000393, l3: 0.000431, l4: 0.000760, l5: 0.001207, l6: 0.001610

[epoch: 143/1000, batch:   616/ 1052, ite: 37500] train loss: 0.006584, tar: 0.000535 
l0: 0.000264, l1: 0.000283, l2: 0.000303, l3: 0.000265, l4: 0.000478, l5: 0.000818, l6: 0.001027

[epoch: 143/1000, batch:   696/ 1052, ite: 37520] train loss: 0.006585, tar: 0.000535 
l0: 0.000378, l1: 0.000383, l2: 0.000412, l3: 0.000387, l4: 0.000596, l5: 0.000943, l6: 0.002183

[epoch: 143/1000, batch:   776/ 1052, ite: 37540] train loss: 0.006585, tar: 0.000535 
l0: 0.000400, l1: 0.000414, l2: 0.000439, l3: 0.000446, l4: 0.000476, l5: 0.000934, l6: 0.001925

[epoch: 143/1000, batch:   856/ 1052, ite: 37560] train loss: 0.006583, tar: 0.000535 
l0: 0.000553, l1: 0.000580, l2: 0.000566, l3: 0.000638, l4: 0.000781, l5: 0.001718, l6: 0.001733

[epoch: 143/1000, batch:   936/ 1052, ite: 37580] train loss: 0.006584, tar: 0.000535 
l0: 0.000299, l1: 0.000292, l2: 0.000307, l3: 0.000326, l4: 0.000531, l5: 0.000962, l6: 0.001305

[epoch: 143/1000, batch:  1016/ 1052, ite: 37600] train loss: 0.006584, tar: 0.000535 
[Epoch 143/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000361, l1: 0.000339, l2: 0.000354, l3: 0.000514, l4: 0.000699, l5: 0.001261, l6: 0.002023

[epoch: 144/1000, batch:    44/ 1052, ite: 37620] train loss: 0.006583, tar: 0.000535 
l0: 0.000169, l1: 0.000156, l2: 0.000194, l3: 0.000261, l4: 0.000403, l5: 0.000789, l6: 0.001223

[epoch: 144/1000, batch:   124/ 1052, ite: 37640] train loss: 0.006581, tar: 0.000534 
l0: 0.000641, l1: 0.000611, l2: 0.000699, l3: 0.000887, l4: 0.001158, l5: 0.002109, l6: 0.003572

[epoch: 144/1000, batch:   204/ 1052, ite: 37660] train loss: 0.006579, tar: 0.000534 
l0: 0.001027, l1: 0.001069, l2: 0.001027, l3: 0.001115, l4: 0.001202, l5: 0.001449, l6: 0.002490

[epoch: 144/1000, batch:   284/ 1052, ite: 37680] train loss: 0.006579, tar: 0.000534 
l0: 0.000523, l1: 0.000504, l2: 0.000508, l3: 0.000605, l4: 0.000830, l5: 0.001166, l6: 0.001693

[epoch: 144/1000, batch:   364/ 1052, ite: 37700] train loss: 0.006577, tar: 0.000534 
l0: 0.000674, l1: 0.000635, l2: 0.000641, l3: 0.000756, l4: 0.001045, l5: 0.001624, l6: 0.002668

[epoch: 144/1000, batch:   444/ 1052, ite: 37720] train loss: 0.006574, tar: 0.000533 
l0: 0.000375, l1: 0.000396, l2: 0.000377, l3: 0.000522, l4: 0.000733, l5: 0.001279, l6: 0.001659

[epoch: 144/1000, batch:   524/ 1052, ite: 37740] train loss: 0.006572, tar: 0.000533 
l0: 0.000274, l1: 0.000262, l2: 0.000278, l3: 0.000383, l4: 0.000549, l5: 0.001201, l6: 0.001197

[epoch: 144/1000, batch:   604/ 1052, ite: 37760] train loss: 0.006568, tar: 0.000533 
l0: 0.000444, l1: 0.000437, l2: 0.000463, l3: 0.000588, l4: 0.000733, l5: 0.001321, l6: 0.002888

[epoch: 144/1000, batch:   684/ 1052, ite: 37780] train loss: 0.006565, tar: 0.000533 
l0: 0.000276, l1: 0.000277, l2: 0.000275, l3: 0.000304, l4: 0.000422, l5: 0.000689, l6: 0.001102

[epoch: 144/1000, batch:   764/ 1052, ite: 37800] train loss: 0.006563, tar: 0.000532 
l0: 0.000255, l1: 0.000255, l2: 0.000276, l3: 0.000315, l4: 0.000612, l5: 0.000874, l6: 0.001564

[epoch: 144/1000, batch:   844/ 1052, ite: 37820] train loss: 0.006567, tar: 0.000533 
l0: 0.000224, l1: 0.000228, l2: 0.000238, l3: 0.000359, l4: 0.000490, l5: 0.000876, l6: 0.001357

[epoch: 144/1000, batch:   924/ 1052, ite: 37840] train loss: 0.006568, tar: 0.000533 
l0: 0.000546, l1: 0.000589, l2: 0.000576, l3: 0.000620, l4: 0.000847, l5: 0.001652, l6: 0.001912

[epoch: 144/1000, batch:  1004/ 1052, ite: 37860] train loss: 0.006569, tar: 0.000533 
[Epoch 144/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000287, l1: 0.000285, l2: 0.000372, l3: 0.000384, l4: 0.000541, l5: 0.001080, l6: 0.001533

[epoch: 145/1000, batch:    32/ 1052, ite: 37880] train loss: 0.006570, tar: 0.000533 
l0: 0.000548, l1: 0.000545, l2: 0.000546, l3: 0.000617, l4: 0.000864, l5: 0.001864, l6: 0.003217

[epoch: 145/1000, batch:   112/ 1052, ite: 37900] train loss: 0.006569, tar: 0.000533 
l0: 0.000355, l1: 0.000363, l2: 0.000366, l3: 0.000367, l4: 0.000629, l5: 0.001182, l6: 0.001318

[epoch: 145/1000, batch:   192/ 1052, ite: 37920] train loss: 0.006568, tar: 0.000532 
l0: 0.000624, l1: 0.000659, l2: 0.000674, l3: 0.000723, l4: 0.000787, l5: 0.001116, l6: 0.001839

[epoch: 145/1000, batch:   272/ 1052, ite: 37940] train loss: 0.006566, tar: 0.000532 
l0: 0.000212, l1: 0.000210, l2: 0.000242, l3: 0.000272, l4: 0.000419, l5: 0.000646, l6: 0.001445

[epoch: 145/1000, batch:   352/ 1052, ite: 37960] train loss: 0.006565, tar: 0.000532 
l0: 0.000603, l1: 0.000599, l2: 0.000664, l3: 0.000604, l4: 0.000836, l5: 0.001214, l6: 0.002062

[epoch: 145/1000, batch:   432/ 1052, ite: 37980] train loss: 0.006564, tar: 0.000532 
l0: 0.001058, l1: 0.001128, l2: 0.001136, l3: 0.001058, l4: 0.001123, l5: 0.001524, l6: 0.002539

[epoch: 145/1000, batch:   512/ 1052, ite: 38000] train loss: 0.006565, tar: 0.000532 
l0: 0.000429, l1: 0.000457, l2: 0.000425, l3: 0.000426, l4: 0.000677, l5: 0.001310, l6: 0.001435

[epoch: 145/1000, batch:   592/ 1052, ite: 38020] train loss: 0.006565, tar: 0.000532 
l0: 0.000313, l1: 0.000306, l2: 0.000362, l3: 0.000472, l4: 0.000633, l5: 0.000980, l6: 0.002361

[epoch: 145/1000, batch:   672/ 1052, ite: 38040] train loss: 0.006565, tar: 0.000532 
l0: 0.000356, l1: 0.000354, l2: 0.000349, l3: 0.000392, l4: 0.000597, l5: 0.001127, l6: 0.001563

[epoch: 145/1000, batch:   752/ 1052, ite: 38060] train loss: 0.006563, tar: 0.000532 
l0: 0.000399, l1: 0.000397, l2: 0.000416, l3: 0.000414, l4: 0.000749, l5: 0.000947, l6: 0.001894

[epoch: 145/1000, batch:   832/ 1052, ite: 38080] train loss: 0.006563, tar: 0.000532 
l0: 0.000586, l1: 0.000606, l2: 0.000657, l3: 0.000646, l4: 0.000919, l5: 0.001752, l6: 0.002705

[epoch: 145/1000, batch:   912/ 1052, ite: 38100] train loss: 0.006563, tar: 0.000532 
l0: 0.000473, l1: 0.000481, l2: 0.000510, l3: 0.000541, l4: 0.000926, l5: 0.001602, l6: 0.002673

[epoch: 145/1000, batch:   992/ 1052, ite: 38120] train loss: 0.006559, tar: 0.000531 
[Epoch 145/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000497, l1: 0.000472, l2: 0.000556, l3: 0.000585, l4: 0.000932, l5: 0.001424, l6: 0.002260

[epoch: 146/1000, batch:    20/ 1052, ite: 38140] train loss: 0.006559, tar: 0.000531 
l0: 0.000818, l1: 0.000794, l2: 0.000882, l3: 0.000976, l4: 0.001351, l5: 0.002271, l6: 0.003809

[epoch: 146/1000, batch:   100/ 1052, ite: 38160] train loss: 0.006557, tar: 0.000531 
l0: 0.000258, l1: 0.000253, l2: 0.000280, l3: 0.000312, l4: 0.000511, l5: 0.000897, l6: 0.001140

[epoch: 146/1000, batch:   180/ 1052, ite: 38180] train loss: 0.006558, tar: 0.000531 
l0: 0.000578, l1: 0.000569, l2: 0.000642, l3: 0.000777, l4: 0.001055, l5: 0.002106, l6: 0.003104

[epoch: 146/1000, batch:   260/ 1052, ite: 38200] train loss: 0.006559, tar: 0.000531 
l0: 0.000276, l1: 0.000301, l2: 0.000285, l3: 0.000242, l4: 0.000429, l5: 0.000736, l6: 0.001545

[epoch: 146/1000, batch:   340/ 1052, ite: 38220] train loss: 0.006558, tar: 0.000531 
l0: 0.000485, l1: 0.000519, l2: 0.000546, l3: 0.000553, l4: 0.000848, l5: 0.001132, l6: 0.002399

[epoch: 146/1000, batch:   420/ 1052, ite: 38240] train loss: 0.006557, tar: 0.000531 
l0: 0.000451, l1: 0.000464, l2: 0.000459, l3: 0.000581, l4: 0.000740, l5: 0.001217, l6: 0.002148

[epoch: 146/1000, batch:   500/ 1052, ite: 38260] train loss: 0.006555, tar: 0.000530 
l0: 0.000317, l1: 0.000337, l2: 0.000292, l3: 0.000375, l4: 0.000479, l5: 0.000906, l6: 0.001632

[epoch: 146/1000, batch:   580/ 1052, ite: 38280] train loss: 0.006551, tar: 0.000530 
l0: 0.000293, l1: 0.000292, l2: 0.000304, l3: 0.000338, l4: 0.000461, l5: 0.001054, l6: 0.001441

[epoch: 146/1000, batch:   660/ 1052, ite: 38300] train loss: 0.006551, tar: 0.000530 
l0: 0.000247, l1: 0.000249, l2: 0.000232, l3: 0.000354, l4: 0.000682, l5: 0.000831, l6: 0.001351

[epoch: 146/1000, batch:   740/ 1052, ite: 38320] train loss: 0.006552, tar: 0.000530 
l0: 0.000233, l1: 0.000244, l2: 0.000247, l3: 0.000226, l4: 0.000328, l5: 0.000672, l6: 0.001194

[epoch: 146/1000, batch:   820/ 1052, ite: 38340] train loss: 0.006552, tar: 0.000530 
l0: 0.000331, l1: 0.000336, l2: 0.000379, l3: 0.000398, l4: 0.000607, l5: 0.000858, l6: 0.001755

[epoch: 146/1000, batch:   900/ 1052, ite: 38360] train loss: 0.006550, tar: 0.000530 
l0: 0.000388, l1: 0.000374, l2: 0.000431, l3: 0.000515, l4: 0.000661, l5: 0.001084, l6: 0.002089

[epoch: 146/1000, batch:   980/ 1052, ite: 38380] train loss: 0.006548, tar: 0.000529 
[Epoch 146/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000628, l1: 0.000602, l2: 0.000661, l3: 0.000767, l4: 0.001068, l5: 0.001540, l6: 0.003067

[epoch: 147/1000, batch:     8/ 1052, ite: 38400] train loss: 0.006546, tar: 0.000529 
l0: 0.000684, l1: 0.000632, l2: 0.000617, l3: 0.000843, l4: 0.001256, l5: 0.001533, l6: 0.002867

[epoch: 147/1000, batch:    88/ 1052, ite: 38420] train loss: 0.006544, tar: 0.000529 
l0: 0.000202, l1: 0.000204, l2: 0.000208, l3: 0.000277, l4: 0.000384, l5: 0.000820, l6: 0.001412

[epoch: 147/1000, batch:   168/ 1052, ite: 38440] train loss: 0.006544, tar: 0.000529 
l0: 0.000414, l1: 0.000405, l2: 0.000398, l3: 0.000516, l4: 0.000667, l5: 0.000852, l6: 0.001565

[epoch: 147/1000, batch:   248/ 1052, ite: 38460] train loss: 0.006543, tar: 0.000529 
l0: 0.000330, l1: 0.000323, l2: 0.000374, l3: 0.000374, l4: 0.000655, l5: 0.000920, l6: 0.001907

[epoch: 147/1000, batch:   328/ 1052, ite: 38480] train loss: 0.006541, tar: 0.000529 
l0: 0.000255, l1: 0.000264, l2: 0.000277, l3: 0.000295, l4: 0.000408, l5: 0.000843, l6: 0.001283

[epoch: 147/1000, batch:   408/ 1052, ite: 38500] train loss: 0.006538, tar: 0.000528 
l0: 0.000498, l1: 0.000575, l2: 0.000644, l3: 0.000405, l4: 0.000600, l5: 0.000939, l6: 0.001297

[epoch: 147/1000, batch:   488/ 1052, ite: 38520] train loss: 0.006538, tar: 0.000528 
l0: 0.000318, l1: 0.000330, l2: 0.000353, l3: 0.000391, l4: 0.000543, l5: 0.001168, l6: 0.001930

[epoch: 147/1000, batch:   568/ 1052, ite: 38540] train loss: 0.006537, tar: 0.000528 
l0: 0.001351, l1: 0.001319, l2: 0.001320, l3: 0.001616, l4: 0.001895, l5: 0.002600, l6: 0.004943

[epoch: 147/1000, batch:   648/ 1052, ite: 38560] train loss: 0.006538, tar: 0.000528 
l0: 0.000695, l1: 0.000730, l2: 0.000725, l3: 0.000813, l4: 0.000924, l5: 0.001491, l6: 0.003239

[epoch: 147/1000, batch:   728/ 1052, ite: 38580] train loss: 0.006538, tar: 0.000528 
l0: 0.000285, l1: 0.000282, l2: 0.000294, l3: 0.000375, l4: 0.000577, l5: 0.001137, l6: 0.001827

[epoch: 147/1000, batch:   808/ 1052, ite: 38600] train loss: 0.006536, tar: 0.000528 
l0: 0.000359, l1: 0.000382, l2: 0.000369, l3: 0.000412, l4: 0.000604, l5: 0.000960, l6: 0.001504

[epoch: 147/1000, batch:   888/ 1052, ite: 38620] train loss: 0.006537, tar: 0.000528 
l0: 0.000348, l1: 0.000359, l2: 0.000321, l3: 0.000356, l4: 0.000462, l5: 0.000757, l6: 0.001587

[epoch: 147/1000, batch:   968/ 1052, ite: 38640] train loss: 0.006535, tar: 0.000528 
l0: 0.000310, l1: 0.000310, l2: 0.000316, l3: 0.000329, l4: 0.000508, l5: 0.001323, l6: 0.001515

[epoch: 147/1000, batch:  1048/ 1052, ite: 38660] train loss: 0.006534, tar: 0.000528 
[Epoch 147/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000791, l1: 0.000748, l2: 0.000870, l3: 0.001142, l4: 0.001612, l5: 0.003870, l6: 0.005981

[epoch: 148/1000, batch:    76/ 1052, ite: 38680] train loss: 0.006534, tar: 0.000528 
l0: 0.000419, l1: 0.000441, l2: 0.000419, l3: 0.000441, l4: 0.000562, l5: 0.001061, l6: 0.001411

[epoch: 148/1000, batch:   156/ 1052, ite: 38700] train loss: 0.006533, tar: 0.000527 
l0: 0.000472, l1: 0.000496, l2: 0.000552, l3: 0.000543, l4: 0.000684, l5: 0.001267, l6: 0.001856

[epoch: 148/1000, batch:   236/ 1052, ite: 38720] train loss: 0.006530, tar: 0.000527 
l0: 0.000359, l1: 0.000356, l2: 0.000384, l3: 0.000380, l4: 0.000509, l5: 0.001006, l6: 0.001190

[epoch: 148/1000, batch:   316/ 1052, ite: 38740] train loss: 0.006530, tar: 0.000527 
l0: 0.000249, l1: 0.000267, l2: 0.000253, l3: 0.000240, l4: 0.000391, l5: 0.000628, l6: 0.001056

[epoch: 148/1000, batch:   396/ 1052, ite: 38760] train loss: 0.006527, tar: 0.000527 
l0: 0.000322, l1: 0.000315, l2: 0.000348, l3: 0.000368, l4: 0.000481, l5: 0.000452, l6: 0.001063

[epoch: 148/1000, batch:   476/ 1052, ite: 38780] train loss: 0.006524, tar: 0.000526 
l0: 0.006223, l1: 0.004970, l2: 0.011127, l3: 0.009510, l4: 0.008329, l5: 0.006115, l6: 0.005797

[epoch: 148/1000, batch:   556/ 1052, ite: 38800] train loss: 0.006531, tar: 0.000527 
l0: 0.000469, l1: 0.000456, l2: 0.000564, l3: 0.000592, l4: 0.000674, l5: 0.001306, l6: 0.002371

[epoch: 148/1000, batch:   636/ 1052, ite: 38820] train loss: 0.006536, tar: 0.000528 
l0: 0.000971, l1: 0.001096, l2: 0.000908, l3: 0.001221, l4: 0.001014, l5: 0.001208, l6: 0.002092

[epoch: 148/1000, batch:   716/ 1052, ite: 38840] train loss: 0.006540, tar: 0.000528 
l0: 0.000410, l1: 0.000454, l2: 0.000455, l3: 0.000500, l4: 0.000513, l5: 0.000851, l6: 0.001429

[epoch: 148/1000, batch:   796/ 1052, ite: 38860] train loss: 0.006545, tar: 0.000529 
l0: 0.000478, l1: 0.000478, l2: 0.000532, l3: 0.000610, l4: 0.000607, l5: 0.001217, l6: 0.001298

[epoch: 148/1000, batch:   876/ 1052, ite: 38880] train loss: 0.006550, tar: 0.000530 
l0: 0.000332, l1: 0.000340, l2: 0.000371, l3: 0.000373, l4: 0.000514, l5: 0.001111, l6: 0.001084

[epoch: 148/1000, batch:   956/ 1052, ite: 38900] train loss: 0.006549, tar: 0.000530 
l0: 0.000674, l1: 0.000752, l2: 0.000800, l3: 0.000910, l4: 0.000784, l5: 0.001337, l6: 0.001784

[epoch: 148/1000, batch:  1036/ 1052, ite: 38920] train loss: 0.006549, tar: 0.000530 
[Epoch 148/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000343, l1: 0.000366, l2: 0.000355, l3: 0.000328, l4: 0.000463, l5: 0.000657, l6: 0.001359

[epoch: 149/1000, batch:    64/ 1052, ite: 38940] train loss: 0.006551, tar: 0.000530 
l0: 0.000544, l1: 0.000559, l2: 0.000535, l3: 0.000648, l4: 0.000963, l5: 0.001494, l6: 0.002993

[epoch: 149/1000, batch:   144/ 1052, ite: 38960] train loss: 0.006553, tar: 0.000530 
l0: 0.000392, l1: 0.000373, l2: 0.000407, l3: 0.000440, l4: 0.000758, l5: 0.001303, l6: 0.002322

[epoch: 149/1000, batch:   224/ 1052, ite: 38980] train loss: 0.006553, tar: 0.000530 
l0: 0.000816, l1: 0.000910, l2: 0.000901, l3: 0.000816, l4: 0.001117, l5: 0.001671, l6: 0.002520

[epoch: 149/1000, batch:   304/ 1052, ite: 39000] train loss: 0.006555, tar: 0.000530 
l0: 0.000265, l1: 0.000281, l2: 0.000261, l3: 0.000277, l4: 0.000517, l5: 0.000825, l6: 0.001053

[epoch: 149/1000, batch:   384/ 1052, ite: 39020] train loss: 0.006552, tar: 0.000530 
l0: 0.000219, l1: 0.000232, l2: 0.000256, l3: 0.000310, l4: 0.000510, l5: 0.000807, l6: 0.001459

[epoch: 149/1000, batch:   464/ 1052, ite: 39040] train loss: 0.006550, tar: 0.000530 
l0: 0.000359, l1: 0.000366, l2: 0.000364, l3: 0.000574, l4: 0.000690, l5: 0.000887, l6: 0.001455

[epoch: 149/1000, batch:   544/ 1052, ite: 39060] train loss: 0.006547, tar: 0.000529 
l0: 0.000250, l1: 0.000255, l2: 0.000234, l3: 0.000286, l4: 0.000428, l5: 0.000963, l6: 0.001299

[epoch: 149/1000, batch:   624/ 1052, ite: 39080] train loss: 0.006547, tar: 0.000529 
l0: 0.000959, l1: 0.000960, l2: 0.001041, l3: 0.001096, l4: 0.001151, l5: 0.002118, l6: 0.003970

[epoch: 149/1000, batch:   704/ 1052, ite: 39100] train loss: 0.006548, tar: 0.000529 
l0: 0.000345, l1: 0.000344, l2: 0.000361, l3: 0.000354, l4: 0.000400, l5: 0.000845, l6: 0.001814

[epoch: 149/1000, batch:   784/ 1052, ite: 39120] train loss: 0.006549, tar: 0.000529 
l0: 0.000215, l1: 0.000252, l2: 0.000232, l3: 0.000267, l4: 0.000360, l5: 0.000595, l6: 0.000752

[epoch: 149/1000, batch:   864/ 1052, ite: 39140] train loss: 0.006548, tar: 0.000529 
l0: 0.000550, l1: 0.000547, l2: 0.000550, l3: 0.000703, l4: 0.000924, l5: 0.001405, l6: 0.002083

[epoch: 149/1000, batch:   944/ 1052, ite: 39160] train loss: 0.006548, tar: 0.000529 
l0: 0.000282, l1: 0.000287, l2: 0.000275, l3: 0.000350, l4: 0.000499, l5: 0.000809, l6: 0.001062

[epoch: 149/1000, batch:  1024/ 1052, ite: 39180] train loss: 0.006546, tar: 0.000529 
[Epoch 149/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000664, l1: 0.000668, l2: 0.000707, l3: 0.000828, l4: 0.001042, l5: 0.001950, l6: 0.003912

[epoch: 150/1000, batch:    52/ 1052, ite: 39200] train loss: 0.006541, tar: 0.000528 
l0: 0.000534, l1: 0.000542, l2: 0.000581, l3: 0.000501, l4: 0.000838, l5: 0.001292, l6: 0.001958

[epoch: 150/1000, batch:   132/ 1052, ite: 39220] train loss: 0.006538, tar: 0.000528 
l0: 0.000984, l1: 0.000979, l2: 0.000957, l3: 0.001175, l4: 0.002024, l5: 0.003207, l6: 0.003301

[epoch: 150/1000, batch:   212/ 1052, ite: 39240] train loss: 0.006540, tar: 0.000528 
l0: 0.000773, l1: 0.000811, l2: 0.000961, l3: 0.000718, l4: 0.000775, l5: 0.001553, l6: 0.002270

[epoch: 150/1000, batch:   292/ 1052, ite: 39260] train loss: 0.006539, tar: 0.000528 
l0: 0.001204, l1: 0.001368, l2: 0.001652, l3: 0.001053, l4: 0.000983, l5: 0.001264, l6: 0.003421

[epoch: 150/1000, batch:   372/ 1052, ite: 39280] train loss: 0.006541, tar: 0.000528 
l0: 0.000494, l1: 0.000541, l2: 0.000538, l3: 0.000554, l4: 0.000696, l5: 0.001296, l6: 0.003154

[epoch: 150/1000, batch:   452/ 1052, ite: 39300] train loss: 0.006541, tar: 0.000528 
l0: 0.000505, l1: 0.000511, l2: 0.000536, l3: 0.000542, l4: 0.000605, l5: 0.001157, l6: 0.001706

[epoch: 150/1000, batch:   532/ 1052, ite: 39320] train loss: 0.006540, tar: 0.000528 
l0: 0.000267, l1: 0.000266, l2: 0.000260, l3: 0.000346, l4: 0.000629, l5: 0.001054, l6: 0.001721

[epoch: 150/1000, batch:   612/ 1052, ite: 39340] train loss: 0.006538, tar: 0.000528 
l0: 0.000917, l1: 0.000909, l2: 0.000935, l3: 0.000848, l4: 0.001084, l5: 0.001736, l6: 0.003426

[epoch: 150/1000, batch:   692/ 1052, ite: 39360] train loss: 0.006536, tar: 0.000528 
l0: 0.000310, l1: 0.000305, l2: 0.000320, l3: 0.000321, l4: 0.000542, l5: 0.001146, l6: 0.001412

[epoch: 150/1000, batch:   772/ 1052, ite: 39380] train loss: 0.006537, tar: 0.000528 
l0: 0.000418, l1: 0.000406, l2: 0.000455, l3: 0.000536, l4: 0.000821, l5: 0.001287, l6: 0.001392

[epoch: 150/1000, batch:   852/ 1052, ite: 39400] train loss: 0.006537, tar: 0.000528 
l0: 0.000433, l1: 0.000441, l2: 0.000424, l3: 0.000515, l4: 0.000770, l5: 0.001604, l6: 0.002825

[epoch: 150/1000, batch:   932/ 1052, ite: 39420] train loss: 0.006537, tar: 0.000528 
l0: 0.000615, l1: 0.000641, l2: 0.000637, l3: 0.000600, l4: 0.000899, l5: 0.001945, l6: 0.003102

[epoch: 150/1000, batch:  1012/ 1052, ite: 39440] train loss: 0.006537, tar: 0.000528 
[Epoch 150/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000325, l1: 0.000330, l2: 0.000334, l3: 0.000417, l4: 0.000681, l5: 0.001083, l6: 0.002286

[epoch: 151/1000, batch:    40/ 1052, ite: 39460] train loss: 0.006538, tar: 0.000528 
l0: 0.000572, l1: 0.000600, l2: 0.000606, l3: 0.000646, l4: 0.000683, l5: 0.001357, l6: 0.002896

[epoch: 151/1000, batch:   120/ 1052, ite: 39480] train loss: 0.006537, tar: 0.000528 
l0: 0.000486, l1: 0.000475, l2: 0.000509, l3: 0.000762, l4: 0.000874, l5: 0.001458, l6: 0.002708

[epoch: 151/1000, batch:   200/ 1052, ite: 39500] train loss: 0.006540, tar: 0.000528 
l0: 0.000326, l1: 0.000309, l2: 0.000315, l3: 0.000361, l4: 0.000551, l5: 0.001027, l6: 0.001705

[epoch: 151/1000, batch:   280/ 1052, ite: 39520] train loss: 0.006539, tar: 0.000528 
l0: 0.001854, l1: 0.001858, l2: 0.001895, l3: 0.002032, l4: 0.002070, l5: 0.002945, l6: 0.003585

[epoch: 151/1000, batch:   360/ 1052, ite: 39540] train loss: 0.006538, tar: 0.000528 
l0: 0.000808, l1: 0.000889, l2: 0.000880, l3: 0.000888, l4: 0.000966, l5: 0.001720, l6: 0.002305

[epoch: 151/1000, batch:   440/ 1052, ite: 39560] train loss: 0.006539, tar: 0.000528 
l0: 0.000255, l1: 0.000253, l2: 0.000266, l3: 0.000262, l4: 0.000339, l5: 0.000739, l6: 0.001350

[epoch: 151/1000, batch:   520/ 1052, ite: 39580] train loss: 0.006537, tar: 0.000527 
l0: 0.000230, l1: 0.000230, l2: 0.000296, l3: 0.000348, l4: 0.000553, l5: 0.001088, l6: 0.001019

[epoch: 151/1000, batch:   600/ 1052, ite: 39600] train loss: 0.006534, tar: 0.000527 
l0: 0.000379, l1: 0.000369, l2: 0.000363, l3: 0.000435, l4: 0.000563, l5: 0.000823, l6: 0.001597

[epoch: 151/1000, batch:   680/ 1052, ite: 39620] train loss: 0.006535, tar: 0.000527 
l0: 0.000337, l1: 0.000347, l2: 0.000338, l3: 0.000374, l4: 0.000648, l5: 0.000898, l6: 0.001581

[epoch: 151/1000, batch:   760/ 1052, ite: 39640] train loss: 0.006532, tar: 0.000527 
l0: 0.000458, l1: 0.000448, l2: 0.000514, l3: 0.000604, l4: 0.000833, l5: 0.001400, l6: 0.002487

[epoch: 151/1000, batch:   840/ 1052, ite: 39660] train loss: 0.006530, tar: 0.000527 
l0: 0.000372, l1: 0.000373, l2: 0.000385, l3: 0.000431, l4: 0.000594, l5: 0.001099, l6: 0.001981

[epoch: 151/1000, batch:   920/ 1052, ite: 39680] train loss: 0.006529, tar: 0.000526 
l0: 0.000933, l1: 0.000939, l2: 0.000925, l3: 0.000961, l4: 0.001411, l5: 0.002446, l6: 0.003917

[epoch: 151/1000, batch:  1000/ 1052, ite: 39700] train loss: 0.006528, tar: 0.000526 
[Epoch 151/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000491, l1: 0.000481, l2: 0.000531, l3: 0.000614, l4: 0.000928, l5: 0.001712, l6: 0.002821

[epoch: 152/1000, batch:    28/ 1052, ite: 39720] train loss: 0.006526, tar: 0.000526 
l0: 0.000211, l1: 0.000208, l2: 0.000227, l3: 0.000264, l4: 0.000402, l5: 0.000836, l6: 0.001629

[epoch: 152/1000, batch:   108/ 1052, ite: 39740] train loss: 0.006527, tar: 0.000526 
l0: 0.000566, l1: 0.000575, l2: 0.000548, l3: 0.000644, l4: 0.000910, l5: 0.001708, l6: 0.003329

[epoch: 152/1000, batch:   188/ 1052, ite: 39760] train loss: 0.006525, tar: 0.000526 
l0: 0.001254, l1: 0.001276, l2: 0.001267, l3: 0.001251, l4: 0.001757, l5: 0.003149, l6: 0.004155

[epoch: 152/1000, batch:   268/ 1052, ite: 39780] train loss: 0.006526, tar: 0.000526 
l0: 0.000791, l1: 0.000829, l2: 0.000840, l3: 0.000834, l4: 0.001298, l5: 0.001439, l6: 0.002811

[epoch: 152/1000, batch:   348/ 1052, ite: 39800] train loss: 0.006524, tar: 0.000526 
l0: 0.000529, l1: 0.000522, l2: 0.000542, l3: 0.000696, l4: 0.001006, l5: 0.001828, l6: 0.002911

[epoch: 152/1000, batch:   428/ 1052, ite: 39820] train loss: 0.006523, tar: 0.000526 
l0: 0.000212, l1: 0.000204, l2: 0.000211, l3: 0.000282, l4: 0.000339, l5: 0.000931, l6: 0.001054

[epoch: 152/1000, batch:   508/ 1052, ite: 39840] train loss: 0.006522, tar: 0.000525 
l0: 0.000610, l1: 0.000576, l2: 0.000683, l3: 0.000925, l4: 0.001195, l5: 0.002446, l6: 0.003514

[epoch: 152/1000, batch:   588/ 1052, ite: 39860] train loss: 0.006520, tar: 0.000525 
l0: 0.000323, l1: 0.000322, l2: 0.000337, l3: 0.000407, l4: 0.000615, l5: 0.000855, l6: 0.002074

[epoch: 152/1000, batch:   668/ 1052, ite: 39880] train loss: 0.006522, tar: 0.000525 
l0: 0.001286, l1: 0.001382, l2: 0.001341, l3: 0.001082, l4: 0.001150, l5: 0.001678, l6: 0.002238

[epoch: 152/1000, batch:   748/ 1052, ite: 39900] train loss: 0.006521, tar: 0.000525 
l0: 0.000414, l1: 0.000403, l2: 0.000441, l3: 0.000420, l4: 0.000567, l5: 0.000974, l6: 0.001640

[epoch: 152/1000, batch:   828/ 1052, ite: 39920] train loss: 0.006519, tar: 0.000525 
l0: 0.000577, l1: 0.000594, l2: 0.000597, l3: 0.000610, l4: 0.000820, l5: 0.001119, l6: 0.002603

[epoch: 152/1000, batch:   908/ 1052, ite: 39940] train loss: 0.006520, tar: 0.000525 
l0: 0.000341, l1: 0.000324, l2: 0.000380, l3: 0.000460, l4: 0.000538, l5: 0.001084, l6: 0.001372

[epoch: 152/1000, batch:   988/ 1052, ite: 39960] train loss: 0.006519, tar: 0.000525 
[Epoch 152/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000366, l1: 0.000344, l2: 0.000386, l3: 0.000523, l4: 0.000657, l5: 0.001589, l6: 0.002758

[epoch: 153/1000, batch:    16/ 1052, ite: 39980] train loss: 0.006517, tar: 0.000525 
l0: 0.000335, l1: 0.000349, l2: 0.000325, l3: 0.000451, l4: 0.000522, l5: 0.000714, l6: 0.000986

[epoch: 153/1000, batch:    96/ 1052, ite: 40000] train loss: 0.006519, tar: 0.000525 
l0: 0.000528, l1: 0.000535, l2: 0.000590, l3: 0.000718, l4: 0.000919, l5: 0.001920, l6: 0.002526

[epoch: 153/1000, batch:   176/ 1052, ite: 40020] train loss: 0.006519, tar: 0.000525 
l0: 0.000724, l1: 0.000777, l2: 0.000701, l3: 0.000711, l4: 0.000940, l5: 0.001645, l6: 0.002343

[epoch: 153/1000, batch:   256/ 1052, ite: 40040] train loss: 0.006516, tar: 0.000524 
l0: 0.000907, l1: 0.000863, l2: 0.000932, l3: 0.000985, l4: 0.001265, l5: 0.002438, l6: 0.003804

[epoch: 153/1000, batch:   336/ 1052, ite: 40060] train loss: 0.006515, tar: 0.000524 
l0: 0.000344, l1: 0.000347, l2: 0.000358, l3: 0.000372, l4: 0.000512, l5: 0.001134, l6: 0.001619

[epoch: 153/1000, batch:   416/ 1052, ite: 40080] train loss: 0.006512, tar: 0.000524 
l0: 0.000638, l1: 0.000620, l2: 0.000625, l3: 0.000734, l4: 0.000947, l5: 0.001399, l6: 0.002433

[epoch: 153/1000, batch:   496/ 1052, ite: 40100] train loss: 0.006513, tar: 0.000524 
l0: 0.000776, l1: 0.000745, l2: 0.000791, l3: 0.000900, l4: 0.001150, l5: 0.001664, l6: 0.003121

[epoch: 153/1000, batch:   576/ 1052, ite: 40120] train loss: 0.006513, tar: 0.000524 
l0: 0.000562, l1: 0.000573, l2: 0.000566, l3: 0.000563, l4: 0.000769, l5: 0.001036, l6: 0.001909

[epoch: 153/1000, batch:   656/ 1052, ite: 40140] train loss: 0.006512, tar: 0.000524 
l0: 0.000437, l1: 0.000461, l2: 0.000481, l3: 0.000454, l4: 0.000844, l5: 0.001272, l6: 0.001933

[epoch: 153/1000, batch:   736/ 1052, ite: 40160] train loss: 0.006511, tar: 0.000524 
l0: 0.000690, l1: 0.000720, l2: 0.000691, l3: 0.000715, l4: 0.000838, l5: 0.001376, l6: 0.002152

[epoch: 153/1000, batch:   816/ 1052, ite: 40180] train loss: 0.006511, tar: 0.000524 
l0: 0.000311, l1: 0.000310, l2: 0.000318, l3: 0.000334, l4: 0.000498, l5: 0.001176, l6: 0.001061

[epoch: 153/1000, batch:   896/ 1052, ite: 40200] train loss: 0.006510, tar: 0.000523 
l0: 0.000724, l1: 0.000715, l2: 0.000786, l3: 0.001034, l4: 0.001588, l5: 0.003199, l6: 0.005314

[epoch: 153/1000, batch:   976/ 1052, ite: 40220] train loss: 0.006510, tar: 0.000523 
[Epoch 153/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000259, l1: 0.000262, l2: 0.000277, l3: 0.000334, l4: 0.000646, l5: 0.001014, l6: 0.001237

[epoch: 154/1000, batch:     4/ 1052, ite: 40240] train loss: 0.006508, tar: 0.000523 
l0: 0.000744, l1: 0.000732, l2: 0.000772, l3: 0.000803, l4: 0.001404, l5: 0.001720, l6: 0.003184

[epoch: 154/1000, batch:    84/ 1052, ite: 40260] train loss: 0.006509, tar: 0.000523 
l0: 0.000200, l1: 0.000201, l2: 0.000214, l3: 0.000252, l4: 0.000451, l5: 0.000685, l6: 0.001419

[epoch: 154/1000, batch:   164/ 1052, ite: 40280] train loss: 0.006509, tar: 0.000523 
l0: 0.000583, l1: 0.000562, l2: 0.000626, l3: 0.000768, l4: 0.000930, l5: 0.001737, l6: 0.002682

[epoch: 154/1000, batch:   244/ 1052, ite: 40300] train loss: 0.006507, tar: 0.000523 
l0: 0.000354, l1: 0.000371, l2: 0.000365, l3: 0.000428, l4: 0.000532, l5: 0.000945, l6: 0.001946

[epoch: 154/1000, batch:   324/ 1052, ite: 40320] train loss: 0.006508, tar: 0.000523 
l0: 0.000198, l1: 0.000197, l2: 0.000211, l3: 0.000270, l4: 0.000365, l5: 0.000691, l6: 0.000786

[epoch: 154/1000, batch:   404/ 1052, ite: 40340] train loss: 0.006508, tar: 0.000523 
l0: 0.000378, l1: 0.000377, l2: 0.000394, l3: 0.000500, l4: 0.000587, l5: 0.001273, l6: 0.001870

[epoch: 154/1000, batch:   484/ 1052, ite: 40360] train loss: 0.006508, tar: 0.000523 
l0: 0.000312, l1: 0.000335, l2: 0.000337, l3: 0.000462, l4: 0.000445, l5: 0.000834, l6: 0.001342

[epoch: 154/1000, batch:   564/ 1052, ite: 40380] train loss: 0.006506, tar: 0.000523 
l0: 0.000365, l1: 0.000365, l2: 0.000395, l3: 0.000410, l4: 0.000665, l5: 0.001422, l6: 0.001736

[epoch: 154/1000, batch:   644/ 1052, ite: 40400] train loss: 0.006507, tar: 0.000523 
l0: 0.000469, l1: 0.000450, l2: 0.000539, l3: 0.000587, l4: 0.000748, l5: 0.001313, l6: 0.001551

[epoch: 154/1000, batch:   724/ 1052, ite: 40420] train loss: 0.006505, tar: 0.000522 
l0: 0.000309, l1: 0.000325, l2: 0.000328, l3: 0.000347, l4: 0.000446, l5: 0.001061, l6: 0.002017

[epoch: 154/1000, batch:   804/ 1052, ite: 40440] train loss: 0.006504, tar: 0.000522 
l0: 0.000500, l1: 0.000499, l2: 0.000555, l3: 0.000490, l4: 0.000608, l5: 0.001105, l6: 0.001123

[epoch: 154/1000, batch:   884/ 1052, ite: 40460] train loss: 0.006502, tar: 0.000522 
l0: 0.000186, l1: 0.000191, l2: 0.000191, l3: 0.000213, l4: 0.000319, l5: 0.000563, l6: 0.001068

[epoch: 154/1000, batch:   964/ 1052, ite: 40480] train loss: 0.006499, tar: 0.000522 
l0: 0.000639, l1: 0.000680, l2: 0.000627, l3: 0.000621, l4: 0.000776, l5: 0.001065, l6: 0.001900

[epoch: 154/1000, batch:  1044/ 1052, ite: 40500] train loss: 0.006501, tar: 0.000522 
[Epoch 154/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000655, l1: 0.000670, l2: 0.000688, l3: 0.000752, l4: 0.000786, l5: 0.001580, l6: 0.002297

[epoch: 155/1000, batch:    72/ 1052, ite: 40520] train loss: 0.006501, tar: 0.000522 
l0: 0.000424, l1: 0.000440, l2: 0.000463, l3: 0.000441, l4: 0.000652, l5: 0.001139, l6: 0.001724

[epoch: 155/1000, batch:   152/ 1052, ite: 40540] train loss: 0.006498, tar: 0.000522 
l0: 0.000167, l1: 0.000171, l2: 0.000202, l3: 0.000231, l4: 0.000357, l5: 0.000728, l6: 0.000895

[epoch: 155/1000, batch:   232/ 1052, ite: 40560] train loss: 0.006495, tar: 0.000521 
l0: 0.000573, l1: 0.000600, l2: 0.000530, l3: 0.000495, l4: 0.000874, l5: 0.000955, l6: 0.001225

[epoch: 155/1000, batch:   312/ 1052, ite: 40580] train loss: 0.006493, tar: 0.000521 
l0: 0.001123, l1: 0.001175, l2: 0.001202, l3: 0.001246, l4: 0.001188, l5: 0.002412, l6: 0.004139

[epoch: 155/1000, batch:   392/ 1052, ite: 40600] train loss: 0.006494, tar: 0.000521 
l0: 0.000442, l1: 0.000452, l2: 0.000485, l3: 0.000556, l4: 0.000986, l5: 0.002199, l6: 0.003448

[epoch: 155/1000, batch:   472/ 1052, ite: 40620] train loss: 0.006493, tar: 0.000521 
l0: 0.000299, l1: 0.000310, l2: 0.000300, l3: 0.000340, l4: 0.000488, l5: 0.000885, l6: 0.001021

[epoch: 155/1000, batch:   552/ 1052, ite: 40640] train loss: 0.006491, tar: 0.000521 
l0: 0.000471, l1: 0.000474, l2: 0.000512, l3: 0.000598, l4: 0.000625, l5: 0.001171, l6: 0.002771

[epoch: 155/1000, batch:   632/ 1052, ite: 40660] train loss: 0.006491, tar: 0.000521 
l0: 0.000354, l1: 0.000355, l2: 0.000366, l3: 0.000490, l4: 0.000553, l5: 0.000827, l6: 0.001960

[epoch: 155/1000, batch:   712/ 1052, ite: 40680] train loss: 0.006491, tar: 0.000521 
l0: 0.001399, l1: 0.001425, l2: 0.001366, l3: 0.001528, l4: 0.001801, l5: 0.002746, l6: 0.003729

[epoch: 155/1000, batch:   792/ 1052, ite: 40700] train loss: 0.006490, tar: 0.000520 
l0: 0.000208, l1: 0.000168, l2: 0.000283, l3: 0.000644, l4: 0.000570, l5: 0.000627, l6: 0.000426

[epoch: 155/1000, batch:   872/ 1052, ite: 40720] train loss: 0.006490, tar: 0.000520 
l0: 0.000471, l1: 0.000466, l2: 0.000496, l3: 0.000591, l4: 0.000710, l5: 0.001536, l6: 0.002787

[epoch: 155/1000, batch:   952/ 1052, ite: 40740] train loss: 0.006490, tar: 0.000521 
l0: 0.000393, l1: 0.000416, l2: 0.000417, l3: 0.000447, l4: 0.000668, l5: 0.000972, l6: 0.001415

[epoch: 155/1000, batch:  1032/ 1052, ite: 40760] train loss: 0.006490, tar: 0.000520 
[Epoch 155/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000384, l1: 0.000413, l2: 0.000394, l3: 0.000456, l4: 0.000593, l5: 0.001353, l6: 0.002086

[epoch: 156/1000, batch:    60/ 1052, ite: 40780] train loss: 0.006490, tar: 0.000521 
l0: 0.000352, l1: 0.000374, l2: 0.000376, l3: 0.000399, l4: 0.000540, l5: 0.001454, l6: 0.002108

[epoch: 156/1000, batch:   140/ 1052, ite: 40800] train loss: 0.006489, tar: 0.000520 
l0: 0.000754, l1: 0.000765, l2: 0.000800, l3: 0.000832, l4: 0.001192, l5: 0.002327, l6: 0.002730

[epoch: 156/1000, batch:   220/ 1052, ite: 40820] train loss: 0.006488, tar: 0.000520 
l0: 0.000477, l1: 0.000468, l2: 0.000486, l3: 0.000566, l4: 0.000716, l5: 0.001172, l6: 0.001703

[epoch: 156/1000, batch:   300/ 1052, ite: 40840] train loss: 0.006487, tar: 0.000520 
l0: 0.000520, l1: 0.000500, l2: 0.000536, l3: 0.000665, l4: 0.001099, l5: 0.001779, l6: 0.003502

[epoch: 156/1000, batch:   380/ 1052, ite: 40860] train loss: 0.006485, tar: 0.000520 
l0: 0.000294, l1: 0.000275, l2: 0.000331, l3: 0.000493, l4: 0.000644, l5: 0.001072, l6: 0.001431

[epoch: 156/1000, batch:   460/ 1052, ite: 40880] train loss: 0.006484, tar: 0.000520 
l0: 0.000693, l1: 0.000757, l2: 0.000681, l3: 0.000834, l4: 0.000973, l5: 0.001211, l6: 0.001663

[epoch: 156/1000, batch:   540/ 1052, ite: 40900] train loss: 0.006483, tar: 0.000520 
l0: 0.000296, l1: 0.000295, l2: 0.000312, l3: 0.000376, l4: 0.000495, l5: 0.001274, l6: 0.002047

[epoch: 156/1000, batch:   620/ 1052, ite: 40920] train loss: 0.006485, tar: 0.000520 
l0: 0.000456, l1: 0.000465, l2: 0.000487, l3: 0.000649, l4: 0.000819, l5: 0.001833, l6: 0.002818

[epoch: 156/1000, batch:   700/ 1052, ite: 40940] train loss: 0.006484, tar: 0.000520 
l0: 0.000396, l1: 0.000401, l2: 0.000430, l3: 0.000552, l4: 0.000786, l5: 0.001335, l6: 0.002207

[epoch: 156/1000, batch:   780/ 1052, ite: 40960] train loss: 0.006486, tar: 0.000520 
l0: 0.000667, l1: 0.000693, l2: 0.000754, l3: 0.000844, l4: 0.000901, l5: 0.001602, l6: 0.003533

[epoch: 156/1000, batch:   860/ 1052, ite: 40980] train loss: 0.006487, tar: 0.000520 
l0: 0.000467, l1: 0.000472, l2: 0.000489, l3: 0.000581, l4: 0.000711, l5: 0.001313, l6: 0.001796

[epoch: 156/1000, batch:   940/ 1052, ite: 41000] train loss: 0.006487, tar: 0.000520 
l0: 0.000662, l1: 0.000662, l2: 0.000743, l3: 0.000740, l4: 0.001044, l5: 0.001735, l6: 0.003346

[epoch: 156/1000, batch:  1020/ 1052, ite: 41020] train loss: 0.006485, tar: 0.000520 
[Epoch 156/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000649, l1: 0.000665, l2: 0.000666, l3: 0.000696, l4: 0.000977, l5: 0.001894, l6: 0.002809

[epoch: 157/1000, batch:    48/ 1052, ite: 41040] train loss: 0.006483, tar: 0.000519 
l0: 0.000338, l1: 0.000323, l2: 0.000348, l3: 0.000543, l4: 0.000713, l5: 0.000931, l6: 0.001471

[epoch: 157/1000, batch:   128/ 1052, ite: 41060] train loss: 0.006481, tar: 0.000519 
l0: 0.000138, l1: 0.000135, l2: 0.000156, l3: 0.000174, l4: 0.000257, l5: 0.000624, l6: 0.000966

[epoch: 157/1000, batch:   208/ 1052, ite: 41080] train loss: 0.006481, tar: 0.000519 
l0: 0.000267, l1: 0.000278, l2: 0.000288, l3: 0.000272, l4: 0.000505, l5: 0.000780, l6: 0.001575

[epoch: 157/1000, batch:   288/ 1052, ite: 41100] train loss: 0.006480, tar: 0.000519 
l0: 0.000183, l1: 0.000184, l2: 0.000211, l3: 0.000252, l4: 0.000405, l5: 0.000624, l6: 0.001071

[epoch: 157/1000, batch:   368/ 1052, ite: 41120] train loss: 0.006480, tar: 0.000519 
l0: 0.000417, l1: 0.000415, l2: 0.000424, l3: 0.000425, l4: 0.000530, l5: 0.001058, l6: 0.001797

[epoch: 157/1000, batch:   448/ 1052, ite: 41140] train loss: 0.006478, tar: 0.000519 
l0: 0.000470, l1: 0.000492, l2: 0.000499, l3: 0.000534, l4: 0.000643, l5: 0.001452, l6: 0.001412

[epoch: 157/1000, batch:   528/ 1052, ite: 41160] train loss: 0.006478, tar: 0.000519 
l0: 0.000663, l1: 0.000658, l2: 0.000743, l3: 0.000882, l4: 0.001166, l5: 0.002219, l6: 0.003626

[epoch: 157/1000, batch:   608/ 1052, ite: 41180] train loss: 0.006477, tar: 0.000518 
l0: 0.000370, l1: 0.000363, l2: 0.000397, l3: 0.000456, l4: 0.000616, l5: 0.001192, l6: 0.001512

[epoch: 157/1000, batch:   688/ 1052, ite: 41200] train loss: 0.006477, tar: 0.000518 
l0: 0.000327, l1: 0.000331, l2: 0.000347, l3: 0.000370, l4: 0.000504, l5: 0.000869, l6: 0.001128

[epoch: 157/1000, batch:   768/ 1052, ite: 41220] train loss: 0.006476, tar: 0.000518 
l0: 0.000563, l1: 0.000637, l2: 0.000646, l3: 0.000641, l4: 0.000901, l5: 0.001454, l6: 0.002237

[epoch: 157/1000, batch:   848/ 1052, ite: 41240] train loss: 0.006475, tar: 0.000518 
l0: 0.000248, l1: 0.000256, l2: 0.000258, l3: 0.000339, l4: 0.000493, l5: 0.000818, l6: 0.001076

[epoch: 157/1000, batch:   928/ 1052, ite: 41260] train loss: 0.006475, tar: 0.000518 
l0: 0.000373, l1: 0.000378, l2: 0.000388, l3: 0.000504, l4: 0.000514, l5: 0.001035, l6: 0.001668

[epoch: 157/1000, batch:  1008/ 1052, ite: 41280] train loss: 0.006473, tar: 0.000518 
[Epoch 157/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000422, l1: 0.000419, l2: 0.000442, l3: 0.000502, l4: 0.000769, l5: 0.001623, l6: 0.002159

[epoch: 158/1000, batch:    36/ 1052, ite: 41300] train loss: 0.006472, tar: 0.000518 
l0: 0.000342, l1: 0.000351, l2: 0.000355, l3: 0.000439, l4: 0.000638, l5: 0.001385, l6: 0.001921

[epoch: 158/1000, batch:   116/ 1052, ite: 41320] train loss: 0.006471, tar: 0.000518 
l0: 0.000448, l1: 0.000453, l2: 0.000486, l3: 0.000544, l4: 0.000849, l5: 0.001226, l6: 0.002418

[epoch: 158/1000, batch:   196/ 1052, ite: 41340] train loss: 0.006470, tar: 0.000518 
l0: 0.000299, l1: 0.000316, l2: 0.000304, l3: 0.000372, l4: 0.000589, l5: 0.001521, l6: 0.002177

[epoch: 158/1000, batch:   276/ 1052, ite: 41360] train loss: 0.006470, tar: 0.000518 
l0: 0.000367, l1: 0.000382, l2: 0.000366, l3: 0.000392, l4: 0.000588, l5: 0.000823, l6: 0.001968

[epoch: 158/1000, batch:   356/ 1052, ite: 41380] train loss: 0.006469, tar: 0.000517 
l0: 0.000553, l1: 0.000552, l2: 0.000558, l3: 0.000704, l4: 0.000971, l5: 0.001637, l6: 0.001994

[epoch: 158/1000, batch:   436/ 1052, ite: 41400] train loss: 0.006468, tar: 0.000517 
l0: 0.001061, l1: 0.001061, l2: 0.001196, l3: 0.001209, l4: 0.001282, l5: 0.001599, l6: 0.003310

[epoch: 158/1000, batch:   516/ 1052, ite: 41420] train loss: 0.006467, tar: 0.000517 
l0: 0.000556, l1: 0.000545, l2: 0.000628, l3: 0.000779, l4: 0.001117, l5: 0.002051, l6: 0.003534

[epoch: 158/1000, batch:   596/ 1052, ite: 41440] train loss: 0.006465, tar: 0.000517 
l0: 0.000572, l1: 0.000573, l2: 0.000596, l3: 0.000732, l4: 0.001054, l5: 0.001257, l6: 0.003001

[epoch: 158/1000, batch:   676/ 1052, ite: 41460] train loss: 0.006465, tar: 0.000517 
l0: 0.000406, l1: 0.000422, l2: 0.000431, l3: 0.000454, l4: 0.000687, l5: 0.000851, l6: 0.001546

[epoch: 158/1000, batch:   756/ 1052, ite: 41480] train loss: 0.006470, tar: 0.000517 
l0: 0.000504, l1: 0.000526, l2: 0.000564, l3: 0.000498, l4: 0.000682, l5: 0.001067, l6: 0.001726

[epoch: 158/1000, batch:   836/ 1052, ite: 41500] train loss: 0.006471, tar: 0.000518 
l0: 0.001014, l1: 0.001077, l2: 0.001062, l3: 0.001124, l4: 0.001425, l5: 0.002447, l6: 0.003493

[epoch: 158/1000, batch:   916/ 1052, ite: 41520] train loss: 0.006476, tar: 0.000518 
l0: 0.000335, l1: 0.000332, l2: 0.000378, l3: 0.000453, l4: 0.000795, l5: 0.000925, l6: 0.001771

[epoch: 158/1000, batch:   996/ 1052, ite: 41540] train loss: 0.006477, tar: 0.000518 
[Epoch 158/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000350, l1: 0.000360, l2: 0.000399, l3: 0.000391, l4: 0.000659, l5: 0.001183, l6: 0.002020

[epoch: 159/1000, batch:    24/ 1052, ite: 41560] train loss: 0.006477, tar: 0.000518 
l0: 0.000460, l1: 0.000473, l2: 0.000503, l3: 0.000509, l4: 0.000667, l5: 0.001660, l6: 0.002700

[epoch: 159/1000, batch:   104/ 1052, ite: 41580] train loss: 0.006480, tar: 0.000518 
l0: 0.000397, l1: 0.000375, l2: 0.000436, l3: 0.000588, l4: 0.000926, l5: 0.001280, l6: 0.002673

[epoch: 159/1000, batch:   184/ 1052, ite: 41600] train loss: 0.006481, tar: 0.000518 
l0: 0.000356, l1: 0.000344, l2: 0.000442, l3: 0.000481, l4: 0.000639, l5: 0.000941, l6: 0.001102

[epoch: 159/1000, batch:   264/ 1052, ite: 41620] train loss: 0.006480, tar: 0.000518 
l0: 0.000630, l1: 0.000675, l2: 0.000682, l3: 0.000693, l4: 0.001477, l5: 0.002174, l6: 0.003072

[epoch: 159/1000, batch:   344/ 1052, ite: 41640] train loss: 0.006482, tar: 0.000519 
l0: 0.000340, l1: 0.000337, l2: 0.000359, l3: 0.000421, l4: 0.000593, l5: 0.001096, l6: 0.001712

[epoch: 159/1000, batch:   424/ 1052, ite: 41660] train loss: 0.006483, tar: 0.000519 
l0: 0.000202, l1: 0.000197, l2: 0.000211, l3: 0.000239, l4: 0.000393, l5: 0.000627, l6: 0.000977

[epoch: 159/1000, batch:   504/ 1052, ite: 41680] train loss: 0.006484, tar: 0.000519 
l0: 0.000989, l1: 0.001077, l2: 0.001172, l3: 0.001144, l4: 0.001154, l5: 0.001740, l6: 0.002310

[epoch: 159/1000, batch:   584/ 1052, ite: 41700] train loss: 0.006483, tar: 0.000519 
l0: 0.000515, l1: 0.000526, l2: 0.000548, l3: 0.000581, l4: 0.000679, l5: 0.000836, l6: 0.001365

[epoch: 159/1000, batch:   664/ 1052, ite: 41720] train loss: 0.006485, tar: 0.000519 
l0: 0.000568, l1: 0.000562, l2: 0.000609, l3: 0.000655, l4: 0.000906, l5: 0.001687, l6: 0.003148

[epoch: 159/1000, batch:   744/ 1052, ite: 41740] train loss: 0.006484, tar: 0.000519 
l0: 0.000438, l1: 0.000419, l2: 0.000435, l3: 0.000708, l4: 0.000836, l5: 0.001032, l6: 0.001430

[epoch: 159/1000, batch:   824/ 1052, ite: 41760] train loss: 0.006483, tar: 0.000519 
l0: 0.000506, l1: 0.000483, l2: 0.000530, l3: 0.000714, l4: 0.001019, l5: 0.001189, l6: 0.001766

[epoch: 159/1000, batch:   904/ 1052, ite: 41780] train loss: 0.006481, tar: 0.000518 
l0: 0.000389, l1: 0.000385, l2: 0.000385, l3: 0.000489, l4: 0.000613, l5: 0.001028, l6: 0.002224

[epoch: 159/1000, batch:   984/ 1052, ite: 41800] train loss: 0.006481, tar: 0.000518 
[Epoch 159/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000769, l1: 0.000768, l2: 0.000808, l3: 0.001009, l4: 0.001326, l5: 0.001892, l6: 0.002264

[epoch: 160/1000, batch:    12/ 1052, ite: 41820] train loss: 0.006480, tar: 0.000518 
l0: 0.000276, l1: 0.000288, l2: 0.000262, l3: 0.000307, l4: 0.000372, l5: 0.000816, l6: 0.001191

[epoch: 160/1000, batch:    92/ 1052, ite: 41840] train loss: 0.006479, tar: 0.000518 
l0: 0.000516, l1: 0.000496, l2: 0.000596, l3: 0.000591, l4: 0.000712, l5: 0.001612, l6: 0.001923

[epoch: 160/1000, batch:   172/ 1052, ite: 41860] train loss: 0.006478, tar: 0.000518 
l0: 0.000310, l1: 0.000376, l2: 0.000313, l3: 0.000376, l4: 0.000562, l5: 0.000637, l6: 0.001195

[epoch: 160/1000, batch:   252/ 1052, ite: 41880] train loss: 0.006477, tar: 0.000518 
l0: 0.000611, l1: 0.000610, l2: 0.000596, l3: 0.000672, l4: 0.001029, l5: 0.002089, l6: 0.003264

[epoch: 160/1000, batch:   332/ 1052, ite: 41900] train loss: 0.006476, tar: 0.000518 
l0: 0.000241, l1: 0.000240, l2: 0.000265, l3: 0.000285, l4: 0.000440, l5: 0.001179, l6: 0.001488

[epoch: 160/1000, batch:   412/ 1052, ite: 41920] train loss: 0.006476, tar: 0.000518 
l0: 0.000471, l1: 0.000492, l2: 0.000471, l3: 0.000516, l4: 0.000727, l5: 0.000829, l6: 0.001440

[epoch: 160/1000, batch:   492/ 1052, ite: 41940] train loss: 0.006475, tar: 0.000518 
l0: 0.000479, l1: 0.000489, l2: 0.000546, l3: 0.000509, l4: 0.000850, l5: 0.001391, l6: 0.001726

[epoch: 160/1000, batch:   572/ 1052, ite: 41960] train loss: 0.006475, tar: 0.000518 
l0: 0.000272, l1: 0.000262, l2: 0.000324, l3: 0.000356, l4: 0.000569, l5: 0.001000, l6: 0.001297

[epoch: 160/1000, batch:   652/ 1052, ite: 41980] train loss: 0.006473, tar: 0.000517 
l0: 0.000361, l1: 0.000343, l2: 0.000365, l3: 0.000481, l4: 0.000713, l5: 0.001614, l6: 0.002448

[epoch: 160/1000, batch:   732/ 1052, ite: 42000] train loss: 0.006478, tar: 0.000518 
l0: 0.000243, l1: 0.000241, l2: 0.000238, l3: 0.000306, l4: 0.000380, l5: 0.001054, l6: 0.001526

[epoch: 160/1000, batch:   812/ 1052, ite: 42020] train loss: 0.006475, tar: 0.000518 
l0: 0.000545, l1: 0.000571, l2: 0.000569, l3: 0.000643, l4: 0.000861, l5: 0.001552, l6: 0.002361

[epoch: 160/1000, batch:   892/ 1052, ite: 42040] train loss: 0.006475, tar: 0.000518 
l0: 0.000595, l1: 0.000582, l2: 0.000620, l3: 0.000629, l4: 0.000943, l5: 0.001275, l6: 0.002243

[epoch: 160/1000, batch:   972/ 1052, ite: 42060] train loss: 0.006475, tar: 0.000518 
l0: 0.000878, l1: 0.000860, l2: 0.000903, l3: 0.000896, l4: 0.001062, l5: 0.001469, l6: 0.001540

[epoch: 160/1000, batch:  1052/ 1052, ite: 42080] train loss: 0.006474, tar: 0.000518 
[Epoch 160/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000247, l1: 0.000241, l2: 0.000255, l3: 0.000326, l4: 0.000397, l5: 0.000810, l6: 0.001782

[epoch: 161/1000, batch:    80/ 1052, ite: 42100] train loss: 0.005710, tar: 0.000412 
l0: 0.000450, l1: 0.000443, l2: 0.000467, l3: 0.000517, l4: 0.000615, l5: 0.001316, l6: 0.002368

[epoch: 161/1000, batch:   160/ 1052, ite: 42120] train loss: 0.005707, tar: 0.000415 
l0: 0.000588, l1: 0.000609, l2: 0.000640, l3: 0.000654, l4: 0.001063, l5: 0.001427, l6: 0.002664

[epoch: 161/1000, batch:   240/ 1052, ite: 42140] train loss: 0.005793, tar: 0.000428 
l0: 0.000331, l1: 0.000375, l2: 0.000329, l3: 0.000316, l4: 0.000565, l5: 0.001072, l6: 0.002173

[epoch: 161/1000, batch:   320/ 1052, ite: 42160] train loss: 0.005759, tar: 0.000425 
l0: 0.000541, l1: 0.000550, l2: 0.000838, l3: 0.000763, l4: 0.000962, l5: 0.001719, l6: 0.002623

[epoch: 161/1000, batch:   400/ 1052, ite: 42180] train loss: 0.005821, tar: 0.000434 
l0: 0.000347, l1: 0.000361, l2: 0.000346, l3: 0.000346, l4: 0.000449, l5: 0.000597, l6: 0.000989

[epoch: 161/1000, batch:   480/ 1052, ite: 42200] train loss: 0.005883, tar: 0.000441 
l0: 0.000247, l1: 0.000257, l2: 0.000279, l3: 0.000299, l4: 0.000487, l5: 0.000919, l6: 0.001357

[epoch: 161/1000, batch:   560/ 1052, ite: 42220] train loss: 0.005913, tar: 0.000445 
l0: 0.000650, l1: 0.000682, l2: 0.000679, l3: 0.000678, l4: 0.000958, l5: 0.001449, l6: 0.002401

[epoch: 161/1000, batch:   640/ 1052, ite: 42240] train loss: 0.006073, tar: 0.000463 
l0: 0.000242, l1: 0.000241, l2: 0.000252, l3: 0.000280, l4: 0.000410, l5: 0.000821, l6: 0.001437

[epoch: 161/1000, batch:   720/ 1052, ite: 42260] train loss: 0.006106, tar: 0.000467 
l0: 0.000210, l1: 0.000206, l2: 0.000228, l3: 0.000289, l4: 0.000469, l5: 0.000955, l6: 0.001280

[epoch: 161/1000, batch:   800/ 1052, ite: 42280] train loss: 0.006069, tar: 0.000466 
l0: 0.000236, l1: 0.000219, l2: 0.000234, l3: 0.000376, l4: 0.000496, l5: 0.000870, l6: 0.001238

[epoch: 161/1000, batch:   880/ 1052, ite: 42300] train loss: 0.006120, tar: 0.000469 
l0: 0.001817, l1: 0.001869, l2: 0.001838, l3: 0.002054, l4: 0.001607, l5: 0.001964, l6: 0.003259

[epoch: 161/1000, batch:   960/ 1052, ite: 42320] train loss: 0.006196, tar: 0.000475 
l0: 0.000289, l1: 0.000291, l2: 0.000302, l3: 0.000314, l4: 0.000412, l5: 0.001018, l6: 0.001255

[epoch: 161/1000, batch:  1040/ 1052, ite: 42340] train loss: 0.006259, tar: 0.000481 
[Epoch 161/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000781, l1: 0.000737, l2: 0.000801, l3: 0.000911, l4: 0.001477, l5: 0.002436, l6: 0.003310

[epoch: 162/1000, batch:    68/ 1052, ite: 42360] train loss: 0.006241, tar: 0.000480 
l0: 0.000282, l1: 0.000269, l2: 0.000259, l3: 0.000388, l4: 0.000704, l5: 0.001392, l6: 0.001728

[epoch: 162/1000, batch:   148/ 1052, ite: 42380] train loss: 0.006219, tar: 0.000478 
l0: 0.000419, l1: 0.000430, l2: 0.000434, l3: 0.000490, l4: 0.000664, l5: 0.001353, l6: 0.002065

[epoch: 162/1000, batch:   228/ 1052, ite: 42400] train loss: 0.006149, tar: 0.000470 
l0: 0.000389, l1: 0.000397, l2: 0.000406, l3: 0.000441, l4: 0.000762, l5: 0.001561, l6: 0.001849

[epoch: 162/1000, batch:   308/ 1052, ite: 42420] train loss: 0.006126, tar: 0.000467 
l0: 0.000459, l1: 0.000496, l2: 0.000434, l3: 0.000408, l4: 0.000628, l5: 0.001167, l6: 0.002981

[epoch: 162/1000, batch:   388/ 1052, ite: 42440] train loss: 0.006151, tar: 0.000471 
l0: 0.000392, l1: 0.000388, l2: 0.000463, l3: 0.000463, l4: 0.000583, l5: 0.001182, l6: 0.001588

[epoch: 162/1000, batch:   468/ 1052, ite: 42460] train loss: 0.006132, tar: 0.000469 
l0: 0.000602, l1: 0.000611, l2: 0.000595, l3: 0.000659, l4: 0.000806, l5: 0.000967, l6: 0.001891

[epoch: 162/1000, batch:   548/ 1052, ite: 42480] train loss: 0.006141, tar: 0.000470 
l0: 0.000300, l1: 0.000294, l2: 0.000305, l3: 0.000309, l4: 0.000397, l5: 0.000717, l6: 0.001437

[epoch: 162/1000, batch:   628/ 1052, ite: 42500] train loss: 0.006149, tar: 0.000470 
l0: 0.000589, l1: 0.000624, l2: 0.000609, l3: 0.000625, l4: 0.000783, l5: 0.001487, l6: 0.002950

[epoch: 162/1000, batch:   708/ 1052, ite: 42520] train loss: 0.006155, tar: 0.000470 
l0: 0.000489, l1: 0.000497, l2: 0.000526, l3: 0.000591, l4: 0.000763, l5: 0.001660, l6: 0.002165

[epoch: 162/1000, batch:   788/ 1052, ite: 42540] train loss: 0.006142, tar: 0.000468 
l0: 0.000274, l1: 0.000269, l2: 0.000294, l3: 0.000323, l4: 0.000522, l5: 0.001000, l6: 0.001188

[epoch: 162/1000, batch:   868/ 1052, ite: 42560] train loss: 0.006234, tar: 0.000483 
l0: 0.000218, l1: 0.000208, l2: 0.000228, l3: 0.000278, l4: 0.000501, l5: 0.000847, l6: 0.001562

[epoch: 162/1000, batch:   948/ 1052, ite: 42580] train loss: 0.006229, tar: 0.000483 
l0: 0.000257, l1: 0.000286, l2: 0.000270, l3: 0.000196, l4: 0.000261, l5: 0.000446, l6: 0.001147

[epoch: 162/1000, batch:  1028/ 1052, ite: 42600] train loss: 0.006212, tar: 0.000482 
[Epoch 162/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000446, l1: 0.000434, l2: 0.000480, l3: 0.000521, l4: 0.000679, l5: 0.001445, l6: 0.001774

[epoch: 163/1000, batch:    56/ 1052, ite: 42620] train loss: 0.006239, tar: 0.000484 
l0: 0.000510, l1: 0.000538, l2: 0.000486, l3: 0.000590, l4: 0.000893, l5: 0.001207, l6: 0.002794

[epoch: 163/1000, batch:   136/ 1052, ite: 42640] train loss: 0.006345, tar: 0.000501 
l0: 0.000330, l1: 0.000305, l2: 0.000325, l3: 0.000398, l4: 0.000572, l5: 0.001246, l6: 0.001858

[epoch: 163/1000, batch:   216/ 1052, ite: 42660] train loss: 0.006375, tar: 0.000503 
l0: 0.000256, l1: 0.000255, l2: 0.000274, l3: 0.000370, l4: 0.000617, l5: 0.000833, l6: 0.001310

[epoch: 163/1000, batch:   296/ 1052, ite: 42680] train loss: 0.006393, tar: 0.000503 
l0: 0.000501, l1: 0.000457, l2: 0.000603, l3: 0.000807, l4: 0.001130, l5: 0.002278, l6: 0.003119

[epoch: 163/1000, batch:   376/ 1052, ite: 42700] train loss: 0.006400, tar: 0.000502 
l0: 0.000270, l1: 0.000327, l2: 0.001399, l3: 0.000930, l4: 0.000370, l5: 0.000895, l6: 0.001232

[epoch: 163/1000, batch:   456/ 1052, ite: 42720] train loss: 0.006410, tar: 0.000503 
l0: 0.000463, l1: 0.000440, l2: 0.000532, l3: 0.000588, l4: 0.000927, l5: 0.000987, l6: 0.001874

[epoch: 163/1000, batch:   536/ 1052, ite: 42740] train loss: 0.006396, tar: 0.000502 
l0: 0.000396, l1: 0.000389, l2: 0.000447, l3: 0.000475, l4: 0.000637, l5: 0.001344, l6: 0.001965

[epoch: 163/1000, batch:   616/ 1052, ite: 42760] train loss: 0.006425, tar: 0.000505 
l0: 0.000494, l1: 0.000509, l2: 0.000507, l3: 0.000528, l4: 0.000765, l5: 0.001541, l6: 0.001941

[epoch: 163/1000, batch:   696/ 1052, ite: 42780] train loss: 0.006426, tar: 0.000504 
l0: 0.000523, l1: 0.000529, l2: 0.000552, l3: 0.000616, l4: 0.001051, l5: 0.001348, l6: 0.002462

[epoch: 163/1000, batch:   776/ 1052, ite: 42800] train loss: 0.006436, tar: 0.000506 
l0: 0.000434, l1: 0.000445, l2: 0.000614, l3: 0.000448, l4: 0.000642, l5: 0.000783, l6: 0.001940

[epoch: 163/1000, batch:   856/ 1052, ite: 42820] train loss: 0.006444, tar: 0.000506 
l0: 0.000412, l1: 0.000430, l2: 0.000461, l3: 0.000450, l4: 0.000729, l5: 0.001341, l6: 0.001686

[epoch: 163/1000, batch:   936/ 1052, ite: 42840] train loss: 0.006423, tar: 0.000504 
l0: 0.000208, l1: 0.000209, l2: 0.000242, l3: 0.000256, l4: 0.000476, l5: 0.000908, l6: 0.001532

[epoch: 163/1000, batch:  1016/ 1052, ite: 42860] train loss: 0.006393, tar: 0.000501 
[Epoch 163/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000570, l1: 0.000528, l2: 0.000619, l3: 0.000754, l4: 0.001121, l5: 0.001863, l6: 0.003514

[epoch: 164/1000, batch:    44/ 1052, ite: 42880] train loss: 0.006407, tar: 0.000502 
l0: 0.000453, l1: 0.000416, l2: 0.000482, l3: 0.000577, l4: 0.000843, l5: 0.001410, l6: 0.002493

[epoch: 164/1000, batch:   124/ 1052, ite: 42900] train loss: 0.006396, tar: 0.000500 
l0: 0.000503, l1: 0.000499, l2: 0.000502, l3: 0.000539, l4: 0.001014, l5: 0.001505, l6: 0.002987

[epoch: 164/1000, batch:   204/ 1052, ite: 42920] train loss: 0.006391, tar: 0.000499 
l0: 0.000268, l1: 0.000258, l2: 0.000308, l3: 0.000364, l4: 0.000471, l5: 0.001203, l6: 0.001556

[epoch: 164/1000, batch:   284/ 1052, ite: 42940] train loss: 0.006383, tar: 0.000498 
l0: 0.000304, l1: 0.000324, l2: 0.000320, l3: 0.000294, l4: 0.000423, l5: 0.000586, l6: 0.001336

[epoch: 164/1000, batch:   364/ 1052, ite: 42960] train loss: 0.006388, tar: 0.000498 
l0: 0.000683, l1: 0.000687, l2: 0.000719, l3: 0.000767, l4: 0.000862, l5: 0.000993, l6: 0.001836

[epoch: 164/1000, batch:   444/ 1052, ite: 42980] train loss: 0.006390, tar: 0.000498 
l0: 0.000371, l1: 0.000365, l2: 0.000352, l3: 0.000487, l4: 0.000758, l5: 0.001705, l6: 0.002097

[epoch: 164/1000, batch:   524/ 1052, ite: 43000] train loss: 0.006387, tar: 0.000498 
l0: 0.000369, l1: 0.000367, l2: 0.000365, l3: 0.000409, l4: 0.000512, l5: 0.001029, l6: 0.001674

[epoch: 164/1000, batch:   604/ 1052, ite: 43020] train loss: 0.006382, tar: 0.000497 
l0: 0.000353, l1: 0.000360, l2: 0.000365, l3: 0.000405, l4: 0.000554, l5: 0.000940, l6: 0.001271

[epoch: 164/1000, batch:   684/ 1052, ite: 43040] train loss: 0.006407, tar: 0.000499 
l0: 0.000273, l1: 0.000270, l2: 0.000308, l3: 0.000366, l4: 0.000702, l5: 0.001130, l6: 0.001294

[epoch: 164/1000, batch:   764/ 1052, ite: 43060] train loss: 0.006384, tar: 0.000497 
l0: 0.000340, l1: 0.000317, l2: 0.000332, l3: 0.000422, l4: 0.000382, l5: 0.000885, l6: 0.001698

[epoch: 164/1000, batch:   844/ 1052, ite: 43080] train loss: 0.006390, tar: 0.000497 
l0: 0.000249, l1: 0.000283, l2: 0.000278, l3: 0.000280, l4: 0.000413, l5: 0.000629, l6: 0.000796

[epoch: 164/1000, batch:   924/ 1052, ite: 43100] train loss: 0.006375, tar: 0.000496 
l0: 0.000338, l1: 0.000354, l2: 0.000344, l3: 0.000351, l4: 0.000480, l5: 0.000793, l6: 0.001409

[epoch: 164/1000, batch:  1004/ 1052, ite: 43120] train loss: 0.006375, tar: 0.000496 
[Epoch 164/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000469, l1: 0.000478, l2: 0.000493, l3: 0.000660, l4: 0.001138, l5: 0.001569, l6: 0.002264

[epoch: 165/1000, batch:    32/ 1052, ite: 43140] train loss: 0.006380, tar: 0.000497 
l0: 0.000335, l1: 0.000339, l2: 0.000349, l3: 0.000383, l4: 0.000447, l5: 0.000896, l6: 0.001385

[epoch: 165/1000, batch:   112/ 1052, ite: 43160] train loss: 0.006384, tar: 0.000497 
l0: 0.000302, l1: 0.000297, l2: 0.000323, l3: 0.000391, l4: 0.000695, l5: 0.001297, l6: 0.001929

[epoch: 165/1000, batch:   192/ 1052, ite: 43180] train loss: 0.006369, tar: 0.000496 
l0: 0.000428, l1: 0.000416, l2: 0.000438, l3: 0.000492, l4: 0.000748, l5: 0.001409, l6: 0.002405

[epoch: 165/1000, batch:   272/ 1052, ite: 43200] train loss: 0.006364, tar: 0.000496 
l0: 0.000204, l1: 0.000210, l2: 0.000210, l3: 0.000244, l4: 0.000374, l5: 0.000744, l6: 0.000976

[epoch: 165/1000, batch:   352/ 1052, ite: 43220] train loss: 0.006352, tar: 0.000495 
l0: 0.000665, l1: 0.000612, l2: 0.000790, l3: 0.001098, l4: 0.001501, l5: 0.002963, l6: 0.004257

[epoch: 165/1000, batch:   432/ 1052, ite: 43240] train loss: 0.006349, tar: 0.000494 
l0: 0.000269, l1: 0.000268, l2: 0.000287, l3: 0.000346, l4: 0.000417, l5: 0.000876, l6: 0.001480

[epoch: 165/1000, batch:   512/ 1052, ite: 43260] train loss: 0.006352, tar: 0.000494 
l0: 0.000517, l1: 0.000529, l2: 0.000544, l3: 0.000603, l4: 0.000990, l5: 0.001383, l6: 0.003270

[epoch: 165/1000, batch:   592/ 1052, ite: 43280] train loss: 0.006343, tar: 0.000494 
l0: 0.000518, l1: 0.000482, l2: 0.000527, l3: 0.000723, l4: 0.000977, l5: 0.002022, l6: 0.002881

[epoch: 165/1000, batch:   672/ 1052, ite: 43300] train loss: 0.006348, tar: 0.000494 
l0: 0.000574, l1: 0.000561, l2: 0.000608, l3: 0.000820, l4: 0.001018, l5: 0.001309, l6: 0.002649

[epoch: 165/1000, batch:   752/ 1052, ite: 43320] train loss: 0.006347, tar: 0.000494 
l0: 0.000736, l1: 0.000767, l2: 0.000739, l3: 0.000807, l4: 0.001041, l5: 0.001615, l6: 0.002896

[epoch: 165/1000, batch:   832/ 1052, ite: 43340] train loss: 0.006343, tar: 0.000493 
l0: 0.000742, l1: 0.000763, l2: 0.000872, l3: 0.000888, l4: 0.001148, l5: 0.001768, l6: 0.003057

[epoch: 165/1000, batch:   912/ 1052, ite: 43360] train loss: 0.006331, tar: 0.000492 
l0: 0.000332, l1: 0.000327, l2: 0.000351, l3: 0.000424, l4: 0.000584, l5: 0.000974, l6: 0.002404

[epoch: 165/1000, batch:   992/ 1052, ite: 43380] train loss: 0.006324, tar: 0.000491 
[Epoch 165/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000450, l1: 0.000470, l2: 0.000468, l3: 0.000532, l4: 0.000911, l5: 0.001463, l6: 0.002336

[epoch: 166/1000, batch:    20/ 1052, ite: 43400] train loss: 0.006336, tar: 0.000492 
l0: 0.000811, l1: 0.000751, l2: 0.000855, l3: 0.001156, l4: 0.001660, l5: 0.002541, l6: 0.004592

[epoch: 166/1000, batch:   100/ 1052, ite: 43420] train loss: 0.006356, tar: 0.000493 
l0: 0.000225, l1: 0.000216, l2: 0.000260, l3: 0.000349, l4: 0.000575, l5: 0.000883, l6: 0.001590

[epoch: 166/1000, batch:   180/ 1052, ite: 43440] train loss: 0.006339, tar: 0.000492 
l0: 0.000232, l1: 0.000233, l2: 0.000263, l3: 0.000320, l4: 0.000526, l5: 0.000886, l6: 0.001400

[epoch: 166/1000, batch:   260/ 1052, ite: 43460] train loss: 0.006327, tar: 0.000491 
l0: 0.000567, l1: 0.000583, l2: 0.000589, l3: 0.000794, l4: 0.001073, l5: 0.001254, l6: 0.003099

[epoch: 166/1000, batch:   340/ 1052, ite: 43480] train loss: 0.006318, tar: 0.000490 
l0: 0.000249, l1: 0.000242, l2: 0.000272, l3: 0.000303, l4: 0.000409, l5: 0.000771, l6: 0.001370

[epoch: 166/1000, batch:   420/ 1052, ite: 43500] train loss: 0.006312, tar: 0.000489 
l0: 0.000506, l1: 0.000477, l2: 0.000520, l3: 0.000686, l4: 0.000951, l5: 0.001337, l6: 0.001287

[epoch: 166/1000, batch:   500/ 1052, ite: 43520] train loss: 0.006314, tar: 0.000489 
l0: 0.000814, l1: 0.000849, l2: 0.000836, l3: 0.000811, l4: 0.000964, l5: 0.001472, l6: 0.003031

[epoch: 166/1000, batch:   580/ 1052, ite: 43540] train loss: 0.006305, tar: 0.000488 
l0: 0.000554, l1: 0.000572, l2: 0.000577, l3: 0.000673, l4: 0.001032, l5: 0.002290, l6: 0.004303

[epoch: 166/1000, batch:   660/ 1052, ite: 43560] train loss: 0.006322, tar: 0.000489 
l0: 0.000305, l1: 0.000300, l2: 0.000308, l3: 0.000399, l4: 0.000646, l5: 0.000930, l6: 0.001596

[epoch: 166/1000, batch:   740/ 1052, ite: 43580] train loss: 0.006311, tar: 0.000488 
l0: 0.000497, l1: 0.000456, l2: 0.000553, l3: 0.000761, l4: 0.001026, l5: 0.001680, l6: 0.002520

[epoch: 166/1000, batch:   820/ 1052, ite: 43600] train loss: 0.006303, tar: 0.000487 
l0: 0.001201, l1: 0.001266, l2: 0.001167, l3: 0.001163, l4: 0.001102, l5: 0.002101, l6: 0.003190

[epoch: 166/1000, batch:   900/ 1052, ite: 43620] train loss: 0.006297, tar: 0.000487 
l0: 0.000605, l1: 0.000660, l2: 0.000652, l3: 0.000672, l4: 0.000923, l5: 0.001473, l6: 0.003324

[epoch: 166/1000, batch:   980/ 1052, ite: 43640] train loss: 0.006297, tar: 0.000487 
[Epoch 166/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000260, l1: 0.000270, l2: 0.000268, l3: 0.000312, l4: 0.000502, l5: 0.001010, l6: 0.001595

[epoch: 167/1000, batch:     8/ 1052, ite: 43660] train loss: 0.006299, tar: 0.000487 
l0: 0.000336, l1: 0.000349, l2: 0.000357, l3: 0.000461, l4: 0.000767, l5: 0.001299, l6: 0.001560

[epoch: 167/1000, batch:    88/ 1052, ite: 43680] train loss: 0.006301, tar: 0.000487 
l0: 0.000466, l1: 0.000482, l2: 0.000445, l3: 0.000465, l4: 0.000734, l5: 0.000945, l6: 0.001783

[epoch: 167/1000, batch:   168/ 1052, ite: 43700] train loss: 0.006298, tar: 0.000487 
l0: 0.001101, l1: 0.001223, l2: 0.001190, l3: 0.001110, l4: 0.001054, l5: 0.001512, l6: 0.001734

[epoch: 167/1000, batch:   248/ 1052, ite: 43720] train loss: 0.006293, tar: 0.000486 
l0: 0.000499, l1: 0.000516, l2: 0.000527, l3: 0.000620, l4: 0.000819, l5: 0.001615, l6: 0.003312

[epoch: 167/1000, batch:   328/ 1052, ite: 43740] train loss: 0.006296, tar: 0.000486 
l0: 0.000481, l1: 0.000458, l2: 0.000504, l3: 0.000624, l4: 0.000845, l5: 0.001093, l6: 0.001859

[epoch: 167/1000, batch:   408/ 1052, ite: 43760] train loss: 0.006290, tar: 0.000486 
l0: 0.000454, l1: 0.000424, l2: 0.000487, l3: 0.000654, l4: 0.000885, l5: 0.001663, l6: 0.002324

[epoch: 167/1000, batch:   488/ 1052, ite: 43780] train loss: 0.006292, tar: 0.000485 
l0: 0.000698, l1: 0.000685, l2: 0.000754, l3: 0.000941, l4: 0.001311, l5: 0.001444, l6: 0.002643

[epoch: 167/1000, batch:   568/ 1052, ite: 43800] train loss: 0.006293, tar: 0.000486 
l0: 0.000272, l1: 0.000255, l2: 0.000298, l3: 0.000380, l4: 0.000536, l5: 0.001087, l6: 0.001602

[epoch: 167/1000, batch:   648/ 1052, ite: 43820] train loss: 0.006289, tar: 0.000485 
l0: 0.000414, l1: 0.000449, l2: 0.000439, l3: 0.000383, l4: 0.000454, l5: 0.001209, l6: 0.001031

[epoch: 167/1000, batch:   728/ 1052, ite: 43840] train loss: 0.006282, tar: 0.000485 
l0: 0.000907, l1: 0.001007, l2: 0.000929, l3: 0.000876, l4: 0.001386, l5: 0.002214, l6: 0.002996

[epoch: 167/1000, batch:   808/ 1052, ite: 43860] train loss: 0.006281, tar: 0.000485 
l0: 0.000276, l1: 0.000271, l2: 0.000310, l3: 0.000339, l4: 0.000593, l5: 0.001082, l6: 0.001573

[epoch: 167/1000, batch:   888/ 1052, ite: 43880] train loss: 0.006281, tar: 0.000484 
l0: 0.000523, l1: 0.000561, l2: 0.000515, l3: 0.000557, l4: 0.000945, l5: 0.001400, l6: 0.003867

[epoch: 167/1000, batch:   968/ 1052, ite: 43900] train loss: 0.006276, tar: 0.000484 
l0: 0.000701, l1: 0.000693, l2: 0.000813, l3: 0.001071, l4: 0.001600, l5: 0.002569, l6: 0.003538

[epoch: 167/1000, batch:  1048/ 1052, ite: 43920] train loss: 0.006277, tar: 0.000484 
[Epoch 167/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000661, l1: 0.000674, l2: 0.000716, l3: 0.000681, l4: 0.000858, l5: 0.001774, l6: 0.002372

[epoch: 168/1000, batch:    76/ 1052, ite: 43940] train loss: 0.006273, tar: 0.000484 
l0: 0.000287, l1: 0.000301, l2: 0.000296, l3: 0.000318, l4: 0.000400, l5: 0.000792, l6: 0.001338

[epoch: 168/1000, batch:   156/ 1052, ite: 43960] train loss: 0.006264, tar: 0.000483 
l0: 0.000314, l1: 0.000318, l2: 0.000337, l3: 0.000380, l4: 0.000549, l5: 0.000878, l6: 0.001962

[epoch: 168/1000, batch:   236/ 1052, ite: 43980] train loss: 0.006268, tar: 0.000483 
l0: 0.000403, l1: 0.000395, l2: 0.000453, l3: 0.000589, l4: 0.000861, l5: 0.001227, l6: 0.001572

[epoch: 168/1000, batch:   316/ 1052, ite: 44000] train loss: 0.006268, tar: 0.000482 
l0: 0.000240, l1: 0.000239, l2: 0.000269, l3: 0.000315, l4: 0.000385, l5: 0.001019, l6: 0.001424

[epoch: 168/1000, batch:   396/ 1052, ite: 44020] train loss: 0.006256, tar: 0.000481 
l0: 0.000925, l1: 0.001000, l2: 0.001086, l3: 0.000923, l4: 0.001070, l5: 0.001500, l6: 0.002449

[epoch: 168/1000, batch:   476/ 1052, ite: 44040] train loss: 0.006260, tar: 0.000482 
l0: 0.000719, l1: 0.000697, l2: 0.000727, l3: 0.000831, l4: 0.001151, l5: 0.001706, l6: 0.003299

[epoch: 168/1000, batch:   556/ 1052, ite: 44060] train loss: 0.006255, tar: 0.000481 
l0: 0.000649, l1: 0.000684, l2: 0.000643, l3: 0.000690, l4: 0.000907, l5: 0.001560, l6: 0.002800

[epoch: 168/1000, batch:   636/ 1052, ite: 44080] train loss: 0.006253, tar: 0.000481 
l0: 0.000616, l1: 0.000666, l2: 0.000623, l3: 0.000585, l4: 0.000779, l5: 0.001280, l6: 0.002308

[epoch: 168/1000, batch:   716/ 1052, ite: 44100] train loss: 0.006264, tar: 0.000482 
l0: 0.000241, l1: 0.000240, l2: 0.000310, l3: 0.000363, l4: 0.000672, l5: 0.000839, l6: 0.001500

[epoch: 168/1000, batch:   796/ 1052, ite: 44120] train loss: 0.006265, tar: 0.000482 
l0: 0.000418, l1: 0.000401, l2: 0.000464, l3: 0.000542, l4: 0.000690, l5: 0.001340, l6: 0.001796

[epoch: 168/1000, batch:   876/ 1052, ite: 44140] train loss: 0.006264, tar: 0.000482 
l0: 0.000286, l1: 0.000287, l2: 0.000289, l3: 0.000352, l4: 0.000472, l5: 0.000680, l6: 0.001463

[epoch: 168/1000, batch:   956/ 1052, ite: 44160] train loss: 0.006259, tar: 0.000482 
l0: 0.000191, l1: 0.000187, l2: 0.000227, l3: 0.000276, l4: 0.000426, l5: 0.000770, l6: 0.001103

[epoch: 168/1000, batch:  1036/ 1052, ite: 44180] train loss: 0.006254, tar: 0.000481 
[Epoch 168/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000398, l1: 0.000390, l2: 0.000427, l3: 0.000457, l4: 0.000595, l5: 0.001075, l6: 0.002368

[epoch: 169/1000, batch:    64/ 1052, ite: 44200] train loss: 0.006254, tar: 0.000481 
l0: 0.000501, l1: 0.000544, l2: 0.000553, l3: 0.000525, l4: 0.000700, l5: 0.001916, l6: 0.002660

[epoch: 169/1000, batch:   144/ 1052, ite: 44220] train loss: 0.006249, tar: 0.000480 
l0: 0.000881, l1: 0.000947, l2: 0.000926, l3: 0.000884, l4: 0.001136, l5: 0.003507, l6: 0.005542

[epoch: 169/1000, batch:   224/ 1052, ite: 44240] train loss: 0.006244, tar: 0.000479 
l0: 0.000324, l1: 0.000343, l2: 0.000329, l3: 0.000318, l4: 0.000493, l5: 0.000754, l6: 0.001079

[epoch: 169/1000, batch:   304/ 1052, ite: 44260] train loss: 0.006245, tar: 0.000479 
l0: 0.000283, l1: 0.000279, l2: 0.000292, l3: 0.000370, l4: 0.000587, l5: 0.001101, l6: 0.001555

[epoch: 169/1000, batch:   384/ 1052, ite: 44280] train loss: 0.006251, tar: 0.000480 
l0: 0.001121, l1: 0.001168, l2: 0.001191, l3: 0.001230, l4: 0.001147, l5: 0.002160, l6: 0.003938

[epoch: 169/1000, batch:   464/ 1052, ite: 44300] train loss: 0.006250, tar: 0.000480 
l0: 0.000183, l1: 0.000162, l2: 0.000212, l3: 0.000331, l4: 0.000378, l5: 0.000637, l6: 0.000853

[epoch: 169/1000, batch:   544/ 1052, ite: 44320] train loss: 0.006249, tar: 0.000480 
l0: 0.000525, l1: 0.000510, l2: 0.000561, l3: 0.000646, l4: 0.000767, l5: 0.000830, l6: 0.001795

[epoch: 169/1000, batch:   624/ 1052, ite: 44340] train loss: 0.006250, tar: 0.000480 
l0: 0.000458, l1: 0.000464, l2: 0.000563, l3: 0.000564, l4: 0.000932, l5: 0.001197, l6: 0.001940

[epoch: 169/1000, batch:   704/ 1052, ite: 44360] train loss: 0.006249, tar: 0.000480 
l0: 0.000311, l1: 0.000321, l2: 0.000326, l3: 0.000391, l4: 0.000501, l5: 0.001041, l6: 0.002156

[epoch: 169/1000, batch:   784/ 1052, ite: 44380] train loss: 0.006241, tar: 0.000479 
l0: 0.000395, l1: 0.000384, l2: 0.000478, l3: 0.000624, l4: 0.000843, l5: 0.001900, l6: 0.003630

[epoch: 169/1000, batch:   864/ 1052, ite: 44400] train loss: 0.006244, tar: 0.000479 
l0: 0.000209, l1: 0.000208, l2: 0.000224, l3: 0.000238, l4: 0.000369, l5: 0.000637, l6: 0.000908

[epoch: 169/1000, batch:   944/ 1052, ite: 44420] train loss: 0.006242, tar: 0.000479 
l0: 0.000228, l1: 0.000228, l2: 0.000239, l3: 0.000278, l4: 0.000371, l5: 0.000968, l6: 0.001428

[epoch: 169/1000, batch:  1024/ 1052, ite: 44440] train loss: 0.006236, tar: 0.000478 
[Epoch 169/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000481, l1: 0.000479, l2: 0.000518, l3: 0.000588, l4: 0.000640, l5: 0.000975, l6: 0.001428

[epoch: 170/1000, batch:    52/ 1052, ite: 44460] train loss: 0.006235, tar: 0.000478 
l0: 0.000401, l1: 0.000403, l2: 0.000435, l3: 0.000483, l4: 0.000720, l5: 0.001208, l6: 0.001763

[epoch: 170/1000, batch:   132/ 1052, ite: 44480] train loss: 0.006233, tar: 0.000478 
l0: 0.000586, l1: 0.000604, l2: 0.000666, l3: 0.000577, l4: 0.000767, l5: 0.002073, l6: 0.003111

[epoch: 170/1000, batch:   212/ 1052, ite: 44500] train loss: 0.006233, tar: 0.000478 
l0: 0.000431, l1: 0.000434, l2: 0.000454, l3: 0.000498, l4: 0.000856, l5: 0.001530, l6: 0.003055

[epoch: 170/1000, batch:   292/ 1052, ite: 44520] train loss: 0.006231, tar: 0.000477 
l0: 0.000438, l1: 0.000440, l2: 0.000503, l3: 0.000563, l4: 0.000729, l5: 0.001145, l6: 0.002936

[epoch: 170/1000, batch:   372/ 1052, ite: 44540] train loss: 0.006230, tar: 0.000477 
l0: 0.000392, l1: 0.000398, l2: 0.000409, l3: 0.000468, l4: 0.000640, l5: 0.001418, l6: 0.002390

[epoch: 170/1000, batch:   452/ 1052, ite: 44560] train loss: 0.006226, tar: 0.000477 
l0: 0.000298, l1: 0.000298, l2: 0.000338, l3: 0.000313, l4: 0.000452, l5: 0.000689, l6: 0.001409

[epoch: 170/1000, batch:   532/ 1052, ite: 44580] train loss: 0.006218, tar: 0.000476 
l0: 0.000409, l1: 0.000393, l2: 0.000468, l3: 0.000520, l4: 0.000556, l5: 0.001020, l6: 0.000902

[epoch: 170/1000, batch:   612/ 1052, ite: 44600] train loss: 0.006219, tar: 0.000477 
l0: 0.000383, l1: 0.000363, l2: 0.000384, l3: 0.000480, l4: 0.000663, l5: 0.000956, l6: 0.001388

[epoch: 170/1000, batch:   692/ 1052, ite: 44620] train loss: 0.006217, tar: 0.000476 
l0: 0.000298, l1: 0.000296, l2: 0.000310, l3: 0.000357, l4: 0.000597, l5: 0.001354, l6: 0.002108

[epoch: 170/1000, batch:   772/ 1052, ite: 44640] train loss: 0.006216, tar: 0.000477 
l0: 0.000376, l1: 0.000385, l2: 0.000385, l3: 0.000470, l4: 0.000678, l5: 0.001138, l6: 0.001853

[epoch: 170/1000, batch:   852/ 1052, ite: 44660] train loss: 0.006220, tar: 0.000477 
l0: 0.000257, l1: 0.000260, l2: 0.000276, l3: 0.000304, l4: 0.000411, l5: 0.000795, l6: 0.001223

[epoch: 170/1000, batch:   932/ 1052, ite: 44680] train loss: 0.006218, tar: 0.000477 
l0: 0.000585, l1: 0.000585, l2: 0.000615, l3: 0.000765, l4: 0.001189, l5: 0.001853, l6: 0.003546

[epoch: 170/1000, batch:  1012/ 1052, ite: 44700] train loss: 0.006216, tar: 0.000476 
[Epoch 170/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000681, l1: 0.000719, l2: 0.000629, l3: 0.000650, l4: 0.000901, l5: 0.001206, l6: 0.002279

[epoch: 171/1000, batch:    40/ 1052, ite: 44720] train loss: 0.006209, tar: 0.000476 
l0: 0.000768, l1: 0.000765, l2: 0.000819, l3: 0.000983, l4: 0.001569, l5: 0.002655, l6: 0.004325

[epoch: 171/1000, batch:   120/ 1052, ite: 44740] train loss: 0.006208, tar: 0.000475 
l0: 0.000340, l1: 0.000328, l2: 0.000364, l3: 0.000455, l4: 0.000600, l5: 0.001296, l6: 0.002037

[epoch: 171/1000, batch:   200/ 1052, ite: 44760] train loss: 0.006208, tar: 0.000475 
l0: 0.000604, l1: 0.000618, l2: 0.000633, l3: 0.000654, l4: 0.000886, l5: 0.001473, l6: 0.001943

[epoch: 171/1000, batch:   280/ 1052, ite: 44780] train loss: 0.006207, tar: 0.000475 
l0: 0.000304, l1: 0.000324, l2: 0.000294, l3: 0.000325, l4: 0.000471, l5: 0.000925, l6: 0.001926

[epoch: 171/1000, batch:   360/ 1052, ite: 44800] train loss: 0.006204, tar: 0.000475 
l0: 0.000220, l1: 0.000217, l2: 0.000233, l3: 0.000281, l4: 0.000432, l5: 0.000787, l6: 0.001455

[epoch: 171/1000, batch:   440/ 1052, ite: 44820] train loss: 0.006201, tar: 0.000474 
l0: 0.000302, l1: 0.000290, l2: 0.000341, l3: 0.000369, l4: 0.000498, l5: 0.000955, l6: 0.001799

[epoch: 171/1000, batch:   520/ 1052, ite: 44840] train loss: 0.006199, tar: 0.000474 
l0: 0.000355, l1: 0.000362, l2: 0.000368, l3: 0.000389, l4: 0.000489, l5: 0.000941, l6: 0.001798

[epoch: 171/1000, batch:   600/ 1052, ite: 44860] train loss: 0.006202, tar: 0.000474 
l0: 0.000529, l1: 0.000537, l2: 0.000544, l3: 0.000672, l4: 0.000841, l5: 0.001448, l6: 0.001744

[epoch: 171/1000, batch:   680/ 1052, ite: 44880] train loss: 0.006198, tar: 0.000474 
l0: 0.000446, l1: 0.000476, l2: 0.000448, l3: 0.000504, l4: 0.000746, l5: 0.000805, l6: 0.002163

[epoch: 171/1000, batch:   760/ 1052, ite: 44900] train loss: 0.006195, tar: 0.000474 
l0: 0.000520, l1: 0.000534, l2: 0.000606, l3: 0.000745, l4: 0.001090, l5: 0.001461, l6: 0.002291

[epoch: 171/1000, batch:   840/ 1052, ite: 44920] train loss: 0.006204, tar: 0.000474 
l0: 0.000455, l1: 0.000453, l2: 0.000477, l3: 0.000531, l4: 0.000655, l5: 0.001090, l6: 0.001634

[epoch: 171/1000, batch:   920/ 1052, ite: 44940] train loss: 0.006194, tar: 0.000474 
l0: 0.000328, l1: 0.000349, l2: 0.000363, l3: 0.000383, l4: 0.000613, l5: 0.000990, l6: 0.001142

[epoch: 171/1000, batch:  1000/ 1052, ite: 44960] train loss: 0.006192, tar: 0.000473 
[Epoch 171/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000193, l1: 0.000182, l2: 0.000222, l3: 0.000305, l4: 0.000456, l5: 0.000611, l6: 0.000957

[epoch: 172/1000, batch:    28/ 1052, ite: 44980] train loss: 0.006183, tar: 0.000473 
l0: 0.000416, l1: 0.000418, l2: 0.000459, l3: 0.000583, l4: 0.000970, l5: 0.001623, l6: 0.002307

[epoch: 172/1000, batch:   108/ 1052, ite: 45000] train loss: 0.006185, tar: 0.000473 
l0: 0.000362, l1: 0.000361, l2: 0.000361, l3: 0.000436, l4: 0.000657, l5: 0.001210, l6: 0.001567

[epoch: 172/1000, batch:   188/ 1052, ite: 45020] train loss: 0.006181, tar: 0.000472 
l0: 0.000324, l1: 0.000336, l2: 0.000338, l3: 0.000355, l4: 0.000467, l5: 0.001108, l6: 0.002309

[epoch: 172/1000, batch:   268/ 1052, ite: 45040] train loss: 0.006174, tar: 0.000472 
l0: 0.000581, l1: 0.000563, l2: 0.000656, l3: 0.000767, l4: 0.001099, l5: 0.001891, l6: 0.003275

[epoch: 172/1000, batch:   348/ 1052, ite: 45060] train loss: 0.006176, tar: 0.000472 
l0: 0.000884, l1: 0.000936, l2: 0.001002, l3: 0.001092, l4: 0.001516, l5: 0.002283, l6: 0.004634

[epoch: 172/1000, batch:   428/ 1052, ite: 45080] train loss: 0.006172, tar: 0.000471 
l0: 0.000621, l1: 0.000582, l2: 0.000649, l3: 0.000672, l4: 0.001040, l5: 0.001752, l6: 0.002589

[epoch: 172/1000, batch:   508/ 1052, ite: 45100] train loss: 0.006169, tar: 0.000471 
l0: 0.000701, l1: 0.000708, l2: 0.000715, l3: 0.000802, l4: 0.001085, l5: 0.001403, l6: 0.002461

[epoch: 172/1000, batch:   588/ 1052, ite: 45120] train loss: 0.006162, tar: 0.000470 
l0: 0.001356, l1: 0.001849, l2: 0.001965, l3: 0.000795, l4: 0.001108, l5: 0.002304, l6: 0.002851

[epoch: 172/1000, batch:   668/ 1052, ite: 45140] train loss: 0.006181, tar: 0.000474 
l0: 0.000853, l1: 0.000879, l2: 0.000912, l3: 0.000958, l4: 0.001011, l5: 0.001874, l6: 0.003795

[epoch: 172/1000, batch:   748/ 1052, ite: 45160] train loss: 0.006187, tar: 0.000474 
l0: 0.000566, l1: 0.000577, l2: 0.000613, l3: 0.000673, l4: 0.000859, l5: 0.001530, l6: 0.002550

[epoch: 172/1000, batch:   828/ 1052, ite: 45180] train loss: 0.006190, tar: 0.000475 
l0: 0.000504, l1: 0.000497, l2: 0.000629, l3: 0.000658, l4: 0.000819, l5: 0.001389, l6: 0.002268

[epoch: 172/1000, batch:   908/ 1052, ite: 45200] train loss: 0.006192, tar: 0.000475 
l0: 0.000334, l1: 0.000335, l2: 0.000405, l3: 0.000488, l4: 0.000599, l5: 0.001307, l6: 0.001692

[epoch: 172/1000, batch:   988/ 1052, ite: 45220] train loss: 0.006194, tar: 0.000475 
[Epoch 172/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000389, l1: 0.000422, l2: 0.000488, l3: 0.000443, l4: 0.000688, l5: 0.001297, l6: 0.001572

[epoch: 173/1000, batch:    16/ 1052, ite: 45240] train loss: 0.006195, tar: 0.000475 
l0: 0.000302, l1: 0.000307, l2: 0.000329, l3: 0.000387, l4: 0.000463, l5: 0.001170, l6: 0.001626

[epoch: 173/1000, batch:    96/ 1052, ite: 45260] train loss: 0.006194, tar: 0.000475 
l0: 0.000402, l1: 0.000415, l2: 0.000430, l3: 0.000476, l4: 0.000734, l5: 0.001207, l6: 0.002355

[epoch: 173/1000, batch:   176/ 1052, ite: 45280] train loss: 0.006194, tar: 0.000475 
l0: 0.000433, l1: 0.000448, l2: 0.000397, l3: 0.000476, l4: 0.000755, l5: 0.001588, l6: 0.002927

[epoch: 173/1000, batch:   256/ 1052, ite: 45300] train loss: 0.006190, tar: 0.000474 
l0: 0.000280, l1: 0.000275, l2: 0.000260, l3: 0.000398, l4: 0.000608, l5: 0.000813, l6: 0.001565

[epoch: 173/1000, batch:   336/ 1052, ite: 45320] train loss: 0.006190, tar: 0.000474 
l0: 0.000278, l1: 0.000274, l2: 0.000276, l3: 0.000347, l4: 0.000537, l5: 0.000861, l6: 0.001577

[epoch: 173/1000, batch:   416/ 1052, ite: 45340] train loss: 0.006193, tar: 0.000474 
l0: 0.000454, l1: 0.000449, l2: 0.000465, l3: 0.000551, l4: 0.000840, l5: 0.001564, l6: 0.002659

[epoch: 173/1000, batch:   496/ 1052, ite: 45360] train loss: 0.006196, tar: 0.000475 
l0: 0.000360, l1: 0.000380, l2: 0.000410, l3: 0.000409, l4: 0.000719, l5: 0.001211, l6: 0.002002

[epoch: 173/1000, batch:   576/ 1052, ite: 45380] train loss: 0.006196, tar: 0.000475 
l0: 0.000260, l1: 0.000255, l2: 0.000266, l3: 0.000257, l4: 0.000435, l5: 0.000875, l6: 0.001161

[epoch: 173/1000, batch:   656/ 1052, ite: 45400] train loss: 0.006193, tar: 0.000475 
l0: 0.000691, l1: 0.000710, l2: 0.000750, l3: 0.000711, l4: 0.001048, l5: 0.001992, l6: 0.003690

[epoch: 173/1000, batch:   736/ 1052, ite: 45420] train loss: 0.006188, tar: 0.000474 
l0: 0.000584, l1: 0.000613, l2: 0.000618, l3: 0.000627, l4: 0.000763, l5: 0.001496, l6: 0.003286

[epoch: 173/1000, batch:   816/ 1052, ite: 45440] train loss: 0.006188, tar: 0.000474 
l0: 0.000336, l1: 0.000331, l2: 0.000343, l3: 0.000413, l4: 0.000554, l5: 0.000696, l6: 0.001843

[epoch: 173/1000, batch:   896/ 1052, ite: 45460] train loss: 0.006193, tar: 0.000475 
l0: 0.000329, l1: 0.000323, l2: 0.000326, l3: 0.000451, l4: 0.000720, l5: 0.000882, l6: 0.002191

[epoch: 173/1000, batch:   976/ 1052, ite: 45480] train loss: 0.006193, tar: 0.000474 
[Epoch 173/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000537, l1: 0.000548, l2: 0.000557, l3: 0.000523, l4: 0.000897, l5: 0.000790, l6: 0.001967

[epoch: 174/1000, batch:     4/ 1052, ite: 45500] train loss: 0.006192, tar: 0.000475 
l0: 0.000727, l1: 0.000765, l2: 0.000681, l3: 0.000725, l4: 0.001338, l5: 0.001599, l6: 0.002654

[epoch: 174/1000, batch:    84/ 1052, ite: 45520] train loss: 0.006195, tar: 0.000475 
l0: 0.000405, l1: 0.000444, l2: 0.000434, l3: 0.000410, l4: 0.000497, l5: 0.000907, l6: 0.001764

[epoch: 174/1000, batch:   164/ 1052, ite: 45540] train loss: 0.006194, tar: 0.000475 
l0: 0.000775, l1: 0.000753, l2: 0.000805, l3: 0.000910, l4: 0.001039, l5: 0.001335, l6: 0.002014

[epoch: 174/1000, batch:   244/ 1052, ite: 45560] train loss: 0.006192, tar: 0.000474 
l0: 0.000460, l1: 0.000501, l2: 0.000497, l3: 0.000540, l4: 0.000656, l5: 0.001459, l6: 0.001425

[epoch: 174/1000, batch:   324/ 1052, ite: 45580] train loss: 0.006189, tar: 0.000474 
l0: 0.000173, l1: 0.000180, l2: 0.000169, l3: 0.000240, l4: 0.000410, l5: 0.000866, l6: 0.001062

[epoch: 174/1000, batch:   404/ 1052, ite: 45600] train loss: 0.006193, tar: 0.000475 
l0: 0.000252, l1: 0.000247, l2: 0.000253, l3: 0.000349, l4: 0.000498, l5: 0.001245, l6: 0.000959

[epoch: 174/1000, batch:   484/ 1052, ite: 45620] train loss: 0.006192, tar: 0.000474 
l0: 0.000415, l1: 0.000411, l2: 0.000424, l3: 0.000539, l4: 0.000625, l5: 0.001124, l6: 0.001700

[epoch: 174/1000, batch:   564/ 1052, ite: 45640] train loss: 0.006196, tar: 0.000475 
l0: 0.000305, l1: 0.000297, l2: 0.000322, l3: 0.000438, l4: 0.000619, l5: 0.001455, l6: 0.001739

[epoch: 174/1000, batch:   644/ 1052, ite: 45660] train loss: 0.006200, tar: 0.000475 
l0: 0.000427, l1: 0.000420, l2: 0.000447, l3: 0.000577, l4: 0.000895, l5: 0.001234, l6: 0.002331

[epoch: 174/1000, batch:   724/ 1052, ite: 45680] train loss: 0.006202, tar: 0.000475 
l0: 0.000220, l1: 0.000249, l2: 0.000210, l3: 0.000282, l4: 0.000480, l5: 0.000782, l6: 0.001364

[epoch: 174/1000, batch:   804/ 1052, ite: 45700] train loss: 0.006203, tar: 0.000475 
l0: 0.000428, l1: 0.000437, l2: 0.000470, l3: 0.000533, l4: 0.000692, l5: 0.001227, l6: 0.002062

[epoch: 174/1000, batch:   884/ 1052, ite: 45720] train loss: 0.006197, tar: 0.000475 
l0: 0.000651, l1: 0.000609, l2: 0.000700, l3: 0.000971, l4: 0.001529, l5: 0.002549, l6: 0.003660

[epoch: 174/1000, batch:   964/ 1052, ite: 45740] train loss: 0.006194, tar: 0.000475 
l0: 0.000468, l1: 0.000485, l2: 0.000483, l3: 0.000508, l4: 0.000857, l5: 0.001596, l6: 0.002367

[epoch: 174/1000, batch:  1044/ 1052, ite: 45760] train loss: 0.006191, tar: 0.000474 
[Epoch 174/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000383, l1: 0.000383, l2: 0.000407, l3: 0.000487, l4: 0.000535, l5: 0.001195, l6: 0.001733

[epoch: 175/1000, batch:    72/ 1052, ite: 45780] train loss: 0.006190, tar: 0.000474 
l0: 0.000704, l1: 0.000716, l2: 0.000771, l3: 0.000772, l4: 0.001070, l5: 0.002150, l6: 0.002544

[epoch: 175/1000, batch:   152/ 1052, ite: 45800] train loss: 0.006196, tar: 0.000474 
l0: 0.000789, l1: 0.000780, l2: 0.000776, l3: 0.000875, l4: 0.001271, l5: 0.001867, l6: 0.003549

[epoch: 175/1000, batch:   232/ 1052, ite: 45820] train loss: 0.006198, tar: 0.000474 
l0: 0.000507, l1: 0.000484, l2: 0.000526, l3: 0.000732, l4: 0.001080, l5: 0.001472, l6: 0.002195

[epoch: 175/1000, batch:   312/ 1052, ite: 45840] train loss: 0.006197, tar: 0.000474 
l0: 0.000615, l1: 0.000589, l2: 0.000668, l3: 0.000821, l4: 0.000773, l5: 0.001225, l6: 0.001669

[epoch: 175/1000, batch:   392/ 1052, ite: 45860] train loss: 0.006205, tar: 0.000475 
l0: 0.000393, l1: 0.000430, l2: 0.000370, l3: 0.000394, l4: 0.000642, l5: 0.000785, l6: 0.001074

[epoch: 175/1000, batch:   472/ 1052, ite: 45880] train loss: 0.006210, tar: 0.000476 
l0: 0.000385, l1: 0.000368, l2: 0.000415, l3: 0.000483, l4: 0.000592, l5: 0.001558, l6: 0.001794

[epoch: 175/1000, batch:   552/ 1052, ite: 45900] train loss: 0.006215, tar: 0.000477 
l0: 0.000360, l1: 0.000355, l2: 0.000385, l3: 0.000407, l4: 0.000550, l5: 0.001043, l6: 0.001824

[epoch: 175/1000, batch:   632/ 1052, ite: 45920] train loss: 0.006215, tar: 0.000477 
l0: 0.000924, l1: 0.000849, l2: 0.001009, l3: 0.001269, l4: 0.001469, l5: 0.002326, l6: 0.003071

[epoch: 175/1000, batch:   712/ 1052, ite: 45940] train loss: 0.006216, tar: 0.000477 
l0: 0.000492, l1: 0.000492, l2: 0.000511, l3: 0.000612, l4: 0.001141, l5: 0.001726, l6: 0.002227

[epoch: 175/1000, batch:   792/ 1052, ite: 45960] train loss: 0.006216, tar: 0.000477 
l0: 0.000888, l1: 0.000916, l2: 0.000865, l3: 0.001047, l4: 0.001416, l5: 0.002761, l6: 0.003107

[epoch: 175/1000, batch:   872/ 1052, ite: 45980] train loss: 0.006218, tar: 0.000477 
l0: 0.000347, l1: 0.000337, l2: 0.000396, l3: 0.000427, l4: 0.000598, l5: 0.001155, l6: 0.001965

[epoch: 175/1000, batch:   952/ 1052, ite: 46000] train loss: 0.006216, tar: 0.000477 
l0: 0.000474, l1: 0.000488, l2: 0.000476, l3: 0.000511, l4: 0.000703, l5: 0.001045, l6: 0.002282

[epoch: 175/1000, batch:  1032/ 1052, ite: 46020] train loss: 0.006214, tar: 0.000477 
[Epoch 175/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000437, l1: 0.000449, l2: 0.000481, l3: 0.000485, l4: 0.000510, l5: 0.001080, l6: 0.002283

[epoch: 176/1000, batch:    60/ 1052, ite: 46040] train loss: 0.006213, tar: 0.000477 
l0: 0.000969, l1: 0.001003, l2: 0.001146, l3: 0.001115, l4: 0.001475, l5: 0.002430, l6: 0.004837

[epoch: 176/1000, batch:   140/ 1052, ite: 46060] train loss: 0.006216, tar: 0.000477 
l0: 0.000235, l1: 0.000234, l2: 0.000225, l3: 0.000294, l4: 0.000541, l5: 0.000518, l6: 0.001291

[epoch: 176/1000, batch:   220/ 1052, ite: 46080] train loss: 0.006214, tar: 0.000476 
l0: 0.000151, l1: 0.000181, l2: 0.000171, l3: 0.000221, l4: 0.000247, l5: 0.000507, l6: 0.000634

[epoch: 176/1000, batch:   300/ 1052, ite: 46100] train loss: 0.006216, tar: 0.000477 
l0: 0.000193, l1: 0.000184, l2: 0.000234, l3: 0.000291, l4: 0.000480, l5: 0.000598, l6: 0.001331

[epoch: 176/1000, batch:   380/ 1052, ite: 46120] train loss: 0.006217, tar: 0.000477 
l0: 0.000532, l1: 0.000527, l2: 0.000602, l3: 0.000673, l4: 0.001008, l5: 0.001428, l6: 0.002242

[epoch: 176/1000, batch:   460/ 1052, ite: 46140] train loss: 0.006215, tar: 0.000477 
l0: 0.000592, l1: 0.000612, l2: 0.000643, l3: 0.000717, l4: 0.000923, l5: 0.001363, l6: 0.002263

[epoch: 176/1000, batch:   540/ 1052, ite: 46160] train loss: 0.006215, tar: 0.000477 
l0: 0.000393, l1: 0.000384, l2: 0.000474, l3: 0.000549, l4: 0.000676, l5: 0.001309, l6: 0.002248

[epoch: 176/1000, batch:   620/ 1052, ite: 46180] train loss: 0.006214, tar: 0.000476 
l0: 0.000417, l1: 0.000445, l2: 0.000430, l3: 0.000472, l4: 0.000450, l5: 0.000858, l6: 0.002055

[epoch: 176/1000, batch:   700/ 1052, ite: 46200] train loss: 0.006211, tar: 0.000476 
l0: 0.000347, l1: 0.000344, l2: 0.000401, l3: 0.000515, l4: 0.000736, l5: 0.001174, l6: 0.001787

[epoch: 176/1000, batch:   780/ 1052, ite: 46220] train loss: 0.006212, tar: 0.000476 
l0: 0.000439, l1: 0.000441, l2: 0.000484, l3: 0.000506, l4: 0.000768, l5: 0.001432, l6: 0.001790

[epoch: 176/1000, batch:   860/ 1052, ite: 46240] train loss: 0.006207, tar: 0.000476 
l0: 0.000477, l1: 0.000489, l2: 0.000450, l3: 0.000541, l4: 0.000660, l5: 0.000704, l6: 0.001445

[epoch: 176/1000, batch:   940/ 1052, ite: 46260] train loss: 0.006206, tar: 0.000475 
l0: 0.000224, l1: 0.000227, l2: 0.000256, l3: 0.000256, l4: 0.000407, l5: 0.001208, l6: 0.001692

[epoch: 176/1000, batch:  1020/ 1052, ite: 46280] train loss: 0.006203, tar: 0.000475 
[Epoch 176/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000273, l1: 0.000275, l2: 0.000299, l3: 0.000342, l4: 0.000414, l5: 0.000704, l6: 0.000993

[epoch: 177/1000, batch:    48/ 1052, ite: 46300] train loss: 0.006202, tar: 0.000475 
l0: 0.000317, l1: 0.000324, l2: 0.000329, l3: 0.000330, l4: 0.000599, l5: 0.000780, l6: 0.001017

[epoch: 177/1000, batch:   128/ 1052, ite: 46320] train loss: 0.006202, tar: 0.000475 
l0: 0.000394, l1: 0.000381, l2: 0.000424, l3: 0.000543, l4: 0.000626, l5: 0.001051, l6: 0.001871

[epoch: 177/1000, batch:   208/ 1052, ite: 46340] train loss: 0.006198, tar: 0.000474 
l0: 0.000644, l1: 0.000708, l2: 0.000738, l3: 0.000624, l4: 0.001053, l5: 0.001128, l6: 0.002233

[epoch: 177/1000, batch:   288/ 1052, ite: 46360] train loss: 0.006195, tar: 0.000474 
l0: 0.000226, l1: 0.000234, l2: 0.000246, l3: 0.000309, l4: 0.000560, l5: 0.000901, l6: 0.001565

[epoch: 177/1000, batch:   368/ 1052, ite: 46380] train loss: 0.006197, tar: 0.000474 
l0: 0.000271, l1: 0.000275, l2: 0.000253, l3: 0.000287, l4: 0.000358, l5: 0.000838, l6: 0.001445

[epoch: 177/1000, batch:   448/ 1052, ite: 46400] train loss: 0.006196, tar: 0.000474 
l0: 0.000551, l1: 0.000581, l2: 0.000637, l3: 0.000572, l4: 0.000826, l5: 0.001692, l6: 0.002561

[epoch: 177/1000, batch:   528/ 1052, ite: 46420] train loss: 0.006196, tar: 0.000474 
l0: 0.000270, l1: 0.000252, l2: 0.000306, l3: 0.000347, l4: 0.000559, l5: 0.001085, l6: 0.001818

[epoch: 177/1000, batch:   608/ 1052, ite: 46440] train loss: 0.006199, tar: 0.000474 
l0: 0.000158, l1: 0.000188, l2: 0.000165, l3: 0.000187, l4: 0.000393, l5: 0.000586, l6: 0.000910

[epoch: 177/1000, batch:   688/ 1052, ite: 46460] train loss: 0.006200, tar: 0.000474 
l0: 0.000305, l1: 0.000301, l2: 0.000311, l3: 0.000366, l4: 0.000662, l5: 0.001096, l6: 0.001671

[epoch: 177/1000, batch:   768/ 1052, ite: 46480] train loss: 0.006199, tar: 0.000474 
l0: 0.000292, l1: 0.000287, l2: 0.000309, l3: 0.000323, l4: 0.000419, l5: 0.000629, l6: 0.000878

[epoch: 177/1000, batch:   848/ 1052, ite: 46500] train loss: 0.006194, tar: 0.000474 
l0: 0.000295, l1: 0.000307, l2: 0.000345, l3: 0.000390, l4: 0.000618, l5: 0.000852, l6: 0.001718

[epoch: 177/1000, batch:   928/ 1052, ite: 46520] train loss: 0.006194, tar: 0.000474 
l0: 0.000180, l1: 0.000176, l2: 0.000194, l3: 0.000237, l4: 0.000362, l5: 0.000701, l6: 0.000988

[epoch: 177/1000, batch:  1008/ 1052, ite: 46540] train loss: 0.006191, tar: 0.000473 
[Epoch 177/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000471, l1: 0.000474, l2: 0.000443, l3: 0.000598, l4: 0.000725, l5: 0.001515, l6: 0.002679

[epoch: 178/1000, batch:    36/ 1052, ite: 46560] train loss: 0.006192, tar: 0.000474 
l0: 0.000509, l1: 0.000550, l2: 0.000539, l3: 0.000531, l4: 0.000824, l5: 0.001620, l6: 0.002574

[epoch: 178/1000, batch:   116/ 1052, ite: 46580] train loss: 0.006193, tar: 0.000474 
l0: 0.000597, l1: 0.000649, l2: 0.000652, l3: 0.000588, l4: 0.000930, l5: 0.001323, l6: 0.002527

[epoch: 178/1000, batch:   196/ 1052, ite: 46600] train loss: 0.006188, tar: 0.000473 
l0: 0.000442, l1: 0.000434, l2: 0.000494, l3: 0.000557, l4: 0.000804, l5: 0.001220, l6: 0.001865

[epoch: 178/1000, batch:   276/ 1052, ite: 46620] train loss: 0.006191, tar: 0.000473 
l0: 0.000291, l1: 0.000297, l2: 0.000305, l3: 0.000346, l4: 0.000645, l5: 0.001242, l6: 0.001418

[epoch: 178/1000, batch:   356/ 1052, ite: 46640] train loss: 0.006189, tar: 0.000473 
l0: 0.000412, l1: 0.000413, l2: 0.000418, l3: 0.000518, l4: 0.000749, l5: 0.001514, l6: 0.002584

[epoch: 178/1000, batch:   436/ 1052, ite: 46660] train loss: 0.006185, tar: 0.000473 
l0: 0.000304, l1: 0.000295, l2: 0.000323, l3: 0.000416, l4: 0.000570, l5: 0.001176, l6: 0.002257

[epoch: 178/1000, batch:   516/ 1052, ite: 46680] train loss: 0.006181, tar: 0.000472 
l0: 0.000161, l1: 0.000167, l2: 0.000175, l3: 0.000173, l4: 0.000272, l5: 0.000497, l6: 0.001176

[epoch: 178/1000, batch:   596/ 1052, ite: 46700] train loss: 0.006178, tar: 0.000472 
l0: 0.000416, l1: 0.000405, l2: 0.000426, l3: 0.000486, l4: 0.000596, l5: 0.001165, l6: 0.001669

[epoch: 178/1000, batch:   676/ 1052, ite: 46720] train loss: 0.006177, tar: 0.000472 
l0: 0.000251, l1: 0.000253, l2: 0.000245, l3: 0.000303, l4: 0.000407, l5: 0.000731, l6: 0.001394

[epoch: 178/1000, batch:   756/ 1052, ite: 46740] train loss: 0.006177, tar: 0.000472 
l0: 0.000347, l1: 0.000336, l2: 0.000368, l3: 0.000417, l4: 0.000633, l5: 0.001402, l6: 0.001733

[epoch: 178/1000, batch:   836/ 1052, ite: 46760] train loss: 0.006173, tar: 0.000471 
l0: 0.000456, l1: 0.000463, l2: 0.000467, l3: 0.000503, l4: 0.001047, l5: 0.001265, l6: 0.002340

[epoch: 178/1000, batch:   916/ 1052, ite: 46780] train loss: 0.006172, tar: 0.000471 
l0: 0.000502, l1: 0.000472, l2: 0.000541, l3: 0.000707, l4: 0.001192, l5: 0.001636, l6: 0.002972

[epoch: 178/1000, batch:   996/ 1052, ite: 46800] train loss: 0.006170, tar: 0.000471 
[Epoch 178/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000209, l1: 0.000220, l2: 0.000204, l3: 0.000266, l4: 0.000543, l5: 0.000809, l6: 0.001811

[epoch: 179/1000, batch:    24/ 1052, ite: 46820] train loss: 0.006173, tar: 0.000471 
l0: 0.000415, l1: 0.000419, l2: 0.000418, l3: 0.000440, l4: 0.000546, l5: 0.001140, l6: 0.001145

[epoch: 179/1000, batch:   104/ 1052, ite: 46840] train loss: 0.006169, tar: 0.000471 
l0: 0.000251, l1: 0.000253, l2: 0.000274, l3: 0.000330, l4: 0.000508, l5: 0.001007, l6: 0.001342

[epoch: 179/1000, batch:   184/ 1052, ite: 46860] train loss: 0.006171, tar: 0.000471 
l0: 0.000209, l1: 0.000210, l2: 0.000216, l3: 0.000280, l4: 0.000573, l5: 0.000893, l6: 0.001166

[epoch: 179/1000, batch:   264/ 1052, ite: 46880] train loss: 0.006169, tar: 0.000470 
l0: 0.000260, l1: 0.000262, l2: 0.000273, l3: 0.000272, l4: 0.000597, l5: 0.000813, l6: 0.001249

[epoch: 179/1000, batch:   344/ 1052, ite: 46900] train loss: 0.006165, tar: 0.000470 
l0: 0.000437, l1: 0.000448, l2: 0.000479, l3: 0.000480, l4: 0.000722, l5: 0.001739, l6: 0.002054

[epoch: 179/1000, batch:   424/ 1052, ite: 46920] train loss: 0.006165, tar: 0.000470 
l0: 0.000622, l1: 0.000639, l2: 0.000621, l3: 0.000629, l4: 0.000835, l5: 0.001522, l6: 0.002341

[epoch: 179/1000, batch:   504/ 1052, ite: 46940] train loss: 0.006165, tar: 0.000470 
l0: 0.000233, l1: 0.000236, l2: 0.000252, l3: 0.000322, l4: 0.000539, l5: 0.000861, l6: 0.001286

[epoch: 179/1000, batch:   584/ 1052, ite: 46960] train loss: 0.006165, tar: 0.000470 
l0: 0.000232, l1: 0.000239, l2: 0.000243, l3: 0.000293, l4: 0.000486, l5: 0.000868, l6: 0.001592

[epoch: 179/1000, batch:   664/ 1052, ite: 46980] train loss: 0.006161, tar: 0.000470 
l0: 0.000443, l1: 0.000459, l2: 0.000485, l3: 0.000595, l4: 0.000907, l5: 0.001694, l6: 0.002512

[epoch: 179/1000, batch:   744/ 1052, ite: 47000] train loss: 0.006158, tar: 0.000469 
l0: 0.000169, l1: 0.000166, l2: 0.000186, l3: 0.000246, l4: 0.000384, l5: 0.000702, l6: 0.001038

[epoch: 179/1000, batch:   824/ 1052, ite: 47020] train loss: 0.006160, tar: 0.000469 
l0: 0.000333, l1: 0.000334, l2: 0.000365, l3: 0.000420, l4: 0.000844, l5: 0.001706, l6: 0.002326

[epoch: 179/1000, batch:   904/ 1052, ite: 47040] train loss: 0.006158, tar: 0.000469 
l0: 0.000338, l1: 0.000324, l2: 0.000324, l3: 0.000425, l4: 0.000584, l5: 0.000889, l6: 0.001596

[epoch: 179/1000, batch:   984/ 1052, ite: 47060] train loss: 0.006159, tar: 0.000469 
[Epoch 179/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000417, l1: 0.000421, l2: 0.000487, l3: 0.000493, l4: 0.000628, l5: 0.001026, l6: 0.001540

[epoch: 180/1000, batch:    12/ 1052, ite: 47080] train loss: 0.006161, tar: 0.000469 
l0: 0.000444, l1: 0.000448, l2: 0.000451, l3: 0.000526, l4: 0.000715, l5: 0.001266, l6: 0.002482

[epoch: 180/1000, batch:    92/ 1052, ite: 47100] train loss: 0.006157, tar: 0.000469 
l0: 0.000332, l1: 0.000348, l2: 0.000369, l3: 0.000338, l4: 0.000471, l5: 0.001023, l6: 0.001547

[epoch: 180/1000, batch:   172/ 1052, ite: 47120] train loss: 0.006161, tar: 0.000469 
l0: 0.000391, l1: 0.000397, l2: 0.000396, l3: 0.000474, l4: 0.000615, l5: 0.001157, l6: 0.001930

[epoch: 180/1000, batch:   252/ 1052, ite: 47140] train loss: 0.006160, tar: 0.000469 
l0: 0.000243, l1: 0.000239, l2: 0.000266, l3: 0.000322, l4: 0.000486, l5: 0.000839, l6: 0.001072

[epoch: 180/1000, batch:   332/ 1052, ite: 47160] train loss: 0.006155, tar: 0.000469 
l0: 0.000280, l1: 0.000281, l2: 0.000323, l3: 0.000421, l4: 0.000693, l5: 0.001009, l6: 0.001782

[epoch: 180/1000, batch:   412/ 1052, ite: 47180] train loss: 0.006154, tar: 0.000469 
l0: 0.000197, l1: 0.000206, l2: 0.000213, l3: 0.000236, l4: 0.000358, l5: 0.000458, l6: 0.001292

[epoch: 180/1000, batch:   492/ 1052, ite: 47200] train loss: 0.006152, tar: 0.000468 
l0: 0.000340, l1: 0.000327, l2: 0.000419, l3: 0.000578, l4: 0.000893, l5: 0.001930, l6: 0.002640

[epoch: 180/1000, batch:   572/ 1052, ite: 47220] train loss: 0.006155, tar: 0.000468 
l0: 0.000394, l1: 0.000377, l2: 0.000383, l3: 0.000578, l4: 0.000829, l5: 0.001071, l6: 0.001546

[epoch: 180/1000, batch:   652/ 1052, ite: 47240] train loss: 0.006154, tar: 0.000468 
l0: 0.000443, l1: 0.000453, l2: 0.000529, l3: 0.000536, l4: 0.000918, l5: 0.001368, l6: 0.003040

[epoch: 180/1000, batch:   732/ 1052, ite: 47260] train loss: 0.006152, tar: 0.000468 
l0: 0.000849, l1: 0.000836, l2: 0.000820, l3: 0.000909, l4: 0.001218, l5: 0.001849, l6: 0.003706

[epoch: 180/1000, batch:   812/ 1052, ite: 47280] train loss: 0.006149, tar: 0.000467 
l0: 0.000251, l1: 0.000256, l2: 0.000277, l3: 0.000289, l4: 0.000284, l5: 0.000697, l6: 0.001314

[epoch: 180/1000, batch:   892/ 1052, ite: 47300] train loss: 0.006149, tar: 0.000467 
l0: 0.000731, l1: 0.000758, l2: 0.000735, l3: 0.000836, l4: 0.000768, l5: 0.001151, l6: 0.002052

[epoch: 180/1000, batch:   972/ 1052, ite: 47320] train loss: 0.006146, tar: 0.000467 
l0: 0.000299, l1: 0.000302, l2: 0.000297, l3: 0.000336, l4: 0.000525, l5: 0.000714, l6: 0.001566

[epoch: 180/1000, batch:  1052/ 1052, ite: 47340] train loss: 0.006147, tar: 0.000467 
[Epoch 180/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000429, l1: 0.000457, l2: 0.000427, l3: 0.000492, l4: 0.000605, l5: 0.001234, l6: 0.002355

[epoch: 181/1000, batch:    80/ 1052, ite: 47360] train loss: 0.006145, tar: 0.000467 
l0: 0.000533, l1: 0.000529, l2: 0.000525, l3: 0.000626, l4: 0.000755, l5: 0.001069, l6: 0.002003

[epoch: 181/1000, batch:   160/ 1052, ite: 47380] train loss: 0.006145, tar: 0.000467 
l0: 0.000284, l1: 0.000285, l2: 0.000310, l3: 0.000360, l4: 0.000418, l5: 0.001316, l6: 0.001614

[epoch: 181/1000, batch:   240/ 1052, ite: 47400] train loss: 0.006144, tar: 0.000467 
l0: 0.000273, l1: 0.000263, l2: 0.000283, l3: 0.000393, l4: 0.000813, l5: 0.001517, l6: 0.002213

[epoch: 181/1000, batch:   320/ 1052, ite: 47420] train loss: 0.006142, tar: 0.000466 
l0: 0.000668, l1: 0.000721, l2: 0.000707, l3: 0.000673, l4: 0.000970, l5: 0.001340, l6: 0.002215

[epoch: 181/1000, batch:   400/ 1052, ite: 47440] train loss: 0.006145, tar: 0.000467 
l0: 0.000643, l1: 0.000677, l2: 0.000747, l3: 0.000676, l4: 0.000781, l5: 0.001455, l6: 0.001531

[epoch: 181/1000, batch:   480/ 1052, ite: 47460] train loss: 0.006146, tar: 0.000467 
l0: 0.000646, l1: 0.000668, l2: 0.000595, l3: 0.000669, l4: 0.000835, l5: 0.001771, l6: 0.003077

[epoch: 181/1000, batch:   560/ 1052, ite: 47480] train loss: 0.006148, tar: 0.000467 
l0: 0.000403, l1: 0.000417, l2: 0.000436, l3: 0.000447, l4: 0.000610, l5: 0.001096, l6: 0.001655

[epoch: 181/1000, batch:   640/ 1052, ite: 47500] train loss: 0.006149, tar: 0.000467 
l0: 0.000557, l1: 0.000523, l2: 0.000550, l3: 0.000668, l4: 0.000856, l5: 0.001400, l6: 0.002303

[epoch: 181/1000, batch:   720/ 1052, ite: 47520] train loss: 0.006149, tar: 0.000467 
l0: 0.000342, l1: 0.000343, l2: 0.000372, l3: 0.000449, l4: 0.000711, l5: 0.000965, l6: 0.001458

[epoch: 181/1000, batch:   800/ 1052, ite: 47540] train loss: 0.006148, tar: 0.000467 
l0: 0.000404, l1: 0.000406, l2: 0.000421, l3: 0.000437, l4: 0.000725, l5: 0.001473, l6: 0.002135

[epoch: 181/1000, batch:   880/ 1052, ite: 47560] train loss: 0.006151, tar: 0.000467 
l0: 0.000456, l1: 0.000474, l2: 0.000496, l3: 0.000557, l4: 0.001013, l5: 0.001483, l6: 0.003307

[epoch: 181/1000, batch:   960/ 1052, ite: 47580] train loss: 0.006149, tar: 0.000467 
l0: 0.000359, l1: 0.000360, l2: 0.000367, l3: 0.000489, l4: 0.000734, l5: 0.001076, l6: 0.001908

[epoch: 181/1000, batch:  1040/ 1052, ite: 47600] train loss: 0.006147, tar: 0.000467 
[Epoch 181/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000441, l1: 0.000437, l2: 0.000482, l3: 0.000543, l4: 0.000691, l5: 0.001464, l6: 0.001840

[epoch: 182/1000, batch:    68/ 1052, ite: 47620] train loss: 0.006144, tar: 0.000466 
l0: 0.000643, l1: 0.000618, l2: 0.000619, l3: 0.000788, l4: 0.000846, l5: 0.001307, l6: 0.002029

[epoch: 182/1000, batch:   148/ 1052, ite: 47640] train loss: 0.006143, tar: 0.000466 
l0: 0.000948, l1: 0.000959, l2: 0.000968, l3: 0.000931, l4: 0.001024, l5: 0.001913, l6: 0.002477

[epoch: 182/1000, batch:   228/ 1052, ite: 47660] train loss: 0.006143, tar: 0.000466 
l0: 0.000504, l1: 0.000506, l2: 0.000534, l3: 0.000541, l4: 0.000693, l5: 0.001331, l6: 0.002161

[epoch: 182/1000, batch:   308/ 1052, ite: 47680] train loss: 0.006144, tar: 0.000466 
l0: 0.000289, l1: 0.000290, l2: 0.000303, l3: 0.000383, l4: 0.000441, l5: 0.000925, l6: 0.001603

[epoch: 182/1000, batch:   388/ 1052, ite: 47700] train loss: 0.006141, tar: 0.000466 
l0: 0.000360, l1: 0.000364, l2: 0.000340, l3: 0.000356, l4: 0.000385, l5: 0.000644, l6: 0.000623

[epoch: 182/1000, batch:   468/ 1052, ite: 47720] train loss: 0.006139, tar: 0.000466 
l0: 0.000354, l1: 0.000351, l2: 0.000350, l3: 0.000419, l4: 0.000574, l5: 0.001058, l6: 0.001538

[epoch: 182/1000, batch:   548/ 1052, ite: 47740] train loss: 0.006138, tar: 0.000466 
l0: 0.000878, l1: 0.000851, l2: 0.000875, l3: 0.001046, l4: 0.000802, l5: 0.001990, l6: 0.003616

[epoch: 182/1000, batch:   628/ 1052, ite: 47760] train loss: 0.006142, tar: 0.000466 
l0: 0.000278, l1: 0.000269, l2: 0.000337, l3: 0.000342, l4: 0.000525, l5: 0.000882, l6: 0.001262

[epoch: 182/1000, batch:   708/ 1052, ite: 47780] train loss: 0.006139, tar: 0.000466 
l0: 0.000222, l1: 0.000224, l2: 0.000235, l3: 0.000248, l4: 0.000337, l5: 0.000623, l6: 0.001401

[epoch: 182/1000, batch:   788/ 1052, ite: 47800] train loss: 0.006139, tar: 0.000466 
l0: 0.000456, l1: 0.000473, l2: 0.000452, l3: 0.000491, l4: 0.000535, l5: 0.000678, l6: 0.001461

[epoch: 182/1000, batch:   868/ 1052, ite: 47820] train loss: 0.006137, tar: 0.000466 
l0: 0.000549, l1: 0.000548, l2: 0.000546, l3: 0.000627, l4: 0.000801, l5: 0.001105, l6: 0.002598

[epoch: 182/1000, batch:   948/ 1052, ite: 47840] train loss: 0.006138, tar: 0.000465 
l0: 0.000626, l1: 0.000649, l2: 0.000717, l3: 0.000638, l4: 0.000839, l5: 0.001668, l6: 0.001564

[epoch: 182/1000, batch:  1028/ 1052, ite: 47860] train loss: 0.006136, tar: 0.000465 
[Epoch 182/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000241, l1: 0.000241, l2: 0.000269, l3: 0.000305, l4: 0.000637, l5: 0.001163, l6: 0.002285

[epoch: 183/1000, batch:    56/ 1052, ite: 47880] train loss: 0.006139, tar: 0.000466 
l0: 0.000282, l1: 0.000296, l2: 0.000293, l3: 0.000355, l4: 0.000669, l5: 0.001146, l6: 0.001824

[epoch: 183/1000, batch:   136/ 1052, ite: 47900] train loss: 0.006137, tar: 0.000465 
l0: 0.000390, l1: 0.000394, l2: 0.000387, l3: 0.000456, l4: 0.000692, l5: 0.001238, l6: 0.001478

[epoch: 183/1000, batch:   216/ 1052, ite: 47920] train loss: 0.006134, tar: 0.000465 
l0: 0.000219, l1: 0.000230, l2: 0.000241, l3: 0.000252, l4: 0.000405, l5: 0.000481, l6: 0.000891

[epoch: 183/1000, batch:   296/ 1052, ite: 47940] train loss: 0.006133, tar: 0.000465 
l0: 0.000842, l1: 0.000838, l2: 0.000851, l3: 0.000996, l4: 0.001684, l5: 0.004403, l6: 0.006352

[epoch: 183/1000, batch:   376/ 1052, ite: 47960] train loss: 0.006132, tar: 0.000465 
l0: 0.000389, l1: 0.000400, l2: 0.000404, l3: 0.000417, l4: 0.000645, l5: 0.001123, l6: 0.001484

[epoch: 183/1000, batch:   456/ 1052, ite: 47980] train loss: 0.006134, tar: 0.000465 
l0: 0.001375, l1: 0.001343, l2: 0.001380, l3: 0.001362, l4: 0.001728, l5: 0.003381, l6: 0.003539

[epoch: 183/1000, batch:   536/ 1052, ite: 48000] train loss: 0.006136, tar: 0.000465 
l0: 0.000226, l1: 0.000222, l2: 0.000235, l3: 0.000284, l4: 0.000425, l5: 0.001024, l6: 0.001409

[epoch: 183/1000, batch:   616/ 1052, ite: 48020] train loss: 0.006137, tar: 0.000465 
l0: 0.000699, l1: 0.000757, l2: 0.000818, l3: 0.000883, l4: 0.001137, l5: 0.002040, l6: 0.003270

[epoch: 183/1000, batch:   696/ 1052, ite: 48040] train loss: 0.006134, tar: 0.000465 
l0: 0.000281, l1: 0.000306, l2: 0.000362, l3: 0.000378, l4: 0.000643, l5: 0.001299, l6: 0.002105

[epoch: 183/1000, batch:   776/ 1052, ite: 48060] train loss: 0.006133, tar: 0.000465 
l0: 0.000306, l1: 0.000323, l2: 0.000342, l3: 0.000391, l4: 0.000578, l5: 0.001221, l6: 0.002644

[epoch: 183/1000, batch:   856/ 1052, ite: 48080] train loss: 0.006132, tar: 0.000465 
l0: 0.000455, l1: 0.000456, l2: 0.000491, l3: 0.000512, l4: 0.000674, l5: 0.001394, l6: 0.002059

[epoch: 183/1000, batch:   936/ 1052, ite: 48100] train loss: 0.006130, tar: 0.000464 
l0: 0.000385, l1: 0.000373, l2: 0.000437, l3: 0.000451, l4: 0.000552, l5: 0.001119, l6: 0.001897

[epoch: 183/1000, batch:  1016/ 1052, ite: 48120] train loss: 0.006131, tar: 0.000464 
[Epoch 183/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000460, l1: 0.000479, l2: 0.000467, l3: 0.000541, l4: 0.000834, l5: 0.001333, l6: 0.001682

[epoch: 184/1000, batch:    44/ 1052, ite: 48140] train loss: 0.006129, tar: 0.000464 
l0: 0.000372, l1: 0.000368, l2: 0.000412, l3: 0.000432, l4: 0.000614, l5: 0.000835, l6: 0.002082

[epoch: 184/1000, batch:   124/ 1052, ite: 48160] train loss: 0.006127, tar: 0.000464 
l0: 0.000291, l1: 0.000277, l2: 0.000307, l3: 0.000450, l4: 0.000682, l5: 0.001303, l6: 0.001848

[epoch: 184/1000, batch:   204/ 1052, ite: 48180] train loss: 0.006128, tar: 0.000464 
l0: 0.000320, l1: 0.000329, l2: 0.000340, l3: 0.000345, l4: 0.000497, l5: 0.001154, l6: 0.001646

[epoch: 184/1000, batch:   284/ 1052, ite: 48200] train loss: 0.006129, tar: 0.000464 
l0: 0.000303, l1: 0.000283, l2: 0.000336, l3: 0.000440, l4: 0.000694, l5: 0.001261, l6: 0.002056

[epoch: 184/1000, batch:   364/ 1052, ite: 48220] train loss: 0.006130, tar: 0.000464 
l0: 0.000506, l1: 0.000542, l2: 0.000525, l3: 0.000627, l4: 0.000876, l5: 0.001419, l6: 0.002241

[epoch: 184/1000, batch:   444/ 1052, ite: 48240] train loss: 0.006128, tar: 0.000464 
l0: 0.000264, l1: 0.000258, l2: 0.000293, l3: 0.000381, l4: 0.000469, l5: 0.001035, l6: 0.002072

[epoch: 184/1000, batch:   524/ 1052, ite: 48260] train loss: 0.006129, tar: 0.000464 
l0: 0.000564, l1: 0.000564, l2: 0.000630, l3: 0.000657, l4: 0.000877, l5: 0.001533, l6: 0.002238

[epoch: 184/1000, batch:   604/ 1052, ite: 48280] train loss: 0.006129, tar: 0.000464 
l0: 0.000582, l1: 0.000578, l2: 0.000617, l3: 0.000686, l4: 0.000969, l5: 0.001810, l6: 0.002527

[epoch: 184/1000, batch:   684/ 1052, ite: 48300] train loss: 0.006127, tar: 0.000464 
l0: 0.000476, l1: 0.000469, l2: 0.000502, l3: 0.000607, l4: 0.000859, l5: 0.001550, l6: 0.002127

[epoch: 184/1000, batch:   764/ 1052, ite: 48320] train loss: 0.006125, tar: 0.000463 
l0: 0.000365, l1: 0.000381, l2: 0.000369, l3: 0.000360, l4: 0.000599, l5: 0.000773, l6: 0.001912

[epoch: 184/1000, batch:   844/ 1052, ite: 48340] train loss: 0.006124, tar: 0.000463 
l0: 0.000170, l1: 0.000169, l2: 0.000204, l3: 0.000248, l4: 0.000393, l5: 0.000716, l6: 0.001864

[epoch: 184/1000, batch:   924/ 1052, ite: 48360] train loss: 0.006122, tar: 0.000463 
l0: 0.000218, l1: 0.000219, l2: 0.000244, l3: 0.000300, l4: 0.000422, l5: 0.000568, l6: 0.001230

[epoch: 184/1000, batch:  1004/ 1052, ite: 48380] train loss: 0.006122, tar: 0.000463 
[Epoch 184/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000228, l1: 0.000217, l2: 0.000225, l3: 0.000286, l4: 0.000526, l5: 0.000824, l6: 0.001440

[epoch: 185/1000, batch:    32/ 1052, ite: 48400] train loss: 0.006120, tar: 0.000463 
l0: 0.000214, l1: 0.000222, l2: 0.000228, l3: 0.000294, l4: 0.000362, l5: 0.000780, l6: 0.001851

[epoch: 185/1000, batch:   112/ 1052, ite: 48420] train loss: 0.006118, tar: 0.000462 
l0: 0.000515, l1: 0.000520, l2: 0.000514, l3: 0.000578, l4: 0.000657, l5: 0.001462, l6: 0.002552

[epoch: 185/1000, batch:   192/ 1052, ite: 48440] train loss: 0.006119, tar: 0.000462 
l0: 0.000293, l1: 0.000294, l2: 0.000321, l3: 0.000365, l4: 0.000499, l5: 0.000892, l6: 0.001127

[epoch: 185/1000, batch:   272/ 1052, ite: 48460] train loss: 0.006118, tar: 0.000462 
l0: 0.000225, l1: 0.000226, l2: 0.000259, l3: 0.000281, l4: 0.000467, l5: 0.000664, l6: 0.001054

[epoch: 185/1000, batch:   352/ 1052, ite: 48480] train loss: 0.006123, tar: 0.000462 
l0: 0.000550, l1: 0.000533, l2: 0.000587, l3: 0.000666, l4: 0.000895, l5: 0.001419, l6: 0.003015

[epoch: 185/1000, batch:   432/ 1052, ite: 48500] train loss: 0.006121, tar: 0.000462 
l0: 0.000259, l1: 0.000266, l2: 0.000238, l3: 0.000314, l4: 0.000455, l5: 0.000641, l6: 0.001418

[epoch: 185/1000, batch:   512/ 1052, ite: 48520] train loss: 0.006119, tar: 0.000462 
l0: 0.000311, l1: 0.000315, l2: 0.000321, l3: 0.000351, l4: 0.000408, l5: 0.000864, l6: 0.001662

[epoch: 185/1000, batch:   592/ 1052, ite: 48540] train loss: 0.006120, tar: 0.000462 
l0: 0.000596, l1: 0.000575, l2: 0.000651, l3: 0.000834, l4: 0.000978, l5: 0.001923, l6: 0.002913

[epoch: 185/1000, batch:   672/ 1052, ite: 48560] train loss: 0.006116, tar: 0.000462 
l0: 0.000432, l1: 0.000427, l2: 0.000474, l3: 0.000537, l4: 0.000712, l5: 0.001295, l6: 0.002149

[epoch: 185/1000, batch:   752/ 1052, ite: 48580] train loss: 0.006116, tar: 0.000461 
l0: 0.000395, l1: 0.000392, l2: 0.000405, l3: 0.000506, l4: 0.000703, l5: 0.001101, l6: 0.002408

[epoch: 185/1000, batch:   832/ 1052, ite: 48600] train loss: 0.006116, tar: 0.000462 
l0: 0.000331, l1: 0.000322, l2: 0.000331, l3: 0.000526, l4: 0.000634, l5: 0.000960, l6: 0.001478

[epoch: 185/1000, batch:   912/ 1052, ite: 48620] train loss: 0.006116, tar: 0.000462 
l0: 0.000548, l1: 0.000579, l2: 0.000646, l3: 0.000556, l4: 0.000784, l5: 0.001578, l6: 0.002285

[epoch: 185/1000, batch:   992/ 1052, ite: 48640] train loss: 0.006113, tar: 0.000461 
[Epoch 185/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000498, l1: 0.000559, l2: 0.000496, l3: 0.000486, l4: 0.000634, l5: 0.001260, l6: 0.002339

[epoch: 186/1000, batch:    20/ 1052, ite: 48660] train loss: 0.006112, tar: 0.000461 
l0: 0.000255, l1: 0.000262, l2: 0.000282, l3: 0.000296, l4: 0.000517, l5: 0.000740, l6: 0.001394

[epoch: 186/1000, batch:   100/ 1052, ite: 48680] train loss: 0.006113, tar: 0.000461 
l0: 0.000291, l1: 0.000290, l2: 0.000344, l3: 0.000392, l4: 0.000575, l5: 0.001272, l6: 0.001707

[epoch: 186/1000, batch:   180/ 1052, ite: 48700] train loss: 0.006111, tar: 0.000461 
l0: 0.000237, l1: 0.000245, l2: 0.000247, l3: 0.000302, l4: 0.000364, l5: 0.001124, l6: 0.001397

[epoch: 186/1000, batch:   260/ 1052, ite: 48720] train loss: 0.006107, tar: 0.000460 
l0: 0.000412, l1: 0.000403, l2: 0.000435, l3: 0.000489, l4: 0.000736, l5: 0.001143, l6: 0.001893

[epoch: 186/1000, batch:   340/ 1052, ite: 48740] train loss: 0.006107, tar: 0.000461 
l0: 0.000321, l1: 0.000310, l2: 0.000336, l3: 0.000454, l4: 0.000790, l5: 0.001374, l6: 0.002048

[epoch: 186/1000, batch:   420/ 1052, ite: 48760] train loss: 0.006106, tar: 0.000461 
l0: 0.000663, l1: 0.000654, l2: 0.000620, l3: 0.000727, l4: 0.000824, l5: 0.001489, l6: 0.001742

[epoch: 186/1000, batch:   500/ 1052, ite: 48780] train loss: 0.006105, tar: 0.000460 
l0: 0.000504, l1: 0.000503, l2: 0.000542, l3: 0.000574, l4: 0.000673, l5: 0.000701, l6: 0.001358

[epoch: 186/1000, batch:   580/ 1052, ite: 48800] train loss: 0.006107, tar: 0.000461 
l0: 0.000419, l1: 0.000433, l2: 0.000446, l3: 0.000466, l4: 0.000819, l5: 0.001683, l6: 0.003426

[epoch: 186/1000, batch:   660/ 1052, ite: 48820] train loss: 0.006105, tar: 0.000460 
l0: 0.000862, l1: 0.000983, l2: 0.000889, l3: 0.000885, l4: 0.001325, l5: 0.001536, l6: 0.004260

[epoch: 186/1000, batch:   740/ 1052, ite: 48840] train loss: 0.006104, tar: 0.000460 
l0: 0.000291, l1: 0.000300, l2: 0.000348, l3: 0.000335, l4: 0.000525, l5: 0.001009, l6: 0.002306

[epoch: 186/1000, batch:   820/ 1052, ite: 48860] train loss: 0.006103, tar: 0.000460 
l0: 0.000485, l1: 0.000461, l2: 0.000510, l3: 0.000589, l4: 0.000951, l5: 0.001415, l6: 0.002114

[epoch: 186/1000, batch:   900/ 1052, ite: 48880] train loss: 0.006104, tar: 0.000460 
l0: 0.000302, l1: 0.000302, l2: 0.000320, l3: 0.000366, l4: 0.000546, l5: 0.001063, l6: 0.001531

[epoch: 186/1000, batch:   980/ 1052, ite: 48900] train loss: 0.006103, tar: 0.000460 
[Epoch 186/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000453, l1: 0.000457, l2: 0.000461, l3: 0.000567, l4: 0.000601, l5: 0.000981, l6: 0.001376

[epoch: 187/1000, batch:     8/ 1052, ite: 48920] train loss: 0.006103, tar: 0.000460 
l0: 0.000121, l1: 0.000110, l2: 0.000144, l3: 0.000198, l4: 0.000321, l5: 0.000437, l6: 0.000514

[epoch: 187/1000, batch:    88/ 1052, ite: 48940] train loss: 0.006102, tar: 0.000459 
l0: 0.000469, l1: 0.000456, l2: 0.000488, l3: 0.000587, l4: 0.000797, l5: 0.001144, l6: 0.001800

[epoch: 187/1000, batch:   168/ 1052, ite: 48960] train loss: 0.006099, tar: 0.000459 
l0: 0.000603, l1: 0.000612, l2: 0.000664, l3: 0.000731, l4: 0.001178, l5: 0.002414, l6: 0.004201

[epoch: 187/1000, batch:   248/ 1052, ite: 48980] train loss: 0.006099, tar: 0.000459 
l0: 0.000366, l1: 0.000359, l2: 0.000361, l3: 0.000432, l4: 0.000734, l5: 0.001358, l6: 0.002679

[epoch: 187/1000, batch:   328/ 1052, ite: 49000] train loss: 0.006098, tar: 0.000459 
l0: 0.000317, l1: 0.000324, l2: 0.000331, l3: 0.000336, l4: 0.000496, l5: 0.001154, l6: 0.002061

[epoch: 187/1000, batch:   408/ 1052, ite: 49020] train loss: 0.006098, tar: 0.000459 
l0: 0.000355, l1: 0.000348, l2: 0.000387, l3: 0.000441, l4: 0.000563, l5: 0.001465, l6: 0.002175

[epoch: 187/1000, batch:   488/ 1052, ite: 49040] train loss: 0.006098, tar: 0.000459 
l0: 0.000236, l1: 0.000239, l2: 0.000245, l3: 0.000255, l4: 0.000367, l5: 0.000670, l6: 0.001062

[epoch: 187/1000, batch:   568/ 1052, ite: 49060] train loss: 0.006098, tar: 0.000459 
l0: 0.000493, l1: 0.000526, l2: 0.000541, l3: 0.000634, l4: 0.001017, l5: 0.001305, l6: 0.002546

[epoch: 187/1000, batch:   648/ 1052, ite: 49080] train loss: 0.006100, tar: 0.000459 
l0: 0.000172, l1: 0.000173, l2: 0.000195, l3: 0.000198, l4: 0.000335, l5: 0.000711, l6: 0.000779

[epoch: 187/1000, batch:   728/ 1052, ite: 49100] train loss: 0.006101, tar: 0.000459 
l0: 0.000506, l1: 0.000509, l2: 0.000543, l3: 0.000574, l4: 0.000869, l5: 0.000818, l6: 0.002722

[epoch: 187/1000, batch:   808/ 1052, ite: 49120] train loss: 0.006099, tar: 0.000459 
l0: 0.000828, l1: 0.000851, l2: 0.000773, l3: 0.000881, l4: 0.001076, l5: 0.001490, l6: 0.001981

[epoch: 187/1000, batch:   888/ 1052, ite: 49140] train loss: 0.006099, tar: 0.000459 
l0: 0.000508, l1: 0.000535, l2: 0.000503, l3: 0.000560, l4: 0.000840, l5: 0.001514, l6: 0.002489

[epoch: 187/1000, batch:   968/ 1052, ite: 49160] train loss: 0.006098, tar: 0.000459 
l0: 0.000324, l1: 0.000311, l2: 0.000291, l3: 0.000441, l4: 0.000438, l5: 0.000639, l6: 0.002193

[epoch: 187/1000, batch:  1048/ 1052, ite: 49180] train loss: 0.006096, tar: 0.000459 
[Epoch 187/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000361, l1: 0.000361, l2: 0.000410, l3: 0.000441, l4: 0.000559, l5: 0.001022, l6: 0.001377

[epoch: 188/1000, batch:    76/ 1052, ite: 49200] train loss: 0.006097, tar: 0.000459 
l0: 0.000280, l1: 0.000286, l2: 0.000285, l3: 0.000333, l4: 0.000481, l5: 0.000991, l6: 0.002451

[epoch: 188/1000, batch:   156/ 1052, ite: 49220] train loss: 0.006096, tar: 0.000459 
l0: 0.000843, l1: 0.000858, l2: 0.000867, l3: 0.001043, l4: 0.001441, l5: 0.002011, l6: 0.003749

[epoch: 188/1000, batch:   236/ 1052, ite: 49240] train loss: 0.006097, tar: 0.000459 
l0: 0.000470, l1: 0.000469, l2: 0.000486, l3: 0.000638, l4: 0.000803, l5: 0.001435, l6: 0.002217

[epoch: 188/1000, batch:   316/ 1052, ite: 49260] train loss: 0.006098, tar: 0.000459 
l0: 0.000852, l1: 0.000911, l2: 0.000897, l3: 0.000836, l4: 0.001231, l5: 0.001343, l6: 0.001979

[epoch: 188/1000, batch:   396/ 1052, ite: 49280] train loss: 0.006096, tar: 0.000459 
l0: 0.000378, l1: 0.000331, l2: 0.000389, l3: 0.000469, l4: 0.000774, l5: 0.001142, l6: 0.001847

[epoch: 188/1000, batch:   476/ 1052, ite: 49300] train loss: 0.006095, tar: 0.000459 
l0: 0.000452, l1: 0.000482, l2: 0.000476, l3: 0.000502, l4: 0.000725, l5: 0.001146, l6: 0.002096

[epoch: 188/1000, batch:   556/ 1052, ite: 49320] train loss: 0.006093, tar: 0.000458 
l0: 0.000654, l1: 0.000661, l2: 0.000664, l3: 0.000826, l4: 0.000902, l5: 0.001280, l6: 0.002132

[epoch: 188/1000, batch:   636/ 1052, ite: 49340] train loss: 0.006092, tar: 0.000458 
l0: 0.000432, l1: 0.000437, l2: 0.000448, l3: 0.000555, l4: 0.000853, l5: 0.001953, l6: 0.002441

[epoch: 188/1000, batch:   716/ 1052, ite: 49360] train loss: 0.006091, tar: 0.000458 
l0: 0.000643, l1: 0.000643, l2: 0.000612, l3: 0.000771, l4: 0.000943, l5: 0.002301, l6: 0.002571

[epoch: 188/1000, batch:   796/ 1052, ite: 49380] train loss: 0.006092, tar: 0.000458 
l0: 0.000506, l1: 0.000502, l2: 0.000530, l3: 0.000576, l4: 0.000945, l5: 0.001549, l6: 0.002126

[epoch: 188/1000, batch:   876/ 1052, ite: 49400] train loss: 0.006092, tar: 0.000458 
l0: 0.000236, l1: 0.000237, l2: 0.000259, l3: 0.000302, l4: 0.000568, l5: 0.001122, l6: 0.001733

[epoch: 188/1000, batch:   956/ 1052, ite: 49420] train loss: 0.006091, tar: 0.000458 
l0: 0.000263, l1: 0.000283, l2: 0.000288, l3: 0.000301, l4: 0.000459, l5: 0.000950, l6: 0.001610

[epoch: 188/1000, batch:  1036/ 1052, ite: 49440] train loss: 0.006090, tar: 0.000458 
[Epoch 188/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000261, l1: 0.000265, l2: 0.000279, l3: 0.000308, l4: 0.000359, l5: 0.000935, l6: 0.001051

[epoch: 189/1000, batch:    64/ 1052, ite: 49460] train loss: 0.006089, tar: 0.000458 
l0: 0.000541, l1: 0.000524, l2: 0.000607, l3: 0.000763, l4: 0.001078, l5: 0.001808, l6: 0.003358

[epoch: 189/1000, batch:   144/ 1052, ite: 49480] train loss: 0.006090, tar: 0.000458 
l0: 0.000323, l1: 0.000319, l2: 0.000312, l3: 0.000413, l4: 0.000507, l5: 0.001044, l6: 0.001899

[epoch: 189/1000, batch:   224/ 1052, ite: 49500] train loss: 0.006090, tar: 0.000458 
l0: 0.000591, l1: 0.000609, l2: 0.000611, l3: 0.000692, l4: 0.000918, l5: 0.001382, l6: 0.003102

[epoch: 189/1000, batch:   304/ 1052, ite: 49520] train loss: 0.006091, tar: 0.000458 
l0: 0.000761, l1: 0.000824, l2: 0.000768, l3: 0.000771, l4: 0.001204, l5: 0.001885, l6: 0.002598

[epoch: 189/1000, batch:   384/ 1052, ite: 49540] train loss: 0.006093, tar: 0.000458 
l0: 0.000604, l1: 0.000591, l2: 0.000617, l3: 0.000718, l4: 0.000833, l5: 0.002003, l6: 0.002778

[epoch: 189/1000, batch:   464/ 1052, ite: 49560] train loss: 0.006093, tar: 0.000458 
l0: 0.000542, l1: 0.000537, l2: 0.000629, l3: 0.000641, l4: 0.000824, l5: 0.001901, l6: 0.002828

[epoch: 189/1000, batch:   544/ 1052, ite: 49580] train loss: 0.006092, tar: 0.000458 
l0: 0.000395, l1: 0.000402, l2: 0.000415, l3: 0.000455, l4: 0.000728, l5: 0.001317, l6: 0.002844

[epoch: 189/1000, batch:   624/ 1052, ite: 49600] train loss: 0.006094, tar: 0.000458 
l0: 0.000381, l1: 0.000370, l2: 0.000445, l3: 0.000588, l4: 0.000773, l5: 0.001692, l6: 0.002428

[epoch: 189/1000, batch:   704/ 1052, ite: 49620] train loss: 0.006093, tar: 0.000458 
l0: 0.000478, l1: 0.000480, l2: 0.000521, l3: 0.000661, l4: 0.000876, l5: 0.001152, l6: 0.002566

[epoch: 189/1000, batch:   784/ 1052, ite: 49640] train loss: 0.006094, tar: 0.000458 
l0: 0.000369, l1: 0.000361, l2: 0.000414, l3: 0.000470, l4: 0.000523, l5: 0.001147, l6: 0.001972

[epoch: 189/1000, batch:   864/ 1052, ite: 49660] train loss: 0.006094, tar: 0.000458 
l0: 0.000376, l1: 0.000385, l2: 0.000390, l3: 0.000423, l4: 0.000460, l5: 0.000802, l6: 0.002291

[epoch: 189/1000, batch:   944/ 1052, ite: 49680] train loss: 0.006093, tar: 0.000458 
l0: 0.000301, l1: 0.000308, l2: 0.000347, l3: 0.000466, l4: 0.000491, l5: 0.001333, l6: 0.001822

[epoch: 189/1000, batch:  1024/ 1052, ite: 49700] train loss: 0.006092, tar: 0.000458 
[Epoch 189/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000331, l1: 0.000330, l2: 0.000343, l3: 0.000404, l4: 0.000419, l5: 0.000861, l6: 0.001214

[epoch: 190/1000, batch:    52/ 1052, ite: 49720] train loss: 0.006089, tar: 0.000458 
l0: 0.000429, l1: 0.000414, l2: 0.000421, l3: 0.000657, l4: 0.000651, l5: 0.001154, l6: 0.002109

[epoch: 190/1000, batch:   132/ 1052, ite: 49740] train loss: 0.006090, tar: 0.000458 
l0: 0.000280, l1: 0.000277, l2: 0.000271, l3: 0.000351, l4: 0.000472, l5: 0.000837, l6: 0.001487

[epoch: 190/1000, batch:   212/ 1052, ite: 49760] train loss: 0.006089, tar: 0.000458 
l0: 0.000158, l1: 0.000170, l2: 0.000174, l3: 0.000191, l4: 0.000328, l5: 0.000474, l6: 0.000833

[epoch: 190/1000, batch:   292/ 1052, ite: 49780] train loss: 0.006088, tar: 0.000458 
l0: 0.000207, l1: 0.000207, l2: 0.000227, l3: 0.000262, l4: 0.000397, l5: 0.000785, l6: 0.001642

[epoch: 190/1000, batch:   372/ 1052, ite: 49800] train loss: 0.006089, tar: 0.000458 
l0: 0.000462, l1: 0.000472, l2: 0.000489, l3: 0.000587, l4: 0.000805, l5: 0.001395, l6: 0.003131

[epoch: 190/1000, batch:   452/ 1052, ite: 49820] train loss: 0.006087, tar: 0.000458 
l0: 0.000342, l1: 0.000367, l2: 0.000327, l3: 0.000424, l4: 0.000511, l5: 0.000994, l6: 0.001506

[epoch: 190/1000, batch:   532/ 1052, ite: 49840] train loss: 0.006085, tar: 0.000457 
l0: 0.000471, l1: 0.000487, l2: 0.000514, l3: 0.000641, l4: 0.001165, l5: 0.001589, l6: 0.002231

[epoch: 190/1000, batch:   612/ 1052, ite: 49860] train loss: 0.006087, tar: 0.000457 
l0: 0.000316, l1: 0.000319, l2: 0.000345, l3: 0.000386, l4: 0.000660, l5: 0.001354, l6: 0.002727

[epoch: 190/1000, batch:   692/ 1052, ite: 49880] train loss: 0.006085, tar: 0.000457 
l0: 0.000534, l1: 0.000527, l2: 0.000569, l3: 0.000672, l4: 0.001234, l5: 0.002319, l6: 0.002277

[epoch: 190/1000, batch:   772/ 1052, ite: 49900] train loss: 0.006087, tar: 0.000457 
l0: 0.000363, l1: 0.000359, l2: 0.000411, l3: 0.000440, l4: 0.000674, l5: 0.001297, l6: 0.001961

[epoch: 190/1000, batch:   852/ 1052, ite: 49920] train loss: 0.006087, tar: 0.000457 
l0: 0.000271, l1: 0.000270, l2: 0.000271, l3: 0.000359, l4: 0.000420, l5: 0.001225, l6: 0.001472

[epoch: 190/1000, batch:   932/ 1052, ite: 49940] train loss: 0.006086, tar: 0.000457 
l0: 0.000428, l1: 0.000439, l2: 0.000472, l3: 0.000458, l4: 0.000639, l5: 0.001259, l6: 0.002544

[epoch: 190/1000, batch:  1012/ 1052, ite: 49960] train loss: 0.006084, tar: 0.000457 
[Epoch 190/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000643, l1: 0.000649, l2: 0.000681, l3: 0.000728, l4: 0.000804, l5: 0.001654, l6: 0.002349

[epoch: 191/1000, batch:    40/ 1052, ite: 49980] train loss: 0.006084, tar: 0.000457 
l0: 0.000449, l1: 0.000439, l2: 0.000465, l3: 0.000527, l4: 0.000681, l5: 0.001108, l6: 0.001673

[epoch: 191/1000, batch:   120/ 1052, ite: 50000] train loss: 0.006081, tar: 0.000457 
l0: 0.000360, l1: 0.000351, l2: 0.000399, l3: 0.000442, l4: 0.000683, l5: 0.001271, l6: 0.002091

[epoch: 191/1000, batch:   200/ 1052, ite: 50020] train loss: 0.006082, tar: 0.000457 
l0: 0.000223, l1: 0.000230, l2: 0.000252, l3: 0.000228, l4: 0.000406, l5: 0.000793, l6: 0.000828

[epoch: 191/1000, batch:   280/ 1052, ite: 50040] train loss: 0.006081, tar: 0.000457 
l0: 0.000335, l1: 0.000340, l2: 0.000362, l3: 0.000483, l4: 0.000548, l5: 0.001285, l6: 0.002313

[epoch: 191/1000, batch:   360/ 1052, ite: 50060] train loss: 0.006081, tar: 0.000456 
l0: 0.000339, l1: 0.000357, l2: 0.000350, l3: 0.000378, l4: 0.000701, l5: 0.001058, l6: 0.002330

[epoch: 191/1000, batch:   440/ 1052, ite: 50080] train loss: 0.006082, tar: 0.000457 
l0: 0.000302, l1: 0.000316, l2: 0.000300, l3: 0.000360, l4: 0.000529, l5: 0.001259, l6: 0.001111

[epoch: 191/1000, batch:   520/ 1052, ite: 50100] train loss: 0.006081, tar: 0.000456 
l0: 0.000319, l1: 0.000306, l2: 0.000340, l3: 0.000425, l4: 0.000741, l5: 0.001055, l6: 0.001504

[epoch: 191/1000, batch:   600/ 1052, ite: 50120] train loss: 0.006080, tar: 0.000456 
l0: 0.000165, l1: 0.000169, l2: 0.000174, l3: 0.000199, l4: 0.000350, l5: 0.000781, l6: 0.001137

[epoch: 191/1000, batch:   680/ 1052, ite: 50140] train loss: 0.006077, tar: 0.000456 
l0: 0.000248, l1: 0.000252, l2: 0.000254, l3: 0.000292, l4: 0.000404, l5: 0.000597, l6: 0.001184

[epoch: 191/1000, batch:   760/ 1052, ite: 50160] train loss: 0.006075, tar: 0.000456 
l0: 0.000491, l1: 0.000491, l2: 0.000542, l3: 0.000582, l4: 0.000775, l5: 0.001911, l6: 0.004395

[epoch: 191/1000, batch:   840/ 1052, ite: 50180] train loss: 0.006077, tar: 0.000456 
l0: 0.000341, l1: 0.000350, l2: 0.000325, l3: 0.000363, l4: 0.000422, l5: 0.000630, l6: 0.001575

[epoch: 191/1000, batch:   920/ 1052, ite: 50200] train loss: 0.006076, tar: 0.000456 
l0: 0.000412, l1: 0.000396, l2: 0.000407, l3: 0.000479, l4: 0.000617, l5: 0.001039, l6: 0.001469

[epoch: 191/1000, batch:  1000/ 1052, ite: 50220] train loss: 0.006075, tar: 0.000456 
[Epoch 191/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000317, l1: 0.000315, l2: 0.000379, l3: 0.000373, l4: 0.000615, l5: 0.000972, l6: 0.001728

[epoch: 192/1000, batch:    28/ 1052, ite: 50240] train loss: 0.006074, tar: 0.000455 
l0: 0.000546, l1: 0.000548, l2: 0.000566, l3: 0.000516, l4: 0.000860, l5: 0.001432, l6: 0.002428

[epoch: 192/1000, batch:   108/ 1052, ite: 50260] train loss: 0.006073, tar: 0.000455 
l0: 0.000401, l1: 0.000411, l2: 0.000414, l3: 0.000439, l4: 0.000510, l5: 0.001125, l6: 0.001851

[epoch: 192/1000, batch:   188/ 1052, ite: 50280] train loss: 0.006072, tar: 0.000455 
l0: 0.000409, l1: 0.000405, l2: 0.000444, l3: 0.000469, l4: 0.000611, l5: 0.001270, l6: 0.001924

[epoch: 192/1000, batch:   268/ 1052, ite: 50300] train loss: 0.006072, tar: 0.000455 
l0: 0.000251, l1: 0.000249, l2: 0.000250, l3: 0.000374, l4: 0.000530, l5: 0.000963, l6: 0.001718

[epoch: 192/1000, batch:   348/ 1052, ite: 50320] train loss: 0.006070, tar: 0.000455 
l0: 0.000333, l1: 0.000309, l2: 0.000371, l3: 0.000511, l4: 0.000739, l5: 0.001554, l6: 0.001847

[epoch: 192/1000, batch:   428/ 1052, ite: 50340] train loss: 0.006070, tar: 0.000455 
l0: 0.000331, l1: 0.000326, l2: 0.000368, l3: 0.000425, l4: 0.000659, l5: 0.000958, l6: 0.001466

[epoch: 192/1000, batch:   508/ 1052, ite: 50360] train loss: 0.006069, tar: 0.000455 
l0: 0.000366, l1: 0.000370, l2: 0.000413, l3: 0.000468, l4: 0.000614, l5: 0.001255, l6: 0.002996

[epoch: 192/1000, batch:   588/ 1052, ite: 50380] train loss: 0.006068, tar: 0.000455 
l0: 0.000311, l1: 0.000316, l2: 0.000337, l3: 0.000406, l4: 0.000478, l5: 0.000788, l6: 0.001345

[epoch: 192/1000, batch:   668/ 1052, ite: 50400] train loss: 0.006068, tar: 0.000455 
l0: 0.000557, l1: 0.000582, l2: 0.000608, l3: 0.000623, l4: 0.000754, l5: 0.001184, l6: 0.002882

[epoch: 192/1000, batch:   748/ 1052, ite: 50420] train loss: 0.006069, tar: 0.000455 
l0: 0.000424, l1: 0.000448, l2: 0.000559, l3: 0.000506, l4: 0.000642, l5: 0.000838, l6: 0.001330

[epoch: 192/1000, batch:   828/ 1052, ite: 50440] train loss: 0.006069, tar: 0.000455 
l0: 0.000609, l1: 0.000624, l2: 0.000641, l3: 0.000636, l4: 0.001124, l5: 0.001902, l6: 0.004226

[epoch: 192/1000, batch:   908/ 1052, ite: 50460] train loss: 0.006068, tar: 0.000454 
l0: 0.000376, l1: 0.000380, l2: 0.000393, l3: 0.000437, l4: 0.000675, l5: 0.001421, l6: 0.001821

[epoch: 192/1000, batch:   988/ 1052, ite: 50480] train loss: 0.006067, tar: 0.000454 
[Epoch 192/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000140, l1: 0.000142, l2: 0.000154, l3: 0.000195, l4: 0.000377, l5: 0.000846, l6: 0.001307

[epoch: 193/1000, batch:    16/ 1052, ite: 50500] train loss: 0.006067, tar: 0.000454 
l0: 0.000475, l1: 0.000464, l2: 0.000505, l3: 0.000598, l4: 0.000782, l5: 0.001479, l6: 0.001973

[epoch: 193/1000, batch:    96/ 1052, ite: 50520] train loss: 0.006067, tar: 0.000454 
l0: 0.000335, l1: 0.000362, l2: 0.000364, l3: 0.000351, l4: 0.000745, l5: 0.001010, l6: 0.001880

[epoch: 193/1000, batch:   176/ 1052, ite: 50540] train loss: 0.006066, tar: 0.000454 
l0: 0.000208, l1: 0.000212, l2: 0.000206, l3: 0.000221, l4: 0.000413, l5: 0.000815, l6: 0.001462

[epoch: 193/1000, batch:   256/ 1052, ite: 50560] train loss: 0.006065, tar: 0.000454 
l0: 0.000355, l1: 0.000351, l2: 0.000342, l3: 0.000418, l4: 0.000450, l5: 0.000505, l6: 0.001287

[epoch: 193/1000, batch:   336/ 1052, ite: 50580] train loss: 0.006065, tar: 0.000454 
l0: 0.000420, l1: 0.000439, l2: 0.000497, l3: 0.000408, l4: 0.000664, l5: 0.001215, l6: 0.002365

[epoch: 193/1000, batch:   416/ 1052, ite: 50600] train loss: 0.006065, tar: 0.000454 
l0: 0.000269, l1: 0.000296, l2: 0.000280, l3: 0.000269, l4: 0.000442, l5: 0.000818, l6: 0.000915

[epoch: 193/1000, batch:   496/ 1052, ite: 50620] train loss: 0.006064, tar: 0.000454 
l0: 0.000360, l1: 0.000370, l2: 0.000473, l3: 0.000583, l4: 0.000682, l5: 0.000975, l6: 0.002214

[epoch: 193/1000, batch:   576/ 1052, ite: 50640] train loss: 0.006063, tar: 0.000454 
l0: 0.000544, l1: 0.000570, l2: 0.000597, l3: 0.000515, l4: 0.000638, l5: 0.001302, l6: 0.002562

[epoch: 193/1000, batch:   656/ 1052, ite: 50660] train loss: 0.006063, tar: 0.000454 
l0: 0.000251, l1: 0.000255, l2: 0.000244, l3: 0.000276, l4: 0.000329, l5: 0.000905, l6: 0.001485

[epoch: 193/1000, batch:   736/ 1052, ite: 50680] train loss: 0.006064, tar: 0.000454 
l0: 0.000215, l1: 0.000224, l2: 0.000254, l3: 0.000248, l4: 0.000510, l5: 0.000888, l6: 0.001287

[epoch: 193/1000, batch:   816/ 1052, ite: 50700] train loss: 0.006064, tar: 0.000454 
l0: 0.000794, l1: 0.000898, l2: 0.000805, l3: 0.000895, l4: 0.001168, l5: 0.001657, l6: 0.002841

[epoch: 193/1000, batch:   896/ 1052, ite: 50720] train loss: 0.006064, tar: 0.000454 
l0: 0.000285, l1: 0.000300, l2: 0.000304, l3: 0.000332, l4: 0.000555, l5: 0.001133, l6: 0.002024

[epoch: 193/1000, batch:   976/ 1052, ite: 50740] train loss: 0.006066, tar: 0.000454 
[Epoch 193/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000614, l1: 0.000555, l2: 0.000569, l3: 0.000882, l4: 0.000919, l5: 0.001281, l6: 0.002556

[epoch: 194/1000, batch:     4/ 1052, ite: 50760] train loss: 0.006065, tar: 0.000454 
l0: 0.000301, l1: 0.000287, l2: 0.000303, l3: 0.000454, l4: 0.000608, l5: 0.000966, l6: 0.001759

[epoch: 194/1000, batch:    84/ 1052, ite: 50780] train loss: 0.006062, tar: 0.000454 
l0: 0.000806, l1: 0.000805, l2: 0.000861, l3: 0.000903, l4: 0.001294, l5: 0.003047, l6: 0.005081

[epoch: 194/1000, batch:   164/ 1052, ite: 50800] train loss: 0.006063, tar: 0.000454 
l0: 0.000199, l1: 0.000201, l2: 0.000209, l3: 0.000256, l4: 0.000498, l5: 0.000655, l6: 0.001230

[epoch: 194/1000, batch:   244/ 1052, ite: 50820] train loss: 0.006061, tar: 0.000453 
l0: 0.000329, l1: 0.000331, l2: 0.000355, l3: 0.000412, l4: 0.000559, l5: 0.001029, l6: 0.001529

[epoch: 194/1000, batch:   324/ 1052, ite: 50840] train loss: 0.006060, tar: 0.000453 
l0: 0.000235, l1: 0.000225, l2: 0.000264, l3: 0.000362, l4: 0.000489, l5: 0.001119, l6: 0.001806

[epoch: 194/1000, batch:   404/ 1052, ite: 50860] train loss: 0.006059, tar: 0.000453 
l0: 0.000186, l1: 0.000185, l2: 0.000192, l3: 0.000224, l4: 0.000439, l5: 0.000782, l6: 0.001225

[epoch: 194/1000, batch:   484/ 1052, ite: 50880] train loss: 0.006057, tar: 0.000453 
l0: 0.000491, l1: 0.000498, l2: 0.000511, l3: 0.000530, l4: 0.001077, l5: 0.002533, l6: 0.003743

[epoch: 194/1000, batch:   564/ 1052, ite: 50900] train loss: 0.006059, tar: 0.000453 
l0: 0.000324, l1: 0.000309, l2: 0.000352, l3: 0.000508, l4: 0.000655, l5: 0.001289, l6: 0.001770

[epoch: 194/1000, batch:   644/ 1052, ite: 50920] train loss: 0.006058, tar: 0.000453 
l0: 0.000377, l1: 0.000376, l2: 0.000392, l3: 0.000516, l4: 0.000669, l5: 0.001319, l6: 0.002132

[epoch: 194/1000, batch:   724/ 1052, ite: 50940] train loss: 0.006058, tar: 0.000453 
l0: 0.000333, l1: 0.000420, l2: 0.000415, l3: 0.000393, l4: 0.000464, l5: 0.001016, l6: 0.001461

[epoch: 194/1000, batch:   804/ 1052, ite: 50960] train loss: 0.006058, tar: 0.000453 
l0: 0.000266, l1: 0.000271, l2: 0.000292, l3: 0.000322, l4: 0.000415, l5: 0.001166, l6: 0.001288

[epoch: 194/1000, batch:   884/ 1052, ite: 50980] train loss: 0.006058, tar: 0.000453 
l0: 0.000630, l1: 0.000640, l2: 0.000640, l3: 0.000722, l4: 0.001215, l5: 0.001700, l6: 0.003160

[epoch: 194/1000, batch:   964/ 1052, ite: 51000] train loss: 0.006059, tar: 0.000453 
l0: 0.000448, l1: 0.000401, l2: 0.000444, l3: 0.000688, l4: 0.000756, l5: 0.001052, l6: 0.001961

[epoch: 194/1000, batch:  1044/ 1052, ite: 51020] train loss: 0.006059, tar: 0.000453 
[Epoch 194/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000295, l1: 0.000296, l2: 0.000309, l3: 0.000353, l4: 0.000573, l5: 0.000814, l6: 0.002142

[epoch: 195/1000, batch:    72/ 1052, ite: 51040] train loss: 0.006058, tar: 0.000453 
l0: 0.000263, l1: 0.000281, l2: 0.000291, l3: 0.000302, l4: 0.000488, l5: 0.001009, l6: 0.001874

[epoch: 195/1000, batch:   152/ 1052, ite: 51060] train loss: 0.006057, tar: 0.000453 
l0: 0.000273, l1: 0.000274, l2: 0.000270, l3: 0.000324, l4: 0.000554, l5: 0.001135, l6: 0.001417

[epoch: 195/1000, batch:   232/ 1052, ite: 51080] train loss: 0.006055, tar: 0.000453 
l0: 0.000502, l1: 0.000515, l2: 0.000513, l3: 0.000554, l4: 0.000748, l5: 0.001243, l6: 0.001730

[epoch: 195/1000, batch:   312/ 1052, ite: 51100] train loss: 0.006053, tar: 0.000452 
l0: 0.000933, l1: 0.000978, l2: 0.000988, l3: 0.000979, l4: 0.001376, l5: 0.002147, l6: 0.004380

[epoch: 195/1000, batch:   392/ 1052, ite: 51120] train loss: 0.006052, tar: 0.000452 
l0: 0.000497, l1: 0.000491, l2: 0.000515, l3: 0.000605, l4: 0.000961, l5: 0.001364, l6: 0.002636

[epoch: 195/1000, batch:   472/ 1052, ite: 51140] train loss: 0.006053, tar: 0.000452 
l0: 0.000505, l1: 0.000510, l2: 0.000515, l3: 0.000611, l4: 0.000813, l5: 0.001590, l6: 0.002658

[epoch: 195/1000, batch:   552/ 1052, ite: 51160] train loss: 0.006054, tar: 0.000452 
l0: 0.000226, l1: 0.000231, l2: 0.000254, l3: 0.000292, l4: 0.000430, l5: 0.001214, l6: 0.001138

[epoch: 195/1000, batch:   632/ 1052, ite: 51180] train loss: 0.006053, tar: 0.000452 
l0: 0.000207, l1: 0.000198, l2: 0.000239, l3: 0.000266, l4: 0.000363, l5: 0.000731, l6: 0.000643

[epoch: 195/1000, batch:   712/ 1052, ite: 51200] train loss: 0.006052, tar: 0.000452 
l0: 0.000534, l1: 0.000536, l2: 0.000558, l3: 0.000644, l4: 0.000889, l5: 0.001544, l6: 0.003147

[epoch: 195/1000, batch:   792/ 1052, ite: 51220] train loss: 0.006052, tar: 0.000452 
l0: 0.000463, l1: 0.000488, l2: 0.000536, l3: 0.000642, l4: 0.001226, l5: 0.002345, l6: 0.003626

[epoch: 195/1000, batch:   872/ 1052, ite: 51240] train loss: 0.006053, tar: 0.000452 
l0: 0.000471, l1: 0.000500, l2: 0.000540, l3: 0.000511, l4: 0.000951, l5: 0.001758, l6: 0.002554

[epoch: 195/1000, batch:   952/ 1052, ite: 51260] train loss: 0.006052, tar: 0.000452 
l0: 0.000291, l1: 0.000302, l2: 0.000296, l3: 0.000343, l4: 0.000492, l5: 0.000852, l6: 0.001253

[epoch: 195/1000, batch:  1032/ 1052, ite: 51280] train loss: 0.006052, tar: 0.000452 
[Epoch 195/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000500, l1: 0.000526, l2: 0.000490, l3: 0.000453, l4: 0.000746, l5: 0.000829, l6: 0.001769

[epoch: 196/1000, batch:    60/ 1052, ite: 51300] train loss: 0.006052, tar: 0.000452 
l0: 0.000435, l1: 0.000409, l2: 0.000502, l3: 0.000741, l4: 0.001079, l5: 0.001747, l6: 0.002871

[epoch: 196/1000, batch:   140/ 1052, ite: 51320] train loss: 0.006050, tar: 0.000452 
l0: 0.000283, l1: 0.000284, l2: 0.000286, l3: 0.000330, l4: 0.000421, l5: 0.001133, l6: 0.001756

[epoch: 196/1000, batch:   220/ 1052, ite: 51340] train loss: 0.006049, tar: 0.000452 
l0: 0.000911, l1: 0.000959, l2: 0.000978, l3: 0.000964, l4: 0.001188, l5: 0.002795, l6: 0.005820

[epoch: 196/1000, batch:   300/ 1052, ite: 51360] train loss: 0.006049, tar: 0.000451 
l0: 0.000578, l1: 0.000600, l2: 0.000694, l3: 0.000763, l4: 0.001247, l5: 0.002204, l6: 0.003163

[epoch: 196/1000, batch:   380/ 1052, ite: 51380] train loss: 0.006049, tar: 0.000451 
l0: 0.000217, l1: 0.000222, l2: 0.000211, l3: 0.000231, l4: 0.000323, l5: 0.000789, l6: 0.000695

[epoch: 196/1000, batch:   460/ 1052, ite: 51400] train loss: 0.006048, tar: 0.000451 
l0: 0.000201, l1: 0.000189, l2: 0.000215, l3: 0.000275, l4: 0.000541, l5: 0.001125, l6: 0.001563

[epoch: 196/1000, batch:   540/ 1052, ite: 51420] train loss: 0.006045, tar: 0.000451 
l0: 0.000312, l1: 0.000321, l2: 0.000372, l3: 0.000343, l4: 0.000350, l5: 0.000867, l6: 0.001389

[epoch: 196/1000, batch:   620/ 1052, ite: 51440] train loss: 0.006046, tar: 0.000451 
l0: 0.000484, l1: 0.000510, l2: 0.000482, l3: 0.000524, l4: 0.000807, l5: 0.001491, l6: 0.002517

[epoch: 196/1000, batch:   700/ 1052, ite: 51460] train loss: 0.006047, tar: 0.000451 
l0: 0.000403, l1: 0.000432, l2: 0.000454, l3: 0.000407, l4: 0.000659, l5: 0.001076, l6: 0.001361

[epoch: 196/1000, batch:   780/ 1052, ite: 51480] train loss: 0.006048, tar: 0.000451 
l0: 0.000510, l1: 0.000518, l2: 0.000543, l3: 0.000566, l4: 0.000867, l5: 0.001192, l6: 0.001903

[epoch: 196/1000, batch:   860/ 1052, ite: 51500] train loss: 0.006047, tar: 0.000451 
l0: 0.000422, l1: 0.000419, l2: 0.000418, l3: 0.000476, l4: 0.000940, l5: 0.001265, l6: 0.002264

[epoch: 196/1000, batch:   940/ 1052, ite: 51520] train loss: 0.006047, tar: 0.000451 
l0: 0.000335, l1: 0.000380, l2: 0.000357, l3: 0.000436, l4: 0.000555, l5: 0.001165, l6: 0.002001

[epoch: 196/1000, batch:  1020/ 1052, ite: 51540] train loss: 0.006046, tar: 0.000451 
[Epoch 196/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000501, l1: 0.000504, l2: 0.000541, l3: 0.000635, l4: 0.001028, l5: 0.002273, l6: 0.002517

[epoch: 197/1000, batch:    48/ 1052, ite: 51560] train loss: 0.006047, tar: 0.000451 
l0: 0.000331, l1: 0.000335, l2: 0.000380, l3: 0.000404, l4: 0.000413, l5: 0.000653, l6: 0.001462

[epoch: 197/1000, batch:   128/ 1052, ite: 51580] train loss: 0.006045, tar: 0.000451 
l0: 0.000330, l1: 0.000328, l2: 0.000340, l3: 0.000370, l4: 0.000468, l5: 0.000880, l6: 0.001431

[epoch: 197/1000, batch:   208/ 1052, ite: 51600] train loss: 0.006045, tar: 0.000451 
l0: 0.000604, l1: 0.000572, l2: 0.000636, l3: 0.000799, l4: 0.000865, l5: 0.000944, l6: 0.001786

[epoch: 197/1000, batch:   288/ 1052, ite: 51620] train loss: 0.006044, tar: 0.000451 
l0: 0.000379, l1: 0.000377, l2: 0.000419, l3: 0.000494, l4: 0.000771, l5: 0.001564, l6: 0.001792

[epoch: 197/1000, batch:   368/ 1052, ite: 51640] train loss: 0.006044, tar: 0.000451 
l0: 0.000443, l1: 0.000443, l2: 0.000460, l3: 0.000582, l4: 0.000808, l5: 0.001163, l6: 0.001789

[epoch: 197/1000, batch:   448/ 1052, ite: 51660] train loss: 0.006043, tar: 0.000451 
l0: 0.000246, l1: 0.000237, l2: 0.000256, l3: 0.000327, l4: 0.000548, l5: 0.000862, l6: 0.001382

[epoch: 197/1000, batch:   528/ 1052, ite: 51680] train loss: 0.006043, tar: 0.000451 
l0: 0.000522, l1: 0.000523, l2: 0.000527, l3: 0.000621, l4: 0.000796, l5: 0.001047, l6: 0.002708

[epoch: 197/1000, batch:   608/ 1052, ite: 51700] train loss: 0.006043, tar: 0.000451 
l0: 0.000242, l1: 0.000266, l2: 0.000255, l3: 0.000267, l4: 0.000435, l5: 0.000662, l6: 0.000844

[epoch: 197/1000, batch:   688/ 1052, ite: 51720] train loss: 0.006042, tar: 0.000451 
l0: 0.000240, l1: 0.000248, l2: 0.000266, l3: 0.000286, l4: 0.000543, l5: 0.001017, l6: 0.001208

[epoch: 197/1000, batch:   768/ 1052, ite: 51740] train loss: 0.006042, tar: 0.000451 
l0: 0.000356, l1: 0.000379, l2: 0.000372, l3: 0.000357, l4: 0.000665, l5: 0.001242, l6: 0.002204

[epoch: 197/1000, batch:   848/ 1052, ite: 51760] train loss: 0.006041, tar: 0.000450 
l0: 0.000363, l1: 0.000358, l2: 0.000382, l3: 0.000396, l4: 0.000508, l5: 0.000845, l6: 0.001993

[epoch: 197/1000, batch:   928/ 1052, ite: 51780] train loss: 0.006040, tar: 0.000450 
l0: 0.000244, l1: 0.000262, l2: 0.000245, l3: 0.000303, l4: 0.000566, l5: 0.000725, l6: 0.001438

[epoch: 197/1000, batch:  1008/ 1052, ite: 51800] train loss: 0.006040, tar: 0.000450 
[Epoch 197/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000418, l1: 0.000441, l2: 0.000429, l3: 0.000486, l4: 0.000728, l5: 0.001236, l6: 0.002497

[epoch: 198/1000, batch:    36/ 1052, ite: 51820] train loss: 0.006040, tar: 0.000450 
l0: 0.000732, l1: 0.000718, l2: 0.000734, l3: 0.000709, l4: 0.000868, l5: 0.001237, l6: 0.002092

[epoch: 198/1000, batch:   116/ 1052, ite: 51840] train loss: 0.006040, tar: 0.000450 
l0: 0.000143, l1: 0.000147, l2: 0.000105, l3: 0.000165, l4: 0.000300, l5: 0.000458, l6: 0.000714

[epoch: 198/1000, batch:   196/ 1052, ite: 51860] train loss: 0.006038, tar: 0.000450 
l0: 0.000276, l1: 0.000273, l2: 0.000288, l3: 0.000371, l4: 0.000458, l5: 0.000965, l6: 0.001255

[epoch: 198/1000, batch:   276/ 1052, ite: 51880] train loss: 0.006038, tar: 0.000450 
l0: 0.000307, l1: 0.000305, l2: 0.000352, l3: 0.000412, l4: 0.000471, l5: 0.000955, l6: 0.001453

[epoch: 198/1000, batch:   356/ 1052, ite: 51900] train loss: 0.006038, tar: 0.000450 
l0: 0.000796, l1: 0.000819, l2: 0.000796, l3: 0.000822, l4: 0.001011, l5: 0.001744, l6: 0.002376

[epoch: 198/1000, batch:   436/ 1052, ite: 51920] train loss: 0.006039, tar: 0.000450 
l0: 0.000296, l1: 0.000298, l2: 0.000328, l3: 0.000371, l4: 0.000472, l5: 0.000807, l6: 0.001280

[epoch: 198/1000, batch:   516/ 1052, ite: 51940] train loss: 0.006038, tar: 0.000450 
l0: 0.000423, l1: 0.000394, l2: 0.000383, l3: 0.000591, l4: 0.000582, l5: 0.000865, l6: 0.001219

[epoch: 198/1000, batch:   596/ 1052, ite: 51960] train loss: 0.006039, tar: 0.000450 
l0: 0.000163, l1: 0.000155, l2: 0.000177, l3: 0.000230, l4: 0.000358, l5: 0.000823, l6: 0.001494

[epoch: 198/1000, batch:   676/ 1052, ite: 51980] train loss: 0.006038, tar: 0.000450 
l0: 0.000367, l1: 0.000363, l2: 0.000392, l3: 0.000428, l4: 0.000534, l5: 0.001061, l6: 0.001254

[epoch: 198/1000, batch:   756/ 1052, ite: 52000] train loss: 0.006037, tar: 0.000450 
l0: 0.000340, l1: 0.000326, l2: 0.000400, l3: 0.000441, l4: 0.000570, l5: 0.001104, l6: 0.001388

[epoch: 198/1000, batch:   836/ 1052, ite: 52020] train loss: 0.006036, tar: 0.000450 
l0: 0.000287, l1: 0.000287, l2: 0.000337, l3: 0.000341, l4: 0.000458, l5: 0.001104, l6: 0.001406

[epoch: 198/1000, batch:   916/ 1052, ite: 52040] train loss: 0.006035, tar: 0.000449 
l0: 0.000560, l1: 0.000566, l2: 0.000556, l3: 0.000533, l4: 0.000802, l5: 0.001293, l6: 0.001444

[epoch: 198/1000, batch:   996/ 1052, ite: 52060] train loss: 0.006033, tar: 0.000449 
[Epoch 198/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000288, l1: 0.000291, l2: 0.000303, l3: 0.000358, l4: 0.000459, l5: 0.001072, l6: 0.001723

[epoch: 199/1000, batch:    24/ 1052, ite: 52080] train loss: 0.006033, tar: 0.000449 
l0: 0.000382, l1: 0.000385, l2: 0.000390, l3: 0.000426, l4: 0.000476, l5: 0.001179, l6: 0.001181

[epoch: 199/1000, batch:   104/ 1052, ite: 52100] train loss: 0.006034, tar: 0.000449 
l0: 0.000181, l1: 0.000186, l2: 0.000171, l3: 0.000248, l4: 0.000327, l5: 0.000685, l6: 0.001032

[epoch: 199/1000, batch:   184/ 1052, ite: 52120] train loss: 0.006033, tar: 0.000449 
l0: 0.000250, l1: 0.000262, l2: 0.000264, l3: 0.000288, l4: 0.000275, l5: 0.000665, l6: 0.001133

[epoch: 199/1000, batch:   264/ 1052, ite: 52140] train loss: 0.006031, tar: 0.000449 
l0: 0.000315, l1: 0.000302, l2: 0.000320, l3: 0.000315, l4: 0.000552, l5: 0.000885, l6: 0.001510

[epoch: 199/1000, batch:   344/ 1052, ite: 52160] train loss: 0.006028, tar: 0.000449 
l0: 0.000400, l1: 0.000408, l2: 0.000421, l3: 0.000442, l4: 0.000785, l5: 0.001362, l6: 0.002889

[epoch: 199/1000, batch:   424/ 1052, ite: 52180] train loss: 0.006027, tar: 0.000448 
l0: 0.000227, l1: 0.000235, l2: 0.000289, l3: 0.000359, l4: 0.000551, l5: 0.000835, l6: 0.001612

[epoch: 199/1000, batch:   504/ 1052, ite: 52200] train loss: 0.006026, tar: 0.000448 
l0: 0.000638, l1: 0.000665, l2: 0.000653, l3: 0.000743, l4: 0.001372, l5: 0.001719, l6: 0.003533

[epoch: 199/1000, batch:   584/ 1052, ite: 52220] train loss: 0.006027, tar: 0.000448 
l0: 0.000317, l1: 0.000319, l2: 0.000376, l3: 0.000416, l4: 0.000512, l5: 0.000676, l6: 0.001572

[epoch: 199/1000, batch:   664/ 1052, ite: 52240] train loss: 0.006026, tar: 0.000448 
l0: 0.000602, l1: 0.000619, l2: 0.000614, l3: 0.000583, l4: 0.000961, l5: 0.002287, l6: 0.003368

[epoch: 199/1000, batch:   744/ 1052, ite: 52260] train loss: 0.006027, tar: 0.000448 
l0: 0.000876, l1: 0.000839, l2: 0.000892, l3: 0.001076, l4: 0.001433, l5: 0.002319, l6: 0.004769

[epoch: 199/1000, batch:   824/ 1052, ite: 52280] train loss: 0.006027, tar: 0.000448 
l0: 0.000395, l1: 0.000399, l2: 0.000389, l3: 0.000458, l4: 0.000771, l5: 0.001299, l6: 0.002172

[epoch: 199/1000, batch:   904/ 1052, ite: 52300] train loss: 0.006026, tar: 0.000448 
l0: 0.000327, l1: 0.000334, l2: 0.000333, l3: 0.000393, l4: 0.000643, l5: 0.001304, l6: 0.002181

[epoch: 199/1000, batch:   984/ 1052, ite: 52320] train loss: 0.006026, tar: 0.000448 
[Epoch 199/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000330, l1: 0.000328, l2: 0.000385, l3: 0.000453, l4: 0.000676, l5: 0.001386, l6: 0.002567

[epoch: 200/1000, batch:    12/ 1052, ite: 52340] train loss: 0.006025, tar: 0.000448 
l0: 0.000439, l1: 0.000464, l2: 0.000468, l3: 0.000418, l4: 0.000786, l5: 0.001435, l6: 0.001730

[epoch: 200/1000, batch:    92/ 1052, ite: 52360] train loss: 0.006024, tar: 0.000448 
l0: 0.000266, l1: 0.000265, l2: 0.000282, l3: 0.000330, l4: 0.000459, l5: 0.000753, l6: 0.001412

[epoch: 200/1000, batch:   172/ 1052, ite: 52380] train loss: 0.006022, tar: 0.000447 
l0: 0.000314, l1: 0.000336, l2: 0.000332, l3: 0.000335, l4: 0.000477, l5: 0.000879, l6: 0.001903

[epoch: 200/1000, batch:   252/ 1052, ite: 52400] train loss: 0.006021, tar: 0.000447 
l0: 0.000276, l1: 0.000287, l2: 0.000296, l3: 0.000356, l4: 0.000518, l5: 0.000889, l6: 0.001193

[epoch: 200/1000, batch:   332/ 1052, ite: 52420] train loss: 0.006021, tar: 0.000447 
l0: 0.000243, l1: 0.000239, l2: 0.000246, l3: 0.000309, l4: 0.000295, l5: 0.000755, l6: 0.001304

[epoch: 200/1000, batch:   412/ 1052, ite: 52440] train loss: 0.006020, tar: 0.000447 
l0: 0.000648, l1: 0.000712, l2: 0.000656, l3: 0.000684, l4: 0.001154, l5: 0.001968, l6: 0.002816

[epoch: 200/1000, batch:   492/ 1052, ite: 52460] train loss: 0.006020, tar: 0.000447 
l0: 0.000266, l1: 0.000284, l2: 0.000276, l3: 0.000292, l4: 0.000427, l5: 0.000896, l6: 0.001468

[epoch: 200/1000, batch:   572/ 1052, ite: 52480] train loss: 0.006020, tar: 0.000447 
l0: 0.000195, l1: 0.000202, l2: 0.000214, l3: 0.000253, l4: 0.000380, l5: 0.000534, l6: 0.000910

[epoch: 200/1000, batch:   652/ 1052, ite: 52500] train loss: 0.006021, tar: 0.000447 
l0: 0.000371, l1: 0.000365, l2: 0.000427, l3: 0.000501, l4: 0.000771, l5: 0.001278, l6: 0.001718

[epoch: 200/1000, batch:   732/ 1052, ite: 52520] train loss: 0.006023, tar: 0.000447 
l0: 0.000290, l1: 0.000290, l2: 0.000309, l3: 0.000427, l4: 0.000662, l5: 0.001176, l6: 0.001868

[epoch: 200/1000, batch:   812/ 1052, ite: 52540] train loss: 0.006024, tar: 0.000447 
l0: 0.000437, l1: 0.000440, l2: 0.000443, l3: 0.000524, l4: 0.000726, l5: 0.001026, l6: 0.002651

[epoch: 200/1000, batch:   892/ 1052, ite: 52560] train loss: 0.006024, tar: 0.000448 
l0: 0.000444, l1: 0.000456, l2: 0.000475, l3: 0.000525, l4: 0.000745, l5: 0.001582, l6: 0.002220

[epoch: 200/1000, batch:   972/ 1052, ite: 52580] train loss: 0.006023, tar: 0.000447 
l0: 0.000400, l1: 0.000447, l2: 0.000466, l3: 0.000495, l4: 0.000534, l5: 0.001281, l6: 0.002728

[epoch: 200/1000, batch:  1052/ 1052, ite: 52600] train loss: 0.006023, tar: 0.000447 
[Epoch 200/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000468, l1: 0.000482, l2: 0.000489, l3: 0.000559, l4: 0.001007, l5: 0.001772, l6: 0.002786

[epoch: 201/1000, batch:    80/ 1052, ite: 52620] train loss: 0.005947, tar: 0.000420 
l0: 0.000315, l1: 0.000313, l2: 0.000340, l3: 0.000463, l4: 0.000730, l5: 0.000965, l6: 0.001990

[epoch: 201/1000, batch:   160/ 1052, ite: 52640] train loss: 0.005904, tar: 0.000439 
l0: 0.000236, l1: 0.000248, l2: 0.000239, l3: 0.000302, l4: 0.000481, l5: 0.000813, l6: 0.001509

[epoch: 201/1000, batch:   240/ 1052, ite: 52660] train loss: 0.005667, tar: 0.000419 
l0: 0.000298, l1: 0.000272, l2: 0.000325, l3: 0.000428, l4: 0.000727, l5: 0.001128, l6: 0.002191

[epoch: 201/1000, batch:   320/ 1052, ite: 52680] train loss: 0.005822, tar: 0.000430 
l0: 0.000391, l1: 0.000385, l2: 0.000449, l3: 0.000450, l4: 0.000829, l5: 0.001105, l6: 0.002359

[epoch: 201/1000, batch:   400/ 1052, ite: 52700] train loss: 0.005792, tar: 0.000421 
l0: 0.000240, l1: 0.000246, l2: 0.000274, l3: 0.000320, l4: 0.000552, l5: 0.000733, l6: 0.001336

[epoch: 201/1000, batch:   480/ 1052, ite: 52720] train loss: 0.005788, tar: 0.000423 
l0: 0.000330, l1: 0.000329, l2: 0.000345, l3: 0.000427, l4: 0.000523, l5: 0.001036, l6: 0.002143

[epoch: 201/1000, batch:   560/ 1052, ite: 52740] train loss: 0.005665, tar: 0.000408 
l0: 0.000705, l1: 0.000648, l2: 0.000700, l3: 0.000829, l4: 0.001451, l5: 0.002219, l6: 0.002459

[epoch: 201/1000, batch:   640/ 1052, ite: 52760] train loss: 0.005607, tar: 0.000403 
l0: 0.000236, l1: 0.000225, l2: 0.000306, l3: 0.000366, l4: 0.000492, l5: 0.001024, l6: 0.001314

[epoch: 201/1000, batch:   720/ 1052, ite: 52780] train loss: 0.005587, tar: 0.000401 
l0: 0.000593, l1: 0.000598, l2: 0.000600, l3: 0.000662, l4: 0.000836, l5: 0.001955, l6: 0.003614

[epoch: 201/1000, batch:   800/ 1052, ite: 52800] train loss: 0.005758, tar: 0.000417 
l0: 0.000445, l1: 0.000449, l2: 0.000449, l3: 0.000538, l4: 0.000933, l5: 0.001264, l6: 0.001729

[epoch: 201/1000, batch:   880/ 1052, ite: 52820] train loss: 0.005723, tar: 0.000414 
l0: 0.000618, l1: 0.000655, l2: 0.000638, l3: 0.000644, l4: 0.001049, l5: 0.001875, l6: 0.003648

[epoch: 201/1000, batch:   960/ 1052, ite: 52840] train loss: 0.005716, tar: 0.000411 
l0: 0.000246, l1: 0.000241, l2: 0.000283, l3: 0.000294, l4: 0.000512, l5: 0.000602, l6: 0.001138

[epoch: 201/1000, batch:  1040/ 1052, ite: 52860] train loss: 0.005743, tar: 0.000414 
[Epoch 201/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000730, l1: 0.000690, l2: 0.000682, l3: 0.000773, l4: 0.000990, l5: 0.001588, l6: 0.002641

[epoch: 202/1000, batch:    68/ 1052, ite: 52880] train loss: 0.005809, tar: 0.000419 
l0: 0.000301, l1: 0.000323, l2: 0.000309, l3: 0.000393, l4: 0.000445, l5: 0.001006, l6: 0.001339

[epoch: 202/1000, batch:   148/ 1052, ite: 52900] train loss: 0.005789, tar: 0.000415 
l0: 0.000705, l1: 0.000722, l2: 0.000714, l3: 0.000876, l4: 0.001430, l5: 0.002426, l6: 0.004903

[epoch: 202/1000, batch:   228/ 1052, ite: 52920] train loss: 0.005789, tar: 0.000413 
l0: 0.000540, l1: 0.000535, l2: 0.000623, l3: 0.000593, l4: 0.000809, l5: 0.001435, l6: 0.002668

[epoch: 202/1000, batch:   308/ 1052, ite: 52940] train loss: 0.005794, tar: 0.000413 
l0: 0.000610, l1: 0.000623, l2: 0.000700, l3: 0.000833, l4: 0.000985, l5: 0.001345, l6: 0.002295

[epoch: 202/1000, batch:   388/ 1052, ite: 52960] train loss: 0.005821, tar: 0.000419 
l0: 0.000597, l1: 0.000613, l2: 0.000567, l3: 0.000546, l4: 0.000701, l5: 0.001396, l6: 0.002720

[epoch: 202/1000, batch:   468/ 1052, ite: 52980] train loss: 0.005837, tar: 0.000422 
l0: 0.000397, l1: 0.000406, l2: 0.000429, l3: 0.000467, l4: 0.000548, l5: 0.001290, l6: 0.001801

[epoch: 202/1000, batch:   548/ 1052, ite: 53000] train loss: 0.005916, tar: 0.000427 
l0: 0.000395, l1: 0.000417, l2: 0.000455, l3: 0.000534, l4: 0.000729, l5: 0.001166, l6: 0.003091

[epoch: 202/1000, batch:   628/ 1052, ite: 53020] train loss: 0.005942, tar: 0.000429 
l0: 0.000562, l1: 0.000554, l2: 0.000492, l3: 0.000671, l4: 0.000844, l5: 0.001714, l6: 0.003483

[epoch: 202/1000, batch:   708/ 1052, ite: 53040] train loss: 0.005959, tar: 0.000431 
l0: 0.000507, l1: 0.000552, l2: 0.000556, l3: 0.000468, l4: 0.000584, l5: 0.000996, l6: 0.002124

[epoch: 202/1000, batch:   788/ 1052, ite: 53060] train loss: 0.005958, tar: 0.000433 
l0: 0.000390, l1: 0.000388, l2: 0.000415, l3: 0.000471, l4: 0.000874, l5: 0.001282, l6: 0.003055

[epoch: 202/1000, batch:   868/ 1052, ite: 53080] train loss: 0.005951, tar: 0.000431 
l0: 0.000392, l1: 0.000416, l2: 0.000744, l3: 0.000710, l4: 0.000623, l5: 0.001215, l6: 0.001195

[epoch: 202/1000, batch:   948/ 1052, ite: 53100] train loss: 0.005955, tar: 0.000432 
l0: 0.000505, l1: 0.000494, l2: 0.000564, l3: 0.000654, l4: 0.000778, l5: 0.001330, l6: 0.002022

[epoch: 202/1000, batch:  1028/ 1052, ite: 53120] train loss: 0.005977, tar: 0.000435 
[Epoch 202/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000338, l1: 0.000368, l2: 0.000387, l3: 0.000415, l4: 0.000788, l5: 0.001463, l6: 0.002081

[epoch: 203/1000, batch:    56/ 1052, ite: 53140] train loss: 0.005968, tar: 0.000433 
l0: 0.000976, l1: 0.001054, l2: 0.000976, l3: 0.000955, l4: 0.001674, l5: 0.001865, l6: 0.003578

[epoch: 203/1000, batch:   136/ 1052, ite: 53160] train loss: 0.005959, tar: 0.000433 
l0: 0.000697, l1: 0.000734, l2: 0.000776, l3: 0.000723, l4: 0.000965, l5: 0.001763, l6: 0.002991

[epoch: 203/1000, batch:   216/ 1052, ite: 53180] train loss: 0.005950, tar: 0.000432 
l0: 0.000362, l1: 0.000371, l2: 0.000429, l3: 0.000499, l4: 0.000732, l5: 0.001204, l6: 0.002102

[epoch: 203/1000, batch:   296/ 1052, ite: 53200] train loss: 0.006192, tar: 0.000480 
l0: 0.000755, l1: 0.000757, l2: 0.000749, l3: 0.000974, l4: 0.001284, l5: 0.001868, l6: 0.002670

[epoch: 203/1000, batch:   376/ 1052, ite: 53220] train loss: 0.006258, tar: 0.000486 
l0: 0.000895, l1: 0.000906, l2: 0.000899, l3: 0.001128, l4: 0.001623, l5: 0.002318, l6: 0.003606

[epoch: 203/1000, batch:   456/ 1052, ite: 53240] train loss: 0.006302, tar: 0.000490 
l0: 0.000506, l1: 0.000504, l2: 0.000572, l3: 0.000613, l4: 0.000618, l5: 0.001068, l6: 0.001531

[epoch: 203/1000, batch:   536/ 1052, ite: 53260] train loss: 0.006339, tar: 0.000494 
l0: 0.000514, l1: 0.000468, l2: 0.000501, l3: 0.000622, l4: 0.000931, l5: 0.001479, l6: 0.002538

[epoch: 203/1000, batch:   616/ 1052, ite: 53280] train loss: 0.006415, tar: 0.000502 
l0: 0.000698, l1: 0.001032, l2: 0.000904, l3: 0.001092, l4: 0.000957, l5: 0.001131, l6: 0.002037

[epoch: 203/1000, batch:   696/ 1052, ite: 53300] train loss: 0.006634, tar: 0.000541 
l0: 0.000583, l1: 0.000602, l2: 0.000692, l3: 0.000650, l4: 0.000741, l5: 0.001429, l6: 0.002329

[epoch: 203/1000, batch:   776/ 1052, ite: 53320] train loss: 0.006667, tar: 0.000545 
l0: 0.000425, l1: 0.000422, l2: 0.000366, l3: 0.000528, l4: 0.001016, l5: 0.000954, l6: 0.002660

[epoch: 203/1000, batch:   856/ 1052, ite: 53340] train loss: 0.006717, tar: 0.000550 
l0: 0.000483, l1: 0.000465, l2: 0.000485, l3: 0.000673, l4: 0.000930, l5: 0.001625, l6: 0.002025

[epoch: 203/1000, batch:   936/ 1052, ite: 53360] train loss: 0.006709, tar: 0.000549 
l0: 0.001174, l1: 0.001117, l2: 0.001310, l3: 0.001292, l4: 0.001708, l5: 0.002928, l6: 0.004303

[epoch: 203/1000, batch:  1016/ 1052, ite: 53380] train loss: 0.006727, tar: 0.000551 
[Epoch 203/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000364, l1: 0.000411, l2: 0.000376, l3: 0.000370, l4: 0.000557, l5: 0.000926, l6: 0.001626

[epoch: 204/1000, batch:    44/ 1052, ite: 53400] train loss: 0.006729, tar: 0.000551 
l0: 0.000516, l1: 0.000711, l2: 0.000514, l3: 0.000719, l4: 0.000638, l5: 0.000956, l6: 0.001429

[epoch: 204/1000, batch:   124/ 1052, ite: 53420] train loss: 0.006731, tar: 0.000552 
l0: 0.000434, l1: 0.000436, l2: 0.000416, l3: 0.000522, l4: 0.000700, l5: 0.001401, l6: 0.001961

[epoch: 204/1000, batch:   204/ 1052, ite: 53440] train loss: 0.006726, tar: 0.000551 
l0: 0.000326, l1: 0.000331, l2: 0.000343, l3: 0.000345, l4: 0.000494, l5: 0.001093, l6: 0.001939

[epoch: 204/1000, batch:   284/ 1052, ite: 53460] train loss: 0.006719, tar: 0.000550 
l0: 0.000454, l1: 0.000457, l2: 0.000444, l3: 0.000508, l4: 0.000666, l5: 0.001138, l6: 0.002002

[epoch: 204/1000, batch:   364/ 1052, ite: 53480] train loss: 0.006742, tar: 0.000552 
l0: 0.000190, l1: 0.000191, l2: 0.000201, l3: 0.000217, l4: 0.000349, l5: 0.000974, l6: 0.001083

[epoch: 204/1000, batch:   444/ 1052, ite: 53500] train loss: 0.006737, tar: 0.000550 
l0: 0.000259, l1: 0.000276, l2: 0.000292, l3: 0.000287, l4: 0.000410, l5: 0.000865, l6: 0.001163

[epoch: 204/1000, batch:   524/ 1052, ite: 53520] train loss: 0.006707, tar: 0.000547 
l0: 0.000310, l1: 0.000319, l2: 0.000314, l3: 0.000387, l4: 0.000478, l5: 0.000723, l6: 0.001437

[epoch: 204/1000, batch:   604/ 1052, ite: 53540] train loss: 0.006723, tar: 0.000548 
l0: 0.000523, l1: 0.000529, l2: 0.000569, l3: 0.000577, l4: 0.000773, l5: 0.001123, l6: 0.002514

[epoch: 204/1000, batch:   684/ 1052, ite: 53560] train loss: 0.006721, tar: 0.000547 
l0: 0.001065, l1: 0.001034, l2: 0.000920, l3: 0.001088, l4: 0.001594, l5: 0.001862, l6: 0.003510

[epoch: 204/1000, batch:   764/ 1052, ite: 53580] train loss: 0.006718, tar: 0.000546 
l0: 0.000733, l1: 0.000819, l2: 0.000840, l3: 0.000798, l4: 0.000990, l5: 0.001575, l6: 0.001597

[epoch: 204/1000, batch:   844/ 1052, ite: 53600] train loss: 0.006692, tar: 0.000544 
l0: 0.000286, l1: 0.000286, l2: 0.000296, l3: 0.000405, l4: 0.000490, l5: 0.000939, l6: 0.001033

[epoch: 204/1000, batch:   924/ 1052, ite: 53620] train loss: 0.006669, tar: 0.000541 
l0: 0.000657, l1: 0.000634, l2: 0.000605, l3: 0.000761, l4: 0.001067, l5: 0.002303, l6: 0.004027

[epoch: 204/1000, batch:  1004/ 1052, ite: 53640] train loss: 0.006670, tar: 0.000541 
[Epoch 204/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000731, l1: 0.000718, l2: 0.000795, l3: 0.000948, l4: 0.001402, l5: 0.002389, l6: 0.004019

[epoch: 205/1000, batch:    32/ 1052, ite: 53660] train loss: 0.006680, tar: 0.000541 
l0: 0.000283, l1: 0.000274, l2: 0.000292, l3: 0.000350, l4: 0.000590, l5: 0.001573, l6: 0.002102

[epoch: 205/1000, batch:   112/ 1052, ite: 53680] train loss: 0.006663, tar: 0.000538 
l0: 0.000563, l1: 0.000539, l2: 0.000571, l3: 0.000621, l4: 0.001229, l5: 0.001687, l6: 0.003581

[epoch: 205/1000, batch:   192/ 1052, ite: 53700] train loss: 0.006639, tar: 0.000536 
l0: 0.001648, l1: 0.002076, l2: 0.001837, l3: 0.001230, l4: 0.001316, l5: 0.001912, l6: 0.003502

[epoch: 205/1000, batch:   272/ 1052, ite: 53720] train loss: 0.006636, tar: 0.000535 
l0: 0.000702, l1: 0.000674, l2: 0.000724, l3: 0.000867, l4: 0.001320, l5: 0.001913, l6: 0.004093

[epoch: 205/1000, batch:   352/ 1052, ite: 53740] train loss: 0.006628, tar: 0.000534 
l0: 0.001154, l1: 0.001284, l2: 0.001230, l3: 0.001032, l4: 0.001596, l5: 0.003137, l6: 0.004893

[epoch: 205/1000, batch:   432/ 1052, ite: 53760] train loss: 0.006612, tar: 0.000532 
l0: 0.000454, l1: 0.000414, l2: 0.000484, l3: 0.000601, l4: 0.000720, l5: 0.001174, l6: 0.002132

[epoch: 205/1000, batch:   512/ 1052, ite: 53780] train loss: 0.006621, tar: 0.000532 
l0: 0.000256, l1: 0.000247, l2: 0.000343, l3: 0.000435, l4: 0.000606, l5: 0.001222, l6: 0.001856

[epoch: 205/1000, batch:   592/ 1052, ite: 53800] train loss: 0.006620, tar: 0.000532 
l0: 0.000327, l1: 0.000314, l2: 0.000364, l3: 0.000455, l4: 0.000645, l5: 0.001005, l6: 0.002336

[epoch: 205/1000, batch:   672/ 1052, ite: 53820] train loss: 0.006605, tar: 0.000530 
l0: 0.000547, l1: 0.000519, l2: 0.000570, l3: 0.000725, l4: 0.001122, l5: 0.001724, l6: 0.002737

[epoch: 205/1000, batch:   752/ 1052, ite: 53840] train loss: 0.006593, tar: 0.000528 
l0: 0.000731, l1: 0.000720, l2: 0.000711, l3: 0.000803, l4: 0.001085, l5: 0.001735, l6: 0.002718

[epoch: 205/1000, batch:   832/ 1052, ite: 53860] train loss: 0.006603, tar: 0.000528 
l0: 0.000171, l1: 0.000170, l2: 0.000184, l3: 0.000202, l4: 0.000415, l5: 0.000737, l6: 0.000792

[epoch: 205/1000, batch:   912/ 1052, ite: 53880] train loss: 0.006586, tar: 0.000527 
l0: 0.000734, l1: 0.000818, l2: 0.000828, l3: 0.000856, l4: 0.000752, l5: 0.001428, l6: 0.002245

[epoch: 205/1000, batch:   992/ 1052, ite: 53900] train loss: 0.006570, tar: 0.000525 
[Epoch 205/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000229, l1: 0.000228, l2: 0.000246, l3: 0.000297, l4: 0.000481, l5: 0.000685, l6: 0.001941

[epoch: 206/1000, batch:    20/ 1052, ite: 53920] train loss: 0.006553, tar: 0.000523 
l0: 0.000449, l1: 0.000437, l2: 0.000474, l3: 0.000508, l4: 0.000630, l5: 0.001084, l6: 0.001878

[epoch: 206/1000, batch:   100/ 1052, ite: 53940] train loss: 0.006547, tar: 0.000521 
l0: 0.000747, l1: 0.000738, l2: 0.000774, l3: 0.000895, l4: 0.001022, l5: 0.001607, l6: 0.002881

[epoch: 206/1000, batch:   180/ 1052, ite: 53960] train loss: 0.006554, tar: 0.000521 
l0: 0.000280, l1: 0.000282, l2: 0.000315, l3: 0.000359, l4: 0.000472, l5: 0.000763, l6: 0.001178

[epoch: 206/1000, batch:   260/ 1052, ite: 53980] train loss: 0.006537, tar: 0.000519 
l0: 0.000566, l1: 0.000585, l2: 0.000615, l3: 0.000588, l4: 0.000755, l5: 0.001202, l6: 0.001342

[epoch: 206/1000, batch:   340/ 1052, ite: 54000] train loss: 0.006526, tar: 0.000518 
l0: 0.000357, l1: 0.000343, l2: 0.000358, l3: 0.000451, l4: 0.000664, l5: 0.000860, l6: 0.001437

[epoch: 206/1000, batch:   420/ 1052, ite: 54020] train loss: 0.006505, tar: 0.000516 
l0: 0.000296, l1: 0.000295, l2: 0.000299, l3: 0.000396, l4: 0.000578, l5: 0.001003, l6: 0.001457

[epoch: 206/1000, batch:   500/ 1052, ite: 54040] train loss: 0.006498, tar: 0.000515 
l0: 0.000276, l1: 0.000274, l2: 0.000306, l3: 0.000346, l4: 0.000496, l5: 0.001140, l6: 0.001315

[epoch: 206/1000, batch:   580/ 1052, ite: 54060] train loss: 0.006490, tar: 0.000513 
l0: 0.000403, l1: 0.000412, l2: 0.000429, l3: 0.000423, l4: 0.000629, l5: 0.001265, l6: 0.001983

[epoch: 206/1000, batch:   660/ 1052, ite: 54080] train loss: 0.006476, tar: 0.000512 
l0: 0.000350, l1: 0.000355, l2: 0.000345, l3: 0.000423, l4: 0.000578, l5: 0.001256, l6: 0.001675

[epoch: 206/1000, batch:   740/ 1052, ite: 54100] train loss: 0.006485, tar: 0.000512 
l0: 0.000405, l1: 0.000400, l2: 0.000408, l3: 0.000466, l4: 0.000674, l5: 0.000854, l6: 0.002271

[epoch: 206/1000, batch:   820/ 1052, ite: 54120] train loss: 0.006470, tar: 0.000510 
l0: 0.000554, l1: 0.000540, l2: 0.000646, l3: 0.000787, l4: 0.001083, l5: 0.001569, l6: 0.002640

[epoch: 206/1000, batch:   900/ 1052, ite: 54140] train loss: 0.006462, tar: 0.000509 
l0: 0.000213, l1: 0.000202, l2: 0.000231, l3: 0.000292, l4: 0.000354, l5: 0.000651, l6: 0.000895

[epoch: 206/1000, batch:   980/ 1052, ite: 54160] train loss: 0.006454, tar: 0.000507 
[Epoch 206/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000253, l1: 0.000273, l2: 0.000259, l3: 0.000245, l4: 0.000449, l5: 0.000914, l6: 0.001744

[epoch: 207/1000, batch:     8/ 1052, ite: 54180] train loss: 0.006453, tar: 0.000506 
l0: 0.000508, l1: 0.000516, l2: 0.000495, l3: 0.000552, l4: 0.001076, l5: 0.001772, l6: 0.002794

[epoch: 207/1000, batch:    88/ 1052, ite: 54200] train loss: 0.006446, tar: 0.000505 
l0: 0.000494, l1: 0.000476, l2: 0.000530, l3: 0.000740, l4: 0.001238, l5: 0.001664, l6: 0.002977

[epoch: 207/1000, batch:   168/ 1052, ite: 54220] train loss: 0.006438, tar: 0.000504 
l0: 0.000309, l1: 0.000288, l2: 0.000340, l3: 0.000550, l4: 0.000819, l5: 0.001220, l6: 0.001988

[epoch: 207/1000, batch:   248/ 1052, ite: 54240] train loss: 0.006434, tar: 0.000503 
l0: 0.000310, l1: 0.000324, l2: 0.000347, l3: 0.000321, l4: 0.000521, l5: 0.000663, l6: 0.001441

[epoch: 207/1000, batch:   328/ 1052, ite: 54260] train loss: 0.006420, tar: 0.000502 
l0: 0.000530, l1: 0.000527, l2: 0.000568, l3: 0.000643, l4: 0.000923, l5: 0.001353, l6: 0.003445

[epoch: 207/1000, batch:   408/ 1052, ite: 54280] train loss: 0.006418, tar: 0.000501 
l0: 0.000215, l1: 0.000210, l2: 0.000231, l3: 0.000296, l4: 0.000507, l5: 0.000890, l6: 0.001295

[epoch: 207/1000, batch:   488/ 1052, ite: 54300] train loss: 0.006409, tar: 0.000500 
l0: 0.000336, l1: 0.000333, l2: 0.000375, l3: 0.000512, l4: 0.000590, l5: 0.001042, l6: 0.001822

[epoch: 207/1000, batch:   568/ 1052, ite: 54320] train loss: 0.006399, tar: 0.000499 
l0: 0.000811, l1: 0.000849, l2: 0.000810, l3: 0.000985, l4: 0.001303, l5: 0.002385, l6: 0.003603

[epoch: 207/1000, batch:   648/ 1052, ite: 54340] train loss: 0.006395, tar: 0.000498 
l0: 0.000197, l1: 0.000194, l2: 0.000211, l3: 0.000245, l4: 0.000406, l5: 0.000890, l6: 0.001222

[epoch: 207/1000, batch:   728/ 1052, ite: 54360] train loss: 0.006384, tar: 0.000496 
l0: 0.000206, l1: 0.000204, l2: 0.000235, l3: 0.000354, l4: 0.000573, l5: 0.000668, l6: 0.001620

[epoch: 207/1000, batch:   808/ 1052, ite: 54380] train loss: 0.006372, tar: 0.000495 
l0: 0.000402, l1: 0.000422, l2: 0.000396, l3: 0.000457, l4: 0.000718, l5: 0.001008, l6: 0.001967

[epoch: 207/1000, batch:   888/ 1052, ite: 54400] train loss: 0.006366, tar: 0.000494 
l0: 0.000279, l1: 0.000301, l2: 0.000298, l3: 0.000267, l4: 0.000407, l5: 0.000739, l6: 0.001551

[epoch: 207/1000, batch:   968/ 1052, ite: 54420] train loss: 0.006367, tar: 0.000494 
l0: 0.000244, l1: 0.000246, l2: 0.000271, l3: 0.000285, l4: 0.000422, l5: 0.000691, l6: 0.001241

[epoch: 207/1000, batch:  1048/ 1052, ite: 54440] train loss: 0.006365, tar: 0.000493 
[Epoch 207/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000251, l1: 0.000257, l2: 0.000273, l3: 0.000276, l4: 0.000390, l5: 0.001159, l6: 0.001868

[epoch: 208/1000, batch:    76/ 1052, ite: 54460] train loss: 0.006360, tar: 0.000492 
l0: 0.000274, l1: 0.000297, l2: 0.000270, l3: 0.000292, l4: 0.000458, l5: 0.000792, l6: 0.001108

[epoch: 208/1000, batch:   156/ 1052, ite: 54480] train loss: 0.006364, tar: 0.000492 
l0: 0.000345, l1: 0.000356, l2: 0.000369, l3: 0.000372, l4: 0.000713, l5: 0.001070, l6: 0.002181

[epoch: 208/1000, batch:   236/ 1052, ite: 54500] train loss: 0.006356, tar: 0.000491 
l0: 0.001219, l1: 0.001343, l2: 0.001292, l3: 0.001288, l4: 0.001540, l5: 0.002393, l6: 0.005189

[epoch: 208/1000, batch:   316/ 1052, ite: 54520] train loss: 0.006355, tar: 0.000490 
l0: 0.000189, l1: 0.000195, l2: 0.000183, l3: 0.000255, l4: 0.000471, l5: 0.000786, l6: 0.001280

[epoch: 208/1000, batch:   396/ 1052, ite: 54540] train loss: 0.006352, tar: 0.000489 
l0: 0.000243, l1: 0.000236, l2: 0.000245, l3: 0.000324, l4: 0.000442, l5: 0.000827, l6: 0.001653

[epoch: 208/1000, batch:   476/ 1052, ite: 54560] train loss: 0.006355, tar: 0.000489 
l0: 0.000494, l1: 0.000497, l2: 0.000509, l3: 0.000536, l4: 0.000759, l5: 0.001485, l6: 0.003092

[epoch: 208/1000, batch:   556/ 1052, ite: 54580] train loss: 0.006347, tar: 0.000488 
l0: 0.000362, l1: 0.000386, l2: 0.000408, l3: 0.000449, l4: 0.000626, l5: 0.001373, l6: 0.001766

[epoch: 208/1000, batch:   636/ 1052, ite: 54600] train loss: 0.006335, tar: 0.000487 
l0: 0.000464, l1: 0.000472, l2: 0.000531, l3: 0.000443, l4: 0.000692, l5: 0.000906, l6: 0.001275

[epoch: 208/1000, batch:   716/ 1052, ite: 54620] train loss: 0.006325, tar: 0.000486 
l0: 0.000306, l1: 0.000303, l2: 0.000337, l3: 0.000437, l4: 0.000607, l5: 0.000957, l6: 0.001732

[epoch: 208/1000, batch:   796/ 1052, ite: 54640] train loss: 0.006315, tar: 0.000484 
l0: 0.000264, l1: 0.000259, l2: 0.000307, l3: 0.000430, l4: 0.000711, l5: 0.001370, l6: 0.001985

[epoch: 208/1000, batch:   876/ 1052, ite: 54660] train loss: 0.006315, tar: 0.000484 
l0: 0.000285, l1: 0.000288, l2: 0.000294, l3: 0.000368, l4: 0.000613, l5: 0.001136, l6: 0.002318

[epoch: 208/1000, batch:   956/ 1052, ite: 54680] train loss: 0.006301, tar: 0.000482 
l0: 0.000519, l1: 0.000521, l2: 0.000529, l3: 0.000577, l4: 0.000948, l5: 0.001789, l6: 0.003244

[epoch: 208/1000, batch:  1036/ 1052, ite: 54700] train loss: 0.006286, tar: 0.000481 
[Epoch 208/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000227, l1: 0.000231, l2: 0.000231, l3: 0.000279, l4: 0.000421, l5: 0.000687, l6: 0.001375

[epoch: 209/1000, batch:    64/ 1052, ite: 54720] train loss: 0.006283, tar: 0.000480 
l0: 0.000407, l1: 0.000402, l2: 0.000443, l3: 0.000514, l4: 0.000822, l5: 0.001467, l6: 0.002398

[epoch: 209/1000, batch:   144/ 1052, ite: 54740] train loss: 0.006280, tar: 0.000480 
l0: 0.000920, l1: 0.000924, l2: 0.000938, l3: 0.000967, l4: 0.001301, l5: 0.002053, l6: 0.004551

[epoch: 209/1000, batch:   224/ 1052, ite: 54760] train loss: 0.006274, tar: 0.000479 
l0: 0.000676, l1: 0.000685, l2: 0.000722, l3: 0.000701, l4: 0.000816, l5: 0.001083, l6: 0.001765

[epoch: 209/1000, batch:   304/ 1052, ite: 54780] train loss: 0.006272, tar: 0.000479 
l0: 0.000344, l1: 0.000341, l2: 0.000408, l3: 0.000389, l4: 0.000636, l5: 0.001289, l6: 0.002136

[epoch: 209/1000, batch:   384/ 1052, ite: 54800] train loss: 0.006270, tar: 0.000478 
l0: 0.000318, l1: 0.000320, l2: 0.000359, l3: 0.000408, l4: 0.000742, l5: 0.001296, l6: 0.001827

[epoch: 209/1000, batch:   464/ 1052, ite: 54820] train loss: 0.006265, tar: 0.000477 
l0: 0.000622, l1: 0.000672, l2: 0.000621, l3: 0.000679, l4: 0.000786, l5: 0.001734, l6: 0.003033

[epoch: 209/1000, batch:   544/ 1052, ite: 54840] train loss: 0.006255, tar: 0.000476 
l0: 0.000405, l1: 0.000447, l2: 0.000386, l3: 0.000357, l4: 0.000483, l5: 0.000780, l6: 0.001189

[epoch: 209/1000, batch:   624/ 1052, ite: 54860] train loss: 0.006254, tar: 0.000476 
l0: 0.000249, l1: 0.000239, l2: 0.000251, l3: 0.000356, l4: 0.000431, l5: 0.000735, l6: 0.001286

[epoch: 209/1000, batch:   704/ 1052, ite: 54880] train loss: 0.006245, tar: 0.000475 
l0: 0.000341, l1: 0.000327, l2: 0.000416, l3: 0.000572, l4: 0.000707, l5: 0.001499, l6: 0.002187

[epoch: 209/1000, batch:   784/ 1052, ite: 54900] train loss: 0.006245, tar: 0.000474 
l0: 0.000618, l1: 0.000572, l2: 0.000696, l3: 0.000857, l4: 0.001225, l5: 0.002113, l6: 0.003264

[epoch: 209/1000, batch:   864/ 1052, ite: 54920] train loss: 0.006239, tar: 0.000473 
l0: 0.000301, l1: 0.000319, l2: 0.000286, l3: 0.000312, l4: 0.000355, l5: 0.001041, l6: 0.001599

[epoch: 209/1000, batch:   944/ 1052, ite: 54940] train loss: 0.006229, tar: 0.000472 
l0: 0.000779, l1: 0.000827, l2: 0.000752, l3: 0.000671, l4: 0.000870, l5: 0.001582, l6: 0.002288

[epoch: 209/1000, batch:  1024/ 1052, ite: 54960] train loss: 0.006223, tar: 0.000471 
[Epoch 209/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000338, l1: 0.000338, l2: 0.000367, l3: 0.000408, l4: 0.000664, l5: 0.001155, l6: 0.001995

[epoch: 210/1000, batch:    52/ 1052, ite: 54980] train loss: 0.006214, tar: 0.000470 
l0: 0.000357, l1: 0.000361, l2: 0.000398, l3: 0.000468, l4: 0.000677, l5: 0.001110, l6: 0.002760

[epoch: 210/1000, batch:   132/ 1052, ite: 55000] train loss: 0.006211, tar: 0.000469 
l0: 0.000413, l1: 0.000411, l2: 0.000427, l3: 0.000501, l4: 0.000701, l5: 0.001112, l6: 0.002582

[epoch: 210/1000, batch:   212/ 1052, ite: 55020] train loss: 0.006202, tar: 0.000469 
l0: 0.000195, l1: 0.000200, l2: 0.000193, l3: 0.000234, l4: 0.000311, l5: 0.000773, l6: 0.001171

[epoch: 210/1000, batch:   292/ 1052, ite: 55040] train loss: 0.006198, tar: 0.000468 
l0: 0.000462, l1: 0.000468, l2: 0.000485, l3: 0.000498, l4: 0.000817, l5: 0.001556, l6: 0.003088

[epoch: 210/1000, batch:   372/ 1052, ite: 55060] train loss: 0.006199, tar: 0.000467 
l0: 0.000328, l1: 0.000328, l2: 0.000345, l3: 0.000471, l4: 0.000732, l5: 0.001401, l6: 0.002053

[epoch: 210/1000, batch:   452/ 1052, ite: 55080] train loss: 0.006197, tar: 0.000467 
l0: 0.000698, l1: 0.000680, l2: 0.000739, l3: 0.000904, l4: 0.001074, l5: 0.002009, l6: 0.003499

[epoch: 210/1000, batch:   532/ 1052, ite: 55100] train loss: 0.006196, tar: 0.000466 
l0: 0.000461, l1: 0.000456, l2: 0.000474, l3: 0.000584, l4: 0.000805, l5: 0.001333, l6: 0.001841

[epoch: 210/1000, batch:   612/ 1052, ite: 55120] train loss: 0.006187, tar: 0.000465 
l0: 0.000296, l1: 0.000313, l2: 0.000328, l3: 0.000317, l4: 0.000611, l5: 0.001445, l6: 0.001999

[epoch: 210/1000, batch:   692/ 1052, ite: 55140] train loss: 0.006181, tar: 0.000465 
l0: 0.000897, l1: 0.000879, l2: 0.000913, l3: 0.000992, l4: 0.001226, l5: 0.001802, l6: 0.002266

[epoch: 210/1000, batch:   772/ 1052, ite: 55160] train loss: 0.006175, tar: 0.000464 
l0: 0.000250, l1: 0.000236, l2: 0.000267, l3: 0.000413, l4: 0.000652, l5: 0.001206, l6: 0.001641

[epoch: 210/1000, batch:   852/ 1052, ite: 55180] train loss: 0.006167, tar: 0.000463 
l0: 0.000764, l1: 0.000762, l2: 0.000797, l3: 0.000873, l4: 0.001240, l5: 0.002355, l6: 0.002633

[epoch: 210/1000, batch:   932/ 1052, ite: 55200] train loss: 0.006163, tar: 0.000463 
l0: 0.000226, l1: 0.000233, l2: 0.000253, l3: 0.000264, l4: 0.000322, l5: 0.000793, l6: 0.001658

[epoch: 210/1000, batch:  1012/ 1052, ite: 55220] train loss: 0.006163, tar: 0.000463 
[Epoch 210/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000713, l1: 0.000701, l2: 0.000782, l3: 0.000895, l4: 0.001091, l5: 0.001428, l6: 0.002415

[epoch: 211/1000, batch:    40/ 1052, ite: 55240] train loss: 0.006161, tar: 0.000462 
l0: 0.000406, l1: 0.000394, l2: 0.000416, l3: 0.000575, l4: 0.001056, l5: 0.001827, l6: 0.002852

[epoch: 211/1000, batch:   120/ 1052, ite: 55260] train loss: 0.006156, tar: 0.000462 
l0: 0.000353, l1: 0.000410, l2: 0.000398, l3: 0.000292, l4: 0.000532, l5: 0.000947, l6: 0.001477

[epoch: 211/1000, batch:   200/ 1052, ite: 55280] train loss: 0.006152, tar: 0.000461 
l0: 0.000236, l1: 0.000234, l2: 0.000252, l3: 0.000334, l4: 0.000606, l5: 0.000890, l6: 0.001430

[epoch: 211/1000, batch:   280/ 1052, ite: 55300] train loss: 0.006143, tar: 0.000460 
l0: 0.000535, l1: 0.000529, l2: 0.000561, l3: 0.000675, l4: 0.001147, l5: 0.001807, l6: 0.003039

[epoch: 211/1000, batch:   360/ 1052, ite: 55320] train loss: 0.006140, tar: 0.000460 
l0: 0.001035, l1: 0.001026, l2: 0.001036, l3: 0.001288, l4: 0.001943, l5: 0.003304, l6: 0.005000

[epoch: 211/1000, batch:   440/ 1052, ite: 55340] train loss: 0.006138, tar: 0.000460 
l0: 0.000282, l1: 0.000259, l2: 0.000298, l3: 0.000436, l4: 0.000889, l5: 0.001111, l6: 0.001994

[epoch: 211/1000, batch:   520/ 1052, ite: 55360] train loss: 0.006136, tar: 0.000459 
l0: 0.000247, l1: 0.000245, l2: 0.000257, l3: 0.000285, l4: 0.000387, l5: 0.001028, l6: 0.001258

[epoch: 211/1000, batch:   600/ 1052, ite: 55380] train loss: 0.006137, tar: 0.000459 
l0: 0.000259, l1: 0.000258, l2: 0.000290, l3: 0.000300, l4: 0.000402, l5: 0.000782, l6: 0.001925

[epoch: 211/1000, batch:   680/ 1052, ite: 55400] train loss: 0.006129, tar: 0.000458 
l0: 0.000233, l1: 0.000239, l2: 0.000251, l3: 0.000381, l4: 0.000654, l5: 0.001159, l6: 0.001360

[epoch: 211/1000, batch:   760/ 1052, ite: 55420] train loss: 0.006125, tar: 0.000457 
l0: 0.000234, l1: 0.000257, l2: 0.000220, l3: 0.000241, l4: 0.000523, l5: 0.000927, l6: 0.001982

[epoch: 211/1000, batch:   840/ 1052, ite: 55440] train loss: 0.006122, tar: 0.000457 
l0: 0.000255, l1: 0.000250, l2: 0.000241, l3: 0.000321, l4: 0.000504, l5: 0.000733, l6: 0.001234

[epoch: 211/1000, batch:   920/ 1052, ite: 55460] train loss: 0.006118, tar: 0.000456 
l0: 0.000403, l1: 0.000407, l2: 0.000441, l3: 0.000484, l4: 0.000607, l5: 0.001067, l6: 0.002467

[epoch: 211/1000, batch:  1000/ 1052, ite: 55480] train loss: 0.006114, tar: 0.000456 
[Epoch 211/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000357, l1: 0.000359, l2: 0.000379, l3: 0.000360, l4: 0.000623, l5: 0.001249, l6: 0.001425

[epoch: 212/1000, batch:    28/ 1052, ite: 55500] train loss: 0.006112, tar: 0.000456 
l0: 0.000487, l1: 0.000472, l2: 0.000473, l3: 0.000649, l4: 0.001209, l5: 0.001634, l6: 0.002195

[epoch: 212/1000, batch:   108/ 1052, ite: 55520] train loss: 0.006106, tar: 0.000455 
l0: 0.000240, l1: 0.000256, l2: 0.000287, l3: 0.000381, l4: 0.000483, l5: 0.001096, l6: 0.001631

[epoch: 212/1000, batch:   188/ 1052, ite: 55540] train loss: 0.006099, tar: 0.000454 
l0: 0.000252, l1: 0.000267, l2: 0.000262, l3: 0.000292, l4: 0.000393, l5: 0.000585, l6: 0.001163

[epoch: 212/1000, batch:   268/ 1052, ite: 55560] train loss: 0.006100, tar: 0.000454 
l0: 0.000227, l1: 0.000235, l2: 0.000221, l3: 0.000325, l4: 0.000502, l5: 0.001021, l6: 0.001455

[epoch: 212/1000, batch:   348/ 1052, ite: 55580] train loss: 0.006093, tar: 0.000453 
l0: 0.000304, l1: 0.000320, l2: 0.000339, l3: 0.000337, l4: 0.000472, l5: 0.000577, l6: 0.001540

[epoch: 212/1000, batch:   428/ 1052, ite: 55600] train loss: 0.006093, tar: 0.000453 
l0: 0.000484, l1: 0.000525, l2: 0.000577, l3: 0.000539, l4: 0.000830, l5: 0.001934, l6: 0.002286

[epoch: 212/1000, batch:   508/ 1052, ite: 55620] train loss: 0.006090, tar: 0.000452 
l0: 0.000941, l1: 0.000991, l2: 0.000971, l3: 0.000956, l4: 0.001019, l5: 0.001619, l6: 0.003158

[epoch: 212/1000, batch:   588/ 1052, ite: 55640] train loss: 0.006087, tar: 0.000452 
l0: 0.001015, l1: 0.001006, l2: 0.001042, l3: 0.001092, l4: 0.001058, l5: 0.001447, l6: 0.002356

[epoch: 212/1000, batch:   668/ 1052, ite: 55660] train loss: 0.006082, tar: 0.000451 
l0: 0.000305, l1: 0.000312, l2: 0.000322, l3: 0.000391, l4: 0.000577, l5: 0.001575, l6: 0.001285

[epoch: 212/1000, batch:   748/ 1052, ite: 55680] train loss: 0.006077, tar: 0.000451 
l0: 0.000396, l1: 0.000390, l2: 0.000405, l3: 0.000476, l4: 0.000651, l5: 0.001193, l6: 0.001678

[epoch: 212/1000, batch:   828/ 1052, ite: 55700] train loss: 0.006072, tar: 0.000450 
l0: 0.000442, l1: 0.000450, l2: 0.000460, l3: 0.000458, l4: 0.000690, l5: 0.001329, l6: 0.001923

[epoch: 212/1000, batch:   908/ 1052, ite: 55720] train loss: 0.006070, tar: 0.000450 
l0: 0.000460, l1: 0.000477, l2: 0.000500, l3: 0.000521, l4: 0.000799, l5: 0.000957, l6: 0.001900

[epoch: 212/1000, batch:   988/ 1052, ite: 55740] train loss: 0.006068, tar: 0.000450 
[Epoch 212/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000353, l1: 0.000356, l2: 0.000350, l3: 0.000518, l4: 0.000690, l5: 0.001083, l6: 0.002140

[epoch: 213/1000, batch:    16/ 1052, ite: 55760] train loss: 0.006073, tar: 0.000450 
l0: 0.000464, l1: 0.000461, l2: 0.000503, l3: 0.000572, l4: 0.000752, l5: 0.001475, l6: 0.003090

[epoch: 213/1000, batch:    96/ 1052, ite: 55780] train loss: 0.006074, tar: 0.000450 
l0: 0.001086, l1: 0.001112, l2: 0.001044, l3: 0.001236, l4: 0.001512, l5: 0.001509, l6: 0.004853

[epoch: 213/1000, batch:   176/ 1052, ite: 55800] train loss: 0.006072, tar: 0.000449 
l0: 0.000376, l1: 0.000367, l2: 0.000433, l3: 0.000535, l4: 0.000720, l5: 0.001593, l6: 0.002625

[epoch: 213/1000, batch:   256/ 1052, ite: 55820] train loss: 0.006070, tar: 0.000449 
l0: 0.000200, l1: 0.000202, l2: 0.000205, l3: 0.000261, l4: 0.000486, l5: 0.000713, l6: 0.002080

[epoch: 213/1000, batch:   336/ 1052, ite: 55840] train loss: 0.006064, tar: 0.000448 
l0: 0.000400, l1: 0.000382, l2: 0.000469, l3: 0.000504, l4: 0.000640, l5: 0.001286, l6: 0.001330

[epoch: 213/1000, batch:   416/ 1052, ite: 55860] train loss: 0.006063, tar: 0.000448 
l0: 0.000464, l1: 0.000472, l2: 0.000473, l3: 0.000556, l4: 0.000700, l5: 0.001410, l6: 0.002171

[epoch: 213/1000, batch:   496/ 1052, ite: 55880] train loss: 0.006056, tar: 0.000447 
l0: 0.000325, l1: 0.000321, l2: 0.000353, l3: 0.000472, l4: 0.000732, l5: 0.000968, l6: 0.002097

[epoch: 213/1000, batch:   576/ 1052, ite: 55900] train loss: 0.006059, tar: 0.000447 
l0: 0.000371, l1: 0.000388, l2: 0.000393, l3: 0.000399, l4: 0.000729, l5: 0.001309, l6: 0.001837

[epoch: 213/1000, batch:   656/ 1052, ite: 55920] train loss: 0.006060, tar: 0.000447 
l0: 0.000314, l1: 0.000313, l2: 0.000334, l3: 0.000363, l4: 0.000707, l5: 0.001029, l6: 0.001599

[epoch: 213/1000, batch:   736/ 1052, ite: 55940] train loss: 0.006057, tar: 0.000447 
l0: 0.000297, l1: 0.000303, l2: 0.000345, l3: 0.000354, l4: 0.000495, l5: 0.000986, l6: 0.001695

[epoch: 213/1000, batch:   816/ 1052, ite: 55960] train loss: 0.006054, tar: 0.000446 
l0: 0.000282, l1: 0.000276, l2: 0.000295, l3: 0.000383, l4: 0.000489, l5: 0.001126, l6: 0.001796

[epoch: 213/1000, batch:   896/ 1052, ite: 55980] train loss: 0.006051, tar: 0.000446 
l0: 0.000370, l1: 0.000361, l2: 0.000382, l3: 0.000444, l4: 0.000572, l5: 0.001180, l6: 0.001240

[epoch: 213/1000, batch:   976/ 1052, ite: 56000] train loss: 0.006049, tar: 0.000445 
[Epoch 213/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000177, l1: 0.000180, l2: 0.000214, l3: 0.000200, l4: 0.000366, l5: 0.000503, l6: 0.000978

[epoch: 214/1000, batch:     4/ 1052, ite: 56020] train loss: 0.006046, tar: 0.000445 
l0: 0.000206, l1: 0.000206, l2: 0.000223, l3: 0.000274, l4: 0.000323, l5: 0.000815, l6: 0.001017

[epoch: 214/1000, batch:    84/ 1052, ite: 56040] train loss: 0.006046, tar: 0.000445 
l0: 0.000338, l1: 0.000348, l2: 0.000376, l3: 0.000424, l4: 0.000577, l5: 0.000960, l6: 0.001885

[epoch: 214/1000, batch:   164/ 1052, ite: 56060] train loss: 0.006045, tar: 0.000445 
l0: 0.000312, l1: 0.000310, l2: 0.000364, l3: 0.000494, l4: 0.000828, l5: 0.001331, l6: 0.001794

[epoch: 214/1000, batch:   244/ 1052, ite: 56080] train loss: 0.006040, tar: 0.000444 
l0: 0.000221, l1: 0.000235, l2: 0.000232, l3: 0.000269, l4: 0.000396, l5: 0.000949, l6: 0.001219

[epoch: 214/1000, batch:   324/ 1052, ite: 56100] train loss: 0.006040, tar: 0.000444 
l0: 0.000242, l1: 0.000242, l2: 0.000270, l3: 0.000368, l4: 0.000445, l5: 0.001038, l6: 0.001611

[epoch: 214/1000, batch:   404/ 1052, ite: 56120] train loss: 0.006036, tar: 0.000444 
l0: 0.000416, l1: 0.000422, l2: 0.000423, l3: 0.000448, l4: 0.000678, l5: 0.001248, l6: 0.001611

[epoch: 214/1000, batch:   484/ 1052, ite: 56140] train loss: 0.006034, tar: 0.000443 
l0: 0.000267, l1: 0.000275, l2: 0.000246, l3: 0.000297, l4: 0.000403, l5: 0.000716, l6: 0.001350

[epoch: 214/1000, batch:   564/ 1052, ite: 56160] train loss: 0.006033, tar: 0.000443 
l0: 0.000183, l1: 0.000186, l2: 0.000205, l3: 0.000282, l4: 0.000514, l5: 0.000813, l6: 0.001364

[epoch: 214/1000, batch:   644/ 1052, ite: 56180] train loss: 0.006029, tar: 0.000443 
l0: 0.000222, l1: 0.000231, l2: 0.000265, l3: 0.000326, l4: 0.000615, l5: 0.001315, l6: 0.001911

[epoch: 214/1000, batch:   724/ 1052, ite: 56200] train loss: 0.006026, tar: 0.000442 
l0: 0.000391, l1: 0.000405, l2: 0.000436, l3: 0.000412, l4: 0.000694, l5: 0.001355, l6: 0.001779

[epoch: 214/1000, batch:   804/ 1052, ite: 56220] train loss: 0.006027, tar: 0.000442 
l0: 0.000211, l1: 0.000215, l2: 0.000225, l3: 0.000262, l4: 0.000470, l5: 0.000897, l6: 0.001632

[epoch: 214/1000, batch:   884/ 1052, ite: 56240] train loss: 0.006023, tar: 0.000442 
l0: 0.000195, l1: 0.000205, l2: 0.000205, l3: 0.000192, l4: 0.000257, l5: 0.000579, l6: 0.000818

[epoch: 214/1000, batch:   964/ 1052, ite: 56260] train loss: 0.006021, tar: 0.000441 
l0: 0.000821, l1: 0.000823, l2: 0.000807, l3: 0.000813, l4: 0.001218, l5: 0.001405, l6: 0.002811

[epoch: 214/1000, batch:  1044/ 1052, ite: 56280] train loss: 0.006018, tar: 0.000441 
[Epoch 214/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000279, l1: 0.000289, l2: 0.000307, l3: 0.000294, l4: 0.000504, l5: 0.000779, l6: 0.000937

[epoch: 215/1000, batch:    72/ 1052, ite: 56300] train loss: 0.006013, tar: 0.000440 
l0: 0.000402, l1: 0.000397, l2: 0.000434, l3: 0.000521, l4: 0.000898, l5: 0.001320, l6: 0.002560

[epoch: 215/1000, batch:   152/ 1052, ite: 56320] train loss: 0.006013, tar: 0.000440 
l0: 0.000361, l1: 0.000375, l2: 0.000383, l3: 0.000399, l4: 0.000667, l5: 0.001524, l6: 0.003141

[epoch: 215/1000, batch:   232/ 1052, ite: 56340] train loss: 0.006008, tar: 0.000439 
l0: 0.000412, l1: 0.000443, l2: 0.000487, l3: 0.000514, l4: 0.000995, l5: 0.001738, l6: 0.002468

[epoch: 215/1000, batch:   312/ 1052, ite: 56360] train loss: 0.006007, tar: 0.000439 
l0: 0.001034, l1: 0.001099, l2: 0.001078, l3: 0.000991, l4: 0.001692, l5: 0.002726, l6: 0.004813

[epoch: 215/1000, batch:   392/ 1052, ite: 56380] train loss: 0.006006, tar: 0.000439 
l0: 0.000345, l1: 0.000335, l2: 0.000382, l3: 0.000572, l4: 0.000715, l5: 0.001256, l6: 0.002218

[epoch: 215/1000, batch:   472/ 1052, ite: 56400] train loss: 0.006003, tar: 0.000438 
l0: 0.000499, l1: 0.000514, l2: 0.000539, l3: 0.000525, l4: 0.000768, l5: 0.001270, l6: 0.001425

[epoch: 215/1000, batch:   552/ 1052, ite: 56420] train loss: 0.005996, tar: 0.000438 
l0: 0.000268, l1: 0.000273, l2: 0.000253, l3: 0.000338, l4: 0.000477, l5: 0.001085, l6: 0.001605

[epoch: 215/1000, batch:   632/ 1052, ite: 56440] train loss: 0.005994, tar: 0.000438 
l0: 0.000193, l1: 0.000199, l2: 0.000191, l3: 0.000255, l4: 0.000314, l5: 0.000566, l6: 0.001030

[epoch: 215/1000, batch:   712/ 1052, ite: 56460] train loss: 0.005992, tar: 0.000437 
l0: 0.000475, l1: 0.000482, l2: 0.000488, l3: 0.000572, l4: 0.000785, l5: 0.001203, l6: 0.001756

[epoch: 215/1000, batch:   792/ 1052, ite: 56480] train loss: 0.005990, tar: 0.000437 
l0: 0.000457, l1: 0.000431, l2: 0.000515, l3: 0.000657, l4: 0.001039, l5: 0.001391, l6: 0.001924

[epoch: 215/1000, batch:   872/ 1052, ite: 56500] train loss: 0.005991, tar: 0.000437 
l0: 0.000361, l1: 0.000389, l2: 0.000381, l3: 0.000428, l4: 0.000656, l5: 0.001457, l6: 0.001708

[epoch: 215/1000, batch:   952/ 1052, ite: 56520] train loss: 0.005991, tar: 0.000437 
l0: 0.000268, l1: 0.000269, l2: 0.000275, l3: 0.000327, l4: 0.000354, l5: 0.000911, l6: 0.001483

[epoch: 215/1000, batch:  1032/ 1052, ite: 56540] train loss: 0.005991, tar: 0.000437 
[Epoch 215/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000388, l1: 0.000363, l2: 0.000394, l3: 0.000482, l4: 0.000525, l5: 0.000918, l6: 0.001010

[epoch: 216/1000, batch:    60/ 1052, ite: 56560] train loss: 0.005987, tar: 0.000437 
l0: 0.000329, l1: 0.000331, l2: 0.000370, l3: 0.000431, l4: 0.000620, l5: 0.000981, l6: 0.001454

[epoch: 216/1000, batch:   140/ 1052, ite: 56580] train loss: 0.005982, tar: 0.000436 
l0: 0.000306, l1: 0.000279, l2: 0.000303, l3: 0.000495, l4: 0.000713, l5: 0.001104, l6: 0.001878

[epoch: 216/1000, batch:   220/ 1052, ite: 56600] train loss: 0.005983, tar: 0.000436 
l0: 0.000663, l1: 0.000682, l2: 0.000732, l3: 0.000806, l4: 0.001134, l5: 0.002151, l6: 0.002835

[epoch: 216/1000, batch:   300/ 1052, ite: 56620] train loss: 0.005980, tar: 0.000436 
l0: 0.000190, l1: 0.000199, l2: 0.000197, l3: 0.000235, l4: 0.000435, l5: 0.001009, l6: 0.001432

[epoch: 216/1000, batch:   380/ 1052, ite: 56640] train loss: 0.005976, tar: 0.000435 
l0: 0.000359, l1: 0.000356, l2: 0.000361, l3: 0.000456, l4: 0.000663, l5: 0.001163, l6: 0.001662

[epoch: 216/1000, batch:   460/ 1052, ite: 56660] train loss: 0.005975, tar: 0.000435 
l0: 0.000265, l1: 0.000255, l2: 0.000304, l3: 0.000324, l4: 0.000628, l5: 0.000787, l6: 0.001195

[epoch: 216/1000, batch:   540/ 1052, ite: 56680] train loss: 0.005974, tar: 0.000435 
l0: 0.000729, l1: 0.000750, l2: 0.000770, l3: 0.000924, l4: 0.002056, l5: 0.003261, l6: 0.005402

[epoch: 216/1000, batch:   620/ 1052, ite: 56700] train loss: 0.005975, tar: 0.000435 
l0: 0.000414, l1: 0.000414, l2: 0.000457, l3: 0.000486, l4: 0.000575, l5: 0.001061, l6: 0.002881

[epoch: 216/1000, batch:   700/ 1052, ite: 56720] train loss: 0.005977, tar: 0.000434 
l0: 0.000255, l1: 0.000252, l2: 0.000282, l3: 0.000454, l4: 0.000556, l5: 0.001121, l6: 0.001992

[epoch: 216/1000, batch:   780/ 1052, ite: 56740] train loss: 0.005973, tar: 0.000434 
l0: 0.000242, l1: 0.000243, l2: 0.000251, l3: 0.000315, l4: 0.000512, l5: 0.000866, l6: 0.001932

[epoch: 216/1000, batch:   860/ 1052, ite: 56760] train loss: 0.005971, tar: 0.000434 
l0: 0.000310, l1: 0.000325, l2: 0.000348, l3: 0.000411, l4: 0.000603, l5: 0.001396, l6: 0.002703

[epoch: 216/1000, batch:   940/ 1052, ite: 56780] train loss: 0.005967, tar: 0.000433 
l0: 0.000220, l1: 0.000225, l2: 0.000229, l3: 0.000288, l4: 0.000413, l5: 0.000556, l6: 0.001758

[epoch: 216/1000, batch:  1020/ 1052, ite: 56800] train loss: 0.005966, tar: 0.000433 
[Epoch 216/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000252, l1: 0.000245, l2: 0.000267, l3: 0.000314, l4: 0.000619, l5: 0.001031, l6: 0.001406

[epoch: 217/1000, batch:    48/ 1052, ite: 56820] train loss: 0.005965, tar: 0.000433 
l0: 0.000270, l1: 0.000281, l2: 0.000310, l3: 0.000332, l4: 0.000614, l5: 0.001216, l6: 0.002206

[epoch: 217/1000, batch:   128/ 1052, ite: 56840] train loss: 0.005965, tar: 0.000433 
l0: 0.000228, l1: 0.000229, l2: 0.000252, l3: 0.000278, l4: 0.000455, l5: 0.000790, l6: 0.001336

[epoch: 217/1000, batch:   208/ 1052, ite: 56860] train loss: 0.005958, tar: 0.000432 
l0: 0.000363, l1: 0.000354, l2: 0.000388, l3: 0.000484, l4: 0.000838, l5: 0.001224, l6: 0.002541

[epoch: 217/1000, batch:   288/ 1052, ite: 56880] train loss: 0.005956, tar: 0.000432 
l0: 0.000314, l1: 0.000332, l2: 0.000314, l3: 0.000324, l4: 0.000532, l5: 0.000678, l6: 0.000827

[epoch: 217/1000, batch:   368/ 1052, ite: 56900] train loss: 0.005954, tar: 0.000432 
l0: 0.000482, l1: 0.000505, l2: 0.000603, l3: 0.000555, l4: 0.000895, l5: 0.001314, l6: 0.002035

[epoch: 217/1000, batch:   448/ 1052, ite: 56920] train loss: 0.005951, tar: 0.000431 
l0: 0.000375, l1: 0.000360, l2: 0.000392, l3: 0.000546, l4: 0.000881, l5: 0.001370, l6: 0.002054

[epoch: 217/1000, batch:   528/ 1052, ite: 56940] train loss: 0.005953, tar: 0.000431 
l0: 0.000176, l1: 0.000177, l2: 0.000201, l3: 0.000230, l4: 0.000337, l5: 0.000500, l6: 0.001231

[epoch: 217/1000, batch:   608/ 1052, ite: 56960] train loss: 0.005950, tar: 0.000431 
l0: 0.000379, l1: 0.000377, l2: 0.000398, l3: 0.000483, l4: 0.000925, l5: 0.001314, l6: 0.002000

[epoch: 217/1000, batch:   688/ 1052, ite: 56980] train loss: 0.005950, tar: 0.000431 
l0: 0.000158, l1: 0.000158, l2: 0.000182, l3: 0.000249, l4: 0.000468, l5: 0.000569, l6: 0.001516

[epoch: 217/1000, batch:   768/ 1052, ite: 57000] train loss: 0.005948, tar: 0.000431 
l0: 0.000452, l1: 0.000469, l2: 0.000488, l3: 0.000503, l4: 0.000761, l5: 0.001902, l6: 0.002064

[epoch: 217/1000, batch:   848/ 1052, ite: 57020] train loss: 0.005946, tar: 0.000430 
l0: 0.000235, l1: 0.000220, l2: 0.000277, l3: 0.000354, l4: 0.000468, l5: 0.001152, l6: 0.001236

[epoch: 217/1000, batch:   928/ 1052, ite: 57040] train loss: 0.005945, tar: 0.000430 
l0: 0.000336, l1: 0.000342, l2: 0.000367, l3: 0.000428, l4: 0.000678, l5: 0.001203, l6: 0.002200

[epoch: 217/1000, batch:  1008/ 1052, ite: 57060] train loss: 0.005942, tar: 0.000430 
[Epoch 217/1000] Test loss: 0.008, Test target loss: 0.001
l0: 0.000348, l1: 0.000363, l2: 0.000377, l3: 0.000430, l4: 0.000681, l5: 0.001263, l6: 0.001651

[epoch: 218/1000, batch:    36/ 1052, ite: 57080] train loss: 0.005942, tar: 0.000430 
l0: 0.000294, l1: 0.000299, l2: 0.000324, l3: 0.000391, l4: 0.000674, l5: 0.001036, l6: 0.002218

[epoch: 218/1000, batch:   116/ 1052, ite: 57100] train loss: 0.005942, tar: 0.000429 
l0: 0.000180, l1: 0.000189, l2: 0.000197, l3: 0.000219, l4: 0.000282, l5: 0.000731, l6: 0.001007

[epoch: 218/1000, batch:   196/ 1052, ite: 57120] train loss: 0.005941, tar: 0.000429 
l0: 0.000383, l1: 0.000396, l2: 0.000426, l3: 0.000418, l4: 0.000814, l5: 0.001465, l6: 0.002364

[epoch: 218/1000, batch:   276/ 1052, ite: 57140] train loss: 0.005938, tar: 0.000429 
l0: 0.000653, l1: 0.000632, l2: 0.000698, l3: 0.000884, l4: 0.001341, l5: 0.002442, l6: 0.003200

[epoch: 218/1000, batch:   356/ 1052, ite: 57160] train loss: 0.005935, tar: 0.000428 
l0: 0.000375, l1: 0.000395, l2: 0.000359, l3: 0.000500, l4: 0.000698, l5: 0.001458, l6: 0.001708

[epoch: 218/1000, batch:   436/ 1052, ite: 57180] train loss: 0.005935, tar: 0.000428 
l0: 0.000418, l1: 0.000428, l2: 0.000450, l3: 0.000518, l4: 0.000784, l5: 0.001648, l6: 0.002996

[epoch: 218/1000, batch:   516/ 1052, ite: 57200] train loss: 0.005935, tar: 0.000428 
l0: 0.000254, l1: 0.000255, l2: 0.000272, l3: 0.000304, l4: 0.000403, l5: 0.000934, l6: 0.001368

[epoch: 218/1000, batch:   596/ 1052, ite: 57220] train loss: 0.005931, tar: 0.000428 
l0: 0.000895, l1: 0.000959, l2: 0.000902, l3: 0.000864, l4: 0.001192, l5: 0.002071, l6: 0.003328

[epoch: 218/1000, batch:   676/ 1052, ite: 57240] train loss: 0.005930, tar: 0.000428 
l0: 0.000334, l1: 0.000318, l2: 0.000343, l3: 0.000426, l4: 0.000495, l5: 0.000906, l6: 0.001481

[epoch: 218/1000, batch:   756/ 1052, ite: 57260] train loss: 0.005929, tar: 0.000428 
l0: 0.000258, l1: 0.000252, l2: 0.000305, l3: 0.000483, l4: 0.000661, l5: 0.000906, l6: 0.001873

[epoch: 218/1000, batch:   836/ 1052, ite: 57280] train loss: 0.005926, tar: 0.000427 
l0: 0.000458, l1: 0.000475, l2: 0.000422, l3: 0.000511, l4: 0.000619, l5: 0.000889, l6: 0.001379

[epoch: 218/1000, batch:   916/ 1052, ite: 57300] train loss: 0.005924, tar: 0.000427 
l0: 0.000506, l1: 0.000513, l2: 0.000545, l3: 0.000575, l4: 0.000743, l5: 0.001314, l6: 0.002860

[epoch: 218/1000, batch:   996/ 1052, ite: 57320] train loss: 0.005922, tar: 0.000427 
[Epoch 218/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000161, l1: 0.000161, l2: 0.000170, l3: 0.000190, l4: 0.000252, l5: 0.000536, l6: 0.000767

[epoch: 219/1000, batch:    24/ 1052, ite: 57340] train loss: 0.005921, tar: 0.000427 
l0: 0.000100, l1: 0.000096, l2: 0.000134, l3: 0.000145, l4: 0.000348, l5: 0.000540, l6: 0.001075

[epoch: 219/1000, batch:   104/ 1052, ite: 57360] train loss: 0.005920, tar: 0.000426 
l0: 0.000433, l1: 0.000464, l2: 0.000444, l3: 0.000461, l4: 0.000787, l5: 0.001702, l6: 0.003012

[epoch: 219/1000, batch:   184/ 1052, ite: 57380] train loss: 0.005917, tar: 0.000426 
l0: 0.000242, l1: 0.000246, l2: 0.000270, l3: 0.000345, l4: 0.000581, l5: 0.000894, l6: 0.001678

[epoch: 219/1000, batch:   264/ 1052, ite: 57400] train loss: 0.005916, tar: 0.000426 
l0: 0.000320, l1: 0.000319, l2: 0.000382, l3: 0.000371, l4: 0.000447, l5: 0.000813, l6: 0.001419

[epoch: 219/1000, batch:   344/ 1052, ite: 57420] train loss: 0.005915, tar: 0.000426 
l0: 0.000495, l1: 0.000490, l2: 0.000539, l3: 0.000634, l4: 0.000963, l5: 0.001460, l6: 0.002544

[epoch: 219/1000, batch:   424/ 1052, ite: 57440] train loss: 0.005914, tar: 0.000425 
l0: 0.000206, l1: 0.000205, l2: 0.000215, l3: 0.000316, l4: 0.000368, l5: 0.000742, l6: 0.001223

[epoch: 219/1000, batch:   504/ 1052, ite: 57460] train loss: 0.005913, tar: 0.000425 
l0: 0.000414, l1: 0.000429, l2: 0.000458, l3: 0.000456, l4: 0.000771, l5: 0.001426, l6: 0.002517

[epoch: 219/1000, batch:   584/ 1052, ite: 57480] train loss: 0.005907, tar: 0.000425 
l0: 0.000327, l1: 0.000325, l2: 0.000327, l3: 0.000399, l4: 0.000524, l5: 0.001411, l6: 0.001863

[epoch: 219/1000, batch:   664/ 1052, ite: 57500] train loss: 0.005906, tar: 0.000424 
l0: 0.000278, l1: 0.000275, l2: 0.000339, l3: 0.000433, l4: 0.000616, l5: 0.001061, l6: 0.001357

[epoch: 219/1000, batch:   744/ 1052, ite: 57520] train loss: 0.005908, tar: 0.000425 
l0: 0.000411, l1: 0.000408, l2: 0.000419, l3: 0.000608, l4: 0.000779, l5: 0.001608, l6: 0.002681

[epoch: 219/1000, batch:   824/ 1052, ite: 57540] train loss: 0.005909, tar: 0.000425 
l0: 0.000316, l1: 0.000316, l2: 0.000319, l3: 0.000370, l4: 0.000687, l5: 0.001060, l6: 0.001382

[epoch: 219/1000, batch:   904/ 1052, ite: 57560] train loss: 0.005906, tar: 0.000424 
l0: 0.000203, l1: 0.000193, l2: 0.000223, l3: 0.000314, l4: 0.000510, l5: 0.001157, l6: 0.001813

[epoch: 219/1000, batch:   984/ 1052, ite: 57580] train loss: 0.005905, tar: 0.000424 
[Epoch 219/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000261, l1: 0.000262, l2: 0.000262, l3: 0.000295, l4: 0.000496, l5: 0.000800, l6: 0.001207

[epoch: 220/1000, batch:    12/ 1052, ite: 57600] train loss: 0.005905, tar: 0.000424 
l0: 0.000469, l1: 0.000492, l2: 0.000497, l3: 0.000419, l4: 0.000542, l5: 0.001103, l6: 0.001236

[epoch: 220/1000, batch:    92/ 1052, ite: 57620] train loss: 0.005900, tar: 0.000423 
l0: 0.000218, l1: 0.000205, l2: 0.000244, l3: 0.000332, l4: 0.000629, l5: 0.000965, l6: 0.001004

[epoch: 220/1000, batch:   172/ 1052, ite: 57640] train loss: 0.005899, tar: 0.000423 
l0: 0.000781, l1: 0.000836, l2: 0.000807, l3: 0.000783, l4: 0.001236, l5: 0.002154, l6: 0.002832

[epoch: 220/1000, batch:   252/ 1052, ite: 57660] train loss: 0.005900, tar: 0.000423 
l0: 0.000265, l1: 0.000274, l2: 0.000274, l3: 0.000301, l4: 0.000349, l5: 0.000683, l6: 0.001603

[epoch: 220/1000, batch:   332/ 1052, ite: 57680] train loss: 0.005900, tar: 0.000423 
l0: 0.000256, l1: 0.000250, l2: 0.000270, l3: 0.000370, l4: 0.000566, l5: 0.000976, l6: 0.001701

[epoch: 220/1000, batch:   412/ 1052, ite: 57700] train loss: 0.005897, tar: 0.000423 
l0: 0.000325, l1: 0.000316, l2: 0.000340, l3: 0.000430, l4: 0.000776, l5: 0.001247, l6: 0.001637

[epoch: 220/1000, batch:   492/ 1052, ite: 57720] train loss: 0.005900, tar: 0.000423 
l0: 0.000189, l1: 0.000189, l2: 0.000193, l3: 0.000227, l4: 0.000393, l5: 0.000597, l6: 0.001400

[epoch: 220/1000, batch:   572/ 1052, ite: 57740] train loss: 0.005897, tar: 0.000423 
l0: 0.000426, l1: 0.000420, l2: 0.000486, l3: 0.000583, l4: 0.000873, l5: 0.001197, l6: 0.002038

[epoch: 220/1000, batch:   652/ 1052, ite: 57760] train loss: 0.005898, tar: 0.000423 
l0: 0.000294, l1: 0.000291, l2: 0.000307, l3: 0.000371, l4: 0.000603, l5: 0.001303, l6: 0.002084

[epoch: 220/1000, batch:   732/ 1052, ite: 57780] train loss: 0.005896, tar: 0.000422 
l0: 0.000199, l1: 0.000207, l2: 0.000242, l3: 0.000275, l4: 0.000488, l5: 0.001254, l6: 0.000976

[epoch: 220/1000, batch:   812/ 1052, ite: 57800] train loss: 0.005894, tar: 0.000422 
l0: 0.000248, l1: 0.000247, l2: 0.000243, l3: 0.000307, l4: 0.000589, l5: 0.001152, l6: 0.001420

[epoch: 220/1000, batch:   892/ 1052, ite: 57820] train loss: 0.005892, tar: 0.000422 
l0: 0.000562, l1: 0.000559, l2: 0.000587, l3: 0.000667, l4: 0.000971, l5: 0.001820, l6: 0.003035

[epoch: 220/1000, batch:   972/ 1052, ite: 57840] train loss: 0.005891, tar: 0.000422 
l0: 0.000263, l1: 0.000264, l2: 0.000267, l3: 0.000318, l4: 0.000624, l5: 0.000973, l6: 0.002092

[epoch: 220/1000, batch:  1052/ 1052, ite: 57860] train loss: 0.005888, tar: 0.000421 
[Epoch 220/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000355, l1: 0.000346, l2: 0.000384, l3: 0.000435, l4: 0.000738, l5: 0.000979, l6: 0.001741

[epoch: 221/1000, batch:    80/ 1052, ite: 57880] train loss: 0.005886, tar: 0.000421 
l0: 0.000386, l1: 0.000386, l2: 0.000370, l3: 0.000447, l4: 0.000613, l5: 0.001163, l6: 0.001667

[epoch: 221/1000, batch:   160/ 1052, ite: 57900] train loss: 0.005885, tar: 0.000421 
l0: 0.000414, l1: 0.000430, l2: 0.000426, l3: 0.000439, l4: 0.000597, l5: 0.001454, l6: 0.001628

[epoch: 221/1000, batch:   240/ 1052, ite: 57920] train loss: 0.005882, tar: 0.000421 
l0: 0.000192, l1: 0.000189, l2: 0.000211, l3: 0.000255, l4: 0.000409, l5: 0.000551, l6: 0.001081

[epoch: 221/1000, batch:   320/ 1052, ite: 57940] train loss: 0.005880, tar: 0.000420 
l0: 0.000815, l1: 0.000867, l2: 0.000805, l3: 0.000706, l4: 0.000978, l5: 0.001851, l6: 0.002734

[epoch: 221/1000, batch:   400/ 1052, ite: 57960] train loss: 0.005879, tar: 0.000420 
l0: 0.000335, l1: 0.000354, l2: 0.000350, l3: 0.000326, l4: 0.000613, l5: 0.000840, l6: 0.001527

[epoch: 221/1000, batch:   480/ 1052, ite: 57980] train loss: 0.005874, tar: 0.000420 
l0: 0.000400, l1: 0.000436, l2: 0.000411, l3: 0.000451, l4: 0.000838, l5: 0.001608, l6: 0.003219

[epoch: 221/1000, batch:   560/ 1052, ite: 58000] train loss: 0.005874, tar: 0.000420 
l0: 0.000510, l1: 0.000501, l2: 0.000499, l3: 0.000608, l4: 0.001009, l5: 0.001694, l6: 0.002442

[epoch: 221/1000, batch:   640/ 1052, ite: 58020] train loss: 0.005873, tar: 0.000419 
l0: 0.001032, l1: 0.001241, l2: 0.001166, l3: 0.001041, l4: 0.001211, l5: 0.002646, l6: 0.004689

[epoch: 221/1000, batch:   720/ 1052, ite: 58040] train loss: 0.005876, tar: 0.000420 
l0: 0.000285, l1: 0.000273, l2: 0.000334, l3: 0.000391, l4: 0.000624, l5: 0.001196, l6: 0.001909

[epoch: 221/1000, batch:   800/ 1052, ite: 58060] train loss: 0.005874, tar: 0.000419 
l0: 0.000252, l1: 0.000265, l2: 0.000271, l3: 0.000297, l4: 0.000576, l5: 0.001263, l6: 0.001517

[epoch: 221/1000, batch:   880/ 1052, ite: 58080] train loss: 0.005871, tar: 0.000419 
l0: 0.000366, l1: 0.000387, l2: 0.000370, l3: 0.000386, l4: 0.000660, l5: 0.001069, l6: 0.002200

[epoch: 221/1000, batch:   960/ 1052, ite: 58100] train loss: 0.005870, tar: 0.000419 
l0: 0.000437, l1: 0.000474, l2: 0.000472, l3: 0.000445, l4: 0.000624, l5: 0.001125, l6: 0.002557

[epoch: 221/1000, batch:  1040/ 1052, ite: 58120] train loss: 0.005873, tar: 0.000419 
[Epoch 221/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000241, l1: 0.000263, l2: 0.000270, l3: 0.000295, l4: 0.000341, l5: 0.000657, l6: 0.001223

[epoch: 222/1000, batch:    68/ 1052, ite: 58140] train loss: 0.005873, tar: 0.000419 
l0: 0.000422, l1: 0.000438, l2: 0.000447, l3: 0.000496, l4: 0.000864, l5: 0.001458, l6: 0.002452

[epoch: 222/1000, batch:   148/ 1052, ite: 58160] train loss: 0.005873, tar: 0.000419 
l0: 0.000411, l1: 0.000424, l2: 0.000407, l3: 0.000421, l4: 0.000743, l5: 0.001915, l6: 0.002700

[epoch: 222/1000, batch:   228/ 1052, ite: 58180] train loss: 0.005871, tar: 0.000419 
l0: 0.000253, l1: 0.000255, l2: 0.000250, l3: 0.000354, l4: 0.000398, l5: 0.000884, l6: 0.000990

[epoch: 222/1000, batch:   308/ 1052, ite: 58200] train loss: 0.005869, tar: 0.000419 
l0: 0.000480, l1: 0.000500, l2: 0.000516, l3: 0.000555, l4: 0.000893, l5: 0.001313, l6: 0.003005

[epoch: 222/1000, batch:   388/ 1052, ite: 58220] train loss: 0.005869, tar: 0.000418 
l0: 0.000259, l1: 0.000253, l2: 0.000273, l3: 0.000384, l4: 0.000572, l5: 0.001150, l6: 0.002306

[epoch: 222/1000, batch:   468/ 1052, ite: 58240] train loss: 0.005864, tar: 0.000418 
l0: 0.000229, l1: 0.000237, l2: 0.000258, l3: 0.000315, l4: 0.000480, l5: 0.000862, l6: 0.001569

[epoch: 222/1000, batch:   548/ 1052, ite: 58260] train loss: 0.005863, tar: 0.000418 
l0: 0.000152, l1: 0.000149, l2: 0.000182, l3: 0.000221, l4: 0.000409, l5: 0.000887, l6: 0.001203

[epoch: 222/1000, batch:   628/ 1052, ite: 58280] train loss: 0.005861, tar: 0.000418 
l0: 0.000327, l1: 0.000338, l2: 0.000360, l3: 0.000416, l4: 0.000692, l5: 0.001172, l6: 0.002120

[epoch: 222/1000, batch:   708/ 1052, ite: 58300] train loss: 0.005861, tar: 0.000417 
l0: 0.000472, l1: 0.000479, l2: 0.000576, l3: 0.000632, l4: 0.001032, l5: 0.001992, l6: 0.004354

[epoch: 222/1000, batch:   788/ 1052, ite: 58320] train loss: 0.005861, tar: 0.000418 
l0: 0.000347, l1: 0.000359, l2: 0.000409, l3: 0.000397, l4: 0.000640, l5: 0.001082, l6: 0.002783

[epoch: 222/1000, batch:   868/ 1052, ite: 58340] train loss: 0.005862, tar: 0.000418 
l0: 0.000363, l1: 0.000347, l2: 0.000405, l3: 0.000475, l4: 0.000721, l5: 0.001037, l6: 0.001891

[epoch: 222/1000, batch:   948/ 1052, ite: 58360] train loss: 0.005861, tar: 0.000418 
l0: 0.000138, l1: 0.000139, l2: 0.000184, l3: 0.000202, l4: 0.000259, l5: 0.000526, l6: 0.000796

[epoch: 222/1000, batch:  1028/ 1052, ite: 58380] train loss: 0.005859, tar: 0.000417 
[Epoch 222/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000581, l1: 0.000588, l2: 0.000688, l3: 0.000773, l4: 0.001327, l5: 0.002070, l6: 0.003191

[epoch: 223/1000, batch:    56/ 1052, ite: 58400] train loss: 0.005859, tar: 0.000417 
l0: 0.000589, l1: 0.000568, l2: 0.000549, l3: 0.000680, l4: 0.000767, l5: 0.001294, l6: 0.002000

[epoch: 223/1000, batch:   136/ 1052, ite: 58420] train loss: 0.005857, tar: 0.000417 
l0: 0.000143, l1: 0.000140, l2: 0.000152, l3: 0.000174, l4: 0.000328, l5: 0.000572, l6: 0.001054

[epoch: 223/1000, batch:   216/ 1052, ite: 58440] train loss: 0.005854, tar: 0.000416 
l0: 0.000312, l1: 0.000310, l2: 0.000329, l3: 0.000390, l4: 0.000690, l5: 0.001129, l6: 0.001561

[epoch: 223/1000, batch:   296/ 1052, ite: 58460] train loss: 0.005854, tar: 0.000416 
l0: 0.000389, l1: 0.000408, l2: 0.000392, l3: 0.000470, l4: 0.000552, l5: 0.001399, l6: 0.002894

[epoch: 223/1000, batch:   376/ 1052, ite: 58480] train loss: 0.005856, tar: 0.000416 
l0: 0.000168, l1: 0.000170, l2: 0.000173, l3: 0.000238, l4: 0.000432, l5: 0.000907, l6: 0.001514

[epoch: 223/1000, batch:   456/ 1052, ite: 58500] train loss: 0.005852, tar: 0.000416 
l0: 0.000339, l1: 0.000334, l2: 0.000353, l3: 0.000420, l4: 0.000544, l5: 0.001074, l6: 0.002210

[epoch: 223/1000, batch:   536/ 1052, ite: 58520] train loss: 0.005850, tar: 0.000416 
l0: 0.000268, l1: 0.000266, l2: 0.000296, l3: 0.000318, l4: 0.000483, l5: 0.000942, l6: 0.001309

[epoch: 223/1000, batch:   616/ 1052, ite: 58540] train loss: 0.005847, tar: 0.000415 
l0: 0.000143, l1: 0.000147, l2: 0.000159, l3: 0.000170, l4: 0.000275, l5: 0.000701, l6: 0.001082

[epoch: 223/1000, batch:   696/ 1052, ite: 58560] train loss: 0.005846, tar: 0.000415 
l0: 0.000422, l1: 0.000447, l2: 0.000448, l3: 0.000443, l4: 0.000746, l5: 0.001369, l6: 0.002147

[epoch: 223/1000, batch:   776/ 1052, ite: 58580] train loss: 0.005847, tar: 0.000415 
l0: 0.000675, l1: 0.000751, l2: 0.000698, l3: 0.000748, l4: 0.001090, l5: 0.001773, l6: 0.003287

[epoch: 223/1000, batch:   856/ 1052, ite: 58600] train loss: 0.005847, tar: 0.000415 
l0: 0.000377, l1: 0.000396, l2: 0.000437, l3: 0.000466, l4: 0.000669, l5: 0.001242, l6: 0.002590

[epoch: 223/1000, batch:   936/ 1052, ite: 58620] train loss: 0.005847, tar: 0.000415 
l0: 0.000365, l1: 0.000356, l2: 0.000381, l3: 0.000448, l4: 0.000709, l5: 0.001146, l6: 0.001605

[epoch: 223/1000, batch:  1016/ 1052, ite: 58640] train loss: 0.005845, tar: 0.000415 
[Epoch 223/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000283, l1: 0.000274, l2: 0.000278, l3: 0.000367, l4: 0.000542, l5: 0.001096, l6: 0.001598

[epoch: 224/1000, batch:    44/ 1052, ite: 58660] train loss: 0.005841, tar: 0.000415 
l0: 0.000523, l1: 0.000504, l2: 0.000512, l3: 0.000723, l4: 0.001343, l5: 0.001396, l6: 0.002448

[epoch: 224/1000, batch:   124/ 1052, ite: 58680] train loss: 0.005841, tar: 0.000415 
l0: 0.000369, l1: 0.000386, l2: 0.000349, l3: 0.000410, l4: 0.000646, l5: 0.000926, l6: 0.001440

[epoch: 224/1000, batch:   204/ 1052, ite: 58700] train loss: 0.005841, tar: 0.000415 
l0: 0.000419, l1: 0.000435, l2: 0.000422, l3: 0.000499, l4: 0.000786, l5: 0.001431, l6: 0.002199

[epoch: 224/1000, batch:   284/ 1052, ite: 58720] train loss: 0.005843, tar: 0.000415 
l0: 0.000329, l1: 0.000348, l2: 0.000443, l3: 0.000436, l4: 0.000613, l5: 0.001175, l6: 0.001471

[epoch: 224/1000, batch:   364/ 1052, ite: 58740] train loss: 0.005839, tar: 0.000415 
l0: 0.000511, l1: 0.000515, l2: 0.000561, l3: 0.000570, l4: 0.000681, l5: 0.000994, l6: 0.001643

[epoch: 224/1000, batch:   444/ 1052, ite: 58760] train loss: 0.005840, tar: 0.000415 
l0: 0.000330, l1: 0.000319, l2: 0.000385, l3: 0.000410, l4: 0.000578, l5: 0.001710, l6: 0.002597

[epoch: 224/1000, batch:   524/ 1052, ite: 58780] train loss: 0.005841, tar: 0.000415 
l0: 0.000307, l1: 0.000328, l2: 0.000279, l3: 0.000372, l4: 0.000608, l5: 0.001258, l6: 0.001789

[epoch: 224/1000, batch:   604/ 1052, ite: 58800] train loss: 0.005842, tar: 0.000415 
l0: 0.000604, l1: 0.000584, l2: 0.000633, l3: 0.000774, l4: 0.001203, l5: 0.002512, l6: 0.004125

[epoch: 224/1000, batch:   684/ 1052, ite: 58820] train loss: 0.005844, tar: 0.000415 
l0: 0.002026, l1: 0.001867, l2: 0.002128, l3: 0.002240, l4: 0.002036, l5: 0.003863, l6: 0.004603

[epoch: 224/1000, batch:   764/ 1052, ite: 58840] train loss: 0.005843, tar: 0.000415 
l0: 0.000543, l1: 0.000553, l2: 0.000533, l3: 0.000512, l4: 0.000857, l5: 0.001334, l6: 0.002198

[epoch: 224/1000, batch:   844/ 1052, ite: 58860] train loss: 0.005842, tar: 0.000415 
l0: 0.000238, l1: 0.000255, l2: 0.000241, l3: 0.000290, l4: 0.000349, l5: 0.000592, l6: 0.001204

[epoch: 224/1000, batch:   924/ 1052, ite: 58880] train loss: 0.005842, tar: 0.000415 
l0: 0.000418, l1: 0.000430, l2: 0.000475, l3: 0.000509, l4: 0.000716, l5: 0.001253, l6: 0.002680

[epoch: 224/1000, batch:  1004/ 1052, ite: 58900] train loss: 0.005841, tar: 0.000415 
[Epoch 224/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000729, l1: 0.000796, l2: 0.000744, l3: 0.000772, l4: 0.000894, l5: 0.001483, l6: 0.002055

[epoch: 225/1000, batch:    32/ 1052, ite: 58920] train loss: 0.005843, tar: 0.000415 
l0: 0.000448, l1: 0.000446, l2: 0.000492, l3: 0.000587, l4: 0.000754, l5: 0.001247, l6: 0.003279

[epoch: 225/1000, batch:   112/ 1052, ite: 58940] train loss: 0.005842, tar: 0.000415 
l0: 0.000432, l1: 0.000421, l2: 0.000484, l3: 0.000586, l4: 0.000783, l5: 0.001211, l6: 0.001370

[epoch: 225/1000, batch:   192/ 1052, ite: 58960] train loss: 0.005840, tar: 0.000415 
l0: 0.000509, l1: 0.000511, l2: 0.000531, l3: 0.000611, l4: 0.000857, l5: 0.001279, l6: 0.001826

[epoch: 225/1000, batch:   272/ 1052, ite: 58980] train loss: 0.005840, tar: 0.000415 
l0: 0.001285, l1: 0.001778, l2: 0.001632, l3: 0.001301, l4: 0.001170, l5: 0.002160, l6: 0.003930

[epoch: 225/1000, batch:   352/ 1052, ite: 59000] train loss: 0.005842, tar: 0.000415 
l0: 0.000302, l1: 0.000316, l2: 0.000338, l3: 0.000379, l4: 0.000509, l5: 0.000710, l6: 0.001225

[epoch: 225/1000, batch:   432/ 1052, ite: 59020] train loss: 0.005845, tar: 0.000415 
l0: 0.001369, l1: 0.001481, l2: 0.001463, l3: 0.001242, l4: 0.001576, l5: 0.002247, l6: 0.003716

[epoch: 225/1000, batch:   512/ 1052, ite: 59040] train loss: 0.005846, tar: 0.000415 
l0: 0.000230, l1: 0.000223, l2: 0.000252, l3: 0.000332, l4: 0.000414, l5: 0.000871, l6: 0.001700

[epoch: 225/1000, batch:   592/ 1052, ite: 59060] train loss: 0.005847, tar: 0.000415 
l0: 0.000430, l1: 0.000439, l2: 0.000459, l3: 0.000490, l4: 0.000701, l5: 0.001492, l6: 0.001985

[epoch: 225/1000, batch:   672/ 1052, ite: 59080] train loss: 0.005848, tar: 0.000416 
l0: 0.000468, l1: 0.000445, l2: 0.000555, l3: 0.000613, l4: 0.000779, l5: 0.001357, l6: 0.002003

[epoch: 225/1000, batch:   752/ 1052, ite: 59100] train loss: 0.005848, tar: 0.000415 
l0: 0.000328, l1: 0.000319, l2: 0.000349, l3: 0.000373, l4: 0.000698, l5: 0.001115, l6: 0.001847

[epoch: 225/1000, batch:   832/ 1052, ite: 59120] train loss: 0.005848, tar: 0.000415 
l0: 0.000565, l1: 0.000565, l2: 0.000572, l3: 0.000640, l4: 0.000932, l5: 0.001678, l6: 0.003033

[epoch: 225/1000, batch:   912/ 1052, ite: 59140] train loss: 0.005848, tar: 0.000415 
l0: 0.000389, l1: 0.000386, l2: 0.000450, l3: 0.000415, l4: 0.000655, l5: 0.000969, l6: 0.001561

[epoch: 225/1000, batch:   992/ 1052, ite: 59160] train loss: 0.005845, tar: 0.000415 
[Epoch 225/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000284, l1: 0.000283, l2: 0.000297, l3: 0.000374, l4: 0.000622, l5: 0.001209, l6: 0.001657

[epoch: 226/1000, batch:    20/ 1052, ite: 59180] train loss: 0.005844, tar: 0.000415 
l0: 0.000433, l1: 0.000418, l2: 0.000453, l3: 0.000475, l4: 0.000594, l5: 0.001173, l6: 0.001985

[epoch: 226/1000, batch:   100/ 1052, ite: 59200] train loss: 0.005845, tar: 0.000415 
l0: 0.000366, l1: 0.000375, l2: 0.000351, l3: 0.000342, l4: 0.000660, l5: 0.001204, l6: 0.001319

[epoch: 226/1000, batch:   180/ 1052, ite: 59220] train loss: 0.005843, tar: 0.000415 
l0: 0.000438, l1: 0.000429, l2: 0.000507, l3: 0.000500, l4: 0.000638, l5: 0.001131, l6: 0.001604

[epoch: 226/1000, batch:   260/ 1052, ite: 59240] train loss: 0.005843, tar: 0.000415 
l0: 0.000983, l1: 0.000970, l2: 0.001055, l3: 0.001222, l4: 0.001733, l5: 0.002817, l6: 0.003684

[epoch: 226/1000, batch:   340/ 1052, ite: 59260] train loss: 0.005842, tar: 0.000415 
l0: 0.000473, l1: 0.000486, l2: 0.000473, l3: 0.000509, l4: 0.000787, l5: 0.001765, l6: 0.002820

[epoch: 226/1000, batch:   420/ 1052, ite: 59280] train loss: 0.005842, tar: 0.000415 
l0: 0.000249, l1: 0.000235, l2: 0.000280, l3: 0.000340, l4: 0.000586, l5: 0.000723, l6: 0.001459

[epoch: 226/1000, batch:   500/ 1052, ite: 59300] train loss: 0.005842, tar: 0.000415 
l0: 0.000367, l1: 0.000354, l2: 0.000393, l3: 0.000498, l4: 0.000706, l5: 0.001863, l6: 0.001418

[epoch: 226/1000, batch:   580/ 1052, ite: 59320] train loss: 0.005842, tar: 0.000414 
l0: 0.000473, l1: 0.000468, l2: 0.000480, l3: 0.000494, l4: 0.000707, l5: 0.001007, l6: 0.001771

[epoch: 226/1000, batch:   660/ 1052, ite: 59340] train loss: 0.005840, tar: 0.000414 
l0: 0.000284, l1: 0.000278, l2: 0.000279, l3: 0.000367, l4: 0.000541, l5: 0.001120, l6: 0.001841

[epoch: 226/1000, batch:   740/ 1052, ite: 59360] train loss: 0.005838, tar: 0.000414 
l0: 0.000238, l1: 0.000245, l2: 0.000250, l3: 0.000291, l4: 0.000553, l5: 0.001166, l6: 0.001865

[epoch: 226/1000, batch:   820/ 1052, ite: 59380] train loss: 0.005838, tar: 0.000414 
l0: 0.000369, l1: 0.000385, l2: 0.000375, l3: 0.000416, l4: 0.000659, l5: 0.001299, l6: 0.003088

[epoch: 226/1000, batch:   900/ 1052, ite: 59400] train loss: 0.005837, tar: 0.000414 
l0: 0.000376, l1: 0.000414, l2: 0.000422, l3: 0.000490, l4: 0.000818, l5: 0.001080, l6: 0.002912

[epoch: 226/1000, batch:   980/ 1052, ite: 59420] train loss: 0.005834, tar: 0.000414 
[Epoch 226/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000365, l1: 0.000370, l2: 0.000363, l3: 0.000433, l4: 0.000701, l5: 0.001342, l6: 0.001677

[epoch: 227/1000, batch:     8/ 1052, ite: 59440] train loss: 0.005835, tar: 0.000414 
l0: 0.000379, l1: 0.000389, l2: 0.000437, l3: 0.000454, l4: 0.000648, l5: 0.001265, l6: 0.002373

[epoch: 227/1000, batch:    88/ 1052, ite: 59460] train loss: 0.005837, tar: 0.000414 
l0: 0.000460, l1: 0.000455, l2: 0.000499, l3: 0.000641, l4: 0.001105, l5: 0.001807, l6: 0.002504

[epoch: 227/1000, batch:   168/ 1052, ite: 59480] train loss: 0.005837, tar: 0.000413 
l0: 0.000353, l1: 0.000362, l2: 0.000376, l3: 0.000403, l4: 0.000807, l5: 0.001364, l6: 0.002000

[epoch: 227/1000, batch:   248/ 1052, ite: 59500] train loss: 0.005837, tar: 0.000413 
l0: 0.000294, l1: 0.000301, l2: 0.000354, l3: 0.000338, l4: 0.000535, l5: 0.001186, l6: 0.001182

[epoch: 227/1000, batch:   328/ 1052, ite: 59520] train loss: 0.005835, tar: 0.000413 
l0: 0.000325, l1: 0.000351, l2: 0.000342, l3: 0.000325, l4: 0.000553, l5: 0.001011, l6: 0.002033

[epoch: 227/1000, batch:   408/ 1052, ite: 59540] train loss: 0.005835, tar: 0.000413 
l0: 0.000409, l1: 0.000399, l2: 0.000451, l3: 0.000558, l4: 0.001030, l5: 0.001723, l6: 0.002686

[epoch: 227/1000, batch:   488/ 1052, ite: 59560] train loss: 0.005835, tar: 0.000413 
l0: 0.000233, l1: 0.000241, l2: 0.000260, l3: 0.000298, l4: 0.000320, l5: 0.000844, l6: 0.001280

[epoch: 227/1000, batch:   568/ 1052, ite: 59580] train loss: 0.005833, tar: 0.000413 
l0: 0.000118, l1: 0.000127, l2: 0.000139, l3: 0.000170, l4: 0.000395, l5: 0.000630, l6: 0.001009

[epoch: 227/1000, batch:   648/ 1052, ite: 59600] train loss: 0.005831, tar: 0.000413 
l0: 0.000314, l1: 0.000313, l2: 0.000338, l3: 0.000343, l4: 0.000448, l5: 0.001126, l6: 0.001926

[epoch: 227/1000, batch:   728/ 1052, ite: 59620] train loss: 0.005830, tar: 0.000412 
l0: 0.000389, l1: 0.000394, l2: 0.000394, l3: 0.000504, l4: 0.000752, l5: 0.001484, l6: 0.002498

[epoch: 227/1000, batch:   808/ 1052, ite: 59640] train loss: 0.005830, tar: 0.000412 
l0: 0.000363, l1: 0.000348, l2: 0.000410, l3: 0.000532, l4: 0.000878, l5: 0.001779, l6: 0.002413

[epoch: 227/1000, batch:   888/ 1052, ite: 59660] train loss: 0.005827, tar: 0.000412 
l0: 0.000225, l1: 0.000229, l2: 0.000266, l3: 0.000327, l4: 0.000463, l5: 0.001255, l6: 0.001463

[epoch: 227/1000, batch:   968/ 1052, ite: 59680] train loss: 0.005826, tar: 0.000412 
l0: 0.000186, l1: 0.000190, l2: 0.000182, l3: 0.000233, l4: 0.000354, l5: 0.000690, l6: 0.001163

[epoch: 227/1000, batch:  1048/ 1052, ite: 59700] train loss: 0.005825, tar: 0.000412 
[Epoch 227/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000400, l1: 0.000379, l2: 0.000422, l3: 0.000551, l4: 0.000800, l5: 0.001560, l6: 0.002009

[epoch: 228/1000, batch:    76/ 1052, ite: 59720] train loss: 0.005823, tar: 0.000412 
l0: 0.000278, l1: 0.000261, l2: 0.000315, l3: 0.000422, l4: 0.000687, l5: 0.000844, l6: 0.001690

[epoch: 228/1000, batch:   156/ 1052, ite: 59740] train loss: 0.005823, tar: 0.000411 
l0: 0.000434, l1: 0.000414, l2: 0.000489, l3: 0.000604, l4: 0.000945, l5: 0.001898, l6: 0.003085

[epoch: 228/1000, batch:   236/ 1052, ite: 59760] train loss: 0.005823, tar: 0.000411 
l0: 0.000224, l1: 0.000239, l2: 0.000255, l3: 0.000264, l4: 0.000479, l5: 0.001103, l6: 0.000937

[epoch: 228/1000, batch:   316/ 1052, ite: 59780] train loss: 0.005823, tar: 0.000411 
l0: 0.000393, l1: 0.000384, l2: 0.000403, l3: 0.000560, l4: 0.001012, l5: 0.002061, l6: 0.004122

[epoch: 228/1000, batch:   396/ 1052, ite: 59800] train loss: 0.005824, tar: 0.000411 
l0: 0.000220, l1: 0.000222, l2: 0.000244, l3: 0.000289, l4: 0.000379, l5: 0.001086, l6: 0.001453

[epoch: 228/1000, batch:   476/ 1052, ite: 59820] train loss: 0.005823, tar: 0.000411 
l0: 0.000132, l1: 0.000139, l2: 0.000145, l3: 0.000163, l4: 0.000269, l5: 0.000703, l6: 0.000864

[epoch: 228/1000, batch:   556/ 1052, ite: 59840] train loss: 0.005822, tar: 0.000411 
l0: 0.000782, l1: 0.000812, l2: 0.000805, l3: 0.000884, l4: 0.001288, l5: 0.002611, l6: 0.003365

[epoch: 228/1000, batch:   636/ 1052, ite: 59860] train loss: 0.005822, tar: 0.000411 
l0: 0.000304, l1: 0.000306, l2: 0.000321, l3: 0.000372, l4: 0.000568, l5: 0.001377, l6: 0.002134

[epoch: 228/1000, batch:   716/ 1052, ite: 59880] train loss: 0.005823, tar: 0.000411 
l0: 0.000431, l1: 0.000428, l2: 0.000455, l3: 0.000492, l4: 0.000705, l5: 0.001147, l6: 0.002250

[epoch: 228/1000, batch:   796/ 1052, ite: 59900] train loss: 0.005820, tar: 0.000411 
l0: 0.000460, l1: 0.000477, l2: 0.000509, l3: 0.000585, l4: 0.000940, l5: 0.001592, l6: 0.002972

[epoch: 228/1000, batch:   876/ 1052, ite: 59920] train loss: 0.005817, tar: 0.000410 
l0: 0.000283, l1: 0.000289, l2: 0.000334, l3: 0.000356, l4: 0.000569, l5: 0.001272, l6: 0.002111

[epoch: 228/1000, batch:   956/ 1052, ite: 59940] train loss: 0.005815, tar: 0.000410 
l0: 0.000335, l1: 0.000353, l2: 0.000365, l3: 0.000530, l4: 0.000859, l5: 0.001538, l6: 0.002441

[epoch: 228/1000, batch:  1036/ 1052, ite: 59960] train loss: 0.005815, tar: 0.000410 
[Epoch 228/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000353, l1: 0.000361, l2: 0.000369, l3: 0.000426, l4: 0.000681, l5: 0.001215, l6: 0.001205

[epoch: 229/1000, batch:    64/ 1052, ite: 59980] train loss: 0.005815, tar: 0.000410 
l0: 0.000476, l1: 0.000497, l2: 0.000505, l3: 0.000514, l4: 0.000805, l5: 0.001571, l6: 0.003380

[epoch: 229/1000, batch:   144/ 1052, ite: 60000] train loss: 0.005815, tar: 0.000410 
l0: 0.000219, l1: 0.000218, l2: 0.000293, l3: 0.000388, l4: 0.000658, l5: 0.001078, l6: 0.001895

[epoch: 229/1000, batch:   224/ 1052, ite: 60020] train loss: 0.005812, tar: 0.000410 
l0: 0.000351, l1: 0.000355, l2: 0.000370, l3: 0.000459, l4: 0.000724, l5: 0.001233, l6: 0.002108

[epoch: 229/1000, batch:   304/ 1052, ite: 60040] train loss: 0.005812, tar: 0.000410 
l0: 0.000340, l1: 0.000344, l2: 0.000372, l3: 0.000402, l4: 0.000635, l5: 0.001103, l6: 0.002319

[epoch: 229/1000, batch:   384/ 1052, ite: 60060] train loss: 0.005812, tar: 0.000409 
l0: 0.000227, l1: 0.000225, l2: 0.000251, l3: 0.000382, l4: 0.000639, l5: 0.001059, l6: 0.001229

[epoch: 229/1000, batch:   464/ 1052, ite: 60080] train loss: 0.005810, tar: 0.000409 
l0: 0.000225, l1: 0.000226, l2: 0.000228, l3: 0.000302, l4: 0.000429, l5: 0.001044, l6: 0.001227

[epoch: 229/1000, batch:   544/ 1052, ite: 60100] train loss: 0.005808, tar: 0.000409 
l0: 0.000398, l1: 0.000386, l2: 0.000454, l3: 0.000628, l4: 0.000838, l5: 0.001436, l6: 0.002885

[epoch: 229/1000, batch:   624/ 1052, ite: 60120] train loss: 0.005810, tar: 0.000409 
l0: 0.000274, l1: 0.000270, l2: 0.000306, l3: 0.000409, l4: 0.000536, l5: 0.001395, l6: 0.002018

[epoch: 229/1000, batch:   704/ 1052, ite: 60140] train loss: 0.005809, tar: 0.000409 
l0: 0.000167, l1: 0.000168, l2: 0.000181, l3: 0.000225, l4: 0.000464, l5: 0.000957, l6: 0.001147

[epoch: 229/1000, batch:   784/ 1052, ite: 60160] train loss: 0.005807, tar: 0.000409 
l0: 0.000176, l1: 0.000179, l2: 0.000172, l3: 0.000248, l4: 0.000435, l5: 0.001017, l6: 0.001128

[epoch: 229/1000, batch:   864/ 1052, ite: 60180] train loss: 0.005807, tar: 0.000409 
l0: 0.000271, l1: 0.000258, l2: 0.000264, l3: 0.000403, l4: 0.000486, l5: 0.001202, l6: 0.001331

[epoch: 229/1000, batch:   944/ 1052, ite: 60200] train loss: 0.005808, tar: 0.000409 
l0: 0.000274, l1: 0.000281, l2: 0.000308, l3: 0.000363, l4: 0.000660, l5: 0.001244, l6: 0.001820

[epoch: 229/1000, batch:  1024/ 1052, ite: 60220] train loss: 0.005810, tar: 0.000409 
[Epoch 229/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000539, l1: 0.000561, l2: 0.000604, l3: 0.000577, l4: 0.000826, l5: 0.001253, l6: 0.001715

[epoch: 230/1000, batch:    52/ 1052, ite: 60240] train loss: 0.005809, tar: 0.000409 
l0: 0.000280, l1: 0.000241, l2: 0.000312, l3: 0.000540, l4: 0.000691, l5: 0.001290, l6: 0.002065

[epoch: 230/1000, batch:   132/ 1052, ite: 60260] train loss: 0.005809, tar: 0.000409 
l0: 0.000282, l1: 0.000275, l2: 0.000293, l3: 0.000364, l4: 0.000483, l5: 0.001192, l6: 0.001433

[epoch: 230/1000, batch:   212/ 1052, ite: 60280] train loss: 0.005808, tar: 0.000408 
l0: 0.000627, l1: 0.000632, l2: 0.000671, l3: 0.000641, l4: 0.000843, l5: 0.001629, l6: 0.002169

[epoch: 230/1000, batch:   292/ 1052, ite: 60300] train loss: 0.005809, tar: 0.000408 
l0: 0.000279, l1: 0.000256, l2: 0.000305, l3: 0.000365, l4: 0.000514, l5: 0.000797, l6: 0.001293

[epoch: 230/1000, batch:   372/ 1052, ite: 60320] train loss: 0.005808, tar: 0.000408 
l0: 0.000217, l1: 0.000217, l2: 0.000275, l3: 0.000319, l4: 0.000432, l5: 0.001170, l6: 0.002196

[epoch: 230/1000, batch:   452/ 1052, ite: 60340] train loss: 0.005807, tar: 0.000408 
l0: 0.000350, l1: 0.000356, l2: 0.000395, l3: 0.000463, l4: 0.000634, l5: 0.001042, l6: 0.001866

[epoch: 230/1000, batch:   532/ 1052, ite: 60360] train loss: 0.005805, tar: 0.000408 
l0: 0.000881, l1: 0.000933, l2: 0.000935, l3: 0.000940, l4: 0.000923, l5: 0.001170, l6: 0.002427

[epoch: 230/1000, batch:   612/ 1052, ite: 60380] train loss: 0.005805, tar: 0.000408 
l0: 0.000194, l1: 0.000189, l2: 0.000222, l3: 0.000277, l4: 0.000512, l5: 0.001031, l6: 0.001973

[epoch: 230/1000, batch:   692/ 1052, ite: 60400] train loss: 0.005805, tar: 0.000408 
l0: 0.000204, l1: 0.000197, l2: 0.000203, l3: 0.000296, l4: 0.000544, l5: 0.000759, l6: 0.001096

[epoch: 230/1000, batch:   772/ 1052, ite: 60420] train loss: 0.005804, tar: 0.000408 
l0: 0.000438, l1: 0.000445, l2: 0.000451, l3: 0.000572, l4: 0.000734, l5: 0.001052, l6: 0.002445

[epoch: 230/1000, batch:   852/ 1052, ite: 60440] train loss: 0.005804, tar: 0.000408 
l0: 0.000413, l1: 0.000419, l2: 0.000485, l3: 0.000448, l4: 0.000790, l5: 0.001245, l6: 0.001796

[epoch: 230/1000, batch:   932/ 1052, ite: 60460] train loss: 0.005802, tar: 0.000408 
l0: 0.000219, l1: 0.000227, l2: 0.000245, l3: 0.000226, l4: 0.000369, l5: 0.000871, l6: 0.001446

[epoch: 230/1000, batch:  1012/ 1052, ite: 60480] train loss: 0.005800, tar: 0.000407 
[Epoch 230/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000426, l1: 0.000431, l2: 0.000455, l3: 0.000718, l4: 0.001083, l5: 0.001572, l6: 0.003170

[epoch: 231/1000, batch:    40/ 1052, ite: 60500] train loss: 0.005799, tar: 0.000407 
l0: 0.000278, l1: 0.000294, l2: 0.000296, l3: 0.000388, l4: 0.000678, l5: 0.001059, l6: 0.001541

[epoch: 231/1000, batch:   120/ 1052, ite: 60520] train loss: 0.005798, tar: 0.000407 
l0: 0.000176, l1: 0.000181, l2: 0.000196, l3: 0.000228, l4: 0.000350, l5: 0.000691, l6: 0.001702

[epoch: 231/1000, batch:   200/ 1052, ite: 60540] train loss: 0.005796, tar: 0.000407 
l0: 0.000413, l1: 0.000420, l2: 0.000394, l3: 0.000448, l4: 0.000604, l5: 0.001191, l6: 0.002437

[epoch: 231/1000, batch:   280/ 1052, ite: 60560] train loss: 0.005797, tar: 0.000407 
l0: 0.000351, l1: 0.000340, l2: 0.000394, l3: 0.000536, l4: 0.001041, l5: 0.001657, l6: 0.002132

[epoch: 231/1000, batch:   360/ 1052, ite: 60580] train loss: 0.005794, tar: 0.000407 
l0: 0.000248, l1: 0.000251, l2: 0.000302, l3: 0.000328, l4: 0.000440, l5: 0.000727, l6: 0.002400

[epoch: 231/1000, batch:   440/ 1052, ite: 60600] train loss: 0.005795, tar: 0.000406 
l0: 0.000203, l1: 0.000198, l2: 0.000224, l3: 0.000312, l4: 0.000483, l5: 0.001278, l6: 0.001597

[epoch: 231/1000, batch:   520/ 1052, ite: 60620] train loss: 0.005796, tar: 0.000406 
l0: 0.000144, l1: 0.000140, l2: 0.000171, l3: 0.000214, l4: 0.000274, l5: 0.000623, l6: 0.000667

[epoch: 231/1000, batch:   600/ 1052, ite: 60640] train loss: 0.005794, tar: 0.000406 
l0: 0.000652, l1: 0.000675, l2: 0.000694, l3: 0.000798, l4: 0.001131, l5: 0.001684, l6: 0.003144

[epoch: 231/1000, batch:   680/ 1052, ite: 60660] train loss: 0.005794, tar: 0.000406 
l0: 0.000297, l1: 0.000304, l2: 0.000304, l3: 0.000360, l4: 0.000618, l5: 0.000653, l6: 0.001703

[epoch: 231/1000, batch:   760/ 1052, ite: 60680] train loss: 0.005791, tar: 0.000406 
l0: 0.000218, l1: 0.000218, l2: 0.000242, l3: 0.000319, l4: 0.000587, l5: 0.001287, l6: 0.002006

[epoch: 231/1000, batch:   840/ 1052, ite: 60700] train loss: 0.005790, tar: 0.000406 
l0: 0.000391, l1: 0.000407, l2: 0.000409, l3: 0.000499, l4: 0.000807, l5: 0.001700, l6: 0.003182

[epoch: 231/1000, batch:   920/ 1052, ite: 60720] train loss: 0.005787, tar: 0.000405 
l0: 0.000278, l1: 0.000279, l2: 0.000301, l3: 0.000373, l4: 0.000523, l5: 0.001173, l6: 0.002222

[epoch: 231/1000, batch:  1000/ 1052, ite: 60740] train loss: 0.005787, tar: 0.000405 
[Epoch 231/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000681, l1: 0.000683, l2: 0.000756, l3: 0.000853, l4: 0.001306, l5: 0.001846, l6: 0.004092

[epoch: 232/1000, batch:    28/ 1052, ite: 60760] train loss: 0.005787, tar: 0.000405 
l0: 0.000822, l1: 0.000872, l2: 0.000862, l3: 0.000890, l4: 0.001157, l5: 0.001717, l6: 0.003572

[epoch: 232/1000, batch:   108/ 1052, ite: 60780] train loss: 0.005785, tar: 0.000405 
l0: 0.000217, l1: 0.000221, l2: 0.000234, l3: 0.000281, l4: 0.000535, l5: 0.001052, l6: 0.001603

[epoch: 232/1000, batch:   188/ 1052, ite: 60800] train loss: 0.005783, tar: 0.000405 
l0: 0.000311, l1: 0.000316, l2: 0.000315, l3: 0.000398, l4: 0.000728, l5: 0.001594, l6: 0.002298

[epoch: 232/1000, batch:   268/ 1052, ite: 60820] train loss: 0.005781, tar: 0.000405 
l0: 0.000491, l1: 0.000510, l2: 0.000528, l3: 0.000508, l4: 0.000816, l5: 0.001631, l6: 0.002684

[epoch: 232/1000, batch:   348/ 1052, ite: 60840] train loss: 0.005782, tar: 0.000405 
l0: 0.000495, l1: 0.000501, l2: 0.000515, l3: 0.000558, l4: 0.001009, l5: 0.001871, l6: 0.003203

[epoch: 232/1000, batch:   428/ 1052, ite: 60860] train loss: 0.005781, tar: 0.000404 
l0: 0.000298, l1: 0.000298, l2: 0.000296, l3: 0.000353, l4: 0.000667, l5: 0.001307, l6: 0.001473

[epoch: 232/1000, batch:   508/ 1052, ite: 60880] train loss: 0.005781, tar: 0.000404 
l0: 0.000296, l1: 0.000302, l2: 0.000304, l3: 0.000375, l4: 0.000617, l5: 0.000956, l6: 0.002039

[epoch: 232/1000, batch:   588/ 1052, ite: 60900] train loss: 0.005781, tar: 0.000404 
l0: 0.000396, l1: 0.000395, l2: 0.000419, l3: 0.000500, l4: 0.000757, l5: 0.001315, l6: 0.002466

[epoch: 232/1000, batch:   668/ 1052, ite: 60920] train loss: 0.005779, tar: 0.000404 
l0: 0.000423, l1: 0.000437, l2: 0.000438, l3: 0.000448, l4: 0.000723, l5: 0.000760, l6: 0.002374

[epoch: 232/1000, batch:   748/ 1052, ite: 60940] train loss: 0.005781, tar: 0.000404 
l0: 0.000279, l1: 0.000278, l2: 0.000300, l3: 0.000339, l4: 0.000516, l5: 0.000945, l6: 0.002032

[epoch: 232/1000, batch:   828/ 1052, ite: 60960] train loss: 0.005779, tar: 0.000404 
l0: 0.000401, l1: 0.000386, l2: 0.000410, l3: 0.000514, l4: 0.000704, l5: 0.001365, l6: 0.002101

[epoch: 232/1000, batch:   908/ 1052, ite: 60980] train loss: 0.005778, tar: 0.000404 
l0: 0.000483, l1: 0.000524, l2: 0.000468, l3: 0.000494, l4: 0.000583, l5: 0.001166, l6: 0.002417

[epoch: 232/1000, batch:   988/ 1052, ite: 61000] train loss: 0.005778, tar: 0.000404 
[Epoch 232/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000270, l1: 0.000274, l2: 0.000257, l3: 0.000331, l4: 0.000484, l5: 0.000783, l6: 0.001844

[epoch: 233/1000, batch:    16/ 1052, ite: 61020] train loss: 0.005775, tar: 0.000403 
l0: 0.000404, l1: 0.000395, l2: 0.000438, l3: 0.000564, l4: 0.001004, l5: 0.001559, l6: 0.002885

[epoch: 233/1000, batch:    96/ 1052, ite: 61040] train loss: 0.005774, tar: 0.000403 
l0: 0.000462, l1: 0.000451, l2: 0.000498, l3: 0.000549, l4: 0.000823, l5: 0.001371, l6: 0.003082

[epoch: 233/1000, batch:   176/ 1052, ite: 61060] train loss: 0.005774, tar: 0.000403 
l0: 0.000268, l1: 0.000272, l2: 0.000272, l3: 0.000361, l4: 0.000660, l5: 0.000962, l6: 0.001758

[epoch: 233/1000, batch:   256/ 1052, ite: 61080] train loss: 0.005773, tar: 0.000403 
l0: 0.000376, l1: 0.000398, l2: 0.000407, l3: 0.000369, l4: 0.000623, l5: 0.001029, l6: 0.002355

[epoch: 233/1000, batch:   336/ 1052, ite: 61100] train loss: 0.005772, tar: 0.000403 
l0: 0.000181, l1: 0.000185, l2: 0.000209, l3: 0.000253, l4: 0.000404, l5: 0.000667, l6: 0.001324

[epoch: 233/1000, batch:   416/ 1052, ite: 61120] train loss: 0.005771, tar: 0.000403 
l0: 0.000362, l1: 0.000372, l2: 0.000374, l3: 0.000459, l4: 0.000838, l5: 0.001085, l6: 0.002651

[epoch: 233/1000, batch:   496/ 1052, ite: 61140] train loss: 0.005771, tar: 0.000403 
l0: 0.000212, l1: 0.000222, l2: 0.000232, l3: 0.000290, l4: 0.000474, l5: 0.001106, l6: 0.001966

[epoch: 233/1000, batch:   576/ 1052, ite: 61160] train loss: 0.005772, tar: 0.000403 
l0: 0.000515, l1: 0.000533, l2: 0.000523, l3: 0.000709, l4: 0.001036, l5: 0.001369, l6: 0.003487

[epoch: 233/1000, batch:   656/ 1052, ite: 61180] train loss: 0.005771, tar: 0.000402 
l0: 0.000173, l1: 0.000166, l2: 0.000218, l3: 0.000284, l4: 0.000481, l5: 0.000712, l6: 0.001360

[epoch: 233/1000, batch:   736/ 1052, ite: 61200] train loss: 0.005770, tar: 0.000402 
l0: 0.000818, l1: 0.000859, l2: 0.000829, l3: 0.000832, l4: 0.001219, l5: 0.002443, l6: 0.005179

[epoch: 233/1000, batch:   816/ 1052, ite: 61220] train loss: 0.005770, tar: 0.000402 
l0: 0.000679, l1: 0.000674, l2: 0.000716, l3: 0.000898, l4: 0.001409, l5: 0.003505, l6: 0.006034

[epoch: 233/1000, batch:   896/ 1052, ite: 61240] train loss: 0.005770, tar: 0.000402 
l0: 0.000093, l1: 0.000086, l2: 0.000138, l3: 0.000185, l4: 0.000503, l5: 0.000605, l6: 0.001093

[epoch: 233/1000, batch:   976/ 1052, ite: 61260] train loss: 0.005769, tar: 0.000402 
[Epoch 233/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000236, l1: 0.000238, l2: 0.000235, l3: 0.000274, l4: 0.000688, l5: 0.001115, l6: 0.001695

[epoch: 234/1000, batch:     4/ 1052, ite: 61280] train loss: 0.005767, tar: 0.000402 
l0: 0.000354, l1: 0.000340, l2: 0.000381, l3: 0.000527, l4: 0.000767, l5: 0.001034, l6: 0.001410

[epoch: 234/1000, batch:    84/ 1052, ite: 61300] train loss: 0.005768, tar: 0.000402 
l0: 0.000438, l1: 0.000464, l2: 0.000436, l3: 0.000485, l4: 0.000812, l5: 0.001417, l6: 0.002408

[epoch: 234/1000, batch:   164/ 1052, ite: 61320] train loss: 0.005767, tar: 0.000402 
l0: 0.000397, l1: 0.000400, l2: 0.000442, l3: 0.000531, l4: 0.000774, l5: 0.001566, l6: 0.002414

[epoch: 234/1000, batch:   244/ 1052, ite: 61340] train loss: 0.005766, tar: 0.000402 
l0: 0.000180, l1: 0.000180, l2: 0.000191, l3: 0.000236, l4: 0.000366, l5: 0.000837, l6: 0.001227

[epoch: 234/1000, batch:   324/ 1052, ite: 61360] train loss: 0.005764, tar: 0.000401 
l0: 0.000468, l1: 0.000475, l2: 0.000540, l3: 0.000612, l4: 0.000950, l5: 0.001457, l6: 0.002882

[epoch: 234/1000, batch:   404/ 1052, ite: 61380] train loss: 0.005766, tar: 0.000401 
l0: 0.000280, l1: 0.000286, l2: 0.000295, l3: 0.000340, l4: 0.000434, l5: 0.001245, l6: 0.002078

[epoch: 234/1000, batch:   484/ 1052, ite: 61400] train loss: 0.005767, tar: 0.000401 
l0: 0.000714, l1: 0.000715, l2: 0.000793, l3: 0.000732, l4: 0.001001, l5: 0.001654, l6: 0.002128

[epoch: 234/1000, batch:   564/ 1052, ite: 61420] train loss: 0.005765, tar: 0.000401 
l0: 0.000415, l1: 0.000442, l2: 0.000435, l3: 0.000438, l4: 0.000556, l5: 0.000903, l6: 0.002065

[epoch: 234/1000, batch:   644/ 1052, ite: 61440] train loss: 0.005766, tar: 0.000401 
l0: 0.000210, l1: 0.000202, l2: 0.000244, l3: 0.000400, l4: 0.000585, l5: 0.001252, l6: 0.001904

[epoch: 234/1000, batch:   724/ 1052, ite: 61460] train loss: 0.005765, tar: 0.000401 
l0: 0.000134, l1: 0.000128, l2: 0.000165, l3: 0.000209, l4: 0.000335, l5: 0.000590, l6: 0.001088

[epoch: 234/1000, batch:   804/ 1052, ite: 61480] train loss: 0.005764, tar: 0.000401 
l0: 0.000508, l1: 0.000526, l2: 0.000574, l3: 0.000507, l4: 0.000684, l5: 0.000932, l6: 0.001885

[epoch: 234/1000, batch:   884/ 1052, ite: 61500] train loss: 0.005762, tar: 0.000401 
l0: 0.000263, l1: 0.000248, l2: 0.000281, l3: 0.000346, l4: 0.000540, l5: 0.000786, l6: 0.001520

[epoch: 234/1000, batch:   964/ 1052, ite: 61520] train loss: 0.005763, tar: 0.000401 
l0: 0.000199, l1: 0.000188, l2: 0.000213, l3: 0.000312, l4: 0.000443, l5: 0.001432, l6: 0.002014

[epoch: 234/1000, batch:  1044/ 1052, ite: 61540] train loss: 0.005761, tar: 0.000401 
[Epoch 234/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000508, l1: 0.000494, l2: 0.000549, l3: 0.000652, l4: 0.000885, l5: 0.001707, l6: 0.002981

[epoch: 235/1000, batch:    72/ 1052, ite: 61560] train loss: 0.005761, tar: 0.000401 
l0: 0.000410, l1: 0.000461, l2: 0.000455, l3: 0.000396, l4: 0.000819, l5: 0.001410, l6: 0.003012

[epoch: 235/1000, batch:   152/ 1052, ite: 61580] train loss: 0.005760, tar: 0.000400 
l0: 0.000165, l1: 0.000163, l2: 0.000195, l3: 0.000251, l4: 0.000467, l5: 0.000846, l6: 0.001427

[epoch: 235/1000, batch:   232/ 1052, ite: 61600] train loss: 0.005758, tar: 0.000400 
l0: 0.000204, l1: 0.000203, l2: 0.000239, l3: 0.000338, l4: 0.000600, l5: 0.000917, l6: 0.001959

[epoch: 235/1000, batch:   312/ 1052, ite: 61620] train loss: 0.005757, tar: 0.000400 
l0: 0.000261, l1: 0.000293, l2: 0.000326, l3: 0.000401, l4: 0.000658, l5: 0.001118, l6: 0.001761

[epoch: 235/1000, batch:   392/ 1052, ite: 61640] train loss: 0.005756, tar: 0.000400 
l0: 0.000557, l1: 0.000568, l2: 0.000581, l3: 0.000559, l4: 0.001104, l5: 0.002082, l6: 0.003851

[epoch: 235/1000, batch:   472/ 1052, ite: 61660] train loss: 0.005755, tar: 0.000400 
l0: 0.000362, l1: 0.000383, l2: 0.000401, l3: 0.000436, l4: 0.000732, l5: 0.001250, l6: 0.002321

[epoch: 235/1000, batch:   552/ 1052, ite: 61680] train loss: 0.005756, tar: 0.000400 
l0: 0.000381, l1: 0.000392, l2: 0.000428, l3: 0.000494, l4: 0.000783, l5: 0.001281, l6: 0.002218

[epoch: 235/1000, batch:   632/ 1052, ite: 61700] train loss: 0.005756, tar: 0.000400 
l0: 0.000192, l1: 0.000187, l2: 0.000214, l3: 0.000256, l4: 0.000368, l5: 0.000623, l6: 0.001036

[epoch: 235/1000, batch:   712/ 1052, ite: 61720] train loss: 0.005755, tar: 0.000399 
l0: 0.000550, l1: 0.000539, l2: 0.000580, l3: 0.000694, l4: 0.001263, l5: 0.002123, l6: 0.004133

[epoch: 235/1000, batch:   792/ 1052, ite: 61740] train loss: 0.005755, tar: 0.000399 
l0: 0.000399, l1: 0.000413, l2: 0.000407, l3: 0.000407, l4: 0.000566, l5: 0.001407, l6: 0.001666

[epoch: 235/1000, batch:   872/ 1052, ite: 61760] train loss: 0.005754, tar: 0.000399 
l0: 0.000264, l1: 0.000310, l2: 0.000215, l3: 0.000209, l4: 0.000260, l5: 0.000375, l6: 0.000477

[epoch: 235/1000, batch:   952/ 1052, ite: 61780] train loss: 0.005753, tar: 0.000399 
l0: 0.000389, l1: 0.000377, l2: 0.000451, l3: 0.000500, l4: 0.000809, l5: 0.001374, l6: 0.002950

[epoch: 235/1000, batch:  1032/ 1052, ite: 61800] train loss: 0.005752, tar: 0.000399 
[Epoch 235/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000186, l1: 0.000184, l2: 0.000219, l3: 0.000304, l4: 0.000561, l5: 0.001048, l6: 0.001719

[epoch: 236/1000, batch:    60/ 1052, ite: 61820] train loss: 0.005751, tar: 0.000399 
l0: 0.000563, l1: 0.000560, l2: 0.000559, l3: 0.000689, l4: 0.000972, l5: 0.001791, l6: 0.002991

[epoch: 236/1000, batch:   140/ 1052, ite: 61840] train loss: 0.005751, tar: 0.000399 
l0: 0.000253, l1: 0.000262, l2: 0.000274, l3: 0.000266, l4: 0.000333, l5: 0.000858, l6: 0.001432

[epoch: 236/1000, batch:   220/ 1052, ite: 61860] train loss: 0.005750, tar: 0.000399 
l0: 0.000491, l1: 0.000518, l2: 0.000498, l3: 0.000471, l4: 0.000762, l5: 0.001510, l6: 0.002189

[epoch: 236/1000, batch:   300/ 1052, ite: 61880] train loss: 0.005749, tar: 0.000399 
l0: 0.000341, l1: 0.000339, l2: 0.000366, l3: 0.000497, l4: 0.000759, l5: 0.001165, l6: 0.002180

[epoch: 236/1000, batch:   380/ 1052, ite: 61900] train loss: 0.005749, tar: 0.000398 
l0: 0.000279, l1: 0.000281, l2: 0.000320, l3: 0.000383, l4: 0.000712, l5: 0.001211, l6: 0.001786

[epoch: 236/1000, batch:   460/ 1052, ite: 61920] train loss: 0.005747, tar: 0.000398 
l0: 0.000276, l1: 0.000273, l2: 0.000290, l3: 0.000354, l4: 0.000733, l5: 0.001070, l6: 0.002340

[epoch: 236/1000, batch:   540/ 1052, ite: 61940] train loss: 0.005747, tar: 0.000398 
l0: 0.000326, l1: 0.000307, l2: 0.000402, l3: 0.000601, l4: 0.000818, l5: 0.001264, l6: 0.002253

[epoch: 236/1000, batch:   620/ 1052, ite: 61960] train loss: 0.005749, tar: 0.000398 
l0: 0.000489, l1: 0.000483, l2: 0.000471, l3: 0.000690, l4: 0.000727, l5: 0.001876, l6: 0.002323

[epoch: 236/1000, batch:   700/ 1052, ite: 61980] train loss: 0.005751, tar: 0.000398 
l0: 0.000188, l1: 0.000189, l2: 0.000196, l3: 0.000239, l4: 0.000314, l5: 0.000746, l6: 0.001377

[epoch: 236/1000, batch:   780/ 1052, ite: 62000] train loss: 0.005750, tar: 0.000398 
l0: 0.000257, l1: 0.000255, l2: 0.000288, l3: 0.000378, l4: 0.000502, l5: 0.001045, l6: 0.001756

[epoch: 236/1000, batch:   860/ 1052, ite: 62020] train loss: 0.005749, tar: 0.000398 
l0: 0.000349, l1: 0.000345, l2: 0.000383, l3: 0.000444, l4: 0.000610, l5: 0.001022, l6: 0.001521

[epoch: 236/1000, batch:   940/ 1052, ite: 62040] train loss: 0.005747, tar: 0.000398 
l0: 0.000144, l1: 0.000145, l2: 0.000177, l3: 0.000214, l4: 0.000379, l5: 0.000616, l6: 0.001132

[epoch: 236/1000, batch:  1020/ 1052, ite: 62060] train loss: 0.005745, tar: 0.000398 
[Epoch 236/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000312, l1: 0.000315, l2: 0.000404, l3: 0.000503, l4: 0.000866, l5: 0.001330, l6: 0.002861

[epoch: 237/1000, batch:    48/ 1052, ite: 62080] train loss: 0.005746, tar: 0.000398 
l0: 0.000174, l1: 0.000177, l2: 0.000191, l3: 0.000225, l4: 0.000379, l5: 0.000814, l6: 0.001868

[epoch: 237/1000, batch:   128/ 1052, ite: 62100] train loss: 0.005746, tar: 0.000398 
l0: 0.000295, l1: 0.000295, l2: 0.000285, l3: 0.000326, l4: 0.000468, l5: 0.000859, l6: 0.001404

[epoch: 237/1000, batch:   208/ 1052, ite: 62120] train loss: 0.005745, tar: 0.000398 
l0: 0.000364, l1: 0.000366, l2: 0.000385, l3: 0.000464, l4: 0.000770, l5: 0.001340, l6: 0.002480

[epoch: 237/1000, batch:   288/ 1052, ite: 62140] train loss: 0.005746, tar: 0.000398 
l0: 0.000576, l1: 0.000581, l2: 0.000643, l3: 0.000662, l4: 0.001181, l5: 0.001636, l6: 0.003268

[epoch: 237/1000, batch:   368/ 1052, ite: 62160] train loss: 0.005744, tar: 0.000397 
l0: 0.000601, l1: 0.000593, l2: 0.000636, l3: 0.000839, l4: 0.001278, l5: 0.001919, l6: 0.003634

[epoch: 237/1000, batch:   448/ 1052, ite: 62180] train loss: 0.005745, tar: 0.000397 
l0: 0.000297, l1: 0.000294, l2: 0.000332, l3: 0.000373, l4: 0.000592, l5: 0.000995, l6: 0.002004

[epoch: 237/1000, batch:   528/ 1052, ite: 62200] train loss: 0.005744, tar: 0.000397 
l0: 0.000235, l1: 0.000245, l2: 0.000265, l3: 0.000432, l4: 0.000744, l5: 0.001256, l6: 0.001642

[epoch: 237/1000, batch:   608/ 1052, ite: 62220] train loss: 0.005742, tar: 0.000397 
l0: 0.000444, l1: 0.000451, l2: 0.000488, l3: 0.000564, l4: 0.000868, l5: 0.001625, l6: 0.003060

[epoch: 237/1000, batch:   688/ 1052, ite: 62240] train loss: 0.005742, tar: 0.000397 
l0: 0.000275, l1: 0.000290, l2: 0.000286, l3: 0.000344, l4: 0.000582, l5: 0.001001, l6: 0.001062

[epoch: 237/1000, batch:   768/ 1052, ite: 62260] train loss: 0.005740, tar: 0.000397 
l0: 0.000432, l1: 0.000445, l2: 0.000457, l3: 0.000520, l4: 0.000940, l5: 0.001548, l6: 0.002819

[epoch: 237/1000, batch:   848/ 1052, ite: 62280] train loss: 0.005739, tar: 0.000397 
l0: 0.000218, l1: 0.000229, l2: 0.000226, l3: 0.000274, l4: 0.000359, l5: 0.000807, l6: 0.001414

[epoch: 237/1000, batch:   928/ 1052, ite: 62300] train loss: 0.005738, tar: 0.000397 
l0: 0.000262, l1: 0.000255, l2: 0.000331, l3: 0.000445, l4: 0.000638, l5: 0.001160, l6: 0.002018

[epoch: 237/1000, batch:  1008/ 1052, ite: 62320] train loss: 0.005737, tar: 0.000397 
[Epoch 237/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000317, l1: 0.000311, l2: 0.000372, l3: 0.000410, l4: 0.000689, l5: 0.001039, l6: 0.002429

[epoch: 238/1000, batch:    36/ 1052, ite: 62340] train loss: 0.005737, tar: 0.000397 
l0: 0.000219, l1: 0.000243, l2: 0.000223, l3: 0.000230, l4: 0.000464, l5: 0.000656, l6: 0.001129

[epoch: 238/1000, batch:   116/ 1052, ite: 62360] train loss: 0.005736, tar: 0.000396 
l0: 0.000289, l1: 0.000283, l2: 0.000319, l3: 0.000406, l4: 0.000629, l5: 0.001256, l6: 0.002258

[epoch: 238/1000, batch:   196/ 1052, ite: 62380] train loss: 0.005735, tar: 0.000396 
l0: 0.000331, l1: 0.000335, l2: 0.000355, l3: 0.000367, l4: 0.000495, l5: 0.000986, l6: 0.001737

[epoch: 238/1000, batch:   276/ 1052, ite: 62400] train loss: 0.005734, tar: 0.000396 
l0: 0.000295, l1: 0.000301, l2: 0.000290, l3: 0.000344, l4: 0.000544, l5: 0.000849, l6: 0.000829

[epoch: 238/1000, batch:   356/ 1052, ite: 62420] train loss: 0.005734, tar: 0.000396 
l0: 0.000237, l1: 0.000244, l2: 0.000250, l3: 0.000404, l4: 0.000869, l5: 0.001435, l6: 0.001850

[epoch: 238/1000, batch:   436/ 1052, ite: 62440] train loss: 0.005735, tar: 0.000396 
l0: 0.000258, l1: 0.000262, l2: 0.000269, l3: 0.000261, l4: 0.000441, l5: 0.000742, l6: 0.001338

[epoch: 238/1000, batch:   516/ 1052, ite: 62460] train loss: 0.005734, tar: 0.000396 
l0: 0.000481, l1: 0.000463, l2: 0.000536, l3: 0.000751, l4: 0.001234, l5: 0.001918, l6: 0.002515

[epoch: 238/1000, batch:   596/ 1052, ite: 62480] train loss: 0.005733, tar: 0.000396 
l0: 0.000449, l1: 0.000491, l2: 0.000411, l3: 0.000605, l4: 0.000689, l5: 0.001487, l6: 0.002230

[epoch: 238/1000, batch:   676/ 1052, ite: 62500] train loss: 0.005731, tar: 0.000396 
l0: 0.000859, l1: 0.000888, l2: 0.000913, l3: 0.001015, l4: 0.001620, l5: 0.002948, l6: 0.005215

[epoch: 238/1000, batch:   756/ 1052, ite: 62520] train loss: 0.005731, tar: 0.000396 
l0: 0.000731, l1: 0.000715, l2: 0.000788, l3: 0.000793, l4: 0.000839, l5: 0.001326, l6: 0.002857

[epoch: 238/1000, batch:   836/ 1052, ite: 62540] train loss: 0.005731, tar: 0.000395 
l0: 0.000570, l1: 0.000589, l2: 0.000573, l3: 0.000580, l4: 0.000910, l5: 0.001789, l6: 0.002626

[epoch: 238/1000, batch:   916/ 1052, ite: 62560] train loss: 0.005730, tar: 0.000395 
l0: 0.000527, l1: 0.000567, l2: 0.000582, l3: 0.000585, l4: 0.000757, l5: 0.001691, l6: 0.002615

[epoch: 238/1000, batch:   996/ 1052, ite: 62580] train loss: 0.005732, tar: 0.000395 
[Epoch 238/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000423, l1: 0.000409, l2: 0.000475, l3: 0.000639, l4: 0.000885, l5: 0.001434, l6: 0.002375

[epoch: 239/1000, batch:    24/ 1052, ite: 62600] train loss: 0.005731, tar: 0.000395 
l0: 0.000252, l1: 0.000238, l2: 0.000259, l3: 0.000381, l4: 0.000535, l5: 0.001084, l6: 0.001485

[epoch: 239/1000, batch:   104/ 1052, ite: 62620] train loss: 0.005729, tar: 0.000395 
l0: 0.000204, l1: 0.000202, l2: 0.000225, l3: 0.000266, l4: 0.000445, l5: 0.000622, l6: 0.001418

[epoch: 239/1000, batch:   184/ 1052, ite: 62640] train loss: 0.005728, tar: 0.000395 
l0: 0.000408, l1: 0.000423, l2: 0.000438, l3: 0.000682, l4: 0.001090, l5: 0.001955, l6: 0.002735

[epoch: 239/1000, batch:   264/ 1052, ite: 62660] train loss: 0.005729, tar: 0.000395 
l0: 0.000227, l1: 0.000228, l2: 0.000272, l3: 0.000269, l4: 0.000511, l5: 0.001068, l6: 0.001417

[epoch: 239/1000, batch:   344/ 1052, ite: 62680] train loss: 0.005729, tar: 0.000395 
l0: 0.000230, l1: 0.000241, l2: 0.000236, l3: 0.000330, l4: 0.000489, l5: 0.001087, l6: 0.001622

[epoch: 239/1000, batch:   424/ 1052, ite: 62700] train loss: 0.005728, tar: 0.000395 
l0: 0.000428, l1: 0.000456, l2: 0.000415, l3: 0.000420, l4: 0.000542, l5: 0.001270, l6: 0.001889

[epoch: 239/1000, batch:   504/ 1052, ite: 62720] train loss: 0.005727, tar: 0.000395 
l0: 0.000505, l1: 0.000518, l2: 0.000488, l3: 0.000552, l4: 0.000738, l5: 0.001782, l6: 0.002572

[epoch: 239/1000, batch:   584/ 1052, ite: 62740] train loss: 0.005725, tar: 0.000395 
l0: 0.000399, l1: 0.000394, l2: 0.000437, l3: 0.000540, l4: 0.000796, l5: 0.001747, l6: 0.003259

[epoch: 239/1000, batch:   664/ 1052, ite: 62760] train loss: 0.005725, tar: 0.000394 
l0: 0.000160, l1: 0.000160, l2: 0.000179, l3: 0.000233, l4: 0.000425, l5: 0.000938, l6: 0.001604

[epoch: 239/1000, batch:   744/ 1052, ite: 62780] train loss: 0.005724, tar: 0.000394 
l0: 0.000209, l1: 0.000215, l2: 0.000213, l3: 0.000240, l4: 0.000377, l5: 0.000934, l6: 0.001301

[epoch: 239/1000, batch:   824/ 1052, ite: 62800] train loss: 0.005724, tar: 0.000394 
l0: 0.000237, l1: 0.000248, l2: 0.000230, l3: 0.000266, l4: 0.000614, l5: 0.000863, l6: 0.001709

[epoch: 239/1000, batch:   904/ 1052, ite: 62820] train loss: 0.005725, tar: 0.000394 
l0: 0.000395, l1: 0.000410, l2: 0.000425, l3: 0.000521, l4: 0.001114, l5: 0.001741, l6: 0.003044

[epoch: 239/1000, batch:   984/ 1052, ite: 62840] train loss: 0.005724, tar: 0.000394 
[Epoch 239/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000365, l1: 0.000359, l2: 0.000435, l3: 0.000436, l4: 0.000609, l5: 0.001432, l6: 0.001807

[epoch: 240/1000, batch:    12/ 1052, ite: 62860] train loss: 0.005723, tar: 0.000394 
l0: 0.000358, l1: 0.000353, l2: 0.000417, l3: 0.000471, l4: 0.000690, l5: 0.000959, l6: 0.001995

[epoch: 240/1000, batch:    92/ 1052, ite: 62880] train loss: 0.005723, tar: 0.000394 
l0: 0.000394, l1: 0.000402, l2: 0.000392, l3: 0.000441, l4: 0.000789, l5: 0.001638, l6: 0.002542

[epoch: 240/1000, batch:   172/ 1052, ite: 62900] train loss: 0.005721, tar: 0.000394 
l0: 0.000395, l1: 0.000390, l2: 0.000530, l3: 0.000691, l4: 0.000993, l5: 0.001692, l6: 0.002897

[epoch: 240/1000, batch:   252/ 1052, ite: 62920] train loss: 0.005722, tar: 0.000394 
l0: 0.000317, l1: 0.000337, l2: 0.000329, l3: 0.000354, l4: 0.000577, l5: 0.001333, l6: 0.001903

[epoch: 240/1000, batch:   332/ 1052, ite: 62940] train loss: 0.005720, tar: 0.000394 
l0: 0.000189, l1: 0.000184, l2: 0.000210, l3: 0.000268, l4: 0.000493, l5: 0.001028, l6: 0.001645

[epoch: 240/1000, batch:   412/ 1052, ite: 62960] train loss: 0.005720, tar: 0.000394 
l0: 0.000232, l1: 0.000232, l2: 0.000245, l3: 0.000378, l4: 0.000715, l5: 0.001265, l6: 0.001811

[epoch: 240/1000, batch:   492/ 1052, ite: 62980] train loss: 0.005720, tar: 0.000393 
l0: 0.000320, l1: 0.000312, l2: 0.000363, l3: 0.000479, l4: 0.000951, l5: 0.001615, l6: 0.002315

[epoch: 240/1000, batch:   572/ 1052, ite: 63000] train loss: 0.005721, tar: 0.000394 
l0: 0.000469, l1: 0.000467, l2: 0.000491, l3: 0.000638, l4: 0.000788, l5: 0.001420, l6: 0.001949

[epoch: 240/1000, batch:   652/ 1052, ite: 63020] train loss: 0.005723, tar: 0.000394 
l0: 0.000257, l1: 0.000267, l2: 0.000272, l3: 0.000293, l4: 0.000406, l5: 0.000807, l6: 0.001385

[epoch: 240/1000, batch:   732/ 1052, ite: 63040] train loss: 0.005721, tar: 0.000393 
l0: 0.000647, l1: 0.000646, l2: 0.000684, l3: 0.000740, l4: 0.001162, l5: 0.001798, l6: 0.002689

[epoch: 240/1000, batch:   812/ 1052, ite: 63060] train loss: 0.005721, tar: 0.000393 
l0: 0.000503, l1: 0.000510, l2: 0.000518, l3: 0.000634, l4: 0.000903, l5: 0.001437, l6: 0.002535

[epoch: 240/1000, batch:   892/ 1052, ite: 63080] train loss: 0.005720, tar: 0.000393 
l0: 0.000188, l1: 0.000186, l2: 0.000196, l3: 0.000302, l4: 0.000275, l5: 0.000695, l6: 0.001173

[epoch: 240/1000, batch:   972/ 1052, ite: 63100] train loss: 0.005719, tar: 0.000393 
l0: 0.000318, l1: 0.000315, l2: 0.000347, l3: 0.000396, l4: 0.000447, l5: 0.001201, l6: 0.001659

[epoch: 240/1000, batch:  1052/ 1052, ite: 63120] train loss: 0.005718, tar: 0.000393 
[Epoch 240/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000225, l1: 0.000230, l2: 0.000250, l3: 0.000299, l4: 0.000477, l5: 0.000895, l6: 0.002218

[epoch: 241/1000, batch:    80/ 1052, ite: 63140] train loss: 0.004850, tar: 0.000298 
l0: 0.000191, l1: 0.000183, l2: 0.000225, l3: 0.000259, l4: 0.000340, l5: 0.000882, l6: 0.001126

[epoch: 241/1000, batch:   160/ 1052, ite: 63160] train loss: 0.004956, tar: 0.000299 
l0: 0.000246, l1: 0.000245, l2: 0.000315, l3: 0.000262, l4: 0.000479, l5: 0.000735, l6: 0.001800

[epoch: 241/1000, batch:   240/ 1052, ite: 63180] train loss: 0.005016, tar: 0.000300 
l0: 0.000230, l1: 0.000226, l2: 0.000263, l3: 0.000351, l4: 0.000643, l5: 0.001196, l6: 0.001899

[epoch: 241/1000, batch:   320/ 1052, ite: 63200] train loss: 0.005172, tar: 0.000319 
l0: 0.000273, l1: 0.000283, l2: 0.000300, l3: 0.000302, l4: 0.000402, l5: 0.000881, l6: 0.001685

[epoch: 241/1000, batch:   400/ 1052, ite: 63220] train loss: 0.005306, tar: 0.000327 
l0: 0.000291, l1: 0.000311, l2: 0.000338, l3: 0.000320, l4: 0.000480, l5: 0.000807, l6: 0.001923

[epoch: 241/1000, batch:   480/ 1052, ite: 63240] train loss: 0.005349, tar: 0.000332 
l0: 0.000146, l1: 0.000148, l2: 0.000142, l3: 0.000198, l4: 0.000297, l5: 0.000711, l6: 0.001090

[epoch: 241/1000, batch:   560/ 1052, ite: 63260] train loss: 0.005325, tar: 0.000331 
l0: 0.000369, l1: 0.000383, l2: 0.000374, l3: 0.000420, l4: 0.000576, l5: 0.000918, l6: 0.001980

[epoch: 241/1000, batch:   640/ 1052, ite: 63280] train loss: 0.005315, tar: 0.000334 
l0: 0.000314, l1: 0.000314, l2: 0.000350, l3: 0.000406, l4: 0.000581, l5: 0.000963, l6: 0.001946

[epoch: 241/1000, batch:   720/ 1052, ite: 63300] train loss: 0.005323, tar: 0.000338 
l0: 0.000314, l1: 0.000336, l2: 0.000395, l3: 0.000382, l4: 0.000694, l5: 0.001502, l6: 0.002482

[epoch: 241/1000, batch:   800/ 1052, ite: 63320] train loss: 0.005281, tar: 0.000333 
l0: 0.000334, l1: 0.000335, l2: 0.000369, l3: 0.000409, l4: 0.000681, l5: 0.002305, l6: 0.002100

[epoch: 241/1000, batch:   880/ 1052, ite: 63340] train loss: 0.005303, tar: 0.000333 
l0: 0.000315, l1: 0.000322, l2: 0.000325, l3: 0.000351, l4: 0.000539, l5: 0.000716, l6: 0.001664

[epoch: 241/1000, batch:   960/ 1052, ite: 63360] train loss: 0.005352, tar: 0.000336 
l0: 0.000415, l1: 0.000408, l2: 0.000456, l3: 0.000601, l4: 0.000697, l5: 0.001354, l6: 0.002323

[epoch: 241/1000, batch:  1040/ 1052, ite: 63380] train loss: 0.005394, tar: 0.000338 
[Epoch 241/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000181, l1: 0.000188, l2: 0.000197, l3: 0.000234, l4: 0.000220, l5: 0.000781, l6: 0.001302

[epoch: 242/1000, batch:    68/ 1052, ite: 63400] train loss: 0.005389, tar: 0.000338 
l0: 0.000352, l1: 0.000363, l2: 0.000393, l3: 0.000394, l4: 0.000648, l5: 0.001242, l6: 0.002636

[epoch: 242/1000, batch:   148/ 1052, ite: 63420] train loss: 0.005416, tar: 0.000339 
l0: 0.000343, l1: 0.000341, l2: 0.000376, l3: 0.000370, l4: 0.000643, l5: 0.000834, l6: 0.001936

[epoch: 242/1000, batch:   228/ 1052, ite: 63440] train loss: 0.005411, tar: 0.000337 
l0: 0.000173, l1: 0.000178, l2: 0.000188, l3: 0.000241, l4: 0.000417, l5: 0.001012, l6: 0.001229

[epoch: 242/1000, batch:   308/ 1052, ite: 63460] train loss: 0.005440, tar: 0.000339 
l0: 0.000409, l1: 0.000425, l2: 0.000444, l3: 0.000440, l4: 0.000613, l5: 0.000805, l6: 0.001524

[epoch: 242/1000, batch:   388/ 1052, ite: 63480] train loss: 0.005429, tar: 0.000338 
l0: 0.000626, l1: 0.000615, l2: 0.000623, l3: 0.000736, l4: 0.001104, l5: 0.002094, l6: 0.003300

[epoch: 242/1000, batch:   468/ 1052, ite: 63500] train loss: 0.005428, tar: 0.000338 
l0: 0.000210, l1: 0.000215, l2: 0.000219, l3: 0.000240, l4: 0.000398, l5: 0.000850, l6: 0.001476

[epoch: 242/1000, batch:   548/ 1052, ite: 63520] train loss: 0.005412, tar: 0.000337 
l0: 0.000413, l1: 0.000404, l2: 0.000510, l3: 0.000633, l4: 0.000931, l5: 0.001250, l6: 0.002898

[epoch: 242/1000, batch:   628/ 1052, ite: 63540] train loss: 0.005420, tar: 0.000338 
l0: 0.000290, l1: 0.000286, l2: 0.000308, l3: 0.000366, l4: 0.000606, l5: 0.001390, l6: 0.002503

[epoch: 242/1000, batch:   708/ 1052, ite: 63560] train loss: 0.005443, tar: 0.000340 
l0: 0.000426, l1: 0.000433, l2: 0.000437, l3: 0.000537, l4: 0.000912, l5: 0.001468, l6: 0.002547

[epoch: 242/1000, batch:   788/ 1052, ite: 63580] train loss: 0.005453, tar: 0.000339 
l0: 0.000338, l1: 0.000341, l2: 0.000324, l3: 0.000456, l4: 0.000639, l5: 0.001067, l6: 0.002652

[epoch: 242/1000, batch:   868/ 1052, ite: 63600] train loss: 0.005435, tar: 0.000338 
l0: 0.000266, l1: 0.000276, l2: 0.000286, l3: 0.000311, l4: 0.000462, l5: 0.001170, l6: 0.001479

[epoch: 242/1000, batch:   948/ 1052, ite: 63620] train loss: 0.005402, tar: 0.000337 
l0: 0.000307, l1: 0.000297, l2: 0.000358, l3: 0.000514, l4: 0.000820, l5: 0.001164, l6: 0.002840

[epoch: 242/1000, batch:  1028/ 1052, ite: 63640] train loss: 0.005398, tar: 0.000336 
[Epoch 242/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000216, l1: 0.000225, l2: 0.000236, l3: 0.000266, l4: 0.000540, l5: 0.001151, l6: 0.002340

[epoch: 243/1000, batch:    56/ 1052, ite: 63660] train loss: 0.005379, tar: 0.000335 
l0: 0.000151, l1: 0.000146, l2: 0.000186, l3: 0.000237, l4: 0.000537, l5: 0.000894, l6: 0.001286

[epoch: 243/1000, batch:   136/ 1052, ite: 63680] train loss: 0.005392, tar: 0.000335 
l0: 0.000268, l1: 0.000269, l2: 0.000269, l3: 0.000310, l4: 0.000526, l5: 0.001048, l6: 0.001587

[epoch: 243/1000, batch:   216/ 1052, ite: 63700] train loss: 0.005357, tar: 0.000332 
l0: 0.000281, l1: 0.000281, l2: 0.000338, l3: 0.000339, l4: 0.000541, l5: 0.001072, l6: 0.001471

[epoch: 243/1000, batch:   296/ 1052, ite: 63720] train loss: 0.005372, tar: 0.000333 
l0: 0.000710, l1: 0.000742, l2: 0.000585, l3: 0.000768, l4: 0.001052, l5: 0.001678, l6: 0.002463

[epoch: 243/1000, batch:   376/ 1052, ite: 63740] train loss: 0.005387, tar: 0.000334 
l0: 0.000146, l1: 0.000154, l2: 0.000171, l3: 0.000175, l4: 0.000485, l5: 0.000914, l6: 0.001278

[epoch: 243/1000, batch:   456/ 1052, ite: 63760] train loss: 0.005386, tar: 0.000334 
l0: 0.000194, l1: 0.000163, l2: 0.000209, l3: 0.000300, l4: 0.000348, l5: 0.000545, l6: 0.000874

[epoch: 243/1000, batch:   536/ 1052, ite: 63780] train loss: 0.005393, tar: 0.000335 
l0: 0.000350, l1: 0.000371, l2: 0.000387, l3: 0.000365, l4: 0.000462, l5: 0.000951, l6: 0.001460

[epoch: 243/1000, batch:   616/ 1052, ite: 63800] train loss: 0.005377, tar: 0.000335 
l0: 0.000203, l1: 0.000209, l2: 0.000226, l3: 0.000254, l4: 0.000407, l5: 0.000882, l6: 0.001311

[epoch: 243/1000, batch:   696/ 1052, ite: 63820] train loss: 0.005374, tar: 0.000334 
l0: 0.000588, l1: 0.000581, l2: 0.000610, l3: 0.000792, l4: 0.001303, l5: 0.001782, l6: 0.003517

[epoch: 243/1000, batch:   776/ 1052, ite: 63840] train loss: 0.005387, tar: 0.000335 
l0: 0.000241, l1: 0.000251, l2: 0.000243, l3: 0.000314, l4: 0.000561, l5: 0.001532, l6: 0.001007

[epoch: 243/1000, batch:   856/ 1052, ite: 63860] train loss: 0.005390, tar: 0.000336 
l0: 0.000466, l1: 0.000462, l2: 0.000491, l3: 0.000535, l4: 0.000830, l5: 0.001554, l6: 0.003156

[epoch: 243/1000, batch:   936/ 1052, ite: 63880] train loss: 0.005389, tar: 0.000336 
l0: 0.000271, l1: 0.000278, l2: 0.000320, l3: 0.000369, l4: 0.000631, l5: 0.001082, l6: 0.001359

[epoch: 243/1000, batch:  1016/ 1052, ite: 63900] train loss: 0.005394, tar: 0.000336 
[Epoch 243/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000227, l1: 0.000224, l2: 0.000245, l3: 0.000285, l4: 0.000383, l5: 0.000657, l6: 0.001059

[epoch: 244/1000, batch:    44/ 1052, ite: 63920] train loss: 0.005386, tar: 0.000335 
l0: 0.000177, l1: 0.000187, l2: 0.000171, l3: 0.000183, l4: 0.000250, l5: 0.000598, l6: 0.000989

[epoch: 244/1000, batch:   124/ 1052, ite: 63940] train loss: 0.005378, tar: 0.000335 
l0: 0.000213, l1: 0.000223, l2: 0.000234, l3: 0.000250, l4: 0.000416, l5: 0.000820, l6: 0.000968

[epoch: 244/1000, batch:   204/ 1052, ite: 63960] train loss: 0.005369, tar: 0.000334 
l0: 0.000148, l1: 0.000152, l2: 0.000154, l3: 0.000193, l4: 0.000256, l5: 0.000746, l6: 0.001318

[epoch: 244/1000, batch:   284/ 1052, ite: 63980] train loss: 0.005382, tar: 0.000335 
l0: 0.000175, l1: 0.000179, l2: 0.000178, l3: 0.000234, l4: 0.000390, l5: 0.000808, l6: 0.000952

[epoch: 244/1000, batch:   364/ 1052, ite: 64000] train loss: 0.005373, tar: 0.000334 
l0: 0.000186, l1: 0.000195, l2: 0.000224, l3: 0.000239, l4: 0.000541, l5: 0.000834, l6: 0.001087

[epoch: 244/1000, batch:   444/ 1052, ite: 64020] train loss: 0.005359, tar: 0.000333 
l0: 0.000403, l1: 0.000397, l2: 0.000421, l3: 0.000511, l4: 0.000593, l5: 0.001105, l6: 0.001542

[epoch: 244/1000, batch:   524/ 1052, ite: 64040] train loss: 0.005359, tar: 0.000333 
l0: 0.000239, l1: 0.000238, l2: 0.000244, l3: 0.000296, l4: 0.000506, l5: 0.001017, l6: 0.001796

[epoch: 244/1000, batch:   604/ 1052, ite: 64060] train loss: 0.005369, tar: 0.000334 
l0: 0.000423, l1: 0.000421, l2: 0.000483, l3: 0.000498, l4: 0.000721, l5: 0.001453, l6: 0.002607

[epoch: 244/1000, batch:   684/ 1052, ite: 64080] train loss: 0.005369, tar: 0.000333 
l0: 0.000656, l1: 0.000700, l2: 0.000740, l3: 0.000724, l4: 0.001027, l5: 0.001911, l6: 0.004177

[epoch: 244/1000, batch:   764/ 1052, ite: 64100] train loss: 0.005369, tar: 0.000333 
l0: 0.000282, l1: 0.000285, l2: 0.000350, l3: 0.000361, l4: 0.000571, l5: 0.001318, l6: 0.002325

[epoch: 244/1000, batch:   844/ 1052, ite: 64120] train loss: 0.005363, tar: 0.000333 
l0: 0.000524, l1: 0.000552, l2: 0.000542, l3: 0.000547, l4: 0.000797, l5: 0.001771, l6: 0.002218

[epoch: 244/1000, batch:   924/ 1052, ite: 64140] train loss: 0.005378, tar: 0.000335 
l0: 0.000168, l1: 0.000161, l2: 0.000196, l3: 0.000248, l4: 0.000361, l5: 0.000801, l6: 0.001259

[epoch: 244/1000, batch:  1004/ 1052, ite: 64160] train loss: 0.005380, tar: 0.000336 
[Epoch 244/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000313, l1: 0.000319, l2: 0.000322, l3: 0.000343, l4: 0.000597, l5: 0.001119, l6: 0.001480

[epoch: 245/1000, batch:    32/ 1052, ite: 64180] train loss: 0.005385, tar: 0.000336 
l0: 0.001242, l1: 0.001359, l2: 0.001561, l3: 0.000929, l4: 0.001171, l5: 0.001581, l6: 0.002532

[epoch: 245/1000, batch:   112/ 1052, ite: 64200] train loss: 0.005398, tar: 0.000337 
l0: 0.000223, l1: 0.000225, l2: 0.000261, l3: 0.000298, l4: 0.000423, l5: 0.000602, l6: 0.001081

[epoch: 245/1000, batch:   192/ 1052, ite: 64220] train loss: 0.005410, tar: 0.000340 
l0: 0.000337, l1: 0.000358, l2: 0.000354, l3: 0.000469, l4: 0.000703, l5: 0.000821, l6: 0.001560

[epoch: 245/1000, batch:   272/ 1052, ite: 64240] train loss: 0.005408, tar: 0.000340 
l0: 0.000537, l1: 0.000543, l2: 0.000555, l3: 0.000645, l4: 0.001265, l5: 0.002107, l6: 0.003426

[epoch: 245/1000, batch:   352/ 1052, ite: 64260] train loss: 0.005420, tar: 0.000342 
l0: 0.000272, l1: 0.000269, l2: 0.000309, l3: 0.000368, l4: 0.000614, l5: 0.001168, l6: 0.001958

[epoch: 245/1000, batch:   432/ 1052, ite: 64280] train loss: 0.005417, tar: 0.000342 
l0: 0.000375, l1: 0.000378, l2: 0.000402, l3: 0.000447, l4: 0.000636, l5: 0.001435, l6: 0.002315

[epoch: 245/1000, batch:   512/ 1052, ite: 64300] train loss: 0.005424, tar: 0.000343 
l0: 0.000261, l1: 0.000268, l2: 0.000286, l3: 0.000333, l4: 0.000495, l5: 0.001066, l6: 0.002794

[epoch: 245/1000, batch:   592/ 1052, ite: 64320] train loss: 0.005427, tar: 0.000343 
l0: 0.000338, l1: 0.000340, l2: 0.000403, l3: 0.000479, l4: 0.000699, l5: 0.001248, l6: 0.002443

[epoch: 245/1000, batch:   672/ 1052, ite: 64340] train loss: 0.005431, tar: 0.000343 
l0: 0.000328, l1: 0.000340, l2: 0.000348, l3: 0.000388, l4: 0.000633, l5: 0.001072, l6: 0.002007

[epoch: 245/1000, batch:   752/ 1052, ite: 64360] train loss: 0.005449, tar: 0.000345 
l0: 0.000349, l1: 0.000355, l2: 0.000388, l3: 0.000433, l4: 0.000722, l5: 0.001179, l6: 0.002708

[epoch: 245/1000, batch:   832/ 1052, ite: 64380] train loss: 0.005457, tar: 0.000346 
l0: 0.000387, l1: 0.000376, l2: 0.000435, l3: 0.000517, l4: 0.000825, l5: 0.001296, l6: 0.002251

[epoch: 245/1000, batch:   912/ 1052, ite: 64400] train loss: 0.005450, tar: 0.000345 
l0: 0.000209, l1: 0.000210, l2: 0.000219, l3: 0.000269, l4: 0.000391, l5: 0.000804, l6: 0.001692

[epoch: 245/1000, batch:   992/ 1052, ite: 64420] train loss: 0.005449, tar: 0.000345 
[Epoch 245/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000484, l1: 0.000487, l2: 0.000491, l3: 0.000641, l4: 0.000822, l5: 0.001932, l6: 0.003759

[epoch: 246/1000, batch:    20/ 1052, ite: 64440] train loss: 0.005445, tar: 0.000345 
l0: 0.000131, l1: 0.000129, l2: 0.000146, l3: 0.000257, l4: 0.000498, l5: 0.000860, l6: 0.001327

[epoch: 246/1000, batch:   100/ 1052, ite: 64460] train loss: 0.005450, tar: 0.000346 
l0: 0.000302, l1: 0.000307, l2: 0.000319, l3: 0.000318, l4: 0.000535, l5: 0.000779, l6: 0.001555

[epoch: 246/1000, batch:   180/ 1052, ite: 64480] train loss: 0.005449, tar: 0.000346 
l0: 0.000102, l1: 0.000102, l2: 0.000110, l3: 0.000133, l4: 0.000287, l5: 0.000503, l6: 0.000758

[epoch: 246/1000, batch:   260/ 1052, ite: 64500] train loss: 0.005457, tar: 0.000346 
l0: 0.000553, l1: 0.000561, l2: 0.000578, l3: 0.000607, l4: 0.000796, l5: 0.002048, l6: 0.003479

[epoch: 246/1000, batch:   340/ 1052, ite: 64520] train loss: 0.005455, tar: 0.000346 
l0: 0.000319, l1: 0.000331, l2: 0.000368, l3: 0.000372, l4: 0.000606, l5: 0.000897, l6: 0.001897

[epoch: 246/1000, batch:   420/ 1052, ite: 64540] train loss: 0.005449, tar: 0.000346 
l0: 0.000244, l1: 0.000256, l2: 0.000282, l3: 0.000355, l4: 0.000629, l5: 0.000909, l6: 0.001891

[epoch: 246/1000, batch:   500/ 1052, ite: 64560] train loss: 0.005444, tar: 0.000345 
l0: 0.000510, l1: 0.000490, l2: 0.000590, l3: 0.000699, l4: 0.000788, l5: 0.002254, l6: 0.003053

[epoch: 246/1000, batch:   580/ 1052, ite: 64580] train loss: 0.005444, tar: 0.000345 
l0: 0.000373, l1: 0.000376, l2: 0.000414, l3: 0.000433, l4: 0.000763, l5: 0.000890, l6: 0.002247

[epoch: 246/1000, batch:   660/ 1052, ite: 64600] train loss: 0.005447, tar: 0.000345 
l0: 0.000215, l1: 0.000221, l2: 0.000223, l3: 0.000304, l4: 0.000330, l5: 0.000485, l6: 0.000774

[epoch: 246/1000, batch:   740/ 1052, ite: 64620] train loss: 0.005445, tar: 0.000344 
l0: 0.000523, l1: 0.000558, l2: 0.000620, l3: 0.000646, l4: 0.001354, l5: 0.002114, l6: 0.003680

[epoch: 246/1000, batch:   820/ 1052, ite: 64640] train loss: 0.005447, tar: 0.000345 
l0: 0.000270, l1: 0.000279, l2: 0.000242, l3: 0.000314, l4: 0.000524, l5: 0.000788, l6: 0.001343

[epoch: 246/1000, batch:   900/ 1052, ite: 64660] train loss: 0.005436, tar: 0.000344 
l0: 0.000287, l1: 0.000283, l2: 0.000328, l3: 0.000387, l4: 0.000639, l5: 0.000898, l6: 0.001466

[epoch: 246/1000, batch:   980/ 1052, ite: 64680] train loss: 0.005425, tar: 0.000343 
[Epoch 246/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000329, l1: 0.000319, l2: 0.000348, l3: 0.000443, l4: 0.000658, l5: 0.001432, l6: 0.001827

[epoch: 247/1000, batch:     8/ 1052, ite: 64700] train loss: 0.005426, tar: 0.000343 
l0: 0.000467, l1: 0.000474, l2: 0.000468, l3: 0.000545, l4: 0.000775, l5: 0.001110, l6: 0.001575

[epoch: 247/1000, batch:    88/ 1052, ite: 64720] train loss: 0.005417, tar: 0.000342 
l0: 0.000366, l1: 0.000367, l2: 0.000395, l3: 0.000492, l4: 0.000801, l5: 0.001729, l6: 0.002096

[epoch: 247/1000, batch:   168/ 1052, ite: 64740] train loss: 0.005417, tar: 0.000342 
l0: 0.000275, l1: 0.000270, l2: 0.000301, l3: 0.000388, l4: 0.000671, l5: 0.001039, l6: 0.001697

[epoch: 247/1000, batch:   248/ 1052, ite: 64760] train loss: 0.005420, tar: 0.000342 
l0: 0.000180, l1: 0.000181, l2: 0.000201, l3: 0.000237, l4: 0.000412, l5: 0.000994, l6: 0.001277

[epoch: 247/1000, batch:   328/ 1052, ite: 64780] train loss: 0.005424, tar: 0.000342 
l0: 0.000339, l1: 0.000348, l2: 0.000359, l3: 0.000401, l4: 0.000725, l5: 0.001179, l6: 0.001999

[epoch: 247/1000, batch:   408/ 1052, ite: 64800] train loss: 0.005421, tar: 0.000341 
l0: 0.000511, l1: 0.000521, l2: 0.000553, l3: 0.000615, l4: 0.001193, l5: 0.002243, l6: 0.002977

[epoch: 247/1000, batch:   488/ 1052, ite: 64820] train loss: 0.005415, tar: 0.000341 
l0: 0.000264, l1: 0.000264, l2: 0.000292, l3: 0.000303, l4: 0.000461, l5: 0.000802, l6: 0.001306

[epoch: 247/1000, batch:   568/ 1052, ite: 64840] train loss: 0.005415, tar: 0.000341 
l0: 0.000159, l1: 0.000154, l2: 0.000174, l3: 0.000233, l4: 0.000382, l5: 0.000770, l6: 0.001263

[epoch: 247/1000, batch:   648/ 1052, ite: 64860] train loss: 0.005408, tar: 0.000340 
l0: 0.000295, l1: 0.000313, l2: 0.000325, l3: 0.000349, l4: 0.000663, l5: 0.001038, l6: 0.002068

[epoch: 247/1000, batch:   728/ 1052, ite: 64880] train loss: 0.005405, tar: 0.000340 
l0: 0.000338, l1: 0.000324, l2: 0.000360, l3: 0.000441, l4: 0.000407, l5: 0.000939, l6: 0.001408

[epoch: 247/1000, batch:   808/ 1052, ite: 64900] train loss: 0.005404, tar: 0.000340 
l0: 0.000176, l1: 0.000177, l2: 0.000173, l3: 0.000233, l4: 0.000393, l5: 0.000591, l6: 0.001317

[epoch: 247/1000, batch:   888/ 1052, ite: 64920] train loss: 0.005402, tar: 0.000340 
l0: 0.000251, l1: 0.000253, l2: 0.000261, l3: 0.000371, l4: 0.000841, l5: 0.001336, l6: 0.001746

[epoch: 247/1000, batch:   968/ 1052, ite: 64940] train loss: 0.005406, tar: 0.000340 
l0: 0.000513, l1: 0.000523, l2: 0.000547, l3: 0.000713, l4: 0.001172, l5: 0.001737, l6: 0.002614

[epoch: 247/1000, batch:  1048/ 1052, ite: 64960] train loss: 0.005404, tar: 0.000340 
[Epoch 247/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000168, l1: 0.000161, l2: 0.000202, l3: 0.000293, l4: 0.000435, l5: 0.000726, l6: 0.000986

[epoch: 248/1000, batch:    76/ 1052, ite: 64980] train loss: 0.005403, tar: 0.000340 
l0: 0.000270, l1: 0.000286, l2: 0.000296, l3: 0.000287, l4: 0.000550, l5: 0.001043, l6: 0.002437

[epoch: 248/1000, batch:   156/ 1052, ite: 65000] train loss: 0.005404, tar: 0.000339 
l0: 0.000149, l1: 0.000150, l2: 0.000182, l3: 0.000221, l4: 0.000617, l5: 0.000874, l6: 0.001112

[epoch: 248/1000, batch:   236/ 1052, ite: 65020] train loss: 0.005396, tar: 0.000339 
l0: 0.000543, l1: 0.000544, l2: 0.000571, l3: 0.000636, l4: 0.000870, l5: 0.001171, l6: 0.002607

[epoch: 248/1000, batch:   316/ 1052, ite: 65040] train loss: 0.005399, tar: 0.000339 
l0: 0.000531, l1: 0.000532, l2: 0.000574, l3: 0.000727, l4: 0.001271, l5: 0.002095, l6: 0.003121

[epoch: 248/1000, batch:   396/ 1052, ite: 65060] train loss: 0.005397, tar: 0.000339 
l0: 0.000156, l1: 0.000164, l2: 0.000150, l3: 0.000182, l4: 0.000339, l5: 0.000618, l6: 0.001156

[epoch: 248/1000, batch:   476/ 1052, ite: 65080] train loss: 0.005395, tar: 0.000339 
l0: 0.000177, l1: 0.000177, l2: 0.000164, l3: 0.000212, l4: 0.000264, l5: 0.000433, l6: 0.001182

[epoch: 248/1000, batch:   556/ 1052, ite: 65100] train loss: 0.005392, tar: 0.000338 
l0: 0.000533, l1: 0.000564, l2: 0.000561, l3: 0.000525, l4: 0.000796, l5: 0.001595, l6: 0.002506

[epoch: 248/1000, batch:   636/ 1052, ite: 65120] train loss: 0.005393, tar: 0.000338 
l0: 0.000347, l1: 0.000345, l2: 0.000392, l3: 0.000425, l4: 0.000704, l5: 0.001407, l6: 0.001406

[epoch: 248/1000, batch:   716/ 1052, ite: 65140] train loss: 0.005389, tar: 0.000338 
l0: 0.000401, l1: 0.000404, l2: 0.000405, l3: 0.000538, l4: 0.000878, l5: 0.002571, l6: 0.003426

[epoch: 248/1000, batch:   796/ 1052, ite: 65160] train loss: 0.005386, tar: 0.000338 
l0: 0.000223, l1: 0.000217, l2: 0.000285, l3: 0.000418, l4: 0.000702, l5: 0.001410, l6: 0.002110

[epoch: 248/1000, batch:   876/ 1052, ite: 65180] train loss: 0.005390, tar: 0.000337 
l0: 0.000168, l1: 0.000174, l2: 0.000171, l3: 0.000203, l4: 0.000453, l5: 0.000704, l6: 0.001059

[epoch: 248/1000, batch:   956/ 1052, ite: 65200] train loss: 0.005388, tar: 0.000337 
l0: 0.000285, l1: 0.000299, l2: 0.000297, l3: 0.000359, l4: 0.000462, l5: 0.001288, l6: 0.001464

[epoch: 248/1000, batch:  1036/ 1052, ite: 65220] train loss: 0.005389, tar: 0.000337 
[Epoch 248/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000183, l1: 0.000178, l2: 0.000227, l3: 0.000341, l4: 0.000645, l5: 0.000721, l6: 0.001438

[epoch: 249/1000, batch:    64/ 1052, ite: 65240] train loss: 0.005394, tar: 0.000337 
l0: 0.000159, l1: 0.000164, l2: 0.000173, l3: 0.000219, l4: 0.000392, l5: 0.000605, l6: 0.001263

[epoch: 249/1000, batch:   144/ 1052, ite: 65260] train loss: 0.005393, tar: 0.000337 
l0: 0.000087, l1: 0.000086, l2: 0.000129, l3: 0.000157, l4: 0.000292, l5: 0.000403, l6: 0.000838

[epoch: 249/1000, batch:   224/ 1052, ite: 65280] train loss: 0.005392, tar: 0.000337 
l0: 0.000368, l1: 0.000377, l2: 0.000390, l3: 0.000573, l4: 0.000999, l5: 0.001581, l6: 0.002587

[epoch: 249/1000, batch:   304/ 1052, ite: 65300] train loss: 0.005396, tar: 0.000337 
l0: 0.000280, l1: 0.000298, l2: 0.000280, l3: 0.000331, l4: 0.000513, l5: 0.000582, l6: 0.001685

[epoch: 249/1000, batch:   384/ 1052, ite: 65320] train loss: 0.005388, tar: 0.000337 
l0: 0.000191, l1: 0.000190, l2: 0.000216, l3: 0.000233, l4: 0.000452, l5: 0.000726, l6: 0.001166

[epoch: 249/1000, batch:   464/ 1052, ite: 65340] train loss: 0.005383, tar: 0.000336 
l0: 0.000290, l1: 0.000298, l2: 0.000306, l3: 0.000386, l4: 0.000673, l5: 0.001466, l6: 0.002346

[epoch: 249/1000, batch:   544/ 1052, ite: 65360] train loss: 0.005382, tar: 0.000336 
l0: 0.000283, l1: 0.000287, l2: 0.000316, l3: 0.000382, l4: 0.000780, l5: 0.001432, l6: 0.002379

[epoch: 249/1000, batch:   624/ 1052, ite: 65380] train loss: 0.005384, tar: 0.000336 
l0: 0.000480, l1: 0.000458, l2: 0.000545, l3: 0.000772, l4: 0.001313, l5: 0.001835, l6: 0.002922

[epoch: 249/1000, batch:   704/ 1052, ite: 65400] train loss: 0.005386, tar: 0.000336 
l0: 0.000307, l1: 0.000321, l2: 0.000289, l3: 0.000306, l4: 0.000435, l5: 0.000792, l6: 0.001207

[epoch: 249/1000, batch:   784/ 1052, ite: 65420] train loss: 0.005391, tar: 0.000336 
l0: 0.000485, l1: 0.000502, l2: 0.000473, l3: 0.000544, l4: 0.000658, l5: 0.001231, l6: 0.002775

[epoch: 249/1000, batch:   864/ 1052, ite: 65440] train loss: 0.005395, tar: 0.000336 
l0: 0.000360, l1: 0.000364, l2: 0.000401, l3: 0.000423, l4: 0.000640, l5: 0.001223, l6: 0.002045

[epoch: 249/1000, batch:   944/ 1052, ite: 65460] train loss: 0.005394, tar: 0.000336 
l0: 0.000280, l1: 0.000276, l2: 0.000314, l3: 0.000360, l4: 0.000497, l5: 0.001307, l6: 0.001273

[epoch: 249/1000, batch:  1024/ 1052, ite: 65480] train loss: 0.005393, tar: 0.000336 
[Epoch 249/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000260, l1: 0.000260, l2: 0.000260, l3: 0.000487, l4: 0.000630, l5: 0.001136, l6: 0.001408

[epoch: 250/1000, batch:    52/ 1052, ite: 65500] train loss: 0.005397, tar: 0.000337 
l0: 0.000281, l1: 0.000294, l2: 0.000296, l3: 0.000302, l4: 0.000608, l5: 0.001289, l6: 0.001748

[epoch: 250/1000, batch:   132/ 1052, ite: 65520] train loss: 0.005399, tar: 0.000337 
l0: 0.000318, l1: 0.000328, l2: 0.000392, l3: 0.000484, l4: 0.000836, l5: 0.001510, l6: 0.002167

[epoch: 250/1000, batch:   212/ 1052, ite: 65540] train loss: 0.005392, tar: 0.000336 
l0: 0.000181, l1: 0.000187, l2: 0.000190, l3: 0.000215, l4: 0.000304, l5: 0.000886, l6: 0.001222

[epoch: 250/1000, batch:   292/ 1052, ite: 65560] train loss: 0.005384, tar: 0.000336 
l0: 0.000399, l1: 0.000398, l2: 0.000441, l3: 0.000482, l4: 0.000537, l5: 0.001000, l6: 0.002475

[epoch: 250/1000, batch:   372/ 1052, ite: 65580] train loss: 0.005384, tar: 0.000336 
l0: 0.000192, l1: 0.000187, l2: 0.000245, l3: 0.000285, l4: 0.000417, l5: 0.000679, l6: 0.001357

[epoch: 250/1000, batch:   452/ 1052, ite: 65600] train loss: 0.005387, tar: 0.000336 
l0: 0.000365, l1: 0.000365, l2: 0.000389, l3: 0.000479, l4: 0.000672, l5: 0.001520, l6: 0.002430

[epoch: 250/1000, batch:   532/ 1052, ite: 65620] train loss: 0.005387, tar: 0.000336 
l0: 0.000286, l1: 0.000291, l2: 0.000286, l3: 0.000410, l4: 0.000642, l5: 0.001379, l6: 0.002003

[epoch: 250/1000, batch:   612/ 1052, ite: 65640] train loss: 0.005387, tar: 0.000336 
l0: 0.000630, l1: 0.000616, l2: 0.000714, l3: 0.000733, l4: 0.000908, l5: 0.001944, l6: 0.002103

[epoch: 250/1000, batch:   692/ 1052, ite: 65660] train loss: 0.005389, tar: 0.000336 
l0: 0.000199, l1: 0.000199, l2: 0.000202, l3: 0.000328, l4: 0.000499, l5: 0.001002, l6: 0.001553

[epoch: 250/1000, batch:   772/ 1052, ite: 65680] train loss: 0.005394, tar: 0.000336 
l0: 0.000143, l1: 0.000145, l2: 0.000157, l3: 0.000238, l4: 0.000506, l5: 0.000935, l6: 0.001277

[epoch: 250/1000, batch:   852/ 1052, ite: 65700] train loss: 0.005391, tar: 0.000336 
l0: 0.000237, l1: 0.000234, l2: 0.000297, l3: 0.000345, l4: 0.000495, l5: 0.001438, l6: 0.001640

[epoch: 250/1000, batch:   932/ 1052, ite: 65720] train loss: 0.005390, tar: 0.000336 
l0: 0.000414, l1: 0.000441, l2: 0.000404, l3: 0.000391, l4: 0.000598, l5: 0.001387, l6: 0.002585

[epoch: 250/1000, batch:  1012/ 1052, ite: 65740] train loss: 0.005385, tar: 0.000335 
[Epoch 250/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000280, l1: 0.000287, l2: 0.000294, l3: 0.000302, l4: 0.000423, l5: 0.001042, l6: 0.001611

[epoch: 251/1000, batch:    40/ 1052, ite: 65760] train loss: 0.005383, tar: 0.000335 
l0: 0.000177, l1: 0.000175, l2: 0.000213, l3: 0.000231, l4: 0.000419, l5: 0.000555, l6: 0.001321

[epoch: 251/1000, batch:   120/ 1052, ite: 65780] train loss: 0.005380, tar: 0.000335 
l0: 0.000237, l1: 0.000240, l2: 0.000278, l3: 0.000338, l4: 0.000673, l5: 0.001021, l6: 0.001740

[epoch: 251/1000, batch:   200/ 1052, ite: 65800] train loss: 0.005377, tar: 0.000335 
l0: 0.000673, l1: 0.000610, l2: 0.000674, l3: 0.000891, l4: 0.001096, l5: 0.001529, l6: 0.003542

[epoch: 251/1000, batch:   280/ 1052, ite: 65820] train loss: 0.005375, tar: 0.000334 
l0: 0.000267, l1: 0.000270, l2: 0.000282, l3: 0.000399, l4: 0.000624, l5: 0.001571, l6: 0.002072

[epoch: 251/1000, batch:   360/ 1052, ite: 65840] train loss: 0.005377, tar: 0.000334 
l0: 0.000350, l1: 0.000349, l2: 0.000362, l3: 0.000483, l4: 0.000898, l5: 0.001811, l6: 0.002964

[epoch: 251/1000, batch:   440/ 1052, ite: 65860] train loss: 0.005386, tar: 0.000335 
l0: 0.000264, l1: 0.000258, l2: 0.000313, l3: 0.000454, l4: 0.000693, l5: 0.001444, l6: 0.001940

[epoch: 251/1000, batch:   520/ 1052, ite: 65880] train loss: 0.005382, tar: 0.000334 
l0: 0.000177, l1: 0.000178, l2: 0.000226, l3: 0.000306, l4: 0.000458, l5: 0.000874, l6: 0.001241

[epoch: 251/1000, batch:   600/ 1052, ite: 65900] train loss: 0.005378, tar: 0.000334 
l0: 0.000272, l1: 0.000284, l2: 0.000273, l3: 0.000347, l4: 0.000493, l5: 0.001243, l6: 0.001602

[epoch: 251/1000, batch:   680/ 1052, ite: 65920] train loss: 0.005383, tar: 0.000334 
l0: 0.000479, l1: 0.000488, l2: 0.000503, l3: 0.000562, l4: 0.001050, l5: 0.002471, l6: 0.003630

[epoch: 251/1000, batch:   760/ 1052, ite: 65940] train loss: 0.005391, tar: 0.000335 
l0: 0.000314, l1: 0.000321, l2: 0.000370, l3: 0.000561, l4: 0.001180, l5: 0.001828, l6: 0.002731

[epoch: 251/1000, batch:   840/ 1052, ite: 65960] train loss: 0.005389, tar: 0.000334 
l0: 0.000211, l1: 0.000211, l2: 0.000229, l3: 0.000292, l4: 0.000511, l5: 0.000630, l6: 0.001497

[epoch: 251/1000, batch:   920/ 1052, ite: 65980] train loss: 0.005384, tar: 0.000334 
l0: 0.000367, l1: 0.000376, l2: 0.000363, l3: 0.000403, l4: 0.000525, l5: 0.001285, l6: 0.001849

[epoch: 251/1000, batch:  1000/ 1052, ite: 66000] train loss: 0.005383, tar: 0.000334 
[Epoch 251/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000168, l1: 0.000186, l2: 0.000163, l3: 0.000241, l4: 0.000383, l5: 0.000640, l6: 0.000662

[epoch: 252/1000, batch:    28/ 1052, ite: 66020] train loss: 0.005380, tar: 0.000334 
l0: 0.000205, l1: 0.000203, l2: 0.000243, l3: 0.000237, l4: 0.000438, l5: 0.000721, l6: 0.000938

[epoch: 252/1000, batch:   108/ 1052, ite: 66040] train loss: 0.005377, tar: 0.000334 
l0: 0.000198, l1: 0.000201, l2: 0.000266, l3: 0.000269, l4: 0.000441, l5: 0.000726, l6: 0.002085

[epoch: 252/1000, batch:   188/ 1052, ite: 66060] train loss: 0.005374, tar: 0.000333 
l0: 0.000265, l1: 0.000264, l2: 0.000287, l3: 0.000319, l4: 0.000466, l5: 0.000777, l6: 0.001647

[epoch: 252/1000, batch:   268/ 1052, ite: 66080] train loss: 0.005383, tar: 0.000334 
l0: 0.000446, l1: 0.000452, l2: 0.000469, l3: 0.000505, l4: 0.001009, l5: 0.001337, l6: 0.001964

[epoch: 252/1000, batch:   348/ 1052, ite: 66100] train loss: 0.005383, tar: 0.000334 
l0: 0.000218, l1: 0.000225, l2: 0.000220, l3: 0.000242, l4: 0.000457, l5: 0.000585, l6: 0.001166

[epoch: 252/1000, batch:   428/ 1052, ite: 66120] train loss: 0.005387, tar: 0.000334 
l0: 0.000410, l1: 0.000426, l2: 0.000414, l3: 0.000493, l4: 0.000870, l5: 0.001631, l6: 0.004521

[epoch: 252/1000, batch:   508/ 1052, ite: 66140] train loss: 0.005390, tar: 0.000334 
l0: 0.000349, l1: 0.000358, l2: 0.000364, l3: 0.000400, l4: 0.000584, l5: 0.001105, l6: 0.001926

[epoch: 252/1000, batch:   588/ 1052, ite: 66160] train loss: 0.005390, tar: 0.000334 
l0: 0.000186, l1: 0.000193, l2: 0.000206, l3: 0.000191, l4: 0.000283, l5: 0.000747, l6: 0.001182

[epoch: 252/1000, batch:   668/ 1052, ite: 66180] train loss: 0.005386, tar: 0.000334 
l0: 0.000227, l1: 0.000232, l2: 0.000266, l3: 0.000270, l4: 0.000362, l5: 0.000906, l6: 0.001301

[epoch: 252/1000, batch:   748/ 1052, ite: 66200] train loss: 0.005381, tar: 0.000334 
l0: 0.000564, l1: 0.000575, l2: 0.000600, l3: 0.000637, l4: 0.000980, l5: 0.001673, l6: 0.003808

[epoch: 252/1000, batch:   828/ 1052, ite: 66220] train loss: 0.005380, tar: 0.000334 
l0: 0.000190, l1: 0.000192, l2: 0.000205, l3: 0.000268, l4: 0.000353, l5: 0.001173, l6: 0.001459

[epoch: 252/1000, batch:   908/ 1052, ite: 66240] train loss: 0.005378, tar: 0.000334 
l0: 0.000273, l1: 0.000271, l2: 0.000287, l3: 0.000343, l4: 0.000611, l5: 0.000954, l6: 0.001694

[epoch: 252/1000, batch:   988/ 1052, ite: 66260] train loss: 0.005379, tar: 0.000334 
[Epoch 252/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000403, l1: 0.000431, l2: 0.000395, l3: 0.000524, l4: 0.000817, l5: 0.001690, l6: 0.003733

[epoch: 253/1000, batch:    16/ 1052, ite: 66280] train loss: 0.005379, tar: 0.000333 
l0: 0.000223, l1: 0.000218, l2: 0.000247, l3: 0.000295, l4: 0.000422, l5: 0.000648, l6: 0.001364

[epoch: 253/1000, batch:    96/ 1052, ite: 66300] train loss: 0.005377, tar: 0.000333 
l0: 0.000263, l1: 0.000266, l2: 0.000292, l3: 0.000304, l4: 0.000489, l5: 0.000981, l6: 0.001168

[epoch: 253/1000, batch:   176/ 1052, ite: 66320] train loss: 0.005381, tar: 0.000334 
l0: 0.000217, l1: 0.000215, l2: 0.000232, l3: 0.000326, l4: 0.000530, l5: 0.000796, l6: 0.001423

[epoch: 253/1000, batch:   256/ 1052, ite: 66340] train loss: 0.005379, tar: 0.000333 
l0: 0.000307, l1: 0.000292, l2: 0.000372, l3: 0.000561, l4: 0.000846, l5: 0.001337, l6: 0.002304

[epoch: 253/1000, batch:   336/ 1052, ite: 66360] train loss: 0.005376, tar: 0.000333 
l0: 0.000383, l1: 0.000415, l2: 0.000399, l3: 0.000454, l4: 0.000724, l5: 0.000817, l6: 0.002151

[epoch: 253/1000, batch:   416/ 1052, ite: 66380] train loss: 0.005384, tar: 0.000334 
l0: 0.000206, l1: 0.000212, l2: 0.000223, l3: 0.000269, l4: 0.000415, l5: 0.000832, l6: 0.001551

[epoch: 253/1000, batch:   496/ 1052, ite: 66400] train loss: 0.005385, tar: 0.000334 
l0: 0.000202, l1: 0.000195, l2: 0.000213, l3: 0.000299, l4: 0.000473, l5: 0.001231, l6: 0.001476

[epoch: 253/1000, batch:   576/ 1052, ite: 66420] train loss: 0.005384, tar: 0.000334 
l0: 0.000392, l1: 0.000401, l2: 0.000413, l3: 0.000499, l4: 0.000785, l5: 0.001534, l6: 0.002328

[epoch: 253/1000, batch:   656/ 1052, ite: 66440] train loss: 0.005381, tar: 0.000334 
l0: 0.000308, l1: 0.000313, l2: 0.000429, l3: 0.000448, l4: 0.000614, l5: 0.001013, l6: 0.002463

[epoch: 253/1000, batch:   736/ 1052, ite: 66460] train loss: 0.005381, tar: 0.000334 
l0: 0.000635, l1: 0.000651, l2: 0.000648, l3: 0.000785, l4: 0.001126, l5: 0.001895, l6: 0.004156

[epoch: 253/1000, batch:   816/ 1052, ite: 66480] train loss: 0.005378, tar: 0.000333 
l0: 0.000253, l1: 0.000257, l2: 0.000315, l3: 0.000288, l4: 0.000518, l5: 0.001338, l6: 0.002295

[epoch: 253/1000, batch:   896/ 1052, ite: 66500] train loss: 0.005382, tar: 0.000334 
l0: 0.000543, l1: 0.000521, l2: 0.000595, l3: 0.000822, l4: 0.001454, l5: 0.003056, l6: 0.003668

[epoch: 253/1000, batch:   976/ 1052, ite: 66520] train loss: 0.005381, tar: 0.000334 
[Epoch 253/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000329, l1: 0.000341, l2: 0.000389, l3: 0.000476, l4: 0.000934, l5: 0.001366, l6: 0.002319

[epoch: 254/1000, batch:     4/ 1052, ite: 66540] train loss: 0.005383, tar: 0.000334 
l0: 0.000221, l1: 0.000227, l2: 0.000237, l3: 0.000282, l4: 0.000537, l5: 0.000954, l6: 0.001705

[epoch: 254/1000, batch:    84/ 1052, ite: 66560] train loss: 0.005380, tar: 0.000334 
l0: 0.000144, l1: 0.000151, l2: 0.000159, l3: 0.000220, l4: 0.000401, l5: 0.000728, l6: 0.001407

[epoch: 254/1000, batch:   164/ 1052, ite: 66580] train loss: 0.005377, tar: 0.000333 
l0: 0.000187, l1: 0.000185, l2: 0.000213, l3: 0.000301, l4: 0.000519, l5: 0.001343, l6: 0.001587

[epoch: 254/1000, batch:   244/ 1052, ite: 66600] train loss: 0.005378, tar: 0.000333 
l0: 0.000234, l1: 0.000233, l2: 0.000253, l3: 0.000321, l4: 0.000457, l5: 0.001150, l6: 0.001621

[epoch: 254/1000, batch:   324/ 1052, ite: 66620] train loss: 0.005375, tar: 0.000333 
l0: 0.000317, l1: 0.000318, l2: 0.000324, l3: 0.000373, l4: 0.000610, l5: 0.000820, l6: 0.001364

[epoch: 254/1000, batch:   404/ 1052, ite: 66640] train loss: 0.005374, tar: 0.000333 
l0: 0.000249, l1: 0.000250, l2: 0.000318, l3: 0.000388, l4: 0.000672, l5: 0.001498, l6: 0.002454

[epoch: 254/1000, batch:   484/ 1052, ite: 66660] train loss: 0.005375, tar: 0.000333 
l0: 0.000411, l1: 0.000404, l2: 0.000467, l3: 0.000645, l4: 0.001110, l5: 0.001481, l6: 0.002606

[epoch: 254/1000, batch:   564/ 1052, ite: 66680] train loss: 0.005380, tar: 0.000333 
l0: 0.000128, l1: 0.000130, l2: 0.000174, l3: 0.000205, l4: 0.000507, l5: 0.000937, l6: 0.001652

[epoch: 254/1000, batch:   644/ 1052, ite: 66700] train loss: 0.005381, tar: 0.000333 
l0: 0.000202, l1: 0.000211, l2: 0.000196, l3: 0.000243, l4: 0.000389, l5: 0.000479, l6: 0.000971

[epoch: 254/1000, batch:   724/ 1052, ite: 66720] train loss: 0.005379, tar: 0.000333 
l0: 0.000208, l1: 0.000216, l2: 0.000236, l3: 0.000258, l4: 0.000372, l5: 0.000815, l6: 0.001467

[epoch: 254/1000, batch:   804/ 1052, ite: 66740] train loss: 0.005378, tar: 0.000333 
l0: 0.000550, l1: 0.000547, l2: 0.000685, l3: 0.000725, l4: 0.001410, l5: 0.002268, l6: 0.003817

[epoch: 254/1000, batch:   884/ 1052, ite: 66760] train loss: 0.005377, tar: 0.000333 
l0: 0.000197, l1: 0.000203, l2: 0.000221, l3: 0.000269, l4: 0.000448, l5: 0.000997, l6: 0.001043

[epoch: 254/1000, batch:   964/ 1052, ite: 66780] train loss: 0.005376, tar: 0.000333 
l0: 0.000229, l1: 0.000236, l2: 0.000250, l3: 0.000289, l4: 0.000413, l5: 0.000707, l6: 0.001518

[epoch: 254/1000, batch:  1044/ 1052, ite: 66800] train loss: 0.005373, tar: 0.000332 
[Epoch 254/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000246, l1: 0.000246, l2: 0.000270, l3: 0.000306, l4: 0.000572, l5: 0.001105, l6: 0.001902

[epoch: 255/1000, batch:    72/ 1052, ite: 66820] train loss: 0.005368, tar: 0.000332 
l0: 0.000221, l1: 0.000218, l2: 0.000228, l3: 0.000278, l4: 0.000496, l5: 0.000618, l6: 0.001193

[epoch: 255/1000, batch:   152/ 1052, ite: 66840] train loss: 0.005363, tar: 0.000331 
l0: 0.000384, l1: 0.000407, l2: 0.000393, l3: 0.000454, l4: 0.000873, l5: 0.001330, l6: 0.001574

[epoch: 255/1000, batch:   232/ 1052, ite: 66860] train loss: 0.005364, tar: 0.000331 
l0: 0.000325, l1: 0.000339, l2: 0.000322, l3: 0.000371, l4: 0.000642, l5: 0.001672, l6: 0.002489

[epoch: 255/1000, batch:   312/ 1052, ite: 66880] train loss: 0.005366, tar: 0.000331 
l0: 0.000221, l1: 0.000233, l2: 0.000226, l3: 0.000238, l4: 0.000388, l5: 0.000584, l6: 0.001386

[epoch: 255/1000, batch:   392/ 1052, ite: 66900] train loss: 0.005367, tar: 0.000331 
l0: 0.000176, l1: 0.000174, l2: 0.000206, l3: 0.000286, l4: 0.000343, l5: 0.001026, l6: 0.001490

[epoch: 255/1000, batch:   472/ 1052, ite: 66920] train loss: 0.005364, tar: 0.000331 
l0: 0.000217, l1: 0.000218, l2: 0.000217, l3: 0.000256, l4: 0.000402, l5: 0.001063, l6: 0.001752

[epoch: 255/1000, batch:   552/ 1052, ite: 66940] train loss: 0.005362, tar: 0.000331 
l0: 0.000323, l1: 0.000323, l2: 0.000350, l3: 0.000398, l4: 0.000515, l5: 0.001486, l6: 0.001782

[epoch: 255/1000, batch:   632/ 1052, ite: 66960] train loss: 0.005360, tar: 0.000331 
l0: 0.000214, l1: 0.000230, l2: 0.000236, l3: 0.000321, l4: 0.000580, l5: 0.000947, l6: 0.001213

[epoch: 255/1000, batch:   712/ 1052, ite: 66980] train loss: 0.005358, tar: 0.000331 
l0: 0.000262, l1: 0.000282, l2: 0.000259, l3: 0.000256, l4: 0.000358, l5: 0.000914, l6: 0.001238

[epoch: 255/1000, batch:   792/ 1052, ite: 67000] train loss: 0.005358, tar: 0.000331 
l0: 0.000802, l1: 0.000826, l2: 0.000831, l3: 0.000880, l4: 0.001511, l5: 0.002483, l6: 0.003849

[epoch: 255/1000, batch:   872/ 1052, ite: 67020] train loss: 0.005361, tar: 0.000331 
l0: 0.000326, l1: 0.000338, l2: 0.000382, l3: 0.000490, l4: 0.000867, l5: 0.001727, l6: 0.002330

[epoch: 255/1000, batch:   952/ 1052, ite: 67040] train loss: 0.005361, tar: 0.000331 
l0: 0.000254, l1: 0.000252, l2: 0.000283, l3: 0.000468, l4: 0.000705, l5: 0.001437, l6: 0.002174

[epoch: 255/1000, batch:  1032/ 1052, ite: 67060] train loss: 0.005364, tar: 0.000331 
[Epoch 255/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000279, l1: 0.000288, l2: 0.000328, l3: 0.000354, l4: 0.000576, l5: 0.001056, l6: 0.001391

[epoch: 256/1000, batch:    60/ 1052, ite: 67080] train loss: 0.005361, tar: 0.000330 
l0: 0.000273, l1: 0.000279, l2: 0.000320, l3: 0.000323, l4: 0.000474, l5: 0.001107, l6: 0.001603

[epoch: 256/1000, batch:   140/ 1052, ite: 67100] train loss: 0.005363, tar: 0.000331 
l0: 0.000377, l1: 0.000387, l2: 0.000423, l3: 0.000434, l4: 0.000881, l5: 0.001625, l6: 0.002564

[epoch: 256/1000, batch:   220/ 1052, ite: 67120] train loss: 0.005366, tar: 0.000331 
l0: 0.000270, l1: 0.000296, l2: 0.000301, l3: 0.000289, l4: 0.000625, l5: 0.001083, l6: 0.001397

[epoch: 256/1000, batch:   300/ 1052, ite: 67140] train loss: 0.005364, tar: 0.000331 
l0: 0.000180, l1: 0.000184, l2: 0.000219, l3: 0.000291, l4: 0.000657, l5: 0.001001, l6: 0.001585

[epoch: 256/1000, batch:   380/ 1052, ite: 67160] train loss: 0.005362, tar: 0.000331 
l0: 0.000258, l1: 0.000263, l2: 0.000271, l3: 0.000334, l4: 0.000523, l5: 0.001343, l6: 0.002417

[epoch: 256/1000, batch:   460/ 1052, ite: 67180] train loss: 0.005361, tar: 0.000330 
l0: 0.000321, l1: 0.000318, l2: 0.000314, l3: 0.000463, l4: 0.000578, l5: 0.000996, l6: 0.001592

[epoch: 256/1000, batch:   540/ 1052, ite: 67200] train loss: 0.005359, tar: 0.000330 
l0: 0.000470, l1: 0.000465, l2: 0.000534, l3: 0.000805, l4: 0.001420, l5: 0.002336, l6: 0.003339

[epoch: 256/1000, batch:   620/ 1052, ite: 67220] train loss: 0.005359, tar: 0.000330 
l0: 0.000402, l1: 0.000391, l2: 0.000466, l3: 0.000575, l4: 0.000943, l5: 0.001355, l6: 0.002851

[epoch: 256/1000, batch:   700/ 1052, ite: 67240] train loss: 0.005357, tar: 0.000330 
l0: 0.000360, l1: 0.000380, l2: 0.000382, l3: 0.000437, l4: 0.000679, l5: 0.001261, l6: 0.001774

[epoch: 256/1000, batch:   780/ 1052, ite: 67260] train loss: 0.005355, tar: 0.000330 
l0: 0.000534, l1: 0.000545, l2: 0.000647, l3: 0.000719, l4: 0.001333, l5: 0.003060, l6: 0.004672

[epoch: 256/1000, batch:   860/ 1052, ite: 67280] train loss: 0.005357, tar: 0.000330 
l0: 0.000336, l1: 0.000361, l2: 0.000363, l3: 0.000333, l4: 0.000660, l5: 0.001475, l6: 0.002337

[epoch: 256/1000, batch:   940/ 1052, ite: 67300] train loss: 0.005358, tar: 0.000330 
l0: 0.000241, l1: 0.000237, l2: 0.000261, l3: 0.000314, l4: 0.000388, l5: 0.000855, l6: 0.001481

[epoch: 256/1000, batch:  1020/ 1052, ite: 67320] train loss: 0.005355, tar: 0.000330 
[Epoch 256/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000319, l1: 0.000328, l2: 0.000341, l3: 0.000448, l4: 0.000974, l5: 0.001679, l6: 0.002056

[epoch: 257/1000, batch:    48/ 1052, ite: 67340] train loss: 0.005360, tar: 0.000330 
l0: 0.000307, l1: 0.000319, l2: 0.000359, l3: 0.000441, l4: 0.001113, l5: 0.001318, l6: 0.002794

[epoch: 257/1000, batch:   128/ 1052, ite: 67360] train loss: 0.005360, tar: 0.000330 
l0: 0.000401, l1: 0.000413, l2: 0.000421, l3: 0.000471, l4: 0.000851, l5: 0.002405, l6: 0.003619

[epoch: 257/1000, batch:   208/ 1052, ite: 67380] train loss: 0.005358, tar: 0.000330 
l0: 0.000420, l1: 0.000418, l2: 0.000417, l3: 0.000567, l4: 0.000735, l5: 0.001732, l6: 0.003972

[epoch: 257/1000, batch:   288/ 1052, ite: 67400] train loss: 0.005356, tar: 0.000329 
l0: 0.000362, l1: 0.000369, l2: 0.000438, l3: 0.000448, l4: 0.000600, l5: 0.001120, l6: 0.002158

[epoch: 257/1000, batch:   368/ 1052, ite: 67420] train loss: 0.005357, tar: 0.000329 
l0: 0.000333, l1: 0.000342, l2: 0.000347, l3: 0.000438, l4: 0.000610, l5: 0.001213, l6: 0.001967

[epoch: 257/1000, batch:   448/ 1052, ite: 67440] train loss: 0.005358, tar: 0.000330 
l0: 0.000220, l1: 0.000221, l2: 0.000262, l3: 0.000291, l4: 0.000519, l5: 0.001012, l6: 0.001743

[epoch: 257/1000, batch:   528/ 1052, ite: 67460] train loss: 0.005356, tar: 0.000329 
l0: 0.000288, l1: 0.000278, l2: 0.000294, l3: 0.000485, l4: 0.000708, l5: 0.001443, l6: 0.002143

[epoch: 257/1000, batch:   608/ 1052, ite: 67480] train loss: 0.005360, tar: 0.000330 
l0: 0.000276, l1: 0.000274, l2: 0.000321, l3: 0.000391, l4: 0.000575, l5: 0.001115, l6: 0.002230

[epoch: 257/1000, batch:   688/ 1052, ite: 67500] train loss: 0.005358, tar: 0.000329 
l0: 0.000232, l1: 0.000234, l2: 0.000279, l3: 0.000324, l4: 0.000524, l5: 0.001047, l6: 0.002020

[epoch: 257/1000, batch:   768/ 1052, ite: 67520] train loss: 0.005356, tar: 0.000329 
l0: 0.000415, l1: 0.000409, l2: 0.000481, l3: 0.000779, l4: 0.001169, l5: 0.002447, l6: 0.003951

[epoch: 257/1000, batch:   848/ 1052, ite: 67540] train loss: 0.005356, tar: 0.000329 
l0: 0.000658, l1: 0.000664, l2: 0.000689, l3: 0.000706, l4: 0.001056, l5: 0.001855, l6: 0.004307

[epoch: 257/1000, batch:   928/ 1052, ite: 67560] train loss: 0.005357, tar: 0.000329 
l0: 0.000154, l1: 0.000147, l2: 0.000176, l3: 0.000274, l4: 0.000389, l5: 0.000605, l6: 0.001202

[epoch: 257/1000, batch:  1008/ 1052, ite: 67580] train loss: 0.005356, tar: 0.000329 
[Epoch 257/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000435, l1: 0.000426, l2: 0.000477, l3: 0.000626, l4: 0.000982, l5: 0.001337, l6: 0.003142

[epoch: 258/1000, batch:    36/ 1052, ite: 67600] train loss: 0.005355, tar: 0.000329 
l0: 0.000930, l1: 0.001024, l2: 0.000837, l3: 0.000871, l4: 0.001153, l5: 0.001777, l6: 0.004829

[epoch: 258/1000, batch:   116/ 1052, ite: 67620] train loss: 0.005356, tar: 0.000329 
l0: 0.000238, l1: 0.000257, l2: 0.000261, l3: 0.000292, l4: 0.000664, l5: 0.001139, l6: 0.001943

[epoch: 258/1000, batch:   196/ 1052, ite: 67640] train loss: 0.005357, tar: 0.000329 
l0: 0.000288, l1: 0.000278, l2: 0.000410, l3: 0.000609, l4: 0.000943, l5: 0.001652, l6: 0.002933

[epoch: 258/1000, batch:   276/ 1052, ite: 67660] train loss: 0.005359, tar: 0.000329 
l0: 0.000309, l1: 0.000311, l2: 0.000311, l3: 0.000396, l4: 0.000609, l5: 0.001629, l6: 0.001797

[epoch: 258/1000, batch:   356/ 1052, ite: 67680] train loss: 0.005356, tar: 0.000329 
l0: 0.000459, l1: 0.000462, l2: 0.000515, l3: 0.000494, l4: 0.000623, l5: 0.001440, l6: 0.002635

[epoch: 258/1000, batch:   436/ 1052, ite: 67700] train loss: 0.005362, tar: 0.000329 
l0: 0.000396, l1: 0.000424, l2: 0.000453, l3: 0.000438, l4: 0.000526, l5: 0.001260, l6: 0.001966

[epoch: 258/1000, batch:   516/ 1052, ite: 67720] train loss: 0.005363, tar: 0.000330 
l0: 0.000267, l1: 0.000265, l2: 0.000283, l3: 0.000341, l4: 0.000466, l5: 0.000495, l6: 0.001388

[epoch: 258/1000, batch:   596/ 1052, ite: 67740] train loss: 0.005371, tar: 0.000331 
l0: 0.000357, l1: 0.000377, l2: 0.000431, l3: 0.000439, l4: 0.000579, l5: 0.000816, l6: 0.001551

[epoch: 258/1000, batch:   676/ 1052, ite: 67760] train loss: 0.005373, tar: 0.000331 
l0: 0.000409, l1: 0.000391, l2: 0.000414, l3: 0.000500, l4: 0.000718, l5: 0.001207, l6: 0.002247

[epoch: 258/1000, batch:   756/ 1052, ite: 67780] train loss: 0.005376, tar: 0.000332 
l0: 0.000310, l1: 0.000313, l2: 0.000315, l3: 0.000308, l4: 0.000566, l5: 0.001462, l6: 0.001992

[epoch: 258/1000, batch:   836/ 1052, ite: 67800] train loss: 0.005377, tar: 0.000332 
l0: 0.000316, l1: 0.000299, l2: 0.000350, l3: 0.000423, l4: 0.000935, l5: 0.000981, l6: 0.001661

[epoch: 258/1000, batch:   916/ 1052, ite: 67820] train loss: 0.005378, tar: 0.000332 
l0: 0.000479, l1: 0.000490, l2: 0.000506, l3: 0.000489, l4: 0.000568, l5: 0.001319, l6: 0.002683

[epoch: 258/1000, batch:   996/ 1052, ite: 67840] train loss: 0.005380, tar: 0.000332 
[Epoch 258/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000488, l1: 0.000474, l2: 0.000546, l3: 0.000631, l4: 0.000735, l5: 0.001322, l6: 0.002265

[epoch: 259/1000, batch:    24/ 1052, ite: 67860] train loss: 0.005381, tar: 0.000333 
l0: 0.000224, l1: 0.000247, l2: 0.000238, l3: 0.000257, l4: 0.000391, l5: 0.000819, l6: 0.001043

[epoch: 259/1000, batch:   104/ 1052, ite: 67880] train loss: 0.005387, tar: 0.000333 
l0: 0.000500, l1: 0.000481, l2: 0.000448, l3: 0.000583, l4: 0.000794, l5: 0.001347, l6: 0.002821

[epoch: 259/1000, batch:   184/ 1052, ite: 67900] train loss: 0.005398, tar: 0.000335 
l0: 0.000479, l1: 0.000489, l2: 0.000506, l3: 0.000617, l4: 0.000893, l5: 0.001397, l6: 0.001881

[epoch: 259/1000, batch:   264/ 1052, ite: 67920] train loss: 0.005406, tar: 0.000336 
l0: 0.000537, l1: 0.000516, l2: 0.000540, l3: 0.000744, l4: 0.000866, l5: 0.001595, l6: 0.002921

[epoch: 259/1000, batch:   344/ 1052, ite: 67940] train loss: 0.005406, tar: 0.000336 
l0: 0.000574, l1: 0.000581, l2: 0.000586, l3: 0.000695, l4: 0.001123, l5: 0.001744, l6: 0.003510

[epoch: 259/1000, batch:   424/ 1052, ite: 67960] train loss: 0.005406, tar: 0.000337 
l0: 0.000634, l1: 0.000636, l2: 0.000706, l3: 0.000879, l4: 0.000932, l5: 0.001725, l6: 0.003932

[epoch: 259/1000, batch:   504/ 1052, ite: 67980] train loss: 0.005408, tar: 0.000337 
l0: 0.000329, l1: 0.000337, l2: 0.000440, l3: 0.000446, l4: 0.000590, l5: 0.000783, l6: 0.001294

[epoch: 259/1000, batch:   584/ 1052, ite: 68000] train loss: 0.005416, tar: 0.000338 
l0: 0.000357, l1: 0.000352, l2: 0.000413, l3: 0.000501, l4: 0.000788, l5: 0.001413, l6: 0.002201

[epoch: 259/1000, batch:   664/ 1052, ite: 68020] train loss: 0.005421, tar: 0.000338 
l0: 0.000310, l1: 0.000317, l2: 0.000324, l3: 0.000393, l4: 0.000654, l5: 0.001264, l6: 0.002059

[epoch: 259/1000, batch:   744/ 1052, ite: 68040] train loss: 0.005426, tar: 0.000339 
l0: 0.000550, l1: 0.000547, l2: 0.000575, l3: 0.000722, l4: 0.000772, l5: 0.001156, l6: 0.002826

[epoch: 259/1000, batch:   824/ 1052, ite: 68060] train loss: 0.005427, tar: 0.000339 
l0: 0.000290, l1: 0.000290, l2: 0.000276, l3: 0.000349, l4: 0.000671, l5: 0.001001, l6: 0.001876

[epoch: 259/1000, batch:   904/ 1052, ite: 68080] train loss: 0.005427, tar: 0.000339 
l0: 0.000460, l1: 0.000445, l2: 0.000481, l3: 0.000544, l4: 0.001208, l5: 0.001700, l6: 0.003452

[epoch: 259/1000, batch:   984/ 1052, ite: 68100] train loss: 0.005430, tar: 0.000340 
[Epoch 259/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000287, l1: 0.000286, l2: 0.000326, l3: 0.000431, l4: 0.000798, l5: 0.001200, l6: 0.001290

[epoch: 260/1000, batch:    12/ 1052, ite: 68120] train loss: 0.005429, tar: 0.000340 
l0: 0.000254, l1: 0.000249, l2: 0.000289, l3: 0.000316, l4: 0.000392, l5: 0.000861, l6: 0.002233

[epoch: 260/1000, batch:    92/ 1052, ite: 68140] train loss: 0.005436, tar: 0.000341 
l0: 0.000548, l1: 0.000570, l2: 0.000603, l3: 0.000633, l4: 0.000996, l5: 0.001736, l6: 0.003585

[epoch: 260/1000, batch:   172/ 1052, ite: 68160] train loss: 0.005439, tar: 0.000341 
l0: 0.000418, l1: 0.000438, l2: 0.000478, l3: 0.000494, l4: 0.000716, l5: 0.001252, l6: 0.001801

[epoch: 260/1000, batch:   252/ 1052, ite: 68180] train loss: 0.005442, tar: 0.000341 
l0: 0.000595, l1: 0.000600, l2: 0.000646, l3: 0.000699, l4: 0.001102, l5: 0.002766, l6: 0.003507

[epoch: 260/1000, batch:   332/ 1052, ite: 68200] train loss: 0.005443, tar: 0.000341 
l0: 0.000322, l1: 0.000329, l2: 0.000333, l3: 0.000413, l4: 0.000601, l5: 0.000940, l6: 0.001280

[epoch: 260/1000, batch:   412/ 1052, ite: 68220] train loss: 0.005442, tar: 0.000341 
l0: 0.000172, l1: 0.000170, l2: 0.000173, l3: 0.000238, l4: 0.000398, l5: 0.000714, l6: 0.000797

[epoch: 260/1000, batch:   492/ 1052, ite: 68240] train loss: 0.005443, tar: 0.000341 
l0: 0.000382, l1: 0.000380, l2: 0.000410, l3: 0.000374, l4: 0.000571, l5: 0.001110, l6: 0.002497

[epoch: 260/1000, batch:   572/ 1052, ite: 68260] train loss: 0.005442, tar: 0.000341 
l0: 0.000240, l1: 0.000244, l2: 0.000245, l3: 0.000258, l4: 0.000375, l5: 0.000900, l6: 0.001396

[epoch: 260/1000, batch:   652/ 1052, ite: 68280] train loss: 0.005441, tar: 0.000341 
l0: 0.000308, l1: 0.000307, l2: 0.000324, l3: 0.000425, l4: 0.000699, l5: 0.001182, l6: 0.001759

[epoch: 260/1000, batch:   732/ 1052, ite: 68300] train loss: 0.005440, tar: 0.000341 
l0: 0.000228, l1: 0.000215, l2: 0.000231, l3: 0.000331, l4: 0.000501, l5: 0.000638, l6: 0.001074

[epoch: 260/1000, batch:   812/ 1052, ite: 68320] train loss: 0.005442, tar: 0.000341 
l0: 0.000302, l1: 0.000284, l2: 0.000318, l3: 0.000458, l4: 0.000767, l5: 0.000839, l6: 0.001912

[epoch: 260/1000, batch:   892/ 1052, ite: 68340] train loss: 0.005442, tar: 0.000341 
l0: 0.000541, l1: 0.000535, l2: 0.000566, l3: 0.000606, l4: 0.000926, l5: 0.001723, l6: 0.003488

[epoch: 260/1000, batch:   972/ 1052, ite: 68360] train loss: 0.005442, tar: 0.000341 
l0: 0.000615, l1: 0.000648, l2: 0.000663, l3: 0.000635, l4: 0.001041, l5: 0.001829, l6: 0.003173

[epoch: 260/1000, batch:  1052/ 1052, ite: 68380] train loss: 0.005443, tar: 0.000341 
[Epoch 260/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000191, l1: 0.000198, l2: 0.000212, l3: 0.000229, l4: 0.000507, l5: 0.000765, l6: 0.001806

[epoch: 261/1000, batch:    80/ 1052, ite: 68400] train loss: 0.005441, tar: 0.000341 
l0: 0.000266, l1: 0.000267, l2: 0.000286, l3: 0.000333, l4: 0.000668, l5: 0.000896, l6: 0.001512

[epoch: 261/1000, batch:   160/ 1052, ite: 68420] train loss: 0.005440, tar: 0.000341 
l0: 0.000358, l1: 0.000442, l2: 0.000319, l3: 0.000382, l4: 0.000485, l5: 0.000901, l6: 0.001150

[epoch: 261/1000, batch:   240/ 1052, ite: 68440] train loss: 0.005439, tar: 0.000341 
l0: 0.000434, l1: 0.000426, l2: 0.000473, l3: 0.000700, l4: 0.001207, l5: 0.001630, l6: 0.003072

[epoch: 261/1000, batch:   320/ 1052, ite: 68460] train loss: 0.005439, tar: 0.000341 
l0: 0.000355, l1: 0.000352, l2: 0.000386, l3: 0.000464, l4: 0.000659, l5: 0.000944, l6: 0.002339

[epoch: 261/1000, batch:   400/ 1052, ite: 68480] train loss: 0.005438, tar: 0.000341 
l0: 0.000562, l1: 0.000564, l2: 0.000566, l3: 0.000647, l4: 0.000944, l5: 0.001559, l6: 0.002588

[epoch: 261/1000, batch:   480/ 1052, ite: 68500] train loss: 0.005435, tar: 0.000341 
l0: 0.000482, l1: 0.000517, l2: 0.000590, l3: 0.000502, l4: 0.000784, l5: 0.001590, l6: 0.001831

[epoch: 261/1000, batch:   560/ 1052, ite: 68520] train loss: 0.005437, tar: 0.000341 
l0: 0.000341, l1: 0.000368, l2: 0.000358, l3: 0.000333, l4: 0.000501, l5: 0.000811, l6: 0.001561

[epoch: 261/1000, batch:   640/ 1052, ite: 68540] train loss: 0.005436, tar: 0.000341 
l0: 0.000320, l1: 0.000335, l2: 0.000365, l3: 0.000407, l4: 0.000630, l5: 0.001654, l6: 0.002214

[epoch: 261/1000, batch:   720/ 1052, ite: 68560] train loss: 0.005435, tar: 0.000341 
l0: 0.000292, l1: 0.000292, l2: 0.000279, l3: 0.000366, l4: 0.000546, l5: 0.000783, l6: 0.001936

[epoch: 261/1000, batch:   800/ 1052, ite: 68580] train loss: 0.005436, tar: 0.000341 
l0: 0.000229, l1: 0.000226, l2: 0.000264, l3: 0.000294, l4: 0.000578, l5: 0.001238, l6: 0.002569

[epoch: 261/1000, batch:   880/ 1052, ite: 68600] train loss: 0.005439, tar: 0.000341 
l0: 0.000402, l1: 0.000370, l2: 0.000415, l3: 0.000561, l4: 0.000903, l5: 0.001027, l6: 0.002677

[epoch: 261/1000, batch:   960/ 1052, ite: 68620] train loss: 0.005440, tar: 0.000341 
l0: 0.000287, l1: 0.000302, l2: 0.000261, l3: 0.000297, l4: 0.000528, l5: 0.001176, l6: 0.001849

[epoch: 261/1000, batch:  1040/ 1052, ite: 68640] train loss: 0.005436, tar: 0.000341 
[Epoch 261/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000174, l1: 0.000179, l2: 0.000214, l3: 0.000256, l4: 0.000368, l5: 0.000623, l6: 0.000971

[epoch: 262/1000, batch:    68/ 1052, ite: 68660] train loss: 0.005437, tar: 0.000341 
l0: 0.000360, l1: 0.000357, l2: 0.000397, l3: 0.000493, l4: 0.000946, l5: 0.001669, l6: 0.002469

[epoch: 262/1000, batch:   148/ 1052, ite: 68680] train loss: 0.005437, tar: 0.000341 
l0: 0.000277, l1: 0.000273, l2: 0.000307, l3: 0.000314, l4: 0.000563, l5: 0.000581, l6: 0.001176

[epoch: 262/1000, batch:   228/ 1052, ite: 68700] train loss: 0.005441, tar: 0.000341 
l0: 0.000299, l1: 0.000307, l2: 0.000304, l3: 0.000363, l4: 0.000538, l5: 0.001126, l6: 0.001530

[epoch: 262/1000, batch:   308/ 1052, ite: 68720] train loss: 0.005441, tar: 0.000341 
l0: 0.000305, l1: 0.000298, l2: 0.000337, l3: 0.000438, l4: 0.000426, l5: 0.001275, l6: 0.002138

[epoch: 262/1000, batch:   388/ 1052, ite: 68740] train loss: 0.005440, tar: 0.000340 
l0: 0.000139, l1: 0.000142, l2: 0.000151, l3: 0.000170, l4: 0.000258, l5: 0.000513, l6: 0.000735

[epoch: 262/1000, batch:   468/ 1052, ite: 68760] train loss: 0.005437, tar: 0.000340 
l0: 0.000359, l1: 0.000370, l2: 0.000334, l3: 0.000387, l4: 0.000652, l5: 0.001293, l6: 0.001581

[epoch: 262/1000, batch:   548/ 1052, ite: 68780] train loss: 0.005436, tar: 0.000340 
l0: 0.000307, l1: 0.000309, l2: 0.000330, l3: 0.000350, l4: 0.000920, l5: 0.000967, l6: 0.002383

[epoch: 262/1000, batch:   628/ 1052, ite: 68800] train loss: 0.005435, tar: 0.000340 
l0: 0.000456, l1: 0.000461, l2: 0.000469, l3: 0.000491, l4: 0.000790, l5: 0.001751, l6: 0.002305

[epoch: 262/1000, batch:   708/ 1052, ite: 68820] train loss: 0.005432, tar: 0.000340 
l0: 0.000316, l1: 0.000334, l2: 0.000350, l3: 0.000366, l4: 0.000590, l5: 0.001176, l6: 0.003334

[epoch: 262/1000, batch:   788/ 1052, ite: 68840] train loss: 0.005433, tar: 0.000340 
l0: 0.000244, l1: 0.000247, l2: 0.000283, l3: 0.000330, l4: 0.000542, l5: 0.001025, l6: 0.001316

[epoch: 262/1000, batch:   868/ 1052, ite: 68860] train loss: 0.005434, tar: 0.000340 
l0: 0.000421, l1: 0.000437, l2: 0.000444, l3: 0.000550, l4: 0.000963, l5: 0.001964, l6: 0.002688

[epoch: 262/1000, batch:   948/ 1052, ite: 68880] train loss: 0.005433, tar: 0.000340 
l0: 0.000258, l1: 0.000247, l2: 0.000276, l3: 0.000405, l4: 0.000669, l5: 0.001370, l6: 0.001636

[epoch: 262/1000, batch:  1028/ 1052, ite: 68900] train loss: 0.005433, tar: 0.000340 
[Epoch 262/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000204, l1: 0.000212, l2: 0.000213, l3: 0.000250, l4: 0.000423, l5: 0.000983, l6: 0.001545

[epoch: 263/1000, batch:    56/ 1052, ite: 68920] train loss: 0.005431, tar: 0.000340 
l0: 0.000192, l1: 0.000186, l2: 0.000200, l3: 0.000291, l4: 0.000594, l5: 0.000942, l6: 0.001624

[epoch: 263/1000, batch:   136/ 1052, ite: 68940] train loss: 0.005429, tar: 0.000339 
l0: 0.000470, l1: 0.000487, l2: 0.000460, l3: 0.000463, l4: 0.000680, l5: 0.000944, l6: 0.001755

[epoch: 263/1000, batch:   216/ 1052, ite: 68960] train loss: 0.005429, tar: 0.000339 
l0: 0.000198, l1: 0.000194, l2: 0.000255, l3: 0.000344, l4: 0.000564, l5: 0.001133, l6: 0.001836

[epoch: 263/1000, batch:   296/ 1052, ite: 68980] train loss: 0.005430, tar: 0.000339 
l0: 0.000193, l1: 0.000202, l2: 0.000209, l3: 0.000251, l4: 0.000300, l5: 0.000656, l6: 0.001247

[epoch: 263/1000, batch:   376/ 1052, ite: 69000] train loss: 0.005428, tar: 0.000339 
l0: 0.000396, l1: 0.000378, l2: 0.000456, l3: 0.000541, l4: 0.000784, l5: 0.001593, l6: 0.002770

[epoch: 263/1000, batch:   456/ 1052, ite: 69020] train loss: 0.005430, tar: 0.000339 
l0: 0.000362, l1: 0.000362, l2: 0.000352, l3: 0.000432, l4: 0.000493, l5: 0.001025, l6: 0.001685

[epoch: 263/1000, batch:   536/ 1052, ite: 69040] train loss: 0.005431, tar: 0.000339 
l0: 0.000405, l1: 0.000425, l2: 0.000400, l3: 0.000421, l4: 0.000676, l5: 0.002138, l6: 0.003191

[epoch: 263/1000, batch:   616/ 1052, ite: 69060] train loss: 0.005429, tar: 0.000339 
l0: 0.000188, l1: 0.000193, l2: 0.000177, l3: 0.000294, l4: 0.000449, l5: 0.001059, l6: 0.002422

[epoch: 263/1000, batch:   696/ 1052, ite: 69080] train loss: 0.005427, tar: 0.000339 
l0: 0.000321, l1: 0.000319, l2: 0.000289, l3: 0.000380, l4: 0.000730, l5: 0.001071, l6: 0.001286

[epoch: 263/1000, batch:   776/ 1052, ite: 69100] train loss: 0.005425, tar: 0.000338 
l0: 0.000236, l1: 0.000243, l2: 0.000249, l3: 0.000293, l4: 0.000326, l5: 0.000964, l6: 0.002192

[epoch: 263/1000, batch:   856/ 1052, ite: 69120] train loss: 0.005425, tar: 0.000338 
l0: 0.000134, l1: 0.000129, l2: 0.000153, l3: 0.000179, l4: 0.000279, l5: 0.000665, l6: 0.001235

[epoch: 263/1000, batch:   936/ 1052, ite: 69140] train loss: 0.005427, tar: 0.000338 
l0: 0.000366, l1: 0.000358, l2: 0.000376, l3: 0.000494, l4: 0.000852, l5: 0.001080, l6: 0.002121

[epoch: 263/1000, batch:  1016/ 1052, ite: 69160] train loss: 0.005424, tar: 0.000338 
[Epoch 263/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000306, l1: 0.000316, l2: 0.000335, l3: 0.000377, l4: 0.000493, l5: 0.001147, l6: 0.001229

[epoch: 264/1000, batch:    44/ 1052, ite: 69180] train loss: 0.005423, tar: 0.000338 
l0: 0.000452, l1: 0.000460, l2: 0.000487, l3: 0.000634, l4: 0.001146, l5: 0.002261, l6: 0.004167

[epoch: 264/1000, batch:   124/ 1052, ite: 69200] train loss: 0.005422, tar: 0.000338 
l0: 0.000363, l1: 0.000365, l2: 0.000368, l3: 0.000493, l4: 0.000712, l5: 0.001580, l6: 0.002286

[epoch: 264/1000, batch:   204/ 1052, ite: 69220] train loss: 0.005423, tar: 0.000338 
l0: 0.000150, l1: 0.000147, l2: 0.000177, l3: 0.000249, l4: 0.000398, l5: 0.000627, l6: 0.001310

[epoch: 264/1000, batch:   284/ 1052, ite: 69240] train loss: 0.005421, tar: 0.000338 
l0: 0.000235, l1: 0.000238, l2: 0.000280, l3: 0.000317, l4: 0.000548, l5: 0.000977, l6: 0.001488

[epoch: 264/1000, batch:   364/ 1052, ite: 69260] train loss: 0.005418, tar: 0.000337 
l0: 0.000258, l1: 0.000255, l2: 0.000293, l3: 0.000314, l4: 0.000571, l5: 0.000749, l6: 0.001406

[epoch: 264/1000, batch:   444/ 1052, ite: 69280] train loss: 0.005419, tar: 0.000337 
l0: 0.000268, l1: 0.000279, l2: 0.000279, l3: 0.000339, l4: 0.000557, l5: 0.001183, l6: 0.001266

[epoch: 264/1000, batch:   524/ 1052, ite: 69300] train loss: 0.005418, tar: 0.000337 
l0: 0.000180, l1: 0.000192, l2: 0.000210, l3: 0.000180, l4: 0.000393, l5: 0.000908, l6: 0.001661

[epoch: 264/1000, batch:   604/ 1052, ite: 69320] train loss: 0.005418, tar: 0.000337 
l0: 0.000172, l1: 0.000181, l2: 0.000188, l3: 0.000228, l4: 0.000418, l5: 0.000804, l6: 0.001447

[epoch: 264/1000, batch:   684/ 1052, ite: 69340] train loss: 0.005419, tar: 0.000337 
l0: 0.000406, l1: 0.000428, l2: 0.000437, l3: 0.000474, l4: 0.000801, l5: 0.001469, l6: 0.002533

[epoch: 264/1000, batch:   764/ 1052, ite: 69360] train loss: 0.005420, tar: 0.000337 
l0: 0.000381, l1: 0.000397, l2: 0.000367, l3: 0.000435, l4: 0.000630, l5: 0.000925, l6: 0.002130

[epoch: 264/1000, batch:   844/ 1052, ite: 69380] train loss: 0.005417, tar: 0.000337 
l0: 0.000306, l1: 0.000307, l2: 0.000321, l3: 0.000422, l4: 0.000503, l5: 0.001340, l6: 0.002358

[epoch: 264/1000, batch:   924/ 1052, ite: 69400] train loss: 0.005416, tar: 0.000337 
l0: 0.000370, l1: 0.000367, l2: 0.000423, l3: 0.000537, l4: 0.000741, l5: 0.001691, l6: 0.003611

[epoch: 264/1000, batch:  1004/ 1052, ite: 69420] train loss: 0.005416, tar: 0.000337 
[Epoch 264/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000711, l1: 0.000752, l2: 0.000681, l3: 0.000799, l4: 0.001160, l5: 0.002385, l6: 0.004260

[epoch: 265/1000, batch:    32/ 1052, ite: 69440] train loss: 0.005418, tar: 0.000337 
l0: 0.000441, l1: 0.000467, l2: 0.000508, l3: 0.000666, l4: 0.001058, l5: 0.002032, l6: 0.002986

[epoch: 265/1000, batch:   112/ 1052, ite: 69460] train loss: 0.005417, tar: 0.000337 
l0: 0.000230, l1: 0.000226, l2: 0.000277, l3: 0.000333, l4: 0.000532, l5: 0.001214, l6: 0.002123

[epoch: 265/1000, batch:   192/ 1052, ite: 69480] train loss: 0.005415, tar: 0.000336 
l0: 0.000203, l1: 0.000204, l2: 0.000230, l3: 0.000346, l4: 0.000515, l5: 0.001141, l6: 0.001876

[epoch: 265/1000, batch:   272/ 1052, ite: 69500] train loss: 0.005412, tar: 0.000336 
l0: 0.000226, l1: 0.000223, l2: 0.000233, l3: 0.000287, l4: 0.000443, l5: 0.000749, l6: 0.001385

[epoch: 265/1000, batch:   352/ 1052, ite: 69520] train loss: 0.005411, tar: 0.000336 
l0: 0.000364, l1: 0.000373, l2: 0.000368, l3: 0.000441, l4: 0.000679, l5: 0.001438, l6: 0.002412

[epoch: 265/1000, batch:   432/ 1052, ite: 69540] train loss: 0.005412, tar: 0.000336 
l0: 0.000189, l1: 0.000187, l2: 0.000226, l3: 0.000292, l4: 0.000446, l5: 0.001155, l6: 0.001849

[epoch: 265/1000, batch:   512/ 1052, ite: 69560] train loss: 0.005413, tar: 0.000336 
l0: 0.000365, l1: 0.000371, l2: 0.000387, l3: 0.000422, l4: 0.000532, l5: 0.001652, l6: 0.002890

[epoch: 265/1000, batch:   592/ 1052, ite: 69580] train loss: 0.005410, tar: 0.000336 
l0: 0.000359, l1: 0.000380, l2: 0.000377, l3: 0.000493, l4: 0.000768, l5: 0.001572, l6: 0.002538

[epoch: 265/1000, batch:   672/ 1052, ite: 69600] train loss: 0.005409, tar: 0.000335 
l0: 0.000199, l1: 0.000204, l2: 0.000232, l3: 0.000279, l4: 0.000470, l5: 0.001127, l6: 0.002185

[epoch: 265/1000, batch:   752/ 1052, ite: 69620] train loss: 0.005407, tar: 0.000335 
l0: 0.000261, l1: 0.000277, l2: 0.000264, l3: 0.000348, l4: 0.000500, l5: 0.000852, l6: 0.001815

[epoch: 265/1000, batch:   832/ 1052, ite: 69640] train loss: 0.005407, tar: 0.000335 
l0: 0.000204, l1: 0.000214, l2: 0.000227, l3: 0.000264, l4: 0.000496, l5: 0.000880, l6: 0.001757

[epoch: 265/1000, batch:   912/ 1052, ite: 69660] train loss: 0.005408, tar: 0.000335 
l0: 0.000388, l1: 0.000389, l2: 0.000399, l3: 0.000471, l4: 0.000669, l5: 0.001327, l6: 0.002658

[epoch: 265/1000, batch:   992/ 1052, ite: 69680] train loss: 0.005406, tar: 0.000335 
[Epoch 265/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000306, l1: 0.000301, l2: 0.000343, l3: 0.000452, l4: 0.000878, l5: 0.001814, l6: 0.002513

[epoch: 266/1000, batch:    20/ 1052, ite: 69700] train loss: 0.005407, tar: 0.000335 
l0: 0.000183, l1: 0.000178, l2: 0.000220, l3: 0.000342, l4: 0.000565, l5: 0.001067, l6: 0.001283

[epoch: 266/1000, batch:   100/ 1052, ite: 69720] train loss: 0.005406, tar: 0.000335 
l0: 0.000197, l1: 0.000201, l2: 0.000230, l3: 0.000241, l4: 0.000424, l5: 0.000822, l6: 0.001203

[epoch: 266/1000, batch:   180/ 1052, ite: 69740] train loss: 0.005403, tar: 0.000335 
l0: 0.000135, l1: 0.000136, l2: 0.000164, l3: 0.000207, l4: 0.000405, l5: 0.000781, l6: 0.000942

[epoch: 266/1000, batch:   260/ 1052, ite: 69760] train loss: 0.005402, tar: 0.000335 
l0: 0.000173, l1: 0.000173, l2: 0.000202, l3: 0.000302, l4: 0.000409, l5: 0.000860, l6: 0.001363

[epoch: 266/1000, batch:   340/ 1052, ite: 69780] train loss: 0.005400, tar: 0.000335 
l0: 0.000240, l1: 0.000242, l2: 0.000252, l3: 0.000312, l4: 0.000577, l5: 0.000466, l6: 0.001250

[epoch: 266/1000, batch:   420/ 1052, ite: 69800] train loss: 0.005399, tar: 0.000334 
l0: 0.000281, l1: 0.000286, l2: 0.000315, l3: 0.000328, l4: 0.000525, l5: 0.001242, l6: 0.002603

[epoch: 266/1000, batch:   500/ 1052, ite: 69820] train loss: 0.005400, tar: 0.000334 
l0: 0.000294, l1: 0.000309, l2: 0.000319, l3: 0.000300, l4: 0.000447, l5: 0.000858, l6: 0.001486

[epoch: 266/1000, batch:   580/ 1052, ite: 69840] train loss: 0.005399, tar: 0.000334 
l0: 0.000471, l1: 0.000479, l2: 0.000511, l3: 0.000566, l4: 0.000998, l5: 0.002378, l6: 0.003992

[epoch: 266/1000, batch:   660/ 1052, ite: 69860] train loss: 0.005400, tar: 0.000334 
l0: 0.000453, l1: 0.000461, l2: 0.000475, l3: 0.000578, l4: 0.000916, l5: 0.002175, l6: 0.002867

[epoch: 266/1000, batch:   740/ 1052, ite: 69880] train loss: 0.005399, tar: 0.000334 
l0: 0.000431, l1: 0.000440, l2: 0.000493, l3: 0.000474, l4: 0.000696, l5: 0.001003, l6: 0.002131

[epoch: 266/1000, batch:   820/ 1052, ite: 69900] train loss: 0.005400, tar: 0.000334 
l0: 0.000176, l1: 0.000170, l2: 0.000210, l3: 0.000306, l4: 0.000348, l5: 0.000699, l6: 0.001046

[epoch: 266/1000, batch:   900/ 1052, ite: 69920] train loss: 0.005401, tar: 0.000334 
l0: 0.000269, l1: 0.000275, l2: 0.000309, l3: 0.000314, l4: 0.000490, l5: 0.000959, l6: 0.001978

[epoch: 266/1000, batch:   980/ 1052, ite: 69940] train loss: 0.005401, tar: 0.000334 
[Epoch 266/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000300, l1: 0.000312, l2: 0.000308, l3: 0.000311, l4: 0.000447, l5: 0.000935, l6: 0.001504

[epoch: 267/1000, batch:     8/ 1052, ite: 69960] train loss: 0.005400, tar: 0.000334 
l0: 0.000207, l1: 0.000211, l2: 0.000241, l3: 0.000308, l4: 0.000562, l5: 0.001350, l6: 0.001941

[epoch: 267/1000, batch:    88/ 1052, ite: 69980] train loss: 0.005399, tar: 0.000334 
l0: 0.000265, l1: 0.000260, l2: 0.000284, l3: 0.000390, l4: 0.000579, l5: 0.001092, l6: 0.001896

[epoch: 267/1000, batch:   168/ 1052, ite: 70000] train loss: 0.005398, tar: 0.000333 
l0: 0.000230, l1: 0.000245, l2: 0.000265, l3: 0.000189, l4: 0.000584, l5: 0.000961, l6: 0.001609

[epoch: 267/1000, batch:   248/ 1052, ite: 70020] train loss: 0.005397, tar: 0.000333 
l0: 0.000253, l1: 0.000260, l2: 0.000311, l3: 0.000291, l4: 0.000682, l5: 0.001448, l6: 0.002123

[epoch: 267/1000, batch:   328/ 1052, ite: 70040] train loss: 0.005397, tar: 0.000333 
l0: 0.000339, l1: 0.000342, l2: 0.000404, l3: 0.000441, l4: 0.000882, l5: 0.001792, l6: 0.002956

[epoch: 267/1000, batch:   408/ 1052, ite: 70060] train loss: 0.005398, tar: 0.000333 
l0: 0.000226, l1: 0.000229, l2: 0.000242, l3: 0.000290, l4: 0.000417, l5: 0.000931, l6: 0.002021

[epoch: 267/1000, batch:   488/ 1052, ite: 70080] train loss: 0.005397, tar: 0.000333 
l0: 0.000195, l1: 0.000215, l2: 0.000210, l3: 0.000179, l4: 0.000542, l5: 0.000678, l6: 0.001304

[epoch: 267/1000, batch:   568/ 1052, ite: 70100] train loss: 0.005396, tar: 0.000333 
l0: 0.000268, l1: 0.000266, l2: 0.000311, l3: 0.000355, l4: 0.000553, l5: 0.001063, l6: 0.002085

[epoch: 267/1000, batch:   648/ 1052, ite: 70120] train loss: 0.005395, tar: 0.000333 
l0: 0.000348, l1: 0.000351, l2: 0.000380, l3: 0.000445, l4: 0.000551, l5: 0.001195, l6: 0.002480

[epoch: 267/1000, batch:   728/ 1052, ite: 70140] train loss: 0.005395, tar: 0.000333 
l0: 0.000375, l1: 0.000377, l2: 0.000373, l3: 0.000464, l4: 0.000921, l5: 0.001417, l6: 0.002996

[epoch: 267/1000, batch:   808/ 1052, ite: 70160] train loss: 0.005393, tar: 0.000332 
l0: 0.000776, l1: 0.000781, l2: 0.000789, l3: 0.001002, l4: 0.001716, l5: 0.002744, l6: 0.006073

[epoch: 267/1000, batch:   888/ 1052, ite: 70180] train loss: 0.005391, tar: 0.000332 
l0: 0.000197, l1: 0.000213, l2: 0.000218, l3: 0.000219, l4: 0.000393, l5: 0.000907, l6: 0.001221

[epoch: 267/1000, batch:   968/ 1052, ite: 70200] train loss: 0.005389, tar: 0.000332 
l0: 0.000275, l1: 0.000279, l2: 0.000324, l3: 0.000326, l4: 0.000686, l5: 0.001221, l6: 0.001909

[epoch: 267/1000, batch:  1048/ 1052, ite: 70220] train loss: 0.005389, tar: 0.000332 
[Epoch 267/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000218, l1: 0.000222, l2: 0.000236, l3: 0.000290, l4: 0.000495, l5: 0.000761, l6: 0.001771

[epoch: 268/1000, batch:    76/ 1052, ite: 70240] train loss: 0.005388, tar: 0.000332 
l0: 0.000560, l1: 0.000578, l2: 0.000551, l3: 0.000797, l4: 0.001351, l5: 0.002510, l6: 0.004720

[epoch: 268/1000, batch:   156/ 1052, ite: 70260] train loss: 0.005389, tar: 0.000332 
l0: 0.000360, l1: 0.000366, l2: 0.000358, l3: 0.000483, l4: 0.000691, l5: 0.001743, l6: 0.002667

[epoch: 268/1000, batch:   236/ 1052, ite: 70280] train loss: 0.005388, tar: 0.000331 
l0: 0.000128, l1: 0.000133, l2: 0.000150, l3: 0.000186, l4: 0.000379, l5: 0.000682, l6: 0.001541

[epoch: 268/1000, batch:   316/ 1052, ite: 70300] train loss: 0.005387, tar: 0.000331 
l0: 0.000222, l1: 0.000227, l2: 0.000245, l3: 0.000297, l4: 0.000447, l5: 0.000754, l6: 0.001370

[epoch: 268/1000, batch:   396/ 1052, ite: 70320] train loss: 0.005385, tar: 0.000331 
l0: 0.000166, l1: 0.000173, l2: 0.000206, l3: 0.000190, l4: 0.000388, l5: 0.000907, l6: 0.001381

[epoch: 268/1000, batch:   476/ 1052, ite: 70340] train loss: 0.005385, tar: 0.000331 
l0: 0.000263, l1: 0.000270, l2: 0.000284, l3: 0.000383, l4: 0.000793, l5: 0.001328, l6: 0.002261

[epoch: 268/1000, batch:   556/ 1052, ite: 70360] train loss: 0.005384, tar: 0.000331 
l0: 0.000319, l1: 0.000322, l2: 0.000343, l3: 0.000445, l4: 0.000715, l5: 0.001310, l6: 0.003375

[epoch: 268/1000, batch:   636/ 1052, ite: 70380] train loss: 0.005385, tar: 0.000331 
l0: 0.000220, l1: 0.000218, l2: 0.000257, l3: 0.000275, l4: 0.000537, l5: 0.000694, l6: 0.001404

[epoch: 268/1000, batch:   716/ 1052, ite: 70400] train loss: 0.005383, tar: 0.000331 
l0: 0.000210, l1: 0.000219, l2: 0.000245, l3: 0.000278, l4: 0.000664, l5: 0.000759, l6: 0.002262

[epoch: 268/1000, batch:   796/ 1052, ite: 70420] train loss: 0.005383, tar: 0.000331 
l0: 0.000364, l1: 0.000368, l2: 0.000365, l3: 0.000463, l4: 0.000720, l5: 0.001086, l6: 0.002741

[epoch: 268/1000, batch:   876/ 1052, ite: 70440] train loss: 0.005384, tar: 0.000331 
l0: 0.000288, l1: 0.000296, l2: 0.000309, l3: 0.000339, l4: 0.000730, l5: 0.001530, l6: 0.001566

[epoch: 268/1000, batch:   956/ 1052, ite: 70460] train loss: 0.005382, tar: 0.000331 
l0: 0.000330, l1: 0.000332, l2: 0.000361, l3: 0.000535, l4: 0.000862, l5: 0.001475, l6: 0.002183

[epoch: 268/1000, batch:  1036/ 1052, ite: 70480] train loss: 0.005380, tar: 0.000330 
[Epoch 268/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000230, l1: 0.000236, l2: 0.000248, l3: 0.000306, l4: 0.000452, l5: 0.000991, l6: 0.001281

[epoch: 269/1000, batch:    64/ 1052, ite: 70500] train loss: 0.005380, tar: 0.000330 
l0: 0.000227, l1: 0.000225, l2: 0.000224, l3: 0.000357, l4: 0.000553, l5: 0.001276, l6: 0.001688

[epoch: 269/1000, batch:   144/ 1052, ite: 70520] train loss: 0.005378, tar: 0.000330 
l0: 0.000261, l1: 0.000284, l2: 0.000268, l3: 0.000329, l4: 0.000490, l5: 0.001116, l6: 0.001854

[epoch: 269/1000, batch:   224/ 1052, ite: 70540] train loss: 0.005377, tar: 0.000330 
l0: 0.000140, l1: 0.000140, l2: 0.000173, l3: 0.000198, l4: 0.000347, l5: 0.000530, l6: 0.001107

[epoch: 269/1000, batch:   304/ 1052, ite: 70560] train loss: 0.005376, tar: 0.000330 
l0: 0.000191, l1: 0.000192, l2: 0.000217, l3: 0.000311, l4: 0.000386, l5: 0.001097, l6: 0.001723

[epoch: 269/1000, batch:   384/ 1052, ite: 70580] train loss: 0.005375, tar: 0.000330 
l0: 0.000506, l1: 0.000496, l2: 0.000560, l3: 0.000722, l4: 0.001283, l5: 0.002361, l6: 0.002442

[epoch: 269/1000, batch:   464/ 1052, ite: 70600] train loss: 0.005376, tar: 0.000330 
l0: 0.000528, l1: 0.000522, l2: 0.000629, l3: 0.000666, l4: 0.000886, l5: 0.001902, l6: 0.003317

[epoch: 269/1000, batch:   544/ 1052, ite: 70620] train loss: 0.005376, tar: 0.000330 
l0: 0.000590, l1: 0.000583, l2: 0.000647, l3: 0.000840, l4: 0.001207, l5: 0.002598, l6: 0.003558

[epoch: 269/1000, batch:   624/ 1052, ite: 70640] train loss: 0.005377, tar: 0.000330 
l0: 0.000163, l1: 0.000172, l2: 0.000186, l3: 0.000201, l4: 0.000452, l5: 0.000673, l6: 0.001345

[epoch: 269/1000, batch:   704/ 1052, ite: 70660] train loss: 0.005376, tar: 0.000330 
l0: 0.000149, l1: 0.000157, l2: 0.000178, l3: 0.000196, l4: 0.000392, l5: 0.000618, l6: 0.001740

[epoch: 269/1000, batch:   784/ 1052, ite: 70680] train loss: 0.005376, tar: 0.000329 
l0: 0.000190, l1: 0.000191, l2: 0.000212, l3: 0.000264, l4: 0.000470, l5: 0.001019, l6: 0.001378

[epoch: 269/1000, batch:   864/ 1052, ite: 70700] train loss: 0.005374, tar: 0.000329 
l0: 0.000259, l1: 0.000257, l2: 0.000302, l3: 0.000443, l4: 0.000541, l5: 0.000858, l6: 0.001465

[epoch: 269/1000, batch:   944/ 1052, ite: 70720] train loss: 0.005373, tar: 0.000329 
l0: 0.000285, l1: 0.000284, l2: 0.000309, l3: 0.000455, l4: 0.000824, l5: 0.001391, l6: 0.001682

[epoch: 269/1000, batch:  1024/ 1052, ite: 70740] train loss: 0.005373, tar: 0.000329 
[Epoch 269/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000321, l1: 0.000314, l2: 0.000384, l3: 0.000414, l4: 0.000614, l5: 0.001015, l6: 0.002637

[epoch: 270/1000, batch:    52/ 1052, ite: 70760] train loss: 0.005372, tar: 0.000329 
l0: 0.000300, l1: 0.000308, l2: 0.000313, l3: 0.000363, l4: 0.000499, l5: 0.001316, l6: 0.002943

[epoch: 270/1000, batch:   132/ 1052, ite: 70780] train loss: 0.005373, tar: 0.000329 
l0: 0.000367, l1: 0.000387, l2: 0.000395, l3: 0.000464, l4: 0.000614, l5: 0.000894, l6: 0.002843

[epoch: 270/1000, batch:   212/ 1052, ite: 70800] train loss: 0.005373, tar: 0.000329 
l0: 0.000289, l1: 0.000296, l2: 0.000338, l3: 0.000356, l4: 0.000663, l5: 0.000972, l6: 0.001460

[epoch: 270/1000, batch:   292/ 1052, ite: 70820] train loss: 0.005371, tar: 0.000329 
l0: 0.000237, l1: 0.000248, l2: 0.000272, l3: 0.000390, l4: 0.000604, l5: 0.001242, l6: 0.001937

[epoch: 270/1000, batch:   372/ 1052, ite: 70840] train loss: 0.005371, tar: 0.000329 
l0: 0.000208, l1: 0.000219, l2: 0.000255, l3: 0.000261, l4: 0.000680, l5: 0.001034, l6: 0.001680

[epoch: 270/1000, batch:   452/ 1052, ite: 70860] train loss: 0.005370, tar: 0.000329 
l0: 0.000304, l1: 0.000303, l2: 0.000312, l3: 0.000416, l4: 0.000878, l5: 0.001824, l6: 0.003126

[epoch: 270/1000, batch:   532/ 1052, ite: 70880] train loss: 0.005371, tar: 0.000328 
l0: 0.000115, l1: 0.000114, l2: 0.000163, l3: 0.000204, l4: 0.000408, l5: 0.000607, l6: 0.000864

[epoch: 270/1000, batch:   612/ 1052, ite: 70900] train loss: 0.005370, tar: 0.000328 
l0: 0.000386, l1: 0.000398, l2: 0.000378, l3: 0.000467, l4: 0.000617, l5: 0.001090, l6: 0.002130

[epoch: 270/1000, batch:   692/ 1052, ite: 70920] train loss: 0.005369, tar: 0.000328 
l0: 0.000529, l1: 0.000549, l2: 0.000563, l3: 0.000590, l4: 0.001061, l5: 0.002264, l6: 0.004380

[epoch: 270/1000, batch:   772/ 1052, ite: 70940] train loss: 0.005370, tar: 0.000328 
l0: 0.000280, l1: 0.000282, l2: 0.000321, l3: 0.000410, l4: 0.000914, l5: 0.001629, l6: 0.002609

[epoch: 270/1000, batch:   852/ 1052, ite: 70960] train loss: 0.005368, tar: 0.000328 
l0: 0.000226, l1: 0.000242, l2: 0.000244, l3: 0.000232, l4: 0.000406, l5: 0.000758, l6: 0.001887

[epoch: 270/1000, batch:   932/ 1052, ite: 70980] train loss: 0.005367, tar: 0.000328 
l0: 0.000330, l1: 0.000336, l2: 0.000393, l3: 0.000532, l4: 0.000768, l5: 0.001257, l6: 0.001607

[epoch: 270/1000, batch:  1012/ 1052, ite: 71000] train loss: 0.005367, tar: 0.000328 
[Epoch 270/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000355, l1: 0.000353, l2: 0.000353, l3: 0.000433, l4: 0.000703, l5: 0.000997, l6: 0.001681

[epoch: 271/1000, batch:    40/ 1052, ite: 71020] train loss: 0.005366, tar: 0.000328 
l0: 0.000684, l1: 0.000698, l2: 0.000719, l3: 0.000761, l4: 0.001146, l5: 0.002024, l6: 0.003571

[epoch: 271/1000, batch:   120/ 1052, ite: 71040] train loss: 0.005366, tar: 0.000328 
l0: 0.000291, l1: 0.000289, l2: 0.000316, l3: 0.000361, l4: 0.000803, l5: 0.001149, l6: 0.002525

[epoch: 271/1000, batch:   200/ 1052, ite: 71060] train loss: 0.005366, tar: 0.000328 
l0: 0.000212, l1: 0.000216, l2: 0.000255, l3: 0.000356, l4: 0.000640, l5: 0.001026, l6: 0.002359

[epoch: 271/1000, batch:   280/ 1052, ite: 71080] train loss: 0.005365, tar: 0.000328 
l0: 0.000336, l1: 0.000334, l2: 0.000378, l3: 0.000419, l4: 0.000598, l5: 0.001397, l6: 0.001899

[epoch: 271/1000, batch:   360/ 1052, ite: 71100] train loss: 0.005366, tar: 0.000327 
l0: 0.000211, l1: 0.000214, l2: 0.000242, l3: 0.000266, l4: 0.000473, l5: 0.000771, l6: 0.001479

[epoch: 271/1000, batch:   440/ 1052, ite: 71120] train loss: 0.005364, tar: 0.000327 
l0: 0.000519, l1: 0.000524, l2: 0.000545, l3: 0.000731, l4: 0.001153, l5: 0.002144, l6: 0.004140

[epoch: 271/1000, batch:   520/ 1052, ite: 71140] train loss: 0.005362, tar: 0.000327 
l0: 0.000138, l1: 0.000141, l2: 0.000164, l3: 0.000179, l4: 0.000435, l5: 0.000846, l6: 0.000907

[epoch: 271/1000, batch:   600/ 1052, ite: 71160] train loss: 0.005362, tar: 0.000327 
l0: 0.000203, l1: 0.000200, l2: 0.000274, l3: 0.000360, l4: 0.000624, l5: 0.001197, l6: 0.002623

[epoch: 271/1000, batch:   680/ 1052, ite: 71180] train loss: 0.005362, tar: 0.000327 
l0: 0.000296, l1: 0.000312, l2: 0.000346, l3: 0.000503, l4: 0.000824, l5: 0.001629, l6: 0.002750

[epoch: 271/1000, batch:   760/ 1052, ite: 71200] train loss: 0.005361, tar: 0.000327 
l0: 0.000212, l1: 0.000215, l2: 0.000254, l3: 0.000303, l4: 0.000428, l5: 0.001119, l6: 0.001720

[epoch: 271/1000, batch:   840/ 1052, ite: 71220] train loss: 0.005360, tar: 0.000327 
l0: 0.000254, l1: 0.000254, l2: 0.000297, l3: 0.000363, l4: 0.000684, l5: 0.001321, l6: 0.002068

[epoch: 271/1000, batch:   920/ 1052, ite: 71240] train loss: 0.005359, tar: 0.000327 
l0: 0.000291, l1: 0.000288, l2: 0.000296, l3: 0.000369, l4: 0.000589, l5: 0.001134, l6: 0.001872

[epoch: 271/1000, batch:  1000/ 1052, ite: 71260] train loss: 0.005357, tar: 0.000326 
[Epoch 271/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000401, l1: 0.000421, l2: 0.000479, l3: 0.000482, l4: 0.000845, l5: 0.002457, l6: 0.003351

[epoch: 272/1000, batch:    28/ 1052, ite: 71280] train loss: 0.005359, tar: 0.000326 
l0: 0.000335, l1: 0.000330, l2: 0.000391, l3: 0.000459, l4: 0.000656, l5: 0.001116, l6: 0.002106

[epoch: 272/1000, batch:   108/ 1052, ite: 71300] train loss: 0.005358, tar: 0.000326 
l0: 0.000314, l1: 0.000326, l2: 0.000343, l3: 0.000432, l4: 0.000619, l5: 0.001272, l6: 0.002601

[epoch: 272/1000, batch:   188/ 1052, ite: 71320] train loss: 0.005357, tar: 0.000326 
l0: 0.000398, l1: 0.000389, l2: 0.000440, l3: 0.000531, l4: 0.000767, l5: 0.001222, l6: 0.001815

[epoch: 272/1000, batch:   268/ 1052, ite: 71340] train loss: 0.005356, tar: 0.000326 
l0: 0.000227, l1: 0.000241, l2: 0.000219, l3: 0.000239, l4: 0.000378, l5: 0.000742, l6: 0.001064

[epoch: 272/1000, batch:   348/ 1052, ite: 71360] train loss: 0.005356, tar: 0.000326 
l0: 0.000246, l1: 0.000251, l2: 0.000268, l3: 0.000292, l4: 0.000459, l5: 0.000878, l6: 0.002326

[epoch: 272/1000, batch:   428/ 1052, ite: 71380] train loss: 0.005356, tar: 0.000326 
l0: 0.000085, l1: 0.000084, l2: 0.000108, l3: 0.000149, l4: 0.000224, l5: 0.000684, l6: 0.001209

[epoch: 272/1000, batch:   508/ 1052, ite: 71400] train loss: 0.005354, tar: 0.000326 
l0: 0.000289, l1: 0.000298, l2: 0.000313, l3: 0.000371, l4: 0.000554, l5: 0.001163, l6: 0.002194

[epoch: 272/1000, batch:   588/ 1052, ite: 71420] train loss: 0.005354, tar: 0.000326 
l0: 0.000827, l1: 0.000855, l2: 0.000887, l3: 0.001007, l4: 0.001658, l5: 0.003755, l6: 0.007204

[epoch: 272/1000, batch:   668/ 1052, ite: 71440] train loss: 0.005355, tar: 0.000326 
l0: 0.000271, l1: 0.000267, l2: 0.000282, l3: 0.000387, l4: 0.000620, l5: 0.001346, l6: 0.001854

[epoch: 272/1000, batch:   748/ 1052, ite: 71460] train loss: 0.005354, tar: 0.000326 
l0: 0.000153, l1: 0.000144, l2: 0.000209, l3: 0.000248, l4: 0.000391, l5: 0.000636, l6: 0.001037

[epoch: 272/1000, batch:   828/ 1052, ite: 71480] train loss: 0.005354, tar: 0.000325 
l0: 0.000250, l1: 0.000250, l2: 0.000264, l3: 0.000305, l4: 0.000408, l5: 0.000867, l6: 0.001369

[epoch: 272/1000, batch:   908/ 1052, ite: 71500] train loss: 0.005354, tar: 0.000325 
l0: 0.000117, l1: 0.000120, l2: 0.000120, l3: 0.000149, l4: 0.000334, l5: 0.000398, l6: 0.000974

[epoch: 272/1000, batch:   988/ 1052, ite: 71520] train loss: 0.005353, tar: 0.000325 
[Epoch 272/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000297, l1: 0.000297, l2: 0.000325, l3: 0.000387, l4: 0.000450, l5: 0.000828, l6: 0.001889

[epoch: 273/1000, batch:    16/ 1052, ite: 71540] train loss: 0.005354, tar: 0.000325 
l0: 0.000251, l1: 0.000250, l2: 0.000285, l3: 0.000333, l4: 0.000518, l5: 0.000755, l6: 0.001832

[epoch: 273/1000, batch:    96/ 1052, ite: 71560] train loss: 0.005353, tar: 0.000325 
l0: 0.000179, l1: 0.000178, l2: 0.000209, l3: 0.000250, l4: 0.000388, l5: 0.000888, l6: 0.001309

[epoch: 273/1000, batch:   176/ 1052, ite: 71580] train loss: 0.005353, tar: 0.000325 
l0: 0.000308, l1: 0.000317, l2: 0.000307, l3: 0.000366, l4: 0.000629, l5: 0.001442, l6: 0.002109

[epoch: 273/1000, batch:   256/ 1052, ite: 71600] train loss: 0.005351, tar: 0.000325 
l0: 0.000131, l1: 0.000129, l2: 0.000175, l3: 0.000227, l4: 0.000441, l5: 0.000831, l6: 0.001179

[epoch: 273/1000, batch:   336/ 1052, ite: 71620] train loss: 0.005351, tar: 0.000325 
l0: 0.000614, l1: 0.000600, l2: 0.000605, l3: 0.000726, l4: 0.001070, l5: 0.001852, l6: 0.001979

[epoch: 273/1000, batch:   416/ 1052, ite: 71640] train loss: 0.005352, tar: 0.000325 
l0: 0.000133, l1: 0.000134, l2: 0.000153, l3: 0.000180, l4: 0.000354, l5: 0.000853, l6: 0.000894

[epoch: 273/1000, batch:   496/ 1052, ite: 71660] train loss: 0.005352, tar: 0.000325 
l0: 0.000172, l1: 0.000172, l2: 0.000216, l3: 0.000223, l4: 0.000432, l5: 0.000606, l6: 0.001089

[epoch: 273/1000, batch:   576/ 1052, ite: 71680] train loss: 0.005351, tar: 0.000325 
l0: 0.000288, l1: 0.000299, l2: 0.000294, l3: 0.000306, l4: 0.000494, l5: 0.000881, l6: 0.001648

[epoch: 273/1000, batch:   656/ 1052, ite: 71700] train loss: 0.005351, tar: 0.000325 
l0: 0.000424, l1: 0.000455, l2: 0.000448, l3: 0.000419, l4: 0.000786, l5: 0.001186, l6: 0.003467

[epoch: 273/1000, batch:   736/ 1052, ite: 71720] train loss: 0.005350, tar: 0.000324 
l0: 0.000389, l1: 0.000370, l2: 0.000434, l3: 0.000647, l4: 0.001022, l5: 0.001920, l6: 0.002742

[epoch: 273/1000, batch:   816/ 1052, ite: 71740] train loss: 0.005348, tar: 0.000324 
l0: 0.000565, l1: 0.000600, l2: 0.000593, l3: 0.000566, l4: 0.000813, l5: 0.002032, l6: 0.002590

[epoch: 273/1000, batch:   896/ 1052, ite: 71760] train loss: 0.005348, tar: 0.000324 
l0: 0.000259, l1: 0.000262, l2: 0.000277, l3: 0.000362, l4: 0.000599, l5: 0.001111, l6: 0.002375

[epoch: 273/1000, batch:   976/ 1052, ite: 71780] train loss: 0.005346, tar: 0.000324 
[Epoch 273/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000191, l1: 0.000196, l2: 0.000193, l3: 0.000210, l4: 0.000331, l5: 0.000547, l6: 0.001060

[epoch: 274/1000, batch:     4/ 1052, ite: 71800] train loss: 0.005347, tar: 0.000324 
l0: 0.000598, l1: 0.000625, l2: 0.000609, l3: 0.000675, l4: 0.001029, l5: 0.002346, l6: 0.003730

[epoch: 274/1000, batch:    84/ 1052, ite: 71820] train loss: 0.005347, tar: 0.000324 
l0: 0.000368, l1: 0.000370, l2: 0.000368, l3: 0.000511, l4: 0.000770, l5: 0.001202, l6: 0.002954

[epoch: 274/1000, batch:   164/ 1052, ite: 71840] train loss: 0.005347, tar: 0.000324 
l0: 0.000282, l1: 0.000288, l2: 0.000298, l3: 0.000455, l4: 0.000742, l5: 0.001586, l6: 0.002172

[epoch: 274/1000, batch:   244/ 1052, ite: 71860] train loss: 0.005346, tar: 0.000324 
l0: 0.000291, l1: 0.000303, l2: 0.000355, l3: 0.000479, l4: 0.000766, l5: 0.001100, l6: 0.002149

[epoch: 274/1000, batch:   324/ 1052, ite: 71880] train loss: 0.005346, tar: 0.000324 
l0: 0.000183, l1: 0.000180, l2: 0.000224, l3: 0.000255, l4: 0.000789, l5: 0.000982, l6: 0.002041

[epoch: 274/1000, batch:   404/ 1052, ite: 71900] train loss: 0.005345, tar: 0.000324 
l0: 0.000174, l1: 0.000175, l2: 0.000207, l3: 0.000244, l4: 0.000586, l5: 0.000956, l6: 0.001742

[epoch: 274/1000, batch:   484/ 1052, ite: 71920] train loss: 0.005345, tar: 0.000324 
l0: 0.000252, l1: 0.000259, l2: 0.000309, l3: 0.000385, l4: 0.000805, l5: 0.001821, l6: 0.002907

[epoch: 274/1000, batch:   564/ 1052, ite: 71940] train loss: 0.005343, tar: 0.000324 
l0: 0.000175, l1: 0.000173, l2: 0.000216, l3: 0.000317, l4: 0.000645, l5: 0.000748, l6: 0.001523

[epoch: 274/1000, batch:   644/ 1052, ite: 71960] train loss: 0.005345, tar: 0.000324 
l0: 0.000194, l1: 0.000182, l2: 0.000243, l3: 0.000359, l4: 0.000462, l5: 0.000872, l6: 0.001976

[epoch: 274/1000, batch:   724/ 1052, ite: 71980] train loss: 0.005345, tar: 0.000324 
l0: 0.000314, l1: 0.000318, l2: 0.000337, l3: 0.000390, l4: 0.000612, l5: 0.001374, l6: 0.002203

[epoch: 274/1000, batch:   804/ 1052, ite: 72000] train loss: 0.005345, tar: 0.000324 
l0: 0.000428, l1: 0.000451, l2: 0.000451, l3: 0.000607, l4: 0.001241, l5: 0.001576, l6: 0.003574

[epoch: 274/1000, batch:   884/ 1052, ite: 72020] train loss: 0.005345, tar: 0.000324 
l0: 0.000217, l1: 0.000214, l2: 0.000257, l3: 0.000345, l4: 0.000681, l5: 0.001332, l6: 0.002024

[epoch: 274/1000, batch:   964/ 1052, ite: 72040] train loss: 0.005345, tar: 0.000324 
l0: 0.000177, l1: 0.000175, l2: 0.000208, l3: 0.000251, l4: 0.000429, l5: 0.000693, l6: 0.000959

[epoch: 274/1000, batch:  1044/ 1052, ite: 72060] train loss: 0.005344, tar: 0.000323 
[Epoch 274/1000] Test loss: 0.009, Test target loss: 0.001
l0: 0.000240, l1: 0.000230, l2: 0.000292, l3: 0.000412, l4: 0.000786, l5: 0.000787, l6: 0.001972

[epoch: 275/1000, batch:    72/ 1052, ite: 72080] train loss: 0.005343, tar: 0.000323 
l0: 0.000325, l1: 0.000315, l2: 0.000412, l3: 0.000665, l4: 0.001150, l5: 0.002205, l6: 0.003404

[epoch: 275/1000, batch:   152/ 1052, ite: 72100] train loss: 0.005341, tar: 0.000323 
l0: 0.000163, l1: 0.000174, l2: 0.000178, l3: 0.000180, l4: 0.000265, l5: 0.000916, l6: 0.001422

[epoch: 275/1000, batch:   232/ 1052, ite: 72120] train loss: 0.005341, tar: 0.000323 
l0: 0.000176, l1: 0.000176, l2: 0.000200, l3: 0.000249, l4: 0.000419, l5: 0.001297, l6: 0.001768

[epoch: 275/1000, batch:   312/ 1052, ite: 72140] train loss: 0.005339, tar: 0.000323 
l0: 0.000192, l1: 0.000199, l2: 0.000201, l3: 0.000238, l4: 0.000385, l5: 0.000919, l6: 0.001398

[epoch: 275/1000, batch:   392/ 1052, ite: 72160] train loss: 0.005340, tar: 0.000323 
l0: 0.000257, l1: 0.000259, l2: 0.000259, l3: 0.000312, l4: 0.000469, l5: 0.000670, l6: 0.001425

[epoch: 275/1000, batch:   472/ 1052, ite: 72180] train loss: 0.005340, tar: 0.000323 
l0: 0.000369, l1: 0.000366, l2: 0.000384, l3: 0.000568, l4: 0.000801, l5: 0.002117, l6: 0.003083

[epoch: 275/1000, batch:   552/ 1052, ite: 72200] train loss: 0.005340, tar: 0.000323 
l0: 0.000334, l1: 0.000372, l2: 0.000359, l3: 0.000400, l4: 0.000780, l5: 0.000880, l6: 0.002058

[epoch: 275/1000, batch:   632/ 1052, ite: 72220] train loss: 0.005338, tar: 0.000323 
l0: 0.000245, l1: 0.000240, l2: 0.000276, l3: 0.000302, l4: 0.000354, l5: 0.000866, l6: 0.001367

[epoch: 275/1000, batch:   712/ 1052, ite: 72240] train loss: 0.005339, tar: 0.000323 
l0: 0.000288, l1: 0.000301, l2: 0.000298, l3: 0.000397, l4: 0.000761, l5: 0.001327, l6: 0.002174

[epoch: 275/1000, batch:   792/ 1052, ite: 72260] train loss: 0.005337, tar: 0.000322 
l0: 0.000244, l1: 0.000233, l2: 0.000272, l3: 0.000341, l4: 0.000520, l5: 0.001040, l6: 0.001525

[epoch: 275/1000, batch:   872/ 1052, ite: 72280] train loss: 0.005339, tar: 0.000322 
l0: 0.000329, l1: 0.000349, l2: 0.000385, l3: 0.000393, l4: 0.000649, l5: 0.001197, l6: 0.002838

[epoch: 275/1000, batch:   952/ 1052, ite: 72300] train loss: 0.005339, tar: 0.000322 
l0: 0.000289, l1: 0.000291, l2: 0.000321, l3: 0.000371, l4: 0.000583, l5: 0.001040, l6: 0.001145

[epoch: 275/1000, batch:  1032/ 1052, ite: 72320] train loss: 0.005337, tar: 0.000322 
[Epoch 275/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000169, l1: 0.000169, l2: 0.000225, l3: 0.000253, l4: 0.000441, l5: 0.000654, l6: 0.001488

[epoch: 276/1000, batch:    60/ 1052, ite: 72340] train loss: 0.005337, tar: 0.000322 
l0: 0.000441, l1: 0.000474, l2: 0.000459, l3: 0.000450, l4: 0.000579, l5: 0.001483, l6: 0.001838

[epoch: 276/1000, batch:   140/ 1052, ite: 72360] train loss: 0.005335, tar: 0.000322 
l0: 0.000156, l1: 0.000149, l2: 0.000159, l3: 0.000262, l4: 0.000341, l5: 0.000656, l6: 0.001065

[epoch: 276/1000, batch:   220/ 1052, ite: 72380] train loss: 0.005335, tar: 0.000322 
l0: 0.000190, l1: 0.000192, l2: 0.000213, l3: 0.000276, l4: 0.000418, l5: 0.000944, l6: 0.001923

[epoch: 276/1000, batch:   300/ 1052, ite: 72400] train loss: 0.005335, tar: 0.000322 
l0: 0.000167, l1: 0.000160, l2: 0.000181, l3: 0.000244, l4: 0.000362, l5: 0.000614, l6: 0.000880

[epoch: 276/1000, batch:   380/ 1052, ite: 72420] train loss: 0.005334, tar: 0.000322 
l0: 0.000233, l1: 0.000245, l2: 0.000257, l3: 0.000318, l4: 0.000622, l5: 0.001279, l6: 0.002541

[epoch: 276/1000, batch:   460/ 1052, ite: 72440] train loss: 0.005335, tar: 0.000322 
l0: 0.000533, l1: 0.000552, l2: 0.000566, l3: 0.000686, l4: 0.001192, l5: 0.002497, l6: 0.003104

[epoch: 276/1000, batch:   540/ 1052, ite: 72460] train loss: 0.005334, tar: 0.000322 
l0: 0.000217, l1: 0.000215, l2: 0.000280, l3: 0.000312, l4: 0.000516, l5: 0.000893, l6: 0.002397

[epoch: 276/1000, batch:   620/ 1052, ite: 72480] train loss: 0.005334, tar: 0.000322 
l0: 0.000232, l1: 0.000242, l2: 0.000257, l3: 0.000317, l4: 0.000550, l5: 0.001177, l6: 0.002013

[epoch: 276/1000, batch:   700/ 1052, ite: 72500] train loss: 0.005335, tar: 0.000322 
l0: 0.000208, l1: 0.000208, l2: 0.000217, l3: 0.000265, l4: 0.000332, l5: 0.001022, l6: 0.001362

[epoch: 276/1000, batch:   780/ 1052, ite: 72520] train loss: 0.005335, tar: 0.000322 
l0: 0.000184, l1: 0.000191, l2: 0.000207, l3: 0.000270, l4: 0.000659, l5: 0.001175, l6: 0.002293

[epoch: 276/1000, batch:   860/ 1052, ite: 72540] train loss: 0.005334, tar: 0.000322 
l0: 0.000224, l1: 0.000220, l2: 0.000242, l3: 0.000360, l4: 0.000458, l5: 0.000637, l6: 0.001172

[epoch: 276/1000, batch:   940/ 1052, ite: 72560] train loss: 0.005334, tar: 0.000322 
l0: 0.000215, l1: 0.000212, l2: 0.000217, l3: 0.000276, l4: 0.000498, l5: 0.001079, l6: 0.001401

[epoch: 276/1000, batch:  1020/ 1052, ite: 72580] train loss: 0.005333, tar: 0.000321 
[Epoch 276/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000111, l1: 0.000130, l2: 0.000099, l3: 0.000119, l4: 0.000243, l5: 0.000268, l6: 0.000516

[epoch: 277/1000, batch:    48/ 1052, ite: 72600] train loss: 0.005332, tar: 0.000321 
l0: 0.000337, l1: 0.000340, l2: 0.000387, l3: 0.000473, l4: 0.000922, l5: 0.001351, l6: 0.002730

[epoch: 277/1000, batch:   128/ 1052, ite: 72620] train loss: 0.005331, tar: 0.000321 
l0: 0.000351, l1: 0.000353, l2: 0.000399, l3: 0.000506, l4: 0.001221, l5: 0.002297, l6: 0.003398

[epoch: 277/1000, batch:   208/ 1052, ite: 72640] train loss: 0.005332, tar: 0.000321 
l0: 0.000195, l1: 0.000200, l2: 0.000249, l3: 0.000242, l4: 0.000496, l5: 0.001202, l6: 0.002203

[epoch: 277/1000, batch:   288/ 1052, ite: 72660] train loss: 0.005331, tar: 0.000321 
l0: 0.000457, l1: 0.000461, l2: 0.000488, l3: 0.000571, l4: 0.000966, l5: 0.002042, l6: 0.003645

[epoch: 277/1000, batch:   368/ 1052, ite: 72680] train loss: 0.005330, tar: 0.000321 
l0: 0.000161, l1: 0.000175, l2: 0.000163, l3: 0.000215, l4: 0.000540, l5: 0.000756, l6: 0.001253

[epoch: 277/1000, batch:   448/ 1052, ite: 72700] train loss: 0.005331, tar: 0.000321 
l0: 0.000567, l1: 0.000572, l2: 0.000649, l3: 0.000739, l4: 0.001113, l5: 0.001687, l6: 0.004044

[epoch: 277/1000, batch:   528/ 1052, ite: 72720] train loss: 0.005331, tar: 0.000321 
l0: 0.000427, l1: 0.000461, l2: 0.000450, l3: 0.000436, l4: 0.000833, l5: 0.001604, l6: 0.002872

[epoch: 277/1000, batch:   608/ 1052, ite: 72740] train loss: 0.005329, tar: 0.000321 
l0: 0.000722, l1: 0.000727, l2: 0.000743, l3: 0.000849, l4: 0.001069, l5: 0.001358, l6: 0.003500

[epoch: 277/1000, batch:   688/ 1052, ite: 72760] train loss: 0.005329, tar: 0.000321 
l0: 0.000333, l1: 0.000329, l2: 0.000376, l3: 0.000450, l4: 0.000681, l5: 0.001329, l6: 0.001713

[epoch: 277/1000, batch:   768/ 1052, ite: 72780] train loss: 0.005328, tar: 0.000321 
l0: 0.000331, l1: 0.000344, l2: 0.000324, l3: 0.000388, l4: 0.000630, l5: 0.001428, l6: 0.002523

[epoch: 277/1000, batch:   848/ 1052, ite: 72800] train loss: 0.005327, tar: 0.000321 
l0: 0.000173, l1: 0.000179, l2: 0.000207, l3: 0.000248, l4: 0.000456, l5: 0.000738, l6: 0.002232

[epoch: 277/1000, batch:   928/ 1052, ite: 72820] train loss: 0.005327, tar: 0.000321 
l0: 0.000158, l1: 0.000165, l2: 0.000196, l3: 0.000219, l4: 0.000428, l5: 0.000632, l6: 0.001448

[epoch: 277/1000, batch:  1008/ 1052, ite: 72840] train loss: 0.005326, tar: 0.000320 
[Epoch 277/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000190, l1: 0.000190, l2: 0.000213, l3: 0.000281, l4: 0.000411, l5: 0.001112, l6: 0.001593

[epoch: 278/1000, batch:    36/ 1052, ite: 72860] train loss: 0.005326, tar: 0.000320 
l0: 0.000325, l1: 0.000337, l2: 0.000371, l3: 0.000417, l4: 0.001024, l5: 0.001896, l6: 0.002009

[epoch: 278/1000, batch:   116/ 1052, ite: 72880] train loss: 0.005325, tar: 0.000320 
l0: 0.000601, l1: 0.000625, l2: 0.000634, l3: 0.000729, l4: 0.001056, l5: 0.001647, l6: 0.004724

[epoch: 278/1000, batch:   196/ 1052, ite: 72900] train loss: 0.005330, tar: 0.000321 
l0: 0.000331, l1: 0.000350, l2: 0.000308, l3: 0.000505, l4: 0.001067, l5: 0.001253, l6: 0.003252

[epoch: 278/1000, batch:   276/ 1052, ite: 72920] train loss: 0.005329, tar: 0.000321 
l0: 0.000225, l1: 0.000221, l2: 0.000258, l3: 0.000378, l4: 0.000570, l5: 0.001346, l6: 0.001979

[epoch: 278/1000, batch:   356/ 1052, ite: 72940] train loss: 0.005330, tar: 0.000321 
l0: 0.000301, l1: 0.000311, l2: 0.000299, l3: 0.000369, l4: 0.000578, l5: 0.001209, l6: 0.001669

[epoch: 278/1000, batch:   436/ 1052, ite: 72960] train loss: 0.005329, tar: 0.000321 
l0: 0.000208, l1: 0.000243, l2: 0.000174, l3: 0.000178, l4: 0.000516, l5: 0.000628, l6: 0.001066

[epoch: 278/1000, batch:   516/ 1052, ite: 72980] train loss: 0.005328, tar: 0.000321 
l0: 0.000304, l1: 0.000320, l2: 0.000309, l3: 0.000351, l4: 0.000470, l5: 0.000738, l6: 0.001338

[epoch: 278/1000, batch:   596/ 1052, ite: 73000] train loss: 0.005328, tar: 0.000321 
l0: 0.000445, l1: 0.000426, l2: 0.000444, l3: 0.000544, l4: 0.000730, l5: 0.001151, l6: 0.001781

[epoch: 278/1000, batch:   676/ 1052, ite: 73020] train loss: 0.005331, tar: 0.000321 
l0: 0.000381, l1: 0.000391, l2: 0.000473, l3: 0.000485, l4: 0.000666, l5: 0.001016, l6: 0.002162

[epoch: 278/1000, batch:   756/ 1052, ite: 73040] train loss: 0.005333, tar: 0.000322 
l0: 0.000262, l1: 0.000259, l2: 0.000279, l3: 0.000346, l4: 0.000521, l5: 0.001597, l6: 0.001890

[epoch: 278/1000, batch:   836/ 1052, ite: 73060] train loss: 0.005333, tar: 0.000322 
l0: 0.000388, l1: 0.000397, l2: 0.000373, l3: 0.000466, l4: 0.000558, l5: 0.001029, l6: 0.002744

[epoch: 278/1000, batch:   916/ 1052, ite: 73080] train loss: 0.005334, tar: 0.000322 
l0: 0.000377, l1: 0.000390, l2: 0.000353, l3: 0.000376, l4: 0.000595, l5: 0.000858, l6: 0.002223

[epoch: 278/1000, batch:   996/ 1052, ite: 73100] train loss: 0.005335, tar: 0.000322 
[Epoch 278/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000210, l1: 0.000204, l2: 0.000229, l3: 0.000336, l4: 0.000441, l5: 0.000759, l6: 0.001286

[epoch: 279/1000, batch:    24/ 1052, ite: 73120] train loss: 0.005334, tar: 0.000322 
l0: 0.000553, l1: 0.000540, l2: 0.000550, l3: 0.000752, l4: 0.000944, l5: 0.001501, l6: 0.002035

[epoch: 279/1000, batch:   104/ 1052, ite: 73140] train loss: 0.005334, tar: 0.000322 
l0: 0.000214, l1: 0.000203, l2: 0.000259, l3: 0.000323, l4: 0.000772, l5: 0.001129, l6: 0.002399

[epoch: 279/1000, batch:   184/ 1052, ite: 73160] train loss: 0.005333, tar: 0.000321 
l0: 0.000174, l1: 0.000170, l2: 0.000200, l3: 0.000279, l4: 0.000407, l5: 0.001158, l6: 0.001699

[epoch: 279/1000, batch:   264/ 1052, ite: 73180] train loss: 0.005332, tar: 0.000321 
l0: 0.000264, l1: 0.000276, l2: 0.000301, l3: 0.000312, l4: 0.000497, l5: 0.000751, l6: 0.001509

[epoch: 279/1000, batch:   344/ 1052, ite: 73200] train loss: 0.005331, tar: 0.000321 
l0: 0.000428, l1: 0.000423, l2: 0.000476, l3: 0.000572, l4: 0.000744, l5: 0.001499, l6: 0.002323

[epoch: 279/1000, batch:   424/ 1052, ite: 73220] train loss: 0.005331, tar: 0.000321 
l0: 0.000439, l1: 0.000455, l2: 0.000455, l3: 0.000564, l4: 0.000854, l5: 0.001774, l6: 0.003579

[epoch: 279/1000, batch:   504/ 1052, ite: 73240] train loss: 0.005331, tar: 0.000321 
l0: 0.000284, l1: 0.000284, l2: 0.000307, l3: 0.000367, l4: 0.000628, l5: 0.001164, l6: 0.001390

[epoch: 279/1000, batch:   584/ 1052, ite: 73260] train loss: 0.005330, tar: 0.000321 
l0: 0.000433, l1: 0.000445, l2: 0.000437, l3: 0.000515, l4: 0.000814, l5: 0.001449, l6: 0.003321

[epoch: 279/1000, batch:   664/ 1052, ite: 73280] train loss: 0.005328, tar: 0.000321 
l0: 0.000216, l1: 0.000224, l2: 0.000215, l3: 0.000281, l4: 0.000480, l5: 0.000819, l6: 0.000900

[epoch: 279/1000, batch:   744/ 1052, ite: 73300] train loss: 0.005328, tar: 0.000321 
l0: 0.000267, l1: 0.000278, l2: 0.000278, l3: 0.000386, l4: 0.000653, l5: 0.001129, l6: 0.002352

[epoch: 279/1000, batch:   824/ 1052, ite: 73320] train loss: 0.005328, tar: 0.000321 
l0: 0.000270, l1: 0.000274, l2: 0.000314, l3: 0.000361, l4: 0.000481, l5: 0.001221, l6: 0.002906

[epoch: 279/1000, batch:   904/ 1052, ite: 73340] train loss: 0.005328, tar: 0.000321 
l0: 0.000200, l1: 0.000200, l2: 0.000268, l3: 0.000314, l4: 0.000508, l5: 0.000930, l6: 0.001490

[epoch: 279/1000, batch:   984/ 1052, ite: 73360] train loss: 0.005328, tar: 0.000321 
[Epoch 279/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000400, l1: 0.000401, l2: 0.000428, l3: 0.000511, l4: 0.000680, l5: 0.001392, l6: 0.001838

[epoch: 280/1000, batch:    12/ 1052, ite: 73380] train loss: 0.005328, tar: 0.000321 
l0: 0.000246, l1: 0.000254, l2: 0.000252, l3: 0.000267, l4: 0.000454, l5: 0.001094, l6: 0.001184

[epoch: 280/1000, batch:    92/ 1052, ite: 73400] train loss: 0.005328, tar: 0.000321 
l0: 0.000298, l1: 0.000300, l2: 0.000366, l3: 0.000442, l4: 0.000631, l5: 0.001394, l6: 0.002037

[epoch: 280/1000, batch:   172/ 1052, ite: 73420] train loss: 0.005328, tar: 0.000321 
l0: 0.000206, l1: 0.000214, l2: 0.000193, l3: 0.000254, l4: 0.000352, l5: 0.000894, l6: 0.001351

[epoch: 280/1000, batch:   252/ 1052, ite: 73440] train loss: 0.005328, tar: 0.000320 
l0: 0.000366, l1: 0.000382, l2: 0.000427, l3: 0.000460, l4: 0.000704, l5: 0.001218, l6: 0.002782

[epoch: 280/1000, batch:   332/ 1052, ite: 73460] train loss: 0.005327, tar: 0.000320 
l0: 0.000361, l1: 0.000352, l2: 0.000393, l3: 0.000483, l4: 0.000720, l5: 0.001159, l6: 0.002488

[epoch: 280/1000, batch:   412/ 1052, ite: 73480] train loss: 0.005327, tar: 0.000320 
l0: 0.000208, l1: 0.000219, l2: 0.000252, l3: 0.000293, l4: 0.000502, l5: 0.001566, l6: 0.001595

[epoch: 280/1000, batch:   492/ 1052, ite: 73500] train loss: 0.005325, tar: 0.000320 
l0: 0.000282, l1: 0.000289, l2: 0.000309, l3: 0.000355, l4: 0.000627, l5: 0.001108, l6: 0.001927

[epoch: 280/1000, batch:   572/ 1052, ite: 73520] train loss: 0.005325, tar: 0.000320 
l0: 0.000254, l1: 0.000240, l2: 0.000329, l3: 0.000515, l4: 0.000635, l5: 0.001535, l6: 0.001658

[epoch: 280/1000, batch:   652/ 1052, ite: 73540] train loss: 0.005325, tar: 0.000320 
l0: 0.000227, l1: 0.000232, l2: 0.000275, l3: 0.000338, l4: 0.000455, l5: 0.001021, l6: 0.001662

[epoch: 280/1000, batch:   732/ 1052, ite: 73560] train loss: 0.005326, tar: 0.000320 
l0: 0.000292, l1: 0.000288, l2: 0.000283, l3: 0.000410, l4: 0.000661, l5: 0.001288, l6: 0.001510

[epoch: 280/1000, batch:   812/ 1052, ite: 73580] train loss: 0.005324, tar: 0.000320 
l0: 0.000138, l1: 0.000144, l2: 0.000165, l3: 0.000169, l4: 0.000295, l5: 0.000762, l6: 0.001151

[epoch: 280/1000, batch:   892/ 1052, ite: 73600] train loss: 0.005324, tar: 0.000320 
l0: 0.000387, l1: 0.000390, l2: 0.000404, l3: 0.000546, l4: 0.000927, l5: 0.002045, l6: 0.002238

[epoch: 280/1000, batch:   972/ 1052, ite: 73620] train loss: 0.005324, tar: 0.000320 
l0: 0.000212, l1: 0.000200, l2: 0.000239, l3: 0.000351, l4: 0.000478, l5: 0.000870, l6: 0.001288

[epoch: 280/1000, batch:  1052/ 1052, ite: 73640] train loss: 0.005324, tar: 0.000320 
[Epoch 280/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000397, l1: 0.000406, l2: 0.000417, l3: 0.000535, l4: 0.000875, l5: 0.001370, l6: 0.002097

[epoch: 281/1000, batch:    80/ 1052, ite: 73660] train loss: 0.005851, tar: 0.000328 
l0: 0.000234, l1: 0.000239, l2: 0.000259, l3: 0.000288, l4: 0.000570, l5: 0.001098, l6: 0.001792

[epoch: 281/1000, batch:   160/ 1052, ite: 73680] train loss: 0.005485, tar: 0.000306 
l0: 0.000551, l1: 0.000553, l2: 0.000633, l3: 0.000723, l4: 0.001421, l5: 0.002710, l6: 0.004475

[epoch: 281/1000, batch:   240/ 1052, ite: 73700] train loss: 0.005348, tar: 0.000301 
l0: 0.000433, l1: 0.000442, l2: 0.000425, l3: 0.000491, l4: 0.000813, l5: 0.001808, l6: 0.002970

[epoch: 281/1000, batch:   320/ 1052, ite: 73720] train loss: 0.005469, tar: 0.000302 
l0: 0.000083, l1: 0.000085, l2: 0.000086, l3: 0.000146, l4: 0.000179, l5: 0.000698, l6: 0.000606

[epoch: 281/1000, batch:   400/ 1052, ite: 73740] train loss: 0.005386, tar: 0.000299 
l0: 0.000255, l1: 0.000264, l2: 0.000300, l3: 0.000304, l4: 0.000656, l5: 0.001345, l6: 0.002415

[epoch: 281/1000, batch:   480/ 1052, ite: 73760] train loss: 0.005346, tar: 0.000293 
l0: 0.000245, l1: 0.000241, l2: 0.000253, l3: 0.000374, l4: 0.000620, l5: 0.001521, l6: 0.002688

[epoch: 281/1000, batch:   560/ 1052, ite: 73780] train loss: 0.005273, tar: 0.000291 
l0: 0.000278, l1: 0.000284, l2: 0.000309, l3: 0.000340, l4: 0.000573, l5: 0.000953, l6: 0.001993

[epoch: 281/1000, batch:   640/ 1052, ite: 73800] train loss: 0.005244, tar: 0.000287 
l0: 0.000318, l1: 0.000318, l2: 0.000367, l3: 0.000555, l4: 0.000904, l5: 0.001872, l6: 0.002653

[epoch: 281/1000, batch:   720/ 1052, ite: 73820] train loss: 0.005248, tar: 0.000289 
l0: 0.000206, l1: 0.000212, l2: 0.000262, l3: 0.000295, l4: 0.000583, l5: 0.001425, l6: 0.002086

[epoch: 281/1000, batch:   800/ 1052, ite: 73840] train loss: 0.005197, tar: 0.000286 
l0: 0.000238, l1: 0.000240, l2: 0.000275, l3: 0.000307, l4: 0.000526, l5: 0.001023, l6: 0.001732

[epoch: 281/1000, batch:   880/ 1052, ite: 73860] train loss: 0.005223, tar: 0.000286 
l0: 0.000355, l1: 0.000370, l2: 0.000393, l3: 0.000481, l4: 0.000761, l5: 0.001375, l6: 0.001676

[epoch: 281/1000, batch:   960/ 1052, ite: 73880] train loss: 0.005193, tar: 0.000283 
l0: 0.000238, l1: 0.000228, l2: 0.000288, l3: 0.000390, l4: 0.000690, l5: 0.000779, l6: 0.002243

[epoch: 281/1000, batch:  1040/ 1052, ite: 73900] train loss: 0.005146, tar: 0.000281 
[Epoch 281/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000240, l1: 0.000251, l2: 0.000254, l3: 0.000259, l4: 0.000449, l5: 0.001206, l6: 0.001950

[epoch: 282/1000, batch:    68/ 1052, ite: 73920] train loss: 0.005133, tar: 0.000281 
l0: 0.000258, l1: 0.000253, l2: 0.000295, l3: 0.000410, l4: 0.000659, l5: 0.001494, l6: 0.001779

[epoch: 282/1000, batch:   148/ 1052, ite: 73940] train loss: 0.005181, tar: 0.000285 
l0: 0.000518, l1: 0.000537, l2: 0.000522, l3: 0.000551, l4: 0.000595, l5: 0.001186, l6: 0.001518

[epoch: 282/1000, batch:   228/ 1052, ite: 73960] train loss: 0.005133, tar: 0.000282 
l0: 0.000258, l1: 0.000275, l2: 0.000260, l3: 0.000326, l4: 0.000461, l5: 0.000922, l6: 0.002032

[epoch: 282/1000, batch:   308/ 1052, ite: 73980] train loss: 0.005132, tar: 0.000282 
l0: 0.000287, l1: 0.000296, l2: 0.000347, l3: 0.000400, l4: 0.000975, l5: 0.002060, l6: 0.002842

[epoch: 282/1000, batch:   388/ 1052, ite: 74000] train loss: 0.005120, tar: 0.000280 
l0: 0.000144, l1: 0.000150, l2: 0.000150, l3: 0.000187, l4: 0.000364, l5: 0.000769, l6: 0.001195

[epoch: 282/1000, batch:   468/ 1052, ite: 74020] train loss: 0.005091, tar: 0.000278 
l0: 0.000160, l1: 0.000166, l2: 0.000180, l3: 0.000245, l4: 0.000445, l5: 0.000633, l6: 0.001200

[epoch: 282/1000, batch:   548/ 1052, ite: 74040] train loss: 0.005090, tar: 0.000277 
l0: 0.000234, l1: 0.000246, l2: 0.000242, l3: 0.000262, l4: 0.000438, l5: 0.001290, l6: 0.002455

[epoch: 282/1000, batch:   628/ 1052, ite: 74060] train loss: 0.005105, tar: 0.000278 
l0: 0.000198, l1: 0.000185, l2: 0.000235, l3: 0.000343, l4: 0.000501, l5: 0.001249, l6: 0.001585

[epoch: 282/1000, batch:   708/ 1052, ite: 74080] train loss: 0.005111, tar: 0.000278 
l0: 0.000305, l1: 0.000296, l2: 0.000364, l3: 0.000396, l4: 0.000534, l5: 0.001115, l6: 0.002072

[epoch: 282/1000, batch:   788/ 1052, ite: 74100] train loss: 0.005120, tar: 0.000280 
l0: 0.000204, l1: 0.000205, l2: 0.000207, l3: 0.000313, l4: 0.000389, l5: 0.001121, l6: 0.001503

[epoch: 282/1000, batch:   868/ 1052, ite: 74120] train loss: 0.005114, tar: 0.000280 
l0: 0.000121, l1: 0.000119, l2: 0.000141, l3: 0.000239, l4: 0.000281, l5: 0.000536, l6: 0.000996

[epoch: 282/1000, batch:   948/ 1052, ite: 74140] train loss: 0.005102, tar: 0.000280 
l0: 0.000385, l1: 0.000385, l2: 0.000462, l3: 0.000655, l4: 0.001320, l5: 0.001960, l6: 0.002564

[epoch: 282/1000, batch:  1028/ 1052, ite: 74160] train loss: 0.005113, tar: 0.000280 
[Epoch 282/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000173, l1: 0.000173, l2: 0.000194, l3: 0.000308, l4: 0.000552, l5: 0.001049, l6: 0.001794

[epoch: 283/1000, batch:    56/ 1052, ite: 74180] train loss: 0.005105, tar: 0.000280 
l0: 0.000165, l1: 0.000173, l2: 0.000202, l3: 0.000189, l4: 0.000367, l5: 0.000627, l6: 0.002259

[epoch: 283/1000, batch:   136/ 1052, ite: 74200] train loss: 0.005073, tar: 0.000278 
l0: 0.000192, l1: 0.000196, l2: 0.000254, l3: 0.000271, l4: 0.000478, l5: 0.000946, l6: 0.001542

[epoch: 283/1000, batch:   216/ 1052, ite: 74220] train loss: 0.005081, tar: 0.000278 
l0: 0.000239, l1: 0.000244, l2: 0.000233, l3: 0.000255, l4: 0.000370, l5: 0.000581, l6: 0.001033

[epoch: 283/1000, batch:   296/ 1052, ite: 74240] train loss: 0.005088, tar: 0.000278 
l0: 0.000150, l1: 0.000158, l2: 0.000161, l3: 0.000201, l4: 0.000266, l5: 0.000840, l6: 0.001479

[epoch: 283/1000, batch:   376/ 1052, ite: 74260] train loss: 0.005078, tar: 0.000278 
l0: 0.000347, l1: 0.000363, l2: 0.000327, l3: 0.000451, l4: 0.000665, l5: 0.001115, l6: 0.001669

[epoch: 283/1000, batch:   456/ 1052, ite: 74280] train loss: 0.005093, tar: 0.000279 
l0: 0.000257, l1: 0.000263, l2: 0.000276, l3: 0.000322, l4: 0.000591, l5: 0.001129, l6: 0.001399

[epoch: 283/1000, batch:   536/ 1052, ite: 74300] train loss: 0.005085, tar: 0.000278 
l0: 0.000170, l1: 0.000173, l2: 0.000198, l3: 0.000239, l4: 0.000565, l5: 0.001203, l6: 0.002053

[epoch: 283/1000, batch:   616/ 1052, ite: 74320] train loss: 0.005086, tar: 0.000278 
l0: 0.000301, l1: 0.000306, l2: 0.000341, l3: 0.000310, l4: 0.000583, l5: 0.000691, l6: 0.001961

[epoch: 283/1000, batch:   696/ 1052, ite: 74340] train loss: 0.005072, tar: 0.000278 
l0: 0.000338, l1: 0.000349, l2: 0.000312, l3: 0.000312, l4: 0.000486, l5: 0.001039, l6: 0.001614

[epoch: 283/1000, batch:   776/ 1052, ite: 74360] train loss: 0.005078, tar: 0.000279 
l0: 0.000240, l1: 0.000262, l2: 0.000259, l3: 0.000304, l4: 0.000537, l5: 0.001039, l6: 0.001877

[epoch: 283/1000, batch:   856/ 1052, ite: 74380] train loss: 0.005092, tar: 0.000280 
l0: 0.000219, l1: 0.000222, l2: 0.000221, l3: 0.000333, l4: 0.000429, l5: 0.000699, l6: 0.001954

[epoch: 283/1000, batch:   936/ 1052, ite: 74400] train loss: 0.005116, tar: 0.000282 
l0: 0.000143, l1: 0.000148, l2: 0.000161, l3: 0.000211, l4: 0.000288, l5: 0.000950, l6: 0.000781

[epoch: 283/1000, batch:  1016/ 1052, ite: 74420] train loss: 0.005117, tar: 0.000282 
[Epoch 283/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000344, l1: 0.000345, l2: 0.000371, l3: 0.000407, l4: 0.000898, l5: 0.001337, l6: 0.001988

[epoch: 284/1000, batch:    44/ 1052, ite: 74440] train loss: 0.005129, tar: 0.000282 
l0: 0.000115, l1: 0.000110, l2: 0.000160, l3: 0.000227, l4: 0.000440, l5: 0.000867, l6: 0.001532

[epoch: 284/1000, batch:   124/ 1052, ite: 74460] train loss: 0.005131, tar: 0.000283 
l0: 0.000223, l1: 0.000213, l2: 0.000321, l3: 0.000402, l4: 0.000728, l5: 0.001527, l6: 0.001737

[epoch: 284/1000, batch:   204/ 1052, ite: 74480] train loss: 0.005134, tar: 0.000283 
l0: 0.000284, l1: 0.000294, l2: 0.000297, l3: 0.000329, l4: 0.000473, l5: 0.001038, l6: 0.001883

[epoch: 284/1000, batch:   284/ 1052, ite: 74500] train loss: 0.005136, tar: 0.000283 
l0: 0.000229, l1: 0.000235, l2: 0.000246, l3: 0.000268, l4: 0.000445, l5: 0.000888, l6: 0.001096

[epoch: 284/1000, batch:   364/ 1052, ite: 74520] train loss: 0.005134, tar: 0.000283 
l0: 0.000262, l1: 0.000261, l2: 0.000293, l3: 0.000375, l4: 0.000487, l5: 0.000935, l6: 0.001312

[epoch: 284/1000, batch:   444/ 1052, ite: 74540] train loss: 0.005138, tar: 0.000283 
l0: 0.000446, l1: 0.000472, l2: 0.000529, l3: 0.000574, l4: 0.000981, l5: 0.001976, l6: 0.003566

[epoch: 284/1000, batch:   524/ 1052, ite: 74560] train loss: 0.005147, tar: 0.000284 
l0: 0.000157, l1: 0.000165, l2: 0.000160, l3: 0.000189, l4: 0.000350, l5: 0.001041, l6: 0.001917

[epoch: 284/1000, batch:   604/ 1052, ite: 74580] train loss: 0.005139, tar: 0.000283 
l0: 0.000536, l1: 0.000559, l2: 0.000538, l3: 0.000617, l4: 0.000908, l5: 0.002007, l6: 0.004563

[epoch: 284/1000, batch:   684/ 1052, ite: 74600] train loss: 0.005143, tar: 0.000283 
l0: 0.000437, l1: 0.000435, l2: 0.000447, l3: 0.000593, l4: 0.000927, l5: 0.001492, l6: 0.003200

[epoch: 284/1000, batch:   764/ 1052, ite: 74620] train loss: 0.005141, tar: 0.000283 
l0: 0.000160, l1: 0.000152, l2: 0.000202, l3: 0.000309, l4: 0.000485, l5: 0.001041, l6: 0.001724

[epoch: 284/1000, batch:   844/ 1052, ite: 74640] train loss: 0.005130, tar: 0.000282 
l0: 0.000159, l1: 0.000170, l2: 0.000157, l3: 0.000209, l4: 0.000280, l5: 0.000772, l6: 0.001000

[epoch: 284/1000, batch:   924/ 1052, ite: 74660] train loss: 0.005124, tar: 0.000282 
l0: 0.000386, l1: 0.000397, l2: 0.000404, l3: 0.000423, l4: 0.000632, l5: 0.000968, l6: 0.001645

[epoch: 284/1000, batch:  1004/ 1052, ite: 74680] train loss: 0.005117, tar: 0.000281 
[Epoch 284/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000175, l1: 0.000186, l2: 0.000183, l3: 0.000212, l4: 0.000559, l5: 0.001133, l6: 0.001281

[epoch: 285/1000, batch:    32/ 1052, ite: 74700] train loss: 0.005128, tar: 0.000282 
l0: 0.000130, l1: 0.000124, l2: 0.000179, l3: 0.000271, l4: 0.000348, l5: 0.001011, l6: 0.001541

[epoch: 285/1000, batch:   112/ 1052, ite: 74720] train loss: 0.005119, tar: 0.000281 
l0: 0.000308, l1: 0.000305, l2: 0.000364, l3: 0.000546, l4: 0.001111, l5: 0.001695, l6: 0.003678

[epoch: 285/1000, batch:   192/ 1052, ite: 74740] train loss: 0.005113, tar: 0.000281 
l0: 0.000481, l1: 0.000483, l2: 0.000459, l3: 0.000577, l4: 0.000932, l5: 0.001392, l6: 0.002326

[epoch: 285/1000, batch:   272/ 1052, ite: 74760] train loss: 0.005112, tar: 0.000280 
l0: 0.000213, l1: 0.000203, l2: 0.000257, l3: 0.000322, l4: 0.000565, l5: 0.001311, l6: 0.001726

[epoch: 285/1000, batch:   352/ 1052, ite: 74780] train loss: 0.005116, tar: 0.000280 
l0: 0.000246, l1: 0.000244, l2: 0.000290, l3: 0.000384, l4: 0.000740, l5: 0.001219, l6: 0.003389

[epoch: 285/1000, batch:   432/ 1052, ite: 74800] train loss: 0.005114, tar: 0.000280 
l0: 0.000215, l1: 0.000222, l2: 0.000244, l3: 0.000335, l4: 0.000663, l5: 0.001353, l6: 0.002198

[epoch: 285/1000, batch:   512/ 1052, ite: 74820] train loss: 0.005108, tar: 0.000279 
l0: 0.000186, l1: 0.000181, l2: 0.000240, l3: 0.000281, l4: 0.000483, l5: 0.000978, l6: 0.001264

[epoch: 285/1000, batch:   592/ 1052, ite: 74840] train loss: 0.005102, tar: 0.000280 
l0: 0.000412, l1: 0.000417, l2: 0.000441, l3: 0.000498, l4: 0.000627, l5: 0.001737, l6: 0.003082

[epoch: 285/1000, batch:   672/ 1052, ite: 74860] train loss: 0.005113, tar: 0.000280 
l0: 0.000180, l1: 0.000186, l2: 0.000204, l3: 0.000232, l4: 0.000332, l5: 0.001032, l6: 0.001727

[epoch: 285/1000, batch:   752/ 1052, ite: 74880] train loss: 0.005122, tar: 0.000281 
l0: 0.000156, l1: 0.000159, l2: 0.000188, l3: 0.000234, l4: 0.000423, l5: 0.001243, l6: 0.001521

[epoch: 285/1000, batch:   832/ 1052, ite: 74900] train loss: 0.005117, tar: 0.000280 
l0: 0.000249, l1: 0.000235, l2: 0.000324, l3: 0.000481, l4: 0.000858, l5: 0.001467, l6: 0.001852

[epoch: 285/1000, batch:   912/ 1052, ite: 74920] train loss: 0.005118, tar: 0.000280 
l0: 0.000406, l1: 0.000410, l2: 0.000446, l3: 0.000499, l4: 0.000898, l5: 0.001544, l6: 0.003146

[epoch: 285/1000, batch:   992/ 1052, ite: 74940] train loss: 0.005112, tar: 0.000280 
[Epoch 285/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000484, l1: 0.000500, l2: 0.000520, l3: 0.000616, l4: 0.001006, l5: 0.001361, l6: 0.003391

[epoch: 286/1000, batch:    20/ 1052, ite: 74960] train loss: 0.005111, tar: 0.000279 
l0: 0.000535, l1: 0.000565, l2: 0.000579, l3: 0.000679, l4: 0.001356, l5: 0.002680, l6: 0.003554

[epoch: 286/1000, batch:   100/ 1052, ite: 74980] train loss: 0.005114, tar: 0.000280 
l0: 0.000100, l1: 0.000103, l2: 0.000117, l3: 0.000136, l4: 0.000284, l5: 0.000638, l6: 0.001100

[epoch: 286/1000, batch:   180/ 1052, ite: 75000] train loss: 0.005106, tar: 0.000279 
l0: 0.000179, l1: 0.000174, l2: 0.000232, l3: 0.000242, l4: 0.000416, l5: 0.000659, l6: 0.001251

[epoch: 286/1000, batch:   260/ 1052, ite: 75020] train loss: 0.005111, tar: 0.000279 
l0: 0.000214, l1: 0.000223, l2: 0.000214, l3: 0.000258, l4: 0.000428, l5: 0.000919, l6: 0.001428

[epoch: 286/1000, batch:   340/ 1052, ite: 75040] train loss: 0.005105, tar: 0.000279 
l0: 0.000186, l1: 0.000192, l2: 0.000216, l3: 0.000199, l4: 0.000494, l5: 0.001091, l6: 0.001421

[epoch: 286/1000, batch:   420/ 1052, ite: 75060] train loss: 0.005102, tar: 0.000279 
l0: 0.000235, l1: 0.000241, l2: 0.000288, l3: 0.000362, l4: 0.000814, l5: 0.001659, l6: 0.002174

[epoch: 286/1000, batch:   500/ 1052, ite: 75080] train loss: 0.005101, tar: 0.000279 
l0: 0.000330, l1: 0.000345, l2: 0.000334, l3: 0.000444, l4: 0.000621, l5: 0.001269, l6: 0.002372

[epoch: 286/1000, batch:   580/ 1052, ite: 75100] train loss: 0.005100, tar: 0.000278 
l0: 0.000333, l1: 0.000325, l2: 0.000370, l3: 0.000525, l4: 0.000866, l5: 0.001721, l6: 0.002402

[epoch: 286/1000, batch:   660/ 1052, ite: 75120] train loss: 0.005095, tar: 0.000278 
l0: 0.000533, l1: 0.000530, l2: 0.000603, l3: 0.000831, l4: 0.001585, l5: 0.002577, l6: 0.003820

[epoch: 286/1000, batch:   740/ 1052, ite: 75140] train loss: 0.005099, tar: 0.000278 
l0: 0.000183, l1: 0.000186, l2: 0.000212, l3: 0.000239, l4: 0.000525, l5: 0.000976, l6: 0.001382

[epoch: 286/1000, batch:   820/ 1052, ite: 75160] train loss: 0.005098, tar: 0.000278 
l0: 0.000203, l1: 0.000215, l2: 0.000197, l3: 0.000221, l4: 0.000340, l5: 0.000806, l6: 0.001614

[epoch: 286/1000, batch:   900/ 1052, ite: 75180] train loss: 0.005096, tar: 0.000278 
l0: 0.000329, l1: 0.000341, l2: 0.000353, l3: 0.000409, l4: 0.000606, l5: 0.000964, l6: 0.002244

[epoch: 286/1000, batch:   980/ 1052, ite: 75200] train loss: 0.005098, tar: 0.000278 
[Epoch 286/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000303, l1: 0.000312, l2: 0.000341, l3: 0.000346, l4: 0.000504, l5: 0.001255, l6: 0.001805

[epoch: 287/1000, batch:     8/ 1052, ite: 75220] train loss: 0.005091, tar: 0.000277 
l0: 0.000233, l1: 0.000228, l2: 0.000268, l3: 0.000336, l4: 0.000477, l5: 0.001272, l6: 0.002541

[epoch: 287/1000, batch:    88/ 1052, ite: 75240] train loss: 0.005093, tar: 0.000277 
l0: 0.000113, l1: 0.000116, l2: 0.000128, l3: 0.000179, l4: 0.000256, l5: 0.000731, l6: 0.001025

[epoch: 287/1000, batch:   168/ 1052, ite: 75260] train loss: 0.005096, tar: 0.000278 
l0: 0.000171, l1: 0.000163, l2: 0.000225, l3: 0.000383, l4: 0.000505, l5: 0.000849, l6: 0.001534

[epoch: 287/1000, batch:   248/ 1052, ite: 75280] train loss: 0.005087, tar: 0.000277 
l0: 0.000233, l1: 0.000247, l2: 0.000257, l3: 0.000325, l4: 0.000508, l5: 0.001074, l6: 0.001984

[epoch: 287/1000, batch:   328/ 1052, ite: 75300] train loss: 0.005083, tar: 0.000277 
l0: 0.000116, l1: 0.000112, l2: 0.000162, l3: 0.000244, l4: 0.000415, l5: 0.001068, l6: 0.001248

[epoch: 287/1000, batch:   408/ 1052, ite: 75320] train loss: 0.005081, tar: 0.000277 
l0: 0.000227, l1: 0.000232, l2: 0.000246, l3: 0.000330, l4: 0.000485, l5: 0.001414, l6: 0.003077

[epoch: 287/1000, batch:   488/ 1052, ite: 75340] train loss: 0.005085, tar: 0.000277 
l0: 0.000122, l1: 0.000121, l2: 0.000145, l3: 0.000222, l4: 0.000514, l5: 0.000857, l6: 0.001270

[epoch: 287/1000, batch:   568/ 1052, ite: 75360] train loss: 0.005087, tar: 0.000277 
l0: 0.000164, l1: 0.000163, l2: 0.000192, l3: 0.000260, l4: 0.000554, l5: 0.000958, l6: 0.001541

[epoch: 287/1000, batch:   648/ 1052, ite: 75380] train loss: 0.005086, tar: 0.000277 
l0: 0.000290, l1: 0.000286, l2: 0.000296, l3: 0.000349, l4: 0.000528, l5: 0.000771, l6: 0.001266

[epoch: 287/1000, batch:   728/ 1052, ite: 75400] train loss: 0.005092, tar: 0.000277 
l0: 0.000181, l1: 0.000178, l2: 0.000204, l3: 0.000254, l4: 0.000496, l5: 0.000721, l6: 0.001180

[epoch: 287/1000, batch:   808/ 1052, ite: 75420] train loss: 0.005093, tar: 0.000277 
l0: 0.000214, l1: 0.000214, l2: 0.000231, l3: 0.000310, l4: 0.000391, l5: 0.000822, l6: 0.001661

[epoch: 287/1000, batch:   888/ 1052, ite: 75440] train loss: 0.005087, tar: 0.000277 
l0: 0.000251, l1: 0.000264, l2: 0.000225, l3: 0.000254, l4: 0.000411, l5: 0.001137, l6: 0.001667

[epoch: 287/1000, batch:   968/ 1052, ite: 75460] train loss: 0.005087, tar: 0.000277 
l0: 0.000492, l1: 0.000490, l2: 0.000509, l3: 0.000643, l4: 0.000850, l5: 0.001685, l6: 0.002022

[epoch: 287/1000, batch:  1048/ 1052, ite: 75480] train loss: 0.005088, tar: 0.000277 
[Epoch 287/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000198, l1: 0.000200, l2: 0.000216, l3: 0.000257, l4: 0.000435, l5: 0.000787, l6: 0.001473

[epoch: 288/1000, batch:    76/ 1052, ite: 75500] train loss: 0.005085, tar: 0.000276 
l0: 0.000202, l1: 0.000210, l2: 0.000218, l3: 0.000248, l4: 0.000446, l5: 0.000738, l6: 0.001261

[epoch: 288/1000, batch:   156/ 1052, ite: 75520] train loss: 0.005080, tar: 0.000276 
l0: 0.000140, l1: 0.000135, l2: 0.000165, l3: 0.000233, l4: 0.000402, l5: 0.001022, l6: 0.001585

[epoch: 288/1000, batch:   236/ 1052, ite: 75540] train loss: 0.005079, tar: 0.000276 
l0: 0.000101, l1: 0.000102, l2: 0.000116, l3: 0.000150, l4: 0.000353, l5: 0.000642, l6: 0.001213

[epoch: 288/1000, batch:   316/ 1052, ite: 75560] train loss: 0.005075, tar: 0.000276 
l0: 0.000227, l1: 0.000226, l2: 0.000255, l3: 0.000341, l4: 0.000610, l5: 0.000888, l6: 0.002644

[epoch: 288/1000, batch:   396/ 1052, ite: 75580] train loss: 0.005069, tar: 0.000275 
l0: 0.000378, l1: 0.000386, l2: 0.000376, l3: 0.000488, l4: 0.000836, l5: 0.001575, l6: 0.003056

[epoch: 288/1000, batch:   476/ 1052, ite: 75600] train loss: 0.005073, tar: 0.000276 
l0: 0.000292, l1: 0.000292, l2: 0.000331, l3: 0.000357, l4: 0.000542, l5: 0.000997, l6: 0.001588

[epoch: 288/1000, batch:   556/ 1052, ite: 75620] train loss: 0.005068, tar: 0.000275 
l0: 0.000194, l1: 0.000198, l2: 0.000214, l3: 0.000304, l4: 0.000741, l5: 0.001179, l6: 0.001751

[epoch: 288/1000, batch:   636/ 1052, ite: 75640] train loss: 0.005070, tar: 0.000275 
l0: 0.000190, l1: 0.000188, l2: 0.000208, l3: 0.000338, l4: 0.000544, l5: 0.000774, l6: 0.001523

[epoch: 288/1000, batch:   716/ 1052, ite: 75660] train loss: 0.005067, tar: 0.000275 
l0: 0.000200, l1: 0.000206, l2: 0.000221, l3: 0.000301, l4: 0.000629, l5: 0.000878, l6: 0.002388

[epoch: 288/1000, batch:   796/ 1052, ite: 75680] train loss: 0.005075, tar: 0.000275 
l0: 0.000300, l1: 0.000302, l2: 0.000336, l3: 0.000398, l4: 0.000712, l5: 0.001368, l6: 0.002422

[epoch: 288/1000, batch:   876/ 1052, ite: 75700] train loss: 0.005077, tar: 0.000276 
l0: 0.000274, l1: 0.000271, l2: 0.000298, l3: 0.000349, l4: 0.000394, l5: 0.000830, l6: 0.001876

[epoch: 288/1000, batch:   956/ 1052, ite: 75720] train loss: 0.005077, tar: 0.000276 
l0: 0.000126, l1: 0.000123, l2: 0.000136, l3: 0.000199, l4: 0.000201, l5: 0.000761, l6: 0.001264

[epoch: 288/1000, batch:  1036/ 1052, ite: 75740] train loss: 0.005076, tar: 0.000276 
[Epoch 288/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000486, l1: 0.000495, l2: 0.000585, l3: 0.000630, l4: 0.000868, l5: 0.002068, l6: 0.004296

[epoch: 289/1000, batch:    64/ 1052, ite: 75760] train loss: 0.005075, tar: 0.000276 
l0: 0.000444, l1: 0.000439, l2: 0.000489, l3: 0.000579, l4: 0.000883, l5: 0.001420, l6: 0.002558

[epoch: 289/1000, batch:   144/ 1052, ite: 75780] train loss: 0.005076, tar: 0.000276 
l0: 0.000182, l1: 0.000182, l2: 0.000215, l3: 0.000257, l4: 0.000407, l5: 0.000981, l6: 0.001407

[epoch: 289/1000, batch:   224/ 1052, ite: 75800] train loss: 0.005073, tar: 0.000275 
l0: 0.000171, l1: 0.000169, l2: 0.000207, l3: 0.000237, l4: 0.000463, l5: 0.001036, l6: 0.001569

[epoch: 289/1000, batch:   304/ 1052, ite: 75820] train loss: 0.005075, tar: 0.000275 
l0: 0.000501, l1: 0.000484, l2: 0.000498, l3: 0.000719, l4: 0.001172, l5: 0.002104, l6: 0.003231

[epoch: 289/1000, batch:   384/ 1052, ite: 75840] train loss: 0.005080, tar: 0.000275 
l0: 0.000271, l1: 0.000283, l2: 0.000275, l3: 0.000352, l4: 0.000743, l5: 0.001855, l6: 0.002297

[epoch: 289/1000, batch:   464/ 1052, ite: 75860] train loss: 0.005080, tar: 0.000275 
l0: 0.000279, l1: 0.000282, l2: 0.000319, l3: 0.000351, l4: 0.000695, l5: 0.001267, l6: 0.001931

[epoch: 289/1000, batch:   544/ 1052, ite: 75880] train loss: 0.005078, tar: 0.000275 
l0: 0.000180, l1: 0.000178, l2: 0.000220, l3: 0.000257, l4: 0.000315, l5: 0.000831, l6: 0.001400

[epoch: 289/1000, batch:   624/ 1052, ite: 75900] train loss: 0.005081, tar: 0.000275 
l0: 0.000461, l1: 0.000453, l2: 0.000521, l3: 0.000578, l4: 0.000824, l5: 0.001347, l6: 0.002515

[epoch: 289/1000, batch:   704/ 1052, ite: 75920] train loss: 0.005078, tar: 0.000275 
l0: 0.000238, l1: 0.000236, l2: 0.000276, l3: 0.000371, l4: 0.000619, l5: 0.000984, l6: 0.002216

[epoch: 289/1000, batch:   784/ 1052, ite: 75940] train loss: 0.005075, tar: 0.000275 
l0: 0.000241, l1: 0.000246, l2: 0.000260, l3: 0.000334, l4: 0.000588, l5: 0.001401, l6: 0.001644

[epoch: 289/1000, batch:   864/ 1052, ite: 75960] train loss: 0.005079, tar: 0.000275 
l0: 0.000249, l1: 0.000246, l2: 0.000263, l3: 0.000359, l4: 0.000576, l5: 0.000957, l6: 0.001588

[epoch: 289/1000, batch:   944/ 1052, ite: 75980] train loss: 0.005076, tar: 0.000275 
l0: 0.000124, l1: 0.000119, l2: 0.000178, l3: 0.000230, l4: 0.000359, l5: 0.000704, l6: 0.000802

[epoch: 289/1000, batch:  1024/ 1052, ite: 76000] train loss: 0.005077, tar: 0.000275 
[Epoch 289/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000278, l1: 0.000282, l2: 0.000305, l3: 0.000373, l4: 0.000604, l5: 0.001074, l6: 0.002261

[epoch: 290/1000, batch:    52/ 1052, ite: 76020] train loss: 0.005074, tar: 0.000275 
l0: 0.000475, l1: 0.000472, l2: 0.000486, l3: 0.000552, l4: 0.000900, l5: 0.002120, l6: 0.003378

[epoch: 290/1000, batch:   132/ 1052, ite: 76040] train loss: 0.005075, tar: 0.000275 
l0: 0.000276, l1: 0.000283, l2: 0.000335, l3: 0.000394, l4: 0.000623, l5: 0.001152, l6: 0.002284

[epoch: 290/1000, batch:   212/ 1052, ite: 76060] train loss: 0.005069, tar: 0.000275 
l0: 0.000339, l1: 0.000347, l2: 0.000396, l3: 0.000375, l4: 0.000701, l5: 0.000958, l6: 0.002604

[epoch: 290/1000, batch:   292/ 1052, ite: 76080] train loss: 0.005070, tar: 0.000274 
l0: 0.000188, l1: 0.000190, l2: 0.000232, l3: 0.000363, l4: 0.000824, l5: 0.001527, l6: 0.002092

[epoch: 290/1000, batch:   372/ 1052, ite: 76100] train loss: 0.005066, tar: 0.000274 
l0: 0.000254, l1: 0.000269, l2: 0.000258, l3: 0.000334, l4: 0.000488, l5: 0.001223, l6: 0.002287

[epoch: 290/1000, batch:   452/ 1052, ite: 76120] train loss: 0.005067, tar: 0.000274 
l0: 0.000385, l1: 0.000384, l2: 0.000419, l3: 0.000522, l4: 0.000908, l5: 0.001131, l6: 0.002206

[epoch: 290/1000, batch:   532/ 1052, ite: 76140] train loss: 0.005061, tar: 0.000274 
l0: 0.000204, l1: 0.000216, l2: 0.000210, l3: 0.000353, l4: 0.000585, l5: 0.000777, l6: 0.001487

[epoch: 290/1000, batch:   612/ 1052, ite: 76160] train loss: 0.005060, tar: 0.000274 
l0: 0.000486, l1: 0.000496, l2: 0.000517, l3: 0.000543, l4: 0.000811, l5: 0.001529, l6: 0.003493

[epoch: 290/1000, batch:   692/ 1052, ite: 76180] train loss: 0.005062, tar: 0.000274 
l0: 0.000184, l1: 0.000181, l2: 0.000199, l3: 0.000219, l4: 0.000412, l5: 0.000946, l6: 0.001369

[epoch: 290/1000, batch:   772/ 1052, ite: 76200] train loss: 0.005064, tar: 0.000274 
l0: 0.000185, l1: 0.000186, l2: 0.000206, l3: 0.000258, l4: 0.000493, l5: 0.000604, l6: 0.001326

[epoch: 290/1000, batch:   852/ 1052, ite: 76220] train loss: 0.005065, tar: 0.000274 
l0: 0.000285, l1: 0.000295, l2: 0.000311, l3: 0.000355, l4: 0.000514, l5: 0.001109, l6: 0.002664

[epoch: 290/1000, batch:   932/ 1052, ite: 76240] train loss: 0.005067, tar: 0.000274 
l0: 0.000307, l1: 0.000309, l2: 0.000349, l3: 0.000481, l4: 0.000952, l5: 0.001064, l6: 0.002395

[epoch: 290/1000, batch:  1012/ 1052, ite: 76260] train loss: 0.005073, tar: 0.000274 
[Epoch 290/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000187, l1: 0.000188, l2: 0.000224, l3: 0.000306, l4: 0.000645, l5: 0.001185, l6: 0.002416

[epoch: 291/1000, batch:    40/ 1052, ite: 76280] train loss: 0.005073, tar: 0.000274 
l0: 0.000105, l1: 0.000111, l2: 0.000128, l3: 0.000175, l4: 0.000401, l5: 0.000714, l6: 0.000953

[epoch: 291/1000, batch:   120/ 1052, ite: 76300] train loss: 0.005073, tar: 0.000274 
l0: 0.000423, l1: 0.000430, l2: 0.000476, l3: 0.000428, l4: 0.000727, l5: 0.001363, l6: 0.001767

[epoch: 291/1000, batch:   200/ 1052, ite: 76320] train loss: 0.005073, tar: 0.000274 
l0: 0.000171, l1: 0.000172, l2: 0.000185, l3: 0.000247, l4: 0.000612, l5: 0.000971, l6: 0.001815

[epoch: 291/1000, batch:   280/ 1052, ite: 76340] train loss: 0.005071, tar: 0.000274 
l0: 0.000124, l1: 0.000129, l2: 0.000153, l3: 0.000188, l4: 0.000354, l5: 0.000801, l6: 0.001807

[epoch: 291/1000, batch:   360/ 1052, ite: 76360] train loss: 0.005070, tar: 0.000274 
l0: 0.000347, l1: 0.000350, l2: 0.000364, l3: 0.000418, l4: 0.000845, l5: 0.001768, l6: 0.002761

[epoch: 291/1000, batch:   440/ 1052, ite: 76380] train loss: 0.005070, tar: 0.000274 
l0: 0.000221, l1: 0.000210, l2: 0.000271, l3: 0.000391, l4: 0.000621, l5: 0.000965, l6: 0.002067

[epoch: 291/1000, batch:   520/ 1052, ite: 76400] train loss: 0.005071, tar: 0.000273 
l0: 0.000883, l1: 0.000912, l2: 0.000886, l3: 0.000911, l4: 0.001371, l5: 0.001978, l6: 0.004077

[epoch: 291/1000, batch:   600/ 1052, ite: 76420] train loss: 0.005074, tar: 0.000274 
l0: 0.000252, l1: 0.000263, l2: 0.000292, l3: 0.000340, l4: 0.000558, l5: 0.001484, l6: 0.002121

[epoch: 291/1000, batch:   680/ 1052, ite: 76440] train loss: 0.005074, tar: 0.000274 
l0: 0.000258, l1: 0.000255, l2: 0.000281, l3: 0.000332, l4: 0.000579, l5: 0.001222, l6: 0.001648

[epoch: 291/1000, batch:   760/ 1052, ite: 76460] train loss: 0.005072, tar: 0.000274 
l0: 0.000166, l1: 0.000166, l2: 0.000191, l3: 0.000279, l4: 0.000474, l5: 0.001264, l6: 0.001570

[epoch: 291/1000, batch:   840/ 1052, ite: 76480] train loss: 0.005067, tar: 0.000273 
l0: 0.000279, l1: 0.000289, l2: 0.000298, l3: 0.000348, l4: 0.000487, l5: 0.000939, l6: 0.002525

[epoch: 291/1000, batch:   920/ 1052, ite: 76500] train loss: 0.005064, tar: 0.000273 
l0: 0.000257, l1: 0.000254, l2: 0.000289, l3: 0.000387, l4: 0.000647, l5: 0.001100, l6: 0.002124

[epoch: 291/1000, batch:  1000/ 1052, ite: 76520] train loss: 0.005064, tar: 0.000273 
[Epoch 291/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000329, l1: 0.000326, l2: 0.000340, l3: 0.000388, l4: 0.000736, l5: 0.001094, l6: 0.002797

[epoch: 292/1000, batch:    28/ 1052, ite: 76540] train loss: 0.005065, tar: 0.000273 
l0: 0.000194, l1: 0.000188, l2: 0.000248, l3: 0.000360, l4: 0.000621, l5: 0.000891, l6: 0.002299

[epoch: 292/1000, batch:   108/ 1052, ite: 76560] train loss: 0.005062, tar: 0.000273 
l0: 0.000220, l1: 0.000233, l2: 0.000207, l3: 0.000322, l4: 0.000466, l5: 0.001392, l6: 0.002069

[epoch: 292/1000, batch:   188/ 1052, ite: 76580] train loss: 0.005057, tar: 0.000273 
l0: 0.000278, l1: 0.000290, l2: 0.000293, l3: 0.000446, l4: 0.000611, l5: 0.001618, l6: 0.002838

[epoch: 292/1000, batch:   268/ 1052, ite: 76600] train loss: 0.005058, tar: 0.000273 
l0: 0.000168, l1: 0.000174, l2: 0.000185, l3: 0.000228, l4: 0.000384, l5: 0.000927, l6: 0.001331

[epoch: 292/1000, batch:   348/ 1052, ite: 76620] train loss: 0.005057, tar: 0.000273 
l0: 0.000250, l1: 0.000256, l2: 0.000276, l3: 0.000280, l4: 0.000479, l5: 0.001196, l6: 0.002103

[epoch: 292/1000, batch:   428/ 1052, ite: 76640] train loss: 0.005057, tar: 0.000273 
l0: 0.000315, l1: 0.000329, l2: 0.000314, l3: 0.000368, l4: 0.000562, l5: 0.001172, l6: 0.002020

[epoch: 292/1000, batch:   508/ 1052, ite: 76660] train loss: 0.005061, tar: 0.000273 
l0: 0.000278, l1: 0.000293, l2: 0.000311, l3: 0.000292, l4: 0.000422, l5: 0.000975, l6: 0.002116

[epoch: 292/1000, batch:   588/ 1052, ite: 76680] train loss: 0.005061, tar: 0.000273 
l0: 0.000233, l1: 0.000238, l2: 0.000240, l3: 0.000334, l4: 0.000499, l5: 0.000888, l6: 0.002112

[epoch: 292/1000, batch:   668/ 1052, ite: 76700] train loss: 0.005063, tar: 0.000273 
l0: 0.000296, l1: 0.000308, l2: 0.000315, l3: 0.000412, l4: 0.000818, l5: 0.001668, l6: 0.002545

[epoch: 292/1000, batch:   748/ 1052, ite: 76720] train loss: 0.005062, tar: 0.000273 
l0: 0.000304, l1: 0.000323, l2: 0.000308, l3: 0.000366, l4: 0.000597, l5: 0.001467, l6: 0.002894

[epoch: 292/1000, batch:   828/ 1052, ite: 76740] train loss: 0.005060, tar: 0.000273 
l0: 0.000271, l1: 0.000285, l2: 0.000285, l3: 0.000328, l4: 0.000439, l5: 0.001417, l6: 0.002836

[epoch: 292/1000, batch:   908/ 1052, ite: 76760] train loss: 0.005056, tar: 0.000273 
l0: 0.000266, l1: 0.000269, l2: 0.000272, l3: 0.000350, l4: 0.000595, l5: 0.001152, l6: 0.002207

[epoch: 292/1000, batch:   988/ 1052, ite: 76780] train loss: 0.005059, tar: 0.000273 
[Epoch 292/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000310, l1: 0.000337, l2: 0.000331, l3: 0.000383, l4: 0.000686, l5: 0.001498, l6: 0.002154

[epoch: 293/1000, batch:    16/ 1052, ite: 76800] train loss: 0.005064, tar: 0.000273 
l0: 0.000184, l1: 0.000181, l2: 0.000202, l3: 0.000365, l4: 0.000508, l5: 0.001314, l6: 0.001362

[epoch: 293/1000, batch:    96/ 1052, ite: 76820] train loss: 0.005063, tar: 0.000273 
l0: 0.000258, l1: 0.000258, l2: 0.000261, l3: 0.000374, l4: 0.000559, l5: 0.001105, l6: 0.001810

[epoch: 293/1000, batch:   176/ 1052, ite: 76840] train loss: 0.005061, tar: 0.000273 
l0: 0.000133, l1: 0.000124, l2: 0.000174, l3: 0.000276, l4: 0.000411, l5: 0.001034, l6: 0.001505

[epoch: 293/1000, batch:   256/ 1052, ite: 76860] train loss: 0.005059, tar: 0.000273 
l0: 0.000193, l1: 0.000188, l2: 0.000232, l3: 0.000344, l4: 0.000483, l5: 0.001230, l6: 0.001108

[epoch: 293/1000, batch:   336/ 1052, ite: 76880] train loss: 0.005056, tar: 0.000272 
l0: 0.000323, l1: 0.000331, l2: 0.000347, l3: 0.000588, l4: 0.001077, l5: 0.001835, l6: 0.003041

[epoch: 293/1000, batch:   416/ 1052, ite: 76900] train loss: 0.005051, tar: 0.000272 
l0: 0.000155, l1: 0.000152, l2: 0.000162, l3: 0.000229, l4: 0.000349, l5: 0.000570, l6: 0.001352

[epoch: 293/1000, batch:   496/ 1052, ite: 76920] train loss: 0.005050, tar: 0.000272 
l0: 0.000190, l1: 0.000194, l2: 0.000219, l3: 0.000241, l4: 0.000535, l5: 0.000805, l6: 0.001618

[epoch: 293/1000, batch:   576/ 1052, ite: 76940] train loss: 0.005053, tar: 0.000272 
l0: 0.000308, l1: 0.000315, l2: 0.000355, l3: 0.000409, l4: 0.000458, l5: 0.000741, l6: 0.002535

[epoch: 293/1000, batch:   656/ 1052, ite: 76960] train loss: 0.005054, tar: 0.000272 
l0: 0.000276, l1: 0.000272, l2: 0.000330, l3: 0.000423, l4: 0.000680, l5: 0.001378, l6: 0.002439

[epoch: 293/1000, batch:   736/ 1052, ite: 76980] train loss: 0.005054, tar: 0.000272 
l0: 0.000155, l1: 0.000154, l2: 0.000174, l3: 0.000224, l4: 0.000396, l5: 0.000371, l6: 0.001166

[epoch: 293/1000, batch:   816/ 1052, ite: 77000] train loss: 0.005053, tar: 0.000272 
l0: 0.000274, l1: 0.000283, l2: 0.000289, l3: 0.000344, l4: 0.000489, l5: 0.001294, l6: 0.001995

[epoch: 293/1000, batch:   896/ 1052, ite: 77020] train loss: 0.005053, tar: 0.000272 
l0: 0.001153, l1: 0.001133, l2: 0.001051, l3: 0.001441, l4: 0.001310, l5: 0.002246, l6: 0.003947

[epoch: 293/1000, batch:   976/ 1052, ite: 77040] train loss: 0.005060, tar: 0.000272 
[Epoch 293/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000126, l1: 0.000127, l2: 0.000126, l3: 0.000204, l4: 0.000293, l5: 0.000815, l6: 0.001183

[epoch: 294/1000, batch:     4/ 1052, ite: 77060] train loss: 0.005063, tar: 0.000272 
l0: 0.000342, l1: 0.000369, l2: 0.000373, l3: 0.000421, l4: 0.000626, l5: 0.000940, l6: 0.002343

[epoch: 294/1000, batch:    84/ 1052, ite: 77080] train loss: 0.005065, tar: 0.000272 
l0: 0.000288, l1: 0.000283, l2: 0.000350, l3: 0.000477, l4: 0.000833, l5: 0.001435, l6: 0.002946

[epoch: 294/1000, batch:   164/ 1052, ite: 77100] train loss: 0.005067, tar: 0.000273 
l0: 0.000168, l1: 0.000163, l2: 0.000201, l3: 0.000272, l4: 0.000434, l5: 0.000789, l6: 0.001596

[epoch: 294/1000, batch:   244/ 1052, ite: 77120] train loss: 0.005068, tar: 0.000273 
l0: 0.000222, l1: 0.000220, l2: 0.000248, l3: 0.000311, l4: 0.000512, l5: 0.000904, l6: 0.001543

[epoch: 294/1000, batch:   324/ 1052, ite: 77140] train loss: 0.005075, tar: 0.000273 
l0: 0.000185, l1: 0.000199, l2: 0.000165, l3: 0.000238, l4: 0.000328, l5: 0.000612, l6: 0.001399

[epoch: 294/1000, batch:   404/ 1052, ite: 77160] train loss: 0.005081, tar: 0.000274 
l0: 0.000255, l1: 0.000256, l2: 0.000274, l3: 0.000325, l4: 0.000645, l5: 0.000821, l6: 0.001506

[epoch: 294/1000, batch:   484/ 1052, ite: 77180] train loss: 0.005080, tar: 0.000274 
l0: 0.000331, l1: 0.000331, l2: 0.000370, l3: 0.000510, l4: 0.000849, l5: 0.001722, l6: 0.003853

[epoch: 294/1000, batch:   564/ 1052, ite: 77200] train loss: 0.005079, tar: 0.000274 
l0: 0.000195, l1: 0.000181, l2: 0.000245, l3: 0.000335, l4: 0.000496, l5: 0.001153, l6: 0.001582

[epoch: 294/1000, batch:   644/ 1052, ite: 77220] train loss: 0.005081, tar: 0.000274 
l0: 0.000235, l1: 0.000230, l2: 0.000294, l3: 0.000318, l4: 0.000680, l5: 0.000933, l6: 0.002051

[epoch: 294/1000, batch:   724/ 1052, ite: 77240] train loss: 0.005081, tar: 0.000274 
l0: 0.000165, l1: 0.000172, l2: 0.000173, l3: 0.000209, l4: 0.000346, l5: 0.000528, l6: 0.000826

[epoch: 294/1000, batch:   804/ 1052, ite: 77260] train loss: 0.005077, tar: 0.000274 
l0: 0.000477, l1: 0.000467, l2: 0.000561, l3: 0.000740, l4: 0.001940, l5: 0.002201, l6: 0.004232

[epoch: 294/1000, batch:   884/ 1052, ite: 77280] train loss: 0.005078, tar: 0.000274 
l0: 0.000274, l1: 0.000290, l2: 0.000336, l3: 0.000335, l4: 0.000570, l5: 0.000852, l6: 0.002131

[epoch: 294/1000, batch:   964/ 1052, ite: 77300] train loss: 0.005077, tar: 0.000274 
l0: 0.000152, l1: 0.000162, l2: 0.000179, l3: 0.000268, l4: 0.000443, l5: 0.001217, l6: 0.001402

[epoch: 294/1000, batch:  1044/ 1052, ite: 77320] train loss: 0.005074, tar: 0.000273 
[Epoch 294/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000253, l1: 0.000263, l2: 0.000266, l3: 0.000296, l4: 0.000524, l5: 0.000978, l6: 0.001719

[epoch: 295/1000, batch:    72/ 1052, ite: 77340] train loss: 0.005075, tar: 0.000274 
l0: 0.000288, l1: 0.000295, l2: 0.000301, l3: 0.000413, l4: 0.000795, l5: 0.001370, l6: 0.002188

[epoch: 295/1000, batch:   152/ 1052, ite: 77360] train loss: 0.005077, tar: 0.000274 
l0: 0.000085, l1: 0.000083, l2: 0.000113, l3: 0.000214, l4: 0.000509, l5: 0.000691, l6: 0.001264

[epoch: 295/1000, batch:   232/ 1052, ite: 77380] train loss: 0.005075, tar: 0.000273 
l0: 0.000211, l1: 0.000207, l2: 0.000252, l3: 0.000318, l4: 0.000620, l5: 0.001164, l6: 0.002390

[epoch: 295/1000, batch:   312/ 1052, ite: 77400] train loss: 0.005074, tar: 0.000273 
l0: 0.000201, l1: 0.000199, l2: 0.000254, l3: 0.000285, l4: 0.000497, l5: 0.001002, l6: 0.001512

[epoch: 295/1000, batch:   392/ 1052, ite: 77420] train loss: 0.005076, tar: 0.000273 
l0: 0.000271, l1: 0.000281, l2: 0.000263, l3: 0.000323, l4: 0.000380, l5: 0.001319, l6: 0.001810

[epoch: 295/1000, batch:   472/ 1052, ite: 77440] train loss: 0.005074, tar: 0.000273 
l0: 0.000603, l1: 0.000615, l2: 0.000603, l3: 0.000874, l4: 0.001497, l5: 0.002798, l6: 0.004287

[epoch: 295/1000, batch:   552/ 1052, ite: 77460] train loss: 0.005076, tar: 0.000273 
l0: 0.000170, l1: 0.000171, l2: 0.000193, l3: 0.000227, l4: 0.000440, l5: 0.000693, l6: 0.001942

[epoch: 295/1000, batch:   632/ 1052, ite: 77480] train loss: 0.005077, tar: 0.000273 
l0: 0.000283, l1: 0.000288, l2: 0.000295, l3: 0.000401, l4: 0.000722, l5: 0.001016, l6: 0.001824

[epoch: 295/1000, batch:   712/ 1052, ite: 77500] train loss: 0.005075, tar: 0.000273 
l0: 0.000241, l1: 0.000269, l2: 0.000241, l3: 0.000301, l4: 0.000547, l5: 0.001365, l6: 0.002574

[epoch: 295/1000, batch:   792/ 1052, ite: 77520] train loss: 0.005078, tar: 0.000273 
l0: 0.000143, l1: 0.000145, l2: 0.000172, l3: 0.000204, l4: 0.000341, l5: 0.000918, l6: 0.001406

[epoch: 295/1000, batch:   872/ 1052, ite: 77540] train loss: 0.005077, tar: 0.000273 
l0: 0.000254, l1: 0.000254, l2: 0.000276, l3: 0.000334, l4: 0.000675, l5: 0.001192, l6: 0.001858

[epoch: 295/1000, batch:   952/ 1052, ite: 77560] train loss: 0.005076, tar: 0.000273 
l0: 0.000177, l1: 0.000181, l2: 0.000195, l3: 0.000229, l4: 0.000392, l5: 0.000693, l6: 0.001289

[epoch: 295/1000, batch:  1032/ 1052, ite: 77580] train loss: 0.005073, tar: 0.000273 
[Epoch 295/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000407, l1: 0.000398, l2: 0.000483, l3: 0.000528, l4: 0.000836, l5: 0.002305, l6: 0.003572

[epoch: 296/1000, batch:    60/ 1052, ite: 77600] train loss: 0.005074, tar: 0.000273 
l0: 0.000198, l1: 0.000195, l2: 0.000254, l3: 0.000336, l4: 0.000920, l5: 0.001126, l6: 0.002090

[epoch: 296/1000, batch:   140/ 1052, ite: 77620] train loss: 0.005072, tar: 0.000273 
l0: 0.000237, l1: 0.000253, l2: 0.000231, l3: 0.000335, l4: 0.000766, l5: 0.001028, l6: 0.001875

[epoch: 296/1000, batch:   220/ 1052, ite: 77640] train loss: 0.005073, tar: 0.000272 
l0: 0.000127, l1: 0.000126, l2: 0.000157, l3: 0.000194, l4: 0.000363, l5: 0.000725, l6: 0.001065

[epoch: 296/1000, batch:   300/ 1052, ite: 77660] train loss: 0.005071, tar: 0.000272 
l0: 0.000451, l1: 0.000457, l2: 0.000426, l3: 0.000530, l4: 0.000710, l5: 0.000866, l6: 0.001795

[epoch: 296/1000, batch:   380/ 1052, ite: 77680] train loss: 0.005068, tar: 0.000272 
l0: 0.000265, l1: 0.000268, l2: 0.000275, l3: 0.000334, l4: 0.000565, l5: 0.000911, l6: 0.002157

[epoch: 296/1000, batch:   460/ 1052, ite: 77700] train loss: 0.005069, tar: 0.000272 
l0: 0.000455, l1: 0.000467, l2: 0.000458, l3: 0.000530, l4: 0.000865, l5: 0.001792, l6: 0.002652

[epoch: 296/1000, batch:   540/ 1052, ite: 77720] train loss: 0.005068, tar: 0.000272 
l0: 0.000164, l1: 0.000169, l2: 0.000161, l3: 0.000256, l4: 0.000634, l5: 0.000742, l6: 0.001304

[epoch: 296/1000, batch:   620/ 1052, ite: 77740] train loss: 0.005069, tar: 0.000272 
l0: 0.000184, l1: 0.000190, l2: 0.000277, l3: 0.000379, l4: 0.000771, l5: 0.001106, l6: 0.001609

[epoch: 296/1000, batch:   700/ 1052, ite: 77760] train loss: 0.005068, tar: 0.000272 
l0: 0.000287, l1: 0.000279, l2: 0.000332, l3: 0.000611, l4: 0.000917, l5: 0.001570, l6: 0.002084

[epoch: 296/1000, batch:   780/ 1052, ite: 77780] train loss: 0.005067, tar: 0.000272 
l0: 0.000541, l1: 0.000551, l2: 0.000596, l3: 0.000647, l4: 0.000809, l5: 0.001743, l6: 0.003493

[epoch: 296/1000, batch:   860/ 1052, ite: 77800] train loss: 0.005068, tar: 0.000272 
l0: 0.000155, l1: 0.000154, l2: 0.000201, l3: 0.000238, l4: 0.000570, l5: 0.001180, l6: 0.002617

[epoch: 296/1000, batch:   940/ 1052, ite: 77820] train loss: 0.005068, tar: 0.000272 
l0: 0.000180, l1: 0.000182, l2: 0.000213, l3: 0.000287, l4: 0.000445, l5: 0.000678, l6: 0.001309

[epoch: 296/1000, batch:  1020/ 1052, ite: 77840] train loss: 0.005069, tar: 0.000272 
[Epoch 296/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000347, l1: 0.000355, l2: 0.000376, l3: 0.000378, l4: 0.000671, l5: 0.001316, l6: 0.002976

[epoch: 297/1000, batch:    48/ 1052, ite: 77860] train loss: 0.005068, tar: 0.000272 
l0: 0.000310, l1: 0.000323, l2: 0.000317, l3: 0.000340, l4: 0.000412, l5: 0.001100, l6: 0.001615

[epoch: 297/1000, batch:   128/ 1052, ite: 77880] train loss: 0.005068, tar: 0.000272 
l0: 0.000242, l1: 0.000241, l2: 0.000291, l3: 0.000321, l4: 0.000639, l5: 0.001610, l6: 0.001875

[epoch: 297/1000, batch:   208/ 1052, ite: 77900] train loss: 0.005067, tar: 0.000272 
l0: 0.000270, l1: 0.000269, l2: 0.000298, l3: 0.000301, l4: 0.000529, l5: 0.001072, l6: 0.001822

[epoch: 297/1000, batch:   288/ 1052, ite: 77920] train loss: 0.005066, tar: 0.000272 
l0: 0.000384, l1: 0.000385, l2: 0.000386, l3: 0.000441, l4: 0.000766, l5: 0.001265, l6: 0.002432

[epoch: 297/1000, batch:   368/ 1052, ite: 77940] train loss: 0.005067, tar: 0.000272 
l0: 0.000406, l1: 0.000413, l2: 0.000433, l3: 0.000542, l4: 0.000896, l5: 0.001790, l6: 0.003080

[epoch: 297/1000, batch:   448/ 1052, ite: 77960] train loss: 0.005066, tar: 0.000272 
l0: 0.000396, l1: 0.000399, l2: 0.000456, l3: 0.000598, l4: 0.000921, l5: 0.001502, l6: 0.002547

[epoch: 297/1000, batch:   528/ 1052, ite: 77980] train loss: 0.005067, tar: 0.000272 
l0: 0.000303, l1: 0.000319, l2: 0.000334, l3: 0.000456, l4: 0.000914, l5: 0.001410, l6: 0.002376

[epoch: 297/1000, batch:   608/ 1052, ite: 78000] train loss: 0.005067, tar: 0.000272 
l0: 0.000121, l1: 0.000116, l2: 0.000157, l3: 0.000220, l4: 0.000453, l5: 0.000932, l6: 0.001100

[epoch: 297/1000, batch:   688/ 1052, ite: 78020] train loss: 0.005064, tar: 0.000271 
l0: 0.000159, l1: 0.000159, l2: 0.000168, l3: 0.000195, l4: 0.000472, l5: 0.000696, l6: 0.001125

[epoch: 297/1000, batch:   768/ 1052, ite: 78040] train loss: 0.005065, tar: 0.000272 
l0: 0.000427, l1: 0.000437, l2: 0.000457, l3: 0.000463, l4: 0.001040, l5: 0.001966, l6: 0.002847

[epoch: 297/1000, batch:   848/ 1052, ite: 78060] train loss: 0.005065, tar: 0.000271 
l0: 0.000163, l1: 0.000173, l2: 0.000161, l3: 0.000235, l4: 0.000646, l5: 0.000623, l6: 0.001557

[epoch: 297/1000, batch:   928/ 1052, ite: 78080] train loss: 0.005066, tar: 0.000271 
l0: 0.000160, l1: 0.000160, l2: 0.000182, l3: 0.000220, l4: 0.000405, l5: 0.000893, l6: 0.001508

[epoch: 297/1000, batch:  1008/ 1052, ite: 78100] train loss: 0.005063, tar: 0.000271 
[Epoch 297/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000125, l1: 0.000128, l2: 0.000138, l3: 0.000188, l4: 0.000267, l5: 0.000687, l6: 0.001301

[epoch: 298/1000, batch:    36/ 1052, ite: 78120] train loss: 0.005063, tar: 0.000271 
l0: 0.000447, l1: 0.000456, l2: 0.000471, l3: 0.000538, l4: 0.000873, l5: 0.001570, l6: 0.004020

[epoch: 298/1000, batch:   116/ 1052, ite: 78140] train loss: 0.005062, tar: 0.000271 
l0: 0.000171, l1: 0.000168, l2: 0.000180, l3: 0.000244, l4: 0.000418, l5: 0.000774, l6: 0.000843

[epoch: 298/1000, batch:   196/ 1052, ite: 78160] train loss: 0.005060, tar: 0.000271 
l0: 0.000141, l1: 0.000141, l2: 0.000218, l3: 0.000239, l4: 0.000537, l5: 0.000719, l6: 0.001675

[epoch: 298/1000, batch:   276/ 1052, ite: 78180] train loss: 0.005060, tar: 0.000271 
l0: 0.000236, l1: 0.000223, l2: 0.000350, l3: 0.000530, l4: 0.000861, l5: 0.001345, l6: 0.002314

[epoch: 298/1000, batch:   356/ 1052, ite: 78200] train loss: 0.005063, tar: 0.000271 
l0: 0.000295, l1: 0.000304, l2: 0.000299, l3: 0.000373, l4: 0.000516, l5: 0.001001, l6: 0.002456

[epoch: 298/1000, batch:   436/ 1052, ite: 78220] train loss: 0.005061, tar: 0.000271 
l0: 0.000156, l1: 0.000155, l2: 0.000160, l3: 0.000214, l4: 0.000344, l5: 0.000725, l6: 0.000854

[epoch: 298/1000, batch:   516/ 1052, ite: 78240] train loss: 0.005060, tar: 0.000271 
l0: 0.000149, l1: 0.000157, l2: 0.000140, l3: 0.000174, l4: 0.000364, l5: 0.000906, l6: 0.000978

[epoch: 298/1000, batch:   596/ 1052, ite: 78260] train loss: 0.005059, tar: 0.000271 
l0: 0.000448, l1: 0.000443, l2: 0.000492, l3: 0.000587, l4: 0.000913, l5: 0.001641, l6: 0.003121

[epoch: 298/1000, batch:   676/ 1052, ite: 78280] train loss: 0.005061, tar: 0.000271 
l0: 0.000218, l1: 0.000215, l2: 0.000238, l3: 0.000358, l4: 0.000530, l5: 0.001066, l6: 0.001625

[epoch: 298/1000, batch:   756/ 1052, ite: 78300] train loss: 0.005062, tar: 0.000271 
l0: 0.000372, l1: 0.000369, l2: 0.000386, l3: 0.000476, l4: 0.000663, l5: 0.001437, l6: 0.002091

[epoch: 298/1000, batch:   836/ 1052, ite: 78320] train loss: 0.005062, tar: 0.000271 
l0: 0.000449, l1: 0.000453, l2: 0.000519, l3: 0.000735, l4: 0.001471, l5: 0.002492, l6: 0.003035

[epoch: 298/1000, batch:   916/ 1052, ite: 78340] train loss: 0.005061, tar: 0.000270 
l0: 0.000253, l1: 0.000258, l2: 0.000262, l3: 0.000297, l4: 0.000510, l5: 0.001238, l6: 0.001228

[epoch: 298/1000, batch:   996/ 1052, ite: 78360] train loss: 0.005057, tar: 0.000270 
[Epoch 298/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000074, l1: 0.000080, l2: 0.000074, l3: 0.000154, l4: 0.000208, l5: 0.000476, l6: 0.000568

[epoch: 299/1000, batch:    24/ 1052, ite: 78380] train loss: 0.005056, tar: 0.000270 
l0: 0.000203, l1: 0.000208, l2: 0.000227, l3: 0.000240, l4: 0.000459, l5: 0.000978, l6: 0.001552

[epoch: 299/1000, batch:   104/ 1052, ite: 78400] train loss: 0.005055, tar: 0.000270 
l0: 0.000174, l1: 0.000168, l2: 0.000217, l3: 0.000343, l4: 0.000613, l5: 0.001357, l6: 0.001802

[epoch: 299/1000, batch:   184/ 1052, ite: 78420] train loss: 0.005054, tar: 0.000270 
l0: 0.000302, l1: 0.000315, l2: 0.000308, l3: 0.000465, l4: 0.000724, l5: 0.001391, l6: 0.002471

[epoch: 299/1000, batch:   264/ 1052, ite: 78440] train loss: 0.005054, tar: 0.000270 
l0: 0.000204, l1: 0.000201, l2: 0.000238, l3: 0.000341, l4: 0.000475, l5: 0.001106, l6: 0.001478

[epoch: 299/1000, batch:   344/ 1052, ite: 78460] train loss: 0.005054, tar: 0.000270 
l0: 0.000111, l1: 0.000116, l2: 0.000115, l3: 0.000180, l4: 0.000294, l5: 0.000569, l6: 0.001045

[epoch: 299/1000, batch:   424/ 1052, ite: 78480] train loss: 0.005053, tar: 0.000270 
l0: 0.000291, l1: 0.000270, l2: 0.000399, l3: 0.000566, l4: 0.000832, l5: 0.001914, l6: 0.001947

[epoch: 299/1000, batch:   504/ 1052, ite: 78500] train loss: 0.005053, tar: 0.000270 
l0: 0.000358, l1: 0.000357, l2: 0.000388, l3: 0.000556, l4: 0.000961, l5: 0.001809, l6: 0.002627

[epoch: 299/1000, batch:   584/ 1052, ite: 78520] train loss: 0.005053, tar: 0.000270 
l0: 0.000316, l1: 0.000321, l2: 0.000319, l3: 0.000425, l4: 0.000871, l5: 0.001228, l6: 0.002314

[epoch: 299/1000, batch:   664/ 1052, ite: 78540] train loss: 0.005054, tar: 0.000270 
l0: 0.000289, l1: 0.000277, l2: 0.000389, l3: 0.000708, l4: 0.001104, l5: 0.002058, l6: 0.003297

[epoch: 299/1000, batch:   744/ 1052, ite: 78560] train loss: 0.005052, tar: 0.000269 
l0: 0.000232, l1: 0.000235, l2: 0.000260, l3: 0.000272, l4: 0.000416, l5: 0.000839, l6: 0.000941

[epoch: 299/1000, batch:   824/ 1052, ite: 78580] train loss: 0.005051, tar: 0.000269 
l0: 0.000302, l1: 0.000299, l2: 0.000348, l3: 0.000377, l4: 0.000581, l5: 0.001520, l6: 0.002660

[epoch: 299/1000, batch:   904/ 1052, ite: 78600] train loss: 0.005051, tar: 0.000269 
l0: 0.000164, l1: 0.000172, l2: 0.000186, l3: 0.000228, l4: 0.000479, l5: 0.000845, l6: 0.001799

[epoch: 299/1000, batch:   984/ 1052, ite: 78620] train loss: 0.005051, tar: 0.000269 
[Epoch 299/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000171, l1: 0.000179, l2: 0.000196, l3: 0.000190, l4: 0.000307, l5: 0.000808, l6: 0.001630

[epoch: 300/1000, batch:    12/ 1052, ite: 78640] train loss: 0.005049, tar: 0.000269 
l0: 0.000175, l1: 0.000175, l2: 0.000187, l3: 0.000225, l4: 0.000411, l5: 0.000796, l6: 0.001805

[epoch: 300/1000, batch:    92/ 1052, ite: 78660] train loss: 0.005048, tar: 0.000269 
l0: 0.000436, l1: 0.000412, l2: 0.000437, l3: 0.000454, l4: 0.000639, l5: 0.001221, l6: 0.001834

[epoch: 300/1000, batch:   172/ 1052, ite: 78680] train loss: 0.005047, tar: 0.000269 
l0: 0.000429, l1: 0.000433, l2: 0.000469, l3: 0.000555, l4: 0.000859, l5: 0.001866, l6: 0.003303

[epoch: 300/1000, batch:   252/ 1052, ite: 78700] train loss: 0.005047, tar: 0.000269 
l0: 0.000166, l1: 0.000167, l2: 0.000196, l3: 0.000277, l4: 0.000575, l5: 0.001020, l6: 0.001805

[epoch: 300/1000, batch:   332/ 1052, ite: 78720] train loss: 0.005048, tar: 0.000269 
l0: 0.000237, l1: 0.000233, l2: 0.000263, l3: 0.000361, l4: 0.000612, l5: 0.001167, l6: 0.001913

[epoch: 300/1000, batch:   412/ 1052, ite: 78740] train loss: 0.005047, tar: 0.000269 
l0: 0.000214, l1: 0.000222, l2: 0.000227, l3: 0.000269, l4: 0.000470, l5: 0.001100, l6: 0.001615

[epoch: 300/1000, batch:   492/ 1052, ite: 78760] train loss: 0.005045, tar: 0.000269 
l0: 0.000229, l1: 0.000225, l2: 0.000282, l3: 0.000438, l4: 0.000879, l5: 0.001526, l6: 0.002840

[epoch: 300/1000, batch:   572/ 1052, ite: 78780] train loss: 0.005045, tar: 0.000269 
l0: 0.000203, l1: 0.000199, l2: 0.000226, l3: 0.000252, l4: 0.000402, l5: 0.000784, l6: 0.001445

[epoch: 300/1000, batch:   652/ 1052, ite: 78800] train loss: 0.005046, tar: 0.000269 
l0: 0.000484, l1: 0.000509, l2: 0.000495, l3: 0.000644, l4: 0.001000, l5: 0.002725, l6: 0.004343

[epoch: 300/1000, batch:   732/ 1052, ite: 78820] train loss: 0.005045, tar: 0.000268 
l0: 0.000423, l1: 0.000423, l2: 0.000443, l3: 0.000549, l4: 0.000838, l5: 0.001306, l6: 0.002635

[epoch: 300/1000, batch:   812/ 1052, ite: 78840] train loss: 0.005047, tar: 0.000269 
l0: 0.000418, l1: 0.000414, l2: 0.000463, l3: 0.000567, l4: 0.001132, l5: 0.001585, l6: 0.004694

[epoch: 300/1000, batch:   892/ 1052, ite: 78860] train loss: 0.005045, tar: 0.000268 
l0: 0.000155, l1: 0.000155, l2: 0.000157, l3: 0.000257, l4: 0.000395, l5: 0.000656, l6: 0.001143

[epoch: 300/1000, batch:   972/ 1052, ite: 78880] train loss: 0.005043, tar: 0.000268 
l0: 0.000189, l1: 0.000191, l2: 0.000203, l3: 0.000232, l4: 0.000352, l5: 0.000698, l6: 0.001431

[epoch: 300/1000, batch:  1052/ 1052, ite: 78900] train loss: 0.005044, tar: 0.000268 
[Epoch 300/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000424, l1: 0.000443, l2: 0.000441, l3: 0.000490, l4: 0.000832, l5: 0.001666, l6: 0.002446

[epoch: 301/1000, batch:    80/ 1052, ite: 78920] train loss: 0.005041, tar: 0.000268 
l0: 0.000193, l1: 0.000198, l2: 0.000258, l3: 0.000340, l4: 0.000647, l5: 0.001319, l6: 0.002027

[epoch: 301/1000, batch:   160/ 1052, ite: 78940] train loss: 0.005041, tar: 0.000268 
l0: 0.000172, l1: 0.000189, l2: 0.000187, l3: 0.000214, l4: 0.000343, l5: 0.000800, l6: 0.001527

[epoch: 301/1000, batch:   240/ 1052, ite: 78960] train loss: 0.005042, tar: 0.000268 
l0: 0.000477, l1: 0.000482, l2: 0.000520, l3: 0.000563, l4: 0.000994, l5: 0.001568, l6: 0.002070

[epoch: 301/1000, batch:   320/ 1052, ite: 78980] train loss: 0.005042, tar: 0.000268 
l0: 0.000460, l1: 0.000475, l2: 0.000483, l3: 0.000515, l4: 0.000788, l5: 0.001785, l6: 0.004197

[epoch: 301/1000, batch:   400/ 1052, ite: 79000] train loss: 0.005041, tar: 0.000268 
l0: 0.000194, l1: 0.000191, l2: 0.000219, l3: 0.000294, l4: 0.000466, l5: 0.000999, l6: 0.001982

[epoch: 301/1000, batch:   480/ 1052, ite: 79020] train loss: 0.005039, tar: 0.000267 
l0: 0.000219, l1: 0.000214, l2: 0.000255, l3: 0.000331, l4: 0.000788, l5: 0.001149, l6: 0.001989

[epoch: 301/1000, batch:   560/ 1052, ite: 79040] train loss: 0.005041, tar: 0.000267 
l0: 0.000190, l1: 0.000180, l2: 0.000260, l3: 0.000315, l4: 0.000510, l5: 0.000906, l6: 0.001518

[epoch: 301/1000, batch:   640/ 1052, ite: 79060] train loss: 0.005041, tar: 0.000267 
l0: 0.000178, l1: 0.000178, l2: 0.000219, l3: 0.000241, l4: 0.000457, l5: 0.000988, l6: 0.001974

[epoch: 301/1000, batch:   720/ 1052, ite: 79080] train loss: 0.005041, tar: 0.000267 
l0: 0.000202, l1: 0.000204, l2: 0.000220, l3: 0.000275, l4: 0.000450, l5: 0.000794, l6: 0.001181

[epoch: 301/1000, batch:   800/ 1052, ite: 79100] train loss: 0.005040, tar: 0.000267 
l0: 0.000200, l1: 0.000197, l2: 0.000225, l3: 0.000258, l4: 0.000457, l5: 0.000663, l6: 0.001053

[epoch: 301/1000, batch:   880/ 1052, ite: 79120] train loss: 0.005039, tar: 0.000267 
l0: 0.000338, l1: 0.000339, l2: 0.000422, l3: 0.000489, l4: 0.000708, l5: 0.001707, l6: 0.003238

[epoch: 301/1000, batch:   960/ 1052, ite: 79140] train loss: 0.005042, tar: 0.000267 
l0: 0.000210, l1: 0.000211, l2: 0.000241, l3: 0.000290, l4: 0.000378, l5: 0.001185, l6: 0.001552

[epoch: 301/1000, batch:  1040/ 1052, ite: 79160] train loss: 0.005041, tar: 0.000267 
[Epoch 301/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000207, l1: 0.000208, l2: 0.000244, l3: 0.000324, l4: 0.000501, l5: 0.001165, l6: 0.001108

[epoch: 302/1000, batch:    68/ 1052, ite: 79180] train loss: 0.005039, tar: 0.000267 
l0: 0.000195, l1: 0.000199, l2: 0.000190, l3: 0.000278, l4: 0.000522, l5: 0.000902, l6: 0.002072

[epoch: 302/1000, batch:   148/ 1052, ite: 79200] train loss: 0.005037, tar: 0.000267 
l0: 0.000265, l1: 0.000267, l2: 0.000302, l3: 0.000380, l4: 0.000626, l5: 0.001122, l6: 0.003505

[epoch: 302/1000, batch:   228/ 1052, ite: 79220] train loss: 0.005035, tar: 0.000267 
l0: 0.000369, l1: 0.000382, l2: 0.000398, l3: 0.000577, l4: 0.001055, l5: 0.001967, l6: 0.003664

[epoch: 302/1000, batch:   308/ 1052, ite: 79240] train loss: 0.005035, tar: 0.000267 
l0: 0.000200, l1: 0.000206, l2: 0.000214, l3: 0.000296, l4: 0.000604, l5: 0.001461, l6: 0.002200

[epoch: 302/1000, batch:   388/ 1052, ite: 79260] train loss: 0.005035, tar: 0.000267 
l0: 0.000199, l1: 0.000200, l2: 0.000199, l3: 0.000247, l4: 0.000441, l5: 0.000681, l6: 0.001396

[epoch: 302/1000, batch:   468/ 1052, ite: 79280] train loss: 0.005035, tar: 0.000266 
l0: 0.000402, l1: 0.000400, l2: 0.000454, l3: 0.000425, l4: 0.000475, l5: 0.000915, l6: 0.002234

[epoch: 302/1000, batch:   548/ 1052, ite: 79300] train loss: 0.005036, tar: 0.000266 
l0: 0.000200, l1: 0.000202, l2: 0.000239, l3: 0.000420, l4: 0.000541, l5: 0.001045, l6: 0.001866

[epoch: 302/1000, batch:   628/ 1052, ite: 79320] train loss: 0.005037, tar: 0.000266 
l0: 0.000371, l1: 0.000379, l2: 0.000347, l3: 0.000525, l4: 0.000836, l5: 0.001825, l6: 0.002382

[epoch: 302/1000, batch:   708/ 1052, ite: 79340] train loss: 0.005037, tar: 0.000266 
l0: 0.000229, l1: 0.000238, l2: 0.000257, l3: 0.000440, l4: 0.000812, l5: 0.000929, l6: 0.001753

[epoch: 302/1000, batch:   788/ 1052, ite: 79360] train loss: 0.005039, tar: 0.000266 
l0: 0.000300, l1: 0.000297, l2: 0.000363, l3: 0.000414, l4: 0.000598, l5: 0.001206, l6: 0.001842

[epoch: 302/1000, batch:   868/ 1052, ite: 79380] train loss: 0.005040, tar: 0.000266 
l0: 0.000249, l1: 0.000250, l2: 0.000296, l3: 0.000393, l4: 0.000660, l5: 0.001487, l6: 0.002149

[epoch: 302/1000, batch:   948/ 1052, ite: 79400] train loss: 0.005039, tar: 0.000266 
l0: 0.000104, l1: 0.000103, l2: 0.000150, l3: 0.000243, l4: 0.000494, l5: 0.001155, l6: 0.001990

[epoch: 302/1000, batch:  1028/ 1052, ite: 79420] train loss: 0.005039, tar: 0.000266 
[Epoch 302/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000131, l1: 0.000131, l2: 0.000139, l3: 0.000159, l4: 0.000292, l5: 0.000577, l6: 0.001059

[epoch: 303/1000, batch:    56/ 1052, ite: 79440] train loss: 0.005037, tar: 0.000266 
l0: 0.000488, l1: 0.000494, l2: 0.000562, l3: 0.000639, l4: 0.000848, l5: 0.001867, l6: 0.004205

[epoch: 303/1000, batch:   136/ 1052, ite: 79460] train loss: 0.005040, tar: 0.000266 
l0: 0.000316, l1: 0.000324, l2: 0.000361, l3: 0.000399, l4: 0.000556, l5: 0.001258, l6: 0.002327

[epoch: 303/1000, batch:   216/ 1052, ite: 79480] train loss: 0.005038, tar: 0.000266 
l0: 0.000185, l1: 0.000188, l2: 0.000208, l3: 0.000324, l4: 0.000765, l5: 0.001103, l6: 0.001404

[epoch: 303/1000, batch:   296/ 1052, ite: 79500] train loss: 0.005037, tar: 0.000266 
l0: 0.000380, l1: 0.000384, l2: 0.000394, l3: 0.000504, l4: 0.001224, l5: 0.002198, l6: 0.003389

[epoch: 303/1000, batch:   376/ 1052, ite: 79520] train loss: 0.005036, tar: 0.000266 
l0: 0.000258, l1: 0.000256, l2: 0.000288, l3: 0.000302, l4: 0.000395, l5: 0.000994, l6: 0.001845

[epoch: 303/1000, batch:   456/ 1052, ite: 79540] train loss: 0.005035, tar: 0.000266 
l0: 0.000105, l1: 0.000104, l2: 0.000134, l3: 0.000282, l4: 0.000272, l5: 0.000936, l6: 0.001231

[epoch: 303/1000, batch:   536/ 1052, ite: 79560] train loss: 0.005035, tar: 0.000266 
l0: 0.000260, l1: 0.000260, l2: 0.000312, l3: 0.000329, l4: 0.000536, l5: 0.001423, l6: 0.002360

[epoch: 303/1000, batch:   616/ 1052, ite: 79580] train loss: 0.005035, tar: 0.000266 
l0: 0.000288, l1: 0.000287, l2: 0.000341, l3: 0.000496, l4: 0.000869, l5: 0.001574, l6: 0.002637

[epoch: 303/1000, batch:   696/ 1052, ite: 79600] train loss: 0.005034, tar: 0.000266 
l0: 0.000409, l1: 0.000416, l2: 0.000446, l3: 0.000560, l4: 0.000937, l5: 0.001356, l6: 0.003750

[epoch: 303/1000, batch:   776/ 1052, ite: 79620] train loss: 0.005034, tar: 0.000266 
l0: 0.000365, l1: 0.000373, l2: 0.000414, l3: 0.000445, l4: 0.000884, l5: 0.001361, l6: 0.002639

[epoch: 303/1000, batch:   856/ 1052, ite: 79640] train loss: 0.005034, tar: 0.000266 
l0: 0.000518, l1: 0.000532, l2: 0.000584, l3: 0.000624, l4: 0.001053, l5: 0.002319, l6: 0.004368

[epoch: 303/1000, batch:   936/ 1052, ite: 79660] train loss: 0.005033, tar: 0.000266 
l0: 0.000246, l1: 0.000244, l2: 0.000293, l3: 0.000441, l4: 0.000712, l5: 0.001114, l6: 0.001787

[epoch: 303/1000, batch:  1016/ 1052, ite: 79680] train loss: 0.005033, tar: 0.000265 
[Epoch 303/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000226, l1: 0.000235, l2: 0.000247, l3: 0.000379, l4: 0.000638, l5: 0.001255, l6: 0.001964

[epoch: 304/1000, batch:    44/ 1052, ite: 79700] train loss: 0.005033, tar: 0.000265 
l0: 0.000147, l1: 0.000148, l2: 0.000173, l3: 0.000199, l4: 0.000411, l5: 0.000738, l6: 0.001070

[epoch: 304/1000, batch:   124/ 1052, ite: 79720] train loss: 0.005032, tar: 0.000265 
l0: 0.000164, l1: 0.000164, l2: 0.000176, l3: 0.000203, l4: 0.000337, l5: 0.000836, l6: 0.001452

[epoch: 304/1000, batch:   204/ 1052, ite: 79740] train loss: 0.005031, tar: 0.000265 
l0: 0.000165, l1: 0.000165, l2: 0.000213, l3: 0.000252, l4: 0.000384, l5: 0.001024, l6: 0.001417

[epoch: 304/1000, batch:   284/ 1052, ite: 79760] train loss: 0.005030, tar: 0.000265 
l0: 0.000115, l1: 0.000111, l2: 0.000156, l3: 0.000214, l4: 0.000410, l5: 0.000758, l6: 0.001446

[epoch: 304/1000, batch:   364/ 1052, ite: 79780] train loss: 0.005030, tar: 0.000265 
l0: 0.000485, l1: 0.000485, l2: 0.000505, l3: 0.000610, l4: 0.001103, l5: 0.001203, l6: 0.002822

[epoch: 304/1000, batch:   444/ 1052, ite: 79800] train loss: 0.005029, tar: 0.000265 
l0: 0.000249, l1: 0.000255, l2: 0.000257, l3: 0.000340, l4: 0.000533, l5: 0.001038, l6: 0.002539

[epoch: 304/1000, batch:   524/ 1052, ite: 79820] train loss: 0.005029, tar: 0.000265 
l0: 0.000363, l1: 0.000370, l2: 0.000436, l3: 0.000556, l4: 0.001030, l5: 0.001636, l6: 0.002781

[epoch: 304/1000, batch:   604/ 1052, ite: 79840] train loss: 0.005029, tar: 0.000265 
l0: 0.000403, l1: 0.000420, l2: 0.000451, l3: 0.000587, l4: 0.001162, l5: 0.003451, l6: 0.005393

[epoch: 304/1000, batch:   684/ 1052, ite: 79860] train loss: 0.005029, tar: 0.000265 
l0: 0.000283, l1: 0.000288, l2: 0.000331, l3: 0.000488, l4: 0.001171, l5: 0.001940, l6: 0.003140

[epoch: 304/1000, batch:   764/ 1052, ite: 79880] train loss: 0.005029, tar: 0.000265 
l0: 0.000214, l1: 0.000226, l2: 0.000254, l3: 0.000265, l4: 0.000441, l5: 0.000699, l6: 0.001299

[epoch: 304/1000, batch:   844/ 1052, ite: 79900] train loss: 0.005029, tar: 0.000265 
l0: 0.000150, l1: 0.000150, l2: 0.000216, l3: 0.000318, l4: 0.000484, l5: 0.001249, l6: 0.001828

[epoch: 304/1000, batch:   924/ 1052, ite: 79920] train loss: 0.005027, tar: 0.000265 
l0: 0.000294, l1: 0.000300, l2: 0.000339, l3: 0.000386, l4: 0.000673, l5: 0.001555, l6: 0.003349

[epoch: 304/1000, batch:  1004/ 1052, ite: 79940] train loss: 0.005026, tar: 0.000265 
[Epoch 304/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000316, l1: 0.000315, l2: 0.000376, l3: 0.000520, l4: 0.000869, l5: 0.002341, l6: 0.003921

[epoch: 305/1000, batch:    32/ 1052, ite: 79960] train loss: 0.005026, tar: 0.000265 
l0: 0.000169, l1: 0.000164, l2: 0.000227, l3: 0.000285, l4: 0.000506, l5: 0.000999, l6: 0.001296

[epoch: 305/1000, batch:   112/ 1052, ite: 79980] train loss: 0.005026, tar: 0.000264 
l0: 0.000275, l1: 0.000279, l2: 0.000298, l3: 0.000413, l4: 0.000929, l5: 0.001410, l6: 0.002351

[epoch: 305/1000, batch:   192/ 1052, ite: 80000] train loss: 0.005026, tar: 0.000264 
l0: 0.000203, l1: 0.000202, l2: 0.000227, l3: 0.000348, l4: 0.000681, l5: 0.001508, l6: 0.002155

[epoch: 305/1000, batch:   272/ 1052, ite: 80020] train loss: 0.005025, tar: 0.000264 
l0: 0.000143, l1: 0.000147, l2: 0.000163, l3: 0.000222, l4: 0.000440, l5: 0.000659, l6: 0.001087

[epoch: 305/1000, batch:   352/ 1052, ite: 80040] train loss: 0.005024, tar: 0.000264 
l0: 0.000183, l1: 0.000185, l2: 0.000219, l3: 0.000230, l4: 0.000328, l5: 0.000687, l6: 0.001559

[epoch: 305/1000, batch:   432/ 1052, ite: 80060] train loss: 0.005026, tar: 0.000264 
l0: 0.000342, l1: 0.000355, l2: 0.000368, l3: 0.000527, l4: 0.000853, l5: 0.001439, l6: 0.003135

[epoch: 305/1000, batch:   512/ 1052, ite: 80080] train loss: 0.005025, tar: 0.000264 
l0: 0.000237, l1: 0.000241, l2: 0.000253, l3: 0.000337, l4: 0.000506, l5: 0.002194, l6: 0.002846

[epoch: 305/1000, batch:   592/ 1052, ite: 80100] train loss: 0.005025, tar: 0.000264 
l0: 0.000234, l1: 0.000231, l2: 0.000282, l3: 0.000318, l4: 0.000513, l5: 0.000895, l6: 0.002115

[epoch: 305/1000, batch:   672/ 1052, ite: 80120] train loss: 0.005026, tar: 0.000264 
l0: 0.000281, l1: 0.000271, l2: 0.000307, l3: 0.000399, l4: 0.000577, l5: 0.001302, l6: 0.002127

[epoch: 305/1000, batch:   752/ 1052, ite: 80140] train loss: 0.005025, tar: 0.000264 
l0: 0.000457, l1: 0.000444, l2: 0.000501, l3: 0.000542, l4: 0.000662, l5: 0.001083, l6: 0.001683

[epoch: 305/1000, batch:   832/ 1052, ite: 80160] train loss: 0.005023, tar: 0.000264 
l0: 0.000178, l1: 0.000195, l2: 0.000204, l3: 0.000262, l4: 0.000468, l5: 0.001012, l6: 0.001959

[epoch: 305/1000, batch:   912/ 1052, ite: 80180] train loss: 0.005021, tar: 0.000264 
l0: 0.000251, l1: 0.000248, l2: 0.000283, l3: 0.000315, l4: 0.000406, l5: 0.000905, l6: 0.001887

[epoch: 305/1000, batch:   992/ 1052, ite: 80200] train loss: 0.005022, tar: 0.000264 
[Epoch 305/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000242, l1: 0.000246, l2: 0.000297, l3: 0.000434, l4: 0.000639, l5: 0.001420, l6: 0.002398

[epoch: 306/1000, batch:    20/ 1052, ite: 80220] train loss: 0.005019, tar: 0.000264 
l0: 0.000142, l1: 0.000143, l2: 0.000179, l3: 0.000248, l4: 0.000395, l5: 0.001037, l6: 0.001741

[epoch: 306/1000, batch:   100/ 1052, ite: 80240] train loss: 0.005019, tar: 0.000263 
l0: 0.000112, l1: 0.000121, l2: 0.000124, l3: 0.000180, l4: 0.000316, l5: 0.000985, l6: 0.001157

[epoch: 306/1000, batch:   180/ 1052, ite: 80260] train loss: 0.005018, tar: 0.000263 
l0: 0.000181, l1: 0.000176, l2: 0.000216, l3: 0.000365, l4: 0.000683, l5: 0.001138, l6: 0.002766

[epoch: 306/1000, batch:   260/ 1052, ite: 80280] train loss: 0.005019, tar: 0.000263 
l0: 0.000123, l1: 0.000123, l2: 0.000145, l3: 0.000233, l4: 0.000326, l5: 0.000836, l6: 0.001339

[epoch: 306/1000, batch:   340/ 1052, ite: 80300] train loss: 0.005017, tar: 0.000263 
l0: 0.000316, l1: 0.000308, l2: 0.000359, l3: 0.000399, l4: 0.000681, l5: 0.001252, l6: 0.002308

[epoch: 306/1000, batch:   420/ 1052, ite: 80320] train loss: 0.005016, tar: 0.000263 
l0: 0.000200, l1: 0.000206, l2: 0.000202, l3: 0.000415, l4: 0.000571, l5: 0.001199, l6: 0.001740

[epoch: 306/1000, batch:   500/ 1052, ite: 80340] train loss: 0.005016, tar: 0.000263 
l0: 0.000261, l1: 0.000268, l2: 0.000303, l3: 0.000403, l4: 0.000666, l5: 0.001162, l6: 0.002640

[epoch: 306/1000, batch:   580/ 1052, ite: 80360] train loss: 0.005015, tar: 0.000263 
l0: 0.000265, l1: 0.000275, l2: 0.000296, l3: 0.000388, l4: 0.000726, l5: 0.001931, l6: 0.001836

[epoch: 306/1000, batch:   660/ 1052, ite: 80380] train loss: 0.005018, tar: 0.000263 
l0: 0.000178, l1: 0.000180, l2: 0.000215, l3: 0.000280, l4: 0.000492, l5: 0.001078, l6: 0.002439

[epoch: 306/1000, batch:   740/ 1052, ite: 80400] train loss: 0.005019, tar: 0.000263 
l0: 0.000146, l1: 0.000142, l2: 0.000170, l3: 0.000289, l4: 0.000383, l5: 0.000866, l6: 0.001369

[epoch: 306/1000, batch:   820/ 1052, ite: 80420] train loss: 0.005018, tar: 0.000263 
l0: 0.000076, l1: 0.000078, l2: 0.000092, l3: 0.000109, l4: 0.000276, l5: 0.000522, l6: 0.000938

[epoch: 306/1000, batch:   900/ 1052, ite: 80440] train loss: 0.005017, tar: 0.000263 
l0: 0.000104, l1: 0.000107, l2: 0.000108, l3: 0.000146, l4: 0.000374, l5: 0.000565, l6: 0.001198

[epoch: 306/1000, batch:   980/ 1052, ite: 80460] train loss: 0.005015, tar: 0.000263 
[Epoch 306/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000173, l1: 0.000184, l2: 0.000181, l3: 0.000229, l4: 0.000457, l5: 0.000834, l6: 0.002175

[epoch: 307/1000, batch:     8/ 1052, ite: 80480] train loss: 0.005015, tar: 0.000263 
l0: 0.000322, l1: 0.000334, l2: 0.000395, l3: 0.000448, l4: 0.000625, l5: 0.000940, l6: 0.002370

[epoch: 307/1000, batch:    88/ 1052, ite: 80500] train loss: 0.005015, tar: 0.000263 
l0: 0.000378, l1: 0.000391, l2: 0.000471, l3: 0.000521, l4: 0.000983, l5: 0.001477, l6: 0.003045

[epoch: 307/1000, batch:   168/ 1052, ite: 80520] train loss: 0.005016, tar: 0.000263 
l0: 0.000365, l1: 0.000395, l2: 0.000356, l3: 0.000392, l4: 0.000666, l5: 0.000952, l6: 0.002247

[epoch: 307/1000, batch:   248/ 1052, ite: 80540] train loss: 0.005014, tar: 0.000262 
l0: 0.000119, l1: 0.000121, l2: 0.000151, l3: 0.000194, l4: 0.000413, l5: 0.000703, l6: 0.002063

[epoch: 307/1000, batch:   328/ 1052, ite: 80560] train loss: 0.005014, tar: 0.000262 
l0: 0.000162, l1: 0.000168, l2: 0.000188, l3: 0.000321, l4: 0.000445, l5: 0.001019, l6: 0.001847

[epoch: 307/1000, batch:   408/ 1052, ite: 80580] train loss: 0.005015, tar: 0.000262 
l0: 0.000160, l1: 0.000159, l2: 0.000188, l3: 0.000272, l4: 0.000438, l5: 0.000697, l6: 0.001617

[epoch: 307/1000, batch:   488/ 1052, ite: 80600] train loss: 0.005015, tar: 0.000262 
l0: 0.000249, l1: 0.000254, l2: 0.000242, l3: 0.000235, l4: 0.000388, l5: 0.000536, l6: 0.000997

[epoch: 307/1000, batch:   568/ 1052, ite: 80620] train loss: 0.005014, tar: 0.000262 
l0: 0.000306, l1: 0.000310, l2: 0.000333, l3: 0.000470, l4: 0.000912, l5: 0.002123, l6: 0.002457

[epoch: 307/1000, batch:   648/ 1052, ite: 80640] train loss: 0.005014, tar: 0.000262 
l0: 0.000145, l1: 0.000149, l2: 0.000160, l3: 0.000205, l4: 0.000354, l5: 0.000994, l6: 0.001530

[epoch: 307/1000, batch:   728/ 1052, ite: 80660] train loss: 0.005013, tar: 0.000262 
l0: 0.000231, l1: 0.000238, l2: 0.000220, l3: 0.000363, l4: 0.000567, l5: 0.001454, l6: 0.002082

[epoch: 307/1000, batch:   808/ 1052, ite: 80680] train loss: 0.005013, tar: 0.000262 
l0: 0.000441, l1: 0.000464, l2: 0.000439, l3: 0.000582, l4: 0.000960, l5: 0.002186, l6: 0.003593

[epoch: 307/1000, batch:   888/ 1052, ite: 80700] train loss: 0.005013, tar: 0.000262 
l0: 0.000193, l1: 0.000193, l2: 0.000224, l3: 0.000306, l4: 0.000571, l5: 0.001089, l6: 0.002195

[epoch: 307/1000, batch:   968/ 1052, ite: 80720] train loss: 0.005011, tar: 0.000262 
l0: 0.000175, l1: 0.000177, l2: 0.000201, l3: 0.000240, l4: 0.000525, l5: 0.001238, l6: 0.001103

[epoch: 307/1000, batch:  1048/ 1052, ite: 80740] train loss: 0.005013, tar: 0.000262 
[Epoch 307/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000172, l1: 0.000166, l2: 0.000233, l3: 0.000335, l4: 0.000430, l5: 0.001199, l6: 0.001904

[epoch: 308/1000, batch:    76/ 1052, ite: 80760] train loss: 0.005014, tar: 0.000262 
l0: 0.000621, l1: 0.000628, l2: 0.000630, l3: 0.000813, l4: 0.000980, l5: 0.002098, l6: 0.004201

[epoch: 308/1000, batch:   156/ 1052, ite: 80780] train loss: 0.005016, tar: 0.000262 
l0: 0.000153, l1: 0.000150, l2: 0.000157, l3: 0.000237, l4: 0.000441, l5: 0.000512, l6: 0.000885

[epoch: 308/1000, batch:   236/ 1052, ite: 80800] train loss: 0.005015, tar: 0.000262 
l0: 0.000351, l1: 0.000371, l2: 0.000370, l3: 0.000406, l4: 0.000607, l5: 0.002077, l6: 0.003455

[epoch: 308/1000, batch:   316/ 1052, ite: 80820] train loss: 0.005014, tar: 0.000262 
l0: 0.000184, l1: 0.000176, l2: 0.000296, l3: 0.000581, l4: 0.000848, l5: 0.001851, l6: 0.002839

[epoch: 308/1000, batch:   396/ 1052, ite: 80840] train loss: 0.005016, tar: 0.000262 
l0: 0.000292, l1: 0.000301, l2: 0.000356, l3: 0.000505, l4: 0.000741, l5: 0.001873, l6: 0.002676

[epoch: 308/1000, batch:   476/ 1052, ite: 80860] train loss: 0.005017, tar: 0.000262 
l0: 0.000167, l1: 0.000166, l2: 0.000234, l3: 0.000221, l4: 0.000381, l5: 0.001133, l6: 0.001256

[epoch: 308/1000, batch:   556/ 1052, ite: 80880] train loss: 0.005016, tar: 0.000262 
l0: 0.000255, l1: 0.000263, l2: 0.000282, l3: 0.000262, l4: 0.000389, l5: 0.000836, l6: 0.002048

[epoch: 308/1000, batch:   636/ 1052, ite: 80900] train loss: 0.005016, tar: 0.000262 
l0: 0.000233, l1: 0.000232, l2: 0.000253, l3: 0.000319, l4: 0.000466, l5: 0.001240, l6: 0.002720

[epoch: 308/1000, batch:   716/ 1052, ite: 80920] train loss: 0.005016, tar: 0.000262 
l0: 0.000112, l1: 0.000111, l2: 0.000140, l3: 0.000174, l4: 0.000336, l5: 0.000985, l6: 0.002056

[epoch: 308/1000, batch:   796/ 1052, ite: 80940] train loss: 0.005016, tar: 0.000262 
l0: 0.000865, l1: 0.000863, l2: 0.000841, l3: 0.001025, l4: 0.001476, l5: 0.002078, l6: 0.003255

[epoch: 308/1000, batch:   876/ 1052, ite: 80960] train loss: 0.005015, tar: 0.000262 
l0: 0.000422, l1: 0.000421, l2: 0.000480, l3: 0.000699, l4: 0.001051, l5: 0.001493, l6: 0.002792

[epoch: 308/1000, batch:   956/ 1052, ite: 80980] train loss: 0.005017, tar: 0.000262 
l0: 0.000229, l1: 0.000225, l2: 0.000246, l3: 0.000370, l4: 0.000554, l5: 0.001119, l6: 0.001925

[epoch: 308/1000, batch:  1036/ 1052, ite: 81000] train loss: 0.005017, tar: 0.000263 
[Epoch 308/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000443, l1: 0.000468, l2: 0.000478, l3: 0.000568, l4: 0.000753, l5: 0.000924, l6: 0.002554

[epoch: 309/1000, batch:    64/ 1052, ite: 81020] train loss: 0.005019, tar: 0.000263 
l0: 0.000278, l1: 0.000293, l2: 0.000328, l3: 0.000360, l4: 0.000577, l5: 0.001242, l6: 0.002936

[epoch: 309/1000, batch:   144/ 1052, ite: 81040] train loss: 0.005019, tar: 0.000263 
l0: 0.000177, l1: 0.000171, l2: 0.000183, l3: 0.000292, l4: 0.000498, l5: 0.000745, l6: 0.001261

[epoch: 309/1000, batch:   224/ 1052, ite: 81060] train loss: 0.005019, tar: 0.000263 
l0: 0.000416, l1: 0.000415, l2: 0.000420, l3: 0.000592, l4: 0.000794, l5: 0.001169, l6: 0.001954

[epoch: 309/1000, batch:   304/ 1052, ite: 81080] train loss: 0.005019, tar: 0.000263 
l0: 0.000479, l1: 0.000495, l2: 0.000556, l3: 0.000609, l4: 0.001058, l5: 0.001562, l6: 0.003852

[epoch: 309/1000, batch:   384/ 1052, ite: 81100] train loss: 0.005019, tar: 0.000263 
l0: 0.000334, l1: 0.000346, l2: 0.000347, l3: 0.000415, l4: 0.000744, l5: 0.001563, l6: 0.003239

[epoch: 309/1000, batch:   464/ 1052, ite: 81120] train loss: 0.005020, tar: 0.000263 
l0: 0.000264, l1: 0.000281, l2: 0.000235, l3: 0.000338, l4: 0.000717, l5: 0.001374, l6: 0.002172

[epoch: 309/1000, batch:   544/ 1052, ite: 81140] train loss: 0.005021, tar: 0.000263 
l0: 0.000183, l1: 0.000197, l2: 0.000219, l3: 0.000292, l4: 0.000365, l5: 0.000887, l6: 0.001314

[epoch: 309/1000, batch:   624/ 1052, ite: 81160] train loss: 0.005023, tar: 0.000264 
l0: 0.000326, l1: 0.000328, l2: 0.000376, l3: 0.000567, l4: 0.000982, l5: 0.001790, l6: 0.002291

[epoch: 309/1000, batch:   704/ 1052, ite: 81180] train loss: 0.005026, tar: 0.000264 
l0: 0.000209, l1: 0.000219, l2: 0.000210, l3: 0.000204, l4: 0.000523, l5: 0.000914, l6: 0.001989

[epoch: 309/1000, batch:   784/ 1052, ite: 81200] train loss: 0.005026, tar: 0.000264 
l0: 0.000476, l1: 0.000469, l2: 0.000556, l3: 0.000787, l4: 0.000969, l5: 0.001651, l6: 0.003133

[epoch: 309/1000, batch:   864/ 1052, ite: 81220] train loss: 0.005027, tar: 0.000264 
l0: 0.000267, l1: 0.000273, l2: 0.000279, l3: 0.000344, l4: 0.000718, l5: 0.000971, l6: 0.001923

[epoch: 309/1000, batch:   944/ 1052, ite: 81240] train loss: 0.005026, tar: 0.000264 
l0: 0.000196, l1: 0.000201, l2: 0.000204, l3: 0.000286, l4: 0.000475, l5: 0.001001, l6: 0.002531

[epoch: 309/1000, batch:  1024/ 1052, ite: 81260] train loss: 0.005026, tar: 0.000264 
[Epoch 309/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000161, l1: 0.000161, l2: 0.000200, l3: 0.000318, l4: 0.000506, l5: 0.001201, l6: 0.001712

[epoch: 310/1000, batch:    52/ 1052, ite: 81280] train loss: 0.005025, tar: 0.000264 
l0: 0.000304, l1: 0.000297, l2: 0.000301, l3: 0.000413, l4: 0.000586, l5: 0.000995, l6: 0.001772

[epoch: 310/1000, batch:   132/ 1052, ite: 81300] train loss: 0.005024, tar: 0.000264 
l0: 0.000307, l1: 0.000308, l2: 0.000350, l3: 0.000337, l4: 0.000424, l5: 0.000787, l6: 0.001269

[epoch: 310/1000, batch:   212/ 1052, ite: 81320] train loss: 0.005023, tar: 0.000264 
l0: 0.000129, l1: 0.000127, l2: 0.000157, l3: 0.000174, l4: 0.000324, l5: 0.000554, l6: 0.000798

[epoch: 310/1000, batch:   292/ 1052, ite: 81340] train loss: 0.005022, tar: 0.000264 
l0: 0.000487, l1: 0.000487, l2: 0.000489, l3: 0.000529, l4: 0.000900, l5: 0.001895, l6: 0.003099

[epoch: 310/1000, batch:   372/ 1052, ite: 81360] train loss: 0.005022, tar: 0.000264 
l0: 0.000317, l1: 0.000319, l2: 0.000362, l3: 0.000524, l4: 0.000791, l5: 0.001936, l6: 0.003584

[epoch: 310/1000, batch:   452/ 1052, ite: 81380] train loss: 0.005027, tar: 0.000264 
l0: 0.000162, l1: 0.000157, l2: 0.000210, l3: 0.000248, l4: 0.000594, l5: 0.000771, l6: 0.001525

[epoch: 310/1000, batch:   532/ 1052, ite: 81400] train loss: 0.005030, tar: 0.000264 
l0: 0.000471, l1: 0.000471, l2: 0.000414, l3: 0.000538, l4: 0.000868, l5: 0.001682, l6: 0.002556

[epoch: 310/1000, batch:   612/ 1052, ite: 81420] train loss: 0.005031, tar: 0.000264 
l0: 0.000243, l1: 0.000268, l2: 0.000289, l3: 0.000305, l4: 0.000534, l5: 0.000959, l6: 0.001009

[epoch: 310/1000, batch:   692/ 1052, ite: 81440] train loss: 0.005031, tar: 0.000264 
l0: 0.000550, l1: 0.000539, l2: 0.000624, l3: 0.000850, l4: 0.001282, l5: 0.002063, l6: 0.002964

[epoch: 310/1000, batch:   772/ 1052, ite: 81460] train loss: 0.005032, tar: 0.000265 
l0: 0.000370, l1: 0.000381, l2: 0.000393, l3: 0.000499, l4: 0.000971, l5: 0.001473, l6: 0.003555

[epoch: 310/1000, batch:   852/ 1052, ite: 81480] train loss: 0.005036, tar: 0.000265 
l0: 0.000358, l1: 0.000372, l2: 0.000376, l3: 0.000398, l4: 0.000973, l5: 0.001914, l6: 0.003242

[epoch: 310/1000, batch:   932/ 1052, ite: 81500] train loss: 0.005037, tar: 0.000265 
l0: 0.000263, l1: 0.000270, l2: 0.000280, l3: 0.000427, l4: 0.000535, l5: 0.001376, l6: 0.001372

[epoch: 310/1000, batch:  1012/ 1052, ite: 81520] train loss: 0.005036, tar: 0.000265 
[Epoch 310/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000185, l1: 0.000209, l2: 0.000213, l3: 0.000222, l4: 0.000381, l5: 0.000827, l6: 0.001260

[epoch: 311/1000, batch:    40/ 1052, ite: 81540] train loss: 0.005035, tar: 0.000265 
l0: 0.000080, l1: 0.000074, l2: 0.000097, l3: 0.000160, l4: 0.000336, l5: 0.000630, l6: 0.001035

[epoch: 311/1000, batch:   120/ 1052, ite: 81560] train loss: 0.005035, tar: 0.000265 
l0: 0.000079, l1: 0.000072, l2: 0.000116, l3: 0.000177, l4: 0.000325, l5: 0.000523, l6: 0.001043

[epoch: 311/1000, batch:   200/ 1052, ite: 81580] train loss: 0.005034, tar: 0.000265 
l0: 0.000330, l1: 0.000372, l2: 0.000342, l3: 0.000361, l4: 0.000489, l5: 0.001390, l6: 0.002444

[epoch: 311/1000, batch:   280/ 1052, ite: 81600] train loss: 0.005034, tar: 0.000265 
l0: 0.000299, l1: 0.000293, l2: 0.000344, l3: 0.000447, l4: 0.000702, l5: 0.001297, l6: 0.002548

[epoch: 311/1000, batch:   360/ 1052, ite: 81620] train loss: 0.005035, tar: 0.000265 
l0: 0.000363, l1: 0.000352, l2: 0.000427, l3: 0.000488, l4: 0.000757, l5: 0.000983, l6: 0.001752

[epoch: 311/1000, batch:   440/ 1052, ite: 81640] train loss: 0.005041, tar: 0.000266 
l0: 0.001186, l1: 0.001260, l2: 0.001229, l3: 0.001220, l4: 0.001489, l5: 0.003227, l6: 0.005608

[epoch: 311/1000, batch:   520/ 1052, ite: 81660] train loss: 0.005046, tar: 0.000267 
l0: 0.000355, l1: 0.000363, l2: 0.000390, l3: 0.000437, l4: 0.000902, l5: 0.001382, l6: 0.002111

[epoch: 311/1000, batch:   600/ 1052, ite: 81680] train loss: 0.005051, tar: 0.000267 
l0: 0.000226, l1: 0.000213, l2: 0.000251, l3: 0.000360, l4: 0.000418, l5: 0.000821, l6: 0.001962

[epoch: 311/1000, batch:   680/ 1052, ite: 81700] train loss: 0.005055, tar: 0.000268 
l0: 0.000334, l1: 0.000337, l2: 0.000372, l3: 0.000511, l4: 0.000811, l5: 0.001782, l6: 0.003771

[epoch: 311/1000, batch:   760/ 1052, ite: 81720] train loss: 0.005056, tar: 0.000268 
l0: 0.000372, l1: 0.000390, l2: 0.000426, l3: 0.000520, l4: 0.000824, l5: 0.001580, l6: 0.001910

[epoch: 311/1000, batch:   840/ 1052, ite: 81740] train loss: 0.005056, tar: 0.000268 
l0: 0.000270, l1: 0.000256, l2: 0.000284, l3: 0.000416, l4: 0.000616, l5: 0.001158, l6: 0.001861

[epoch: 311/1000, batch:   920/ 1052, ite: 81760] train loss: 0.005056, tar: 0.000268 
l0: 0.000256, l1: 0.000248, l2: 0.000306, l3: 0.000447, l4: 0.000763, l5: 0.001041, l6: 0.002390

[epoch: 311/1000, batch:  1000/ 1052, ite: 81780] train loss: 0.005055, tar: 0.000268 
[Epoch 311/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000554, l1: 0.000556, l2: 0.000620, l3: 0.000740, l4: 0.001141, l5: 0.002506, l6: 0.003892

[epoch: 312/1000, batch:    28/ 1052, ite: 81800] train loss: 0.005058, tar: 0.000268 
l0: 0.000206, l1: 0.000209, l2: 0.000255, l3: 0.000354, l4: 0.000750, l5: 0.000846, l6: 0.002020

[epoch: 312/1000, batch:   108/ 1052, ite: 81820] train loss: 0.005057, tar: 0.000268 
l0: 0.000546, l1: 0.000548, l2: 0.000564, l3: 0.000537, l4: 0.000823, l5: 0.001159, l6: 0.002958

[epoch: 312/1000, batch:   188/ 1052, ite: 81840] train loss: 0.005058, tar: 0.000268 
l0: 0.000322, l1: 0.000322, l2: 0.000347, l3: 0.000428, l4: 0.000549, l5: 0.001243, l6: 0.002231

[epoch: 312/1000, batch:   268/ 1052, ite: 81860] train loss: 0.005058, tar: 0.000268 
l0: 0.000202, l1: 0.000186, l2: 0.000208, l3: 0.000316, l4: 0.000536, l5: 0.000833, l6: 0.001495

[epoch: 312/1000, batch:   348/ 1052, ite: 81880] train loss: 0.005057, tar: 0.000268 
l0: 0.000193, l1: 0.000179, l2: 0.000273, l3: 0.000478, l4: 0.000977, l5: 0.002022, l6: 0.002393

[epoch: 312/1000, batch:   428/ 1052, ite: 81900] train loss: 0.005057, tar: 0.000268 
l0: 0.000390, l1: 0.000401, l2: 0.000448, l3: 0.000603, l4: 0.000939, l5: 0.002190, l6: 0.003550

[epoch: 312/1000, batch:   508/ 1052, ite: 81920] train loss: 0.005056, tar: 0.000268 
l0: 0.000082, l1: 0.000084, l2: 0.000122, l3: 0.000226, l4: 0.000460, l5: 0.000576, l6: 0.001510

[epoch: 312/1000, batch:   588/ 1052, ite: 81940] train loss: 0.005055, tar: 0.000268 
l0: 0.000310, l1: 0.000311, l2: 0.000386, l3: 0.000539, l4: 0.001150, l5: 0.001297, l6: 0.002534

[epoch: 312/1000, batch:   668/ 1052, ite: 81960] train loss: 0.005055, tar: 0.000268 
l0: 0.000120, l1: 0.000120, l2: 0.000132, l3: 0.000216, l4: 0.000331, l5: 0.000776, l6: 0.001187

[epoch: 312/1000, batch:   748/ 1052, ite: 81980] train loss: 0.005055, tar: 0.000268 
l0: 0.000251, l1: 0.000257, l2: 0.000292, l3: 0.000383, l4: 0.000585, l5: 0.001129, l6: 0.001812

[epoch: 312/1000, batch:   828/ 1052, ite: 82000] train loss: 0.005056, tar: 0.000268 
l0: 0.000164, l1: 0.000160, l2: 0.000217, l3: 0.000309, l4: 0.000595, l5: 0.000740, l6: 0.001803

[epoch: 312/1000, batch:   908/ 1052, ite: 82020] train loss: 0.005059, tar: 0.000268 
l0: 0.000239, l1: 0.000239, l2: 0.000260, l3: 0.000277, l4: 0.000537, l5: 0.001192, l6: 0.001039

[epoch: 312/1000, batch:   988/ 1052, ite: 82040] train loss: 0.005060, tar: 0.000268 
[Epoch 312/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000224, l1: 0.000229, l2: 0.000232, l3: 0.000285, l4: 0.000499, l5: 0.001094, l6: 0.001237

[epoch: 313/1000, batch:    16/ 1052, ite: 82060] train loss: 0.005060, tar: 0.000268 
l0: 0.000305, l1: 0.000310, l2: 0.000339, l3: 0.000368, l4: 0.000595, l5: 0.001383, l6: 0.002146

[epoch: 313/1000, batch:    96/ 1052, ite: 82080] train loss: 0.005060, tar: 0.000268 
l0: 0.000231, l1: 0.000227, l2: 0.000252, l3: 0.000324, l4: 0.000557, l5: 0.001028, l6: 0.002072

[epoch: 313/1000, batch:   176/ 1052, ite: 82100] train loss: 0.005059, tar: 0.000268 
l0: 0.000224, l1: 0.000219, l2: 0.000275, l3: 0.000354, l4: 0.000702, l5: 0.001300, l6: 0.002578

[epoch: 313/1000, batch:   256/ 1052, ite: 82120] train loss: 0.005059, tar: 0.000268 
l0: 0.000196, l1: 0.000215, l2: 0.000219, l3: 0.000246, l4: 0.000616, l5: 0.001276, l6: 0.001517

[epoch: 313/1000, batch:   336/ 1052, ite: 82140] train loss: 0.005059, tar: 0.000268 
l0: 0.000172, l1: 0.000177, l2: 0.000185, l3: 0.000237, l4: 0.000404, l5: 0.000805, l6: 0.001491

[epoch: 313/1000, batch:   416/ 1052, ite: 82160] train loss: 0.005058, tar: 0.000268 
l0: 0.000133, l1: 0.000138, l2: 0.000163, l3: 0.000240, l4: 0.000455, l5: 0.000664, l6: 0.001606

[epoch: 313/1000, batch:   496/ 1052, ite: 82180] train loss: 0.005058, tar: 0.000268 
l0: 0.000253, l1: 0.000248, l2: 0.000261, l3: 0.000365, l4: 0.000635, l5: 0.001235, l6: 0.001460

[epoch: 313/1000, batch:   576/ 1052, ite: 82200] train loss: 0.005059, tar: 0.000268 
l0: 0.000156, l1: 0.000161, l2: 0.000173, l3: 0.000198, l4: 0.000315, l5: 0.001036, l6: 0.001228

[epoch: 313/1000, batch:   656/ 1052, ite: 82220] train loss: 0.005063, tar: 0.000268 
l0: 0.000113, l1: 0.000120, l2: 0.000132, l3: 0.000160, l4: 0.000284, l5: 0.000609, l6: 0.001362

[epoch: 313/1000, batch:   736/ 1052, ite: 82240] train loss: 0.005062, tar: 0.000268 
l0: 0.000202, l1: 0.000195, l2: 0.000238, l3: 0.000310, l4: 0.000641, l5: 0.001147, l6: 0.001633

[epoch: 313/1000, batch:   816/ 1052, ite: 82260] train loss: 0.005061, tar: 0.000268 
l0: 0.000262, l1: 0.000263, l2: 0.000271, l3: 0.000397, l4: 0.000681, l5: 0.001275, l6: 0.002977

[epoch: 313/1000, batch:   896/ 1052, ite: 82280] train loss: 0.005059, tar: 0.000268 
l0: 0.000316, l1: 0.000344, l2: 0.000355, l3: 0.000596, l4: 0.000822, l5: 0.001517, l6: 0.003597

[epoch: 313/1000, batch:   976/ 1052, ite: 82300] train loss: 0.005059, tar: 0.000268 
[Epoch 313/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000215, l1: 0.000207, l2: 0.000245, l3: 0.000277, l4: 0.000506, l5: 0.000817, l6: 0.001281

[epoch: 314/1000, batch:     4/ 1052, ite: 82320] train loss: 0.005058, tar: 0.000268 
l0: 0.000310, l1: 0.000331, l2: 0.000319, l3: 0.000391, l4: 0.000843, l5: 0.001040, l6: 0.002057

[epoch: 314/1000, batch:    84/ 1052, ite: 82340] train loss: 0.005058, tar: 0.000268 
l0: 0.000173, l1: 0.000169, l2: 0.000200, l3: 0.000218, l4: 0.000333, l5: 0.000977, l6: 0.000752

[epoch: 314/1000, batch:   164/ 1052, ite: 82360] train loss: 0.005057, tar: 0.000268 
l0: 0.000163, l1: 0.000163, l2: 0.000177, l3: 0.000250, l4: 0.000368, l5: 0.000700, l6: 0.001114

[epoch: 314/1000, batch:   244/ 1052, ite: 82380] train loss: 0.005057, tar: 0.000268 
l0: 0.000161, l1: 0.000167, l2: 0.000197, l3: 0.000239, l4: 0.000454, l5: 0.000948, l6: 0.002318

[epoch: 314/1000, batch:   324/ 1052, ite: 82400] train loss: 0.005057, tar: 0.000268 
l0: 0.000195, l1: 0.000189, l2: 0.000226, l3: 0.000253, l4: 0.000432, l5: 0.000871, l6: 0.001157

[epoch: 314/1000, batch:   404/ 1052, ite: 82420] train loss: 0.005057, tar: 0.000268 
l0: 0.000319, l1: 0.000317, l2: 0.000323, l3: 0.000480, l4: 0.000771, l5: 0.001266, l6: 0.002572

[epoch: 314/1000, batch:   484/ 1052, ite: 82440] train loss: 0.005058, tar: 0.000268 
l0: 0.000230, l1: 0.000226, l2: 0.000272, l3: 0.000332, l4: 0.000475, l5: 0.001106, l6: 0.001972

[epoch: 314/1000, batch:   564/ 1052, ite: 82460] train loss: 0.005058, tar: 0.000268 
l0: 0.000116, l1: 0.000117, l2: 0.000132, l3: 0.000165, l4: 0.000327, l5: 0.000509, l6: 0.000985

[epoch: 314/1000, batch:   644/ 1052, ite: 82480] train loss: 0.005058, tar: 0.000268 
l0: 0.000399, l1: 0.000430, l2: 0.000415, l3: 0.000520, l4: 0.000840, l5: 0.001385, l6: 0.002740

[epoch: 314/1000, batch:   724/ 1052, ite: 82500] train loss: 0.005058, tar: 0.000268 
l0: 0.000169, l1: 0.000170, l2: 0.000209, l3: 0.000291, l4: 0.000423, l5: 0.000932, l6: 0.001916

[epoch: 314/1000, batch:   804/ 1052, ite: 82520] train loss: 0.005058, tar: 0.000268 
l0: 0.000138, l1: 0.000141, l2: 0.000158, l3: 0.000222, l4: 0.000434, l5: 0.000968, l6: 0.001772

[epoch: 314/1000, batch:   884/ 1052, ite: 82540] train loss: 0.005057, tar: 0.000267 
l0: 0.000216, l1: 0.000211, l2: 0.000253, l3: 0.000352, l4: 0.000595, l5: 0.001156, l6: 0.002155

[epoch: 314/1000, batch:   964/ 1052, ite: 82560] train loss: 0.005056, tar: 0.000267 
l0: 0.000186, l1: 0.000190, l2: 0.000205, l3: 0.000309, l4: 0.000376, l5: 0.000894, l6: 0.001375

[epoch: 314/1000, batch:  1044/ 1052, ite: 82580] train loss: 0.005055, tar: 0.000267 
[Epoch 314/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000225, l1: 0.000207, l2: 0.000287, l3: 0.000343, l4: 0.000787, l5: 0.001656, l6: 0.002212

[epoch: 315/1000, batch:    72/ 1052, ite: 82600] train loss: 0.005053, tar: 0.000267 
l0: 0.000109, l1: 0.000112, l2: 0.000126, l3: 0.000188, l4: 0.000427, l5: 0.000787, l6: 0.001551

[epoch: 315/1000, batch:   152/ 1052, ite: 82620] train loss: 0.005053, tar: 0.000267 
l0: 0.000136, l1: 0.000128, l2: 0.000165, l3: 0.000265, l4: 0.000481, l5: 0.001045, l6: 0.001971

[epoch: 315/1000, batch:   232/ 1052, ite: 82640] train loss: 0.005052, tar: 0.000267 
l0: 0.000261, l1: 0.000256, l2: 0.000313, l3: 0.000404, l4: 0.000662, l5: 0.001287, l6: 0.002218

[epoch: 315/1000, batch:   312/ 1052, ite: 82660] train loss: 0.005052, tar: 0.000267 
l0: 0.000120, l1: 0.000126, l2: 0.000134, l3: 0.000162, l4: 0.000491, l5: 0.000697, l6: 0.001699

[epoch: 315/1000, batch:   392/ 1052, ite: 82680] train loss: 0.005051, tar: 0.000267 
l0: 0.000169, l1: 0.000170, l2: 0.000204, l3: 0.000271, l4: 0.000283, l5: 0.000774, l6: 0.001891

[epoch: 315/1000, batch:   472/ 1052, ite: 82700] train loss: 0.005052, tar: 0.000267 
l0: 0.000142, l1: 0.000147, l2: 0.000148, l3: 0.000175, l4: 0.000282, l5: 0.000625, l6: 0.001056

[epoch: 315/1000, batch:   552/ 1052, ite: 82720] train loss: 0.005051, tar: 0.000267 
l0: 0.000178, l1: 0.000176, l2: 0.000204, l3: 0.000239, l4: 0.000428, l5: 0.000997, l6: 0.001221

[epoch: 315/1000, batch:   632/ 1052, ite: 82740] train loss: 0.005051, tar: 0.000267 
l0: 0.000406, l1: 0.000413, l2: 0.000441, l3: 0.000604, l4: 0.001118, l5: 0.002086, l6: 0.003013

[epoch: 315/1000, batch:   712/ 1052, ite: 82760] train loss: 0.005051, tar: 0.000267 
l0: 0.000477, l1: 0.000466, l2: 0.000518, l3: 0.000808, l4: 0.001207, l5: 0.002560, l6: 0.003756

[epoch: 315/1000, batch:   792/ 1052, ite: 82780] train loss: 0.005049, tar: 0.000266 
l0: 0.000077, l1: 0.000082, l2: 0.000091, l3: 0.000160, l4: 0.000430, l5: 0.000737, l6: 0.001233

[epoch: 315/1000, batch:   872/ 1052, ite: 82800] train loss: 0.005048, tar: 0.000266 
l0: 0.000151, l1: 0.000154, l2: 0.000182, l3: 0.000223, l4: 0.000511, l5: 0.000989, l6: 0.001666

[epoch: 315/1000, batch:   952/ 1052, ite: 82820] train loss: 0.005049, tar: 0.000266 
l0: 0.000404, l1: 0.000411, l2: 0.000441, l3: 0.000470, l4: 0.000668, l5: 0.001441, l6: 0.002616

[epoch: 315/1000, batch:  1032/ 1052, ite: 82840] train loss: 0.005050, tar: 0.000266 
[Epoch 315/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000127, l1: 0.000135, l2: 0.000132, l3: 0.000158, l4: 0.000368, l5: 0.000737, l6: 0.001116

[epoch: 316/1000, batch:    60/ 1052, ite: 82860] train loss: 0.005049, tar: 0.000266 
l0: 0.000197, l1: 0.000195, l2: 0.000221, l3: 0.000300, l4: 0.000538, l5: 0.001171, l6: 0.001783

[epoch: 316/1000, batch:   140/ 1052, ite: 82880] train loss: 0.005048, tar: 0.000266 
l0: 0.000213, l1: 0.000208, l2: 0.000246, l3: 0.000386, l4: 0.000666, l5: 0.001003, l6: 0.002259

[epoch: 316/1000, batch:   220/ 1052, ite: 82900] train loss: 0.005047, tar: 0.000266 
l0: 0.000278, l1: 0.000275, l2: 0.000310, l3: 0.000389, l4: 0.000530, l5: 0.001061, l6: 0.001529

[epoch: 316/1000, batch:   300/ 1052, ite: 82920] train loss: 0.005047, tar: 0.000266 
l0: 0.000253, l1: 0.000264, l2: 0.000279, l3: 0.000289, l4: 0.000497, l5: 0.000877, l6: 0.001876

[epoch: 316/1000, batch:   380/ 1052, ite: 82940] train loss: 0.005046, tar: 0.000266 
l0: 0.000250, l1: 0.000261, l2: 0.000283, l3: 0.000322, l4: 0.000475, l5: 0.001265, l6: 0.002156

[epoch: 316/1000, batch:   460/ 1052, ite: 82960] train loss: 0.005046, tar: 0.000266 
l0: 0.000141, l1: 0.000139, l2: 0.000197, l3: 0.000436, l4: 0.000585, l5: 0.001136, l6: 0.002400

[epoch: 316/1000, batch:   540/ 1052, ite: 82980] train loss: 0.005046, tar: 0.000266 
l0: 0.000336, l1: 0.000348, l2: 0.000384, l3: 0.000420, l4: 0.000768, l5: 0.001146, l6: 0.003911

[epoch: 316/1000, batch:   620/ 1052, ite: 83000] train loss: 0.005046, tar: 0.000266 
l0: 0.000338, l1: 0.000349, l2: 0.000384, l3: 0.000404, l4: 0.000736, l5: 0.001386, l6: 0.002105

[epoch: 316/1000, batch:   700/ 1052, ite: 83020] train loss: 0.005046, tar: 0.000266 
l0: 0.000153, l1: 0.000147, l2: 0.000188, l3: 0.000222, l4: 0.000369, l5: 0.000679, l6: 0.000997

[epoch: 316/1000, batch:   780/ 1052, ite: 83040] train loss: 0.005046, tar: 0.000265 
l0: 0.000220, l1: 0.000226, l2: 0.000239, l3: 0.000273, l4: 0.000416, l5: 0.000718, l6: 0.001186

[epoch: 316/1000, batch:   860/ 1052, ite: 83060] train loss: 0.005046, tar: 0.000265 
l0: 0.000178, l1: 0.000176, l2: 0.000211, l3: 0.000268, l4: 0.000464, l5: 0.001105, l6: 0.001710

[epoch: 316/1000, batch:   940/ 1052, ite: 83080] train loss: 0.005044, tar: 0.000265 
l0: 0.000262, l1: 0.000277, l2: 0.000296, l3: 0.000403, l4: 0.000775, l5: 0.001035, l6: 0.002215

[epoch: 316/1000, batch:  1020/ 1052, ite: 83100] train loss: 0.005044, tar: 0.000265 
[Epoch 316/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000107, l1: 0.000112, l2: 0.000115, l3: 0.000152, l4: 0.000235, l5: 0.000814, l6: 0.000885

[epoch: 317/1000, batch:    48/ 1052, ite: 83120] train loss: 0.005044, tar: 0.000265 
l0: 0.000241, l1: 0.000246, l2: 0.000245, l3: 0.000317, l4: 0.000529, l5: 0.001067, l6: 0.001951

[epoch: 317/1000, batch:   128/ 1052, ite: 83140] train loss: 0.005043, tar: 0.000265 
l0: 0.000298, l1: 0.000293, l2: 0.000374, l3: 0.000543, l4: 0.000860, l5: 0.001249, l6: 0.002915

[epoch: 317/1000, batch:   208/ 1052, ite: 83160] train loss: 0.005042, tar: 0.000265 
l0: 0.000140, l1: 0.000138, l2: 0.000175, l3: 0.000222, l4: 0.000423, l5: 0.000831, l6: 0.001012

[epoch: 317/1000, batch:   288/ 1052, ite: 83180] train loss: 0.005043, tar: 0.000265 
l0: 0.000266, l1: 0.000271, l2: 0.000341, l3: 0.000515, l4: 0.001156, l5: 0.002075, l6: 0.003217

[epoch: 317/1000, batch:   368/ 1052, ite: 83200] train loss: 0.005042, tar: 0.000265 
l0: 0.000082, l1: 0.000083, l2: 0.000099, l3: 0.000190, l4: 0.000353, l5: 0.000743, l6: 0.000830

[epoch: 317/1000, batch:   448/ 1052, ite: 83220] train loss: 0.005042, tar: 0.000265 
l0: 0.000069, l1: 0.000067, l2: 0.000105, l3: 0.000163, l4: 0.000381, l5: 0.000722, l6: 0.000685

[epoch: 317/1000, batch:   528/ 1052, ite: 83240] train loss: 0.005041, tar: 0.000264 
l0: 0.000208, l1: 0.000211, l2: 0.000232, l3: 0.000314, l4: 0.000750, l5: 0.001437, l6: 0.002185

[epoch: 317/1000, batch:   608/ 1052, ite: 83260] train loss: 0.005040, tar: 0.000264 
l0: 0.000106, l1: 0.000107, l2: 0.000114, l3: 0.000118, l4: 0.000297, l5: 0.000569, l6: 0.000810

[epoch: 317/1000, batch:   688/ 1052, ite: 83280] train loss: 0.005040, tar: 0.000264 
l0: 0.000289, l1: 0.000291, l2: 0.000325, l3: 0.000411, l4: 0.000753, l5: 0.001096, l6: 0.001685

[epoch: 317/1000, batch:   768/ 1052, ite: 83300] train loss: 0.005040, tar: 0.000264 
l0: 0.000202, l1: 0.000211, l2: 0.000256, l3: 0.000284, l4: 0.000474, l5: 0.000937, l6: 0.002193

[epoch: 317/1000, batch:   848/ 1052, ite: 83320] train loss: 0.005040, tar: 0.000264 
l0: 0.000169, l1: 0.000166, l2: 0.000210, l3: 0.000325, l4: 0.000767, l5: 0.001292, l6: 0.001810

[epoch: 317/1000, batch:   928/ 1052, ite: 83340] train loss: 0.005039, tar: 0.000264 
l0: 0.000157, l1: 0.000158, l2: 0.000198, l3: 0.000279, l4: 0.000475, l5: 0.000695, l6: 0.001288

[epoch: 317/1000, batch:  1008/ 1052, ite: 83360] train loss: 0.005038, tar: 0.000264 
[Epoch 317/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000089, l1: 0.000090, l2: 0.000104, l3: 0.000165, l4: 0.000441, l5: 0.000853, l6: 0.001028

[epoch: 318/1000, batch:    36/ 1052, ite: 83380] train loss: 0.005037, tar: 0.000264 
l0: 0.000312, l1: 0.000312, l2: 0.000330, l3: 0.000332, l4: 0.000466, l5: 0.000944, l6: 0.001450

[epoch: 318/1000, batch:   116/ 1052, ite: 83400] train loss: 0.005038, tar: 0.000264 
l0: 0.000224, l1: 0.000221, l2: 0.000231, l3: 0.000349, l4: 0.000479, l5: 0.001035, l6: 0.002732

[epoch: 318/1000, batch:   196/ 1052, ite: 83420] train loss: 0.005039, tar: 0.000264 
l0: 0.000202, l1: 0.000207, l2: 0.000211, l3: 0.000266, l4: 0.000450, l5: 0.001024, l6: 0.001502

[epoch: 318/1000, batch:   276/ 1052, ite: 83440] train loss: 0.005040, tar: 0.000264 
l0: 0.000194, l1: 0.000201, l2: 0.000222, l3: 0.000256, l4: 0.000333, l5: 0.000631, l6: 0.001654

[epoch: 318/1000, batch:   356/ 1052, ite: 83460] train loss: 0.005038, tar: 0.000264 
l0: 0.000121, l1: 0.000117, l2: 0.000157, l3: 0.000234, l4: 0.000390, l5: 0.000875, l6: 0.001208

[epoch: 318/1000, batch:   436/ 1052, ite: 83480] train loss: 0.005038, tar: 0.000264 
l0: 0.000190, l1: 0.000189, l2: 0.000231, l3: 0.000319, l4: 0.000662, l5: 0.000976, l6: 0.002127

[epoch: 318/1000, batch:   516/ 1052, ite: 83500] train loss: 0.005037, tar: 0.000263 
l0: 0.000243, l1: 0.000238, l2: 0.000282, l3: 0.000381, l4: 0.000742, l5: 0.001514, l6: 0.002568

[epoch: 318/1000, batch:   596/ 1052, ite: 83520] train loss: 0.005037, tar: 0.000263 
l0: 0.000251, l1: 0.000252, l2: 0.000332, l3: 0.000337, l4: 0.000398, l5: 0.001100, l6: 0.001785

[epoch: 318/1000, batch:   676/ 1052, ite: 83540] train loss: 0.005036, tar: 0.000263 
l0: 0.000541, l1: 0.000538, l2: 0.000600, l3: 0.000773, l4: 0.001177, l5: 0.001810, l6: 0.003345

[epoch: 318/1000, batch:   756/ 1052, ite: 83560] train loss: 0.005036, tar: 0.000263 
l0: 0.000295, l1: 0.000299, l2: 0.000330, l3: 0.000359, l4: 0.000605, l5: 0.000939, l6: 0.001818

[epoch: 318/1000, batch:   836/ 1052, ite: 83580] train loss: 0.005034, tar: 0.000263 
l0: 0.000196, l1: 0.000212, l2: 0.000211, l3: 0.000192, l4: 0.000438, l5: 0.000735, l6: 0.001587

[epoch: 318/1000, batch:   916/ 1052, ite: 83600] train loss: 0.005034, tar: 0.000263 
l0: 0.000282, l1: 0.000282, l2: 0.000348, l3: 0.000407, l4: 0.000820, l5: 0.001991, l6: 0.002698

[epoch: 318/1000, batch:   996/ 1052, ite: 83620] train loss: 0.005034, tar: 0.000263 
[Epoch 318/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000323, l1: 0.000326, l2: 0.000325, l3: 0.000422, l4: 0.000905, l5: 0.001081, l6: 0.002258

[epoch: 319/1000, batch:    24/ 1052, ite: 83640] train loss: 0.005033, tar: 0.000263 
l0: 0.000380, l1: 0.000401, l2: 0.000347, l3: 0.000441, l4: 0.000775, l5: 0.001748, l6: 0.002131

[epoch: 319/1000, batch:   104/ 1052, ite: 83660] train loss: 0.005033, tar: 0.000263 
l0: 0.000207, l1: 0.000205, l2: 0.000227, l3: 0.000337, l4: 0.000407, l5: 0.000701, l6: 0.001091

[epoch: 319/1000, batch:   184/ 1052, ite: 83680] train loss: 0.005032, tar: 0.000263 
l0: 0.000088, l1: 0.000087, l2: 0.000100, l3: 0.000186, l4: 0.000432, l5: 0.000516, l6: 0.000947

[epoch: 319/1000, batch:   264/ 1052, ite: 83700] train loss: 0.005031, tar: 0.000263 
l0: 0.000145, l1: 0.000142, l2: 0.000172, l3: 0.000223, l4: 0.000353, l5: 0.000826, l6: 0.002010

[epoch: 319/1000, batch:   344/ 1052, ite: 83720] train loss: 0.005031, tar: 0.000263 
l0: 0.000092, l1: 0.000097, l2: 0.000119, l3: 0.000114, l4: 0.000252, l5: 0.000326, l6: 0.000997

[epoch: 319/1000, batch:   424/ 1052, ite: 83740] train loss: 0.005030, tar: 0.000262 
l0: 0.000222, l1: 0.000226, l2: 0.000242, l3: 0.000277, l4: 0.000573, l5: 0.001124, l6: 0.002126

[epoch: 319/1000, batch:   504/ 1052, ite: 83760] train loss: 0.005030, tar: 0.000262 
l0: 0.000320, l1: 0.000350, l2: 0.000308, l3: 0.000340, l4: 0.000605, l5: 0.001268, l6: 0.002156

[epoch: 319/1000, batch:   584/ 1052, ite: 83780] train loss: 0.005029, tar: 0.000262 
l0: 0.000234, l1: 0.000234, l2: 0.000252, l3: 0.000373, l4: 0.000532, l5: 0.001227, l6: 0.001199

[epoch: 319/1000, batch:   664/ 1052, ite: 83800] train loss: 0.005028, tar: 0.000262 
l0: 0.000339, l1: 0.000348, l2: 0.000359, l3: 0.000418, l4: 0.000689, l5: 0.001268, l6: 0.002753

[epoch: 319/1000, batch:   744/ 1052, ite: 83820] train loss: 0.005029, tar: 0.000262 
l0: 0.000267, l1: 0.000261, l2: 0.000292, l3: 0.000406, l4: 0.000833, l5: 0.001600, l6: 0.001412

[epoch: 319/1000, batch:   824/ 1052, ite: 83840] train loss: 0.005028, tar: 0.000262 
l0: 0.000182, l1: 0.000193, l2: 0.000186, l3: 0.000317, l4: 0.000525, l5: 0.001268, l6: 0.001806

[epoch: 319/1000, batch:   904/ 1052, ite: 83860] train loss: 0.005027, tar: 0.000262 
l0: 0.000206, l1: 0.000198, l2: 0.000223, l3: 0.000329, l4: 0.000541, l5: 0.000889, l6: 0.001341

[epoch: 319/1000, batch:   984/ 1052, ite: 83880] train loss: 0.005027, tar: 0.000262 
[Epoch 319/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000284, l1: 0.000304, l2: 0.000381, l3: 0.000464, l4: 0.000826, l5: 0.001624, l6: 0.002493

[epoch: 320/1000, batch:    12/ 1052, ite: 83900] train loss: 0.005027, tar: 0.000262 
l0: 0.000159, l1: 0.000173, l2: 0.000153, l3: 0.000242, l4: 0.000350, l5: 0.000745, l6: 0.001270

[epoch: 320/1000, batch:    92/ 1052, ite: 83920] train loss: 0.005025, tar: 0.000262 
l0: 0.000383, l1: 0.000393, l2: 0.000390, l3: 0.000467, l4: 0.000820, l5: 0.001849, l6: 0.002731

[epoch: 320/1000, batch:   172/ 1052, ite: 83940] train loss: 0.005026, tar: 0.000262 
l0: 0.000354, l1: 0.000356, l2: 0.000380, l3: 0.000576, l4: 0.000912, l5: 0.001371, l6: 0.002001

[epoch: 320/1000, batch:   252/ 1052, ite: 83960] train loss: 0.005026, tar: 0.000262 
l0: 0.000127, l1: 0.000131, l2: 0.000156, l3: 0.000192, l4: 0.000481, l5: 0.001014, l6: 0.001606

[epoch: 320/1000, batch:   332/ 1052, ite: 83980] train loss: 0.005025, tar: 0.000262 
l0: 0.000311, l1: 0.000305, l2: 0.000381, l3: 0.000497, l4: 0.000926, l5: 0.001549, l6: 0.002833

[epoch: 320/1000, batch:   412/ 1052, ite: 84000] train loss: 0.005025, tar: 0.000262 
l0: 0.000249, l1: 0.000264, l2: 0.000247, l3: 0.000426, l4: 0.000808, l5: 0.001169, l6: 0.002414

[epoch: 320/1000, batch:   492/ 1052, ite: 84020] train loss: 0.005025, tar: 0.000262 
l0: 0.000067, l1: 0.000069, l2: 0.000086, l3: 0.000105, l4: 0.000215, l5: 0.000493, l6: 0.000972

[epoch: 320/1000, batch:   572/ 1052, ite: 84040] train loss: 0.005025, tar: 0.000261 
l0: 0.000181, l1: 0.000177, l2: 0.000216, l3: 0.000342, l4: 0.000592, l5: 0.000801, l6: 0.001647

[epoch: 320/1000, batch:   652/ 1052, ite: 84060] train loss: 0.005025, tar: 0.000261 
l0: 0.000177, l1: 0.000192, l2: 0.000171, l3: 0.000184, l4: 0.000499, l5: 0.001181, l6: 0.001506

[epoch: 320/1000, batch:   732/ 1052, ite: 84080] train loss: 0.005024, tar: 0.000261 
l0: 0.000239, l1: 0.000242, l2: 0.000279, l3: 0.000298, l4: 0.000426, l5: 0.001060, l6: 0.002028

[epoch: 320/1000, batch:   812/ 1052, ite: 84100] train loss: 0.005023, tar: 0.000261 
l0: 0.000293, l1: 0.000298, l2: 0.000318, l3: 0.000338, l4: 0.000476, l5: 0.001454, l6: 0.003625

[epoch: 320/1000, batch:   892/ 1052, ite: 84120] train loss: 0.005023, tar: 0.000261 
l0: 0.000235, l1: 0.000240, l2: 0.000241, l3: 0.000283, l4: 0.000476, l5: 0.000844, l6: 0.002473

[epoch: 320/1000, batch:   972/ 1052, ite: 84140] train loss: 0.005023, tar: 0.000261 
l0: 0.000370, l1: 0.000370, l2: 0.000388, l3: 0.000549, l4: 0.000973, l5: 0.001730, l6: 0.003272

[epoch: 320/1000, batch:  1052/ 1052, ite: 84160] train loss: 0.005022, tar: 0.000261 
[Epoch 320/1000] Test loss: 0.012, Test target loss: 0.001
l0: 0.000181, l1: 0.000176, l2: 0.000228, l3: 0.000383, l4: 0.000789, l5: 0.000998, l6: 0.002645

[epoch: 321/1000, batch:    80/ 1052, ite: 84180] train loss: 0.004412, tar: 0.000204 
l0: 0.000187, l1: 0.000187, l2: 0.000219, l3: 0.000332, l4: 0.000645, l5: 0.000865, l6: 0.001679

[epoch: 321/1000, batch:   160/ 1052, ite: 84200] train loss: 0.004726, tar: 0.000219 
l0: 0.000191, l1: 0.000180, l2: 0.000244, l3: 0.000279, l4: 0.000463, l5: 0.001105, l6: 0.001417

[epoch: 321/1000, batch:   240/ 1052, ite: 84220] train loss: 0.004850, tar: 0.000221 
l0: 0.000188, l1: 0.000188, l2: 0.000208, l3: 0.000302, l4: 0.000388, l5: 0.000997, l6: 0.002031

[epoch: 321/1000, batch:   320/ 1052, ite: 84240] train loss: 0.004812, tar: 0.000221 
l0: 0.000385, l1: 0.000384, l2: 0.000416, l3: 0.000488, l4: 0.000940, l5: 0.001858, l6: 0.002799

[epoch: 321/1000, batch:   400/ 1052, ite: 84260] train loss: 0.004910, tar: 0.000223 
l0: 0.000187, l1: 0.000184, l2: 0.000223, l3: 0.000262, l4: 0.000448, l5: 0.000635, l6: 0.001639

[epoch: 321/1000, batch:   480/ 1052, ite: 84280] train loss: 0.005005, tar: 0.000231 
l0: 0.000185, l1: 0.000182, l2: 0.000200, l3: 0.000253, l4: 0.000415, l5: 0.000628, l6: 0.001664

[epoch: 321/1000, batch:   560/ 1052, ite: 84300] train loss: 0.005015, tar: 0.000240 
l0: 0.000099, l1: 0.000097, l2: 0.000127, l3: 0.000152, l4: 0.000348, l5: 0.000846, l6: 0.001424

[epoch: 321/1000, batch:   640/ 1052, ite: 84320] train loss: 0.004971, tar: 0.000238 
l0: 0.000260, l1: 0.000271, l2: 0.000252, l3: 0.000290, l4: 0.000667, l5: 0.001108, l6: 0.002183

[epoch: 321/1000, batch:   720/ 1052, ite: 84340] train loss: 0.004952, tar: 0.000239 
l0: 0.000203, l1: 0.000201, l2: 0.000249, l3: 0.000320, l4: 0.000595, l5: 0.001188, l6: 0.002319

[epoch: 321/1000, batch:   800/ 1052, ite: 84360] train loss: 0.004883, tar: 0.000236 
l0: 0.000268, l1: 0.000271, l2: 0.000318, l3: 0.000376, l4: 0.000693, l5: 0.001040, l6: 0.001966

[epoch: 321/1000, batch:   880/ 1052, ite: 84380] train loss: 0.004867, tar: 0.000235 
l0: 0.000386, l1: 0.000382, l2: 0.000434, l3: 0.000567, l4: 0.000666, l5: 0.001810, l6: 0.003227

[epoch: 321/1000, batch:   960/ 1052, ite: 84400] train loss: 0.004949, tar: 0.000237 
l0: 0.000234, l1: 0.000233, l2: 0.000284, l3: 0.000340, l4: 0.000557, l5: 0.001118, l6: 0.001483

[epoch: 321/1000, batch:  1040/ 1052, ite: 84420] train loss: 0.004942, tar: 0.000235 
[Epoch 321/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000218, l1: 0.000213, l2: 0.000247, l3: 0.000330, l4: 0.000387, l5: 0.000669, l6: 0.001966

[epoch: 322/1000, batch:    68/ 1052, ite: 84440] train loss: 0.004935, tar: 0.000234 
l0: 0.000125, l1: 0.000122, l2: 0.000148, l3: 0.000232, l4: 0.000426, l5: 0.000537, l6: 0.001110

[epoch: 322/1000, batch:   148/ 1052, ite: 84460] train loss: 0.004880, tar: 0.000230 
l0: 0.000250, l1: 0.000250, l2: 0.000279, l3: 0.000372, l4: 0.000521, l5: 0.001986, l6: 0.003881

[epoch: 322/1000, batch:   228/ 1052, ite: 84480] train loss: 0.004918, tar: 0.000230 
l0: 0.000270, l1: 0.000275, l2: 0.000309, l3: 0.000374, l4: 0.000879, l5: 0.000869, l6: 0.002003

[epoch: 322/1000, batch:   308/ 1052, ite: 84500] train loss: 0.004905, tar: 0.000230 
l0: 0.000245, l1: 0.000239, l2: 0.000362, l3: 0.000585, l4: 0.001221, l5: 0.001659, l6: 0.002876

[epoch: 322/1000, batch:   388/ 1052, ite: 84520] train loss: 0.004888, tar: 0.000228 
l0: 0.000209, l1: 0.000214, l2: 0.000242, l3: 0.000298, l4: 0.000525, l5: 0.001267, l6: 0.001854

[epoch: 322/1000, batch:   468/ 1052, ite: 84540] train loss: 0.004882, tar: 0.000228 
l0: 0.000106, l1: 0.000104, l2: 0.000149, l3: 0.000191, l4: 0.000453, l5: 0.001043, l6: 0.001399

[epoch: 322/1000, batch:   548/ 1052, ite: 84560] train loss: 0.004864, tar: 0.000228 
l0: 0.000158, l1: 0.000160, l2: 0.000207, l3: 0.000240, l4: 0.000347, l5: 0.000833, l6: 0.001068

[epoch: 322/1000, batch:   628/ 1052, ite: 84580] train loss: 0.004859, tar: 0.000227 
l0: 0.000248, l1: 0.000251, l2: 0.000279, l3: 0.000401, l4: 0.000643, l5: 0.001051, l6: 0.002645

[epoch: 322/1000, batch:   708/ 1052, ite: 84600] train loss: 0.004867, tar: 0.000228 
l0: 0.000306, l1: 0.000300, l2: 0.000355, l3: 0.000373, l4: 0.000577, l5: 0.001036, l6: 0.002046

[epoch: 322/1000, batch:   788/ 1052, ite: 84620] train loss: 0.004864, tar: 0.000228 
l0: 0.000220, l1: 0.000225, l2: 0.000238, l3: 0.000320, l4: 0.000567, l5: 0.001361, l6: 0.002228

[epoch: 322/1000, batch:   868/ 1052, ite: 84640] train loss: 0.004857, tar: 0.000228 
l0: 0.000134, l1: 0.000133, l2: 0.000169, l3: 0.000269, l4: 0.000416, l5: 0.000825, l6: 0.001493

[epoch: 322/1000, batch:   948/ 1052, ite: 84660] train loss: 0.004832, tar: 0.000226 
l0: 0.000139, l1: 0.000147, l2: 0.000164, l3: 0.000167, l4: 0.000467, l5: 0.000928, l6: 0.002275

[epoch: 322/1000, batch:  1028/ 1052, ite: 84680] train loss: 0.004864, tar: 0.000228 
[Epoch 322/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000242, l1: 0.000245, l2: 0.000277, l3: 0.000386, l4: 0.000827, l5: 0.001809, l6: 0.002922

[epoch: 323/1000, batch:    56/ 1052, ite: 84700] train loss: 0.004877, tar: 0.000229 
l0: 0.000133, l1: 0.000135, l2: 0.000157, l3: 0.000197, l4: 0.000361, l5: 0.000558, l6: 0.001400

[epoch: 323/1000, batch:   136/ 1052, ite: 84720] train loss: 0.004891, tar: 0.000230 
l0: 0.000098, l1: 0.000099, l2: 0.000114, l3: 0.000119, l4: 0.000266, l5: 0.000528, l6: 0.000833

[epoch: 323/1000, batch:   216/ 1052, ite: 84740] train loss: 0.004879, tar: 0.000230 
l0: 0.000205, l1: 0.000208, l2: 0.000220, l3: 0.000389, l4: 0.000766, l5: 0.001593, l6: 0.001979

[epoch: 323/1000, batch:   296/ 1052, ite: 84760] train loss: 0.004904, tar: 0.000231 
l0: 0.000219, l1: 0.000216, l2: 0.000280, l3: 0.000563, l4: 0.001245, l5: 0.001808, l6: 0.002636

[epoch: 323/1000, batch:   376/ 1052, ite: 84780] train loss: 0.004907, tar: 0.000230 
l0: 0.000184, l1: 0.000187, l2: 0.000229, l3: 0.000282, l4: 0.000631, l5: 0.001108, l6: 0.001732

[epoch: 323/1000, batch:   456/ 1052, ite: 84800] train loss: 0.004887, tar: 0.000229 
l0: 0.000100, l1: 0.000101, l2: 0.000130, l3: 0.000248, l4: 0.000381, l5: 0.000501, l6: 0.001258

[epoch: 323/1000, batch:   536/ 1052, ite: 84820] train loss: 0.004883, tar: 0.000228 
l0: 0.000113, l1: 0.000115, l2: 0.000159, l3: 0.000234, l4: 0.000520, l5: 0.001035, l6: 0.001105

[epoch: 323/1000, batch:   616/ 1052, ite: 84840] train loss: 0.004875, tar: 0.000227 
l0: 0.000138, l1: 0.000137, l2: 0.000147, l3: 0.000247, l4: 0.000307, l5: 0.000762, l6: 0.001259

[epoch: 323/1000, batch:   696/ 1052, ite: 84860] train loss: 0.004880, tar: 0.000227 
l0: 0.000191, l1: 0.000198, l2: 0.000180, l3: 0.000249, l4: 0.000362, l5: 0.000915, l6: 0.001307

[epoch: 323/1000, batch:   776/ 1052, ite: 84880] train loss: 0.004883, tar: 0.000227 
l0: 0.000151, l1: 0.000156, l2: 0.000156, l3: 0.000206, l4: 0.000289, l5: 0.000642, l6: 0.001348

[epoch: 323/1000, batch:   856/ 1052, ite: 84900] train loss: 0.004868, tar: 0.000227 
l0: 0.000436, l1: 0.000430, l2: 0.000470, l3: 0.000554, l4: 0.000600, l5: 0.001161, l6: 0.002628

[epoch: 323/1000, batch:   936/ 1052, ite: 84920] train loss: 0.004857, tar: 0.000226 
l0: 0.000122, l1: 0.000128, l2: 0.000138, l3: 0.000212, l4: 0.000349, l5: 0.000720, l6: 0.001562

[epoch: 323/1000, batch:  1016/ 1052, ite: 84940] train loss: 0.004864, tar: 0.000227 
[Epoch 323/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000335, l1: 0.000343, l2: 0.000395, l3: 0.000492, l4: 0.000750, l5: 0.001479, l6: 0.001847

[epoch: 324/1000, batch:    44/ 1052, ite: 84960] train loss: 0.004878, tar: 0.000227 
l0: 0.000206, l1: 0.000206, l2: 0.000226, l3: 0.000240, l4: 0.000474, l5: 0.001194, l6: 0.002088

[epoch: 324/1000, batch:   124/ 1052, ite: 84980] train loss: 0.004871, tar: 0.000226 
l0: 0.000299, l1: 0.000295, l2: 0.000352, l3: 0.000463, l4: 0.000812, l5: 0.001405, l6: 0.002304

[epoch: 324/1000, batch:   204/ 1052, ite: 85000] train loss: 0.004880, tar: 0.000227 
l0: 0.000233, l1: 0.000230, l2: 0.000247, l3: 0.000297, l4: 0.000554, l5: 0.001199, l6: 0.002012

[epoch: 324/1000, batch:   284/ 1052, ite: 85020] train loss: 0.004886, tar: 0.000227 
l0: 0.000215, l1: 0.000218, l2: 0.000245, l3: 0.000304, l4: 0.000678, l5: 0.000901, l6: 0.002130

[epoch: 324/1000, batch:   364/ 1052, ite: 85040] train loss: 0.004881, tar: 0.000226 
l0: 0.000230, l1: 0.000225, l2: 0.000276, l3: 0.000384, l4: 0.000673, l5: 0.001107, l6: 0.001560

[epoch: 324/1000, batch:   444/ 1052, ite: 85060] train loss: 0.004871, tar: 0.000225 
l0: 0.000177, l1: 0.000182, l2: 0.000196, l3: 0.000310, l4: 0.000661, l5: 0.001190, l6: 0.002040

[epoch: 324/1000, batch:   524/ 1052, ite: 85080] train loss: 0.004868, tar: 0.000225 
l0: 0.000088, l1: 0.000090, l2: 0.000111, l3: 0.000137, l4: 0.000371, l5: 0.000631, l6: 0.000930

[epoch: 324/1000, batch:   604/ 1052, ite: 85100] train loss: 0.004851, tar: 0.000224 
l0: 0.000249, l1: 0.000246, l2: 0.000282, l3: 0.000390, l4: 0.000620, l5: 0.001124, l6: 0.001868

[epoch: 324/1000, batch:   684/ 1052, ite: 85120] train loss: 0.004844, tar: 0.000224 
l0: 0.000301, l1: 0.000298, l2: 0.000315, l3: 0.000333, l4: 0.000486, l5: 0.001239, l6: 0.002163

[epoch: 324/1000, batch:   764/ 1052, ite: 85140] train loss: 0.004836, tar: 0.000224 
l0: 0.000321, l1: 0.000322, l2: 0.000372, l3: 0.000404, l4: 0.000550, l5: 0.000893, l6: 0.002078

[epoch: 324/1000, batch:   844/ 1052, ite: 85160] train loss: 0.004842, tar: 0.000224 
l0: 0.000096, l1: 0.000096, l2: 0.000120, l3: 0.000159, l4: 0.000325, l5: 0.000872, l6: 0.001195

[epoch: 324/1000, batch:   924/ 1052, ite: 85180] train loss: 0.004848, tar: 0.000224 
l0: 0.000121, l1: 0.000121, l2: 0.000137, l3: 0.000179, l4: 0.000353, l5: 0.000995, l6: 0.001218

[epoch: 324/1000, batch:  1004/ 1052, ite: 85200] train loss: 0.004845, tar: 0.000224 
[Epoch 324/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000074, l1: 0.000091, l2: 0.000114, l3: 0.000155, l4: 0.000230, l5: 0.000746, l6: 0.001059

[epoch: 325/1000, batch:    32/ 1052, ite: 85220] train loss: 0.004844, tar: 0.000224 
l0: 0.000367, l1: 0.000363, l2: 0.000416, l3: 0.000493, l4: 0.000917, l5: 0.001418, l6: 0.003245

[epoch: 325/1000, batch:   112/ 1052, ite: 85240] train loss: 0.004851, tar: 0.000224 
l0: 0.000195, l1: 0.000195, l2: 0.000228, l3: 0.000298, l4: 0.000613, l5: 0.001182, l6: 0.001665

[epoch: 325/1000, batch:   192/ 1052, ite: 85260] train loss: 0.004843, tar: 0.000223 
l0: 0.000373, l1: 0.000363, l2: 0.000435, l3: 0.000475, l4: 0.000555, l5: 0.001097, l6: 0.001178

[epoch: 325/1000, batch:   272/ 1052, ite: 85280] train loss: 0.004851, tar: 0.000224 
l0: 0.000235, l1: 0.000244, l2: 0.000272, l3: 0.000278, l4: 0.000438, l5: 0.000939, l6: 0.001733

[epoch: 325/1000, batch:   352/ 1052, ite: 85300] train loss: 0.004852, tar: 0.000224 
l0: 0.000151, l1: 0.000152, l2: 0.000170, l3: 0.000219, l4: 0.000312, l5: 0.000754, l6: 0.000814

[epoch: 325/1000, batch:   432/ 1052, ite: 85320] train loss: 0.004855, tar: 0.000225 
l0: 0.000203, l1: 0.000212, l2: 0.000190, l3: 0.000248, l4: 0.000385, l5: 0.000828, l6: 0.001331

[epoch: 325/1000, batch:   512/ 1052, ite: 85340] train loss: 0.004853, tar: 0.000224 
l0: 0.000183, l1: 0.000190, l2: 0.000196, l3: 0.000271, l4: 0.000409, l5: 0.000794, l6: 0.002223

[epoch: 325/1000, batch:   592/ 1052, ite: 85360] train loss: 0.004850, tar: 0.000224 
l0: 0.000139, l1: 0.000140, l2: 0.000211, l3: 0.000290, l4: 0.000627, l5: 0.000754, l6: 0.002337

[epoch: 325/1000, batch:   672/ 1052, ite: 85380] train loss: 0.004854, tar: 0.000225 
l0: 0.000172, l1: 0.000179, l2: 0.000238, l3: 0.000371, l4: 0.000777, l5: 0.001459, l6: 0.002462

[epoch: 325/1000, batch:   752/ 1052, ite: 85400] train loss: 0.004842, tar: 0.000224 
l0: 0.000284, l1: 0.000287, l2: 0.000306, l3: 0.000375, l4: 0.000666, l5: 0.001126, l6: 0.002767

[epoch: 325/1000, batch:   832/ 1052, ite: 85420] train loss: 0.004847, tar: 0.000225 
l0: 0.000180, l1: 0.000188, l2: 0.000195, l3: 0.000250, l4: 0.000514, l5: 0.001353, l6: 0.002175

[epoch: 325/1000, batch:   912/ 1052, ite: 85440] train loss: 0.004839, tar: 0.000224 
l0: 0.000191, l1: 0.000192, l2: 0.000212, l3: 0.000322, l4: 0.000404, l5: 0.000776, l6: 0.001767

[epoch: 325/1000, batch:   992/ 1052, ite: 85460] train loss: 0.004831, tar: 0.000224 
[Epoch 325/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000287, l1: 0.000283, l2: 0.000355, l3: 0.000394, l4: 0.000695, l5: 0.000952, l6: 0.002610

[epoch: 326/1000, batch:    20/ 1052, ite: 85480] train loss: 0.004826, tar: 0.000223 
l0: 0.000123, l1: 0.000119, l2: 0.000164, l3: 0.000189, l4: 0.000274, l5: 0.000682, l6: 0.001215

[epoch: 326/1000, batch:   100/ 1052, ite: 85500] train loss: 0.004820, tar: 0.000223 
l0: 0.000135, l1: 0.000144, l2: 0.000161, l3: 0.000238, l4: 0.000397, l5: 0.001262, l6: 0.002028

[epoch: 326/1000, batch:   180/ 1052, ite: 85520] train loss: 0.004820, tar: 0.000223 
l0: 0.000421, l1: 0.000413, l2: 0.000538, l3: 0.000649, l4: 0.001199, l5: 0.002055, l6: 0.004804

[epoch: 326/1000, batch:   260/ 1052, ite: 85540] train loss: 0.004815, tar: 0.000223 
l0: 0.000502, l1: 0.000519, l2: 0.000535, l3: 0.000682, l4: 0.001097, l5: 0.002114, l6: 0.004810

[epoch: 326/1000, batch:   340/ 1052, ite: 85560] train loss: 0.004817, tar: 0.000223 
l0: 0.000332, l1: 0.000338, l2: 0.000348, l3: 0.000433, l4: 0.000654, l5: 0.001235, l6: 0.002397

[epoch: 326/1000, batch:   420/ 1052, ite: 85580] train loss: 0.004811, tar: 0.000223 
l0: 0.000157, l1: 0.000171, l2: 0.000246, l3: 0.000285, l4: 0.000563, l5: 0.001032, l6: 0.001453

[epoch: 326/1000, batch:   500/ 1052, ite: 85600] train loss: 0.004818, tar: 0.000223 
l0: 0.000264, l1: 0.000268, l2: 0.000309, l3: 0.000330, l4: 0.000602, l5: 0.001302, l6: 0.002912

[epoch: 326/1000, batch:   580/ 1052, ite: 85620] train loss: 0.004813, tar: 0.000222 
l0: 0.000318, l1: 0.000321, l2: 0.000307, l3: 0.000408, l4: 0.000573, l5: 0.001165, l6: 0.002043

[epoch: 326/1000, batch:   660/ 1052, ite: 85640] train loss: 0.004808, tar: 0.000222 
l0: 0.000413, l1: 0.000412, l2: 0.000458, l3: 0.000522, l4: 0.001067, l5: 0.002339, l6: 0.003420

[epoch: 326/1000, batch:   740/ 1052, ite: 85660] train loss: 0.004807, tar: 0.000222 
l0: 0.000207, l1: 0.000206, l2: 0.000250, l3: 0.000314, l4: 0.000607, l5: 0.000594, l6: 0.001779

[epoch: 326/1000, batch:   820/ 1052, ite: 85680] train loss: 0.004802, tar: 0.000221 
l0: 0.000276, l1: 0.000281, l2: 0.000301, l3: 0.000462, l4: 0.000526, l5: 0.000989, l6: 0.002439

[epoch: 326/1000, batch:   900/ 1052, ite: 85700] train loss: 0.004799, tar: 0.000221 
l0: 0.000145, l1: 0.000143, l2: 0.000182, l3: 0.000201, l4: 0.000321, l5: 0.000825, l6: 0.000816

[epoch: 326/1000, batch:   980/ 1052, ite: 85720] train loss: 0.004805, tar: 0.000221 
[Epoch 326/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000120, l1: 0.000121, l2: 0.000134, l3: 0.000180, l4: 0.000353, l5: 0.000386, l6: 0.001404

[epoch: 327/1000, batch:     8/ 1052, ite: 85740] train loss: 0.004806, tar: 0.000221 
l0: 0.000228, l1: 0.000229, l2: 0.000240, l3: 0.000300, l4: 0.000685, l5: 0.001272, l6: 0.002096

[epoch: 327/1000, batch:    88/ 1052, ite: 85760] train loss: 0.004804, tar: 0.000221 
l0: 0.000230, l1: 0.000234, l2: 0.000243, l3: 0.000280, l4: 0.000482, l5: 0.001049, l6: 0.001157

[epoch: 327/1000, batch:   168/ 1052, ite: 85780] train loss: 0.004801, tar: 0.000221 
l0: 0.000465, l1: 0.000488, l2: 0.000474, l3: 0.000622, l4: 0.001314, l5: 0.002382, l6: 0.003706

[epoch: 327/1000, batch:   248/ 1052, ite: 85800] train loss: 0.004811, tar: 0.000221 
l0: 0.000188, l1: 0.000188, l2: 0.000207, l3: 0.000257, l4: 0.000372, l5: 0.000993, l6: 0.001224

[epoch: 327/1000, batch:   328/ 1052, ite: 85820] train loss: 0.004807, tar: 0.000221 
l0: 0.000292, l1: 0.000290, l2: 0.000346, l3: 0.000588, l4: 0.000832, l5: 0.001091, l6: 0.002264

[epoch: 327/1000, batch:   408/ 1052, ite: 85840] train loss: 0.004813, tar: 0.000222 
l0: 0.000150, l1: 0.000150, l2: 0.000171, l3: 0.000229, l4: 0.000338, l5: 0.000743, l6: 0.001449

[epoch: 327/1000, batch:   488/ 1052, ite: 85860] train loss: 0.004807, tar: 0.000221 
l0: 0.000169, l1: 0.000175, l2: 0.000194, l3: 0.000236, l4: 0.000405, l5: 0.000912, l6: 0.001125

[epoch: 327/1000, batch:   568/ 1052, ite: 85880] train loss: 0.004809, tar: 0.000221 
l0: 0.000206, l1: 0.000206, l2: 0.000285, l3: 0.000363, l4: 0.000533, l5: 0.001071, l6: 0.001875

[epoch: 327/1000, batch:   648/ 1052, ite: 85900] train loss: 0.004804, tar: 0.000221 
l0: 0.000177, l1: 0.000172, l2: 0.000234, l3: 0.000360, l4: 0.000889, l5: 0.002032, l6: 0.003044

[epoch: 327/1000, batch:   728/ 1052, ite: 85920] train loss: 0.004808, tar: 0.000221 
l0: 0.000139, l1: 0.000149, l2: 0.000140, l3: 0.000188, l4: 0.000226, l5: 0.000533, l6: 0.000891

[epoch: 327/1000, batch:   808/ 1052, ite: 85940] train loss: 0.004805, tar: 0.000221 
l0: 0.000160, l1: 0.000162, l2: 0.000186, l3: 0.000181, l4: 0.000290, l5: 0.000595, l6: 0.000959

[epoch: 327/1000, batch:   888/ 1052, ite: 85960] train loss: 0.004802, tar: 0.000221 
l0: 0.000195, l1: 0.000200, l2: 0.000242, l3: 0.000480, l4: 0.000698, l5: 0.001488, l6: 0.001851

[epoch: 327/1000, batch:   968/ 1052, ite: 85980] train loss: 0.004802, tar: 0.000221 
l0: 0.000105, l1: 0.000104, l2: 0.000144, l3: 0.000203, l4: 0.000533, l5: 0.000947, l6: 0.001252

[epoch: 327/1000, batch:  1048/ 1052, ite: 86000] train loss: 0.004803, tar: 0.000221 
[Epoch 327/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000198, l1: 0.000198, l2: 0.000278, l3: 0.000329, l4: 0.000777, l5: 0.002062, l6: 0.003143

[epoch: 328/1000, batch:    76/ 1052, ite: 86020] train loss: 0.004803, tar: 0.000221 
l0: 0.000166, l1: 0.000166, l2: 0.000200, l3: 0.000232, l4: 0.000347, l5: 0.000929, l6: 0.001954

[epoch: 328/1000, batch:   156/ 1052, ite: 86040] train loss: 0.004806, tar: 0.000221 
l0: 0.000163, l1: 0.000173, l2: 0.000174, l3: 0.000242, l4: 0.000457, l5: 0.001161, l6: 0.001493

[epoch: 328/1000, batch:   236/ 1052, ite: 86060] train loss: 0.004802, tar: 0.000221 
l0: 0.000235, l1: 0.000234, l2: 0.000280, l3: 0.000524, l4: 0.000934, l5: 0.001521, l6: 0.002258

[epoch: 328/1000, batch:   316/ 1052, ite: 86080] train loss: 0.004810, tar: 0.000221 
l0: 0.000190, l1: 0.000198, l2: 0.000196, l3: 0.000226, l4: 0.000461, l5: 0.000929, l6: 0.002113

[epoch: 328/1000, batch:   396/ 1052, ite: 86100] train loss: 0.004806, tar: 0.000221 
l0: 0.000197, l1: 0.000198, l2: 0.000321, l3: 0.000382, l4: 0.000836, l5: 0.001533, l6: 0.001951

[epoch: 328/1000, batch:   476/ 1052, ite: 86120] train loss: 0.004806, tar: 0.000221 
l0: 0.000123, l1: 0.000121, l2: 0.000148, l3: 0.000215, l4: 0.000352, l5: 0.000856, l6: 0.001693

[epoch: 328/1000, batch:   556/ 1052, ite: 86140] train loss: 0.004805, tar: 0.000221 
l0: 0.000200, l1: 0.000199, l2: 0.000241, l3: 0.000331, l4: 0.000616, l5: 0.001136, l6: 0.001355

[epoch: 328/1000, batch:   636/ 1052, ite: 86160] train loss: 0.004807, tar: 0.000221 
l0: 0.000197, l1: 0.000217, l2: 0.000190, l3: 0.000219, l4: 0.000357, l5: 0.000968, l6: 0.001268

[epoch: 328/1000, batch:   716/ 1052, ite: 86180] train loss: 0.004807, tar: 0.000221 
l0: 0.000195, l1: 0.000198, l2: 0.000225, l3: 0.000292, l4: 0.000575, l5: 0.001416, l6: 0.002117

[epoch: 328/1000, batch:   796/ 1052, ite: 86200] train loss: 0.004805, tar: 0.000221 
l0: 0.000237, l1: 0.000235, l2: 0.000347, l3: 0.000516, l4: 0.000866, l5: 0.001824, l6: 0.002982

[epoch: 328/1000, batch:   876/ 1052, ite: 86220] train loss: 0.004805, tar: 0.000220 
l0: 0.000135, l1: 0.000127, l2: 0.000158, l3: 0.000166, l4: 0.000356, l5: 0.000749, l6: 0.001269

[epoch: 328/1000, batch:   956/ 1052, ite: 86240] train loss: 0.004803, tar: 0.000220 
l0: 0.000149, l1: 0.000147, l2: 0.000181, l3: 0.000234, l4: 0.000430, l5: 0.000741, l6: 0.001746

[epoch: 328/1000, batch:  1036/ 1052, ite: 86260] train loss: 0.004805, tar: 0.000220 
[Epoch 328/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000387, l1: 0.000391, l2: 0.000404, l3: 0.000406, l4: 0.000785, l5: 0.001589, l6: 0.003477

[epoch: 329/1000, batch:    64/ 1052, ite: 86280] train loss: 0.004803, tar: 0.000220 
l0: 0.000319, l1: 0.000320, l2: 0.000351, l3: 0.000444, l4: 0.000725, l5: 0.001792, l6: 0.003728

[epoch: 329/1000, batch:   144/ 1052, ite: 86300] train loss: 0.004802, tar: 0.000220 
l0: 0.000140, l1: 0.000143, l2: 0.000174, l3: 0.000287, l4: 0.000472, l5: 0.000964, l6: 0.001385

[epoch: 329/1000, batch:   224/ 1052, ite: 86320] train loss: 0.004803, tar: 0.000220 
l0: 0.000155, l1: 0.000153, l2: 0.000153, l3: 0.000218, l4: 0.000308, l5: 0.000563, l6: 0.001203

[epoch: 329/1000, batch:   304/ 1052, ite: 86340] train loss: 0.004801, tar: 0.000219 
l0: 0.000101, l1: 0.000104, l2: 0.000121, l3: 0.000137, l4: 0.000228, l5: 0.000842, l6: 0.001177

[epoch: 329/1000, batch:   384/ 1052, ite: 86360] train loss: 0.004796, tar: 0.000219 
l0: 0.000202, l1: 0.000201, l2: 0.000236, l3: 0.000368, l4: 0.000621, l5: 0.001237, l6: 0.002610

[epoch: 329/1000, batch:   464/ 1052, ite: 86380] train loss: 0.004797, tar: 0.000219 
l0: 0.000416, l1: 0.000434, l2: 0.000427, l3: 0.000531, l4: 0.000837, l5: 0.001803, l6: 0.004737

[epoch: 329/1000, batch:   544/ 1052, ite: 86400] train loss: 0.004797, tar: 0.000219 
l0: 0.000212, l1: 0.000211, l2: 0.000239, l3: 0.000377, l4: 0.000591, l5: 0.000828, l6: 0.002295

[epoch: 329/1000, batch:   624/ 1052, ite: 86420] train loss: 0.004793, tar: 0.000219 
l0: 0.000349, l1: 0.000347, l2: 0.000355, l3: 0.000409, l4: 0.000666, l5: 0.001219, l6: 0.002897

[epoch: 329/1000, batch:   704/ 1052, ite: 86440] train loss: 0.004795, tar: 0.000219 
l0: 0.000117, l1: 0.000116, l2: 0.000150, l3: 0.000216, l4: 0.000454, l5: 0.000722, l6: 0.001382

[epoch: 329/1000, batch:   784/ 1052, ite: 86460] train loss: 0.004794, tar: 0.000219 
l0: 0.000310, l1: 0.000333, l2: 0.000331, l3: 0.000470, l4: 0.000890, l5: 0.001766, l6: 0.004555

[epoch: 329/1000, batch:   864/ 1052, ite: 86480] train loss: 0.004802, tar: 0.000220 
l0: 0.000142, l1: 0.000146, l2: 0.000169, l3: 0.000209, l4: 0.000374, l5: 0.000717, l6: 0.001713

[epoch: 329/1000, batch:   944/ 1052, ite: 86500] train loss: 0.004799, tar: 0.000220 
l0: 0.000173, l1: 0.000184, l2: 0.000165, l3: 0.000252, l4: 0.000685, l5: 0.001273, l6: 0.001798

[epoch: 329/1000, batch:  1024/ 1052, ite: 86520] train loss: 0.004802, tar: 0.000220 
[Epoch 329/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000054, l1: 0.000052, l2: 0.000093, l3: 0.000124, l4: 0.000242, l5: 0.000688, l6: 0.001190

[epoch: 330/1000, batch:    52/ 1052, ite: 86540] train loss: 0.004806, tar: 0.000220 
l0: 0.000216, l1: 0.000214, l2: 0.000241, l3: 0.000435, l4: 0.000781, l5: 0.001451, l6: 0.002998

[epoch: 330/1000, batch:   132/ 1052, ite: 86560] train loss: 0.004817, tar: 0.000220 
l0: 0.000180, l1: 0.000190, l2: 0.000177, l3: 0.000300, l4: 0.000409, l5: 0.000743, l6: 0.001204

[epoch: 330/1000, batch:   212/ 1052, ite: 86580] train loss: 0.004812, tar: 0.000220 
l0: 0.000165, l1: 0.000160, l2: 0.000217, l3: 0.000289, l4: 0.000509, l5: 0.001134, l6: 0.002031

[epoch: 330/1000, batch:   292/ 1052, ite: 86600] train loss: 0.004808, tar: 0.000220 
l0: 0.000424, l1: 0.000424, l2: 0.000504, l3: 0.000564, l4: 0.000819, l5: 0.001798, l6: 0.003176

[epoch: 330/1000, batch:   372/ 1052, ite: 86620] train loss: 0.004807, tar: 0.000220 
l0: 0.000135, l1: 0.000136, l2: 0.000184, l3: 0.000205, l4: 0.000423, l5: 0.000982, l6: 0.001642

[epoch: 330/1000, batch:   452/ 1052, ite: 86640] train loss: 0.004809, tar: 0.000220 
l0: 0.000136, l1: 0.000144, l2: 0.000129, l3: 0.000202, l4: 0.000396, l5: 0.000830, l6: 0.001158

[epoch: 330/1000, batch:   532/ 1052, ite: 86660] train loss: 0.004812, tar: 0.000220 
l0: 0.000543, l1: 0.000557, l2: 0.000554, l3: 0.000635, l4: 0.000957, l5: 0.001396, l6: 0.003084

[epoch: 330/1000, batch:   612/ 1052, ite: 86680] train loss: 0.004811, tar: 0.000220 
l0: 0.000342, l1: 0.000347, l2: 0.000394, l3: 0.000527, l4: 0.001216, l5: 0.002003, l6: 0.002915

[epoch: 330/1000, batch:   692/ 1052, ite: 86700] train loss: 0.004811, tar: 0.000220 
l0: 0.000177, l1: 0.000187, l2: 0.000205, l3: 0.000224, l4: 0.000453, l5: 0.001035, l6: 0.001621

[epoch: 330/1000, batch:   772/ 1052, ite: 86720] train loss: 0.004806, tar: 0.000220 
l0: 0.000168, l1: 0.000177, l2: 0.000166, l3: 0.000223, l4: 0.000476, l5: 0.000790, l6: 0.001911

[epoch: 330/1000, batch:   852/ 1052, ite: 86740] train loss: 0.004801, tar: 0.000220 
l0: 0.000231, l1: 0.000236, l2: 0.000253, l3: 0.000269, l4: 0.000626, l5: 0.001110, l6: 0.001858

[epoch: 330/1000, batch:   932/ 1052, ite: 86760] train loss: 0.004800, tar: 0.000219 
l0: 0.000216, l1: 0.000224, l2: 0.000265, l3: 0.000350, l4: 0.000650, l5: 0.000942, l6: 0.001945

[epoch: 330/1000, batch:  1012/ 1052, ite: 86780] train loss: 0.004797, tar: 0.000219 
[Epoch 330/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000173, l1: 0.000176, l2: 0.000212, l3: 0.000436, l4: 0.000702, l5: 0.001635, l6: 0.002760

[epoch: 331/1000, batch:    40/ 1052, ite: 86800] train loss: 0.004800, tar: 0.000219 
l0: 0.000145, l1: 0.000151, l2: 0.000144, l3: 0.000183, l4: 0.000313, l5: 0.000561, l6: 0.001361

[epoch: 331/1000, batch:   120/ 1052, ite: 86820] train loss: 0.004800, tar: 0.000219 
l0: 0.000107, l1: 0.000106, l2: 0.000151, l3: 0.000240, l4: 0.000464, l5: 0.000708, l6: 0.001765

[epoch: 331/1000, batch:   200/ 1052, ite: 86840] train loss: 0.004802, tar: 0.000219 
l0: 0.000137, l1: 0.000136, l2: 0.000170, l3: 0.000287, l4: 0.000354, l5: 0.000984, l6: 0.001637

[epoch: 331/1000, batch:   280/ 1052, ite: 86860] train loss: 0.004798, tar: 0.000219 
l0: 0.000254, l1: 0.000262, l2: 0.000314, l3: 0.000431, l4: 0.001006, l5: 0.001606, l6: 0.002626

[epoch: 331/1000, batch:   360/ 1052, ite: 86880] train loss: 0.004799, tar: 0.000219 
l0: 0.000231, l1: 0.000235, l2: 0.000240, l3: 0.000381, l4: 0.000565, l5: 0.001106, l6: 0.000995

[epoch: 331/1000, batch:   440/ 1052, ite: 86900] train loss: 0.004797, tar: 0.000219 
l0: 0.000180, l1: 0.000185, l2: 0.000292, l3: 0.000371, l4: 0.000521, l5: 0.000881, l6: 0.001453

[epoch: 331/1000, batch:   520/ 1052, ite: 86920] train loss: 0.004796, tar: 0.000219 
l0: 0.000240, l1: 0.000248, l2: 0.000222, l3: 0.000304, l4: 0.000599, l5: 0.001231, l6: 0.002155

[epoch: 331/1000, batch:   600/ 1052, ite: 86940] train loss: 0.004797, tar: 0.000219 
l0: 0.000166, l1: 0.000162, l2: 0.000195, l3: 0.000258, l4: 0.000372, l5: 0.000813, l6: 0.001230

[epoch: 331/1000, batch:   680/ 1052, ite: 86960] train loss: 0.004798, tar: 0.000219 
l0: 0.000440, l1: 0.000459, l2: 0.000505, l3: 0.000594, l4: 0.001007, l5: 0.002369, l6: 0.004300

[epoch: 331/1000, batch:   760/ 1052, ite: 86980] train loss: 0.004802, tar: 0.000220 
l0: 0.000149, l1: 0.000146, l2: 0.000183, l3: 0.000257, l4: 0.000459, l5: 0.000887, l6: 0.001188

[epoch: 331/1000, batch:   840/ 1052, ite: 87000] train loss: 0.004797, tar: 0.000219 
l0: 0.000271, l1: 0.000284, l2: 0.000280, l3: 0.000362, l4: 0.000606, l5: 0.001258, l6: 0.002568

[epoch: 331/1000, batch:   920/ 1052, ite: 87020] train loss: 0.004801, tar: 0.000219 
l0: 0.000266, l1: 0.000273, l2: 0.000284, l3: 0.000380, l4: 0.000599, l5: 0.001404, l6: 0.002232

[epoch: 331/1000, batch:  1000/ 1052, ite: 87040] train loss: 0.004801, tar: 0.000220 
[Epoch 331/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000227, l1: 0.000233, l2: 0.000255, l3: 0.000360, l4: 0.000824, l5: 0.001196, l6: 0.002605

[epoch: 332/1000, batch:    28/ 1052, ite: 87060] train loss: 0.004804, tar: 0.000220 
l0: 0.000177, l1: 0.000174, l2: 0.000236, l3: 0.000237, l4: 0.000373, l5: 0.000493, l6: 0.001348

[epoch: 332/1000, batch:   108/ 1052, ite: 87080] train loss: 0.004801, tar: 0.000220 
l0: 0.000163, l1: 0.000159, l2: 0.000205, l3: 0.000263, l4: 0.000496, l5: 0.000948, l6: 0.001847

[epoch: 332/1000, batch:   188/ 1052, ite: 87100] train loss: 0.004798, tar: 0.000219 
l0: 0.000226, l1: 0.000235, l2: 0.000236, l3: 0.000270, l4: 0.000433, l5: 0.000900, l6: 0.001945

[epoch: 332/1000, batch:   268/ 1052, ite: 87120] train loss: 0.004793, tar: 0.000219 
l0: 0.000133, l1: 0.000138, l2: 0.000151, l3: 0.000225, l4: 0.000349, l5: 0.000732, l6: 0.001652

[epoch: 332/1000, batch:   348/ 1052, ite: 87140] train loss: 0.004795, tar: 0.000219 
l0: 0.000255, l1: 0.000253, l2: 0.000272, l3: 0.000392, l4: 0.000584, l5: 0.001988, l6: 0.003131

[epoch: 332/1000, batch:   428/ 1052, ite: 87160] train loss: 0.004796, tar: 0.000219 
l0: 0.000225, l1: 0.000226, l2: 0.000244, l3: 0.000323, l4: 0.000563, l5: 0.001187, l6: 0.001967

[epoch: 332/1000, batch:   508/ 1052, ite: 87180] train loss: 0.004797, tar: 0.000219 
l0: 0.000190, l1: 0.000180, l2: 0.000231, l3: 0.000330, l4: 0.000631, l5: 0.001043, l6: 0.001365

[epoch: 332/1000, batch:   588/ 1052, ite: 87200] train loss: 0.004795, tar: 0.000219 
l0: 0.000275, l1: 0.000284, l2: 0.000298, l3: 0.000373, l4: 0.000549, l5: 0.001125, l6: 0.001673

[epoch: 332/1000, batch:   668/ 1052, ite: 87220] train loss: 0.004796, tar: 0.000219 
l0: 0.000119, l1: 0.000123, l2: 0.000142, l3: 0.000184, l4: 0.000293, l5: 0.000969, l6: 0.001918

[epoch: 332/1000, batch:   748/ 1052, ite: 87240] train loss: 0.004796, tar: 0.000219 
l0: 0.000188, l1: 0.000186, l2: 0.000272, l3: 0.000375, l4: 0.000571, l5: 0.001282, l6: 0.001811

[epoch: 332/1000, batch:   828/ 1052, ite: 87260] train loss: 0.004794, tar: 0.000219 
l0: 0.000074, l1: 0.000080, l2: 0.000064, l3: 0.000126, l4: 0.000223, l5: 0.000682, l6: 0.000861

[epoch: 332/1000, batch:   908/ 1052, ite: 87280] train loss: 0.004795, tar: 0.000219 
l0: 0.000277, l1: 0.000296, l2: 0.000286, l3: 0.000371, l4: 0.000633, l5: 0.001139, l6: 0.002190

[epoch: 332/1000, batch:   988/ 1052, ite: 87300] train loss: 0.004799, tar: 0.000220 
[Epoch 332/1000] Test loss: 0.013, Test target loss: 0.001
l0: 0.000219, l1: 0.000221, l2: 0.000234, l3: 0.000266, l4: 0.000366, l5: 0.000948, l6: 0.001640

[epoch: 333/1000, batch:    16/ 1052, ite: 87320] train loss: 0.004802, tar: 0.000220 
l0: 0.000200, l1: 0.000205, l2: 0.000230, l3: 0.000269, l4: 0.000517, l5: 0.001031, l6: 0.001992

[epoch: 333/1000, batch:    96/ 1052, ite: 87340] train loss: 0.004798, tar: 0.000220 
l0: 0.000253, l1: 0.000270, l2: 0.000252, l3: 0.000260, l4: 0.000548, l5: 0.000591, l6: 0.000927

[epoch: 333/1000, batch:   176/ 1052, ite: 87360] train loss: 0.004799, tar: 0.000220 
l0: 0.000217, l1: 0.000233, l2: 0.000203, l3: 0.000278, l4: 0.000253, l5: 0.000626, l6: 0.001292

[epoch: 333/1000, batch:   256/ 1052, ite: 87380] train loss: 0.004801, tar: 0.000221 
l0: 0.000186, l1: 0.000193, l2: 0.000216, l3: 0.000236, l4: 0.000441, l5: 0.000795, l6: 0.001159

[epoch: 333/1000, batch:   336/ 1052, ite: 87400] train loss: 0.004800, tar: 0.000221 
l0: 0.000257, l1: 0.000248, l2: 0.000321, l3: 0.000442, l4: 0.000757, l5: 0.001509, l6: 0.002569

[epoch: 333/1000, batch:   416/ 1052, ite: 87420] train loss: 0.004802, tar: 0.000221 
l0: 0.000232, l1: 0.000239, l2: 0.000261, l3: 0.000293, l4: 0.000329, l5: 0.000919, l6: 0.001489

[epoch: 333/1000, batch:   496/ 1052, ite: 87440] train loss: 0.004810, tar: 0.000222 
l0: 0.000246, l1: 0.000238, l2: 0.000282, l3: 0.000294, l4: 0.000581, l5: 0.001835, l6: 0.002043

[epoch: 333/1000, batch:   576/ 1052, ite: 87460] train loss: 0.004815, tar: 0.000222 
l0: 0.000334, l1: 0.000343, l2: 0.000348, l3: 0.000349, l4: 0.000648, l5: 0.001364, l6: 0.002207

[epoch: 333/1000, batch:   656/ 1052, ite: 87480] train loss: 0.004813, tar: 0.000222 
l0: 0.000122, l1: 0.000126, l2: 0.000177, l3: 0.000169, l4: 0.000405, l5: 0.000883, l6: 0.001043

[epoch: 333/1000, batch:   736/ 1052, ite: 87500] train loss: 0.004818, tar: 0.000223 
l0: 0.000636, l1: 0.000632, l2: 0.000702, l3: 0.000808, l4: 0.001092, l5: 0.002918, l6: 0.005126

[epoch: 333/1000, batch:   816/ 1052, ite: 87520] train loss: 0.004822, tar: 0.000223 
l0: 0.000445, l1: 0.000449, l2: 0.000465, l3: 0.000740, l4: 0.001179, l5: 0.001415, l6: 0.003198

[epoch: 333/1000, batch:   896/ 1052, ite: 87540] train loss: 0.004823, tar: 0.000223 
l0: 0.000275, l1: 0.000276, l2: 0.000340, l3: 0.000374, l4: 0.000607, l5: 0.000981, l6: 0.002695

[epoch: 333/1000, batch:   976/ 1052, ite: 87560] train loss: 0.004826, tar: 0.000224 
[Epoch 333/1000] Test loss: 0.012, Test target loss: 0.001
l0: 0.000327, l1: 0.000327, l2: 0.000364, l3: 0.000405, l4: 0.000693, l5: 0.001137, l6: 0.003001

[epoch: 334/1000, batch:     4/ 1052, ite: 87580] train loss: 0.004826, tar: 0.000224 
l0: 0.000239, l1: 0.000242, l2: 0.000265, l3: 0.000372, l4: 0.000669, l5: 0.001858, l6: 0.003672

[epoch: 334/1000, batch:    84/ 1052, ite: 87600] train loss: 0.004829, tar: 0.000224 
l0: 0.000220, l1: 0.000222, l2: 0.000276, l3: 0.000401, l4: 0.000763, l5: 0.001417, l6: 0.001926

[epoch: 334/1000, batch:   164/ 1052, ite: 87620] train loss: 0.004831, tar: 0.000224 
l0: 0.000198, l1: 0.000213, l2: 0.000232, l3: 0.000295, l4: 0.000564, l5: 0.001430, l6: 0.001748

[epoch: 334/1000, batch:   244/ 1052, ite: 87640] train loss: 0.004832, tar: 0.000224 
l0: 0.000074, l1: 0.000074, l2: 0.000105, l3: 0.000150, l4: 0.000426, l5: 0.000657, l6: 0.001286

[epoch: 334/1000, batch:   324/ 1052, ite: 87660] train loss: 0.004827, tar: 0.000224 
l0: 0.000289, l1: 0.000288, l2: 0.000290, l3: 0.000414, l4: 0.000730, l5: 0.001113, l6: 0.002694

[epoch: 334/1000, batch:   404/ 1052, ite: 87680] train loss: 0.004826, tar: 0.000224 
l0: 0.000219, l1: 0.000218, l2: 0.000277, l3: 0.000371, l4: 0.000761, l5: 0.001520, l6: 0.002908

[epoch: 334/1000, batch:   484/ 1052, ite: 87700] train loss: 0.004825, tar: 0.000224 
l0: 0.000138, l1: 0.000133, l2: 0.000134, l3: 0.000194, l4: 0.000401, l5: 0.000676, l6: 0.001078

[epoch: 334/1000, batch:   564/ 1052, ite: 87720] train loss: 0.004823, tar: 0.000224 
l0: 0.000314, l1: 0.000317, l2: 0.000333, l3: 0.000454, l4: 0.000740, l5: 0.001292, l6: 0.003883

[epoch: 334/1000, batch:   644/ 1052, ite: 87740] train loss: 0.004826, tar: 0.000224 
l0: 0.000187, l1: 0.000194, l2: 0.000235, l3: 0.000305, l4: 0.000603, l5: 0.001252, l6: 0.002928

[epoch: 334/1000, batch:   724/ 1052, ite: 87760] train loss: 0.004826, tar: 0.000224 
l0: 0.000212, l1: 0.000208, l2: 0.000258, l3: 0.000364, l4: 0.000592, l5: 0.000899, l6: 0.001735

[epoch: 334/1000, batch:   804/ 1052, ite: 87780] train loss: 0.004828, tar: 0.000224 
l0: 0.000166, l1: 0.000169, l2: 0.000186, l3: 0.000256, l4: 0.000380, l5: 0.000587, l6: 0.001280

[epoch: 334/1000, batch:   884/ 1052, ite: 87800] train loss: 0.004825, tar: 0.000224 
l0: 0.000229, l1: 0.000223, l2: 0.000255, l3: 0.000317, l4: 0.000629, l5: 0.001217, l6: 0.002136

[epoch: 334/1000, batch:   964/ 1052, ite: 87820] train loss: 0.004821, tar: 0.000223 
l0: 0.000280, l1: 0.000284, l2: 0.000332, l3: 0.000385, l4: 0.000684, l5: 0.001131, l6: 0.001676

[epoch: 334/1000, batch:  1044/ 1052, ite: 87840] train loss: 0.004823, tar: 0.000223 
[Epoch 334/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000131, l1: 0.000130, l2: 0.000155, l3: 0.000239, l4: 0.000681, l5: 0.001017, l6: 0.002233

[epoch: 335/1000, batch:    72/ 1052, ite: 87860] train loss: 0.004823, tar: 0.000223 
l0: 0.000289, l1: 0.000302, l2: 0.000331, l3: 0.000346, l4: 0.000703, l5: 0.001290, l6: 0.002670

[epoch: 335/1000, batch:   152/ 1052, ite: 87880] train loss: 0.004824, tar: 0.000223 
l0: 0.000134, l1: 0.000135, l2: 0.000196, l3: 0.000311, l4: 0.000543, l5: 0.001001, l6: 0.002902

[epoch: 335/1000, batch:   232/ 1052, ite: 87900] train loss: 0.004824, tar: 0.000223 
l0: 0.000190, l1: 0.000186, l2: 0.000261, l3: 0.000291, l4: 0.000569, l5: 0.001348, l6: 0.002414

[epoch: 335/1000, batch:   312/ 1052, ite: 87920] train loss: 0.004821, tar: 0.000223 
l0: 0.000180, l1: 0.000171, l2: 0.000248, l3: 0.000288, l4: 0.000632, l5: 0.001185, l6: 0.001563

[epoch: 335/1000, batch:   392/ 1052, ite: 87940] train loss: 0.004821, tar: 0.000223 
l0: 0.000244, l1: 0.000236, l2: 0.000307, l3: 0.000366, l4: 0.000790, l5: 0.001276, l6: 0.003054

[epoch: 335/1000, batch:   472/ 1052, ite: 87960] train loss: 0.004823, tar: 0.000223 
l0: 0.000253, l1: 0.000254, l2: 0.000249, l3: 0.000431, l4: 0.000742, l5: 0.001303, l6: 0.001533

[epoch: 335/1000, batch:   552/ 1052, ite: 87980] train loss: 0.004822, tar: 0.000223 
l0: 0.000242, l1: 0.000246, l2: 0.000245, l3: 0.000335, l4: 0.000565, l5: 0.001544, l6: 0.001519

[epoch: 335/1000, batch:   632/ 1052, ite: 88000] train loss: 0.004822, tar: 0.000223 
l0: 0.000244, l1: 0.000247, l2: 0.000254, l3: 0.000333, l4: 0.000535, l5: 0.001188, l6: 0.002717

[epoch: 335/1000, batch:   712/ 1052, ite: 88020] train loss: 0.004822, tar: 0.000223 
l0: 0.000243, l1: 0.000217, l2: 0.000264, l3: 0.000358, l4: 0.000600, l5: 0.000856, l6: 0.001969

[epoch: 335/1000, batch:   792/ 1052, ite: 88040] train loss: 0.004819, tar: 0.000222 
l0: 0.000233, l1: 0.000235, l2: 0.000267, l3: 0.000356, l4: 0.000531, l5: 0.001015, l6: 0.002014

[epoch: 335/1000, batch:   872/ 1052, ite: 88060] train loss: 0.004818, tar: 0.000222 
l0: 0.000164, l1: 0.000166, l2: 0.000214, l3: 0.000252, l4: 0.000720, l5: 0.001403, l6: 0.001365

[epoch: 335/1000, batch:   952/ 1052, ite: 88080] train loss: 0.004820, tar: 0.000222 
l0: 0.000200, l1: 0.000213, l2: 0.000223, l3: 0.000222, l4: 0.000320, l5: 0.000913, l6: 0.001301

[epoch: 335/1000, batch:  1032/ 1052, ite: 88100] train loss: 0.004816, tar: 0.000222 
[Epoch 335/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000201, l1: 0.000197, l2: 0.000282, l3: 0.000408, l4: 0.000911, l5: 0.001880, l6: 0.003135

[epoch: 336/1000, batch:    60/ 1052, ite: 88120] train loss: 0.004813, tar: 0.000222 
l0: 0.000161, l1: 0.000158, l2: 0.000176, l3: 0.000247, l4: 0.000425, l5: 0.001432, l6: 0.002247

[epoch: 336/1000, batch:   140/ 1052, ite: 88140] train loss: 0.004814, tar: 0.000222 
l0: 0.000244, l1: 0.000246, l2: 0.000258, l3: 0.000385, l4: 0.000605, l5: 0.001085, l6: 0.001440

[epoch: 336/1000, batch:   220/ 1052, ite: 88160] train loss: 0.004811, tar: 0.000222 
l0: 0.000303, l1: 0.000310, l2: 0.000361, l3: 0.000505, l4: 0.000842, l5: 0.001473, l6: 0.002493

[epoch: 336/1000, batch:   300/ 1052, ite: 88180] train loss: 0.004811, tar: 0.000222 
l0: 0.000129, l1: 0.000129, l2: 0.000159, l3: 0.000191, l4: 0.000351, l5: 0.000937, l6: 0.002088

[epoch: 336/1000, batch:   380/ 1052, ite: 88200] train loss: 0.004811, tar: 0.000221 
l0: 0.000235, l1: 0.000233, l2: 0.000217, l3: 0.000206, l4: 0.000499, l5: 0.000562, l6: 0.000867

[epoch: 336/1000, batch:   460/ 1052, ite: 88220] train loss: 0.004811, tar: 0.000221 
l0: 0.000225, l1: 0.000230, l2: 0.000240, l3: 0.000338, l4: 0.000544, l5: 0.001451, l6: 0.002631

[epoch: 336/1000, batch:   540/ 1052, ite: 88240] train loss: 0.004810, tar: 0.000221 
l0: 0.000233, l1: 0.000246, l2: 0.000237, l3: 0.000284, l4: 0.000348, l5: 0.000746, l6: 0.002069

[epoch: 336/1000, batch:   620/ 1052, ite: 88260] train loss: 0.004808, tar: 0.000221 
l0: 0.000179, l1: 0.000180, l2: 0.000200, l3: 0.000312, l4: 0.000662, l5: 0.000856, l6: 0.001520

[epoch: 336/1000, batch:   700/ 1052, ite: 88280] train loss: 0.004806, tar: 0.000221 
l0: 0.000172, l1: 0.000172, l2: 0.000226, l3: 0.000399, l4: 0.000701, l5: 0.001152, l6: 0.002319

[epoch: 336/1000, batch:   780/ 1052, ite: 88300] train loss: 0.004807, tar: 0.000221 
l0: 0.000105, l1: 0.000113, l2: 0.000110, l3: 0.000157, l4: 0.000514, l5: 0.000917, l6: 0.001181

[epoch: 336/1000, batch:   860/ 1052, ite: 88320] train loss: 0.004805, tar: 0.000221 
l0: 0.000114, l1: 0.000115, l2: 0.000123, l3: 0.000220, l4: 0.000512, l5: 0.000937, l6: 0.002281

[epoch: 336/1000, batch:   940/ 1052, ite: 88340] train loss: 0.004805, tar: 0.000221 
l0: 0.000114, l1: 0.000118, l2: 0.000126, l3: 0.000182, l4: 0.000380, l5: 0.000921, l6: 0.001300

[epoch: 336/1000, batch:  1020/ 1052, ite: 88360] train loss: 0.004805, tar: 0.000221 
[Epoch 336/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000192, l1: 0.000202, l2: 0.000225, l3: 0.000323, l4: 0.000484, l5: 0.001031, l6: 0.002050

[epoch: 337/1000, batch:    48/ 1052, ite: 88380] train loss: 0.004804, tar: 0.000221 
l0: 0.000280, l1: 0.000277, l2: 0.000296, l3: 0.000324, l4: 0.000639, l5: 0.000875, l6: 0.001586

[epoch: 337/1000, batch:   128/ 1052, ite: 88400] train loss: 0.004805, tar: 0.000221 
l0: 0.000182, l1: 0.000177, l2: 0.000220, l3: 0.000285, l4: 0.000457, l5: 0.000614, l6: 0.001388

[epoch: 337/1000, batch:   208/ 1052, ite: 88420] train loss: 0.004804, tar: 0.000220 
l0: 0.000392, l1: 0.000410, l2: 0.000411, l3: 0.000484, l4: 0.000921, l5: 0.001939, l6: 0.003569

[epoch: 337/1000, batch:   288/ 1052, ite: 88440] train loss: 0.004802, tar: 0.000220 
l0: 0.000251, l1: 0.000267, l2: 0.000250, l3: 0.000347, l4: 0.000658, l5: 0.001473, l6: 0.001981

[epoch: 337/1000, batch:   368/ 1052, ite: 88460] train loss: 0.004805, tar: 0.000220 
l0: 0.000181, l1: 0.000188, l2: 0.000189, l3: 0.000289, l4: 0.000424, l5: 0.000812, l6: 0.001999

[epoch: 337/1000, batch:   448/ 1052, ite: 88480] train loss: 0.004806, tar: 0.000221 
l0: 0.000182, l1: 0.000184, l2: 0.000230, l3: 0.000296, l4: 0.000491, l5: 0.001128, l6: 0.002049

[epoch: 337/1000, batch:   528/ 1052, ite: 88500] train loss: 0.004805, tar: 0.000220 
l0: 0.000467, l1: 0.000448, l2: 0.000487, l3: 0.000612, l4: 0.000712, l5: 0.001241, l6: 0.001541

[epoch: 337/1000, batch:   608/ 1052, ite: 88520] train loss: 0.004804, tar: 0.000220 
l0: 0.000147, l1: 0.000141, l2: 0.000197, l3: 0.000315, l4: 0.000837, l5: 0.001520, l6: 0.001581

[epoch: 337/1000, batch:   688/ 1052, ite: 88540] train loss: 0.004805, tar: 0.000220 
l0: 0.000346, l1: 0.000354, l2: 0.000366, l3: 0.000436, l4: 0.000586, l5: 0.001503, l6: 0.003603

[epoch: 337/1000, batch:   768/ 1052, ite: 88560] train loss: 0.004803, tar: 0.000220 
l0: 0.000150, l1: 0.000152, l2: 0.000159, l3: 0.000188, l4: 0.000534, l5: 0.001021, l6: 0.001101

[epoch: 337/1000, batch:   848/ 1052, ite: 88580] train loss: 0.004805, tar: 0.000220 
l0: 0.000362, l1: 0.000383, l2: 0.000348, l3: 0.000464, l4: 0.000779, l5: 0.001337, l6: 0.002736

[epoch: 337/1000, batch:   928/ 1052, ite: 88600] train loss: 0.004803, tar: 0.000220 
l0: 0.000118, l1: 0.000117, l2: 0.000160, l3: 0.000230, l4: 0.000525, l5: 0.000794, l6: 0.002520

[epoch: 337/1000, batch:  1008/ 1052, ite: 88620] train loss: 0.004803, tar: 0.000220 
[Epoch 337/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000144, l1: 0.000143, l2: 0.000172, l3: 0.000290, l4: 0.000447, l5: 0.000999, l6: 0.002014

[epoch: 338/1000, batch:    36/ 1052, ite: 88640] train loss: 0.004799, tar: 0.000220 
l0: 0.000270, l1: 0.000260, l2: 0.000325, l3: 0.000358, l4: 0.000605, l5: 0.001580, l6: 0.001782

[epoch: 338/1000, batch:   116/ 1052, ite: 88660] train loss: 0.004798, tar: 0.000220 
l0: 0.000148, l1: 0.000142, l2: 0.000208, l3: 0.000266, l4: 0.000437, l5: 0.000694, l6: 0.001475

[epoch: 338/1000, batch:   196/ 1052, ite: 88680] train loss: 0.004797, tar: 0.000220 
l0: 0.000142, l1: 0.000141, l2: 0.000206, l3: 0.000423, l4: 0.000742, l5: 0.001110, l6: 0.002089

[epoch: 338/1000, batch:   276/ 1052, ite: 88700] train loss: 0.004797, tar: 0.000220 
l0: 0.000131, l1: 0.000140, l2: 0.000154, l3: 0.000205, l4: 0.000450, l5: 0.001015, l6: 0.001681

[epoch: 338/1000, batch:   356/ 1052, ite: 88720] train loss: 0.004795, tar: 0.000220 
l0: 0.000174, l1: 0.000170, l2: 0.000232, l3: 0.000331, l4: 0.000540, l5: 0.001258, l6: 0.002671

[epoch: 338/1000, batch:   436/ 1052, ite: 88740] train loss: 0.004794, tar: 0.000219 
l0: 0.000293, l1: 0.000307, l2: 0.000329, l3: 0.000375, l4: 0.000544, l5: 0.001064, l6: 0.002597

[epoch: 338/1000, batch:   516/ 1052, ite: 88760] train loss: 0.004794, tar: 0.000219 
l0: 0.000189, l1: 0.000191, l2: 0.000191, l3: 0.000319, l4: 0.000490, l5: 0.001354, l6: 0.001829

[epoch: 338/1000, batch:   596/ 1052, ite: 88780] train loss: 0.004796, tar: 0.000219 
l0: 0.000191, l1: 0.000188, l2: 0.000261, l3: 0.000275, l4: 0.000728, l5: 0.001458, l6: 0.002082

[epoch: 338/1000, batch:   676/ 1052, ite: 88800] train loss: 0.004798, tar: 0.000220 
l0: 0.000387, l1: 0.000395, l2: 0.000435, l3: 0.000574, l4: 0.001065, l5: 0.001997, l6: 0.003368

[epoch: 338/1000, batch:   756/ 1052, ite: 88820] train loss: 0.004799, tar: 0.000220 
l0: 0.000251, l1: 0.000257, l2: 0.000273, l3: 0.000354, l4: 0.000430, l5: 0.000955, l6: 0.002470

[epoch: 338/1000, batch:   836/ 1052, ite: 88840] train loss: 0.004798, tar: 0.000219 
l0: 0.000109, l1: 0.000109, l2: 0.000138, l3: 0.000174, l4: 0.000239, l5: 0.000787, l6: 0.001127

[epoch: 338/1000, batch:   916/ 1052, ite: 88860] train loss: 0.004798, tar: 0.000219 
l0: 0.000395, l1: 0.000403, l2: 0.000449, l3: 0.000476, l4: 0.000727, l5: 0.001200, l6: 0.003347

[epoch: 338/1000, batch:   996/ 1052, ite: 88880] train loss: 0.004799, tar: 0.000219 
[Epoch 338/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000216, l1: 0.000214, l2: 0.000265, l3: 0.000326, l4: 0.000388, l5: 0.001128, l6: 0.001844

[epoch: 339/1000, batch:    24/ 1052, ite: 88900] train loss: 0.004798, tar: 0.000219 
l0: 0.000235, l1: 0.000234, l2: 0.000271, l3: 0.000389, l4: 0.000741, l5: 0.001739, l6: 0.002644

[epoch: 339/1000, batch:   104/ 1052, ite: 88920] train loss: 0.004798, tar: 0.000219 
l0: 0.000119, l1: 0.000119, l2: 0.000142, l3: 0.000229, l4: 0.000599, l5: 0.000828, l6: 0.001068

[epoch: 339/1000, batch:   184/ 1052, ite: 88940] train loss: 0.004797, tar: 0.000219 
l0: 0.000147, l1: 0.000149, l2: 0.000162, l3: 0.000199, l4: 0.000458, l5: 0.000899, l6: 0.002232

[epoch: 339/1000, batch:   264/ 1052, ite: 88960] train loss: 0.004796, tar: 0.000219 
l0: 0.000141, l1: 0.000141, l2: 0.000160, l3: 0.000166, l4: 0.000352, l5: 0.000663, l6: 0.001109

[epoch: 339/1000, batch:   344/ 1052, ite: 88980] train loss: 0.004796, tar: 0.000219 
l0: 0.000295, l1: 0.000300, l2: 0.000355, l3: 0.000482, l4: 0.000690, l5: 0.001554, l6: 0.002810

[epoch: 339/1000, batch:   424/ 1052, ite: 89000] train loss: 0.004795, tar: 0.000219 
l0: 0.000125, l1: 0.000132, l2: 0.000165, l3: 0.000202, l4: 0.000601, l5: 0.000997, l6: 0.001217

[epoch: 339/1000, batch:   504/ 1052, ite: 89020] train loss: 0.004796, tar: 0.000219 
l0: 0.000190, l1: 0.000206, l2: 0.000188, l3: 0.000232, l4: 0.000405, l5: 0.001282, l6: 0.001304

[epoch: 339/1000, batch:   584/ 1052, ite: 89040] train loss: 0.004795, tar: 0.000219 
l0: 0.000262, l1: 0.000255, l2: 0.000375, l3: 0.000496, l4: 0.000580, l5: 0.001503, l6: 0.002888

[epoch: 339/1000, batch:   664/ 1052, ite: 89060] train loss: 0.004795, tar: 0.000219 
l0: 0.000133, l1: 0.000128, l2: 0.000170, l3: 0.000236, l4: 0.000379, l5: 0.000906, l6: 0.001745

[epoch: 339/1000, batch:   744/ 1052, ite: 89080] train loss: 0.004795, tar: 0.000219 
l0: 0.000137, l1: 0.000133, l2: 0.000206, l3: 0.000335, l4: 0.000640, l5: 0.000987, l6: 0.002444

[epoch: 339/1000, batch:   824/ 1052, ite: 89100] train loss: 0.004794, tar: 0.000219 
l0: 0.000126, l1: 0.000127, l2: 0.000144, l3: 0.000224, l4: 0.000365, l5: 0.000690, l6: 0.001520

[epoch: 339/1000, batch:   904/ 1052, ite: 89120] train loss: 0.004792, tar: 0.000218 
l0: 0.000157, l1: 0.000158, l2: 0.000168, l3: 0.000203, l4: 0.000294, l5: 0.000758, l6: 0.000928

[epoch: 339/1000, batch:   984/ 1052, ite: 89140] train loss: 0.004792, tar: 0.000218 
[Epoch 339/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000132, l1: 0.000133, l2: 0.000185, l3: 0.000247, l4: 0.000342, l5: 0.000735, l6: 0.001172

[epoch: 340/1000, batch:    12/ 1052, ite: 89160] train loss: 0.004794, tar: 0.000218 
l0: 0.000229, l1: 0.000226, l2: 0.000306, l3: 0.000623, l4: 0.000784, l5: 0.002086, l6: 0.002251

[epoch: 340/1000, batch:    92/ 1052, ite: 89180] train loss: 0.004795, tar: 0.000218 
l0: 0.000317, l1: 0.000329, l2: 0.000351, l3: 0.000386, l4: 0.000614, l5: 0.001067, l6: 0.002553

[epoch: 340/1000, batch:   172/ 1052, ite: 89200] train loss: 0.004794, tar: 0.000218 
l0: 0.000200, l1: 0.000198, l2: 0.000229, l3: 0.000320, l4: 0.000407, l5: 0.001316, l6: 0.001821

[epoch: 340/1000, batch:   252/ 1052, ite: 89220] train loss: 0.004795, tar: 0.000218 
l0: 0.000413, l1: 0.000406, l2: 0.000431, l3: 0.000554, l4: 0.001046, l5: 0.001277, l6: 0.003093

[epoch: 340/1000, batch:   332/ 1052, ite: 89240] train loss: 0.004793, tar: 0.000218 
l0: 0.000115, l1: 0.000110, l2: 0.000184, l3: 0.000238, l4: 0.000454, l5: 0.000934, l6: 0.002344

[epoch: 340/1000, batch:   412/ 1052, ite: 89260] train loss: 0.004794, tar: 0.000218 
l0: 0.000120, l1: 0.000125, l2: 0.000138, l3: 0.000270, l4: 0.000759, l5: 0.001099, l6: 0.001671

[epoch: 340/1000, batch:   492/ 1052, ite: 89280] train loss: 0.004793, tar: 0.000218 
l0: 0.000086, l1: 0.000089, l2: 0.000114, l3: 0.000171, l4: 0.000360, l5: 0.000706, l6: 0.001123

[epoch: 340/1000, batch:   572/ 1052, ite: 89300] train loss: 0.004790, tar: 0.000218 
l0: 0.000370, l1: 0.000369, l2: 0.000390, l3: 0.000437, l4: 0.001162, l5: 0.001789, l6: 0.002119

[epoch: 340/1000, batch:   652/ 1052, ite: 89320] train loss: 0.004790, tar: 0.000218 
l0: 0.000195, l1: 0.000198, l2: 0.000201, l3: 0.000257, l4: 0.000351, l5: 0.000740, l6: 0.001431

[epoch: 340/1000, batch:   732/ 1052, ite: 89340] train loss: 0.004789, tar: 0.000218 
l0: 0.000319, l1: 0.000310, l2: 0.000377, l3: 0.000590, l4: 0.000893, l5: 0.001815, l6: 0.003398

[epoch: 340/1000, batch:   812/ 1052, ite: 89360] train loss: 0.004790, tar: 0.000218 
l0: 0.000112, l1: 0.000118, l2: 0.000122, l3: 0.000174, l4: 0.000388, l5: 0.000699, l6: 0.001038

[epoch: 340/1000, batch:   892/ 1052, ite: 89380] train loss: 0.004789, tar: 0.000218 
l0: 0.000103, l1: 0.000103, l2: 0.000142, l3: 0.000198, l4: 0.000398, l5: 0.000729, l6: 0.000880

[epoch: 340/1000, batch:   972/ 1052, ite: 89400] train loss: 0.004789, tar: 0.000218 
l0: 0.000108, l1: 0.000111, l2: 0.000129, l3: 0.000132, l4: 0.000225, l5: 0.000611, l6: 0.000875

[epoch: 340/1000, batch:  1052/ 1052, ite: 89420] train loss: 0.004787, tar: 0.000218 
[Epoch 340/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000275, l1: 0.000281, l2: 0.000324, l3: 0.000385, l4: 0.000615, l5: 0.001357, l6: 0.002667

[epoch: 341/1000, batch:    80/ 1052, ite: 89440] train loss: 0.004786, tar: 0.000218 
l0: 0.000077, l1: 0.000076, l2: 0.000109, l3: 0.000240, l4: 0.000524, l5: 0.001046, l6: 0.001632

[epoch: 341/1000, batch:   160/ 1052, ite: 89460] train loss: 0.004787, tar: 0.000217 
l0: 0.000143, l1: 0.000142, l2: 0.000188, l3: 0.000215, l4: 0.000483, l5: 0.000918, l6: 0.001605

[epoch: 341/1000, batch:   240/ 1052, ite: 89480] train loss: 0.004789, tar: 0.000217 
l0: 0.000263, l1: 0.000263, l2: 0.000295, l3: 0.000398, l4: 0.000743, l5: 0.001507, l6: 0.002790

[epoch: 341/1000, batch:   320/ 1052, ite: 89500] train loss: 0.004789, tar: 0.000217 
l0: 0.000117, l1: 0.000120, l2: 0.000161, l3: 0.000225, l4: 0.000339, l5: 0.001036, l6: 0.001437

[epoch: 341/1000, batch:   400/ 1052, ite: 89520] train loss: 0.004789, tar: 0.000217 
l0: 0.000220, l1: 0.000217, l2: 0.000248, l3: 0.000367, l4: 0.000799, l5: 0.001982, l6: 0.002402

[epoch: 341/1000, batch:   480/ 1052, ite: 89540] train loss: 0.004788, tar: 0.000217 
l0: 0.000167, l1: 0.000166, l2: 0.000207, l3: 0.000287, l4: 0.000651, l5: 0.000970, l6: 0.001424

[epoch: 341/1000, batch:   560/ 1052, ite: 89560] train loss: 0.004786, tar: 0.000217 
l0: 0.000540, l1: 0.000548, l2: 0.000614, l3: 0.000705, l4: 0.000791, l5: 0.001875, l6: 0.004244

[epoch: 341/1000, batch:   640/ 1052, ite: 89580] train loss: 0.004786, tar: 0.000217 
l0: 0.000363, l1: 0.000361, l2: 0.000471, l3: 0.000626, l4: 0.001053, l5: 0.001914, l6: 0.004152

[epoch: 341/1000, batch:   720/ 1052, ite: 89600] train loss: 0.004785, tar: 0.000217 
l0: 0.000242, l1: 0.000244, l2: 0.000313, l3: 0.000420, l4: 0.000693, l5: 0.001173, l6: 0.003176

[epoch: 341/1000, batch:   800/ 1052, ite: 89620] train loss: 0.004787, tar: 0.000217 
l0: 0.000199, l1: 0.000194, l2: 0.000204, l3: 0.000322, l4: 0.000545, l5: 0.000998, l6: 0.001460

[epoch: 341/1000, batch:   880/ 1052, ite: 89640] train loss: 0.004785, tar: 0.000217 
l0: 0.000113, l1: 0.000114, l2: 0.000131, l3: 0.000229, l4: 0.000467, l5: 0.000974, l6: 0.001308

[epoch: 341/1000, batch:   960/ 1052, ite: 89660] train loss: 0.004784, tar: 0.000217 
l0: 0.000063, l1: 0.000064, l2: 0.000076, l3: 0.000137, l4: 0.000278, l5: 0.000455, l6: 0.001044

[epoch: 341/1000, batch:  1040/ 1052, ite: 89680] train loss: 0.004784, tar: 0.000217 
[Epoch 341/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000086, l1: 0.000088, l2: 0.000111, l3: 0.000216, l4: 0.000535, l5: 0.001084, l6: 0.001131

[epoch: 342/1000, batch:    68/ 1052, ite: 89700] train loss: 0.004783, tar: 0.000217 
l0: 0.000290, l1: 0.000282, l2: 0.000390, l3: 0.000471, l4: 0.000846, l5: 0.001600, l6: 0.003319

[epoch: 342/1000, batch:   148/ 1052, ite: 89720] train loss: 0.004783, tar: 0.000217 
l0: 0.000151, l1: 0.000154, l2: 0.000164, l3: 0.000295, l4: 0.000472, l5: 0.000878, l6: 0.001400

[epoch: 342/1000, batch:   228/ 1052, ite: 89740] train loss: 0.004782, tar: 0.000216 
l0: 0.000554, l1: 0.000573, l2: 0.000646, l3: 0.000666, l4: 0.001012, l5: 0.001521, l6: 0.004267

[epoch: 342/1000, batch:   308/ 1052, ite: 89760] train loss: 0.004782, tar: 0.000216 
l0: 0.000124, l1: 0.000127, l2: 0.000141, l3: 0.000258, l4: 0.000336, l5: 0.000652, l6: 0.001010

[epoch: 342/1000, batch:   388/ 1052, ite: 89780] train loss: 0.004781, tar: 0.000216 
l0: 0.000193, l1: 0.000199, l2: 0.000170, l3: 0.000255, l4: 0.000335, l5: 0.000646, l6: 0.001119

[epoch: 342/1000, batch:   468/ 1052, ite: 89800] train loss: 0.004783, tar: 0.000216 
l0: 0.000073, l1: 0.000072, l2: 0.000101, l3: 0.000150, l4: 0.000226, l5: 0.000680, l6: 0.000873

[epoch: 342/1000, batch:   548/ 1052, ite: 89820] train loss: 0.004782, tar: 0.000216 
l0: 0.000414, l1: 0.000431, l2: 0.000381, l3: 0.000421, l4: 0.000865, l5: 0.001828, l6: 0.002964

[epoch: 342/1000, batch:   628/ 1052, ite: 89840] train loss: 0.004782, tar: 0.000216 
l0: 0.000156, l1: 0.000159, l2: 0.000153, l3: 0.000207, l4: 0.000524, l5: 0.001368, l6: 0.002041

[epoch: 342/1000, batch:   708/ 1052, ite: 89860] train loss: 0.004782, tar: 0.000216 
l0: 0.000220, l1: 0.000214, l2: 0.000301, l3: 0.000435, l4: 0.001040, l5: 0.001331, l6: 0.003103

[epoch: 342/1000, batch:   788/ 1052, ite: 89880] train loss: 0.004782, tar: 0.000216 
l0: 0.000315, l1: 0.000314, l2: 0.000321, l3: 0.000442, l4: 0.000516, l5: 0.001323, l6: 0.002396

[epoch: 342/1000, batch:   868/ 1052, ite: 89900] train loss: 0.004783, tar: 0.000216 
l0: 0.000218, l1: 0.000210, l2: 0.000296, l3: 0.000276, l4: 0.000656, l5: 0.001000, l6: 0.001726

[epoch: 342/1000, batch:   948/ 1052, ite: 89920] train loss: 0.004782, tar: 0.000216 
l0: 0.000088, l1: 0.000092, l2: 0.000107, l3: 0.000115, l4: 0.000246, l5: 0.000660, l6: 0.000719

[epoch: 342/1000, batch:  1028/ 1052, ite: 89940] train loss: 0.004782, tar: 0.000216 
[Epoch 342/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000237, l1: 0.000237, l2: 0.000280, l3: 0.000379, l4: 0.000766, l5: 0.001195, l6: 0.002347

[epoch: 343/1000, batch:    56/ 1052, ite: 89960] train loss: 0.004782, tar: 0.000216 
l0: 0.000247, l1: 0.000257, l2: 0.000290, l3: 0.000392, l4: 0.000752, l5: 0.002003, l6: 0.003391

[epoch: 343/1000, batch:   136/ 1052, ite: 89980] train loss: 0.004783, tar: 0.000216 
l0: 0.000177, l1: 0.000184, l2: 0.000191, l3: 0.000232, l4: 0.000396, l5: 0.001301, l6: 0.002086

[epoch: 343/1000, batch:   216/ 1052, ite: 90000] train loss: 0.004783, tar: 0.000216 
l0: 0.000312, l1: 0.000326, l2: 0.000340, l3: 0.000314, l4: 0.000524, l5: 0.001246, l6: 0.001776

[epoch: 343/1000, batch:   296/ 1052, ite: 90020] train loss: 0.004780, tar: 0.000216 
l0: 0.000325, l1: 0.000322, l2: 0.000380, l3: 0.000414, l4: 0.000981, l5: 0.001507, l6: 0.003144

[epoch: 343/1000, batch:   376/ 1052, ite: 90040] train loss: 0.004781, tar: 0.000216 
l0: 0.000136, l1: 0.000140, l2: 0.000181, l3: 0.000218, l4: 0.000347, l5: 0.000905, l6: 0.001519

[epoch: 343/1000, batch:   456/ 1052, ite: 90060] train loss: 0.004780, tar: 0.000216 
l0: 0.000081, l1: 0.000077, l2: 0.000108, l3: 0.000206, l4: 0.000367, l5: 0.001141, l6: 0.001726

[epoch: 343/1000, batch:   536/ 1052, ite: 90080] train loss: 0.004780, tar: 0.000216 
l0: 0.000102, l1: 0.000115, l2: 0.000103, l3: 0.000190, l4: 0.000415, l5: 0.000728, l6: 0.001466

[epoch: 343/1000, batch:   616/ 1052, ite: 90100] train loss: 0.004780, tar: 0.000216 
l0: 0.000488, l1: 0.000481, l2: 0.000542, l3: 0.000699, l4: 0.001234, l5: 0.002264, l6: 0.004265

[epoch: 343/1000, batch:   696/ 1052, ite: 90120] train loss: 0.004783, tar: 0.000216 
l0: 0.000207, l1: 0.000221, l2: 0.000208, l3: 0.000205, l4: 0.000301, l5: 0.000963, l6: 0.001148

[epoch: 343/1000, batch:   776/ 1052, ite: 90140] train loss: 0.004782, tar: 0.000216 
l0: 0.000116, l1: 0.000117, l2: 0.000129, l3: 0.000191, l4: 0.000347, l5: 0.000491, l6: 0.000778

[epoch: 343/1000, batch:   856/ 1052, ite: 90160] train loss: 0.004781, tar: 0.000215 
l0: 0.000137, l1: 0.000137, l2: 0.000159, l3: 0.000212, l4: 0.000457, l5: 0.001197, l6: 0.001684

[epoch: 343/1000, batch:   936/ 1052, ite: 90180] train loss: 0.004780, tar: 0.000215 
l0: 0.000406, l1: 0.000409, l2: 0.000477, l3: 0.000632, l4: 0.000881, l5: 0.002065, l6: 0.003962

[epoch: 343/1000, batch:  1016/ 1052, ite: 90200] train loss: 0.004778, tar: 0.000215 
[Epoch 343/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000070, l1: 0.000075, l2: 0.000088, l3: 0.000168, l4: 0.000298, l5: 0.000614, l6: 0.001173

[epoch: 344/1000, batch:    44/ 1052, ite: 90220] train loss: 0.004777, tar: 0.000215 
l0: 0.000376, l1: 0.000372, l2: 0.000448, l3: 0.000453, l4: 0.000652, l5: 0.001859, l6: 0.002853

[epoch: 344/1000, batch:   124/ 1052, ite: 90240] train loss: 0.004777, tar: 0.000215 
l0: 0.000371, l1: 0.000373, l2: 0.000404, l3: 0.000505, l4: 0.000653, l5: 0.001053, l6: 0.003016

[epoch: 344/1000, batch:   204/ 1052, ite: 90260] train loss: 0.004776, tar: 0.000215 
l0: 0.000115, l1: 0.000122, l2: 0.000139, l3: 0.000162, l4: 0.000326, l5: 0.000583, l6: 0.001090

[epoch: 344/1000, batch:   284/ 1052, ite: 90280] train loss: 0.004773, tar: 0.000215 
l0: 0.000138, l1: 0.000137, l2: 0.000179, l3: 0.000299, l4: 0.000592, l5: 0.000613, l6: 0.002349

[epoch: 344/1000, batch:   364/ 1052, ite: 90300] train loss: 0.004773, tar: 0.000215 
l0: 0.000419, l1: 0.000416, l2: 0.000444, l3: 0.000514, l4: 0.000770, l5: 0.001555, l6: 0.001888

[epoch: 344/1000, batch:   444/ 1052, ite: 90320] train loss: 0.004772, tar: 0.000215 
l0: 0.000129, l1: 0.000132, l2: 0.000162, l3: 0.000250, l4: 0.000638, l5: 0.000988, l6: 0.001090

[epoch: 344/1000, batch:   524/ 1052, ite: 90340] train loss: 0.004774, tar: 0.000215 
l0: 0.000113, l1: 0.000111, l2: 0.000161, l3: 0.000245, l4: 0.000513, l5: 0.001090, l6: 0.001729

[epoch: 344/1000, batch:   604/ 1052, ite: 90360] train loss: 0.004772, tar: 0.000214 
l0: 0.000174, l1: 0.000172, l2: 0.000214, l3: 0.000303, l4: 0.000349, l5: 0.000796, l6: 0.002719

[epoch: 344/1000, batch:   684/ 1052, ite: 90380] train loss: 0.004773, tar: 0.000214 
l0: 0.000261, l1: 0.000262, l2: 0.000311, l3: 0.000466, l4: 0.001016, l5: 0.001682, l6: 0.004160

[epoch: 344/1000, batch:   764/ 1052, ite: 90400] train loss: 0.004773, tar: 0.000214 
l0: 0.000452, l1: 0.000465, l2: 0.000512, l3: 0.000650, l4: 0.001192, l5: 0.003254, l6: 0.005944

[epoch: 344/1000, batch:   844/ 1052, ite: 90420] train loss: 0.004774, tar: 0.000214 
l0: 0.000187, l1: 0.000185, l2: 0.000218, l3: 0.000331, l4: 0.000566, l5: 0.001007, l6: 0.001701

[epoch: 344/1000, batch:   924/ 1052, ite: 90440] train loss: 0.004774, tar: 0.000214 
l0: 0.000241, l1: 0.000254, l2: 0.000305, l3: 0.000403, l4: 0.000591, l5: 0.001527, l6: 0.002399

[epoch: 344/1000, batch:  1004/ 1052, ite: 90460] train loss: 0.004773, tar: 0.000214 
[Epoch 344/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000075, l1: 0.000074, l2: 0.000099, l3: 0.000165, l4: 0.000375, l5: 0.000471, l6: 0.001415

[epoch: 345/1000, batch:    32/ 1052, ite: 90480] train loss: 0.004774, tar: 0.000214 
l0: 0.000293, l1: 0.000294, l2: 0.000338, l3: 0.000471, l4: 0.000829, l5: 0.001261, l6: 0.003261

[epoch: 345/1000, batch:   112/ 1052, ite: 90500] train loss: 0.004773, tar: 0.000214 
l0: 0.000207, l1: 0.000194, l2: 0.000259, l3: 0.000382, l4: 0.000487, l5: 0.000775, l6: 0.001927

[epoch: 345/1000, batch:   192/ 1052, ite: 90520] train loss: 0.004771, tar: 0.000214 
l0: 0.000191, l1: 0.000196, l2: 0.000197, l3: 0.000271, l4: 0.000589, l5: 0.000774, l6: 0.002602

[epoch: 345/1000, batch:   272/ 1052, ite: 90540] train loss: 0.004769, tar: 0.000214 
l0: 0.000338, l1: 0.000331, l2: 0.000397, l3: 0.000422, l4: 0.000883, l5: 0.002221, l6: 0.002755

[epoch: 345/1000, batch:   352/ 1052, ite: 90560] train loss: 0.004770, tar: 0.000214 
l0: 0.000439, l1: 0.000438, l2: 0.000602, l3: 0.000693, l4: 0.001085, l5: 0.003083, l6: 0.004724

[epoch: 345/1000, batch:   432/ 1052, ite: 90580] train loss: 0.004771, tar: 0.000214 
l0: 0.000132, l1: 0.000138, l2: 0.000149, l3: 0.000196, l4: 0.000465, l5: 0.001296, l6: 0.001821

[epoch: 345/1000, batch:   512/ 1052, ite: 90600] train loss: 0.004772, tar: 0.000214 
l0: 0.000206, l1: 0.000203, l2: 0.000267, l3: 0.000315, l4: 0.000550, l5: 0.001125, l6: 0.001834

[epoch: 345/1000, batch:   592/ 1052, ite: 90620] train loss: 0.004771, tar: 0.000214 
l0: 0.000361, l1: 0.000365, l2: 0.000445, l3: 0.000631, l4: 0.001054, l5: 0.002260, l6: 0.003324

[epoch: 345/1000, batch:   672/ 1052, ite: 90640] train loss: 0.004773, tar: 0.000214 
l0: 0.000115, l1: 0.000114, l2: 0.000149, l3: 0.000226, l4: 0.000406, l5: 0.000823, l6: 0.001304

[epoch: 345/1000, batch:   752/ 1052, ite: 90660] train loss: 0.004773, tar: 0.000214 
l0: 0.000179, l1: 0.000184, l2: 0.000225, l3: 0.000328, l4: 0.000738, l5: 0.002201, l6: 0.002253

[epoch: 345/1000, batch:   832/ 1052, ite: 90680] train loss: 0.004774, tar: 0.000214 
l0: 0.000216, l1: 0.000215, l2: 0.000256, l3: 0.000288, l4: 0.000510, l5: 0.000847, l6: 0.001998

[epoch: 345/1000, batch:   912/ 1052, ite: 90700] train loss: 0.004773, tar: 0.000214 
l0: 0.000113, l1: 0.000118, l2: 0.000126, l3: 0.000177, l4: 0.000459, l5: 0.001163, l6: 0.001648

[epoch: 345/1000, batch:   992/ 1052, ite: 90720] train loss: 0.004772, tar: 0.000214 
[Epoch 345/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000111, l1: 0.000114, l2: 0.000140, l3: 0.000181, l4: 0.000462, l5: 0.000738, l6: 0.002061

[epoch: 346/1000, batch:    20/ 1052, ite: 90740] train loss: 0.004773, tar: 0.000214 
l0: 0.000203, l1: 0.000187, l2: 0.000316, l3: 0.000566, l4: 0.001105, l5: 0.001710, l6: 0.002452

[epoch: 346/1000, batch:   100/ 1052, ite: 90760] train loss: 0.004773, tar: 0.000214 
l0: 0.000151, l1: 0.000154, l2: 0.000161, l3: 0.000194, l4: 0.000425, l5: 0.000744, l6: 0.001847

[epoch: 346/1000, batch:   180/ 1052, ite: 90780] train loss: 0.004773, tar: 0.000214 
l0: 0.000181, l1: 0.000182, l2: 0.000209, l3: 0.000274, l4: 0.000447, l5: 0.001218, l6: 0.001936

[epoch: 346/1000, batch:   260/ 1052, ite: 90800] train loss: 0.004772, tar: 0.000214 
l0: 0.000144, l1: 0.000142, l2: 0.000194, l3: 0.000244, l4: 0.000455, l5: 0.001125, l6: 0.001722

[epoch: 346/1000, batch:   340/ 1052, ite: 90820] train loss: 0.004773, tar: 0.000214 
l0: 0.000162, l1: 0.000163, l2: 0.000162, l3: 0.000224, l4: 0.000538, l5: 0.000969, l6: 0.001204

[epoch: 346/1000, batch:   420/ 1052, ite: 90840] train loss: 0.004771, tar: 0.000213 
l0: 0.000193, l1: 0.000187, l2: 0.000265, l3: 0.000388, l4: 0.000773, l5: 0.001521, l6: 0.002827

[epoch: 346/1000, batch:   500/ 1052, ite: 90860] train loss: 0.004772, tar: 0.000213 
l0: 0.000084, l1: 0.000086, l2: 0.000097, l3: 0.000166, l4: 0.000348, l5: 0.000802, l6: 0.001073

[epoch: 346/1000, batch:   580/ 1052, ite: 90880] train loss: 0.004770, tar: 0.000213 
l0: 0.000096, l1: 0.000104, l2: 0.000128, l3: 0.000201, l4: 0.000443, l5: 0.000837, l6: 0.001905

[epoch: 346/1000, batch:   660/ 1052, ite: 90900] train loss: 0.004772, tar: 0.000213 
l0: 0.000234, l1: 0.000244, l2: 0.000267, l3: 0.000373, l4: 0.000701, l5: 0.001386, l6: 0.002535

[epoch: 346/1000, batch:   740/ 1052, ite: 90920] train loss: 0.004772, tar: 0.000213 
l0: 0.000146, l1: 0.000150, l2: 0.000172, l3: 0.000269, l4: 0.000501, l5: 0.001245, l6: 0.002428

[epoch: 346/1000, batch:   820/ 1052, ite: 90940] train loss: 0.004772, tar: 0.000213 
l0: 0.000138, l1: 0.000139, l2: 0.000174, l3: 0.000217, l4: 0.000495, l5: 0.001226, l6: 0.002054

[epoch: 346/1000, batch:   900/ 1052, ite: 90960] train loss: 0.004772, tar: 0.000213 
l0: 0.000072, l1: 0.000073, l2: 0.000087, l3: 0.000161, l4: 0.000218, l5: 0.000761, l6: 0.000948

[epoch: 346/1000, batch:   980/ 1052, ite: 90980] train loss: 0.004771, tar: 0.000213 
[Epoch 346/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000353, l1: 0.000361, l2: 0.000462, l3: 0.000718, l4: 0.001613, l5: 0.002591, l6: 0.003971

[epoch: 347/1000, batch:     8/ 1052, ite: 91000] train loss: 0.004772, tar: 0.000213 
l0: 0.000155, l1: 0.000152, l2: 0.000175, l3: 0.000235, l4: 0.000459, l5: 0.000932, l6: 0.001191

[epoch: 347/1000, batch:    88/ 1052, ite: 91020] train loss: 0.004772, tar: 0.000213 
l0: 0.000130, l1: 0.000128, l2: 0.000183, l3: 0.000313, l4: 0.000651, l5: 0.001600, l6: 0.002952

[epoch: 347/1000, batch:   168/ 1052, ite: 91040] train loss: 0.004772, tar: 0.000213 
l0: 0.000114, l1: 0.000118, l2: 0.000118, l3: 0.000162, l4: 0.000280, l5: 0.000487, l6: 0.001644

[epoch: 347/1000, batch:   248/ 1052, ite: 91060] train loss: 0.004770, tar: 0.000213 
l0: 0.000268, l1: 0.000275, l2: 0.000258, l3: 0.000406, l4: 0.000739, l5: 0.001399, l6: 0.002668

[epoch: 347/1000, batch:   328/ 1052, ite: 91080] train loss: 0.004769, tar: 0.000213 
l0: 0.000131, l1: 0.000137, l2: 0.000149, l3: 0.000203, l4: 0.000399, l5: 0.000815, l6: 0.001967

[epoch: 347/1000, batch:   408/ 1052, ite: 91100] train loss: 0.004768, tar: 0.000213 
l0: 0.000184, l1: 0.000187, l2: 0.000229, l3: 0.000299, l4: 0.000513, l5: 0.001305, l6: 0.002285

[epoch: 347/1000, batch:   488/ 1052, ite: 91120] train loss: 0.004768, tar: 0.000213 
l0: 0.000138, l1: 0.000144, l2: 0.000134, l3: 0.000172, l4: 0.000407, l5: 0.000931, l6: 0.000794

[epoch: 347/1000, batch:   568/ 1052, ite: 91140] train loss: 0.004767, tar: 0.000213 
l0: 0.000166, l1: 0.000164, l2: 0.000210, l3: 0.000257, l4: 0.000422, l5: 0.000679, l6: 0.001162

[epoch: 347/1000, batch:   648/ 1052, ite: 91160] train loss: 0.004766, tar: 0.000213 
l0: 0.000101, l1: 0.000102, l2: 0.000126, l3: 0.000210, l4: 0.000497, l5: 0.000834, l6: 0.001469

[epoch: 347/1000, batch:   728/ 1052, ite: 91180] train loss: 0.004766, tar: 0.000213 
l0: 0.000304, l1: 0.000304, l2: 0.000372, l3: 0.000433, l4: 0.000613, l5: 0.001820, l6: 0.003697

[epoch: 347/1000, batch:   808/ 1052, ite: 91200] train loss: 0.004766, tar: 0.000213 
l0: 0.000271, l1: 0.000275, l2: 0.000322, l3: 0.000507, l4: 0.000615, l5: 0.001271, l6: 0.002017

[epoch: 347/1000, batch:   888/ 1052, ite: 91220] train loss: 0.004767, tar: 0.000213 
l0: 0.000129, l1: 0.000127, l2: 0.000168, l3: 0.000289, l4: 0.000577, l5: 0.000926, l6: 0.001422

[epoch: 347/1000, batch:   968/ 1052, ite: 91240] train loss: 0.004766, tar: 0.000212 
l0: 0.000122, l1: 0.000122, l2: 0.000156, l3: 0.000247, l4: 0.000471, l5: 0.000994, l6: 0.001364

[epoch: 347/1000, batch:  1048/ 1052, ite: 91260] train loss: 0.004767, tar: 0.000213 
[Epoch 347/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000157, l1: 0.000158, l2: 0.000168, l3: 0.000231, l4: 0.000405, l5: 0.001130, l6: 0.001457

[epoch: 348/1000, batch:    76/ 1052, ite: 91280] train loss: 0.004767, tar: 0.000212 
l0: 0.000193, l1: 0.000201, l2: 0.000194, l3: 0.000250, l4: 0.000401, l5: 0.001175, l6: 0.001020

[epoch: 348/1000, batch:   156/ 1052, ite: 91300] train loss: 0.004767, tar: 0.000212 
l0: 0.000128, l1: 0.000129, l2: 0.000173, l3: 0.000210, l4: 0.000324, l5: 0.001038, l6: 0.001171

[epoch: 348/1000, batch:   236/ 1052, ite: 91320] train loss: 0.004766, tar: 0.000212 
l0: 0.000151, l1: 0.000144, l2: 0.000207, l3: 0.000255, l4: 0.000455, l5: 0.000982, l6: 0.001547

[epoch: 348/1000, batch:   316/ 1052, ite: 91340] train loss: 0.004765, tar: 0.000212 
l0: 0.000400, l1: 0.000410, l2: 0.000387, l3: 0.000542, l4: 0.000923, l5: 0.001896, l6: 0.003059

[epoch: 348/1000, batch:   396/ 1052, ite: 91360] train loss: 0.004765, tar: 0.000212 
l0: 0.000205, l1: 0.000213, l2: 0.000216, l3: 0.000190, l4: 0.000341, l5: 0.000655, l6: 0.001761

[epoch: 348/1000, batch:   476/ 1052, ite: 91380] train loss: 0.004766, tar: 0.000212 
l0: 0.000166, l1: 0.000170, l2: 0.000173, l3: 0.000275, l4: 0.000584, l5: 0.001099, l6: 0.001858

[epoch: 348/1000, batch:   556/ 1052, ite: 91400] train loss: 0.004766, tar: 0.000212 
l0: 0.000092, l1: 0.000099, l2: 0.000101, l3: 0.000142, l4: 0.000413, l5: 0.000984, l6: 0.001326

[epoch: 348/1000, batch:   636/ 1052, ite: 91420] train loss: 0.004766, tar: 0.000212 
l0: 0.000184, l1: 0.000172, l2: 0.000167, l3: 0.000246, l4: 0.000637, l5: 0.000879, l6: 0.000884

[epoch: 348/1000, batch:   716/ 1052, ite: 91440] train loss: 0.004766, tar: 0.000212 
l0: 0.000102, l1: 0.000107, l2: 0.000096, l3: 0.000114, l4: 0.000209, l5: 0.000346, l6: 0.000701

[epoch: 348/1000, batch:   796/ 1052, ite: 91460] train loss: 0.004765, tar: 0.000212 
l0: 0.000113, l1: 0.000113, l2: 0.000148, l3: 0.000217, l4: 0.000413, l5: 0.000702, l6: 0.001213

[epoch: 348/1000, batch:   876/ 1052, ite: 91480] train loss: 0.004766, tar: 0.000212 
l0: 0.000121, l1: 0.000124, l2: 0.000137, l3: 0.000229, l4: 0.000451, l5: 0.000787, l6: 0.001810

[epoch: 348/1000, batch:   956/ 1052, ite: 91500] train loss: 0.004765, tar: 0.000212 
l0: 0.000200, l1: 0.000200, l2: 0.000233, l3: 0.000333, l4: 0.000674, l5: 0.001023, l6: 0.001935

[epoch: 348/1000, batch:  1036/ 1052, ite: 91520] train loss: 0.004764, tar: 0.000212 
[Epoch 348/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000408, l1: 0.000419, l2: 0.000406, l3: 0.000518, l4: 0.000826, l5: 0.001500, l6: 0.003521

[epoch: 349/1000, batch:    64/ 1052, ite: 91540] train loss: 0.004765, tar: 0.000212 
l0: 0.000129, l1: 0.000126, l2: 0.000200, l3: 0.000284, l4: 0.000442, l5: 0.000876, l6: 0.001563

[epoch: 349/1000, batch:   144/ 1052, ite: 91560] train loss: 0.004766, tar: 0.000212 
l0: 0.000281, l1: 0.000285, l2: 0.000353, l3: 0.000528, l4: 0.001136, l5: 0.001162, l6: 0.002436

[epoch: 349/1000, batch:   224/ 1052, ite: 91580] train loss: 0.004766, tar: 0.000212 
l0: 0.000191, l1: 0.000188, l2: 0.000239, l3: 0.000299, l4: 0.000666, l5: 0.000945, l6: 0.001819

[epoch: 349/1000, batch:   304/ 1052, ite: 91600] train loss: 0.004764, tar: 0.000212 
l0: 0.000071, l1: 0.000074, l2: 0.000093, l3: 0.000133, l4: 0.000382, l5: 0.000706, l6: 0.001124

[epoch: 349/1000, batch:   384/ 1052, ite: 91620] train loss: 0.004764, tar: 0.000212 
l0: 0.000269, l1: 0.000276, l2: 0.000289, l3: 0.000381, l4: 0.000726, l5: 0.001390, l6: 0.003732

[epoch: 349/1000, batch:   464/ 1052, ite: 91640] train loss: 0.004763, tar: 0.000211 
l0: 0.000195, l1: 0.000193, l2: 0.000251, l3: 0.000409, l4: 0.000758, l5: 0.001522, l6: 0.002882

[epoch: 349/1000, batch:   544/ 1052, ite: 91660] train loss: 0.004762, tar: 0.000211 
l0: 0.000088, l1: 0.000088, l2: 0.000114, l3: 0.000235, l4: 0.000533, l5: 0.001531, l6: 0.001847

[epoch: 349/1000, batch:   624/ 1052, ite: 91680] train loss: 0.004762, tar: 0.000211 
l0: 0.000209, l1: 0.000208, l2: 0.000268, l3: 0.000473, l4: 0.000723, l5: 0.001316, l6: 0.002232

[epoch: 349/1000, batch:   704/ 1052, ite: 91700] train loss: 0.004761, tar: 0.000211 
l0: 0.000187, l1: 0.000200, l2: 0.000188, l3: 0.000237, l4: 0.000524, l5: 0.001034, l6: 0.001365

[epoch: 349/1000, batch:   784/ 1052, ite: 91720] train loss: 0.004760, tar: 0.000211 
l0: 0.000509, l1: 0.000483, l2: 0.000542, l3: 0.000553, l4: 0.000595, l5: 0.001289, l6: 0.001838

[epoch: 349/1000, batch:   864/ 1052, ite: 91740] train loss: 0.004760, tar: 0.000211 
l0: 0.000082, l1: 0.000085, l2: 0.000094, l3: 0.000125, l4: 0.000367, l5: 0.000663, l6: 0.001453

[epoch: 349/1000, batch:   944/ 1052, ite: 91760] train loss: 0.004759, tar: 0.000211 
l0: 0.000249, l1: 0.000255, l2: 0.000289, l3: 0.000342, l4: 0.000556, l5: 0.001179, l6: 0.001596

[epoch: 349/1000, batch:  1024/ 1052, ite: 91780] train loss: 0.004758, tar: 0.000211 
[Epoch 349/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000148, l1: 0.000148, l2: 0.000181, l3: 0.000257, l4: 0.000456, l5: 0.001435, l6: 0.001340

[epoch: 350/1000, batch:    52/ 1052, ite: 91800] train loss: 0.004757, tar: 0.000211 
l0: 0.000133, l1: 0.000125, l2: 0.000183, l3: 0.000355, l4: 0.000589, l5: 0.001133, l6: 0.002234

[epoch: 350/1000, batch:   132/ 1052, ite: 91820] train loss: 0.004757, tar: 0.000211 
l0: 0.000120, l1: 0.000119, l2: 0.000136, l3: 0.000161, l4: 0.000328, l5: 0.000638, l6: 0.001371

[epoch: 350/1000, batch:   212/ 1052, ite: 91840] train loss: 0.004756, tar: 0.000211 
l0: 0.000107, l1: 0.000110, l2: 0.000116, l3: 0.000156, l4: 0.000352, l5: 0.000910, l6: 0.001353

[epoch: 350/1000, batch:   292/ 1052, ite: 91860] train loss: 0.004756, tar: 0.000211 
l0: 0.000130, l1: 0.000130, l2: 0.000164, l3: 0.000197, l4: 0.000464, l5: 0.000353, l6: 0.001461

[epoch: 350/1000, batch:   372/ 1052, ite: 91880] train loss: 0.004755, tar: 0.000211 
l0: 0.000150, l1: 0.000158, l2: 0.000146, l3: 0.000175, l4: 0.000310, l5: 0.000543, l6: 0.001273

[epoch: 350/1000, batch:   452/ 1052, ite: 91900] train loss: 0.004754, tar: 0.000210 
l0: 0.000160, l1: 0.000165, l2: 0.000199, l3: 0.000266, l4: 0.000345, l5: 0.000971, l6: 0.001997

[epoch: 350/1000, batch:   532/ 1052, ite: 91920] train loss: 0.004755, tar: 0.000210 
l0: 0.000234, l1: 0.000228, l2: 0.000285, l3: 0.000348, l4: 0.000494, l5: 0.001367, l6: 0.001725

[epoch: 350/1000, batch:   612/ 1052, ite: 91940] train loss: 0.004755, tar: 0.000210 
l0: 0.000143, l1: 0.000138, l2: 0.000171, l3: 0.000232, l4: 0.000507, l5: 0.000954, l6: 0.001480

[epoch: 350/1000, batch:   692/ 1052, ite: 91960] train loss: 0.004756, tar: 0.000210 
l0: 0.000283, l1: 0.000284, l2: 0.000300, l3: 0.000330, l4: 0.000574, l5: 0.002088, l6: 0.002336

[epoch: 350/1000, batch:   772/ 1052, ite: 91980] train loss: 0.004756, tar: 0.000210 
l0: 0.000430, l1: 0.000428, l2: 0.000472, l3: 0.000607, l4: 0.000790, l5: 0.001540, l6: 0.003687

[epoch: 350/1000, batch:   852/ 1052, ite: 92000] train loss: 0.004755, tar: 0.000210 
l0: 0.000076, l1: 0.000076, l2: 0.000107, l3: 0.000162, l4: 0.000406, l5: 0.001000, l6: 0.001636

[epoch: 350/1000, batch:   932/ 1052, ite: 92020] train loss: 0.004754, tar: 0.000210 
l0: 0.000364, l1: 0.000345, l2: 0.000419, l3: 0.000551, l4: 0.000711, l5: 0.001105, l6: 0.002580

[epoch: 350/1000, batch:  1012/ 1052, ite: 92040] train loss: 0.004753, tar: 0.000210 
[Epoch 350/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000301, l1: 0.000317, l2: 0.000352, l3: 0.000494, l4: 0.001134, l5: 0.002440, l6: 0.004179

[epoch: 351/1000, batch:    40/ 1052, ite: 92060] train loss: 0.004755, tar: 0.000210 
l0: 0.000488, l1: 0.000488, l2: 0.000483, l3: 0.000684, l4: 0.000919, l5: 0.001458, l6: 0.002458

[epoch: 351/1000, batch:   120/ 1052, ite: 92080] train loss: 0.004755, tar: 0.000210 
l0: 0.000148, l1: 0.000146, l2: 0.000167, l3: 0.000230, l4: 0.000383, l5: 0.000711, l6: 0.001248

[epoch: 351/1000, batch:   200/ 1052, ite: 92100] train loss: 0.004754, tar: 0.000210 
l0: 0.000163, l1: 0.000155, l2: 0.000235, l3: 0.000375, l4: 0.000369, l5: 0.001242, l6: 0.001495

[epoch: 351/1000, batch:   280/ 1052, ite: 92120] train loss: 0.004755, tar: 0.000210 
l0: 0.000137, l1: 0.000132, l2: 0.000187, l3: 0.000422, l4: 0.000694, l5: 0.001593, l6: 0.001570

[epoch: 351/1000, batch:   360/ 1052, ite: 92140] train loss: 0.004754, tar: 0.000210 
l0: 0.000211, l1: 0.000214, l2: 0.000216, l3: 0.000292, l4: 0.000558, l5: 0.001262, l6: 0.002030

[epoch: 351/1000, batch:   440/ 1052, ite: 92160] train loss: 0.004753, tar: 0.000210 
l0: 0.000237, l1: 0.000248, l2: 0.000260, l3: 0.000345, l4: 0.000530, l5: 0.001001, l6: 0.002125

[epoch: 351/1000, batch:   520/ 1052, ite: 92180] train loss: 0.004753, tar: 0.000210 
l0: 0.000352, l1: 0.000383, l2: 0.000358, l3: 0.000436, l4: 0.000552, l5: 0.001336, l6: 0.002232

[epoch: 351/1000, batch:   600/ 1052, ite: 92200] train loss: 0.004753, tar: 0.000210 
l0: 0.000140, l1: 0.000139, l2: 0.000157, l3: 0.000210, l4: 0.000450, l5: 0.000846, l6: 0.001638

[epoch: 351/1000, batch:   680/ 1052, ite: 92220] train loss: 0.004753, tar: 0.000210 
l0: 0.000200, l1: 0.000198, l2: 0.000289, l3: 0.000395, l4: 0.000756, l5: 0.001791, l6: 0.002658

[epoch: 351/1000, batch:   760/ 1052, ite: 92240] train loss: 0.004752, tar: 0.000210 
l0: 0.000179, l1: 0.000181, l2: 0.000176, l3: 0.000264, l4: 0.000451, l5: 0.000570, l6: 0.001700

[epoch: 351/1000, batch:   840/ 1052, ite: 92260] train loss: 0.004752, tar: 0.000210 
l0: 0.000159, l1: 0.000159, l2: 0.000212, l3: 0.000279, l4: 0.000389, l5: 0.001133, l6: 0.001418

[epoch: 351/1000, batch:   920/ 1052, ite: 92280] train loss: 0.004751, tar: 0.000210 
l0: 0.000136, l1: 0.000131, l2: 0.000177, l3: 0.000236, l4: 0.000370, l5: 0.001119, l6: 0.001435

[epoch: 351/1000, batch:  1000/ 1052, ite: 92300] train loss: 0.004750, tar: 0.000209 
[Epoch 351/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000137, l1: 0.000132, l2: 0.000193, l3: 0.000224, l4: 0.000500, l5: 0.001514, l6: 0.001961

[epoch: 352/1000, batch:    28/ 1052, ite: 92320] train loss: 0.004749, tar: 0.000209 
l0: 0.000224, l1: 0.000224, l2: 0.000283, l3: 0.000409, l4: 0.000710, l5: 0.001504, l6: 0.002156

[epoch: 352/1000, batch:   108/ 1052, ite: 92340] train loss: 0.004750, tar: 0.000209 
l0: 0.000143, l1: 0.000149, l2: 0.000176, l3: 0.000272, l4: 0.000537, l5: 0.001123, l6: 0.001655

[epoch: 352/1000, batch:   188/ 1052, ite: 92360] train loss: 0.004750, tar: 0.000209 
l0: 0.000335, l1: 0.000340, l2: 0.000349, l3: 0.000445, l4: 0.000855, l5: 0.001660, l6: 0.002424

[epoch: 352/1000, batch:   268/ 1052, ite: 92380] train loss: 0.004750, tar: 0.000209 
l0: 0.000153, l1: 0.000155, l2: 0.000195, l3: 0.000199, l4: 0.000453, l5: 0.001103, l6: 0.001826

[epoch: 352/1000, batch:   348/ 1052, ite: 92400] train loss: 0.004749, tar: 0.000209 
l0: 0.000233, l1: 0.000232, l2: 0.000321, l3: 0.000618, l4: 0.001056, l5: 0.002549, l6: 0.003477

[epoch: 352/1000, batch:   428/ 1052, ite: 92420] train loss: 0.004749, tar: 0.000209 
l0: 0.000129, l1: 0.000127, l2: 0.000150, l3: 0.000213, l4: 0.000319, l5: 0.001095, l6: 0.001732

[epoch: 352/1000, batch:   508/ 1052, ite: 92440] train loss: 0.004748, tar: 0.000209 
l0: 0.000108, l1: 0.000111, l2: 0.000125, l3: 0.000208, l4: 0.000245, l5: 0.000552, l6: 0.001666

[epoch: 352/1000, batch:   588/ 1052, ite: 92460] train loss: 0.004748, tar: 0.000209 
l0: 0.000185, l1: 0.000190, l2: 0.000190, l3: 0.000260, l4: 0.000332, l5: 0.001150, l6: 0.001924

[epoch: 352/1000, batch:   668/ 1052, ite: 92480] train loss: 0.004748, tar: 0.000209 
l0: 0.000224, l1: 0.000227, l2: 0.000264, l3: 0.000387, l4: 0.000682, l5: 0.001671, l6: 0.002110

[epoch: 352/1000, batch:   748/ 1052, ite: 92500] train loss: 0.004749, tar: 0.000209 
l0: 0.000360, l1: 0.000357, l2: 0.000405, l3: 0.000612, l4: 0.000720, l5: 0.000946, l6: 0.001445

[epoch: 352/1000, batch:   828/ 1052, ite: 92520] train loss: 0.004749, tar: 0.000209 
l0: 0.000127, l1: 0.000125, l2: 0.000170, l3: 0.000247, l4: 0.000477, l5: 0.000812, l6: 0.002196

[epoch: 352/1000, batch:   908/ 1052, ite: 92540] train loss: 0.004748, tar: 0.000209 
l0: 0.000142, l1: 0.000139, l2: 0.000177, l3: 0.000326, l4: 0.000652, l5: 0.001641, l6: 0.001920

[epoch: 352/1000, batch:   988/ 1052, ite: 92560] train loss: 0.004747, tar: 0.000209 
[Epoch 352/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000207, l1: 0.000215, l2: 0.000232, l3: 0.000336, l4: 0.000604, l5: 0.001077, l6: 0.002240

[epoch: 353/1000, batch:    16/ 1052, ite: 92580] train loss: 0.004746, tar: 0.000209 
l0: 0.000117, l1: 0.000116, l2: 0.000194, l3: 0.000263, l4: 0.000498, l5: 0.001149, l6: 0.002626

[epoch: 353/1000, batch:    96/ 1052, ite: 92600] train loss: 0.004745, tar: 0.000209 
l0: 0.000090, l1: 0.000092, l2: 0.000117, l3: 0.000226, l4: 0.000325, l5: 0.000738, l6: 0.000927

[epoch: 353/1000, batch:   176/ 1052, ite: 92620] train loss: 0.004744, tar: 0.000209 
l0: 0.000123, l1: 0.000124, l2: 0.000158, l3: 0.000264, l4: 0.000650, l5: 0.001228, l6: 0.002177

[epoch: 353/1000, batch:   256/ 1052, ite: 92640] train loss: 0.004744, tar: 0.000208 
l0: 0.000239, l1: 0.000242, l2: 0.000317, l3: 0.000518, l4: 0.000992, l5: 0.001190, l6: 0.003303

[epoch: 353/1000, batch:   336/ 1052, ite: 92660] train loss: 0.004744, tar: 0.000208 
l0: 0.000157, l1: 0.000156, l2: 0.000181, l3: 0.000291, l4: 0.000481, l5: 0.001190, l6: 0.001423

[epoch: 353/1000, batch:   416/ 1052, ite: 92680] train loss: 0.004743, tar: 0.000208 
l0: 0.000109, l1: 0.000104, l2: 0.000182, l3: 0.000305, l4: 0.000453, l5: 0.001202, l6: 0.001712

[epoch: 353/1000, batch:   496/ 1052, ite: 92700] train loss: 0.004742, tar: 0.000208 
l0: 0.000271, l1: 0.000281, l2: 0.000374, l3: 0.000476, l4: 0.000680, l5: 0.001942, l6: 0.004014

[epoch: 353/1000, batch:   576/ 1052, ite: 92720] train loss: 0.004741, tar: 0.000208 
l0: 0.000183, l1: 0.000183, l2: 0.000221, l3: 0.000364, l4: 0.000825, l5: 0.001886, l6: 0.002401

[epoch: 353/1000, batch:   656/ 1052, ite: 92740] train loss: 0.004742, tar: 0.000208 
l0: 0.000267, l1: 0.000260, l2: 0.000339, l3: 0.000467, l4: 0.000800, l5: 0.001234, l6: 0.002145

[epoch: 353/1000, batch:   736/ 1052, ite: 92760] train loss: 0.004740, tar: 0.000208 
l0: 0.000198, l1: 0.000201, l2: 0.000230, l3: 0.000345, l4: 0.000649, l5: 0.001030, l6: 0.002299

[epoch: 353/1000, batch:   816/ 1052, ite: 92780] train loss: 0.004739, tar: 0.000208 
l0: 0.000273, l1: 0.000275, l2: 0.000298, l3: 0.000341, l4: 0.000756, l5: 0.001767, l6: 0.001383

[epoch: 353/1000, batch:   896/ 1052, ite: 92800] train loss: 0.004741, tar: 0.000208 
l0: 0.000340, l1: 0.000356, l2: 0.000371, l3: 0.000354, l4: 0.000679, l5: 0.001993, l6: 0.003590

[epoch: 353/1000, batch:   976/ 1052, ite: 92820] train loss: 0.004743, tar: 0.000208 
[Epoch 353/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000073, l1: 0.000074, l2: 0.000087, l3: 0.000121, l4: 0.000246, l5: 0.000585, l6: 0.000646

[epoch: 354/1000, batch:     4/ 1052, ite: 92840] train loss: 0.004743, tar: 0.000208 
l0: 0.000313, l1: 0.000319, l2: 0.000366, l3: 0.000457, l4: 0.000768, l5: 0.001635, l6: 0.002833

[epoch: 354/1000, batch:    84/ 1052, ite: 92860] train loss: 0.004742, tar: 0.000208 
l0: 0.000105, l1: 0.000107, l2: 0.000120, l3: 0.000166, l4: 0.000317, l5: 0.000910, l6: 0.001641

[epoch: 354/1000, batch:   164/ 1052, ite: 92880] train loss: 0.004741, tar: 0.000208 
l0: 0.000251, l1: 0.000249, l2: 0.000276, l3: 0.000392, l4: 0.000787, l5: 0.001434, l6: 0.003028

[epoch: 354/1000, batch:   244/ 1052, ite: 92900] train loss: 0.004741, tar: 0.000208 
l0: 0.000149, l1: 0.000158, l2: 0.000156, l3: 0.000241, l4: 0.000449, l5: 0.001102, l6: 0.001514

[epoch: 354/1000, batch:   324/ 1052, ite: 92920] train loss: 0.004741, tar: 0.000208 
l0: 0.000455, l1: 0.000448, l2: 0.000516, l3: 0.000696, l4: 0.001092, l5: 0.001999, l6: 0.003715

[epoch: 354/1000, batch:   404/ 1052, ite: 92940] train loss: 0.004743, tar: 0.000208 
l0: 0.000181, l1: 0.000184, l2: 0.000220, l3: 0.000365, l4: 0.000747, l5: 0.001698, l6: 0.002039

[epoch: 354/1000, batch:   484/ 1052, ite: 92960] train loss: 0.004742, tar: 0.000208 
l0: 0.000066, l1: 0.000066, l2: 0.000074, l3: 0.000132, l4: 0.000276, l5: 0.000553, l6: 0.000651

[epoch: 354/1000, batch:   564/ 1052, ite: 92980] train loss: 0.004741, tar: 0.000208 
l0: 0.000266, l1: 0.000266, l2: 0.000331, l3: 0.000545, l4: 0.001037, l5: 0.002194, l6: 0.002232

[epoch: 354/1000, batch:   644/ 1052, ite: 93000] train loss: 0.004743, tar: 0.000208 
l0: 0.000089, l1: 0.000092, l2: 0.000108, l3: 0.000167, l4: 0.000329, l5: 0.000830, l6: 0.001522

[epoch: 354/1000, batch:   724/ 1052, ite: 93020] train loss: 0.004743, tar: 0.000208 
l0: 0.000117, l1: 0.000113, l2: 0.000146, l3: 0.000239, l4: 0.000475, l5: 0.001010, l6: 0.001933

[epoch: 354/1000, batch:   804/ 1052, ite: 93040] train loss: 0.004743, tar: 0.000208 
l0: 0.000244, l1: 0.000237, l2: 0.000277, l3: 0.000289, l4: 0.000456, l5: 0.001183, l6: 0.001540

[epoch: 354/1000, batch:   884/ 1052, ite: 93060] train loss: 0.004742, tar: 0.000208 
l0: 0.000176, l1: 0.000179, l2: 0.000217, l3: 0.000226, l4: 0.000434, l5: 0.000935, l6: 0.001758

[epoch: 354/1000, batch:   964/ 1052, ite: 93080] train loss: 0.004741, tar: 0.000208 
l0: 0.000322, l1: 0.000333, l2: 0.000385, l3: 0.000392, l4: 0.000557, l5: 0.001054, l6: 0.001568

[epoch: 354/1000, batch:  1044/ 1052, ite: 93100] train loss: 0.004741, tar: 0.000208 
[Epoch 354/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000318, l1: 0.000319, l2: 0.000369, l3: 0.000492, l4: 0.000930, l5: 0.001864, l6: 0.002863

[epoch: 355/1000, batch:    72/ 1052, ite: 93120] train loss: 0.004742, tar: 0.000208 
l0: 0.000195, l1: 0.000191, l2: 0.000216, l3: 0.000283, l4: 0.000396, l5: 0.001002, l6: 0.000975

[epoch: 355/1000, batch:   152/ 1052, ite: 93140] train loss: 0.004743, tar: 0.000208 
l0: 0.000256, l1: 0.000257, l2: 0.000305, l3: 0.000403, l4: 0.000730, l5: 0.001473, l6: 0.001831

[epoch: 355/1000, batch:   232/ 1052, ite: 93160] train loss: 0.004742, tar: 0.000208 
l0: 0.000086, l1: 0.000083, l2: 0.000121, l3: 0.000228, l4: 0.000302, l5: 0.000687, l6: 0.001112

[epoch: 355/1000, batch:   312/ 1052, ite: 93180] train loss: 0.004742, tar: 0.000208 
l0: 0.000190, l1: 0.000191, l2: 0.000213, l3: 0.000357, l4: 0.000593, l5: 0.000919, l6: 0.002702

[epoch: 355/1000, batch:   392/ 1052, ite: 93200] train loss: 0.004741, tar: 0.000208 
l0: 0.000116, l1: 0.000116, l2: 0.000143, l3: 0.000185, l4: 0.000332, l5: 0.000742, l6: 0.001337

[epoch: 355/1000, batch:   472/ 1052, ite: 93220] train loss: 0.004741, tar: 0.000208 
l0: 0.000117, l1: 0.000120, l2: 0.000148, l3: 0.000238, l4: 0.000386, l5: 0.000801, l6: 0.001406

[epoch: 355/1000, batch:   552/ 1052, ite: 93240] train loss: 0.004740, tar: 0.000208 
l0: 0.000083, l1: 0.000080, l2: 0.000126, l3: 0.000209, l4: 0.000422, l5: 0.000690, l6: 0.000870

[epoch: 355/1000, batch:   632/ 1052, ite: 93260] train loss: 0.004739, tar: 0.000207 
l0: 0.000126, l1: 0.000120, l2: 0.000183, l3: 0.000283, l4: 0.000461, l5: 0.001098, l6: 0.002607

[epoch: 355/1000, batch:   712/ 1052, ite: 93280] train loss: 0.004739, tar: 0.000207 
l0: 0.000271, l1: 0.000279, l2: 0.000373, l3: 0.000501, l4: 0.001087, l5: 0.003489, l6: 0.004742

[epoch: 355/1000, batch:   792/ 1052, ite: 93300] train loss: 0.004738, tar: 0.000207 
l0: 0.000080, l1: 0.000078, l2: 0.000121, l3: 0.000188, l4: 0.000356, l5: 0.000760, l6: 0.000867

[epoch: 355/1000, batch:   872/ 1052, ite: 93320] train loss: 0.004737, tar: 0.000207 
l0: 0.000068, l1: 0.000065, l2: 0.000084, l3: 0.000134, l4: 0.000206, l5: 0.000504, l6: 0.000754

[epoch: 355/1000, batch:   952/ 1052, ite: 93340] train loss: 0.004738, tar: 0.000207 
l0: 0.000063, l1: 0.000065, l2: 0.000091, l3: 0.000128, l4: 0.000288, l5: 0.000813, l6: 0.001267

[epoch: 355/1000, batch:  1032/ 1052, ite: 93360] train loss: 0.004737, tar: 0.000207 
[Epoch 355/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000075, l1: 0.000075, l2: 0.000110, l3: 0.000178, l4: 0.000468, l5: 0.000794, l6: 0.001313

[epoch: 356/1000, batch:    60/ 1052, ite: 93380] train loss: 0.004736, tar: 0.000207 
l0: 0.000080, l1: 0.000076, l2: 0.000116, l3: 0.000151, l4: 0.000306, l5: 0.000515, l6: 0.000872

[epoch: 356/1000, batch:   140/ 1052, ite: 93400] train loss: 0.004735, tar: 0.000207 
l0: 0.000316, l1: 0.000326, l2: 0.000374, l3: 0.000426, l4: 0.000699, l5: 0.001300, l6: 0.002811

[epoch: 356/1000, batch:   220/ 1052, ite: 93420] train loss: 0.004734, tar: 0.000207 
l0: 0.000106, l1: 0.000109, l2: 0.000124, l3: 0.000179, l4: 0.000331, l5: 0.000852, l6: 0.001374

[epoch: 356/1000, batch:   300/ 1052, ite: 93440] train loss: 0.004735, tar: 0.000207 
l0: 0.000138, l1: 0.000139, l2: 0.000161, l3: 0.000245, l4: 0.000431, l5: 0.000956, l6: 0.001678

[epoch: 356/1000, batch:   380/ 1052, ite: 93460] train loss: 0.004736, tar: 0.000207 
l0: 0.000431, l1: 0.000440, l2: 0.000458, l3: 0.000516, l4: 0.000831, l5: 0.001848, l6: 0.003186

[epoch: 356/1000, batch:   460/ 1052, ite: 93480] train loss: 0.004735, tar: 0.000207 
l0: 0.000216, l1: 0.000211, l2: 0.000314, l3: 0.000433, l4: 0.000811, l5: 0.001949, l6: 0.002662

[epoch: 356/1000, batch:   540/ 1052, ite: 93500] train loss: 0.004736, tar: 0.000207 
l0: 0.000185, l1: 0.000193, l2: 0.000202, l3: 0.000347, l4: 0.000714, l5: 0.001667, l6: 0.002659

[epoch: 356/1000, batch:   620/ 1052, ite: 93520] train loss: 0.004736, tar: 0.000207 
l0: 0.000144, l1: 0.000141, l2: 0.000197, l3: 0.000310, l4: 0.000582, l5: 0.001150, l6: 0.002270

[epoch: 356/1000, batch:   700/ 1052, ite: 93540] train loss: 0.004736, tar: 0.000207 
l0: 0.000189, l1: 0.000195, l2: 0.000228, l3: 0.000236, l4: 0.000521, l5: 0.000994, l6: 0.001827

[epoch: 356/1000, batch:   780/ 1052, ite: 93560] train loss: 0.004735, tar: 0.000207 
l0: 0.000143, l1: 0.000144, l2: 0.000179, l3: 0.000218, l4: 0.000360, l5: 0.000841, l6: 0.001423

[epoch: 356/1000, batch:   860/ 1052, ite: 93580] train loss: 0.004736, tar: 0.000207 
l0: 0.000221, l1: 0.000233, l2: 0.000325, l3: 0.000576, l4: 0.001015, l5: 0.001376, l6: 0.002034

[epoch: 356/1000, batch:   940/ 1052, ite: 93600] train loss: 0.004735, tar: 0.000207 
l0: 0.000193, l1: 0.000202, l2: 0.000193, l3: 0.000260, l4: 0.000548, l5: 0.000820, l6: 0.001190

[epoch: 356/1000, batch:  1020/ 1052, ite: 93620] train loss: 0.004734, tar: 0.000207 
[Epoch 356/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000186, l1: 0.000187, l2: 0.000198, l3: 0.000300, l4: 0.000547, l5: 0.001182, l6: 0.003114

[epoch: 357/1000, batch:    48/ 1052, ite: 93640] train loss: 0.004734, tar: 0.000207 
l0: 0.000351, l1: 0.000357, l2: 0.000343, l3: 0.000425, l4: 0.000581, l5: 0.000975, l6: 0.002220

[epoch: 357/1000, batch:   128/ 1052, ite: 93660] train loss: 0.004734, tar: 0.000207 
l0: 0.000106, l1: 0.000109, l2: 0.000133, l3: 0.000181, l4: 0.000350, l5: 0.000688, l6: 0.000885

[epoch: 357/1000, batch:   208/ 1052, ite: 93680] train loss: 0.004734, tar: 0.000206 
l0: 0.000117, l1: 0.000114, l2: 0.000153, l3: 0.000245, l4: 0.000586, l5: 0.000877, l6: 0.001783

[epoch: 357/1000, batch:   288/ 1052, ite: 93700] train loss: 0.004734, tar: 0.000206 
l0: 0.000123, l1: 0.000121, l2: 0.000160, l3: 0.000188, l4: 0.000419, l5: 0.000980, l6: 0.002198

[epoch: 357/1000, batch:   368/ 1052, ite: 93720] train loss: 0.004733, tar: 0.000206 
l0: 0.000195, l1: 0.000187, l2: 0.000280, l3: 0.000405, l4: 0.000834, l5: 0.001721, l6: 0.002731

[epoch: 357/1000, batch:   448/ 1052, ite: 93740] train loss: 0.004734, tar: 0.000206 
l0: 0.000194, l1: 0.000206, l2: 0.000189, l3: 0.000235, l4: 0.000442, l5: 0.000727, l6: 0.002381

[epoch: 357/1000, batch:   528/ 1052, ite: 93760] train loss: 0.004733, tar: 0.000206 
l0: 0.000050, l1: 0.000048, l2: 0.000094, l3: 0.000129, l4: 0.000255, l5: 0.000667, l6: 0.000855

[epoch: 357/1000, batch:   608/ 1052, ite: 93780] train loss: 0.004733, tar: 0.000206 
l0: 0.000105, l1: 0.000109, l2: 0.000114, l3: 0.000160, l4: 0.000196, l5: 0.000429, l6: 0.001074

[epoch: 357/1000, batch:   688/ 1052, ite: 93800] train loss: 0.004733, tar: 0.000206 
l0: 0.000268, l1: 0.000270, l2: 0.000342, l3: 0.000634, l4: 0.001293, l5: 0.002071, l6: 0.004047

[epoch: 357/1000, batch:   768/ 1052, ite: 93820] train loss: 0.004734, tar: 0.000206 
l0: 0.000184, l1: 0.000187, l2: 0.000213, l3: 0.000345, l4: 0.000541, l5: 0.001253, l6: 0.002222

[epoch: 357/1000, batch:   848/ 1052, ite: 93840] train loss: 0.004735, tar: 0.000206 
l0: 0.000171, l1: 0.000176, l2: 0.000177, l3: 0.000335, l4: 0.000480, l5: 0.000894, l6: 0.001425

[epoch: 357/1000, batch:   928/ 1052, ite: 93860] train loss: 0.004735, tar: 0.000206 
l0: 0.000191, l1: 0.000188, l2: 0.000223, l3: 0.000306, l4: 0.000538, l5: 0.000753, l6: 0.001257

[epoch: 357/1000, batch:  1008/ 1052, ite: 93880] train loss: 0.004734, tar: 0.000206 
[Epoch 357/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000239, l1: 0.000252, l2: 0.000297, l3: 0.000449, l4: 0.001124, l5: 0.001725, l6: 0.002760

[epoch: 358/1000, batch:    36/ 1052, ite: 93900] train loss: 0.004735, tar: 0.000206 
l0: 0.000179, l1: 0.000179, l2: 0.000207, l3: 0.000333, l4: 0.000560, l5: 0.001392, l6: 0.002001

[epoch: 358/1000, batch:   116/ 1052, ite: 93920] train loss: 0.004735, tar: 0.000206 
l0: 0.000102, l1: 0.000103, l2: 0.000155, l3: 0.000253, l4: 0.000493, l5: 0.000879, l6: 0.001829

[epoch: 358/1000, batch:   196/ 1052, ite: 93940] train loss: 0.004733, tar: 0.000206 
l0: 0.000089, l1: 0.000090, l2: 0.000124, l3: 0.000166, l4: 0.000285, l5: 0.000954, l6: 0.001125

[epoch: 358/1000, batch:   276/ 1052, ite: 93960] train loss: 0.004733, tar: 0.000206 
l0: 0.000327, l1: 0.000328, l2: 0.000374, l3: 0.000554, l4: 0.000877, l5: 0.001773, l6: 0.004239

[epoch: 358/1000, batch:   356/ 1052, ite: 93980] train loss: 0.004733, tar: 0.000206 
l0: 0.000254, l1: 0.000250, l2: 0.000311, l3: 0.000542, l4: 0.000867, l5: 0.001169, l6: 0.001971

[epoch: 358/1000, batch:   436/ 1052, ite: 94000] train loss: 0.004734, tar: 0.000206 
l0: 0.000066, l1: 0.000072, l2: 0.000072, l3: 0.000148, l4: 0.000511, l5: 0.000922, l6: 0.001879

[epoch: 358/1000, batch:   516/ 1052, ite: 94020] train loss: 0.004733, tar: 0.000206 
l0: 0.000254, l1: 0.000249, l2: 0.000332, l3: 0.000422, l4: 0.000693, l5: 0.001277, l6: 0.002691

[epoch: 358/1000, batch:   596/ 1052, ite: 94040] train loss: 0.004732, tar: 0.000206 
l0: 0.000097, l1: 0.000101, l2: 0.000109, l3: 0.000175, l4: 0.000317, l5: 0.000742, l6: 0.001113

[epoch: 358/1000, batch:   676/ 1052, ite: 94060] train loss: 0.004731, tar: 0.000206 
l0: 0.000133, l1: 0.000132, l2: 0.000165, l3: 0.000267, l4: 0.000573, l5: 0.000594, l6: 0.001916

[epoch: 358/1000, batch:   756/ 1052, ite: 94080] train loss: 0.004731, tar: 0.000206 
l0: 0.000151, l1: 0.000148, l2: 0.000199, l3: 0.000213, l4: 0.000348, l5: 0.000900, l6: 0.001403

[epoch: 358/1000, batch:   836/ 1052, ite: 94100] train loss: 0.004731, tar: 0.000206 
l0: 0.000362, l1: 0.000361, l2: 0.000443, l3: 0.000666, l4: 0.001530, l5: 0.003186, l6: 0.004804

[epoch: 358/1000, batch:   916/ 1052, ite: 94120] train loss: 0.004731, tar: 0.000205 
l0: 0.000109, l1: 0.000115, l2: 0.000128, l3: 0.000228, l4: 0.000487, l5: 0.000863, l6: 0.001184

[epoch: 358/1000, batch:   996/ 1052, ite: 94140] train loss: 0.004731, tar: 0.000205 
[Epoch 358/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000112, l1: 0.000112, l2: 0.000150, l3: 0.000218, l4: 0.000424, l5: 0.001120, l6: 0.001439

[epoch: 359/1000, batch:    24/ 1052, ite: 94160] train loss: 0.004730, tar: 0.000205 
l0: 0.000412, l1: 0.000405, l2: 0.000480, l3: 0.000755, l4: 0.001064, l5: 0.002271, l6: 0.004263

[epoch: 359/1000, batch:   104/ 1052, ite: 94180] train loss: 0.004730, tar: 0.000205 
l0: 0.000228, l1: 0.000232, l2: 0.000260, l3: 0.000370, l4: 0.000695, l5: 0.001610, l6: 0.002297

[epoch: 359/1000, batch:   184/ 1052, ite: 94200] train loss: 0.004730, tar: 0.000205 
l0: 0.000068, l1: 0.000065, l2: 0.000113, l3: 0.000146, l4: 0.000448, l5: 0.001207, l6: 0.001089

[epoch: 359/1000, batch:   264/ 1052, ite: 94220] train loss: 0.004729, tar: 0.000205 
l0: 0.000280, l1: 0.000273, l2: 0.000305, l3: 0.000313, l4: 0.000636, l5: 0.000720, l6: 0.001384

[epoch: 359/1000, batch:   344/ 1052, ite: 94240] train loss: 0.004728, tar: 0.000205 
l0: 0.000045, l1: 0.000042, l2: 0.000090, l3: 0.000154, l4: 0.000331, l5: 0.000731, l6: 0.001238

[epoch: 359/1000, batch:   424/ 1052, ite: 94260] train loss: 0.004728, tar: 0.000205 
l0: 0.000186, l1: 0.000191, l2: 0.000220, l3: 0.000281, l4: 0.000748, l5: 0.001417, l6: 0.002430

[epoch: 359/1000, batch:   504/ 1052, ite: 94280] train loss: 0.004728, tar: 0.000205 
l0: 0.000181, l1: 0.000194, l2: 0.000183, l3: 0.000253, l4: 0.000380, l5: 0.000820, l6: 0.001678

[epoch: 359/1000, batch:   584/ 1052, ite: 94300] train loss: 0.004727, tar: 0.000205 
l0: 0.000154, l1: 0.000156, l2: 0.000178, l3: 0.000215, l4: 0.000295, l5: 0.000861, l6: 0.001761

[epoch: 359/1000, batch:   664/ 1052, ite: 94320] train loss: 0.004728, tar: 0.000205 
l0: 0.000192, l1: 0.000191, l2: 0.000239, l3: 0.000355, l4: 0.000590, l5: 0.001589, l6: 0.003091

[epoch: 359/1000, batch:   744/ 1052, ite: 94340] train loss: 0.004727, tar: 0.000205 
l0: 0.000094, l1: 0.000093, l2: 0.000133, l3: 0.000150, l4: 0.000368, l5: 0.000875, l6: 0.001483

[epoch: 359/1000, batch:   824/ 1052, ite: 94360] train loss: 0.004727, tar: 0.000205 
l0: 0.000134, l1: 0.000132, l2: 0.000189, l3: 0.000269, l4: 0.000632, l5: 0.000876, l6: 0.001662

[epoch: 359/1000, batch:   904/ 1052, ite: 94380] train loss: 0.004726, tar: 0.000205 
l0: 0.000429, l1: 0.000429, l2: 0.000518, l3: 0.000633, l4: 0.001272, l5: 0.002302, l6: 0.003683

[epoch: 359/1000, batch:   984/ 1052, ite: 94400] train loss: 0.004727, tar: 0.000205 
[Epoch 359/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000174, l1: 0.000172, l2: 0.000204, l3: 0.000301, l4: 0.000759, l5: 0.001226, l6: 0.001751

[epoch: 360/1000, batch:    12/ 1052, ite: 94420] train loss: 0.004728, tar: 0.000205 
l0: 0.000097, l1: 0.000093, l2: 0.000161, l3: 0.000214, l4: 0.000634, l5: 0.000953, l6: 0.001795

[epoch: 360/1000, batch:    92/ 1052, ite: 94440] train loss: 0.004728, tar: 0.000205 
l0: 0.000135, l1: 0.000135, l2: 0.000151, l3: 0.000241, l4: 0.000493, l5: 0.000950, l6: 0.001844

[epoch: 360/1000, batch:   172/ 1052, ite: 94460] train loss: 0.004727, tar: 0.000205 
l0: 0.000098, l1: 0.000095, l2: 0.000143, l3: 0.000198, l4: 0.000287, l5: 0.000689, l6: 0.001541

[epoch: 360/1000, batch:   252/ 1052, ite: 94480] train loss: 0.004726, tar: 0.000205 
l0: 0.000237, l1: 0.000238, l2: 0.000280, l3: 0.000329, l4: 0.000652, l5: 0.001701, l6: 0.003161

[epoch: 360/1000, batch:   332/ 1052, ite: 94500] train loss: 0.004727, tar: 0.000205 
l0: 0.000229, l1: 0.000224, l2: 0.000304, l3: 0.000418, l4: 0.000643, l5: 0.001157, l6: 0.002193

[epoch: 360/1000, batch:   412/ 1052, ite: 94520] train loss: 0.004726, tar: 0.000204 
l0: 0.000208, l1: 0.000206, l2: 0.000329, l3: 0.000412, l4: 0.000618, l5: 0.001416, l6: 0.002247

[epoch: 360/1000, batch:   492/ 1052, ite: 94540] train loss: 0.004726, tar: 0.000204 
l0: 0.000271, l1: 0.000295, l2: 0.000291, l3: 0.000413, l4: 0.001084, l5: 0.001604, l6: 0.002477

[epoch: 360/1000, batch:   572/ 1052, ite: 94560] train loss: 0.004726, tar: 0.000204 
l0: 0.000141, l1: 0.000142, l2: 0.000163, l3: 0.000164, l4: 0.000317, l5: 0.000808, l6: 0.001073

[epoch: 360/1000, batch:   652/ 1052, ite: 94580] train loss: 0.004725, tar: 0.000204 
l0: 0.000206, l1: 0.000207, l2: 0.000221, l3: 0.000296, l4: 0.000776, l5: 0.001527, l6: 0.002746

[epoch: 360/1000, batch:   732/ 1052, ite: 94600] train loss: 0.004724, tar: 0.000204 
l0: 0.000331, l1: 0.000318, l2: 0.000384, l3: 0.000664, l4: 0.000885, l5: 0.001655, l6: 0.002217

[epoch: 360/1000, batch:   812/ 1052, ite: 94620] train loss: 0.004724, tar: 0.000204 
l0: 0.000108, l1: 0.000112, l2: 0.000143, l3: 0.000253, l4: 0.000540, l5: 0.000965, l6: 0.002227

[epoch: 360/1000, batch:   892/ 1052, ite: 94640] train loss: 0.004724, tar: 0.000204 
l0: 0.000133, l1: 0.000142, l2: 0.000159, l3: 0.000182, l4: 0.000530, l5: 0.001077, l6: 0.002241

[epoch: 360/1000, batch:   972/ 1052, ite: 94660] train loss: 0.004724, tar: 0.000204 
l0: 0.000437, l1: 0.000438, l2: 0.000513, l3: 0.000774, l4: 0.001282, l5: 0.002181, l6: 0.004110

[epoch: 360/1000, batch:  1052/ 1052, ite: 94680] train loss: 0.004725, tar: 0.000204 
[Epoch 360/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000366, l1: 0.000374, l2: 0.000405, l3: 0.000445, l4: 0.000974, l5: 0.001538, l6: 0.002357

[epoch: 361/1000, batch:    80/ 1052, ite: 94700] train loss: 0.004888, tar: 0.000211 
l0: 0.000191, l1: 0.000188, l2: 0.000219, l3: 0.000289, l4: 0.000481, l5: 0.000752, l6: 0.001300

[epoch: 361/1000, batch:   160/ 1052, ite: 94720] train loss: 0.004854, tar: 0.000208 
l0: 0.000142, l1: 0.000144, l2: 0.000153, l3: 0.000233, l4: 0.000344, l5: 0.001308, l6: 0.001528

[epoch: 361/1000, batch:   240/ 1052, ite: 94740] train loss: 0.004833, tar: 0.000194 
l0: 0.000168, l1: 0.000176, l2: 0.000167, l3: 0.000290, l4: 0.000413, l5: 0.000808, l6: 0.001128

[epoch: 361/1000, batch:   320/ 1052, ite: 94760] train loss: 0.004725, tar: 0.000189 
l0: 0.000201, l1: 0.000198, l2: 0.000255, l3: 0.000380, l4: 0.000770, l5: 0.001311, l6: 0.002782

[epoch: 361/1000, batch:   400/ 1052, ite: 94780] train loss: 0.004670, tar: 0.000187 
l0: 0.000231, l1: 0.000224, l2: 0.000284, l3: 0.000376, l4: 0.000483, l5: 0.001503, l6: 0.002020

[epoch: 361/1000, batch:   480/ 1052, ite: 94800] train loss: 0.004763, tar: 0.000190 
l0: 0.000372, l1: 0.000358, l2: 0.000375, l3: 0.000495, l4: 0.000596, l5: 0.001058, l6: 0.000973

[epoch: 361/1000, batch:   560/ 1052, ite: 94820] train loss: 0.004672, tar: 0.000186 
l0: 0.000274, l1: 0.000273, l2: 0.000300, l3: 0.000379, l4: 0.000572, l5: 0.001426, l6: 0.001760

[epoch: 361/1000, batch:   640/ 1052, ite: 94840] train loss: 0.004646, tar: 0.000187 
l0: 0.000249, l1: 0.000259, l2: 0.000272, l3: 0.000288, l4: 0.000488, l5: 0.001399, l6: 0.003209

[epoch: 361/1000, batch:   720/ 1052, ite: 94860] train loss: 0.004661, tar: 0.000187 
l0: 0.000179, l1: 0.000177, l2: 0.000216, l3: 0.000275, l4: 0.000427, l5: 0.001117, l6: 0.001399

[epoch: 361/1000, batch:   800/ 1052, ite: 94880] train loss: 0.004638, tar: 0.000188 
l0: 0.000171, l1: 0.000177, l2: 0.000166, l3: 0.000177, l4: 0.000554, l5: 0.001156, l6: 0.001780

[epoch: 361/1000, batch:   880/ 1052, ite: 94900] train loss: 0.004734, tar: 0.000191 
l0: 0.000264, l1: 0.000262, l2: 0.000319, l3: 0.000464, l4: 0.000920, l5: 0.002024, l6: 0.003661

[epoch: 361/1000, batch:   960/ 1052, ite: 94920] train loss: 0.004724, tar: 0.000188 
l0: 0.000118, l1: 0.000115, l2: 0.000129, l3: 0.000190, l4: 0.000292, l5: 0.000711, l6: 0.000816

[epoch: 361/1000, batch:  1040/ 1052, ite: 94940] train loss: 0.004686, tar: 0.000186 
[Epoch 361/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000102, l1: 0.000105, l2: 0.000128, l3: 0.000160, l4: 0.000375, l5: 0.000586, l6: 0.001419

[epoch: 362/1000, batch:    68/ 1052, ite: 94960] train loss: 0.004674, tar: 0.000185 
l0: 0.000100, l1: 0.000102, l2: 0.000108, l3: 0.000189, l4: 0.000598, l5: 0.001214, l6: 0.001433

[epoch: 362/1000, batch:   148/ 1052, ite: 94980] train loss: 0.004670, tar: 0.000183 
l0: 0.000216, l1: 0.000217, l2: 0.000317, l3: 0.000448, l4: 0.000783, l5: 0.001495, l6: 0.002217

[epoch: 362/1000, batch:   228/ 1052, ite: 95000] train loss: 0.004691, tar: 0.000184 
l0: 0.000312, l1: 0.000316, l2: 0.000415, l3: 0.000650, l4: 0.001015, l5: 0.003225, l6: 0.004020

[epoch: 362/1000, batch:   308/ 1052, ite: 95020] train loss: 0.004669, tar: 0.000183 
l0: 0.000187, l1: 0.000188, l2: 0.000232, l3: 0.000193, l4: 0.000330, l5: 0.000881, l6: 0.001398

[epoch: 362/1000, batch:   388/ 1052, ite: 95040] train loss: 0.004664, tar: 0.000184 
l0: 0.000212, l1: 0.000222, l2: 0.000210, l3: 0.000293, l4: 0.000620, l5: 0.001096, l6: 0.002926

[epoch: 362/1000, batch:   468/ 1052, ite: 95060] train loss: 0.004699, tar: 0.000186 
l0: 0.000122, l1: 0.000120, l2: 0.000162, l3: 0.000176, l4: 0.000297, l5: 0.000874, l6: 0.001383

[epoch: 362/1000, batch:   548/ 1052, ite: 95080] train loss: 0.004696, tar: 0.000186 
l0: 0.000091, l1: 0.000088, l2: 0.000127, l3: 0.000174, l4: 0.000297, l5: 0.000529, l6: 0.001314

[epoch: 362/1000, batch:   628/ 1052, ite: 95100] train loss: 0.004675, tar: 0.000184 
l0: 0.000246, l1: 0.000246, l2: 0.000280, l3: 0.000379, l4: 0.000695, l5: 0.000822, l6: 0.002390

[epoch: 362/1000, batch:   708/ 1052, ite: 95120] train loss: 0.004660, tar: 0.000183 
l0: 0.000156, l1: 0.000157, l2: 0.000196, l3: 0.000229, l4: 0.000475, l5: 0.001051, l6: 0.002251

[epoch: 362/1000, batch:   788/ 1052, ite: 95140] train loss: 0.004650, tar: 0.000182 
l0: 0.000084, l1: 0.000089, l2: 0.000113, l3: 0.000168, l4: 0.000392, l5: 0.001171, l6: 0.001716

[epoch: 362/1000, batch:   868/ 1052, ite: 95160] train loss: 0.004653, tar: 0.000182 
l0: 0.000151, l1: 0.000156, l2: 0.000171, l3: 0.000237, l4: 0.000415, l5: 0.001174, l6: 0.001705

[epoch: 362/1000, batch:   948/ 1052, ite: 95180] train loss: 0.004637, tar: 0.000181 
l0: 0.000455, l1: 0.000437, l2: 0.000511, l3: 0.000663, l4: 0.000760, l5: 0.001531, l6: 0.001692

[epoch: 362/1000, batch:  1028/ 1052, ite: 95200] train loss: 0.004646, tar: 0.000181 
[Epoch 362/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000240, l1: 0.000245, l2: 0.000271, l3: 0.000370, l4: 0.000643, l5: 0.001297, l6: 0.002434

[epoch: 363/1000, batch:    56/ 1052, ite: 95220] train loss: 0.004654, tar: 0.000181 
l0: 0.000069, l1: 0.000069, l2: 0.000090, l3: 0.000185, l4: 0.000311, l5: 0.000922, l6: 0.001411

[epoch: 363/1000, batch:   136/ 1052, ite: 95240] train loss: 0.004634, tar: 0.000179 
l0: 0.000136, l1: 0.000131, l2: 0.000273, l3: 0.000307, l4: 0.000700, l5: 0.001354, l6: 0.002485

[epoch: 363/1000, batch:   216/ 1052, ite: 95260] train loss: 0.004629, tar: 0.000179 
l0: 0.000070, l1: 0.000070, l2: 0.000091, l3: 0.000134, l4: 0.000275, l5: 0.000765, l6: 0.001619

[epoch: 363/1000, batch:   296/ 1052, ite: 95280] train loss: 0.004621, tar: 0.000179 
l0: 0.000153, l1: 0.000159, l2: 0.000174, l3: 0.000200, l4: 0.000330, l5: 0.001253, l6: 0.001754

[epoch: 363/1000, batch:   376/ 1052, ite: 95300] train loss: 0.004618, tar: 0.000179 
l0: 0.000230, l1: 0.000231, l2: 0.000265, l3: 0.000414, l4: 0.000575, l5: 0.001167, l6: 0.002778

[epoch: 363/1000, batch:   456/ 1052, ite: 95320] train loss: 0.004608, tar: 0.000179 
l0: 0.000283, l1: 0.000291, l2: 0.000312, l3: 0.000375, l4: 0.000687, l5: 0.001320, l6: 0.001599

[epoch: 363/1000, batch:   536/ 1052, ite: 95340] train loss: 0.004624, tar: 0.000180 
l0: 0.000098, l1: 0.000098, l2: 0.000158, l3: 0.000258, l4: 0.000456, l5: 0.001096, l6: 0.001547

[epoch: 363/1000, batch:   616/ 1052, ite: 95360] train loss: 0.004621, tar: 0.000180 
l0: 0.000123, l1: 0.000122, l2: 0.000166, l3: 0.000249, l4: 0.000384, l5: 0.000992, l6: 0.002572

[epoch: 363/1000, batch:   696/ 1052, ite: 95380] train loss: 0.004591, tar: 0.000179 
l0: 0.000176, l1: 0.000174, l2: 0.000201, l3: 0.000233, l4: 0.000542, l5: 0.001061, l6: 0.001189

[epoch: 363/1000, batch:   776/ 1052, ite: 95400] train loss: 0.004611, tar: 0.000179 
l0: 0.000255, l1: 0.000254, l2: 0.000294, l3: 0.000454, l4: 0.000800, l5: 0.001810, l6: 0.002647

[epoch: 363/1000, batch:   856/ 1052, ite: 95420] train loss: 0.004619, tar: 0.000179 
l0: 0.000218, l1: 0.000226, l2: 0.000247, l3: 0.000386, l4: 0.000632, l5: 0.001621, l6: 0.002914

[epoch: 363/1000, batch:   936/ 1052, ite: 95440] train loss: 0.004606, tar: 0.000179 
l0: 0.000316, l1: 0.000315, l2: 0.000377, l3: 0.000444, l4: 0.000663, l5: 0.001405, l6: 0.001726

[epoch: 363/1000, batch:  1016/ 1052, ite: 95460] train loss: 0.004613, tar: 0.000179 
[Epoch 363/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000086, l1: 0.000085, l2: 0.000123, l3: 0.000161, l4: 0.000441, l5: 0.001143, l6: 0.000753

[epoch: 364/1000, batch:    44/ 1052, ite: 95480] train loss: 0.004619, tar: 0.000179 
l0: 0.000155, l1: 0.000157, l2: 0.000172, l3: 0.000195, l4: 0.000355, l5: 0.000945, l6: 0.001456

[epoch: 364/1000, batch:   124/ 1052, ite: 95500] train loss: 0.004604, tar: 0.000179 
l0: 0.000301, l1: 0.000291, l2: 0.000363, l3: 0.000583, l4: 0.001105, l5: 0.001893, l6: 0.003598

[epoch: 364/1000, batch:   204/ 1052, ite: 95520] train loss: 0.004615, tar: 0.000180 
l0: 0.000171, l1: 0.000172, l2: 0.000201, l3: 0.000305, l4: 0.000370, l5: 0.000889, l6: 0.001759

[epoch: 364/1000, batch:   284/ 1052, ite: 95540] train loss: 0.004608, tar: 0.000180 
l0: 0.000157, l1: 0.000161, l2: 0.000202, l3: 0.000249, l4: 0.000375, l5: 0.001019, l6: 0.001720

[epoch: 364/1000, batch:   364/ 1052, ite: 95560] train loss: 0.004607, tar: 0.000180 
l0: 0.000068, l1: 0.000069, l2: 0.000094, l3: 0.000131, l4: 0.000260, l5: 0.000466, l6: 0.001153

[epoch: 364/1000, batch:   444/ 1052, ite: 95580] train loss: 0.004587, tar: 0.000179 
l0: 0.000236, l1: 0.000229, l2: 0.000321, l3: 0.000359, l4: 0.000530, l5: 0.001833, l6: 0.003366

[epoch: 364/1000, batch:   524/ 1052, ite: 95600] train loss: 0.004590, tar: 0.000179 
l0: 0.000197, l1: 0.000197, l2: 0.000255, l3: 0.000286, l4: 0.000544, l5: 0.001290, l6: 0.002251

[epoch: 364/1000, batch:   604/ 1052, ite: 95620] train loss: 0.004593, tar: 0.000179 
l0: 0.000090, l1: 0.000096, l2: 0.000090, l3: 0.000161, l4: 0.000275, l5: 0.000672, l6: 0.000919

[epoch: 364/1000, batch:   684/ 1052, ite: 95640] train loss: 0.004596, tar: 0.000179 
l0: 0.000099, l1: 0.000099, l2: 0.000117, l3: 0.000168, l4: 0.000318, l5: 0.000826, l6: 0.001226

[epoch: 364/1000, batch:   764/ 1052, ite: 95660] train loss: 0.004598, tar: 0.000179 
l0: 0.000229, l1: 0.000234, l2: 0.000242, l3: 0.000329, l4: 0.000504, l5: 0.001486, l6: 0.000953

[epoch: 364/1000, batch:   844/ 1052, ite: 95680] train loss: 0.004595, tar: 0.000179 
l0: 0.000173, l1: 0.000173, l2: 0.000226, l3: 0.000301, l4: 0.000643, l5: 0.001786, l6: 0.001672

[epoch: 364/1000, batch:   924/ 1052, ite: 95700] train loss: 0.004600, tar: 0.000179 
l0: 0.000143, l1: 0.000141, l2: 0.000199, l3: 0.000317, l4: 0.000746, l5: 0.001513, l6: 0.002347

[epoch: 364/1000, batch:  1004/ 1052, ite: 95720] train loss: 0.004603, tar: 0.000179 
[Epoch 364/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000142, l1: 0.000149, l2: 0.000172, l3: 0.000176, l4: 0.000323, l5: 0.000867, l6: 0.001467

[epoch: 365/1000, batch:    32/ 1052, ite: 95740] train loss: 0.004619, tar: 0.000179 
l0: 0.000102, l1: 0.000100, l2: 0.000185, l3: 0.000354, l4: 0.000605, l5: 0.001103, l6: 0.001506

[epoch: 365/1000, batch:   112/ 1052, ite: 95760] train loss: 0.004637, tar: 0.000180 
l0: 0.000104, l1: 0.000104, l2: 0.000142, l3: 0.000190, l4: 0.000370, l5: 0.000734, l6: 0.001116

[epoch: 365/1000, batch:   192/ 1052, ite: 95780] train loss: 0.004638, tar: 0.000180 
l0: 0.000176, l1: 0.000176, l2: 0.000191, l3: 0.000264, l4: 0.000335, l5: 0.000971, l6: 0.001342

[epoch: 365/1000, batch:   272/ 1052, ite: 95800] train loss: 0.004636, tar: 0.000180 
l0: 0.000090, l1: 0.000092, l2: 0.000122, l3: 0.000252, l4: 0.000546, l5: 0.000775, l6: 0.001433

[epoch: 365/1000, batch:   352/ 1052, ite: 95820] train loss: 0.004637, tar: 0.000180 
l0: 0.000280, l1: 0.000284, l2: 0.000272, l3: 0.000429, l4: 0.000619, l5: 0.001335, l6: 0.003144

[epoch: 365/1000, batch:   432/ 1052, ite: 95840] train loss: 0.004631, tar: 0.000179 
l0: 0.000303, l1: 0.000296, l2: 0.000370, l3: 0.000452, l4: 0.000573, l5: 0.001449, l6: 0.004105

[epoch: 365/1000, batch:   512/ 1052, ite: 95860] train loss: 0.004629, tar: 0.000179 
l0: 0.000094, l1: 0.000094, l2: 0.000108, l3: 0.000137, l4: 0.000366, l5: 0.000593, l6: 0.000864

[epoch: 365/1000, batch:   592/ 1052, ite: 95880] train loss: 0.004613, tar: 0.000179 
l0: 0.000155, l1: 0.000155, l2: 0.000209, l3: 0.000264, l4: 0.000554, l5: 0.000946, l6: 0.001520

[epoch: 365/1000, batch:   672/ 1052, ite: 95900] train loss: 0.004612, tar: 0.000179 
l0: 0.000213, l1: 0.000240, l2: 0.000175, l3: 0.000244, l4: 0.000566, l5: 0.001479, l6: 0.002653

[epoch: 365/1000, batch:   752/ 1052, ite: 95920] train loss: 0.004627, tar: 0.000180 
l0: 0.000158, l1: 0.000159, l2: 0.000194, l3: 0.000262, l4: 0.000566, l5: 0.001186, l6: 0.002088

[epoch: 365/1000, batch:   832/ 1052, ite: 95940] train loss: 0.004622, tar: 0.000179 
l0: 0.000498, l1: 0.000492, l2: 0.000598, l3: 0.000708, l4: 0.000856, l5: 0.002093, l6: 0.003691

[epoch: 365/1000, batch:   912/ 1052, ite: 95960] train loss: 0.004619, tar: 0.000179 
l0: 0.000275, l1: 0.000276, l2: 0.000301, l3: 0.000452, l4: 0.000999, l5: 0.001657, l6: 0.002434

[epoch: 365/1000, batch:   992/ 1052, ite: 95980] train loss: 0.004616, tar: 0.000179 
[Epoch 365/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000195, l1: 0.000195, l2: 0.000274, l3: 0.000409, l4: 0.000782, l5: 0.001457, l6: 0.002378

[epoch: 366/1000, batch:    20/ 1052, ite: 96000] train loss: 0.004622, tar: 0.000179 
l0: 0.000083, l1: 0.000085, l2: 0.000119, l3: 0.000223, l4: 0.000360, l5: 0.000714, l6: 0.001699

[epoch: 366/1000, batch:   100/ 1052, ite: 96020] train loss: 0.004621, tar: 0.000179 
l0: 0.000156, l1: 0.000157, l2: 0.000193, l3: 0.000375, l4: 0.000610, l5: 0.000921, l6: 0.002225

[epoch: 366/1000, batch:   180/ 1052, ite: 96040] train loss: 0.004620, tar: 0.000179 
l0: 0.000116, l1: 0.000117, l2: 0.000147, l3: 0.000157, l4: 0.000348, l5: 0.000853, l6: 0.001884

[epoch: 366/1000, batch:   260/ 1052, ite: 96060] train loss: 0.004615, tar: 0.000179 
l0: 0.000162, l1: 0.000164, l2: 0.000224, l3: 0.000406, l4: 0.000625, l5: 0.001456, l6: 0.003216

[epoch: 366/1000, batch:   340/ 1052, ite: 96080] train loss: 0.004621, tar: 0.000179 
l0: 0.000321, l1: 0.000341, l2: 0.000283, l3: 0.000346, l4: 0.000521, l5: 0.000716, l6: 0.001539

[epoch: 366/1000, batch:   420/ 1052, ite: 96100] train loss: 0.004612, tar: 0.000179 
l0: 0.000181, l1: 0.000182, l2: 0.000231, l3: 0.000339, l4: 0.000574, l5: 0.000778, l6: 0.001882

[epoch: 366/1000, batch:   500/ 1052, ite: 96120] train loss: 0.004622, tar: 0.000179 
l0: 0.000082, l1: 0.000086, l2: 0.000086, l3: 0.000122, l4: 0.000375, l5: 0.000660, l6: 0.001347

[epoch: 366/1000, batch:   580/ 1052, ite: 96140] train loss: 0.004615, tar: 0.000179 
l0: 0.000149, l1: 0.000148, l2: 0.000186, l3: 0.000192, l4: 0.000482, l5: 0.000582, l6: 0.001252

[epoch: 366/1000, batch:   660/ 1052, ite: 96160] train loss: 0.004618, tar: 0.000179 
l0: 0.000138, l1: 0.000142, l2: 0.000163, l3: 0.000223, l4: 0.000367, l5: 0.001247, l6: 0.002218

[epoch: 366/1000, batch:   740/ 1052, ite: 96180] train loss: 0.004617, tar: 0.000180 
l0: 0.000118, l1: 0.000121, l2: 0.000172, l3: 0.000203, l4: 0.000521, l5: 0.000961, l6: 0.001601

[epoch: 366/1000, batch:   820/ 1052, ite: 96200] train loss: 0.004618, tar: 0.000179 
l0: 0.000150, l1: 0.000144, l2: 0.000201, l3: 0.000445, l4: 0.000764, l5: 0.001694, l6: 0.002534

[epoch: 366/1000, batch:   900/ 1052, ite: 96220] train loss: 0.004617, tar: 0.000179 
l0: 0.000211, l1: 0.000208, l2: 0.000232, l3: 0.000284, l4: 0.000620, l5: 0.001304, l6: 0.001469

[epoch: 366/1000, batch:   980/ 1052, ite: 96240] train loss: 0.004622, tar: 0.000179 
[Epoch 366/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000108, l1: 0.000119, l2: 0.000103, l3: 0.000160, l4: 0.000429, l5: 0.000667, l6: 0.001242

[epoch: 367/1000, batch:     8/ 1052, ite: 96260] train loss: 0.004625, tar: 0.000180 
l0: 0.000257, l1: 0.000265, l2: 0.000327, l3: 0.000521, l4: 0.000971, l5: 0.001380, l6: 0.003155

[epoch: 367/1000, batch:    88/ 1052, ite: 96280] train loss: 0.004629, tar: 0.000180 
l0: 0.000139, l1: 0.000139, l2: 0.000157, l3: 0.000240, l4: 0.000542, l5: 0.001129, l6: 0.002143

[epoch: 367/1000, batch:   168/ 1052, ite: 96300] train loss: 0.004637, tar: 0.000180 
l0: 0.000117, l1: 0.000116, l2: 0.000161, l3: 0.000274, l4: 0.000403, l5: 0.000805, l6: 0.001927

[epoch: 367/1000, batch:   248/ 1052, ite: 96320] train loss: 0.004636, tar: 0.000180 
l0: 0.000073, l1: 0.000074, l2: 0.000088, l3: 0.000123, l4: 0.000243, l5: 0.000715, l6: 0.001171

[epoch: 367/1000, batch:   328/ 1052, ite: 96340] train loss: 0.004632, tar: 0.000179 
l0: 0.000231, l1: 0.000237, l2: 0.000290, l3: 0.000304, l4: 0.000743, l5: 0.001593, l6: 0.002116

[epoch: 367/1000, batch:   408/ 1052, ite: 96360] train loss: 0.004635, tar: 0.000179 
l0: 0.000231, l1: 0.000239, l2: 0.000263, l3: 0.000508, l4: 0.000911, l5: 0.001502, l6: 0.002285

[epoch: 367/1000, batch:   488/ 1052, ite: 96380] train loss: 0.004637, tar: 0.000180 
l0: 0.000223, l1: 0.000225, l2: 0.000224, l3: 0.000324, l4: 0.000517, l5: 0.001536, l6: 0.002169

[epoch: 367/1000, batch:   568/ 1052, ite: 96400] train loss: 0.004636, tar: 0.000179 
l0: 0.000142, l1: 0.000138, l2: 0.000188, l3: 0.000328, l4: 0.000477, l5: 0.001055, l6: 0.001761

[epoch: 367/1000, batch:   648/ 1052, ite: 96420] train loss: 0.004635, tar: 0.000179 
l0: 0.000089, l1: 0.000087, l2: 0.000119, l3: 0.000165, l4: 0.000294, l5: 0.000332, l6: 0.000936

[epoch: 367/1000, batch:   728/ 1052, ite: 96440] train loss: 0.004629, tar: 0.000179 
l0: 0.000033, l1: 0.000032, l2: 0.000061, l3: 0.000098, l4: 0.000271, l5: 0.000449, l6: 0.000600

[epoch: 367/1000, batch:   808/ 1052, ite: 96460] train loss: 0.004626, tar: 0.000178 
l0: 0.000148, l1: 0.000152, l2: 0.000192, l3: 0.000240, l4: 0.000524, l5: 0.000724, l6: 0.002328

[epoch: 367/1000, batch:   888/ 1052, ite: 96480] train loss: 0.004624, tar: 0.000178 
l0: 0.000219, l1: 0.000217, l2: 0.000289, l3: 0.000460, l4: 0.000689, l5: 0.001514, l6: 0.002477

[epoch: 367/1000, batch:   968/ 1052, ite: 96500] train loss: 0.004619, tar: 0.000178 
l0: 0.000167, l1: 0.000166, l2: 0.000187, l3: 0.000225, l4: 0.000473, l5: 0.000898, l6: 0.001707

[epoch: 367/1000, batch:  1048/ 1052, ite: 96520] train loss: 0.004617, tar: 0.000178 
[Epoch 367/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000091, l1: 0.000094, l2: 0.000124, l3: 0.000189, l4: 0.000411, l5: 0.000826, l6: 0.001739

[epoch: 368/1000, batch:    76/ 1052, ite: 96540] train loss: 0.004616, tar: 0.000178 
l0: 0.000166, l1: 0.000166, l2: 0.000192, l3: 0.000281, l4: 0.000428, l5: 0.001332, l6: 0.001949

[epoch: 368/1000, batch:   156/ 1052, ite: 96560] train loss: 0.004613, tar: 0.000178 
l0: 0.000152, l1: 0.000154, l2: 0.000220, l3: 0.000270, l4: 0.000667, l5: 0.001228, l6: 0.003234

[epoch: 368/1000, batch:   236/ 1052, ite: 96580] train loss: 0.004620, tar: 0.000178 
l0: 0.000073, l1: 0.000075, l2: 0.000100, l3: 0.000176, l4: 0.000416, l5: 0.000762, l6: 0.001049

[epoch: 368/1000, batch:   316/ 1052, ite: 96600] train loss: 0.004614, tar: 0.000178 
l0: 0.000176, l1: 0.000172, l2: 0.000271, l3: 0.000429, l4: 0.000691, l5: 0.001748, l6: 0.002524

[epoch: 368/1000, batch:   396/ 1052, ite: 96620] train loss: 0.004614, tar: 0.000178 
l0: 0.000091, l1: 0.000090, l2: 0.000110, l3: 0.000182, l4: 0.000354, l5: 0.000616, l6: 0.001282

[epoch: 368/1000, batch:   476/ 1052, ite: 96640] train loss: 0.004615, tar: 0.000177 
l0: 0.000120, l1: 0.000131, l2: 0.000078, l3: 0.000167, l4: 0.000289, l5: 0.000623, l6: 0.001106

[epoch: 368/1000, batch:   556/ 1052, ite: 96660] train loss: 0.004612, tar: 0.000177 
l0: 0.000222, l1: 0.000229, l2: 0.000256, l3: 0.000339, l4: 0.000714, l5: 0.001204, l6: 0.002328

[epoch: 368/1000, batch:   636/ 1052, ite: 96680] train loss: 0.004620, tar: 0.000178 
l0: 0.000522, l1: 0.000532, l2: 0.000524, l3: 0.000437, l4: 0.001036, l5: 0.001806, l6: 0.002495

[epoch: 368/1000, batch:   716/ 1052, ite: 96700] train loss: 0.004619, tar: 0.000178 
l0: 0.000112, l1: 0.000113, l2: 0.000127, l3: 0.000244, l4: 0.000314, l5: 0.000625, l6: 0.001285

[epoch: 368/1000, batch:   796/ 1052, ite: 96720] train loss: 0.004620, tar: 0.000177 
l0: 0.000281, l1: 0.000283, l2: 0.000303, l3: 0.000337, l4: 0.000571, l5: 0.000992, l6: 0.001668

[epoch: 368/1000, batch:   876/ 1052, ite: 96740] train loss: 0.004624, tar: 0.000178 
l0: 0.000125, l1: 0.000123, l2: 0.000159, l3: 0.000265, l4: 0.000399, l5: 0.001053, l6: 0.001476

[epoch: 368/1000, batch:   956/ 1052, ite: 96760] train loss: 0.004618, tar: 0.000177 
l0: 0.000148, l1: 0.000152, l2: 0.000195, l3: 0.000349, l4: 0.000473, l5: 0.001019, l6: 0.002025

[epoch: 368/1000, batch:  1036/ 1052, ite: 96780] train loss: 0.004613, tar: 0.000177 
[Epoch 368/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000072, l1: 0.000077, l2: 0.000131, l3: 0.000239, l4: 0.000359, l5: 0.000748, l6: 0.001560

[epoch: 369/1000, batch:    64/ 1052, ite: 96800] train loss: 0.004607, tar: 0.000177 
l0: 0.000424, l1: 0.000430, l2: 0.000467, l3: 0.000556, l4: 0.000891, l5: 0.001349, l6: 0.002968

[epoch: 369/1000, batch:   144/ 1052, ite: 96820] train loss: 0.004604, tar: 0.000177 
l0: 0.000066, l1: 0.000067, l2: 0.000087, l3: 0.000104, l4: 0.000240, l5: 0.000720, l6: 0.001448

[epoch: 369/1000, batch:   224/ 1052, ite: 96840] train loss: 0.004599, tar: 0.000176 
l0: 0.000116, l1: 0.000111, l2: 0.000159, l3: 0.000266, l4: 0.000455, l5: 0.000909, l6: 0.002092

[epoch: 369/1000, batch:   304/ 1052, ite: 96860] train loss: 0.004598, tar: 0.000176 
l0: 0.000316, l1: 0.000319, l2: 0.000346, l3: 0.000415, l4: 0.001034, l5: 0.001490, l6: 0.002781

[epoch: 369/1000, batch:   384/ 1052, ite: 96880] train loss: 0.004600, tar: 0.000176 
l0: 0.000084, l1: 0.000088, l2: 0.000136, l3: 0.000210, l4: 0.000369, l5: 0.000836, l6: 0.001782

[epoch: 369/1000, batch:   464/ 1052, ite: 96900] train loss: 0.004596, tar: 0.000176 
l0: 0.000284, l1: 0.000283, l2: 0.000326, l3: 0.000451, l4: 0.000594, l5: 0.001097, l6: 0.002271

[epoch: 369/1000, batch:   544/ 1052, ite: 96920] train loss: 0.004592, tar: 0.000175 
l0: 0.000124, l1: 0.000125, l2: 0.000159, l3: 0.000286, l4: 0.000599, l5: 0.001365, l6: 0.001814

[epoch: 369/1000, batch:   624/ 1052, ite: 96940] train loss: 0.004590, tar: 0.000175 
l0: 0.000180, l1: 0.000176, l2: 0.000230, l3: 0.000320, l4: 0.000527, l5: 0.000899, l6: 0.001875

[epoch: 369/1000, batch:   704/ 1052, ite: 96960] train loss: 0.004589, tar: 0.000175 
l0: 0.000170, l1: 0.000170, l2: 0.000194, l3: 0.000240, l4: 0.000477, l5: 0.001167, l6: 0.001608

[epoch: 369/1000, batch:   784/ 1052, ite: 96980] train loss: 0.004594, tar: 0.000175 
l0: 0.000152, l1: 0.000156, l2: 0.000176, l3: 0.000258, l4: 0.000460, l5: 0.001269, l6: 0.001935

[epoch: 369/1000, batch:   864/ 1052, ite: 97000] train loss: 0.004597, tar: 0.000175 
l0: 0.000062, l1: 0.000062, l2: 0.000101, l3: 0.000148, l4: 0.000391, l5: 0.000541, l6: 0.001227

[epoch: 369/1000, batch:   944/ 1052, ite: 97020] train loss: 0.004597, tar: 0.000175 
l0: 0.000162, l1: 0.000161, l2: 0.000197, l3: 0.000245, l4: 0.000461, l5: 0.001234, l6: 0.002228

[epoch: 369/1000, batch:  1024/ 1052, ite: 97040] train loss: 0.004597, tar: 0.000175 
[Epoch 369/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000182, l1: 0.000188, l2: 0.000256, l3: 0.000433, l4: 0.000866, l5: 0.001304, l6: 0.001931

[epoch: 370/1000, batch:    52/ 1052, ite: 97060] train loss: 0.004597, tar: 0.000175 
l0: 0.000086, l1: 0.000082, l2: 0.000178, l3: 0.000259, l4: 0.000560, l5: 0.001121, l6: 0.001894

[epoch: 370/1000, batch:   132/ 1052, ite: 97080] train loss: 0.004594, tar: 0.000175 
l0: 0.000172, l1: 0.000173, l2: 0.000204, l3: 0.000375, l4: 0.000610, l5: 0.000954, l6: 0.001621

[epoch: 370/1000, batch:   212/ 1052, ite: 97100] train loss: 0.004593, tar: 0.000175 
l0: 0.000336, l1: 0.000346, l2: 0.000348, l3: 0.000439, l4: 0.000583, l5: 0.001151, l6: 0.001227

[epoch: 370/1000, batch:   292/ 1052, ite: 97120] train loss: 0.004591, tar: 0.000175 
l0: 0.000076, l1: 0.000071, l2: 0.000158, l3: 0.000204, l4: 0.000272, l5: 0.000792, l6: 0.001286

[epoch: 370/1000, batch:   372/ 1052, ite: 97140] train loss: 0.004590, tar: 0.000174 
l0: 0.000160, l1: 0.000159, l2: 0.000186, l3: 0.000269, l4: 0.000400, l5: 0.001116, l6: 0.001359

[epoch: 370/1000, batch:   452/ 1052, ite: 97160] train loss: 0.004592, tar: 0.000174 
l0: 0.000120, l1: 0.000119, l2: 0.000157, l3: 0.000252, l4: 0.000577, l5: 0.001327, l6: 0.002195

[epoch: 370/1000, batch:   532/ 1052, ite: 97180] train loss: 0.004587, tar: 0.000174 
l0: 0.000085, l1: 0.000090, l2: 0.000090, l3: 0.000172, l4: 0.000380, l5: 0.000780, l6: 0.002014

[epoch: 370/1000, batch:   612/ 1052, ite: 97200] train loss: 0.004586, tar: 0.000174 
l0: 0.000112, l1: 0.000114, l2: 0.000119, l3: 0.000208, l4: 0.000470, l5: 0.000915, l6: 0.001441

[epoch: 370/1000, batch:   692/ 1052, ite: 97220] train loss: 0.004582, tar: 0.000173 
l0: 0.000172, l1: 0.000172, l2: 0.000196, l3: 0.000232, l4: 0.000424, l5: 0.000678, l6: 0.001641

[epoch: 370/1000, batch:   772/ 1052, ite: 97240] train loss: 0.004585, tar: 0.000173 
l0: 0.000241, l1: 0.000251, l2: 0.000234, l3: 0.000336, l4: 0.000661, l5: 0.001184, l6: 0.002977

[epoch: 370/1000, batch:   852/ 1052, ite: 97260] train loss: 0.004586, tar: 0.000173 
l0: 0.000202, l1: 0.000203, l2: 0.000227, l3: 0.000320, l4: 0.000621, l5: 0.001588, l6: 0.002398

[epoch: 370/1000, batch:   932/ 1052, ite: 97280] train loss: 0.004593, tar: 0.000174 
l0: 0.000094, l1: 0.000094, l2: 0.000117, l3: 0.000200, l4: 0.000318, l5: 0.000629, l6: 0.001292

[epoch: 370/1000, batch:  1012/ 1052, ite: 97300] train loss: 0.004592, tar: 0.000174 
[Epoch 370/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000237, l1: 0.000217, l2: 0.000265, l3: 0.000258, l4: 0.000391, l5: 0.000957, l6: 0.001239

[epoch: 371/1000, batch:    40/ 1052, ite: 97320] train loss: 0.004592, tar: 0.000174 
l0: 0.000147, l1: 0.000150, l2: 0.000157, l3: 0.000259, l4: 0.000530, l5: 0.001240, l6: 0.001877

[epoch: 371/1000, batch:   120/ 1052, ite: 97340] train loss: 0.004595, tar: 0.000174 
l0: 0.000079, l1: 0.000081, l2: 0.000116, l3: 0.000153, l4: 0.000489, l5: 0.000886, l6: 0.001383

[epoch: 371/1000, batch:   200/ 1052, ite: 97360] train loss: 0.004594, tar: 0.000173 
l0: 0.000276, l1: 0.000280, l2: 0.000335, l3: 0.000553, l4: 0.000844, l5: 0.001567, l6: 0.002527

[epoch: 371/1000, batch:   280/ 1052, ite: 97380] train loss: 0.004591, tar: 0.000174 
l0: 0.000097, l1: 0.000096, l2: 0.000134, l3: 0.000188, l4: 0.000494, l5: 0.000946, l6: 0.002275

[epoch: 371/1000, batch:   360/ 1052, ite: 97400] train loss: 0.004596, tar: 0.000174 
l0: 0.000073, l1: 0.000077, l2: 0.000086, l3: 0.000140, l4: 0.000297, l5: 0.000427, l6: 0.001312

[epoch: 371/1000, batch:   440/ 1052, ite: 97420] train loss: 0.004595, tar: 0.000174 
l0: 0.000128, l1: 0.000127, l2: 0.000181, l3: 0.000267, l4: 0.000480, l5: 0.001340, l6: 0.001835

[epoch: 371/1000, batch:   520/ 1052, ite: 97440] train loss: 0.004593, tar: 0.000173 
l0: 0.000122, l1: 0.000116, l2: 0.000172, l3: 0.000255, l4: 0.000486, l5: 0.000920, l6: 0.001352

[epoch: 371/1000, batch:   600/ 1052, ite: 97460] train loss: 0.004591, tar: 0.000173 
l0: 0.000183, l1: 0.000182, l2: 0.000194, l3: 0.000307, l4: 0.000707, l5: 0.001438, l6: 0.001928

[epoch: 371/1000, batch:   680/ 1052, ite: 97480] train loss: 0.004586, tar: 0.000173 
l0: 0.000065, l1: 0.000067, l2: 0.000075, l3: 0.000153, l4: 0.000366, l5: 0.000615, l6: 0.001331

[epoch: 371/1000, batch:   760/ 1052, ite: 97500] train loss: 0.004587, tar: 0.000173 
l0: 0.000124, l1: 0.000130, l2: 0.000128, l3: 0.000182, l4: 0.000406, l5: 0.001230, l6: 0.001679

[epoch: 371/1000, batch:   840/ 1052, ite: 97520] train loss: 0.004588, tar: 0.000173 
l0: 0.000121, l1: 0.000124, l2: 0.000142, l3: 0.000314, l4: 0.000650, l5: 0.001183, l6: 0.002932

[epoch: 371/1000, batch:   920/ 1052, ite: 97540] train loss: 0.004583, tar: 0.000173 
l0: 0.000144, l1: 0.000139, l2: 0.000178, l3: 0.000265, l4: 0.000485, l5: 0.000939, l6: 0.001458

[epoch: 371/1000, batch:  1000/ 1052, ite: 97560] train loss: 0.004586, tar: 0.000173 
[Epoch 371/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000076, l1: 0.000076, l2: 0.000102, l3: 0.000146, l4: 0.000257, l5: 0.000856, l6: 0.001432

[epoch: 372/1000, batch:    28/ 1052, ite: 97580] train loss: 0.004584, tar: 0.000173 
l0: 0.000241, l1: 0.000248, l2: 0.000306, l3: 0.000490, l4: 0.000753, l5: 0.001499, l6: 0.002830

[epoch: 372/1000, batch:   108/ 1052, ite: 97600] train loss: 0.004585, tar: 0.000173 
l0: 0.000174, l1: 0.000176, l2: 0.000176, l3: 0.000235, l4: 0.000368, l5: 0.000863, l6: 0.001578

[epoch: 372/1000, batch:   188/ 1052, ite: 97620] train loss: 0.004587, tar: 0.000173 
l0: 0.000124, l1: 0.000126, l2: 0.000152, l3: 0.000220, l4: 0.000628, l5: 0.001193, l6: 0.001817

[epoch: 372/1000, batch:   268/ 1052, ite: 97640] train loss: 0.004585, tar: 0.000173 
l0: 0.000147, l1: 0.000145, l2: 0.000179, l3: 0.000259, l4: 0.000380, l5: 0.000778, l6: 0.001096

[epoch: 372/1000, batch:   348/ 1052, ite: 97660] train loss: 0.004586, tar: 0.000173 
l0: 0.000058, l1: 0.000057, l2: 0.000121, l3: 0.000205, l4: 0.000498, l5: 0.000982, l6: 0.002051

[epoch: 372/1000, batch:   428/ 1052, ite: 97680] train loss: 0.004589, tar: 0.000173 
l0: 0.000150, l1: 0.000151, l2: 0.000167, l3: 0.000217, l4: 0.000631, l5: 0.001544, l6: 0.002190

[epoch: 372/1000, batch:   508/ 1052, ite: 97700] train loss: 0.004588, tar: 0.000173 
l0: 0.000545, l1: 0.000550, l2: 0.000571, l3: 0.000799, l4: 0.001505, l5: 0.003143, l6: 0.004703

[epoch: 372/1000, batch:   588/ 1052, ite: 97720] train loss: 0.004589, tar: 0.000173 
l0: 0.000167, l1: 0.000177, l2: 0.000202, l3: 0.000269, l4: 0.000509, l5: 0.000977, l6: 0.002236

[epoch: 372/1000, batch:   668/ 1052, ite: 97740] train loss: 0.004591, tar: 0.000173 
l0: 0.000397, l1: 0.000395, l2: 0.000433, l3: 0.000463, l4: 0.000622, l5: 0.001294, l6: 0.001538

[epoch: 372/1000, batch:   748/ 1052, ite: 97760] train loss: 0.004591, tar: 0.000173 
l0: 0.000179, l1: 0.000173, l2: 0.000232, l3: 0.000242, l4: 0.000487, l5: 0.001122, l6: 0.001535

[epoch: 372/1000, batch:   828/ 1052, ite: 97780] train loss: 0.004593, tar: 0.000174 
l0: 0.000140, l1: 0.000152, l2: 0.000158, l3: 0.000255, l4: 0.000410, l5: 0.000959, l6: 0.001011

[epoch: 372/1000, batch:   908/ 1052, ite: 97800] train loss: 0.004597, tar: 0.000175 
l0: 0.000253, l1: 0.000254, l2: 0.000279, l3: 0.000293, l4: 0.000551, l5: 0.001708, l6: 0.002942

[epoch: 372/1000, batch:   988/ 1052, ite: 97820] train loss: 0.004601, tar: 0.000175 
[Epoch 372/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000325, l1: 0.000337, l2: 0.000304, l3: 0.000503, l4: 0.000929, l5: 0.002131, l6: 0.002754

[epoch: 373/1000, batch:    16/ 1052, ite: 97840] train loss: 0.004600, tar: 0.000175 
l0: 0.000286, l1: 0.000293, l2: 0.000373, l3: 0.000588, l4: 0.000830, l5: 0.001269, l6: 0.001999

[epoch: 373/1000, batch:    96/ 1052, ite: 97860] train loss: 0.004601, tar: 0.000175 
l0: 0.000207, l1: 0.000208, l2: 0.000250, l3: 0.000305, l4: 0.000733, l5: 0.001222, l6: 0.002351

[epoch: 373/1000, batch:   176/ 1052, ite: 97880] train loss: 0.004603, tar: 0.000176 
l0: 0.000352, l1: 0.000351, l2: 0.000452, l3: 0.000413, l4: 0.000696, l5: 0.001223, l6: 0.002817

[epoch: 373/1000, batch:   256/ 1052, ite: 97900] train loss: 0.004608, tar: 0.000176 
l0: 0.000197, l1: 0.000214, l2: 0.000253, l3: 0.000286, l4: 0.000461, l5: 0.000930, l6: 0.001476

[epoch: 373/1000, batch:   336/ 1052, ite: 97920] train loss: 0.004618, tar: 0.000178 
l0: 0.000421, l1: 0.000471, l2: 0.000628, l3: 0.000477, l4: 0.000509, l5: 0.000939, l6: 0.001170

[epoch: 373/1000, batch:   416/ 1052, ite: 97940] train loss: 0.004636, tar: 0.000181 
l0: 0.003119, l1: 0.008664, l2: 0.008043, l3: 0.008170, l4: 0.001297, l5: 0.002204, l6: 0.004389

[epoch: 373/1000, batch:   496/ 1052, ite: 97960] train loss: 0.004687, tar: 0.000188 
l0: 0.000275, l1: 0.000303, l2: 0.000264, l3: 0.000285, l4: 0.000458, l5: 0.000832, l6: 0.001234

[epoch: 373/1000, batch:   576/ 1052, ite: 97980] train loss: 0.004705, tar: 0.000191 
l0: 0.000258, l1: 0.000404, l2: 0.000283, l3: 0.000265, l4: 0.000310, l5: 0.000556, l6: 0.001602

[epoch: 373/1000, batch:   656/ 1052, ite: 98000] train loss: 0.004727, tar: 0.000195 
l0: 0.000201, l1: 0.000208, l2: 0.000242, l3: 0.000239, l4: 0.000492, l5: 0.000928, l6: 0.001770

[epoch: 373/1000, batch:   736/ 1052, ite: 98020] train loss: 0.004736, tar: 0.000196 
l0: 0.000373, l1: 0.000432, l2: 0.000298, l3: 0.000271, l4: 0.000408, l5: 0.000821, l6: 0.001508

[epoch: 373/1000, batch:   816/ 1052, ite: 98040] train loss: 0.004737, tar: 0.000198 
l0: 0.000463, l1: 0.000422, l2: 0.000509, l3: 0.000628, l4: 0.001199, l5: 0.001547, l6: 0.002151

[epoch: 373/1000, batch:   896/ 1052, ite: 98060] train loss: 0.004740, tar: 0.000198 
l0: 0.000517, l1: 0.000532, l2: 0.000470, l3: 0.000799, l4: 0.000885, l5: 0.001311, l6: 0.001886

[epoch: 373/1000, batch:   976/ 1052, ite: 98080] train loss: 0.004748, tar: 0.000200 
[Epoch 373/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000269, l1: 0.000312, l2: 0.000291, l3: 0.000347, l4: 0.000401, l5: 0.000961, l6: 0.001030

[epoch: 374/1000, batch:     4/ 1052, ite: 98100] train loss: 0.004755, tar: 0.000201 
l0: 0.000672, l1: 0.000604, l2: 0.000578, l3: 0.000677, l4: 0.001023, l5: 0.002158, l6: 0.002348

[epoch: 374/1000, batch:    84/ 1052, ite: 98120] train loss: 0.004760, tar: 0.000202 
l0: 0.000237, l1: 0.000228, l2: 0.000287, l3: 0.000342, l4: 0.000455, l5: 0.000879, l6: 0.001041

[epoch: 374/1000, batch:   164/ 1052, ite: 98140] train loss: 0.004763, tar: 0.000203 
l0: 0.000172, l1: 0.000200, l2: 0.000216, l3: 0.000230, l4: 0.000378, l5: 0.000730, l6: 0.001338

[epoch: 374/1000, batch:   244/ 1052, ite: 98160] train loss: 0.004770, tar: 0.000203 
l0: 0.000154, l1: 0.000138, l2: 0.000154, l3: 0.000223, l4: 0.000518, l5: 0.000886, l6: 0.001307

[epoch: 374/1000, batch:   324/ 1052, ite: 98180] train loss: 0.004769, tar: 0.000204 
l0: 0.000218, l1: 0.000230, l2: 0.000231, l3: 0.000246, l4: 0.000429, l5: 0.000883, l6: 0.001559

[epoch: 374/1000, batch:   404/ 1052, ite: 98200] train loss: 0.004769, tar: 0.000204 
l0: 0.000241, l1: 0.000245, l2: 0.000250, l3: 0.000311, l4: 0.000451, l5: 0.000848, l6: 0.001423

[epoch: 374/1000, batch:   484/ 1052, ite: 98220] train loss: 0.004773, tar: 0.000205 
l0: 0.000147, l1: 0.000147, l2: 0.000163, l3: 0.000197, l4: 0.000325, l5: 0.000707, l6: 0.001318

[epoch: 374/1000, batch:   564/ 1052, ite: 98240] train loss: 0.004777, tar: 0.000205 
l0: 0.000291, l1: 0.000289, l2: 0.000305, l3: 0.000390, l4: 0.000583, l5: 0.001174, l6: 0.002399

[epoch: 374/1000, batch:   644/ 1052, ite: 98260] train loss: 0.004782, tar: 0.000206 
l0: 0.000509, l1: 0.000524, l2: 0.000556, l3: 0.000594, l4: 0.000936, l5: 0.001635, l6: 0.002218

[epoch: 374/1000, batch:   724/ 1052, ite: 98280] train loss: 0.004783, tar: 0.000206 
l0: 0.000180, l1: 0.000177, l2: 0.000226, l3: 0.000231, l4: 0.000361, l5: 0.000780, l6: 0.001546

[epoch: 374/1000, batch:   804/ 1052, ite: 98300] train loss: 0.004782, tar: 0.000206 
l0: 0.000142, l1: 0.000138, l2: 0.000157, l3: 0.000222, l4: 0.000425, l5: 0.000795, l6: 0.000915

[epoch: 374/1000, batch:   884/ 1052, ite: 98320] train loss: 0.004783, tar: 0.000206 
l0: 0.000359, l1: 0.000369, l2: 0.000370, l3: 0.000480, l4: 0.000914, l5: 0.001806, l6: 0.002657

[epoch: 374/1000, batch:   964/ 1052, ite: 98340] train loss: 0.004784, tar: 0.000207 
l0: 0.000192, l1: 0.000188, l2: 0.000248, l3: 0.000335, l4: 0.000620, l5: 0.001300, l6: 0.003130

[epoch: 374/1000, batch:  1044/ 1052, ite: 98360] train loss: 0.004787, tar: 0.000207 
[Epoch 374/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000176, l1: 0.000168, l2: 0.000209, l3: 0.000233, l4: 0.000444, l5: 0.001065, l6: 0.002391

[epoch: 375/1000, batch:    72/ 1052, ite: 98380] train loss: 0.004790, tar: 0.000207 
l0: 0.000383, l1: 0.000379, l2: 0.000419, l3: 0.000628, l4: 0.000842, l5: 0.001999, l6: 0.002898

[epoch: 375/1000, batch:   152/ 1052, ite: 98400] train loss: 0.004793, tar: 0.000207 
l0: 0.000087, l1: 0.000079, l2: 0.000106, l3: 0.000153, l4: 0.000376, l5: 0.000685, l6: 0.001252

[epoch: 375/1000, batch:   232/ 1052, ite: 98420] train loss: 0.004793, tar: 0.000208 
l0: 0.000131, l1: 0.000132, l2: 0.000160, l3: 0.000200, l4: 0.000390, l5: 0.000822, l6: 0.001692

[epoch: 375/1000, batch:   312/ 1052, ite: 98440] train loss: 0.004791, tar: 0.000207 
l0: 0.000386, l1: 0.000383, l2: 0.000385, l3: 0.000471, l4: 0.000974, l5: 0.002797, l6: 0.004446

[epoch: 375/1000, batch:   392/ 1052, ite: 98460] train loss: 0.004791, tar: 0.000207 
l0: 0.000103, l1: 0.000102, l2: 0.000118, l3: 0.000164, l4: 0.000326, l5: 0.000621, l6: 0.000887

[epoch: 375/1000, batch:   472/ 1052, ite: 98480] train loss: 0.004794, tar: 0.000208 
l0: 0.000229, l1: 0.000242, l2: 0.000257, l3: 0.000363, l4: 0.000591, l5: 0.001333, l6: 0.002311

[epoch: 375/1000, batch:   552/ 1052, ite: 98500] train loss: 0.004796, tar: 0.000208 
l0: 0.000191, l1: 0.000187, l2: 0.000224, l3: 0.000263, l4: 0.000524, l5: 0.001231, l6: 0.001654

[epoch: 375/1000, batch:   632/ 1052, ite: 98520] train loss: 0.004796, tar: 0.000208 
l0: 0.000150, l1: 0.000150, l2: 0.000195, l3: 0.000249, l4: 0.000360, l5: 0.000945, l6: 0.001400

[epoch: 375/1000, batch:   712/ 1052, ite: 98540] train loss: 0.004797, tar: 0.000208 
l0: 0.000122, l1: 0.000123, l2: 0.000171, l3: 0.000253, l4: 0.000492, l5: 0.000691, l6: 0.001418

[epoch: 375/1000, batch:   792/ 1052, ite: 98560] train loss: 0.004796, tar: 0.000208 
l0: 0.000317, l1: 0.000333, l2: 0.000328, l3: 0.000538, l4: 0.000767, l5: 0.001963, l6: 0.002344

[epoch: 375/1000, batch:   872/ 1052, ite: 98580] train loss: 0.004796, tar: 0.000208 
l0: 0.000127, l1: 0.000123, l2: 0.000155, l3: 0.000232, l4: 0.000514, l5: 0.001211, l6: 0.001959

[epoch: 375/1000, batch:   952/ 1052, ite: 98600] train loss: 0.004794, tar: 0.000208 
l0: 0.000100, l1: 0.000098, l2: 0.000134, l3: 0.000186, l4: 0.000471, l5: 0.001097, l6: 0.001187

[epoch: 375/1000, batch:  1032/ 1052, ite: 98620] train loss: 0.004793, tar: 0.000208 
[Epoch 375/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000135, l1: 0.000136, l2: 0.000216, l3: 0.000280, l4: 0.000529, l5: 0.001315, l6: 0.002871

[epoch: 376/1000, batch:    60/ 1052, ite: 98640] train loss: 0.004796, tar: 0.000208 
l0: 0.000163, l1: 0.000162, l2: 0.000179, l3: 0.000195, l4: 0.000555, l5: 0.001295, l6: 0.001222

[epoch: 376/1000, batch:   140/ 1052, ite: 98660] train loss: 0.004797, tar: 0.000209 
l0: 0.000092, l1: 0.000096, l2: 0.000122, l3: 0.000170, l4: 0.000272, l5: 0.000483, l6: 0.001571

[epoch: 376/1000, batch:   220/ 1052, ite: 98680] train loss: 0.004799, tar: 0.000209 
l0: 0.000197, l1: 0.000203, l2: 0.000219, l3: 0.000283, l4: 0.000350, l5: 0.001090, l6: 0.002254

[epoch: 376/1000, batch:   300/ 1052, ite: 98700] train loss: 0.004802, tar: 0.000209 
l0: 0.000129, l1: 0.000114, l2: 0.000148, l3: 0.000216, l4: 0.000459, l5: 0.000686, l6: 0.001370

[epoch: 376/1000, batch:   380/ 1052, ite: 98720] train loss: 0.004799, tar: 0.000209 
l0: 0.000221, l1: 0.000235, l2: 0.000285, l3: 0.000367, l4: 0.000521, l5: 0.001189, l6: 0.002140

[epoch: 376/1000, batch:   460/ 1052, ite: 98740] train loss: 0.004800, tar: 0.000209 
l0: 0.000126, l1: 0.000125, l2: 0.000146, l3: 0.000176, l4: 0.000384, l5: 0.000847, l6: 0.001430

[epoch: 376/1000, batch:   540/ 1052, ite: 98760] train loss: 0.004798, tar: 0.000209 
l0: 0.000148, l1: 0.000148, l2: 0.000178, l3: 0.000230, l4: 0.000440, l5: 0.001179, l6: 0.001914

[epoch: 376/1000, batch:   620/ 1052, ite: 98780] train loss: 0.004800, tar: 0.000209 
l0: 0.000221, l1: 0.000215, l2: 0.000256, l3: 0.000353, l4: 0.000589, l5: 0.001425, l6: 0.003383

[epoch: 376/1000, batch:   700/ 1052, ite: 98800] train loss: 0.004803, tar: 0.000209 
l0: 0.000297, l1: 0.000319, l2: 0.000307, l3: 0.000413, l4: 0.000686, l5: 0.001306, l6: 0.002813

[epoch: 376/1000, batch:   780/ 1052, ite: 98820] train loss: 0.004802, tar: 0.000209 
l0: 0.000162, l1: 0.000160, l2: 0.000213, l3: 0.000306, l4: 0.000571, l5: 0.000835, l6: 0.001971

[epoch: 376/1000, batch:   860/ 1052, ite: 98840] train loss: 0.004801, tar: 0.000209 
l0: 0.000180, l1: 0.000169, l2: 0.000189, l3: 0.000359, l4: 0.000568, l5: 0.001113, l6: 0.003268

[epoch: 376/1000, batch:   940/ 1052, ite: 98860] train loss: 0.004799, tar: 0.000209 
l0: 0.000158, l1: 0.000147, l2: 0.000197, l3: 0.000298, l4: 0.000622, l5: 0.000824, l6: 0.002334

[epoch: 376/1000, batch:  1020/ 1052, ite: 98880] train loss: 0.004800, tar: 0.000209 
[Epoch 376/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000385, l1: 0.000378, l2: 0.000442, l3: 0.000617, l4: 0.000913, l5: 0.001998, l6: 0.002808

[epoch: 377/1000, batch:    48/ 1052, ite: 98900] train loss: 0.004801, tar: 0.000209 
l0: 0.000259, l1: 0.000260, l2: 0.000279, l3: 0.000457, l4: 0.000582, l5: 0.000904, l6: 0.002196

[epoch: 377/1000, batch:   128/ 1052, ite: 98920] train loss: 0.004799, tar: 0.000209 
l0: 0.000220, l1: 0.000217, l2: 0.000244, l3: 0.000267, l4: 0.000447, l5: 0.001006, l6: 0.002248

[epoch: 377/1000, batch:   208/ 1052, ite: 98940] train loss: 0.004797, tar: 0.000209 
l0: 0.000141, l1: 0.000134, l2: 0.000167, l3: 0.000243, l4: 0.000376, l5: 0.001035, l6: 0.001960

[epoch: 377/1000, batch:   288/ 1052, ite: 98960] train loss: 0.004797, tar: 0.000209 
l0: 0.000100, l1: 0.000098, l2: 0.000135, l3: 0.000168, l4: 0.000403, l5: 0.000927, l6: 0.001569

[epoch: 377/1000, batch:   368/ 1052, ite: 98980] train loss: 0.004797, tar: 0.000208 
l0: 0.000413, l1: 0.000435, l2: 0.000530, l3: 0.000589, l4: 0.001125, l5: 0.002276, l6: 0.002403

[epoch: 377/1000, batch:   448/ 1052, ite: 99000] train loss: 0.004797, tar: 0.000208 
l0: 0.000085, l1: 0.000090, l2: 0.000136, l3: 0.000200, l4: 0.000317, l5: 0.000656, l6: 0.000979

[epoch: 377/1000, batch:   528/ 1052, ite: 99020] train loss: 0.004798, tar: 0.000208 
l0: 0.000099, l1: 0.000096, l2: 0.000124, l3: 0.000177, l4: 0.000332, l5: 0.000508, l6: 0.002166

[epoch: 377/1000, batch:   608/ 1052, ite: 99040] train loss: 0.004800, tar: 0.000208 
l0: 0.000118, l1: 0.000114, l2: 0.000159, l3: 0.000204, l4: 0.000306, l5: 0.000610, l6: 0.001320

[epoch: 377/1000, batch:   688/ 1052, ite: 99060] train loss: 0.004795, tar: 0.000208 
l0: 0.000231, l1: 0.000220, l2: 0.000311, l3: 0.000428, l4: 0.000789, l5: 0.001206, l6: 0.001974

[epoch: 377/1000, batch:   768/ 1052, ite: 99080] train loss: 0.004797, tar: 0.000208 
l0: 0.000196, l1: 0.000197, l2: 0.000239, l3: 0.000276, l4: 0.000499, l5: 0.001414, l6: 0.002067

[epoch: 377/1000, batch:   848/ 1052, ite: 99100] train loss: 0.004794, tar: 0.000208 
l0: 0.000216, l1: 0.000218, l2: 0.000247, l3: 0.000328, l4: 0.000477, l5: 0.000918, l6: 0.001068

[epoch: 377/1000, batch:   928/ 1052, ite: 99120] train loss: 0.004794, tar: 0.000207 
l0: 0.000257, l1: 0.000246, l2: 0.000333, l3: 0.000485, l4: 0.001246, l5: 0.001829, l6: 0.002554

[epoch: 377/1000, batch:  1008/ 1052, ite: 99140] train loss: 0.004794, tar: 0.000207 
[Epoch 377/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000416, l1: 0.000432, l2: 0.000512, l3: 0.000558, l4: 0.001063, l5: 0.001807, l6: 0.004170

[epoch: 378/1000, batch:    36/ 1052, ite: 99160] train loss: 0.004792, tar: 0.000207 
l0: 0.000322, l1: 0.000294, l2: 0.000307, l3: 0.000357, l4: 0.000438, l5: 0.000711, l6: 0.000994

[epoch: 378/1000, batch:   116/ 1052, ite: 99180] train loss: 0.004791, tar: 0.000207 
l0: 0.000119, l1: 0.000118, l2: 0.000161, l3: 0.000190, l4: 0.000285, l5: 0.000637, l6: 0.000990

[epoch: 378/1000, batch:   196/ 1052, ite: 99200] train loss: 0.004789, tar: 0.000207 
l0: 0.000124, l1: 0.000119, l2: 0.000123, l3: 0.000188, l4: 0.000284, l5: 0.000685, l6: 0.001698

[epoch: 378/1000, batch:   276/ 1052, ite: 99220] train loss: 0.004787, tar: 0.000207 
l0: 0.000222, l1: 0.000211, l2: 0.000256, l3: 0.000331, l4: 0.000794, l5: 0.001707, l6: 0.002788

[epoch: 378/1000, batch:   356/ 1052, ite: 99240] train loss: 0.004787, tar: 0.000207 
l0: 0.000151, l1: 0.000149, l2: 0.000180, l3: 0.000244, l4: 0.000414, l5: 0.000997, l6: 0.001943

[epoch: 378/1000, batch:   436/ 1052, ite: 99260] train loss: 0.004788, tar: 0.000207 
l0: 0.000252, l1: 0.000246, l2: 0.000291, l3: 0.000435, l4: 0.000723, l5: 0.001222, l6: 0.001850

[epoch: 378/1000, batch:   516/ 1052, ite: 99280] train loss: 0.004789, tar: 0.000207 
l0: 0.000159, l1: 0.000171, l2: 0.000213, l3: 0.000364, l4: 0.000664, l5: 0.000982, l6: 0.002285

[epoch: 378/1000, batch:   596/ 1052, ite: 99300] train loss: 0.004786, tar: 0.000206 
l0: 0.000209, l1: 0.000212, l2: 0.000235, l3: 0.000327, l4: 0.000685, l5: 0.001387, l6: 0.003212

[epoch: 378/1000, batch:   676/ 1052, ite: 99320] train loss: 0.004788, tar: 0.000206 
l0: 0.000162, l1: 0.000159, l2: 0.000175, l3: 0.000252, l4: 0.000460, l5: 0.001361, l6: 0.002273

[epoch: 378/1000, batch:   756/ 1052, ite: 99340] train loss: 0.004788, tar: 0.000206 
l0: 0.000121, l1: 0.000117, l2: 0.000140, l3: 0.000187, l4: 0.000391, l5: 0.000937, l6: 0.001502

[epoch: 378/1000, batch:   836/ 1052, ite: 99360] train loss: 0.004787, tar: 0.000206 
l0: 0.000073, l1: 0.000080, l2: 0.000076, l3: 0.000148, l4: 0.000304, l5: 0.000711, l6: 0.000882

[epoch: 378/1000, batch:   916/ 1052, ite: 99380] train loss: 0.004783, tar: 0.000206 
l0: 0.000145, l1: 0.000144, l2: 0.000163, l3: 0.000224, l4: 0.000431, l5: 0.000919, l6: 0.001909

[epoch: 378/1000, batch:   996/ 1052, ite: 99400] train loss: 0.004781, tar: 0.000205 
[Epoch 378/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000139, l1: 0.000131, l2: 0.000195, l3: 0.000274, l4: 0.000734, l5: 0.001231, l6: 0.001935

[epoch: 379/1000, batch:    24/ 1052, ite: 99420] train loss: 0.004780, tar: 0.000205 
l0: 0.000190, l1: 0.000194, l2: 0.000219, l3: 0.000263, l4: 0.000596, l5: 0.000836, l6: 0.001800

[epoch: 379/1000, batch:   104/ 1052, ite: 99440] train loss: 0.004779, tar: 0.000205 
l0: 0.000100, l1: 0.000110, l2: 0.000115, l3: 0.000183, l4: 0.000362, l5: 0.000940, l6: 0.001140

[epoch: 379/1000, batch:   184/ 1052, ite: 99460] train loss: 0.004777, tar: 0.000205 
l0: 0.000466, l1: 0.000460, l2: 0.000551, l3: 0.000869, l4: 0.001273, l5: 0.001934, l6: 0.005517

[epoch: 379/1000, batch:   264/ 1052, ite: 99480] train loss: 0.004777, tar: 0.000205 
l0: 0.000140, l1: 0.000141, l2: 0.000159, l3: 0.000220, l4: 0.000526, l5: 0.000805, l6: 0.002226

[epoch: 379/1000, batch:   344/ 1052, ite: 99500] train loss: 0.004774, tar: 0.000205 
l0: 0.000168, l1: 0.000149, l2: 0.000220, l3: 0.000271, l4: 0.000441, l5: 0.000970, l6: 0.001276

[epoch: 379/1000, batch:   424/ 1052, ite: 99520] train loss: 0.004773, tar: 0.000204 
l0: 0.000068, l1: 0.000067, l2: 0.000083, l3: 0.000145, l4: 0.000353, l5: 0.000688, l6: 0.001115

[epoch: 379/1000, batch:   504/ 1052, ite: 99540] train loss: 0.004773, tar: 0.000204 
l0: 0.000182, l1: 0.000179, l2: 0.000224, l3: 0.000382, l4: 0.000734, l5: 0.001355, l6: 0.002888

[epoch: 379/1000, batch:   584/ 1052, ite: 99560] train loss: 0.004776, tar: 0.000204 
l0: 0.000130, l1: 0.000128, l2: 0.000146, l3: 0.000198, l4: 0.000409, l5: 0.000778, l6: 0.001659

[epoch: 379/1000, batch:   664/ 1052, ite: 99580] train loss: 0.004776, tar: 0.000204 
l0: 0.000234, l1: 0.000224, l2: 0.000269, l3: 0.000371, l4: 0.000797, l5: 0.001874, l6: 0.001720

[epoch: 379/1000, batch:   744/ 1052, ite: 99600] train loss: 0.004771, tar: 0.000204 
l0: 0.000132, l1: 0.000144, l2: 0.000152, l3: 0.000214, l4: 0.000581, l5: 0.000982, l6: 0.001010

[epoch: 379/1000, batch:   824/ 1052, ite: 99620] train loss: 0.004771, tar: 0.000204 
l0: 0.000170, l1: 0.000178, l2: 0.000210, l3: 0.000330, l4: 0.000614, l5: 0.001435, l6: 0.002071

[epoch: 379/1000, batch:   904/ 1052, ite: 99640] train loss: 0.004768, tar: 0.000204 
l0: 0.000316, l1: 0.000326, l2: 0.000337, l3: 0.000591, l4: 0.001167, l5: 0.002235, l6: 0.003162

[epoch: 379/1000, batch:   984/ 1052, ite: 99660] train loss: 0.004768, tar: 0.000204 
[Epoch 379/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000076, l1: 0.000073, l2: 0.000115, l3: 0.000176, l4: 0.000437, l5: 0.000900, l6: 0.001570

[epoch: 380/1000, batch:    12/ 1052, ite: 99680] train loss: 0.004767, tar: 0.000203 
l0: 0.000157, l1: 0.000153, l2: 0.000189, l3: 0.000259, l4: 0.000610, l5: 0.001199, l6: 0.001713

[epoch: 380/1000, batch:    92/ 1052, ite: 99700] train loss: 0.004765, tar: 0.000203 
l0: 0.000216, l1: 0.000217, l2: 0.000271, l3: 0.000388, l4: 0.000740, l5: 0.001514, l6: 0.003032

[epoch: 380/1000, batch:   172/ 1052, ite: 99720] train loss: 0.004763, tar: 0.000203 
l0: 0.000135, l1: 0.000135, l2: 0.000147, l3: 0.000206, l4: 0.000274, l5: 0.000913, l6: 0.001505

[epoch: 380/1000, batch:   252/ 1052, ite: 99740] train loss: 0.004761, tar: 0.000203 
l0: 0.000148, l1: 0.000143, l2: 0.000193, l3: 0.000241, l4: 0.000323, l5: 0.000879, l6: 0.001582

[epoch: 380/1000, batch:   332/ 1052, ite: 99760] train loss: 0.004758, tar: 0.000202 
l0: 0.000085, l1: 0.000083, l2: 0.000109, l3: 0.000206, l4: 0.000361, l5: 0.001114, l6: 0.001862

[epoch: 380/1000, batch:   412/ 1052, ite: 99780] train loss: 0.004758, tar: 0.000202 
l0: 0.000168, l1: 0.000167, l2: 0.000269, l3: 0.000343, l4: 0.000606, l5: 0.001355, l6: 0.001863

[epoch: 380/1000, batch:   492/ 1052, ite: 99800] train loss: 0.004758, tar: 0.000202 
l0: 0.000143, l1: 0.000150, l2: 0.000187, l3: 0.000251, l4: 0.000671, l5: 0.001359, l6: 0.002121

[epoch: 380/1000, batch:   572/ 1052, ite: 99820] train loss: 0.004756, tar: 0.000202 
l0: 0.000130, l1: 0.000128, l2: 0.000199, l3: 0.000360, l4: 0.000549, l5: 0.000966, l6: 0.001965

[epoch: 380/1000, batch:   652/ 1052, ite: 99840] train loss: 0.004756, tar: 0.000202 
l0: 0.000271, l1: 0.000281, l2: 0.000302, l3: 0.000379, l4: 0.000639, l5: 0.001376, l6: 0.002989

[epoch: 380/1000, batch:   732/ 1052, ite: 99860] train loss: 0.004755, tar: 0.000202 
l0: 0.000152, l1: 0.000160, l2: 0.000172, l3: 0.000239, l4: 0.000473, l5: 0.000918, l6: 0.001993

[epoch: 380/1000, batch:   812/ 1052, ite: 99880] train loss: 0.004754, tar: 0.000201 
l0: 0.000096, l1: 0.000103, l2: 0.000105, l3: 0.000161, l4: 0.000298, l5: 0.000659, l6: 0.001360

[epoch: 380/1000, batch:   892/ 1052, ite: 99900] train loss: 0.004753, tar: 0.000201 
l0: 0.000190, l1: 0.000181, l2: 0.000250, l3: 0.000447, l4: 0.000574, l5: 0.001002, l6: 0.001868

[epoch: 380/1000, batch:   972/ 1052, ite: 99920] train loss: 0.004753, tar: 0.000201 
l0: 0.000202, l1: 0.000184, l2: 0.000245, l3: 0.000445, l4: 0.000699, l5: 0.001175, l6: 0.002183

[epoch: 380/1000, batch:  1052/ 1052, ite: 99940] train loss: 0.004754, tar: 0.000201 
[Epoch 380/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000215, l1: 0.000241, l2: 0.000194, l3: 0.000195, l4: 0.000332, l5: 0.000759, l6: 0.001574

[epoch: 381/1000, batch:    80/ 1052, ite: 99960] train loss: 0.004756, tar: 0.000201 
l0: 0.000230, l1: 0.000237, l2: 0.000258, l3: 0.000407, l4: 0.000891, l5: 0.002151, l6: 0.003511

[epoch: 381/1000, batch:   160/ 1052, ite: 99980] train loss: 0.004756, tar: 0.000201 
l0: 0.000222, l1: 0.000226, l2: 0.000257, l3: 0.000308, l4: 0.000570, l5: 0.001064, l6: 0.001845

[epoch: 381/1000, batch:   240/ 1052, ite: 100000] train loss: 0.004755, tar: 0.000201 
l0: 0.000088, l1: 0.000087, l2: 0.000117, l3: 0.000138, l4: 0.000394, l5: 0.000565, l6: 0.001531

[epoch: 381/1000, batch:   320/ 1052, ite: 100020] train loss: 0.004757, tar: 0.000201 
l0: 0.000222, l1: 0.000217, l2: 0.000251, l3: 0.000353, l4: 0.000636, l5: 0.001307, l6: 0.002495

[epoch: 381/1000, batch:   400/ 1052, ite: 100040] train loss: 0.004757, tar: 0.000200 
l0: 0.000212, l1: 0.000213, l2: 0.000239, l3: 0.000352, l4: 0.000750, l5: 0.001558, l6: 0.002383

[epoch: 381/1000, batch:   480/ 1052, ite: 100060] train loss: 0.004757, tar: 0.000200 
l0: 0.000182, l1: 0.000174, l2: 0.000200, l3: 0.000439, l4: 0.000834, l5: 0.001518, l6: 0.002193

[epoch: 381/1000, batch:   560/ 1052, ite: 100080] train loss: 0.004755, tar: 0.000200 
l0: 0.000117, l1: 0.000111, l2: 0.000154, l3: 0.000228, l4: 0.000390, l5: 0.000687, l6: 0.001540

[epoch: 381/1000, batch:   640/ 1052, ite: 100100] train loss: 0.004752, tar: 0.000200 
l0: 0.000081, l1: 0.000081, l2: 0.000135, l3: 0.000242, l4: 0.000663, l5: 0.000918, l6: 0.002132

[epoch: 381/1000, batch:   720/ 1052, ite: 100120] train loss: 0.004753, tar: 0.000200 
l0: 0.000100, l1: 0.000100, l2: 0.000138, l3: 0.000290, l4: 0.000542, l5: 0.001096, l6: 0.001900

[epoch: 381/1000, batch:   800/ 1052, ite: 100140] train loss: 0.004751, tar: 0.000200 
l0: 0.000133, l1: 0.000138, l2: 0.000172, l3: 0.000200, l4: 0.000424, l5: 0.000908, l6: 0.001421

[epoch: 381/1000, batch:   880/ 1052, ite: 100160] train loss: 0.004747, tar: 0.000199 
l0: 0.000171, l1: 0.000177, l2: 0.000252, l3: 0.000310, l4: 0.000452, l5: 0.000789, l6: 0.001428

[epoch: 381/1000, batch:   960/ 1052, ite: 100180] train loss: 0.004745, tar: 0.000199 
l0: 0.000096, l1: 0.000093, l2: 0.000152, l3: 0.000207, l4: 0.000530, l5: 0.001068, l6: 0.001953

[epoch: 381/1000, batch:  1040/ 1052, ite: 100200] train loss: 0.004744, tar: 0.000199 
[Epoch 381/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000073, l1: 0.000076, l2: 0.000083, l3: 0.000139, l4: 0.000252, l5: 0.000697, l6: 0.001228

[epoch: 382/1000, batch:    68/ 1052, ite: 100220] train loss: 0.004741, tar: 0.000199 
l0: 0.000105, l1: 0.000105, l2: 0.000161, l3: 0.000249, l4: 0.000589, l5: 0.001124, l6: 0.001712

[epoch: 382/1000, batch:   148/ 1052, ite: 100240] train loss: 0.004740, tar: 0.000199 
l0: 0.000170, l1: 0.000158, l2: 0.000287, l3: 0.000657, l4: 0.001041, l5: 0.002063, l6: 0.003376

[epoch: 382/1000, batch:   228/ 1052, ite: 100260] train loss: 0.004739, tar: 0.000198 
l0: 0.000180, l1: 0.000192, l2: 0.000211, l3: 0.000296, l4: 0.000472, l5: 0.001165, l6: 0.001805

[epoch: 382/1000, batch:   308/ 1052, ite: 100280] train loss: 0.004738, tar: 0.000198 
l0: 0.000377, l1: 0.000386, l2: 0.000424, l3: 0.000605, l4: 0.001215, l5: 0.002432, l6: 0.004997

[epoch: 382/1000, batch:   388/ 1052, ite: 100300] train loss: 0.004741, tar: 0.000198 
l0: 0.000140, l1: 0.000134, l2: 0.000228, l3: 0.000307, l4: 0.000423, l5: 0.001382, l6: 0.002276

[epoch: 382/1000, batch:   468/ 1052, ite: 100320] train loss: 0.004738, tar: 0.000198 
l0: 0.000215, l1: 0.000218, l2: 0.000277, l3: 0.000559, l4: 0.000895, l5: 0.001330, l6: 0.003473

[epoch: 382/1000, batch:   548/ 1052, ite: 100340] train loss: 0.004736, tar: 0.000198 
l0: 0.000148, l1: 0.000146, l2: 0.000215, l3: 0.000377, l4: 0.000838, l5: 0.001172, l6: 0.002713

[epoch: 382/1000, batch:   628/ 1052, ite: 100360] train loss: 0.004738, tar: 0.000198 
l0: 0.000120, l1: 0.000126, l2: 0.000167, l3: 0.000227, l4: 0.000495, l5: 0.001268, l6: 0.002264

[epoch: 382/1000, batch:   708/ 1052, ite: 100380] train loss: 0.004736, tar: 0.000198 
l0: 0.000154, l1: 0.000153, l2: 0.000151, l3: 0.000217, l4: 0.000487, l5: 0.001177, l6: 0.001990

[epoch: 382/1000, batch:   788/ 1052, ite: 100400] train loss: 0.004735, tar: 0.000197 
l0: 0.000143, l1: 0.000141, l2: 0.000186, l3: 0.000225, l4: 0.000535, l5: 0.001152, l6: 0.002625

[epoch: 382/1000, batch:   868/ 1052, ite: 100420] train loss: 0.004735, tar: 0.000197 
l0: 0.000177, l1: 0.000177, l2: 0.000203, l3: 0.000370, l4: 0.000726, l5: 0.001034, l6: 0.002753

[epoch: 382/1000, batch:   948/ 1052, ite: 100440] train loss: 0.004734, tar: 0.000197 
l0: 0.000250, l1: 0.000252, l2: 0.000326, l3: 0.000560, l4: 0.001286, l5: 0.002257, l6: 0.003899

[epoch: 382/1000, batch:  1028/ 1052, ite: 100460] train loss: 0.004734, tar: 0.000197 
[Epoch 382/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000177, l1: 0.000180, l2: 0.000191, l3: 0.000266, l4: 0.000514, l5: 0.001082, l6: 0.002208

[epoch: 383/1000, batch:    56/ 1052, ite: 100480] train loss: 0.004732, tar: 0.000197 
l0: 0.000165, l1: 0.000172, l2: 0.000194, l3: 0.000279, l4: 0.000550, l5: 0.001373, l6: 0.001533

[epoch: 383/1000, batch:   136/ 1052, ite: 100500] train loss: 0.004731, tar: 0.000197 
l0: 0.000164, l1: 0.000161, l2: 0.000224, l3: 0.000395, l4: 0.000825, l5: 0.001925, l6: 0.002544

[epoch: 383/1000, batch:   216/ 1052, ite: 100520] train loss: 0.004731, tar: 0.000196 
l0: 0.000149, l1: 0.000145, l2: 0.000228, l3: 0.000357, l4: 0.000433, l5: 0.001248, l6: 0.002005

[epoch: 383/1000, batch:   296/ 1052, ite: 100540] train loss: 0.004730, tar: 0.000196 
l0: 0.000135, l1: 0.000143, l2: 0.000154, l3: 0.000174, l4: 0.000405, l5: 0.001155, l6: 0.001406

[epoch: 383/1000, batch:   376/ 1052, ite: 100560] train loss: 0.004728, tar: 0.000196 
l0: 0.000138, l1: 0.000141, l2: 0.000172, l3: 0.000242, l4: 0.000510, l5: 0.000954, l6: 0.001770

[epoch: 383/1000, batch:   456/ 1052, ite: 100580] train loss: 0.004727, tar: 0.000196 
l0: 0.000147, l1: 0.000150, l2: 0.000213, l3: 0.000344, l4: 0.000694, l5: 0.001571, l6: 0.002855

[epoch: 383/1000, batch:   536/ 1052, ite: 100600] train loss: 0.004725, tar: 0.000196 
l0: 0.000109, l1: 0.000118, l2: 0.000152, l3: 0.000251, l4: 0.000536, l5: 0.001127, l6: 0.002088

[epoch: 383/1000, batch:   616/ 1052, ite: 100620] train loss: 0.004723, tar: 0.000196 
l0: 0.000121, l1: 0.000122, l2: 0.000168, l3: 0.000285, l4: 0.000638, l5: 0.001300, l6: 0.002437

[epoch: 383/1000, batch:   696/ 1052, ite: 100640] train loss: 0.004724, tar: 0.000196 
l0: 0.000176, l1: 0.000180, l2: 0.000163, l3: 0.000248, l4: 0.000570, l5: 0.000855, l6: 0.001939

[epoch: 383/1000, batch:   776/ 1052, ite: 100660] train loss: 0.004723, tar: 0.000195 
l0: 0.000449, l1: 0.000478, l2: 0.000396, l3: 0.000479, l4: 0.000933, l5: 0.002709, l6: 0.003931

[epoch: 383/1000, batch:   856/ 1052, ite: 100680] train loss: 0.004723, tar: 0.000195 
l0: 0.000124, l1: 0.000125, l2: 0.000140, l3: 0.000218, l4: 0.000214, l5: 0.000526, l6: 0.001062

[epoch: 383/1000, batch:   936/ 1052, ite: 100700] train loss: 0.004724, tar: 0.000195 
l0: 0.000185, l1: 0.000185, l2: 0.000186, l3: 0.000264, l4: 0.000477, l5: 0.000824, l6: 0.001839

[epoch: 383/1000, batch:  1016/ 1052, ite: 100720] train loss: 0.004724, tar: 0.000195 
[Epoch 383/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000165, l1: 0.000170, l2: 0.000224, l3: 0.000423, l4: 0.000708, l5: 0.000948, l6: 0.001692

[epoch: 384/1000, batch:    44/ 1052, ite: 100740] train loss: 0.004723, tar: 0.000195 
l0: 0.000128, l1: 0.000132, l2: 0.000150, l3: 0.000257, l4: 0.000392, l5: 0.000677, l6: 0.001658

[epoch: 384/1000, batch:   124/ 1052, ite: 100760] train loss: 0.004722, tar: 0.000195 
l0: 0.000106, l1: 0.000113, l2: 0.000120, l3: 0.000178, l4: 0.000307, l5: 0.000879, l6: 0.001918

[epoch: 384/1000, batch:   204/ 1052, ite: 100780] train loss: 0.004722, tar: 0.000195 
l0: 0.000137, l1: 0.000144, l2: 0.000176, l3: 0.000271, l4: 0.000484, l5: 0.000890, l6: 0.002036

[epoch: 384/1000, batch:   284/ 1052, ite: 100800] train loss: 0.004722, tar: 0.000195 
l0: 0.000243, l1: 0.000249, l2: 0.000302, l3: 0.000360, l4: 0.000747, l5: 0.001382, l6: 0.002558

[epoch: 384/1000, batch:   364/ 1052, ite: 100820] train loss: 0.004720, tar: 0.000195 
l0: 0.000068, l1: 0.000070, l2: 0.000076, l3: 0.000115, l4: 0.000373, l5: 0.000617, l6: 0.001184

[epoch: 384/1000, batch:   444/ 1052, ite: 100840] train loss: 0.004719, tar: 0.000194 
l0: 0.000183, l1: 0.000181, l2: 0.000207, l3: 0.000302, l4: 0.000496, l5: 0.001200, l6: 0.001997

[epoch: 384/1000, batch:   524/ 1052, ite: 100860] train loss: 0.004720, tar: 0.000194 
l0: 0.000099, l1: 0.000099, l2: 0.000162, l3: 0.000250, l4: 0.000600, l5: 0.001362, l6: 0.001579

[epoch: 384/1000, batch:   604/ 1052, ite: 100880] train loss: 0.004719, tar: 0.000194 
l0: 0.000072, l1: 0.000068, l2: 0.000142, l3: 0.000241, l4: 0.000343, l5: 0.000899, l6: 0.001071

[epoch: 384/1000, batch:   684/ 1052, ite: 100900] train loss: 0.004717, tar: 0.000194 
l0: 0.000341, l1: 0.000333, l2: 0.000453, l3: 0.000887, l4: 0.001692, l5: 0.002495, l6: 0.003316

[epoch: 384/1000, batch:   764/ 1052, ite: 100920] train loss: 0.004716, tar: 0.000194 
l0: 0.000081, l1: 0.000081, l2: 0.000114, l3: 0.000217, l4: 0.000346, l5: 0.000859, l6: 0.000989

[epoch: 384/1000, batch:   844/ 1052, ite: 100940] train loss: 0.004713, tar: 0.000194 
l0: 0.000239, l1: 0.000239, l2: 0.000294, l3: 0.000586, l4: 0.000839, l5: 0.001436, l6: 0.003101

[epoch: 384/1000, batch:   924/ 1052, ite: 100960] train loss: 0.004714, tar: 0.000194 
l0: 0.000142, l1: 0.000152, l2: 0.000099, l3: 0.000148, l4: 0.000362, l5: 0.000725, l6: 0.001067

[epoch: 384/1000, batch:  1004/ 1052, ite: 100980] train loss: 0.004713, tar: 0.000193 
[Epoch 384/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000041, l1: 0.000042, l2: 0.000062, l3: 0.000152, l4: 0.000364, l5: 0.000595, l6: 0.001023

[epoch: 385/1000, batch:    32/ 1052, ite: 101000] train loss: 0.004713, tar: 0.000193 
l0: 0.000132, l1: 0.000128, l2: 0.000189, l3: 0.000268, l4: 0.000522, l5: 0.000993, l6: 0.001454

[epoch: 385/1000, batch:   112/ 1052, ite: 101020] train loss: 0.004714, tar: 0.000193 
l0: 0.000052, l1: 0.000047, l2: 0.000087, l3: 0.000185, l4: 0.000320, l5: 0.000510, l6: 0.001088

[epoch: 385/1000, batch:   192/ 1052, ite: 101040] train loss: 0.004711, tar: 0.000193 
l0: 0.000094, l1: 0.000090, l2: 0.000138, l3: 0.000260, l4: 0.000490, l5: 0.000726, l6: 0.001647

[epoch: 385/1000, batch:   272/ 1052, ite: 101060] train loss: 0.004710, tar: 0.000193 
l0: 0.000155, l1: 0.000158, l2: 0.000187, l3: 0.000264, l4: 0.000429, l5: 0.000778, l6: 0.002763

[epoch: 385/1000, batch:   352/ 1052, ite: 101080] train loss: 0.004711, tar: 0.000193 
l0: 0.000206, l1: 0.000205, l2: 0.000221, l3: 0.000316, l4: 0.000371, l5: 0.001105, l6: 0.001846

[epoch: 385/1000, batch:   432/ 1052, ite: 101100] train loss: 0.004712, tar: 0.000193 
l0: 0.000279, l1: 0.000277, l2: 0.000299, l3: 0.000432, l4: 0.000709, l5: 0.001193, l6: 0.003349

[epoch: 385/1000, batch:   512/ 1052, ite: 101120] train loss: 0.004713, tar: 0.000193 
l0: 0.000185, l1: 0.000192, l2: 0.000254, l3: 0.000331, l4: 0.000837, l5: 0.002006, l6: 0.002666

[epoch: 385/1000, batch:   592/ 1052, ite: 101140] train loss: 0.004712, tar: 0.000193 
l0: 0.000127, l1: 0.000133, l2: 0.000122, l3: 0.000165, l4: 0.000267, l5: 0.000967, l6: 0.001307

[epoch: 385/1000, batch:   672/ 1052, ite: 101160] train loss: 0.004710, tar: 0.000192 
l0: 0.000126, l1: 0.000130, l2: 0.000175, l3: 0.000262, l4: 0.000459, l5: 0.000908, l6: 0.001501

[epoch: 385/1000, batch:   752/ 1052, ite: 101180] train loss: 0.004709, tar: 0.000192 
l0: 0.000090, l1: 0.000091, l2: 0.000115, l3: 0.000186, l4: 0.000371, l5: 0.000619, l6: 0.001024

[epoch: 385/1000, batch:   832/ 1052, ite: 101200] train loss: 0.004708, tar: 0.000192 
l0: 0.000160, l1: 0.000163, l2: 0.000159, l3: 0.000243, l4: 0.000344, l5: 0.000884, l6: 0.002069

[epoch: 385/1000, batch:   912/ 1052, ite: 101220] train loss: 0.004707, tar: 0.000192 
l0: 0.000106, l1: 0.000109, l2: 0.000111, l3: 0.000177, l4: 0.000320, l5: 0.000843, l6: 0.001545

[epoch: 385/1000, batch:   992/ 1052, ite: 101240] train loss: 0.004705, tar: 0.000192 
[Epoch 385/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000115, l1: 0.000114, l2: 0.000121, l3: 0.000280, l4: 0.000467, l5: 0.000912, l6: 0.001665

[epoch: 386/1000, batch:    20/ 1052, ite: 101260] train loss: 0.004705, tar: 0.000192 
l0: 0.000092, l1: 0.000091, l2: 0.000138, l3: 0.000216, l4: 0.000624, l5: 0.001186, l6: 0.001663

[epoch: 386/1000, batch:   100/ 1052, ite: 101280] train loss: 0.004706, tar: 0.000192 
l0: 0.000154, l1: 0.000168, l2: 0.000204, l3: 0.000320, l4: 0.000481, l5: 0.001029, l6: 0.002490

[epoch: 386/1000, batch:   180/ 1052, ite: 101300] train loss: 0.004705, tar: 0.000192 
l0: 0.000236, l1: 0.000235, l2: 0.000269, l3: 0.000344, l4: 0.000788, l5: 0.001767, l6: 0.003727

[epoch: 386/1000, batch:   260/ 1052, ite: 101320] train loss: 0.004706, tar: 0.000191 
l0: 0.000131, l1: 0.000127, l2: 0.000189, l3: 0.000432, l4: 0.000790, l5: 0.001407, l6: 0.002005

[epoch: 386/1000, batch:   340/ 1052, ite: 101340] train loss: 0.004704, tar: 0.000191 
l0: 0.000158, l1: 0.000152, l2: 0.000202, l3: 0.000275, l4: 0.000285, l5: 0.000818, l6: 0.001682

[epoch: 386/1000, batch:   420/ 1052, ite: 101360] train loss: 0.004704, tar: 0.000191 
l0: 0.000130, l1: 0.000141, l2: 0.000153, l3: 0.000255, l4: 0.000550, l5: 0.000877, l6: 0.002191

[epoch: 386/1000, batch:   500/ 1052, ite: 101380] train loss: 0.004704, tar: 0.000191 
l0: 0.000278, l1: 0.000311, l2: 0.000286, l3: 0.000425, l4: 0.000869, l5: 0.001415, l6: 0.001737

[epoch: 386/1000, batch:   580/ 1052, ite: 101400] train loss: 0.004706, tar: 0.000191 
l0: 0.000146, l1: 0.000144, l2: 0.000169, l3: 0.000339, l4: 0.000479, l5: 0.000991, l6: 0.001515

[epoch: 386/1000, batch:   660/ 1052, ite: 101420] train loss: 0.004703, tar: 0.000191 
l0: 0.000111, l1: 0.000113, l2: 0.000153, l3: 0.000321, l4: 0.000681, l5: 0.001443, l6: 0.002347

[epoch: 386/1000, batch:   740/ 1052, ite: 101440] train loss: 0.004703, tar: 0.000191 
l0: 0.000184, l1: 0.000184, l2: 0.000223, l3: 0.000295, l4: 0.000551, l5: 0.000966, l6: 0.002589

[epoch: 386/1000, batch:   820/ 1052, ite: 101460] train loss: 0.004701, tar: 0.000191 
l0: 0.000208, l1: 0.000214, l2: 0.000194, l3: 0.000280, l4: 0.000597, l5: 0.001488, l6: 0.002116

[epoch: 386/1000, batch:   900/ 1052, ite: 101480] train loss: 0.004698, tar: 0.000191 
l0: 0.000183, l1: 0.000187, l2: 0.000203, l3: 0.000248, l4: 0.000495, l5: 0.001023, l6: 0.002213

[epoch: 386/1000, batch:   980/ 1052, ite: 101500] train loss: 0.004698, tar: 0.000190 
[Epoch 386/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000232, l1: 0.000229, l2: 0.000258, l3: 0.000403, l4: 0.000818, l5: 0.001702, l6: 0.003246

[epoch: 387/1000, batch:     8/ 1052, ite: 101520] train loss: 0.004697, tar: 0.000190 
l0: 0.000180, l1: 0.000180, l2: 0.000258, l3: 0.000330, l4: 0.000535, l5: 0.001336, l6: 0.001851

[epoch: 387/1000, batch:    88/ 1052, ite: 101540] train loss: 0.004697, tar: 0.000190 
l0: 0.000092, l1: 0.000090, l2: 0.000117, l3: 0.000167, l4: 0.000313, l5: 0.000627, l6: 0.000805

[epoch: 387/1000, batch:   168/ 1052, ite: 101560] train loss: 0.004697, tar: 0.000190 
l0: 0.000047, l1: 0.000049, l2: 0.000082, l3: 0.000139, l4: 0.000205, l5: 0.000562, l6: 0.000460

[epoch: 387/1000, batch:   248/ 1052, ite: 101580] train loss: 0.004694, tar: 0.000190 
l0: 0.000123, l1: 0.000127, l2: 0.000135, l3: 0.000166, l4: 0.000240, l5: 0.000658, l6: 0.001560

[epoch: 387/1000, batch:   328/ 1052, ite: 101600] train loss: 0.004694, tar: 0.000190 
l0: 0.000228, l1: 0.000244, l2: 0.000247, l3: 0.000288, l4: 0.000625, l5: 0.001242, l6: 0.001501

[epoch: 387/1000, batch:   408/ 1052, ite: 101620] train loss: 0.004695, tar: 0.000190 
l0: 0.000132, l1: 0.000136, l2: 0.000169, l3: 0.000255, l4: 0.000422, l5: 0.000777, l6: 0.002662

[epoch: 387/1000, batch:   488/ 1052, ite: 101640] train loss: 0.004693, tar: 0.000190 
l0: 0.000139, l1: 0.000140, l2: 0.000152, l3: 0.000193, l4: 0.000471, l5: 0.001166, l6: 0.001977

[epoch: 387/1000, batch:   568/ 1052, ite: 101660] train loss: 0.004693, tar: 0.000190 
l0: 0.000146, l1: 0.000152, l2: 0.000204, l3: 0.000410, l4: 0.001037, l5: 0.001891, l6: 0.002835

[epoch: 387/1000, batch:   648/ 1052, ite: 101680] train loss: 0.004693, tar: 0.000190 
l0: 0.000109, l1: 0.000110, l2: 0.000117, l3: 0.000156, l4: 0.000384, l5: 0.000579, l6: 0.001234

[epoch: 387/1000, batch:   728/ 1052, ite: 101700] train loss: 0.004690, tar: 0.000189 
l0: 0.000104, l1: 0.000106, l2: 0.000116, l3: 0.000173, l4: 0.000406, l5: 0.000992, l6: 0.001902

[epoch: 387/1000, batch:   808/ 1052, ite: 101720] train loss: 0.004688, tar: 0.000189 
l0: 0.000260, l1: 0.000265, l2: 0.000345, l3: 0.000562, l4: 0.000985, l5: 0.002097, l6: 0.002485

[epoch: 387/1000, batch:   888/ 1052, ite: 101740] train loss: 0.004688, tar: 0.000189 
l0: 0.000289, l1: 0.000301, l2: 0.000350, l3: 0.000583, l4: 0.000992, l5: 0.001680, l6: 0.002345

[epoch: 387/1000, batch:   968/ 1052, ite: 101760] train loss: 0.004687, tar: 0.000189 
l0: 0.000083, l1: 0.000079, l2: 0.000176, l3: 0.000467, l4: 0.000874, l5: 0.001631, l6: 0.003053

[epoch: 387/1000, batch:  1048/ 1052, ite: 101780] train loss: 0.004685, tar: 0.000189 
[Epoch 387/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000148, l1: 0.000148, l2: 0.000198, l3: 0.000383, l4: 0.000617, l5: 0.000849, l6: 0.002117

[epoch: 388/1000, batch:    76/ 1052, ite: 101800] train loss: 0.004684, tar: 0.000189 
l0: 0.000213, l1: 0.000208, l2: 0.000233, l3: 0.000329, l4: 0.000715, l5: 0.001372, l6: 0.002246

[epoch: 388/1000, batch:   156/ 1052, ite: 101820] train loss: 0.004684, tar: 0.000189 
l0: 0.000197, l1: 0.000201, l2: 0.000240, l3: 0.000426, l4: 0.000724, l5: 0.001729, l6: 0.002982

[epoch: 388/1000, batch:   236/ 1052, ite: 101840] train loss: 0.004686, tar: 0.000189 
l0: 0.000051, l1: 0.000052, l2: 0.000083, l3: 0.000120, l4: 0.000292, l5: 0.000768, l6: 0.001274

[epoch: 388/1000, batch:   316/ 1052, ite: 101860] train loss: 0.004685, tar: 0.000188 
l0: 0.000069, l1: 0.000073, l2: 0.000075, l3: 0.000077, l4: 0.000215, l5: 0.000664, l6: 0.001217

[epoch: 388/1000, batch:   396/ 1052, ite: 101880] train loss: 0.004683, tar: 0.000188 
l0: 0.000083, l1: 0.000081, l2: 0.000112, l3: 0.000194, l4: 0.000390, l5: 0.000717, l6: 0.001425

[epoch: 388/1000, batch:   476/ 1052, ite: 101900] train loss: 0.004681, tar: 0.000188 
l0: 0.000271, l1: 0.000278, l2: 0.000313, l3: 0.000411, l4: 0.000843, l5: 0.001584, l6: 0.002316

[epoch: 388/1000, batch:   556/ 1052, ite: 101920] train loss: 0.004681, tar: 0.000188 
l0: 0.000031, l1: 0.000031, l2: 0.000074, l3: 0.000155, l4: 0.000363, l5: 0.000985, l6: 0.001420

[epoch: 388/1000, batch:   636/ 1052, ite: 101940] train loss: 0.004680, tar: 0.000188 
l0: 0.000144, l1: 0.000144, l2: 0.000178, l3: 0.000221, l4: 0.000373, l5: 0.000859, l6: 0.002137

[epoch: 388/1000, batch:   716/ 1052, ite: 101960] train loss: 0.004679, tar: 0.000188 
l0: 0.000211, l1: 0.000208, l2: 0.000314, l3: 0.000571, l4: 0.001348, l5: 0.002029, l6: 0.003240

[epoch: 388/1000, batch:   796/ 1052, ite: 101980] train loss: 0.004679, tar: 0.000188 
l0: 0.000136, l1: 0.000129, l2: 0.000220, l3: 0.000307, l4: 0.000529, l5: 0.001227, l6: 0.001697

[epoch: 388/1000, batch:   876/ 1052, ite: 102000] train loss: 0.004678, tar: 0.000188 
l0: 0.000098, l1: 0.000097, l2: 0.000122, l3: 0.000180, l4: 0.000307, l5: 0.000685, l6: 0.001372

[epoch: 388/1000, batch:   956/ 1052, ite: 102020] train loss: 0.004676, tar: 0.000187 
l0: 0.000221, l1: 0.000223, l2: 0.000241, l3: 0.000359, l4: 0.000593, l5: 0.000853, l6: 0.002803

[epoch: 388/1000, batch:  1036/ 1052, ite: 102040] train loss: 0.004676, tar: 0.000187 
[Epoch 388/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000175, l1: 0.000175, l2: 0.000208, l3: 0.000260, l4: 0.000543, l5: 0.001126, l6: 0.002534

[epoch: 389/1000, batch:    64/ 1052, ite: 102060] train loss: 0.004675, tar: 0.000187 
l0: 0.000097, l1: 0.000099, l2: 0.000140, l3: 0.000218, l4: 0.000316, l5: 0.001071, l6: 0.002132

[epoch: 389/1000, batch:   144/ 1052, ite: 102080] train loss: 0.004674, tar: 0.000187 
l0: 0.000109, l1: 0.000108, l2: 0.000135, l3: 0.000180, l4: 0.000264, l5: 0.001011, l6: 0.001140

[epoch: 389/1000, batch:   224/ 1052, ite: 102100] train loss: 0.004673, tar: 0.000187 
l0: 0.000065, l1: 0.000066, l2: 0.000089, l3: 0.000160, l4: 0.000564, l5: 0.001064, l6: 0.001439

[epoch: 389/1000, batch:   304/ 1052, ite: 102120] train loss: 0.004670, tar: 0.000187 
l0: 0.000316, l1: 0.000301, l2: 0.000361, l3: 0.000480, l4: 0.000749, l5: 0.001289, l6: 0.003725

[epoch: 389/1000, batch:   384/ 1052, ite: 102140] train loss: 0.004671, tar: 0.000187 
l0: 0.000291, l1: 0.000291, l2: 0.000323, l3: 0.000424, l4: 0.000967, l5: 0.002347, l6: 0.004372

[epoch: 389/1000, batch:   464/ 1052, ite: 102160] train loss: 0.004672, tar: 0.000187 
l0: 0.000143, l1: 0.000144, l2: 0.000196, l3: 0.000308, l4: 0.000624, l5: 0.001159, l6: 0.001472

[epoch: 389/1000, batch:   544/ 1052, ite: 102180] train loss: 0.004672, tar: 0.000187 
l0: 0.000184, l1: 0.000189, l2: 0.000199, l3: 0.000254, l4: 0.000400, l5: 0.000929, l6: 0.001644

[epoch: 389/1000, batch:   624/ 1052, ite: 102200] train loss: 0.004671, tar: 0.000187 
l0: 0.000134, l1: 0.000130, l2: 0.000197, l3: 0.000324, l4: 0.000562, l5: 0.001807, l6: 0.002298

[epoch: 389/1000, batch:   704/ 1052, ite: 102220] train loss: 0.004670, tar: 0.000186 
l0: 0.000207, l1: 0.000202, l2: 0.000293, l3: 0.000532, l4: 0.001109, l5: 0.001741, l6: 0.003243

[epoch: 389/1000, batch:   784/ 1052, ite: 102240] train loss: 0.004670, tar: 0.000186 
l0: 0.000093, l1: 0.000097, l2: 0.000092, l3: 0.000155, l4: 0.000259, l5: 0.000716, l6: 0.001248

[epoch: 389/1000, batch:   864/ 1052, ite: 102260] train loss: 0.004670, tar: 0.000186 
l0: 0.000415, l1: 0.000413, l2: 0.000482, l3: 0.000592, l4: 0.000810, l5: 0.001439, l6: 0.002506

[epoch: 389/1000, batch:   944/ 1052, ite: 102280] train loss: 0.004671, tar: 0.000186 
l0: 0.000204, l1: 0.000203, l2: 0.000229, l3: 0.000362, l4: 0.000817, l5: 0.001383, l6: 0.002327

[epoch: 389/1000, batch:  1024/ 1052, ite: 102300] train loss: 0.004671, tar: 0.000186 
[Epoch 389/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000155, l1: 0.000157, l2: 0.000169, l3: 0.000232, l4: 0.000373, l5: 0.000622, l6: 0.001854

[epoch: 390/1000, batch:    52/ 1052, ite: 102320] train loss: 0.004669, tar: 0.000186 
l0: 0.000185, l1: 0.000181, l2: 0.000277, l3: 0.000404, l4: 0.001163, l5: 0.002088, l6: 0.002595

[epoch: 390/1000, batch:   132/ 1052, ite: 102340] train loss: 0.004668, tar: 0.000186 
l0: 0.000323, l1: 0.000317, l2: 0.000380, l3: 0.000412, l4: 0.000690, l5: 0.001573, l6: 0.003085

[epoch: 390/1000, batch:   212/ 1052, ite: 102360] train loss: 0.004670, tar: 0.000186 
l0: 0.000158, l1: 0.000162, l2: 0.000178, l3: 0.000244, l4: 0.000465, l5: 0.001494, l6: 0.002556

[epoch: 390/1000, batch:   292/ 1052, ite: 102380] train loss: 0.004669, tar: 0.000186 
l0: 0.000129, l1: 0.000123, l2: 0.000145, l3: 0.000242, l4: 0.000521, l5: 0.000937, l6: 0.001220

[epoch: 390/1000, batch:   372/ 1052, ite: 102400] train loss: 0.004669, tar: 0.000186 
l0: 0.000064, l1: 0.000070, l2: 0.000064, l3: 0.000077, l4: 0.000298, l5: 0.000736, l6: 0.000851

[epoch: 390/1000, batch:   452/ 1052, ite: 102420] train loss: 0.004668, tar: 0.000186 
l0: 0.000117, l1: 0.000117, l2: 0.000138, l3: 0.000232, l4: 0.000408, l5: 0.001033, l6: 0.001073

[epoch: 390/1000, batch:   532/ 1052, ite: 102440] train loss: 0.004667, tar: 0.000186 
l0: 0.000344, l1: 0.000347, l2: 0.000370, l3: 0.000462, l4: 0.000964, l5: 0.001590, l6: 0.004382

[epoch: 390/1000, batch:   612/ 1052, ite: 102460] train loss: 0.004668, tar: 0.000186 
l0: 0.000093, l1: 0.000089, l2: 0.000143, l3: 0.000192, l4: 0.000397, l5: 0.001184, l6: 0.001768

[epoch: 390/1000, batch:   692/ 1052, ite: 102480] train loss: 0.004668, tar: 0.000185 
l0: 0.000062, l1: 0.000064, l2: 0.000095, l3: 0.000195, l4: 0.000301, l5: 0.000917, l6: 0.001657

[epoch: 390/1000, batch:   772/ 1052, ite: 102500] train loss: 0.004666, tar: 0.000185 
l0: 0.000124, l1: 0.000123, l2: 0.000149, l3: 0.000287, l4: 0.000785, l5: 0.001035, l6: 0.002125

[epoch: 390/1000, batch:   852/ 1052, ite: 102520] train loss: 0.004665, tar: 0.000185 
l0: 0.000155, l1: 0.000150, l2: 0.000213, l3: 0.000331, l4: 0.000739, l5: 0.001765, l6: 0.003295

[epoch: 390/1000, batch:   932/ 1052, ite: 102540] train loss: 0.004666, tar: 0.000185 
l0: 0.000130, l1: 0.000133, l2: 0.000181, l3: 0.000330, l4: 0.000454, l5: 0.001157, l6: 0.001758

[epoch: 390/1000, batch:  1012/ 1052, ite: 102560] train loss: 0.004664, tar: 0.000185 
[Epoch 390/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000145, l1: 0.000144, l2: 0.000177, l3: 0.000247, l4: 0.000411, l5: 0.000658, l6: 0.001496

[epoch: 391/1000, batch:    40/ 1052, ite: 102580] train loss: 0.004664, tar: 0.000185 
l0: 0.000189, l1: 0.000192, l2: 0.000189, l3: 0.000328, l4: 0.000459, l5: 0.001025, l6: 0.001482

[epoch: 391/1000, batch:   120/ 1052, ite: 102600] train loss: 0.004664, tar: 0.000185 
l0: 0.000152, l1: 0.000157, l2: 0.000186, l3: 0.000328, l4: 0.000645, l5: 0.001225, l6: 0.001818

[epoch: 391/1000, batch:   200/ 1052, ite: 102620] train loss: 0.004664, tar: 0.000185 
l0: 0.000193, l1: 0.000198, l2: 0.000238, l3: 0.000363, l4: 0.000636, l5: 0.001399, l6: 0.002598

[epoch: 391/1000, batch:   280/ 1052, ite: 102640] train loss: 0.004665, tar: 0.000185 
l0: 0.000138, l1: 0.000136, l2: 0.000206, l3: 0.000251, l4: 0.000420, l5: 0.000584, l6: 0.001496

[epoch: 391/1000, batch:   360/ 1052, ite: 102660] train loss: 0.004664, tar: 0.000185 
l0: 0.000261, l1: 0.000268, l2: 0.000292, l3: 0.000433, l4: 0.000717, l5: 0.002080, l6: 0.002997

[epoch: 391/1000, batch:   440/ 1052, ite: 102680] train loss: 0.004663, tar: 0.000185 
l0: 0.000133, l1: 0.000135, l2: 0.000186, l3: 0.000323, l4: 0.000511, l5: 0.001673, l6: 0.003076

[epoch: 391/1000, batch:   520/ 1052, ite: 102700] train loss: 0.004662, tar: 0.000184 
l0: 0.000055, l1: 0.000059, l2: 0.000064, l3: 0.000104, l4: 0.000252, l5: 0.000657, l6: 0.001105

[epoch: 391/1000, batch:   600/ 1052, ite: 102720] train loss: 0.004660, tar: 0.000184 
l0: 0.000108, l1: 0.000110, l2: 0.000160, l3: 0.000254, l4: 0.000551, l5: 0.001032, l6: 0.002109

[epoch: 391/1000, batch:   680/ 1052, ite: 102740] train loss: 0.004659, tar: 0.000184 
l0: 0.000082, l1: 0.000079, l2: 0.000154, l3: 0.000239, l4: 0.000599, l5: 0.000824, l6: 0.001961

[epoch: 391/1000, batch:   760/ 1052, ite: 102760] train loss: 0.004657, tar: 0.000184 
l0: 0.000171, l1: 0.000176, l2: 0.000191, l3: 0.000336, l4: 0.000569, l5: 0.001144, l6: 0.001944

[epoch: 391/1000, batch:   840/ 1052, ite: 102780] train loss: 0.004659, tar: 0.000184 
l0: 0.000157, l1: 0.000159, l2: 0.000198, l3: 0.000378, l4: 0.000875, l5: 0.001698, l6: 0.002829

[epoch: 391/1000, batch:   920/ 1052, ite: 102800] train loss: 0.004658, tar: 0.000184 
l0: 0.000114, l1: 0.000113, l2: 0.000147, l3: 0.000269, l4: 0.000393, l5: 0.001042, l6: 0.001663

[epoch: 391/1000, batch:  1000/ 1052, ite: 102820] train loss: 0.004657, tar: 0.000184 
[Epoch 391/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000157, l1: 0.000157, l2: 0.000198, l3: 0.000281, l4: 0.000436, l5: 0.000907, l6: 0.001242

[epoch: 392/1000, batch:    28/ 1052, ite: 102840] train loss: 0.004655, tar: 0.000184 
l0: 0.000091, l1: 0.000090, l2: 0.000220, l3: 0.000418, l4: 0.000608, l5: 0.001424, l6: 0.001781

[epoch: 392/1000, batch:   108/ 1052, ite: 102860] train loss: 0.004654, tar: 0.000184 
l0: 0.000171, l1: 0.000171, l2: 0.000213, l3: 0.000271, l4: 0.000556, l5: 0.001174, l6: 0.002389

[epoch: 392/1000, batch:   188/ 1052, ite: 102880] train loss: 0.004653, tar: 0.000183 
l0: 0.000162, l1: 0.000159, l2: 0.000165, l3: 0.000203, l4: 0.000355, l5: 0.000848, l6: 0.001154

[epoch: 392/1000, batch:   268/ 1052, ite: 102900] train loss: 0.004654, tar: 0.000183 
l0: 0.000207, l1: 0.000209, l2: 0.000233, l3: 0.000400, l4: 0.000439, l5: 0.000838, l6: 0.001019

[epoch: 392/1000, batch:   348/ 1052, ite: 102920] train loss: 0.004652, tar: 0.000183 
l0: 0.000216, l1: 0.000207, l2: 0.000259, l3: 0.000330, l4: 0.000837, l5: 0.001818, l6: 0.002223

[epoch: 392/1000, batch:   428/ 1052, ite: 102940] train loss: 0.004651, tar: 0.000183 
l0: 0.000103, l1: 0.000103, l2: 0.000114, l3: 0.000230, l4: 0.000499, l5: 0.001037, l6: 0.001698

[epoch: 392/1000, batch:   508/ 1052, ite: 102960] train loss: 0.004651, tar: 0.000183 
l0: 0.000171, l1: 0.000171, l2: 0.000219, l3: 0.000353, l4: 0.000800, l5: 0.001578, l6: 0.002405

[epoch: 392/1000, batch:   588/ 1052, ite: 102980] train loss: 0.004651, tar: 0.000183 
l0: 0.000070, l1: 0.000068, l2: 0.000103, l3: 0.000191, l4: 0.000412, l5: 0.000737, l6: 0.001057

[epoch: 392/1000, batch:   668/ 1052, ite: 103000] train loss: 0.004651, tar: 0.000183 
l0: 0.000308, l1: 0.000338, l2: 0.000328, l3: 0.000321, l4: 0.000596, l5: 0.000919, l6: 0.001697

[epoch: 392/1000, batch:   748/ 1052, ite: 103020] train loss: 0.004652, tar: 0.000183 
l0: 0.000244, l1: 0.000254, l2: 0.000253, l3: 0.000348, l4: 0.000620, l5: 0.001712, l6: 0.001773

[epoch: 392/1000, batch:   828/ 1052, ite: 103040] train loss: 0.004655, tar: 0.000184 
l0: 0.000176, l1: 0.000182, l2: 0.000198, l3: 0.000281, l4: 0.000553, l5: 0.001325, l6: 0.002061

[epoch: 392/1000, batch:   908/ 1052, ite: 103060] train loss: 0.004657, tar: 0.000184 
l0: 0.000316, l1: 0.000336, l2: 0.000308, l3: 0.000349, l4: 0.000465, l5: 0.001043, l6: 0.002139

[epoch: 392/1000, batch:   988/ 1052, ite: 103080] train loss: 0.004659, tar: 0.000184 
[Epoch 392/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000282, l1: 0.000301, l2: 0.000326, l3: 0.000507, l4: 0.000741, l5: 0.001498, l6: 0.002235

[epoch: 393/1000, batch:    16/ 1052, ite: 103100] train loss: 0.004661, tar: 0.000185 
l0: 0.000205, l1: 0.000211, l2: 0.000197, l3: 0.000358, l4: 0.000655, l5: 0.000903, l6: 0.001582

[epoch: 393/1000, batch:    96/ 1052, ite: 103120] train loss: 0.004660, tar: 0.000185 
l0: 0.000502, l1: 0.000513, l2: 0.000541, l3: 0.000835, l4: 0.001137, l5: 0.002754, l6: 0.005242

[epoch: 393/1000, batch:   176/ 1052, ite: 103140] train loss: 0.004663, tar: 0.000185 
l0: 0.000317, l1: 0.000331, l2: 0.000340, l3: 0.000464, l4: 0.000935, l5: 0.001392, l6: 0.002277

[epoch: 393/1000, batch:   256/ 1052, ite: 103160] train loss: 0.004663, tar: 0.000185 
l0: 0.000433, l1: 0.000444, l2: 0.000394, l3: 0.000468, l4: 0.000649, l5: 0.001244, l6: 0.002573

[epoch: 393/1000, batch:   336/ 1052, ite: 103180] train loss: 0.004663, tar: 0.000185 
l0: 0.000221, l1: 0.000234, l2: 0.000312, l3: 0.000468, l4: 0.000916, l5: 0.001378, l6: 0.002274

[epoch: 393/1000, batch:   416/ 1052, ite: 103200] train loss: 0.004663, tar: 0.000185 
l0: 0.000091, l1: 0.000110, l2: 0.000124, l3: 0.000145, l4: 0.000338, l5: 0.001013, l6: 0.001394

[epoch: 393/1000, batch:   496/ 1052, ite: 103220] train loss: 0.004663, tar: 0.000185 
l0: 0.000363, l1: 0.000354, l2: 0.000428, l3: 0.000487, l4: 0.000720, l5: 0.001281, l6: 0.002664

[epoch: 393/1000, batch:   576/ 1052, ite: 103240] train loss: 0.004663, tar: 0.000185 
l0: 0.000144, l1: 0.000134, l2: 0.000197, l3: 0.000256, l4: 0.000499, l5: 0.000665, l6: 0.001384

[epoch: 393/1000, batch:   656/ 1052, ite: 103260] train loss: 0.004664, tar: 0.000185 
l0: 0.000223, l1: 0.000244, l2: 0.000287, l3: 0.000288, l4: 0.000507, l5: 0.000960, l6: 0.002255

[epoch: 393/1000, batch:   736/ 1052, ite: 103280] train loss: 0.004665, tar: 0.000185 
l0: 0.000597, l1: 0.000652, l2: 0.000614, l3: 0.000499, l4: 0.000658, l5: 0.001475, l6: 0.002379

[epoch: 393/1000, batch:   816/ 1052, ite: 103300] train loss: 0.004669, tar: 0.000186 
l0: 0.000306, l1: 0.000311, l2: 0.000349, l3: 0.000438, l4: 0.000499, l5: 0.001630, l6: 0.002503

[epoch: 393/1000, batch:   896/ 1052, ite: 103320] train loss: 0.004671, tar: 0.000186 
l0: 0.000359, l1: 0.000418, l2: 0.000467, l3: 0.000777, l4: 0.000707, l5: 0.001119, l6: 0.002329

[epoch: 393/1000, batch:   976/ 1052, ite: 103340] train loss: 0.004679, tar: 0.000187 
[Epoch 393/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000437, l1: 0.000449, l2: 0.000442, l3: 0.000676, l4: 0.000879, l5: 0.001851, l6: 0.002131

[epoch: 394/1000, batch:     4/ 1052, ite: 103360] train loss: 0.004684, tar: 0.000188 
l0: 0.000552, l1: 0.000554, l2: 0.000596, l3: 0.000707, l4: 0.001192, l5: 0.002053, l6: 0.003644

[epoch: 394/1000, batch:    84/ 1052, ite: 103380] train loss: 0.004687, tar: 0.000188 
l0: 0.000251, l1: 0.000261, l2: 0.000305, l3: 0.000355, l4: 0.000470, l5: 0.001372, l6: 0.001708

[epoch: 394/1000, batch:   164/ 1052, ite: 103400] train loss: 0.004687, tar: 0.000188 
l0: 0.000114, l1: 0.000114, l2: 0.000143, l3: 0.000202, l4: 0.000512, l5: 0.000966, l6: 0.001156

[epoch: 394/1000, batch:   244/ 1052, ite: 103420] train loss: 0.004690, tar: 0.000189 
l0: 0.000440, l1: 0.000422, l2: 0.000468, l3: 0.000660, l4: 0.001322, l5: 0.002085, l6: 0.002917

[epoch: 394/1000, batch:   324/ 1052, ite: 103440] train loss: 0.004694, tar: 0.000189 
l0: 0.000245, l1: 0.000230, l2: 0.000284, l3: 0.000348, l4: 0.000599, l5: 0.001291, l6: 0.003230

[epoch: 394/1000, batch:   404/ 1052, ite: 103460] train loss: 0.004695, tar: 0.000189 
l0: 0.000110, l1: 0.000116, l2: 0.000118, l3: 0.000153, l4: 0.000437, l5: 0.000821, l6: 0.000870

[epoch: 394/1000, batch:   484/ 1052, ite: 103480] train loss: 0.004698, tar: 0.000190 
l0: 0.000165, l1: 0.000175, l2: 0.000291, l3: 0.000270, l4: 0.000492, l5: 0.000590, l6: 0.000907

[epoch: 394/1000, batch:   564/ 1052, ite: 103500] train loss: 0.004698, tar: 0.000190 
l0: 0.000276, l1: 0.000258, l2: 0.000329, l3: 0.000456, l4: 0.000799, l5: 0.001728, l6: 0.003705

[epoch: 394/1000, batch:   644/ 1052, ite: 103520] train loss: 0.004699, tar: 0.000190 
l0: 0.000186, l1: 0.000198, l2: 0.000230, l3: 0.000321, l4: 0.000489, l5: 0.001062, l6: 0.001869

[epoch: 394/1000, batch:   724/ 1052, ite: 103540] train loss: 0.004700, tar: 0.000190 
l0: 0.000449, l1: 0.000444, l2: 0.000486, l3: 0.000750, l4: 0.001348, l5: 0.002979, l6: 0.005325

[epoch: 394/1000, batch:   804/ 1052, ite: 103560] train loss: 0.004702, tar: 0.000190 
l0: 0.000326, l1: 0.000329, l2: 0.000366, l3: 0.000529, l4: 0.000699, l5: 0.001218, l6: 0.002974

[epoch: 394/1000, batch:   884/ 1052, ite: 103580] train loss: 0.004702, tar: 0.000190 
l0: 0.000158, l1: 0.000153, l2: 0.000193, l3: 0.000183, l4: 0.000472, l5: 0.000930, l6: 0.000966

[epoch: 394/1000, batch:   964/ 1052, ite: 103600] train loss: 0.004704, tar: 0.000190 
l0: 0.000497, l1: 0.000492, l2: 0.000627, l3: 0.000564, l4: 0.000986, l5: 0.001970, l6: 0.004608

[epoch: 394/1000, batch:  1044/ 1052, ite: 103620] train loss: 0.004704, tar: 0.000190 
[Epoch 394/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000202, l1: 0.000195, l2: 0.000279, l3: 0.000463, l4: 0.000951, l5: 0.001690, l6: 0.002861

[epoch: 395/1000, batch:    72/ 1052, ite: 103640] train loss: 0.004704, tar: 0.000190 
l0: 0.000152, l1: 0.000154, l2: 0.000179, l3: 0.000277, l4: 0.000395, l5: 0.000708, l6: 0.001985

[epoch: 395/1000, batch:   152/ 1052, ite: 103660] train loss: 0.004703, tar: 0.000190 
l0: 0.000106, l1: 0.000100, l2: 0.000124, l3: 0.000169, l4: 0.000385, l5: 0.000655, l6: 0.001702

[epoch: 395/1000, batch:   232/ 1052, ite: 103680] train loss: 0.004702, tar: 0.000190 
l0: 0.000212, l1: 0.000211, l2: 0.000255, l3: 0.000355, l4: 0.000822, l5: 0.001192, l6: 0.002146

[epoch: 395/1000, batch:   312/ 1052, ite: 103700] train loss: 0.004704, tar: 0.000190 
l0: 0.000144, l1: 0.000142, l2: 0.000203, l3: 0.000280, l4: 0.000550, l5: 0.001138, l6: 0.001627

[epoch: 395/1000, batch:   392/ 1052, ite: 103720] train loss: 0.004705, tar: 0.000191 
l0: 0.000226, l1: 0.000232, l2: 0.000286, l3: 0.000345, l4: 0.000546, l5: 0.001235, l6: 0.002066

[epoch: 395/1000, batch:   472/ 1052, ite: 103740] train loss: 0.004705, tar: 0.000191 
l0: 0.000277, l1: 0.000282, l2: 0.000297, l3: 0.000474, l4: 0.000670, l5: 0.001291, l6: 0.003096

[epoch: 395/1000, batch:   552/ 1052, ite: 103760] train loss: 0.004707, tar: 0.000191 
l0: 0.000143, l1: 0.000147, l2: 0.000157, l3: 0.000260, l4: 0.000571, l5: 0.000872, l6: 0.001560

[epoch: 395/1000, batch:   632/ 1052, ite: 103780] train loss: 0.004706, tar: 0.000191 
l0: 0.000237, l1: 0.000239, l2: 0.000256, l3: 0.000372, l4: 0.000766, l5: 0.001554, l6: 0.002848

[epoch: 395/1000, batch:   712/ 1052, ite: 103800] train loss: 0.004706, tar: 0.000191 
l0: 0.000050, l1: 0.000045, l2: 0.000064, l3: 0.000103, l4: 0.000319, l5: 0.000518, l6: 0.000601

[epoch: 395/1000, batch:   792/ 1052, ite: 103820] train loss: 0.004707, tar: 0.000191 
l0: 0.000132, l1: 0.000139, l2: 0.000141, l3: 0.000232, l4: 0.000515, l5: 0.000822, l6: 0.001489

[epoch: 395/1000, batch:   872/ 1052, ite: 103840] train loss: 0.004708, tar: 0.000191 
l0: 0.000245, l1: 0.000251, l2: 0.000269, l3: 0.000370, l4: 0.000599, l5: 0.001361, l6: 0.001624

[epoch: 395/1000, batch:   952/ 1052, ite: 103860] train loss: 0.004709, tar: 0.000191 
l0: 0.000361, l1: 0.000363, l2: 0.000396, l3: 0.000618, l4: 0.000728, l5: 0.001357, l6: 0.002615

[epoch: 395/1000, batch:  1032/ 1052, ite: 103880] train loss: 0.004709, tar: 0.000191 
[Epoch 395/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000138, l1: 0.000138, l2: 0.000156, l3: 0.000249, l4: 0.000433, l5: 0.000971, l6: 0.001844

[epoch: 396/1000, batch:    60/ 1052, ite: 103900] train loss: 0.004708, tar: 0.000191 
l0: 0.000135, l1: 0.000138, l2: 0.000204, l3: 0.000258, l4: 0.000402, l5: 0.000865, l6: 0.002506

[epoch: 396/1000, batch:   140/ 1052, ite: 103920] train loss: 0.004707, tar: 0.000191 
l0: 0.000405, l1: 0.000398, l2: 0.000520, l3: 0.000770, l4: 0.001489, l5: 0.002351, l6: 0.003905

[epoch: 396/1000, batch:   220/ 1052, ite: 103940] train loss: 0.004707, tar: 0.000191 
l0: 0.000163, l1: 0.000160, l2: 0.000229, l3: 0.000345, l4: 0.001077, l5: 0.002577, l6: 0.003132

[epoch: 396/1000, batch:   300/ 1052, ite: 103960] train loss: 0.004709, tar: 0.000191 
l0: 0.000153, l1: 0.000155, l2: 0.000203, l3: 0.000336, l4: 0.000676, l5: 0.001015, l6: 0.001617

[epoch: 396/1000, batch:   380/ 1052, ite: 103980] train loss: 0.004708, tar: 0.000191 
l0: 0.000179, l1: 0.000170, l2: 0.000305, l3: 0.000584, l4: 0.000943, l5: 0.001683, l6: 0.003758

[epoch: 396/1000, batch:   460/ 1052, ite: 104000] train loss: 0.004708, tar: 0.000191 
l0: 0.000265, l1: 0.000261, l2: 0.000293, l3: 0.000416, l4: 0.000785, l5: 0.001966, l6: 0.002780

[epoch: 396/1000, batch:   540/ 1052, ite: 104020] train loss: 0.004709, tar: 0.000191 
l0: 0.000087, l1: 0.000093, l2: 0.000084, l3: 0.000164, l4: 0.000260, l5: 0.000860, l6: 0.001384

[epoch: 396/1000, batch:   620/ 1052, ite: 104040] train loss: 0.004710, tar: 0.000191 
l0: 0.000140, l1: 0.000141, l2: 0.000157, l3: 0.000195, l4: 0.000341, l5: 0.000888, l6: 0.001700

[epoch: 396/1000, batch:   700/ 1052, ite: 104060] train loss: 0.004709, tar: 0.000191 
l0: 0.000151, l1: 0.000148, l2: 0.000180, l3: 0.000265, l4: 0.000468, l5: 0.000738, l6: 0.001277

[epoch: 396/1000, batch:   780/ 1052, ite: 104080] train loss: 0.004708, tar: 0.000191 
l0: 0.000143, l1: 0.000141, l2: 0.000167, l3: 0.000254, l4: 0.000633, l5: 0.001198, l6: 0.001721

[epoch: 396/1000, batch:   860/ 1052, ite: 104100] train loss: 0.004708, tar: 0.000191 
l0: 0.000152, l1: 0.000163, l2: 0.000174, l3: 0.000238, l4: 0.000479, l5: 0.000841, l6: 0.002594

[epoch: 396/1000, batch:   940/ 1052, ite: 104120] train loss: 0.004707, tar: 0.000190 
l0: 0.000362, l1: 0.000369, l2: 0.000380, l3: 0.000556, l4: 0.001160, l5: 0.002165, l6: 0.004138

[epoch: 396/1000, batch:  1020/ 1052, ite: 104140] train loss: 0.004708, tar: 0.000190 
[Epoch 396/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000283, l1: 0.000280, l2: 0.000364, l3: 0.000520, l4: 0.000790, l5: 0.001696, l6: 0.002076

[epoch: 397/1000, batch:    48/ 1052, ite: 104160] train loss: 0.004707, tar: 0.000190 
l0: 0.000160, l1: 0.000167, l2: 0.000169, l3: 0.000241, l4: 0.000539, l5: 0.000700, l6: 0.002313

[epoch: 397/1000, batch:   128/ 1052, ite: 104180] train loss: 0.004708, tar: 0.000190 
l0: 0.000101, l1: 0.000123, l2: 0.000128, l3: 0.000153, l4: 0.000349, l5: 0.000407, l6: 0.000949

[epoch: 397/1000, batch:   208/ 1052, ite: 104200] train loss: 0.004707, tar: 0.000190 
l0: 0.000216, l1: 0.000230, l2: 0.000255, l3: 0.000413, l4: 0.000831, l5: 0.001758, l6: 0.001554

[epoch: 397/1000, batch:   288/ 1052, ite: 104220] train loss: 0.004705, tar: 0.000190 
l0: 0.000112, l1: 0.000112, l2: 0.000125, l3: 0.000168, l4: 0.000369, l5: 0.001081, l6: 0.001996

[epoch: 397/1000, batch:   368/ 1052, ite: 104240] train loss: 0.004705, tar: 0.000190 
l0: 0.000174, l1: 0.000175, l2: 0.000222, l3: 0.000294, l4: 0.000550, l5: 0.001214, l6: 0.002575

[epoch: 397/1000, batch:   448/ 1052, ite: 104260] train loss: 0.004705, tar: 0.000190 
l0: 0.000264, l1: 0.000267, l2: 0.000376, l3: 0.000516, l4: 0.001207, l5: 0.001920, l6: 0.003865

[epoch: 397/1000, batch:   528/ 1052, ite: 104280] train loss: 0.004705, tar: 0.000190 
l0: 0.000301, l1: 0.000296, l2: 0.000422, l3: 0.000518, l4: 0.000839, l5: 0.002122, l6: 0.003913

[epoch: 397/1000, batch:   608/ 1052, ite: 104300] train loss: 0.004707, tar: 0.000190 
l0: 0.000139, l1: 0.000134, l2: 0.000176, l3: 0.000292, l4: 0.000559, l5: 0.001335, l6: 0.001481

[epoch: 397/1000, batch:   688/ 1052, ite: 104320] train loss: 0.004706, tar: 0.000190 
l0: 0.000168, l1: 0.000175, l2: 0.000188, l3: 0.000242, l4: 0.000529, l5: 0.001024, l6: 0.001820

[epoch: 397/1000, batch:   768/ 1052, ite: 104340] train loss: 0.004704, tar: 0.000190 
l0: 0.000091, l1: 0.000093, l2: 0.000111, l3: 0.000247, l4: 0.000510, l5: 0.000768, l6: 0.000832

[epoch: 397/1000, batch:   848/ 1052, ite: 104360] train loss: 0.004704, tar: 0.000190 
l0: 0.000066, l1: 0.000065, l2: 0.000116, l3: 0.000182, l4: 0.000402, l5: 0.001089, l6: 0.001311

[epoch: 397/1000, batch:   928/ 1052, ite: 104380] train loss: 0.004704, tar: 0.000190 
l0: 0.000091, l1: 0.000091, l2: 0.000145, l3: 0.000244, l4: 0.000344, l5: 0.000607, l6: 0.001335

[epoch: 397/1000, batch:  1008/ 1052, ite: 104400] train loss: 0.004703, tar: 0.000190 
[Epoch 397/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000125, l1: 0.000134, l2: 0.000133, l3: 0.000229, l4: 0.000516, l5: 0.000890, l6: 0.002160

[epoch: 398/1000, batch:    36/ 1052, ite: 104420] train loss: 0.004703, tar: 0.000190 
l0: 0.000065, l1: 0.000063, l2: 0.000126, l3: 0.000213, l4: 0.000425, l5: 0.000560, l6: 0.001184

[epoch: 398/1000, batch:   116/ 1052, ite: 104440] train loss: 0.004703, tar: 0.000190 
l0: 0.000306, l1: 0.000304, l2: 0.000374, l3: 0.000565, l4: 0.000888, l5: 0.001811, l6: 0.002804

[epoch: 398/1000, batch:   196/ 1052, ite: 104460] train loss: 0.004704, tar: 0.000190 
l0: 0.000401, l1: 0.000414, l2: 0.000455, l3: 0.000682, l4: 0.001380, l5: 0.002799, l6: 0.004024

[epoch: 398/1000, batch:   276/ 1052, ite: 104480] train loss: 0.004705, tar: 0.000190 
l0: 0.000098, l1: 0.000094, l2: 0.000129, l3: 0.000217, l4: 0.000426, l5: 0.000672, l6: 0.001353

[epoch: 398/1000, batch:   356/ 1052, ite: 104500] train loss: 0.004704, tar: 0.000189 
l0: 0.000094, l1: 0.000097, l2: 0.000107, l3: 0.000168, l4: 0.000374, l5: 0.000614, l6: 0.001048

[epoch: 398/1000, batch:   436/ 1052, ite: 104520] train loss: 0.004704, tar: 0.000189 
l0: 0.000181, l1: 0.000175, l2: 0.000213, l3: 0.000353, l4: 0.000850, l5: 0.001154, l6: 0.002133

[epoch: 398/1000, batch:   516/ 1052, ite: 104540] train loss: 0.004704, tar: 0.000189 
l0: 0.000115, l1: 0.000115, l2: 0.000122, l3: 0.000189, l4: 0.000291, l5: 0.000889, l6: 0.001349

[epoch: 398/1000, batch:   596/ 1052, ite: 104560] train loss: 0.004702, tar: 0.000189 
l0: 0.000137, l1: 0.000144, l2: 0.000163, l3: 0.000204, l4: 0.000351, l5: 0.001099, l6: 0.001678

[epoch: 398/1000, batch:   676/ 1052, ite: 104580] train loss: 0.004703, tar: 0.000189 
l0: 0.000098, l1: 0.000101, l2: 0.000110, l3: 0.000145, l4: 0.000317, l5: 0.000757, l6: 0.001553

[epoch: 398/1000, batch:   756/ 1052, ite: 104600] train loss: 0.004702, tar: 0.000189 
l0: 0.000192, l1: 0.000190, l2: 0.000259, l3: 0.000369, l4: 0.000989, l5: 0.000782, l6: 0.002421

[epoch: 398/1000, batch:   836/ 1052, ite: 104620] train loss: 0.004701, tar: 0.000189 
l0: 0.000102, l1: 0.000105, l2: 0.000109, l3: 0.000169, l4: 0.000333, l5: 0.000754, l6: 0.001420

[epoch: 398/1000, batch:   916/ 1052, ite: 104640] train loss: 0.004700, tar: 0.000189 
l0: 0.000137, l1: 0.000137, l2: 0.000157, l3: 0.000212, l4: 0.000485, l5: 0.000820, l6: 0.001618

[epoch: 398/1000, batch:   996/ 1052, ite: 104660] train loss: 0.004700, tar: 0.000189 
[Epoch 398/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000124, l1: 0.000122, l2: 0.000150, l3: 0.000241, l4: 0.000441, l5: 0.000998, l6: 0.001984

[epoch: 399/1000, batch:    24/ 1052, ite: 104680] train loss: 0.004700, tar: 0.000189 
l0: 0.000045, l1: 0.000043, l2: 0.000067, l3: 0.000152, l4: 0.000279, l5: 0.000809, l6: 0.000890

[epoch: 399/1000, batch:   104/ 1052, ite: 104700] train loss: 0.004698, tar: 0.000189 
l0: 0.000308, l1: 0.000305, l2: 0.000399, l3: 0.000647, l4: 0.001036, l5: 0.001845, l6: 0.003050

[epoch: 399/1000, batch:   184/ 1052, ite: 104720] train loss: 0.004698, tar: 0.000189 
l0: 0.000190, l1: 0.000182, l2: 0.000243, l3: 0.000447, l4: 0.000793, l5: 0.001676, l6: 0.003411

[epoch: 399/1000, batch:   264/ 1052, ite: 104740] train loss: 0.004698, tar: 0.000189 
l0: 0.000102, l1: 0.000105, l2: 0.000137, l3: 0.000198, l4: 0.000443, l5: 0.000762, l6: 0.001437

[epoch: 399/1000, batch:   344/ 1052, ite: 104760] train loss: 0.004698, tar: 0.000188 
l0: 0.000202, l1: 0.000214, l2: 0.000213, l3: 0.000308, l4: 0.000759, l5: 0.002137, l6: 0.002433

[epoch: 399/1000, batch:   424/ 1052, ite: 104780] train loss: 0.004698, tar: 0.000188 
l0: 0.000326, l1: 0.000332, l2: 0.000416, l3: 0.000498, l4: 0.001220, l5: 0.001846, l6: 0.002999

[epoch: 399/1000, batch:   504/ 1052, ite: 104800] train loss: 0.004697, tar: 0.000188 
l0: 0.000149, l1: 0.000152, l2: 0.000191, l3: 0.000242, l4: 0.000580, l5: 0.001370, l6: 0.002935

[epoch: 399/1000, batch:   584/ 1052, ite: 104820] train loss: 0.004697, tar: 0.000188 
l0: 0.000121, l1: 0.000118, l2: 0.000164, l3: 0.000320, l4: 0.000635, l5: 0.001561, l6: 0.002072

[epoch: 399/1000, batch:   664/ 1052, ite: 104840] train loss: 0.004696, tar: 0.000188 
l0: 0.000187, l1: 0.000191, l2: 0.000201, l3: 0.000292, l4: 0.000398, l5: 0.000978, l6: 0.001673

[epoch: 399/1000, batch:   744/ 1052, ite: 104860] train loss: 0.004695, tar: 0.000188 
l0: 0.000131, l1: 0.000132, l2: 0.000179, l3: 0.000310, l4: 0.000618, l5: 0.001038, l6: 0.001989

[epoch: 399/1000, batch:   824/ 1052, ite: 104880] train loss: 0.004694, tar: 0.000188 
l0: 0.000173, l1: 0.000176, l2: 0.000211, l3: 0.000292, l4: 0.000492, l5: 0.000866, l6: 0.001198

[epoch: 399/1000, batch:   904/ 1052, ite: 104900] train loss: 0.004694, tar: 0.000188 
l0: 0.000127, l1: 0.000125, l2: 0.000184, l3: 0.000240, l4: 0.000420, l5: 0.001132, l6: 0.002076

[epoch: 399/1000, batch:   984/ 1052, ite: 104920] train loss: 0.004694, tar: 0.000188 
[Epoch 399/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000143, l1: 0.000137, l2: 0.000202, l3: 0.000324, l4: 0.000587, l5: 0.001333, l6: 0.001844

[epoch: 400/1000, batch:    12/ 1052, ite: 104940] train loss: 0.004694, tar: 0.000188 
l0: 0.000150, l1: 0.000156, l2: 0.000175, l3: 0.000249, l4: 0.000531, l5: 0.001123, l6: 0.002591

[epoch: 400/1000, batch:    92/ 1052, ite: 104960] train loss: 0.004695, tar: 0.000188 
l0: 0.000024, l1: 0.000022, l2: 0.000054, l3: 0.000085, l4: 0.000132, l5: 0.000273, l6: 0.000796

[epoch: 400/1000, batch:   172/ 1052, ite: 104980] train loss: 0.004694, tar: 0.000188 
l0: 0.000165, l1: 0.000170, l2: 0.000230, l3: 0.000273, l4: 0.000524, l5: 0.000975, l6: 0.002813

[epoch: 400/1000, batch:   252/ 1052, ite: 105000] train loss: 0.004693, tar: 0.000188 
l0: 0.000078, l1: 0.000076, l2: 0.000117, l3: 0.000148, l4: 0.000315, l5: 0.000662, l6: 0.001147

[epoch: 400/1000, batch:   332/ 1052, ite: 105020] train loss: 0.004692, tar: 0.000188 
l0: 0.000102, l1: 0.000096, l2: 0.000235, l3: 0.000353, l4: 0.000635, l5: 0.001293, l6: 0.001425

[epoch: 400/1000, batch:   412/ 1052, ite: 105040] train loss: 0.004693, tar: 0.000187 
l0: 0.000089, l1: 0.000090, l2: 0.000120, l3: 0.000218, l4: 0.000710, l5: 0.001042, l6: 0.002250

[epoch: 400/1000, batch:   492/ 1052, ite: 105060] train loss: 0.004692, tar: 0.000187 
l0: 0.000116, l1: 0.000114, l2: 0.000151, l3: 0.000210, l4: 0.000352, l5: 0.000626, l6: 0.001433

[epoch: 400/1000, batch:   572/ 1052, ite: 105080] train loss: 0.004690, tar: 0.000187 
l0: 0.000140, l1: 0.000136, l2: 0.000191, l3: 0.000256, l4: 0.000496, l5: 0.000930, l6: 0.002099

[epoch: 400/1000, batch:   652/ 1052, ite: 105100] train loss: 0.004691, tar: 0.000187 
l0: 0.000202, l1: 0.000196, l2: 0.000235, l3: 0.000368, l4: 0.000578, l5: 0.001553, l6: 0.001830

[epoch: 400/1000, batch:   732/ 1052, ite: 105120] train loss: 0.004690, tar: 0.000187 
l0: 0.000086, l1: 0.000083, l2: 0.000120, l3: 0.000199, l4: 0.000263, l5: 0.000961, l6: 0.001021

[epoch: 400/1000, batch:   812/ 1052, ite: 105140] train loss: 0.004689, tar: 0.000187 
l0: 0.000099, l1: 0.000106, l2: 0.000122, l3: 0.000184, l4: 0.000453, l5: 0.000670, l6: 0.001733

[epoch: 400/1000, batch:   892/ 1052, ite: 105160] train loss: 0.004688, tar: 0.000187 
l0: 0.000117, l1: 0.000125, l2: 0.000141, l3: 0.000163, l4: 0.000485, l5: 0.000926, l6: 0.002081

[epoch: 400/1000, batch:   972/ 1052, ite: 105180] train loss: 0.004688, tar: 0.000187 
l0: 0.000141, l1: 0.000140, l2: 0.000161, l3: 0.000204, l4: 0.000461, l5: 0.001248, l6: 0.001569

[epoch: 400/1000, batch:  1052/ 1052, ite: 105200] train loss: 0.004689, tar: 0.000187 
[Epoch 400/1000] Test loss: 0.011, Test target loss: 0.002
l0: 0.000074, l1: 0.000077, l2: 0.000090, l3: 0.000116, l4: 0.000412, l5: 0.000792, l6: 0.001212

[epoch: 401/1000, batch:    80/ 1052, ite: 105220] train loss: 0.004116, tar: 0.000138 
l0: 0.000055, l1: 0.000056, l2: 0.000099, l3: 0.000172, l4: 0.000270, l5: 0.000688, l6: 0.001439

[epoch: 401/1000, batch:   160/ 1052, ite: 105240] train loss: 0.004111, tar: 0.000141 
l0: 0.000140, l1: 0.000146, l2: 0.000164, l3: 0.000330, l4: 0.000514, l5: 0.001144, l6: 0.001947

[epoch: 401/1000, batch:   240/ 1052, ite: 105260] train loss: 0.004097, tar: 0.000137 
l0: 0.000161, l1: 0.000162, l2: 0.000225, l3: 0.000345, l4: 0.000563, l5: 0.001572, l6: 0.003031

[epoch: 401/1000, batch:   320/ 1052, ite: 105280] train loss: 0.004183, tar: 0.000140 
l0: 0.000274, l1: 0.000281, l2: 0.000313, l3: 0.000375, l4: 0.000822, l5: 0.001451, l6: 0.003227

[epoch: 401/1000, batch:   400/ 1052, ite: 105300] train loss: 0.004211, tar: 0.000140 
l0: 0.000161, l1: 0.000171, l2: 0.000208, l3: 0.000385, l4: 0.000666, l5: 0.001610, l6: 0.001814

[epoch: 401/1000, batch:   480/ 1052, ite: 105320] train loss: 0.004328, tar: 0.000147 
l0: 0.000106, l1: 0.000112, l2: 0.000125, l3: 0.000226, l4: 0.000354, l5: 0.001242, l6: 0.001450

[epoch: 401/1000, batch:   560/ 1052, ite: 105340] train loss: 0.004351, tar: 0.000146 
l0: 0.000204, l1: 0.000201, l2: 0.000256, l3: 0.000347, l4: 0.000647, l5: 0.001223, l6: 0.002208

[epoch: 401/1000, batch:   640/ 1052, ite: 105360] train loss: 0.004354, tar: 0.000145 
l0: 0.000202, l1: 0.000210, l2: 0.000215, l3: 0.000238, l4: 0.000360, l5: 0.000827, l6: 0.001722

[epoch: 401/1000, batch:   720/ 1052, ite: 105380] train loss: 0.004399, tar: 0.000146 
l0: 0.000082, l1: 0.000080, l2: 0.000102, l3: 0.000176, l4: 0.000208, l5: 0.000541, l6: 0.001057

[epoch: 401/1000, batch:   800/ 1052, ite: 105400] train loss: 0.004365, tar: 0.000145 
l0: 0.000119, l1: 0.000120, l2: 0.000138, l3: 0.000173, l4: 0.000320, l5: 0.001143, l6: 0.001337

[epoch: 401/1000, batch:   880/ 1052, ite: 105420] train loss: 0.004391, tar: 0.000146 
l0: 0.000068, l1: 0.000067, l2: 0.000097, l3: 0.000126, l4: 0.000297, l5: 0.000660, l6: 0.000890

[epoch: 401/1000, batch:   960/ 1052, ite: 105440] train loss: 0.004478, tar: 0.000149 
l0: 0.000154, l1: 0.000164, l2: 0.000194, l3: 0.000269, l4: 0.000361, l5: 0.001145, l6: 0.003219

[epoch: 401/1000, batch:  1040/ 1052, ite: 105460] train loss: 0.004469, tar: 0.000148 
[Epoch 401/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000072, l1: 0.000068, l2: 0.000153, l3: 0.000173, l4: 0.000423, l5: 0.000888, l6: 0.000982

[epoch: 402/1000, batch:    68/ 1052, ite: 105480] train loss: 0.004463, tar: 0.000148 
l0: 0.000074, l1: 0.000074, l2: 0.000111, l3: 0.000231, l4: 0.000382, l5: 0.000570, l6: 0.001350

[epoch: 402/1000, batch:   148/ 1052, ite: 105500] train loss: 0.004499, tar: 0.000149 
l0: 0.000120, l1: 0.000120, l2: 0.000170, l3: 0.000367, l4: 0.000709, l5: 0.001957, l6: 0.003025

[epoch: 402/1000, batch:   228/ 1052, ite: 105520] train loss: 0.004468, tar: 0.000147 
l0: 0.000084, l1: 0.000083, l2: 0.000126, l3: 0.000220, l4: 0.000535, l5: 0.001169, l6: 0.001898

[epoch: 402/1000, batch:   308/ 1052, ite: 105540] train loss: 0.004449, tar: 0.000146 
l0: 0.000095, l1: 0.000097, l2: 0.000130, l3: 0.000210, l4: 0.000373, l5: 0.000767, l6: 0.001690

[epoch: 402/1000, batch:   388/ 1052, ite: 105560] train loss: 0.004443, tar: 0.000145 
l0: 0.000175, l1: 0.000184, l2: 0.000204, l3: 0.000393, l4: 0.000692, l5: 0.001794, l6: 0.002972

[epoch: 402/1000, batch:   468/ 1052, ite: 105580] train loss: 0.004472, tar: 0.000147 
l0: 0.000071, l1: 0.000073, l2: 0.000107, l3: 0.000153, l4: 0.000333, l5: 0.000852, l6: 0.001857

[epoch: 402/1000, batch:   548/ 1052, ite: 105600] train loss: 0.004445, tar: 0.000146 
l0: 0.000113, l1: 0.000111, l2: 0.000153, l3: 0.000201, l4: 0.000480, l5: 0.000964, l6: 0.001457

[epoch: 402/1000, batch:   628/ 1052, ite: 105620] train loss: 0.004450, tar: 0.000147 
l0: 0.000067, l1: 0.000070, l2: 0.000087, l3: 0.000146, l4: 0.000519, l5: 0.000849, l6: 0.001485

[epoch: 402/1000, batch:   708/ 1052, ite: 105640] train loss: 0.004468, tar: 0.000147 
l0: 0.000050, l1: 0.000051, l2: 0.000100, l3: 0.000147, l4: 0.000383, l5: 0.000654, l6: 0.001395

[epoch: 402/1000, batch:   788/ 1052, ite: 105660] train loss: 0.004453, tar: 0.000146 
l0: 0.000160, l1: 0.000168, l2: 0.000185, l3: 0.000278, l4: 0.000495, l5: 0.000913, l6: 0.001276

[epoch: 402/1000, batch:   868/ 1052, ite: 105680] train loss: 0.004458, tar: 0.000146 
l0: 0.000189, l1: 0.000180, l2: 0.000268, l3: 0.000431, l4: 0.000907, l5: 0.002320, l6: 0.003353

[epoch: 402/1000, batch:   948/ 1052, ite: 105700] train loss: 0.004456, tar: 0.000145 
l0: 0.000129, l1: 0.000132, l2: 0.000140, l3: 0.000237, l4: 0.000524, l5: 0.001282, l6: 0.001620

[epoch: 402/1000, batch:  1028/ 1052, ite: 105720] train loss: 0.004459, tar: 0.000145 
[Epoch 402/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000089, l1: 0.000086, l2: 0.000160, l3: 0.000284, l4: 0.000423, l5: 0.001291, l6: 0.001978

[epoch: 403/1000, batch:    56/ 1052, ite: 105740] train loss: 0.004447, tar: 0.000144 
l0: 0.000112, l1: 0.000119, l2: 0.000155, l3: 0.000306, l4: 0.000504, l5: 0.001147, l6: 0.002352

[epoch: 403/1000, batch:   136/ 1052, ite: 105760] train loss: 0.004464, tar: 0.000144 
l0: 0.000110, l1: 0.000111, l2: 0.000138, l3: 0.000242, l4: 0.000514, l5: 0.001346, l6: 0.001513

[epoch: 403/1000, batch:   216/ 1052, ite: 105780] train loss: 0.004459, tar: 0.000144 
l0: 0.000149, l1: 0.000151, l2: 0.000166, l3: 0.000235, l4: 0.000403, l5: 0.000992, l6: 0.001824

[epoch: 403/1000, batch:   296/ 1052, ite: 105800] train loss: 0.004477, tar: 0.000145 
l0: 0.000102, l1: 0.000101, l2: 0.000146, l3: 0.000248, l4: 0.000392, l5: 0.000724, l6: 0.001383

[epoch: 403/1000, batch:   376/ 1052, ite: 105820] train loss: 0.004476, tar: 0.000145 
l0: 0.000061, l1: 0.000061, l2: 0.000083, l3: 0.000179, l4: 0.000370, l5: 0.000871, l6: 0.001482

[epoch: 403/1000, batch:   456/ 1052, ite: 105840] train loss: 0.004467, tar: 0.000145 
l0: 0.000146, l1: 0.000146, l2: 0.000203, l3: 0.000310, l4: 0.000485, l5: 0.000618, l6: 0.002411

[epoch: 403/1000, batch:   536/ 1052, ite: 105860] train loss: 0.004467, tar: 0.000145 
l0: 0.000100, l1: 0.000104, l2: 0.000152, l3: 0.000259, l4: 0.000791, l5: 0.001421, l6: 0.001797

[epoch: 403/1000, batch:   616/ 1052, ite: 105880] train loss: 0.004472, tar: 0.000145 
l0: 0.000086, l1: 0.000087, l2: 0.000134, l3: 0.000212, l4: 0.000569, l5: 0.001246, l6: 0.002944

[epoch: 403/1000, batch:   696/ 1052, ite: 105900] train loss: 0.004471, tar: 0.000145 
l0: 0.000153, l1: 0.000155, l2: 0.000168, l3: 0.000298, l4: 0.000704, l5: 0.001294, l6: 0.001816

[epoch: 403/1000, batch:   776/ 1052, ite: 105920] train loss: 0.004469, tar: 0.000145 
l0: 0.000074, l1: 0.000073, l2: 0.000115, l3: 0.000248, l4: 0.000653, l5: 0.000917, l6: 0.001487

[epoch: 403/1000, batch:   856/ 1052, ite: 105940] train loss: 0.004472, tar: 0.000145 
l0: 0.000086, l1: 0.000090, l2: 0.000109, l3: 0.000203, l4: 0.000519, l5: 0.001029, l6: 0.002345

[epoch: 403/1000, batch:   936/ 1052, ite: 105960] train loss: 0.004460, tar: 0.000144 
l0: 0.000186, l1: 0.000183, l2: 0.000256, l3: 0.000378, l4: 0.000827, l5: 0.001317, l6: 0.003772

[epoch: 403/1000, batch:  1016/ 1052, ite: 105980] train loss: 0.004461, tar: 0.000145 
[Epoch 403/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000127, l1: 0.000129, l2: 0.000194, l3: 0.000373, l4: 0.000799, l5: 0.001598, l6: 0.002585

[epoch: 404/1000, batch:    44/ 1052, ite: 106000] train loss: 0.004453, tar: 0.000144 
l0: 0.000126, l1: 0.000123, l2: 0.000153, l3: 0.000192, l4: 0.000368, l5: 0.001056, l6: 0.001579

[epoch: 404/1000, batch:   124/ 1052, ite: 106020] train loss: 0.004475, tar: 0.000145 
l0: 0.000130, l1: 0.000133, l2: 0.000178, l3: 0.000288, l4: 0.000787, l5: 0.001638, l6: 0.002693

[epoch: 404/1000, batch:   204/ 1052, ite: 106040] train loss: 0.004465, tar: 0.000145 
l0: 0.000170, l1: 0.000167, l2: 0.000200, l3: 0.000280, l4: 0.000633, l5: 0.001191, l6: 0.002384

[epoch: 404/1000, batch:   284/ 1052, ite: 106060] train loss: 0.004471, tar: 0.000145 
l0: 0.000076, l1: 0.000079, l2: 0.000082, l3: 0.000125, l4: 0.000261, l5: 0.000501, l6: 0.001065

[epoch: 404/1000, batch:   364/ 1052, ite: 106080] train loss: 0.004479, tar: 0.000145 
l0: 0.000082, l1: 0.000083, l2: 0.000100, l3: 0.000144, l4: 0.000398, l5: 0.000818, l6: 0.001253

[epoch: 404/1000, batch:   444/ 1052, ite: 106100] train loss: 0.004463, tar: 0.000144 
l0: 0.000070, l1: 0.000075, l2: 0.000137, l3: 0.000310, l4: 0.000641, l5: 0.001168, l6: 0.002392

[epoch: 404/1000, batch:   524/ 1052, ite: 106120] train loss: 0.004466, tar: 0.000145 
l0: 0.000158, l1: 0.000155, l2: 0.000173, l3: 0.000282, l4: 0.000419, l5: 0.000839, l6: 0.001914

[epoch: 404/1000, batch:   604/ 1052, ite: 106140] train loss: 0.004477, tar: 0.000145 
l0: 0.000190, l1: 0.000169, l2: 0.000189, l3: 0.000284, l4: 0.000452, l5: 0.000839, l6: 0.001582

[epoch: 404/1000, batch:   684/ 1052, ite: 106160] train loss: 0.004488, tar: 0.000146 
l0: 0.000251, l1: 0.000248, l2: 0.000271, l3: 0.000415, l4: 0.000640, l5: 0.001237, l6: 0.001598

[epoch: 404/1000, batch:   764/ 1052, ite: 106180] train loss: 0.004496, tar: 0.000146 
l0: 0.000068, l1: 0.000068, l2: 0.000094, l3: 0.000128, l4: 0.000323, l5: 0.000860, l6: 0.001334

[epoch: 404/1000, batch:   844/ 1052, ite: 106200] train loss: 0.004494, tar: 0.000145 
l0: 0.000134, l1: 0.000136, l2: 0.000156, l3: 0.000246, l4: 0.000602, l5: 0.001360, l6: 0.002635

[epoch: 404/1000, batch:   924/ 1052, ite: 106220] train loss: 0.004487, tar: 0.000145 
l0: 0.000149, l1: 0.000144, l2: 0.000219, l3: 0.000398, l4: 0.000930, l5: 0.001483, l6: 0.002801

[epoch: 404/1000, batch:  1004/ 1052, ite: 106240] train loss: 0.004483, tar: 0.000145 
[Epoch 404/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000132, l1: 0.000133, l2: 0.000154, l3: 0.000237, l4: 0.000570, l5: 0.000910, l6: 0.002058

[epoch: 405/1000, batch:    32/ 1052, ite: 106260] train loss: 0.004469, tar: 0.000144 
l0: 0.000172, l1: 0.000173, l2: 0.000218, l3: 0.000375, l4: 0.000873, l5: 0.001875, l6: 0.003077

[epoch: 405/1000, batch:   112/ 1052, ite: 106280] train loss: 0.004468, tar: 0.000144 
l0: 0.000202, l1: 0.000203, l2: 0.000227, l3: 0.000314, l4: 0.000506, l5: 0.001147, l6: 0.003362

[epoch: 405/1000, batch:   192/ 1052, ite: 106300] train loss: 0.004461, tar: 0.000144 
l0: 0.000079, l1: 0.000081, l2: 0.000077, l3: 0.000133, l4: 0.000325, l5: 0.000765, l6: 0.001189

[epoch: 405/1000, batch:   272/ 1052, ite: 106320] train loss: 0.004470, tar: 0.000143 
l0: 0.000132, l1: 0.000135, l2: 0.000190, l3: 0.000341, l4: 0.000679, l5: 0.001098, l6: 0.002079

[epoch: 405/1000, batch:   352/ 1052, ite: 106340] train loss: 0.004470, tar: 0.000143 
l0: 0.000049, l1: 0.000051, l2: 0.000066, l3: 0.000137, l4: 0.000441, l5: 0.000732, l6: 0.001861

[epoch: 405/1000, batch:   432/ 1052, ite: 106360] train loss: 0.004468, tar: 0.000144 
l0: 0.000163, l1: 0.000166, l2: 0.000281, l3: 0.000485, l4: 0.001006, l5: 0.001950, l6: 0.002652

[epoch: 405/1000, batch:   512/ 1052, ite: 106380] train loss: 0.004466, tar: 0.000143 
l0: 0.000169, l1: 0.000169, l2: 0.000218, l3: 0.000289, l4: 0.000438, l5: 0.001290, l6: 0.001305

[epoch: 405/1000, batch:   592/ 1052, ite: 106400] train loss: 0.004457, tar: 0.000143 
l0: 0.000215, l1: 0.000222, l2: 0.000287, l3: 0.000445, l4: 0.000742, l5: 0.001349, l6: 0.001963

[epoch: 405/1000, batch:   672/ 1052, ite: 106420] train loss: 0.004452, tar: 0.000143 
l0: 0.000062, l1: 0.000063, l2: 0.000104, l3: 0.000180, l4: 0.000382, l5: 0.000801, l6: 0.000984

[epoch: 405/1000, batch:   752/ 1052, ite: 106440] train loss: 0.004443, tar: 0.000142 
l0: 0.000104, l1: 0.000104, l2: 0.000155, l3: 0.000282, l4: 0.000540, l5: 0.001688, l6: 0.001843

[epoch: 405/1000, batch:   832/ 1052, ite: 106460] train loss: 0.004440, tar: 0.000142 
l0: 0.000152, l1: 0.000148, l2: 0.000157, l3: 0.000266, l4: 0.000453, l5: 0.001072, l6: 0.002096

[epoch: 405/1000, batch:   912/ 1052, ite: 106480] train loss: 0.004444, tar: 0.000142 
l0: 0.000230, l1: 0.000235, l2: 0.000291, l3: 0.000451, l4: 0.000841, l5: 0.001444, l6: 0.002439

[epoch: 405/1000, batch:   992/ 1052, ite: 106500] train loss: 0.004455, tar: 0.000142 
[Epoch 405/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000195, l1: 0.000192, l2: 0.000241, l3: 0.000349, l4: 0.000631, l5: 0.001077, l6: 0.001686

[epoch: 406/1000, batch:    20/ 1052, ite: 106520] train loss: 0.004457, tar: 0.000143 
l0: 0.000156, l1: 0.000155, l2: 0.000185, l3: 0.000267, l4: 0.000555, l5: 0.001299, l6: 0.001603

[epoch: 406/1000, batch:   100/ 1052, ite: 106540] train loss: 0.004455, tar: 0.000143 
l0: 0.000114, l1: 0.000113, l2: 0.000202, l3: 0.000340, l4: 0.000501, l5: 0.000955, l6: 0.001084

[epoch: 406/1000, batch:   180/ 1052, ite: 106560] train loss: 0.004450, tar: 0.000142 
l0: 0.000321, l1: 0.000324, l2: 0.000390, l3: 0.000440, l4: 0.001181, l5: 0.002839, l6: 0.004761

[epoch: 406/1000, batch:   260/ 1052, ite: 106580] train loss: 0.004452, tar: 0.000142 
l0: 0.000161, l1: 0.000162, l2: 0.000187, l3: 0.000220, l4: 0.000592, l5: 0.001050, l6: 0.001779

[epoch: 406/1000, batch:   340/ 1052, ite: 106600] train loss: 0.004447, tar: 0.000142 
l0: 0.000083, l1: 0.000087, l2: 0.000124, l3: 0.000222, l4: 0.000288, l5: 0.000791, l6: 0.001767

[epoch: 406/1000, batch:   420/ 1052, ite: 106620] train loss: 0.004444, tar: 0.000142 
l0: 0.000107, l1: 0.000108, l2: 0.000146, l3: 0.000331, l4: 0.000537, l5: 0.001080, l6: 0.001386

[epoch: 406/1000, batch:   500/ 1052, ite: 106640] train loss: 0.004450, tar: 0.000142 
l0: 0.000106, l1: 0.000098, l2: 0.000188, l3: 0.000352, l4: 0.000408, l5: 0.000857, l6: 0.001673

[epoch: 406/1000, batch:   580/ 1052, ite: 106660] train loss: 0.004457, tar: 0.000142 
l0: 0.000149, l1: 0.000147, l2: 0.000172, l3: 0.000269, l4: 0.000510, l5: 0.000897, l6: 0.002277

[epoch: 406/1000, batch:   660/ 1052, ite: 106680] train loss: 0.004457, tar: 0.000142 
l0: 0.000083, l1: 0.000080, l2: 0.000132, l3: 0.000180, l4: 0.000317, l5: 0.001066, l6: 0.002502

[epoch: 406/1000, batch:   740/ 1052, ite: 106700] train loss: 0.004461, tar: 0.000142 
l0: 0.000142, l1: 0.000133, l2: 0.000205, l3: 0.000224, l4: 0.000313, l5: 0.000899, l6: 0.001347

[epoch: 406/1000, batch:   820/ 1052, ite: 106720] train loss: 0.004464, tar: 0.000143 
l0: 0.000094, l1: 0.000090, l2: 0.000133, l3: 0.000232, l4: 0.000354, l5: 0.000672, l6: 0.001546

[epoch: 406/1000, batch:   900/ 1052, ite: 106740] train loss: 0.004453, tar: 0.000142 
l0: 0.000089, l1: 0.000090, l2: 0.000099, l3: 0.000129, l4: 0.000205, l5: 0.000766, l6: 0.001793

[epoch: 406/1000, batch:   980/ 1052, ite: 106760] train loss: 0.004451, tar: 0.000142 
[Epoch 406/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000068, l1: 0.000066, l2: 0.000131, l3: 0.000197, l4: 0.000449, l5: 0.001232, l6: 0.001284

[epoch: 407/1000, batch:     8/ 1052, ite: 106780] train loss: 0.004448, tar: 0.000142 
l0: 0.000079, l1: 0.000077, l2: 0.000126, l3: 0.000178, l4: 0.000470, l5: 0.000718, l6: 0.001574

[epoch: 407/1000, batch:    88/ 1052, ite: 106800] train loss: 0.004442, tar: 0.000142 
l0: 0.000161, l1: 0.000169, l2: 0.000157, l3: 0.000173, l4: 0.000338, l5: 0.000808, l6: 0.002427

[epoch: 407/1000, batch:   168/ 1052, ite: 106820] train loss: 0.004441, tar: 0.000142 
l0: 0.000131, l1: 0.000138, l2: 0.000126, l3: 0.000185, l4: 0.000350, l5: 0.001106, l6: 0.002139

[epoch: 407/1000, batch:   248/ 1052, ite: 106840] train loss: 0.004448, tar: 0.000142 
l0: 0.000166, l1: 0.000166, l2: 0.000204, l3: 0.000243, l4: 0.000418, l5: 0.001070, l6: 0.002089

[epoch: 407/1000, batch:   328/ 1052, ite: 106860] train loss: 0.004454, tar: 0.000142 
l0: 0.000202, l1: 0.000199, l2: 0.000236, l3: 0.000353, l4: 0.000665, l5: 0.001051, l6: 0.001730

[epoch: 407/1000, batch:   408/ 1052, ite: 106880] train loss: 0.004452, tar: 0.000142 
l0: 0.000079, l1: 0.000081, l2: 0.000111, l3: 0.000163, l4: 0.000396, l5: 0.000715, l6: 0.001376

[epoch: 407/1000, batch:   488/ 1052, ite: 106900] train loss: 0.004445, tar: 0.000142 
l0: 0.000094, l1: 0.000094, l2: 0.000116, l3: 0.000190, l4: 0.000385, l5: 0.000892, l6: 0.001176

[epoch: 407/1000, batch:   568/ 1052, ite: 106920] train loss: 0.004444, tar: 0.000142 
l0: 0.000237, l1: 0.000230, l2: 0.000290, l3: 0.000544, l4: 0.000939, l5: 0.001394, l6: 0.002863

[epoch: 407/1000, batch:   648/ 1052, ite: 106940] train loss: 0.004442, tar: 0.000141 
l0: 0.000114, l1: 0.000116, l2: 0.000145, l3: 0.000238, l4: 0.000268, l5: 0.000835, l6: 0.001192

[epoch: 407/1000, batch:   728/ 1052, ite: 106960] train loss: 0.004438, tar: 0.000141 
l0: 0.000148, l1: 0.000150, l2: 0.000191, l3: 0.000296, l4: 0.000499, l5: 0.000919, l6: 0.001643

[epoch: 407/1000, batch:   808/ 1052, ite: 106980] train loss: 0.004435, tar: 0.000141 
l0: 0.000145, l1: 0.000147, l2: 0.000159, l3: 0.000180, l4: 0.000465, l5: 0.000753, l6: 0.001445

[epoch: 407/1000, batch:   888/ 1052, ite: 107000] train loss: 0.004436, tar: 0.000142 
l0: 0.000198, l1: 0.000196, l2: 0.000251, l3: 0.000311, l4: 0.000665, l5: 0.001646, l6: 0.002227

[epoch: 407/1000, batch:   968/ 1052, ite: 107020] train loss: 0.004439, tar: 0.000142 
l0: 0.000162, l1: 0.000158, l2: 0.000256, l3: 0.000418, l4: 0.000674, l5: 0.001583, l6: 0.002626

[epoch: 407/1000, batch:  1048/ 1052, ite: 107040] train loss: 0.004442, tar: 0.000142 
[Epoch 407/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000145, l1: 0.000148, l2: 0.000182, l3: 0.000224, l4: 0.000542, l5: 0.001058, l6: 0.001138

[epoch: 408/1000, batch:    76/ 1052, ite: 107060] train loss: 0.004437, tar: 0.000142 
l0: 0.000066, l1: 0.000067, l2: 0.000114, l3: 0.000166, l4: 0.000309, l5: 0.000854, l6: 0.001142

[epoch: 408/1000, batch:   156/ 1052, ite: 107080] train loss: 0.004434, tar: 0.000142 
l0: 0.000179, l1: 0.000184, l2: 0.000204, l3: 0.000421, l4: 0.000769, l5: 0.001883, l6: 0.003119

[epoch: 408/1000, batch:   236/ 1052, ite: 107100] train loss: 0.004434, tar: 0.000142 
l0: 0.000097, l1: 0.000099, l2: 0.000138, l3: 0.000178, l4: 0.000387, l5: 0.000786, l6: 0.002121

[epoch: 408/1000, batch:   316/ 1052, ite: 107120] train loss: 0.004432, tar: 0.000142 
l0: 0.000092, l1: 0.000090, l2: 0.000124, l3: 0.000367, l4: 0.000456, l5: 0.001154, l6: 0.001686

[epoch: 408/1000, batch:   396/ 1052, ite: 107140] train loss: 0.004437, tar: 0.000142 
l0: 0.000081, l1: 0.000081, l2: 0.000102, l3: 0.000118, l4: 0.000281, l5: 0.000844, l6: 0.001371

[epoch: 408/1000, batch:   476/ 1052, ite: 107160] train loss: 0.004438, tar: 0.000142 
l0: 0.000066, l1: 0.000070, l2: 0.000096, l3: 0.000169, l4: 0.000373, l5: 0.001113, l6: 0.001563

[epoch: 408/1000, batch:   556/ 1052, ite: 107180] train loss: 0.004442, tar: 0.000142 
l0: 0.000258, l1: 0.000265, l2: 0.000312, l3: 0.000359, l4: 0.000543, l5: 0.001357, l6: 0.002371

[epoch: 408/1000, batch:   636/ 1052, ite: 107200] train loss: 0.004445, tar: 0.000142 
l0: 0.000176, l1: 0.000181, l2: 0.000294, l3: 0.000504, l4: 0.000951, l5: 0.001777, l6: 0.002986

[epoch: 408/1000, batch:   716/ 1052, ite: 107220] train loss: 0.004451, tar: 0.000142 
l0: 0.000141, l1: 0.000143, l2: 0.000180, l3: 0.000323, l4: 0.000687, l5: 0.001023, l6: 0.003290

[epoch: 408/1000, batch:   796/ 1052, ite: 107240] train loss: 0.004449, tar: 0.000142 
l0: 0.000200, l1: 0.000202, l2: 0.000206, l3: 0.000414, l4: 0.000593, l5: 0.001191, l6: 0.001962

[epoch: 408/1000, batch:   876/ 1052, ite: 107260] train loss: 0.004447, tar: 0.000142 
l0: 0.000156, l1: 0.000156, l2: 0.000254, l3: 0.000417, l4: 0.000924, l5: 0.001376, l6: 0.002186

[epoch: 408/1000, batch:   956/ 1052, ite: 107280] train loss: 0.004444, tar: 0.000142 
l0: 0.000072, l1: 0.000068, l2: 0.000120, l3: 0.000227, l4: 0.000442, l5: 0.000818, l6: 0.001380

[epoch: 408/1000, batch:  1036/ 1052, ite: 107300] train loss: 0.004441, tar: 0.000142 
[Epoch 408/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000072, l1: 0.000073, l2: 0.000085, l3: 0.000133, l4: 0.000216, l5: 0.000739, l6: 0.001012

[epoch: 409/1000, batch:    64/ 1052, ite: 107320] train loss: 0.004440, tar: 0.000142 
l0: 0.000098, l1: 0.000095, l2: 0.000200, l3: 0.000249, l4: 0.000496, l5: 0.001700, l6: 0.002956

[epoch: 409/1000, batch:   144/ 1052, ite: 107340] train loss: 0.004445, tar: 0.000142 
l0: 0.000159, l1: 0.000163, l2: 0.000205, l3: 0.000226, l4: 0.000411, l5: 0.000721, l6: 0.001689

[epoch: 409/1000, batch:   224/ 1052, ite: 107360] train loss: 0.004445, tar: 0.000142 
l0: 0.000098, l1: 0.000097, l2: 0.000147, l3: 0.000222, l4: 0.000538, l5: 0.001259, l6: 0.001640

[epoch: 409/1000, batch:   304/ 1052, ite: 107380] train loss: 0.004443, tar: 0.000142 
l0: 0.000170, l1: 0.000170, l2: 0.000186, l3: 0.000307, l4: 0.000513, l5: 0.001556, l6: 0.002590

[epoch: 409/1000, batch:   384/ 1052, ite: 107400] train loss: 0.004441, tar: 0.000142 
l0: 0.000239, l1: 0.000247, l2: 0.000292, l3: 0.000396, l4: 0.000630, l5: 0.001252, l6: 0.003169

[epoch: 409/1000, batch:   464/ 1052, ite: 107420] train loss: 0.004444, tar: 0.000143 
l0: 0.000083, l1: 0.000084, l2: 0.000114, l3: 0.000158, l4: 0.000451, l5: 0.001066, l6: 0.001175

[epoch: 409/1000, batch:   544/ 1052, ite: 107440] train loss: 0.004444, tar: 0.000143 
l0: 0.000028, l1: 0.000029, l2: 0.000047, l3: 0.000076, l4: 0.000165, l5: 0.000616, l6: 0.001090

[epoch: 409/1000, batch:   624/ 1052, ite: 107460] train loss: 0.004449, tar: 0.000143 
l0: 0.000167, l1: 0.000166, l2: 0.000242, l3: 0.000339, l4: 0.000765, l5: 0.001187, l6: 0.002265

[epoch: 409/1000, batch:   704/ 1052, ite: 107480] train loss: 0.004447, tar: 0.000143 
l0: 0.000277, l1: 0.000273, l2: 0.000311, l3: 0.000438, l4: 0.000944, l5: 0.001240, l6: 0.002078

[epoch: 409/1000, batch:   784/ 1052, ite: 107500] train loss: 0.004449, tar: 0.000143 
l0: 0.000123, l1: 0.000125, l2: 0.000153, l3: 0.000259, l4: 0.000544, l5: 0.001013, l6: 0.002014

[epoch: 409/1000, batch:   864/ 1052, ite: 107520] train loss: 0.004444, tar: 0.000143 
l0: 0.000179, l1: 0.000180, l2: 0.000207, l3: 0.000283, l4: 0.000562, l5: 0.000954, l6: 0.001555

[epoch: 409/1000, batch:   944/ 1052, ite: 107540] train loss: 0.004442, tar: 0.000143 
l0: 0.000154, l1: 0.000158, l2: 0.000203, l3: 0.000343, l4: 0.000708, l5: 0.001504, l6: 0.002001

[epoch: 409/1000, batch:  1024/ 1052, ite: 107560] train loss: 0.004445, tar: 0.000143 
[Epoch 409/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000206, l1: 0.000201, l2: 0.000259, l3: 0.000342, l4: 0.000567, l5: 0.000874, l6: 0.001617

[epoch: 410/1000, batch:    52/ 1052, ite: 107580] train loss: 0.004445, tar: 0.000143 
l0: 0.000209, l1: 0.000209, l2: 0.000231, l3: 0.000369, l4: 0.000831, l5: 0.001744, l6: 0.002393

[epoch: 410/1000, batch:   132/ 1052, ite: 107600] train loss: 0.004443, tar: 0.000143 
l0: 0.000097, l1: 0.000097, l2: 0.000126, l3: 0.000150, l4: 0.000267, l5: 0.000701, l6: 0.001590

[epoch: 410/1000, batch:   212/ 1052, ite: 107620] train loss: 0.004446, tar: 0.000143 
l0: 0.000159, l1: 0.000174, l2: 0.000191, l3: 0.000328, l4: 0.000553, l5: 0.000852, l6: 0.002167

[epoch: 410/1000, batch:   292/ 1052, ite: 107640] train loss: 0.004447, tar: 0.000143 
l0: 0.000042, l1: 0.000039, l2: 0.000074, l3: 0.000192, l4: 0.000303, l5: 0.000729, l6: 0.000814

[epoch: 410/1000, batch:   372/ 1052, ite: 107660] train loss: 0.004446, tar: 0.000143 
l0: 0.000160, l1: 0.000146, l2: 0.000232, l3: 0.000274, l4: 0.000481, l5: 0.000729, l6: 0.001648

[epoch: 410/1000, batch:   452/ 1052, ite: 107680] train loss: 0.004446, tar: 0.000143 
l0: 0.000118, l1: 0.000121, l2: 0.000128, l3: 0.000231, l4: 0.000578, l5: 0.000860, l6: 0.001784

[epoch: 410/1000, batch:   532/ 1052, ite: 107700] train loss: 0.004451, tar: 0.000143 
l0: 0.000184, l1: 0.000186, l2: 0.000243, l3: 0.000315, l4: 0.001108, l5: 0.001701, l6: 0.003138

[epoch: 410/1000, batch:   612/ 1052, ite: 107720] train loss: 0.004454, tar: 0.000143 
l0: 0.000118, l1: 0.000122, l2: 0.000128, l3: 0.000185, l4: 0.000420, l5: 0.001157, l6: 0.002935

[epoch: 410/1000, batch:   692/ 1052, ite: 107740] train loss: 0.004449, tar: 0.000143 
l0: 0.000054, l1: 0.000054, l2: 0.000091, l3: 0.000133, l4: 0.000324, l5: 0.001063, l6: 0.002296

[epoch: 410/1000, batch:   772/ 1052, ite: 107760] train loss: 0.004447, tar: 0.000143 
l0: 0.000117, l1: 0.000122, l2: 0.000150, l3: 0.000268, l4: 0.000391, l5: 0.000978, l6: 0.001783

[epoch: 410/1000, batch:   852/ 1052, ite: 107780] train loss: 0.004444, tar: 0.000143 
l0: 0.000049, l1: 0.000050, l2: 0.000081, l3: 0.000148, l4: 0.000257, l5: 0.000787, l6: 0.000846

[epoch: 410/1000, batch:   932/ 1052, ite: 107800] train loss: 0.004438, tar: 0.000142 
l0: 0.000090, l1: 0.000095, l2: 0.000090, l3: 0.000202, l4: 0.000425, l5: 0.000687, l6: 0.001047

[epoch: 410/1000, batch:  1012/ 1052, ite: 107820] train loss: 0.004438, tar: 0.000142 
[Epoch 410/1000] Test loss: 0.012, Test target loss: 0.002
l0: 0.000059, l1: 0.000058, l2: 0.000111, l3: 0.000154, l4: 0.000407, l5: 0.000821, l6: 0.001016

[epoch: 411/1000, batch:    40/ 1052, ite: 107840] train loss: 0.004436, tar: 0.000142 
l0: 0.000231, l1: 0.000234, l2: 0.000292, l3: 0.000369, l4: 0.000728, l5: 0.001478, l6: 0.002350

[epoch: 411/1000, batch:   120/ 1052, ite: 107860] train loss: 0.004436, tar: 0.000143 
l0: 0.000082, l1: 0.000079, l2: 0.000136, l3: 0.000212, l4: 0.000349, l5: 0.000895, l6: 0.000932

[epoch: 411/1000, batch:   200/ 1052, ite: 107880] train loss: 0.004435, tar: 0.000143 
l0: 0.000053, l1: 0.000053, l2: 0.000067, l3: 0.000142, l4: 0.000271, l5: 0.000777, l6: 0.001294

[epoch: 411/1000, batch:   280/ 1052, ite: 107900] train loss: 0.004433, tar: 0.000142 
l0: 0.000211, l1: 0.000212, l2: 0.000225, l3: 0.000324, l4: 0.000349, l5: 0.000734, l6: 0.001864

[epoch: 411/1000, batch:   360/ 1052, ite: 107920] train loss: 0.004438, tar: 0.000142 
l0: 0.000073, l1: 0.000073, l2: 0.000128, l3: 0.000257, l4: 0.000757, l5: 0.001044, l6: 0.001844

[epoch: 411/1000, batch:   440/ 1052, ite: 107940] train loss: 0.004436, tar: 0.000142 
l0: 0.000121, l1: 0.000124, l2: 0.000147, l3: 0.000223, l4: 0.000379, l5: 0.000727, l6: 0.001526

[epoch: 411/1000, batch:   520/ 1052, ite: 107960] train loss: 0.004433, tar: 0.000142 
l0: 0.000223, l1: 0.000226, l2: 0.000237, l3: 0.000310, l4: 0.000617, l5: 0.002183, l6: 0.002743

[epoch: 411/1000, batch:   600/ 1052, ite: 107980] train loss: 0.004436, tar: 0.000142 
l0: 0.000177, l1: 0.000179, l2: 0.000238, l3: 0.000330, l4: 0.000554, l5: 0.001707, l6: 0.002048

[epoch: 411/1000, batch:   680/ 1052, ite: 108000] train loss: 0.004439, tar: 0.000142 
l0: 0.000199, l1: 0.000193, l2: 0.000256, l3: 0.000432, l4: 0.000825, l5: 0.001330, l6: 0.001705

[epoch: 411/1000, batch:   760/ 1052, ite: 108020] train loss: 0.004445, tar: 0.000143 
l0: 0.000266, l1: 0.000279, l2: 0.000319, l3: 0.000533, l4: 0.000975, l5: 0.002254, l6: 0.003875

[epoch: 411/1000, batch:   840/ 1052, ite: 108040] train loss: 0.004447, tar: 0.000143 
l0: 0.000266, l1: 0.000262, l2: 0.000312, l3: 0.000367, l4: 0.000554, l5: 0.000861, l6: 0.001362

[epoch: 411/1000, batch:   920/ 1052, ite: 108060] train loss: 0.004443, tar: 0.000143 
l0: 0.000166, l1: 0.000162, l2: 0.000214, l3: 0.000336, l4: 0.000479, l5: 0.001097, l6: 0.002036

[epoch: 411/1000, batch:  1000/ 1052, ite: 108080] train loss: 0.004444, tar: 0.000143 
[Epoch 411/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000144, l1: 0.000144, l2: 0.000188, l3: 0.000258, l4: 0.000406, l5: 0.000953, l6: 0.001896

[epoch: 412/1000, batch:    28/ 1052, ite: 108100] train loss: 0.004439, tar: 0.000143 
l0: 0.000055, l1: 0.000058, l2: 0.000068, l3: 0.000125, l4: 0.000408, l5: 0.000841, l6: 0.001095

[epoch: 412/1000, batch:   108/ 1052, ite: 108120] train loss: 0.004441, tar: 0.000143 
l0: 0.000098, l1: 0.000105, l2: 0.000120, l3: 0.000164, l4: 0.000548, l5: 0.000805, l6: 0.001489

[epoch: 412/1000, batch:   188/ 1052, ite: 108140] train loss: 0.004440, tar: 0.000143 
l0: 0.000050, l1: 0.000052, l2: 0.000055, l3: 0.000106, l4: 0.000337, l5: 0.000629, l6: 0.001325

[epoch: 412/1000, batch:   268/ 1052, ite: 108160] train loss: 0.004437, tar: 0.000142 
l0: 0.000087, l1: 0.000089, l2: 0.000114, l3: 0.000266, l4: 0.000739, l5: 0.001280, l6: 0.001922

[epoch: 412/1000, batch:   348/ 1052, ite: 108180] train loss: 0.004439, tar: 0.000143 
l0: 0.000219, l1: 0.000218, l2: 0.000252, l3: 0.000266, l4: 0.000510, l5: 0.000718, l6: 0.001608

[epoch: 412/1000, batch:   428/ 1052, ite: 108200] train loss: 0.004440, tar: 0.000143 
l0: 0.000098, l1: 0.000096, l2: 0.000154, l3: 0.000245, l4: 0.000313, l5: 0.001178, l6: 0.001600

[epoch: 412/1000, batch:   508/ 1052, ite: 108220] train loss: 0.004439, tar: 0.000143 
l0: 0.000105, l1: 0.000104, l2: 0.000152, l3: 0.000265, l4: 0.000391, l5: 0.000825, l6: 0.001909

[epoch: 412/1000, batch:   588/ 1052, ite: 108240] train loss: 0.004441, tar: 0.000143 
l0: 0.000094, l1: 0.000096, l2: 0.000173, l3: 0.000279, l4: 0.000559, l5: 0.001185, l6: 0.001701

[epoch: 412/1000, batch:   668/ 1052, ite: 108260] train loss: 0.004440, tar: 0.000143 
l0: 0.000149, l1: 0.000146, l2: 0.000205, l3: 0.000302, l4: 0.000674, l5: 0.001296, l6: 0.002751

[epoch: 412/1000, batch:   748/ 1052, ite: 108280] train loss: 0.004443, tar: 0.000143 
l0: 0.000160, l1: 0.000161, l2: 0.000210, l3: 0.000249, l4: 0.000438, l5: 0.001052, l6: 0.001629

[epoch: 412/1000, batch:   828/ 1052, ite: 108300] train loss: 0.004441, tar: 0.000143 
l0: 0.000193, l1: 0.000197, l2: 0.000239, l3: 0.000329, l4: 0.000590, l5: 0.001551, l6: 0.002869

[epoch: 412/1000, batch:   908/ 1052, ite: 108320] train loss: 0.004445, tar: 0.000143 
l0: 0.000308, l1: 0.000307, l2: 0.000349, l3: 0.000560, l4: 0.000690, l5: 0.001869, l6: 0.002742

[epoch: 412/1000, batch:   988/ 1052, ite: 108340] train loss: 0.004445, tar: 0.000143 
[Epoch 412/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000330, l1: 0.000336, l2: 0.000385, l3: 0.000489, l4: 0.000683, l5: 0.001372, l6: 0.002635

[epoch: 413/1000, batch:    16/ 1052, ite: 108360] train loss: 0.004443, tar: 0.000143 
l0: 0.000043, l1: 0.000041, l2: 0.000083, l3: 0.000241, l4: 0.000631, l5: 0.001421, l6: 0.001834

[epoch: 413/1000, batch:    96/ 1052, ite: 108380] train loss: 0.004446, tar: 0.000143 
l0: 0.000116, l1: 0.000116, l2: 0.000190, l3: 0.000357, l4: 0.000487, l5: 0.001007, l6: 0.001551

[epoch: 413/1000, batch:   176/ 1052, ite: 108400] train loss: 0.004446, tar: 0.000143 
l0: 0.000138, l1: 0.000139, l2: 0.000151, l3: 0.000226, l4: 0.000579, l5: 0.000819, l6: 0.002008

[epoch: 413/1000, batch:   256/ 1052, ite: 108420] train loss: 0.004445, tar: 0.000143 
l0: 0.000096, l1: 0.000096, l2: 0.000138, l3: 0.000228, l4: 0.000484, l5: 0.001022, l6: 0.001483

[epoch: 413/1000, batch:   336/ 1052, ite: 108440] train loss: 0.004446, tar: 0.000143 
l0: 0.000205, l1: 0.000204, l2: 0.000220, l3: 0.000328, l4: 0.000547, l5: 0.001239, l6: 0.001837

[epoch: 413/1000, batch:   416/ 1052, ite: 108460] train loss: 0.004445, tar: 0.000143 
l0: 0.000112, l1: 0.000107, l2: 0.000166, l3: 0.000312, l4: 0.000576, l5: 0.000949, l6: 0.001772

[epoch: 413/1000, batch:   496/ 1052, ite: 108480] train loss: 0.004444, tar: 0.000143 
l0: 0.000252, l1: 0.000252, l2: 0.000386, l3: 0.000635, l4: 0.001428, l5: 0.002068, l6: 0.003786

[epoch: 413/1000, batch:   576/ 1052, ite: 108500] train loss: 0.004444, tar: 0.000143 
l0: 0.000200, l1: 0.000198, l2: 0.000230, l3: 0.000439, l4: 0.000656, l5: 0.001192, l6: 0.002717

[epoch: 413/1000, batch:   656/ 1052, ite: 108520] train loss: 0.004444, tar: 0.000143 
l0: 0.000126, l1: 0.000131, l2: 0.000189, l3: 0.000243, l4: 0.000420, l5: 0.001005, l6: 0.002612

[epoch: 413/1000, batch:   736/ 1052, ite: 108540] train loss: 0.004444, tar: 0.000143 
l0: 0.000063, l1: 0.000063, l2: 0.000087, l3: 0.000144, l4: 0.000390, l5: 0.000869, l6: 0.001358

[epoch: 413/1000, batch:   816/ 1052, ite: 108560] train loss: 0.004441, tar: 0.000143 
l0: 0.000085, l1: 0.000089, l2: 0.000084, l3: 0.000113, l4: 0.000312, l5: 0.000772, l6: 0.000817

[epoch: 413/1000, batch:   896/ 1052, ite: 108580] train loss: 0.004440, tar: 0.000143 
l0: 0.000197, l1: 0.000188, l2: 0.000308, l3: 0.000450, l4: 0.001092, l5: 0.001940, l6: 0.003290

[epoch: 413/1000, batch:   976/ 1052, ite: 108600] train loss: 0.004441, tar: 0.000143 
[Epoch 413/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000103, l1: 0.000101, l2: 0.000113, l3: 0.000240, l4: 0.000521, l5: 0.000858, l6: 0.001406

[epoch: 414/1000, batch:     4/ 1052, ite: 108620] train loss: 0.004439, tar: 0.000143 
l0: 0.000119, l1: 0.000117, l2: 0.000151, l3: 0.000229, l4: 0.000567, l5: 0.001047, l6: 0.001800

[epoch: 414/1000, batch:    84/ 1052, ite: 108640] train loss: 0.004438, tar: 0.000143 
l0: 0.000121, l1: 0.000126, l2: 0.000159, l3: 0.000276, l4: 0.000559, l5: 0.001054, l6: 0.002874

[epoch: 414/1000, batch:   164/ 1052, ite: 108660] train loss: 0.004437, tar: 0.000143 
l0: 0.000296, l1: 0.000296, l2: 0.000329, l3: 0.000456, l4: 0.001061, l5: 0.001856, l6: 0.003735

[epoch: 414/1000, batch:   244/ 1052, ite: 108680] train loss: 0.004435, tar: 0.000143 
l0: 0.000141, l1: 0.000145, l2: 0.000183, l3: 0.000292, l4: 0.000524, l5: 0.001001, l6: 0.001852

[epoch: 414/1000, batch:   324/ 1052, ite: 108700] train loss: 0.004434, tar: 0.000143 
l0: 0.000123, l1: 0.000125, l2: 0.000135, l3: 0.000291, l4: 0.000510, l5: 0.001135, l6: 0.001849

[epoch: 414/1000, batch:   404/ 1052, ite: 108720] train loss: 0.004435, tar: 0.000143 
l0: 0.000133, l1: 0.000136, l2: 0.000161, l3: 0.000256, l4: 0.000437, l5: 0.001122, l6: 0.001566

[epoch: 414/1000, batch:   484/ 1052, ite: 108740] train loss: 0.004437, tar: 0.000143 
l0: 0.000177, l1: 0.000182, l2: 0.000187, l3: 0.000259, l4: 0.000444, l5: 0.000869, l6: 0.001733

[epoch: 414/1000, batch:   564/ 1052, ite: 108760] train loss: 0.004439, tar: 0.000143 
l0: 0.000161, l1: 0.000162, l2: 0.000188, l3: 0.000333, l4: 0.000571, l5: 0.001511, l6: 0.002889

[epoch: 414/1000, batch:   644/ 1052, ite: 108780] train loss: 0.004438, tar: 0.000143 
l0: 0.000172, l1: 0.000169, l2: 0.000241, l3: 0.000400, l4: 0.000522, l5: 0.001330, l6: 0.002658

[epoch: 414/1000, batch:   724/ 1052, ite: 108800] train loss: 0.004441, tar: 0.000143 
l0: 0.000118, l1: 0.000117, l2: 0.000148, l3: 0.000228, l4: 0.000540, l5: 0.000683, l6: 0.001658

[epoch: 414/1000, batch:   804/ 1052, ite: 108820] train loss: 0.004437, tar: 0.000143 
l0: 0.000250, l1: 0.000244, l2: 0.000235, l3: 0.000341, l4: 0.000715, l5: 0.001792, l6: 0.003225

[epoch: 414/1000, batch:   884/ 1052, ite: 108840] train loss: 0.004437, tar: 0.000143 
l0: 0.000094, l1: 0.000087, l2: 0.000185, l3: 0.000256, l4: 0.000416, l5: 0.000791, l6: 0.001490

[epoch: 414/1000, batch:   964/ 1052, ite: 108860] train loss: 0.004436, tar: 0.000143 
l0: 0.000294, l1: 0.000296, l2: 0.000338, l3: 0.000432, l4: 0.000803, l5: 0.001475, l6: 0.002743

[epoch: 414/1000, batch:  1044/ 1052, ite: 108880] train loss: 0.004436, tar: 0.000143 
[Epoch 414/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000050, l1: 0.000049, l2: 0.000086, l3: 0.000135, l4: 0.000319, l5: 0.000878, l6: 0.001432

[epoch: 415/1000, batch:    72/ 1052, ite: 108900] train loss: 0.004435, tar: 0.000143 
l0: 0.000108, l1: 0.000116, l2: 0.000130, l3: 0.000168, l4: 0.000292, l5: 0.001360, l6: 0.001930

[epoch: 415/1000, batch:   152/ 1052, ite: 108920] train loss: 0.004437, tar: 0.000143 
l0: 0.000136, l1: 0.000135, l2: 0.000190, l3: 0.000397, l4: 0.000634, l5: 0.001313, l6: 0.001633

[epoch: 415/1000, batch:   232/ 1052, ite: 108940] train loss: 0.004438, tar: 0.000143 
l0: 0.000335, l1: 0.000332, l2: 0.000466, l3: 0.000654, l4: 0.001060, l5: 0.002717, l6: 0.005825

[epoch: 415/1000, batch:   312/ 1052, ite: 108960] train loss: 0.004442, tar: 0.000143 
l0: 0.000120, l1: 0.000121, l2: 0.000154, l3: 0.000221, l4: 0.000479, l5: 0.000670, l6: 0.001797

[epoch: 415/1000, batch:   392/ 1052, ite: 108980] train loss: 0.004442, tar: 0.000143 
l0: 0.000135, l1: 0.000133, l2: 0.000173, l3: 0.000269, l4: 0.000453, l5: 0.000964, l6: 0.001458

[epoch: 415/1000, batch:   472/ 1052, ite: 109000] train loss: 0.004444, tar: 0.000143 
l0: 0.000102, l1: 0.000104, l2: 0.000185, l3: 0.000291, l4: 0.000742, l5: 0.001343, l6: 0.002629

[epoch: 415/1000, batch:   552/ 1052, ite: 109020] train loss: 0.004446, tar: 0.000143 
l0: 0.000073, l1: 0.000074, l2: 0.000120, l3: 0.000187, l4: 0.000381, l5: 0.000666, l6: 0.001445

[epoch: 415/1000, batch:   632/ 1052, ite: 109040] train loss: 0.004448, tar: 0.000143 
l0: 0.000106, l1: 0.000108, l2: 0.000147, l3: 0.000234, l4: 0.000411, l5: 0.001172, l6: 0.001647

[epoch: 415/1000, batch:   712/ 1052, ite: 109060] train loss: 0.004446, tar: 0.000143 
l0: 0.000133, l1: 0.000134, l2: 0.000194, l3: 0.000264, l4: 0.000574, l5: 0.001333, l6: 0.003078

[epoch: 415/1000, batch:   792/ 1052, ite: 109080] train loss: 0.004446, tar: 0.000143 
l0: 0.000055, l1: 0.000056, l2: 0.000102, l3: 0.000143, l4: 0.000326, l5: 0.000685, l6: 0.001482

[epoch: 415/1000, batch:   872/ 1052, ite: 109100] train loss: 0.004447, tar: 0.000143 
l0: 0.000127, l1: 0.000131, l2: 0.000117, l3: 0.000195, l4: 0.000286, l5: 0.000869, l6: 0.001386

[epoch: 415/1000, batch:   952/ 1052, ite: 109120] train loss: 0.004445, tar: 0.000143 
l0: 0.000029, l1: 0.000028, l2: 0.000065, l3: 0.000128, l4: 0.000327, l5: 0.000609, l6: 0.001222

[epoch: 415/1000, batch:  1032/ 1052, ite: 109140] train loss: 0.004440, tar: 0.000143 
[Epoch 415/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000218, l1: 0.000219, l2: 0.000242, l3: 0.000455, l4: 0.000589, l5: 0.001128, l6: 0.002165

[epoch: 416/1000, batch:    60/ 1052, ite: 109160] train loss: 0.004440, tar: 0.000142 
l0: 0.000177, l1: 0.000168, l2: 0.000297, l3: 0.000555, l4: 0.000803, l5: 0.001506, l6: 0.002975

[epoch: 416/1000, batch:   140/ 1052, ite: 109180] train loss: 0.004443, tar: 0.000142 
l0: 0.000136, l1: 0.000138, l2: 0.000162, l3: 0.000217, l4: 0.000338, l5: 0.000819, l6: 0.001086

[epoch: 416/1000, batch:   220/ 1052, ite: 109200] train loss: 0.004445, tar: 0.000143 
l0: 0.000457, l1: 0.000442, l2: 0.000590, l3: 0.000861, l4: 0.001241, l5: 0.001520, l6: 0.003429

[epoch: 416/1000, batch:   300/ 1052, ite: 109220] train loss: 0.004447, tar: 0.000143 
l0: 0.000104, l1: 0.000108, l2: 0.000121, l3: 0.000150, l4: 0.000409, l5: 0.000541, l6: 0.000852

[epoch: 416/1000, batch:   380/ 1052, ite: 109240] train loss: 0.004447, tar: 0.000143 
l0: 0.000246, l1: 0.000241, l2: 0.000294, l3: 0.000393, l4: 0.000766, l5: 0.001091, l6: 0.002132

[epoch: 416/1000, batch:   460/ 1052, ite: 109260] train loss: 0.004446, tar: 0.000143 
l0: 0.000062, l1: 0.000060, l2: 0.000095, l3: 0.000210, l4: 0.000237, l5: 0.000730, l6: 0.001116

[epoch: 416/1000, batch:   540/ 1052, ite: 109280] train loss: 0.004448, tar: 0.000143 
l0: 0.000159, l1: 0.000165, l2: 0.000169, l3: 0.000254, l4: 0.000418, l5: 0.001059, l6: 0.002325

[epoch: 416/1000, batch:   620/ 1052, ite: 109300] train loss: 0.004448, tar: 0.000143 
l0: 0.000097, l1: 0.000095, l2: 0.000134, l3: 0.000263, l4: 0.000531, l5: 0.001044, l6: 0.002167

[epoch: 416/1000, batch:   700/ 1052, ite: 109320] train loss: 0.004446, tar: 0.000142 
l0: 0.000055, l1: 0.000056, l2: 0.000074, l3: 0.000151, l4: 0.000302, l5: 0.000818, l6: 0.001056

[epoch: 416/1000, batch:   780/ 1052, ite: 109340] train loss: 0.004443, tar: 0.000142 
l0: 0.000080, l1: 0.000081, l2: 0.000121, l3: 0.000237, l4: 0.000537, l5: 0.001233, l6: 0.002283

[epoch: 416/1000, batch:   860/ 1052, ite: 109360] train loss: 0.004440, tar: 0.000142 
l0: 0.000100, l1: 0.000099, l2: 0.000142, l3: 0.000248, l4: 0.000363, l5: 0.000977, l6: 0.001504

[epoch: 416/1000, batch:   940/ 1052, ite: 109380] train loss: 0.004438, tar: 0.000142 
l0: 0.000101, l1: 0.000097, l2: 0.000204, l3: 0.000360, l4: 0.000686, l5: 0.001061, l6: 0.001950

[epoch: 416/1000, batch:  1020/ 1052, ite: 109400] train loss: 0.004438, tar: 0.000142 
[Epoch 416/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000282, l1: 0.000284, l2: 0.000341, l3: 0.000525, l4: 0.000978, l5: 0.001986, l6: 0.003599

[epoch: 417/1000, batch:    48/ 1052, ite: 109420] train loss: 0.004438, tar: 0.000142 
l0: 0.000132, l1: 0.000137, l2: 0.000183, l3: 0.000294, l4: 0.000526, l5: 0.001380, l6: 0.002298

[epoch: 417/1000, batch:   128/ 1052, ite: 109440] train loss: 0.004439, tar: 0.000142 
l0: 0.000137, l1: 0.000136, l2: 0.000204, l3: 0.000328, l4: 0.000638, l5: 0.001459, l6: 0.002901

[epoch: 417/1000, batch:   208/ 1052, ite: 109460] train loss: 0.004439, tar: 0.000142 
l0: 0.000094, l1: 0.000096, l2: 0.000150, l3: 0.000238, l4: 0.000378, l5: 0.000990, l6: 0.002064

[epoch: 417/1000, batch:   288/ 1052, ite: 109480] train loss: 0.004438, tar: 0.000142 
l0: 0.000143, l1: 0.000144, l2: 0.000145, l3: 0.000227, l4: 0.000583, l5: 0.001132, l6: 0.002016

[epoch: 417/1000, batch:   368/ 1052, ite: 109500] train loss: 0.004437, tar: 0.000142 
l0: 0.000120, l1: 0.000124, l2: 0.000151, l3: 0.000358, l4: 0.000642, l5: 0.001039, l6: 0.001353

[epoch: 417/1000, batch:   448/ 1052, ite: 109520] train loss: 0.004436, tar: 0.000142 
l0: 0.000034, l1: 0.000035, l2: 0.000055, l3: 0.000111, l4: 0.000320, l5: 0.000490, l6: 0.001019

[epoch: 417/1000, batch:   528/ 1052, ite: 109540] train loss: 0.004436, tar: 0.000142 
l0: 0.000154, l1: 0.000149, l2: 0.000209, l3: 0.000313, l4: 0.000430, l5: 0.000872, l6: 0.001376

[epoch: 417/1000, batch:   608/ 1052, ite: 109560] train loss: 0.004435, tar: 0.000142 
l0: 0.000039, l1: 0.000040, l2: 0.000076, l3: 0.000134, l4: 0.000343, l5: 0.000543, l6: 0.001228

[epoch: 417/1000, batch:   688/ 1052, ite: 109580] train loss: 0.004436, tar: 0.000142 
l0: 0.000208, l1: 0.000200, l2: 0.000252, l3: 0.000348, l4: 0.000544, l5: 0.001213, l6: 0.001594

[epoch: 417/1000, batch:   768/ 1052, ite: 109600] train loss: 0.004435, tar: 0.000141 
l0: 0.000133, l1: 0.000136, l2: 0.000204, l3: 0.000230, l4: 0.000470, l5: 0.000622, l6: 0.001825

[epoch: 417/1000, batch:   848/ 1052, ite: 109620] train loss: 0.004434, tar: 0.000141 
l0: 0.000370, l1: 0.000369, l2: 0.000400, l3: 0.000594, l4: 0.001091, l5: 0.002064, l6: 0.003382

[epoch: 417/1000, batch:   928/ 1052, ite: 109640] train loss: 0.004433, tar: 0.000141 
l0: 0.000303, l1: 0.000311, l2: 0.000411, l3: 0.000720, l4: 0.001346, l5: 0.001914, l6: 0.004076

[epoch: 417/1000, batch:  1008/ 1052, ite: 109660] train loss: 0.004435, tar: 0.000141 
[Epoch 417/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000196, l1: 0.000199, l2: 0.000237, l3: 0.000424, l4: 0.000848, l5: 0.001831, l6: 0.003043

[epoch: 418/1000, batch:    36/ 1052, ite: 109680] train loss: 0.004434, tar: 0.000141 
l0: 0.000042, l1: 0.000044, l2: 0.000063, l3: 0.000159, l4: 0.000216, l5: 0.000617, l6: 0.001080

[epoch: 418/1000, batch:   116/ 1052, ite: 109700] train loss: 0.004434, tar: 0.000141 
l0: 0.000140, l1: 0.000138, l2: 0.000183, l3: 0.000262, l4: 0.000386, l5: 0.000925, l6: 0.001563

[epoch: 418/1000, batch:   196/ 1052, ite: 109720] train loss: 0.004433, tar: 0.000141 
l0: 0.000065, l1: 0.000062, l2: 0.000098, l3: 0.000154, l4: 0.000221, l5: 0.000937, l6: 0.001162

[epoch: 418/1000, batch:   276/ 1052, ite: 109740] train loss: 0.004433, tar: 0.000141 
l0: 0.000254, l1: 0.000258, l2: 0.000310, l3: 0.000482, l4: 0.000810, l5: 0.002027, l6: 0.003418

[epoch: 418/1000, batch:   356/ 1052, ite: 109760] train loss: 0.004431, tar: 0.000141 
l0: 0.000198, l1: 0.000201, l2: 0.000227, l3: 0.000402, l4: 0.000940, l5: 0.001648, l6: 0.002786

[epoch: 418/1000, batch:   436/ 1052, ite: 109780] train loss: 0.004431, tar: 0.000141 
l0: 0.000050, l1: 0.000051, l2: 0.000075, l3: 0.000134, l4: 0.000401, l5: 0.000558, l6: 0.001153

[epoch: 418/1000, batch:   516/ 1052, ite: 109800] train loss: 0.004434, tar: 0.000141 
l0: 0.000179, l1: 0.000187, l2: 0.000195, l3: 0.000396, l4: 0.000755, l5: 0.001221, l6: 0.002375

[epoch: 418/1000, batch:   596/ 1052, ite: 109820] train loss: 0.004433, tar: 0.000141 
l0: 0.000072, l1: 0.000070, l2: 0.000117, l3: 0.000210, l4: 0.000428, l5: 0.001006, l6: 0.001782

[epoch: 418/1000, batch:   676/ 1052, ite: 109840] train loss: 0.004433, tar: 0.000141 
l0: 0.000112, l1: 0.000105, l2: 0.000168, l3: 0.000146, l4: 0.000316, l5: 0.000405, l6: 0.001101

[epoch: 418/1000, batch:   756/ 1052, ite: 109860] train loss: 0.004433, tar: 0.000141 
l0: 0.000090, l1: 0.000090, l2: 0.000132, l3: 0.000231, l4: 0.000532, l5: 0.000895, l6: 0.002297

[epoch: 418/1000, batch:   836/ 1052, ite: 109880] train loss: 0.004430, tar: 0.000141 
l0: 0.000146, l1: 0.000143, l2: 0.000245, l3: 0.000307, l4: 0.000637, l5: 0.001161, l6: 0.002037

[epoch: 418/1000, batch:   916/ 1052, ite: 109900] train loss: 0.004431, tar: 0.000141 
l0: 0.000077, l1: 0.000076, l2: 0.000118, l3: 0.000184, l4: 0.000586, l5: 0.000975, l6: 0.001033

[epoch: 418/1000, batch:   996/ 1052, ite: 109920] train loss: 0.004429, tar: 0.000141 
[Epoch 418/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000107, l1: 0.000111, l2: 0.000143, l3: 0.000256, l4: 0.000489, l5: 0.001333, l6: 0.001854

[epoch: 419/1000, batch:    24/ 1052, ite: 109940] train loss: 0.004429, tar: 0.000141 
l0: 0.000171, l1: 0.000174, l2: 0.000194, l3: 0.000254, l4: 0.000530, l5: 0.001541, l6: 0.002144

[epoch: 419/1000, batch:   104/ 1052, ite: 109960] train loss: 0.004429, tar: 0.000141 
l0: 0.000114, l1: 0.000115, l2: 0.000130, l3: 0.000212, l4: 0.000428, l5: 0.001334, l6: 0.002567

[epoch: 419/1000, batch:   184/ 1052, ite: 109980] train loss: 0.004427, tar: 0.000141 
l0: 0.000048, l1: 0.000048, l2: 0.000076, l3: 0.000183, l4: 0.000216, l5: 0.000919, l6: 0.001597

[epoch: 419/1000, batch:   264/ 1052, ite: 110000] train loss: 0.004426, tar: 0.000141 
l0: 0.000093, l1: 0.000098, l2: 0.000105, l3: 0.000194, l4: 0.000298, l5: 0.000981, l6: 0.001511

[epoch: 419/1000, batch:   344/ 1052, ite: 110020] train loss: 0.004425, tar: 0.000141 
l0: 0.000170, l1: 0.000169, l2: 0.000204, l3: 0.000273, l4: 0.000494, l5: 0.000882, l6: 0.001692

[epoch: 419/1000, batch:   424/ 1052, ite: 110040] train loss: 0.004424, tar: 0.000141 
l0: 0.000123, l1: 0.000123, l2: 0.000209, l3: 0.000433, l4: 0.000831, l5: 0.001523, l6: 0.003273

[epoch: 419/1000, batch:   504/ 1052, ite: 110060] train loss: 0.004426, tar: 0.000141 
l0: 0.000155, l1: 0.000146, l2: 0.000219, l3: 0.000282, l4: 0.000298, l5: 0.000711, l6: 0.001180

[epoch: 419/1000, batch:   584/ 1052, ite: 110080] train loss: 0.004427, tar: 0.000141 
l0: 0.000110, l1: 0.000109, l2: 0.000152, l3: 0.000190, l4: 0.000485, l5: 0.000995, l6: 0.001597

[epoch: 419/1000, batch:   664/ 1052, ite: 110100] train loss: 0.004426, tar: 0.000141 
l0: 0.000154, l1: 0.000153, l2: 0.000214, l3: 0.000318, l4: 0.000562, l5: 0.001302, l6: 0.002337

[epoch: 419/1000, batch:   744/ 1052, ite: 110120] train loss: 0.004426, tar: 0.000141 
l0: 0.000076, l1: 0.000080, l2: 0.000100, l3: 0.000181, l4: 0.000379, l5: 0.000717, l6: 0.000983

[epoch: 419/1000, batch:   824/ 1052, ite: 110140] train loss: 0.004424, tar: 0.000141 
l0: 0.000184, l1: 0.000186, l2: 0.000233, l3: 0.000453, l4: 0.000797, l5: 0.001495, l6: 0.002299

[epoch: 419/1000, batch:   904/ 1052, ite: 110160] train loss: 0.004423, tar: 0.000140 
l0: 0.000149, l1: 0.000152, l2: 0.000162, l3: 0.000199, l4: 0.000366, l5: 0.000674, l6: 0.001357

[epoch: 419/1000, batch:   984/ 1052, ite: 110180] train loss: 0.004423, tar: 0.000141 
[Epoch 419/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000074, l1: 0.000071, l2: 0.000121, l3: 0.000189, l4: 0.000400, l5: 0.000665, l6: 0.001227

[epoch: 420/1000, batch:    12/ 1052, ite: 110200] train loss: 0.004424, tar: 0.000141 
l0: 0.000072, l1: 0.000082, l2: 0.000059, l3: 0.000078, l4: 0.000137, l5: 0.000398, l6: 0.000458

[epoch: 420/1000, batch:    92/ 1052, ite: 110220] train loss: 0.004421, tar: 0.000141 
l0: 0.000175, l1: 0.000171, l2: 0.000227, l3: 0.000346, l4: 0.000488, l5: 0.001113, l6: 0.001792

[epoch: 420/1000, batch:   172/ 1052, ite: 110240] train loss: 0.004424, tar: 0.000141 
l0: 0.000083, l1: 0.000088, l2: 0.000114, l3: 0.000158, l4: 0.000423, l5: 0.000943, l6: 0.001416

[epoch: 420/1000, batch:   252/ 1052, ite: 110260] train loss: 0.004426, tar: 0.000141 
l0: 0.000042, l1: 0.000041, l2: 0.000079, l3: 0.000153, l4: 0.000371, l5: 0.000562, l6: 0.001133

[epoch: 420/1000, batch:   332/ 1052, ite: 110280] train loss: 0.004423, tar: 0.000140 
l0: 0.000112, l1: 0.000114, l2: 0.000156, l3: 0.000202, l4: 0.000424, l5: 0.000600, l6: 0.001206

[epoch: 420/1000, batch:   412/ 1052, ite: 110300] train loss: 0.004424, tar: 0.000140 
l0: 0.000288, l1: 0.000293, l2: 0.000344, l3: 0.000639, l4: 0.001190, l5: 0.002484, l6: 0.004762

[epoch: 420/1000, batch:   492/ 1052, ite: 110320] train loss: 0.004424, tar: 0.000141 
l0: 0.000289, l1: 0.000290, l2: 0.000402, l3: 0.000606, l4: 0.000949, l5: 0.002229, l6: 0.003946

[epoch: 420/1000, batch:   572/ 1052, ite: 110340] train loss: 0.004425, tar: 0.000141 
l0: 0.000072, l1: 0.000073, l2: 0.000090, l3: 0.000125, l4: 0.000303, l5: 0.000446, l6: 0.000992

[epoch: 420/1000, batch:   652/ 1052, ite: 110360] train loss: 0.004424, tar: 0.000141 
l0: 0.000209, l1: 0.000212, l2: 0.000203, l3: 0.000422, l4: 0.000767, l5: 0.001640, l6: 0.002247

[epoch: 420/1000, batch:   732/ 1052, ite: 110380] train loss: 0.004424, tar: 0.000141 
l0: 0.000128, l1: 0.000130, l2: 0.000145, l3: 0.000177, l4: 0.000446, l5: 0.000521, l6: 0.000877

[epoch: 420/1000, batch:   812/ 1052, ite: 110400] train loss: 0.004424, tar: 0.000141 
l0: 0.000090, l1: 0.000093, l2: 0.000126, l3: 0.000288, l4: 0.000525, l5: 0.001219, l6: 0.001515

[epoch: 420/1000, batch:   892/ 1052, ite: 110420] train loss: 0.004424, tar: 0.000140 
l0: 0.000144, l1: 0.000145, l2: 0.000163, l3: 0.000233, l4: 0.000505, l5: 0.000924, l6: 0.002232

[epoch: 420/1000, batch:   972/ 1052, ite: 110440] train loss: 0.004425, tar: 0.000140 
l0: 0.000234, l1: 0.000226, l2: 0.000312, l3: 0.000365, l4: 0.000732, l5: 0.001285, l6: 0.002919

[epoch: 420/1000, batch:  1052/ 1052, ite: 110460] train loss: 0.004422, tar: 0.000140 
[Epoch 420/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000103, l1: 0.000102, l2: 0.000118, l3: 0.000236, l4: 0.000490, l5: 0.001036, l6: 0.001553

[epoch: 421/1000, batch:    80/ 1052, ite: 110480] train loss: 0.004420, tar: 0.000140 
l0: 0.000112, l1: 0.000117, l2: 0.000165, l3: 0.000191, l4: 0.000429, l5: 0.001241, l6: 0.001945

[epoch: 421/1000, batch:   160/ 1052, ite: 110500] train loss: 0.004420, tar: 0.000140 
l0: 0.000078, l1: 0.000079, l2: 0.000123, l3: 0.000250, l4: 0.000600, l5: 0.001108, l6: 0.001916

[epoch: 421/1000, batch:   240/ 1052, ite: 110520] train loss: 0.004421, tar: 0.000140 
l0: 0.000092, l1: 0.000094, l2: 0.000118, l3: 0.000212, l4: 0.000635, l5: 0.001121, l6: 0.001452

[epoch: 421/1000, batch:   320/ 1052, ite: 110540] train loss: 0.004422, tar: 0.000140 
l0: 0.000114, l1: 0.000117, l2: 0.000149, l3: 0.000257, l4: 0.000701, l5: 0.001589, l6: 0.001855

[epoch: 421/1000, batch:   400/ 1052, ite: 110560] train loss: 0.004422, tar: 0.000140 
l0: 0.000224, l1: 0.000226, l2: 0.000266, l3: 0.000357, l4: 0.000554, l5: 0.001293, l6: 0.002564

[epoch: 421/1000, batch:   480/ 1052, ite: 110580] train loss: 0.004424, tar: 0.000140 
l0: 0.000120, l1: 0.000124, l2: 0.000125, l3: 0.000250, l4: 0.000460, l5: 0.000896, l6: 0.001233

[epoch: 421/1000, batch:   560/ 1052, ite: 110600] train loss: 0.004424, tar: 0.000140 
l0: 0.000149, l1: 0.000149, l2: 0.000206, l3: 0.000308, l4: 0.000696, l5: 0.001414, l6: 0.002557

[epoch: 421/1000, batch:   640/ 1052, ite: 110620] train loss: 0.004424, tar: 0.000140 
l0: 0.000173, l1: 0.000174, l2: 0.000217, l3: 0.000396, l4: 0.000687, l5: 0.001261, l6: 0.001726

[epoch: 421/1000, batch:   720/ 1052, ite: 110640] train loss: 0.004423, tar: 0.000140 
l0: 0.000138, l1: 0.000141, l2: 0.000173, l3: 0.000269, l4: 0.000473, l5: 0.001111, l6: 0.002168

[epoch: 421/1000, batch:   800/ 1052, ite: 110660] train loss: 0.004423, tar: 0.000140 
l0: 0.000094, l1: 0.000097, l2: 0.000124, l3: 0.000208, l4: 0.000449, l5: 0.001304, l6: 0.001242

[epoch: 421/1000, batch:   880/ 1052, ite: 110680] train loss: 0.004421, tar: 0.000140 
l0: 0.000148, l1: 0.000151, l2: 0.000177, l3: 0.000279, l4: 0.000559, l5: 0.001104, l6: 0.001792

[epoch: 421/1000, batch:   960/ 1052, ite: 110700] train loss: 0.004420, tar: 0.000140 
l0: 0.000110, l1: 0.000113, l2: 0.000132, l3: 0.000201, l4: 0.000445, l5: 0.000862, l6: 0.002382

[epoch: 421/1000, batch:  1040/ 1052, ite: 110720] train loss: 0.004419, tar: 0.000140 
[Epoch 421/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000273, l1: 0.000276, l2: 0.000294, l3: 0.000354, l4: 0.000597, l5: 0.001494, l6: 0.002203

[epoch: 422/1000, batch:    68/ 1052, ite: 110740] train loss: 0.004419, tar: 0.000140 
l0: 0.000058, l1: 0.000059, l2: 0.000109, l3: 0.000188, l4: 0.000366, l5: 0.001069, l6: 0.001540

[epoch: 422/1000, batch:   148/ 1052, ite: 110760] train loss: 0.004420, tar: 0.000140 
l0: 0.000152, l1: 0.000157, l2: 0.000221, l3: 0.000321, l4: 0.000750, l5: 0.001535, l6: 0.001967

[epoch: 422/1000, batch:   228/ 1052, ite: 110780] train loss: 0.004419, tar: 0.000140 
l0: 0.000147, l1: 0.000145, l2: 0.000186, l3: 0.000363, l4: 0.000723, l5: 0.001825, l6: 0.002286

[epoch: 422/1000, batch:   308/ 1052, ite: 110800] train loss: 0.004420, tar: 0.000140 
l0: 0.000291, l1: 0.000303, l2: 0.000314, l3: 0.000509, l4: 0.000634, l5: 0.001089, l6: 0.002201

[epoch: 422/1000, batch:   388/ 1052, ite: 110820] train loss: 0.004421, tar: 0.000140 
l0: 0.000160, l1: 0.000161, l2: 0.000196, l3: 0.000302, l4: 0.000433, l5: 0.001113, l6: 0.001937

[epoch: 422/1000, batch:   468/ 1052, ite: 110840] train loss: 0.004423, tar: 0.000140 
l0: 0.000268, l1: 0.000263, l2: 0.000303, l3: 0.000336, l4: 0.000529, l5: 0.001057, l6: 0.003054

[epoch: 422/1000, batch:   548/ 1052, ite: 110860] train loss: 0.004422, tar: 0.000140 
l0: 0.000105, l1: 0.000108, l2: 0.000172, l3: 0.000211, l4: 0.000478, l5: 0.000982, l6: 0.002044

[epoch: 422/1000, batch:   628/ 1052, ite: 110880] train loss: 0.004420, tar: 0.000140 
l0: 0.000072, l1: 0.000070, l2: 0.000096, l3: 0.000162, l4: 0.000294, l5: 0.000753, l6: 0.000916

[epoch: 422/1000, batch:   708/ 1052, ite: 110900] train loss: 0.004420, tar: 0.000140 
l0: 0.000078, l1: 0.000082, l2: 0.000117, l3: 0.000249, l4: 0.000457, l5: 0.000905, l6: 0.001123

[epoch: 422/1000, batch:   788/ 1052, ite: 110920] train loss: 0.004419, tar: 0.000140 
l0: 0.000122, l1: 0.000126, l2: 0.000156, l3: 0.000217, l4: 0.000326, l5: 0.000585, l6: 0.001797

[epoch: 422/1000, batch:   868/ 1052, ite: 110940] train loss: 0.004420, tar: 0.000140 
l0: 0.000127, l1: 0.000129, l2: 0.000146, l3: 0.000214, l4: 0.000611, l5: 0.001187, l6: 0.001382

[epoch: 422/1000, batch:   948/ 1052, ite: 110960] train loss: 0.004421, tar: 0.000140 
l0: 0.000076, l1: 0.000078, l2: 0.000085, l3: 0.000175, l4: 0.000375, l5: 0.000720, l6: 0.001093

[epoch: 422/1000, batch:  1028/ 1052, ite: 110980] train loss: 0.004422, tar: 0.000140 
[Epoch 422/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000114, l1: 0.000117, l2: 0.000135, l3: 0.000189, l4: 0.000449, l5: 0.000881, l6: 0.001559

[epoch: 423/1000, batch:    56/ 1052, ite: 111000] train loss: 0.004423, tar: 0.000140 
l0: 0.000099, l1: 0.000101, l2: 0.000124, l3: 0.000208, l4: 0.000497, l5: 0.001125, l6: 0.001729

[epoch: 423/1000, batch:   136/ 1052, ite: 111020] train loss: 0.004422, tar: 0.000140 
l0: 0.000274, l1: 0.000283, l2: 0.000278, l3: 0.000357, l4: 0.000725, l5: 0.001528, l6: 0.004258

[epoch: 423/1000, batch:   216/ 1052, ite: 111040] train loss: 0.004423, tar: 0.000140 
l0: 0.000164, l1: 0.000172, l2: 0.000267, l3: 0.000326, l4: 0.000550, l5: 0.001054, l6: 0.001955

[epoch: 423/1000, batch:   296/ 1052, ite: 111060] train loss: 0.004422, tar: 0.000140 
l0: 0.000113, l1: 0.000110, l2: 0.000142, l3: 0.000238, l4: 0.000385, l5: 0.000890, l6: 0.001651

[epoch: 423/1000, batch:   376/ 1052, ite: 111080] train loss: 0.004421, tar: 0.000140 
l0: 0.000133, l1: 0.000137, l2: 0.000164, l3: 0.000260, l4: 0.000578, l5: 0.001200, l6: 0.002359

[epoch: 423/1000, batch:   456/ 1052, ite: 111100] train loss: 0.004420, tar: 0.000140 
l0: 0.000065, l1: 0.000064, l2: 0.000086, l3: 0.000142, l4: 0.000382, l5: 0.000865, l6: 0.001419

[epoch: 423/1000, batch:   536/ 1052, ite: 111120] train loss: 0.004420, tar: 0.000140 
l0: 0.000265, l1: 0.000271, l2: 0.000333, l3: 0.000477, l4: 0.000832, l5: 0.002262, l6: 0.003168

[epoch: 423/1000, batch:   616/ 1052, ite: 111140] train loss: 0.004421, tar: 0.000140 
l0: 0.000113, l1: 0.000116, l2: 0.000111, l3: 0.000177, l4: 0.000193, l5: 0.000662, l6: 0.000936

[epoch: 423/1000, batch:   696/ 1052, ite: 111160] train loss: 0.004422, tar: 0.000140 
l0: 0.000207, l1: 0.000209, l2: 0.000271, l3: 0.000397, l4: 0.000682, l5: 0.001142, l6: 0.002213

[epoch: 423/1000, batch:   776/ 1052, ite: 111180] train loss: 0.004423, tar: 0.000140 
l0: 0.000080, l1: 0.000088, l2: 0.000113, l3: 0.000189, l4: 0.000599, l5: 0.000854, l6: 0.001453

[epoch: 423/1000, batch:   856/ 1052, ite: 111200] train loss: 0.004422, tar: 0.000140 
l0: 0.000075, l1: 0.000076, l2: 0.000093, l3: 0.000139, l4: 0.000456, l5: 0.000789, l6: 0.001533

[epoch: 423/1000, batch:   936/ 1052, ite: 111220] train loss: 0.004424, tar: 0.000140 
l0: 0.000193, l1: 0.000192, l2: 0.000251, l3: 0.000456, l4: 0.000666, l5: 0.001316, l6: 0.002078

[epoch: 423/1000, batch:  1016/ 1052, ite: 111240] train loss: 0.004422, tar: 0.000140 
[Epoch 423/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000167, l1: 0.000165, l2: 0.000237, l3: 0.000297, l4: 0.000499, l5: 0.000945, l6: 0.001786

[epoch: 424/1000, batch:    44/ 1052, ite: 111260] train loss: 0.004420, tar: 0.000140 
l0: 0.000018, l1: 0.000016, l2: 0.000059, l3: 0.000099, l4: 0.000383, l5: 0.000713, l6: 0.001470

[epoch: 424/1000, batch:   124/ 1052, ite: 111280] train loss: 0.004420, tar: 0.000139 
l0: 0.000245, l1: 0.000244, l2: 0.000337, l3: 0.000490, l4: 0.001040, l5: 0.002051, l6: 0.003859

[epoch: 424/1000, batch:   204/ 1052, ite: 111300] train loss: 0.004421, tar: 0.000140 
l0: 0.000055, l1: 0.000055, l2: 0.000085, l3: 0.000169, l4: 0.000369, l5: 0.000716, l6: 0.001581

[epoch: 424/1000, batch:   284/ 1052, ite: 111320] train loss: 0.004421, tar: 0.000139 
l0: 0.000082, l1: 0.000084, l2: 0.000113, l3: 0.000239, l4: 0.000390, l5: 0.000775, l6: 0.001257

[epoch: 424/1000, batch:   364/ 1052, ite: 111340] train loss: 0.004419, tar: 0.000139 
l0: 0.000292, l1: 0.000300, l2: 0.000319, l3: 0.000464, l4: 0.000792, l5: 0.001956, l6: 0.003060

[epoch: 424/1000, batch:   444/ 1052, ite: 111360] train loss: 0.004419, tar: 0.000139 
l0: 0.000201, l1: 0.000193, l2: 0.000228, l3: 0.000372, l4: 0.000653, l5: 0.001365, l6: 0.002623

[epoch: 424/1000, batch:   524/ 1052, ite: 111380] train loss: 0.004418, tar: 0.000139 
l0: 0.000081, l1: 0.000085, l2: 0.000102, l3: 0.000160, l4: 0.000352, l5: 0.001108, l6: 0.001420

[epoch: 424/1000, batch:   604/ 1052, ite: 111400] train loss: 0.004418, tar: 0.000139 
l0: 0.000152, l1: 0.000153, l2: 0.000231, l3: 0.000383, l4: 0.000743, l5: 0.001266, l6: 0.002521

[epoch: 424/1000, batch:   684/ 1052, ite: 111420] train loss: 0.004420, tar: 0.000139 
l0: 0.000211, l1: 0.000217, l2: 0.000217, l3: 0.000332, l4: 0.000763, l5: 0.001622, l6: 0.002630

[epoch: 424/1000, batch:   764/ 1052, ite: 111440] train loss: 0.004419, tar: 0.000139 
l0: 0.000254, l1: 0.000251, l2: 0.000241, l3: 0.000249, l4: 0.000535, l5: 0.000710, l6: 0.001172

[epoch: 424/1000, batch:   844/ 1052, ite: 111460] train loss: 0.004420, tar: 0.000139 
l0: 0.000128, l1: 0.000127, l2: 0.000186, l3: 0.000274, l4: 0.000409, l5: 0.001330, l6: 0.002134

[epoch: 424/1000, batch:   924/ 1052, ite: 111480] train loss: 0.004419, tar: 0.000139 
l0: 0.000107, l1: 0.000106, l2: 0.000156, l3: 0.000216, l4: 0.000502, l5: 0.001208, l6: 0.001884

[epoch: 424/1000, batch:  1004/ 1052, ite: 111500] train loss: 0.004419, tar: 0.000139 
[Epoch 424/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000142, l1: 0.000145, l2: 0.000194, l3: 0.000300, l4: 0.000390, l5: 0.001028, l6: 0.001927

[epoch: 425/1000, batch:    32/ 1052, ite: 111520] train loss: 0.004422, tar: 0.000139 
l0: 0.000111, l1: 0.000117, l2: 0.000120, l3: 0.000238, l4: 0.000435, l5: 0.001025, l6: 0.001733

[epoch: 425/1000, batch:   112/ 1052, ite: 111540] train loss: 0.004422, tar: 0.000139 
l0: 0.000157, l1: 0.000155, l2: 0.000179, l3: 0.000254, l4: 0.000420, l5: 0.000850, l6: 0.002743

[epoch: 425/1000, batch:   192/ 1052, ite: 111560] train loss: 0.004423, tar: 0.000139 
l0: 0.000226, l1: 0.000230, l2: 0.000263, l3: 0.000365, l4: 0.000613, l5: 0.001869, l6: 0.003257

[epoch: 425/1000, batch:   272/ 1052, ite: 111580] train loss: 0.004426, tar: 0.000140 
l0: 0.000310, l1: 0.000322, l2: 0.000320, l3: 0.000559, l4: 0.000906, l5: 0.001585, l6: 0.002802

[epoch: 425/1000, batch:   352/ 1052, ite: 111600] train loss: 0.004425, tar: 0.000140 
l0: 0.000086, l1: 0.000088, l2: 0.000135, l3: 0.000227, l4: 0.000524, l5: 0.000966, l6: 0.001143

[epoch: 425/1000, batch:   432/ 1052, ite: 111620] train loss: 0.004424, tar: 0.000139 
l0: 0.000109, l1: 0.000113, l2: 0.000146, l3: 0.000271, l4: 0.000471, l5: 0.000932, l6: 0.002018

[epoch: 425/1000, batch:   512/ 1052, ite: 111640] train loss: 0.004424, tar: 0.000139 
l0: 0.000210, l1: 0.000213, l2: 0.000245, l3: 0.000308, l4: 0.000815, l5: 0.000948, l6: 0.002819

[epoch: 425/1000, batch:   592/ 1052, ite: 111660] train loss: 0.004426, tar: 0.000139 
l0: 0.000141, l1: 0.000141, l2: 0.000164, l3: 0.000280, l4: 0.000600, l5: 0.001290, l6: 0.002016

[epoch: 425/1000, batch:   672/ 1052, ite: 111680] train loss: 0.004426, tar: 0.000139 
l0: 0.000147, l1: 0.000155, l2: 0.000163, l3: 0.000276, l4: 0.000328, l5: 0.000893, l6: 0.001813

[epoch: 425/1000, batch:   752/ 1052, ite: 111700] train loss: 0.004425, tar: 0.000139 
l0: 0.000060, l1: 0.000062, l2: 0.000075, l3: 0.000103, l4: 0.000436, l5: 0.000776, l6: 0.001269

[epoch: 425/1000, batch:   832/ 1052, ite: 111720] train loss: 0.004423, tar: 0.000139 
l0: 0.000070, l1: 0.000070, l2: 0.000115, l3: 0.000196, l4: 0.000492, l5: 0.000893, l6: 0.001284

[epoch: 425/1000, batch:   912/ 1052, ite: 111740] train loss: 0.004422, tar: 0.000139 
l0: 0.000228, l1: 0.000230, l2: 0.000274, l3: 0.000362, l4: 0.000644, l5: 0.001747, l6: 0.003811

[epoch: 425/1000, batch:   992/ 1052, ite: 111760] train loss: 0.004422, tar: 0.000139 
[Epoch 425/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000152, l1: 0.000157, l2: 0.000183, l3: 0.000236, l4: 0.000512, l5: 0.001052, l6: 0.001282

[epoch: 426/1000, batch:    20/ 1052, ite: 111780] train loss: 0.004422, tar: 0.000139 
l0: 0.000137, l1: 0.000144, l2: 0.000172, l3: 0.000345, l4: 0.000848, l5: 0.002069, l6: 0.002325

[epoch: 426/1000, batch:   100/ 1052, ite: 111800] train loss: 0.004422, tar: 0.000139 
l0: 0.000133, l1: 0.000139, l2: 0.000153, l3: 0.000289, l4: 0.000562, l5: 0.001141, l6: 0.002426

[epoch: 426/1000, batch:   180/ 1052, ite: 111820] train loss: 0.004421, tar: 0.000139 
l0: 0.000083, l1: 0.000079, l2: 0.000135, l3: 0.000211, l4: 0.000263, l5: 0.000580, l6: 0.001185

[epoch: 426/1000, batch:   260/ 1052, ite: 111840] train loss: 0.004421, tar: 0.000139 
l0: 0.000198, l1: 0.000196, l2: 0.000302, l3: 0.000608, l4: 0.000905, l5: 0.001892, l6: 0.004189

[epoch: 426/1000, batch:   340/ 1052, ite: 111860] train loss: 0.004422, tar: 0.000139 
l0: 0.000074, l1: 0.000075, l2: 0.000111, l3: 0.000146, l4: 0.000234, l5: 0.000631, l6: 0.001106

[epoch: 426/1000, batch:   420/ 1052, ite: 111880] train loss: 0.004421, tar: 0.000139 
l0: 0.000083, l1: 0.000086, l2: 0.000121, l3: 0.000246, l4: 0.000655, l5: 0.001230, l6: 0.001499

[epoch: 426/1000, batch:   500/ 1052, ite: 111900] train loss: 0.004422, tar: 0.000139 
l0: 0.000361, l1: 0.000354, l2: 0.000488, l3: 0.000541, l4: 0.000553, l5: 0.000904, l6: 0.002291

[epoch: 426/1000, batch:   580/ 1052, ite: 111920] train loss: 0.004422, tar: 0.000139 
l0: 0.000075, l1: 0.000075, l2: 0.000090, l3: 0.000160, l4: 0.000309, l5: 0.000653, l6: 0.000950

[epoch: 426/1000, batch:   660/ 1052, ite: 111940] train loss: 0.004421, tar: 0.000139 
l0: 0.000089, l1: 0.000092, l2: 0.000094, l3: 0.000187, l4: 0.000320, l5: 0.001154, l6: 0.001512

[epoch: 426/1000, batch:   740/ 1052, ite: 111960] train loss: 0.004421, tar: 0.000139 
l0: 0.000183, l1: 0.000180, l2: 0.000222, l3: 0.000427, l4: 0.000713, l5: 0.001471, l6: 0.002651

[epoch: 426/1000, batch:   820/ 1052, ite: 111980] train loss: 0.004421, tar: 0.000139 
l0: 0.000250, l1: 0.000260, l2: 0.000269, l3: 0.000288, l4: 0.000411, l5: 0.001061, l6: 0.001798

[epoch: 426/1000, batch:   900/ 1052, ite: 112000] train loss: 0.004421, tar: 0.000139 
l0: 0.000110, l1: 0.000109, l2: 0.000147, l3: 0.000243, l4: 0.000576, l5: 0.001080, l6: 0.002020

[epoch: 426/1000, batch:   980/ 1052, ite: 112020] train loss: 0.004421, tar: 0.000139 
[Epoch 426/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000230, l1: 0.000222, l2: 0.000382, l3: 0.000562, l4: 0.000978, l5: 0.001695, l6: 0.004043

[epoch: 427/1000, batch:     8/ 1052, ite: 112040] train loss: 0.004423, tar: 0.000139 
l0: 0.000142, l1: 0.000142, l2: 0.000198, l3: 0.000331, l4: 0.000624, l5: 0.001332, l6: 0.001907

[epoch: 427/1000, batch:    88/ 1052, ite: 112060] train loss: 0.004423, tar: 0.000139 
l0: 0.000220, l1: 0.000221, l2: 0.000247, l3: 0.000287, l4: 0.000541, l5: 0.001332, l6: 0.003048

[epoch: 427/1000, batch:   168/ 1052, ite: 112080] train loss: 0.004424, tar: 0.000139 
l0: 0.000111, l1: 0.000113, l2: 0.000116, l3: 0.000153, l4: 0.000469, l5: 0.000691, l6: 0.001280

[epoch: 427/1000, batch:   248/ 1052, ite: 112100] train loss: 0.004423, tar: 0.000139 
l0: 0.000148, l1: 0.000152, l2: 0.000168, l3: 0.000338, l4: 0.000614, l5: 0.001130, l6: 0.001694

[epoch: 427/1000, batch:   328/ 1052, ite: 112120] train loss: 0.004423, tar: 0.000139 
l0: 0.000343, l1: 0.000360, l2: 0.000357, l3: 0.000602, l4: 0.001386, l5: 0.002014, l6: 0.004608

[epoch: 427/1000, batch:   408/ 1052, ite: 112140] train loss: 0.004423, tar: 0.000139 
l0: 0.000158, l1: 0.000159, l2: 0.000184, l3: 0.000257, l4: 0.000517, l5: 0.001357, l6: 0.002271

[epoch: 427/1000, batch:   488/ 1052, ite: 112160] train loss: 0.004424, tar: 0.000139 
l0: 0.000108, l1: 0.000112, l2: 0.000116, l3: 0.000137, l4: 0.000310, l5: 0.000879, l6: 0.001166

[epoch: 427/1000, batch:   568/ 1052, ite: 112180] train loss: 0.004423, tar: 0.000139 
l0: 0.000152, l1: 0.000155, l2: 0.000171, l3: 0.000303, l4: 0.000525, l5: 0.000780, l6: 0.002050

[epoch: 427/1000, batch:   648/ 1052, ite: 112200] train loss: 0.004424, tar: 0.000139 
l0: 0.000107, l1: 0.000106, l2: 0.000156, l3: 0.000218, l4: 0.000430, l5: 0.001100, l6: 0.001713

[epoch: 427/1000, batch:   728/ 1052, ite: 112220] train loss: 0.004424, tar: 0.000139 
l0: 0.000103, l1: 0.000106, l2: 0.000109, l3: 0.000189, l4: 0.000269, l5: 0.000681, l6: 0.001466

[epoch: 427/1000, batch:   808/ 1052, ite: 112240] train loss: 0.004424, tar: 0.000139 
l0: 0.000106, l1: 0.000107, l2: 0.000124, l3: 0.000186, l4: 0.000483, l5: 0.001158, l6: 0.002393

[epoch: 427/1000, batch:   888/ 1052, ite: 112260] train loss: 0.004424, tar: 0.000139 
l0: 0.000145, l1: 0.000143, l2: 0.000193, l3: 0.000263, l4: 0.000636, l5: 0.001578, l6: 0.002238

[epoch: 427/1000, batch:   968/ 1052, ite: 112280] train loss: 0.004424, tar: 0.000139 
l0: 0.000068, l1: 0.000072, l2: 0.000062, l3: 0.000140, l4: 0.000388, l5: 0.000675, l6: 0.001045

[epoch: 427/1000, batch:  1048/ 1052, ite: 112300] train loss: 0.004423, tar: 0.000139 
[Epoch 427/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000067, l1: 0.000071, l2: 0.000060, l3: 0.000126, l4: 0.000256, l5: 0.000573, l6: 0.001260

[epoch: 428/1000, batch:    76/ 1052, ite: 112320] train loss: 0.004423, tar: 0.000139 
l0: 0.000154, l1: 0.000154, l2: 0.000207, l3: 0.000434, l4: 0.001148, l5: 0.002023, l6: 0.003723

[epoch: 428/1000, batch:   156/ 1052, ite: 112340] train loss: 0.004424, tar: 0.000139 
l0: 0.000151, l1: 0.000151, l2: 0.000255, l3: 0.000418, l4: 0.000716, l5: 0.000690, l6: 0.002143

[epoch: 428/1000, batch:   236/ 1052, ite: 112360] train loss: 0.004423, tar: 0.000139 
l0: 0.000082, l1: 0.000079, l2: 0.000094, l3: 0.000146, l4: 0.000185, l5: 0.000625, l6: 0.000845

[epoch: 428/1000, batch:   316/ 1052, ite: 112380] train loss: 0.004424, tar: 0.000139 
l0: 0.000069, l1: 0.000072, l2: 0.000115, l3: 0.000201, l4: 0.000358, l5: 0.000755, l6: 0.002983

[epoch: 428/1000, batch:   396/ 1052, ite: 112400] train loss: 0.004422, tar: 0.000139 
l0: 0.000105, l1: 0.000102, l2: 0.000195, l3: 0.000298, l4: 0.000560, l5: 0.000855, l6: 0.002095

[epoch: 428/1000, batch:   476/ 1052, ite: 112420] train loss: 0.004422, tar: 0.000139 
l0: 0.000082, l1: 0.000079, l2: 0.000136, l3: 0.000257, l4: 0.000354, l5: 0.001283, l6: 0.001852

[epoch: 428/1000, batch:   556/ 1052, ite: 112440] train loss: 0.004423, tar: 0.000139 
l0: 0.000243, l1: 0.000243, l2: 0.000291, l3: 0.000443, l4: 0.000584, l5: 0.001338, l6: 0.002613

[epoch: 428/1000, batch:   636/ 1052, ite: 112460] train loss: 0.004422, tar: 0.000139 
l0: 0.000075, l1: 0.000078, l2: 0.000079, l3: 0.000122, l4: 0.000446, l5: 0.000939, l6: 0.001534

[epoch: 428/1000, batch:   716/ 1052, ite: 112480] train loss: 0.004422, tar: 0.000139 
l0: 0.000105, l1: 0.000103, l2: 0.000146, l3: 0.000211, l4: 0.000389, l5: 0.000939, l6: 0.001395

[epoch: 428/1000, batch:   796/ 1052, ite: 112500] train loss: 0.004422, tar: 0.000139 
l0: 0.000164, l1: 0.000166, l2: 0.000203, l3: 0.000429, l4: 0.000677, l5: 0.001768, l6: 0.003484

[epoch: 428/1000, batch:   876/ 1052, ite: 112520] train loss: 0.004422, tar: 0.000139 
l0: 0.000066, l1: 0.000066, l2: 0.000086, l3: 0.000126, l4: 0.000291, l5: 0.000647, l6: 0.001367

[epoch: 428/1000, batch:   956/ 1052, ite: 112540] train loss: 0.004422, tar: 0.000139 
l0: 0.000134, l1: 0.000135, l2: 0.000157, l3: 0.000179, l4: 0.000549, l5: 0.001062, l6: 0.001703

[epoch: 428/1000, batch:  1036/ 1052, ite: 112560] train loss: 0.004421, tar: 0.000139 
[Epoch 428/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000138, l1: 0.000137, l2: 0.000182, l3: 0.000275, l4: 0.000523, l5: 0.001352, l6: 0.001594

[epoch: 429/1000, batch:    64/ 1052, ite: 112580] train loss: 0.004421, tar: 0.000139 
l0: 0.000189, l1: 0.000186, l2: 0.000259, l3: 0.000425, l4: 0.001004, l5: 0.001298, l6: 0.002778

[epoch: 429/1000, batch:   144/ 1052, ite: 112600] train loss: 0.004419, tar: 0.000139 
l0: 0.000136, l1: 0.000141, l2: 0.000174, l3: 0.000283, l4: 0.000591, l5: 0.001586, l6: 0.003216

[epoch: 429/1000, batch:   224/ 1052, ite: 112620] train loss: 0.004418, tar: 0.000139 
l0: 0.000038, l1: 0.000041, l2: 0.000052, l3: 0.000103, l4: 0.000316, l5: 0.000753, l6: 0.000966

[epoch: 429/1000, batch:   304/ 1052, ite: 112640] train loss: 0.004418, tar: 0.000139 
l0: 0.000143, l1: 0.000146, l2: 0.000221, l3: 0.000314, l4: 0.000677, l5: 0.001231, l6: 0.002243

[epoch: 429/1000, batch:   384/ 1052, ite: 112660] train loss: 0.004418, tar: 0.000139 
l0: 0.000142, l1: 0.000136, l2: 0.000176, l3: 0.000264, l4: 0.000459, l5: 0.000963, l6: 0.001616

[epoch: 429/1000, batch:   464/ 1052, ite: 112680] train loss: 0.004417, tar: 0.000139 
l0: 0.000176, l1: 0.000176, l2: 0.000285, l3: 0.000741, l4: 0.001416, l5: 0.002933, l6: 0.004843

[epoch: 429/1000, batch:   544/ 1052, ite: 112700] train loss: 0.004417, tar: 0.000139 
l0: 0.000083, l1: 0.000083, l2: 0.000118, l3: 0.000144, l4: 0.000311, l5: 0.000543, l6: 0.001553

[epoch: 429/1000, batch:   624/ 1052, ite: 112720] train loss: 0.004416, tar: 0.000138 
l0: 0.000120, l1: 0.000120, l2: 0.000158, l3: 0.000289, l4: 0.000403, l5: 0.001035, l6: 0.001265

[epoch: 429/1000, batch:   704/ 1052, ite: 112740] train loss: 0.004416, tar: 0.000138 
l0: 0.000143, l1: 0.000144, l2: 0.000228, l3: 0.000443, l4: 0.000792, l5: 0.001691, l6: 0.002459

[epoch: 429/1000, batch:   784/ 1052, ite: 112760] train loss: 0.004416, tar: 0.000138 
l0: 0.000291, l1: 0.000297, l2: 0.000320, l3: 0.000454, l4: 0.000681, l5: 0.001355, l6: 0.003471

[epoch: 429/1000, batch:   864/ 1052, ite: 112780] train loss: 0.004418, tar: 0.000139 
l0: 0.000274, l1: 0.000278, l2: 0.000319, l3: 0.000523, l4: 0.000916, l5: 0.001976, l6: 0.002533

[epoch: 429/1000, batch:   944/ 1052, ite: 112800] train loss: 0.004419, tar: 0.000139 
l0: 0.000093, l1: 0.000088, l2: 0.000163, l3: 0.000191, l4: 0.000324, l5: 0.000693, l6: 0.001198

[epoch: 429/1000, batch:  1024/ 1052, ite: 112820] train loss: 0.004419, tar: 0.000139 
[Epoch 429/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000099, l1: 0.000097, l2: 0.000135, l3: 0.000225, l4: 0.000445, l5: 0.000875, l6: 0.001264

[epoch: 430/1000, batch:    52/ 1052, ite: 112840] train loss: 0.004418, tar: 0.000139 
l0: 0.000182, l1: 0.000179, l2: 0.000233, l3: 0.000296, l4: 0.000573, l5: 0.001247, l6: 0.002646

[epoch: 430/1000, batch:   132/ 1052, ite: 112860] train loss: 0.004418, tar: 0.000139 
l0: 0.000174, l1: 0.000184, l2: 0.000193, l3: 0.000231, l4: 0.000338, l5: 0.001073, l6: 0.001787

[epoch: 430/1000, batch:   212/ 1052, ite: 112880] train loss: 0.004418, tar: 0.000139 
l0: 0.000144, l1: 0.000145, l2: 0.000178, l3: 0.000229, l4: 0.000746, l5: 0.001351, l6: 0.002236

[epoch: 430/1000, batch:   292/ 1052, ite: 112900] train loss: 0.004417, tar: 0.000138 
l0: 0.000064, l1: 0.000064, l2: 0.000153, l3: 0.000290, l4: 0.000414, l5: 0.000791, l6: 0.001853

[epoch: 430/1000, batch:   372/ 1052, ite: 112920] train loss: 0.004416, tar: 0.000138 
l0: 0.000204, l1: 0.000211, l2: 0.000270, l3: 0.000345, l4: 0.000909, l5: 0.001767, l6: 0.003013

[epoch: 430/1000, batch:   452/ 1052, ite: 112940] train loss: 0.004416, tar: 0.000138 
l0: 0.000093, l1: 0.000091, l2: 0.000151, l3: 0.000330, l4: 0.000574, l5: 0.001464, l6: 0.002903

[epoch: 430/1000, batch:   532/ 1052, ite: 112960] train loss: 0.004416, tar: 0.000138 
l0: 0.000084, l1: 0.000084, l2: 0.000122, l3: 0.000205, l4: 0.000382, l5: 0.000993, l6: 0.001526

[epoch: 430/1000, batch:   612/ 1052, ite: 112980] train loss: 0.004415, tar: 0.000138 
l0: 0.000114, l1: 0.000115, l2: 0.000145, l3: 0.000181, l4: 0.000333, l5: 0.000936, l6: 0.002535

[epoch: 430/1000, batch:   692/ 1052, ite: 113000] train loss: 0.004415, tar: 0.000138 
l0: 0.000266, l1: 0.000264, l2: 0.000244, l3: 0.000272, l4: 0.000511, l5: 0.001342, l6: 0.002397

[epoch: 430/1000, batch:   772/ 1052, ite: 113020] train loss: 0.004417, tar: 0.000138 
l0: 0.000056, l1: 0.000056, l2: 0.000077, l3: 0.000114, l4: 0.000302, l5: 0.000502, l6: 0.000948

[epoch: 430/1000, batch:   852/ 1052, ite: 113040] train loss: 0.004417, tar: 0.000138 
l0: 0.000089, l1: 0.000087, l2: 0.000152, l3: 0.000224, l4: 0.000503, l5: 0.001116, l6: 0.002039

[epoch: 430/1000, batch:   932/ 1052, ite: 113060] train loss: 0.004418, tar: 0.000138 
l0: 0.000145, l1: 0.000146, l2: 0.000192, l3: 0.000338, l4: 0.000566, l5: 0.001609, l6: 0.003124

[epoch: 430/1000, batch:  1012/ 1052, ite: 113080] train loss: 0.004418, tar: 0.000138 
[Epoch 430/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000094, l1: 0.000099, l2: 0.000174, l3: 0.000321, l4: 0.000502, l5: 0.001225, l6: 0.002443

[epoch: 431/1000, batch:    40/ 1052, ite: 113100] train loss: 0.004417, tar: 0.000138 
l0: 0.000124, l1: 0.000125, l2: 0.000171, l3: 0.000276, l4: 0.000643, l5: 0.001305, l6: 0.002387

[epoch: 431/1000, batch:   120/ 1052, ite: 113120] train loss: 0.004418, tar: 0.000138 
l0: 0.000072, l1: 0.000071, l2: 0.000102, l3: 0.000141, l4: 0.000375, l5: 0.001061, l6: 0.001129

[epoch: 431/1000, batch:   200/ 1052, ite: 113140] train loss: 0.004419, tar: 0.000138 
l0: 0.000101, l1: 0.000102, l2: 0.000126, l3: 0.000208, l4: 0.000540, l5: 0.000898, l6: 0.001370

[epoch: 431/1000, batch:   280/ 1052, ite: 113160] train loss: 0.004418, tar: 0.000138 
l0: 0.000098, l1: 0.000100, l2: 0.000113, l3: 0.000138, l4: 0.000337, l5: 0.000810, l6: 0.001671

[epoch: 431/1000, batch:   360/ 1052, ite: 113180] train loss: 0.004418, tar: 0.000138 
l0: 0.000120, l1: 0.000117, l2: 0.000183, l3: 0.000242, l4: 0.000470, l5: 0.001099, l6: 0.001929

[epoch: 431/1000, batch:   440/ 1052, ite: 113200] train loss: 0.004418, tar: 0.000138 
l0: 0.000057, l1: 0.000059, l2: 0.000069, l3: 0.000197, l4: 0.000408, l5: 0.000719, l6: 0.000605

[epoch: 431/1000, batch:   520/ 1052, ite: 113220] train loss: 0.004418, tar: 0.000138 
l0: 0.000109, l1: 0.000107, l2: 0.000146, l3: 0.000194, l4: 0.000445, l5: 0.000824, l6: 0.001915

[epoch: 431/1000, batch:   600/ 1052, ite: 113240] train loss: 0.004418, tar: 0.000138 
l0: 0.000081, l1: 0.000079, l2: 0.000133, l3: 0.000187, l4: 0.000386, l5: 0.000535, l6: 0.001237

[epoch: 431/1000, batch:   680/ 1052, ite: 113260] train loss: 0.004417, tar: 0.000138 
l0: 0.000297, l1: 0.000299, l2: 0.000325, l3: 0.000375, l4: 0.000622, l5: 0.001154, l6: 0.001875

[epoch: 431/1000, batch:   760/ 1052, ite: 113280] train loss: 0.004417, tar: 0.000138 
l0: 0.000128, l1: 0.000127, l2: 0.000175, l3: 0.000226, l4: 0.000319, l5: 0.000693, l6: 0.001070

[epoch: 431/1000, batch:   840/ 1052, ite: 113300] train loss: 0.004416, tar: 0.000138 
l0: 0.000093, l1: 0.000092, l2: 0.000161, l3: 0.000274, l4: 0.000520, l5: 0.001379, l6: 0.002455

[epoch: 431/1000, batch:   920/ 1052, ite: 113320] train loss: 0.004417, tar: 0.000138 
l0: 0.000044, l1: 0.000045, l2: 0.000092, l3: 0.000189, l4: 0.000496, l5: 0.000599, l6: 0.001727

[epoch: 431/1000, batch:  1000/ 1052, ite: 113340] train loss: 0.004416, tar: 0.000138 
[Epoch 431/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000254, l1: 0.000257, l2: 0.000301, l3: 0.000468, l4: 0.000893, l5: 0.001586, l6: 0.003407

[epoch: 432/1000, batch:    28/ 1052, ite: 113360] train loss: 0.004416, tar: 0.000138 
l0: 0.000098, l1: 0.000093, l2: 0.000119, l3: 0.000189, l4: 0.000425, l5: 0.000921, l6: 0.001215

[epoch: 432/1000, batch:   108/ 1052, ite: 113380] train loss: 0.004416, tar: 0.000138 
l0: 0.000252, l1: 0.000260, l2: 0.000265, l3: 0.000304, l4: 0.000870, l5: 0.001380, l6: 0.003297

[epoch: 432/1000, batch:   188/ 1052, ite: 113400] train loss: 0.004416, tar: 0.000138 
l0: 0.000195, l1: 0.000200, l2: 0.000234, l3: 0.000356, l4: 0.000574, l5: 0.001334, l6: 0.002215

[epoch: 432/1000, batch:   268/ 1052, ite: 113420] train loss: 0.004416, tar: 0.000138 
l0: 0.000126, l1: 0.000126, l2: 0.000178, l3: 0.000193, l4: 0.000557, l5: 0.001236, l6: 0.001781

[epoch: 432/1000, batch:   348/ 1052, ite: 113440] train loss: 0.004416, tar: 0.000138 
l0: 0.000094, l1: 0.000096, l2: 0.000122, l3: 0.000200, l4: 0.000392, l5: 0.001101, l6: 0.001413

[epoch: 432/1000, batch:   428/ 1052, ite: 113460] train loss: 0.004417, tar: 0.000138 
l0: 0.000179, l1: 0.000178, l2: 0.000215, l3: 0.000328, l4: 0.000771, l5: 0.001394, l6: 0.003152

[epoch: 432/1000, batch:   508/ 1052, ite: 113480] train loss: 0.004417, tar: 0.000138 
l0: 0.000066, l1: 0.000068, l2: 0.000087, l3: 0.000116, l4: 0.000285, l5: 0.000757, l6: 0.001372

[epoch: 432/1000, batch:   588/ 1052, ite: 113500] train loss: 0.004418, tar: 0.000138 
l0: 0.000153, l1: 0.000152, l2: 0.000198, l3: 0.000323, l4: 0.000576, l5: 0.001454, l6: 0.002694

[epoch: 432/1000, batch:   668/ 1052, ite: 113520] train loss: 0.004417, tar: 0.000138 
l0: 0.000070, l1: 0.000072, l2: 0.000076, l3: 0.000134, l4: 0.000348, l5: 0.000649, l6: 0.001279

[epoch: 432/1000, batch:   748/ 1052, ite: 113540] train loss: 0.004417, tar: 0.000138 
l0: 0.000136, l1: 0.000134, l2: 0.000204, l3: 0.000298, l4: 0.000472, l5: 0.001025, l6: 0.001910

[epoch: 432/1000, batch:   828/ 1052, ite: 113560] train loss: 0.004416, tar: 0.000137 
l0: 0.000192, l1: 0.000190, l2: 0.000231, l3: 0.000240, l4: 0.000454, l5: 0.001311, l6: 0.001899

[epoch: 432/1000, batch:   908/ 1052, ite: 113580] train loss: 0.004416, tar: 0.000137 
l0: 0.000089, l1: 0.000091, l2: 0.000098, l3: 0.000140, l4: 0.000344, l5: 0.000683, l6: 0.001091

[epoch: 432/1000, batch:   988/ 1052, ite: 113600] train loss: 0.004416, tar: 0.000137 
[Epoch 432/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000061, l1: 0.000063, l2: 0.000078, l3: 0.000165, l4: 0.000280, l5: 0.000805, l6: 0.001328

[epoch: 433/1000, batch:    16/ 1052, ite: 113620] train loss: 0.004415, tar: 0.000137 
l0: 0.000230, l1: 0.000231, l2: 0.000341, l3: 0.000599, l4: 0.001075, l5: 0.002580, l6: 0.003683

[epoch: 433/1000, batch:    96/ 1052, ite: 113640] train loss: 0.004415, tar: 0.000137 
l0: 0.000061, l1: 0.000059, l2: 0.000089, l3: 0.000157, l4: 0.000349, l5: 0.000747, l6: 0.001150

[epoch: 433/1000, batch:   176/ 1052, ite: 113660] train loss: 0.004416, tar: 0.000137 
l0: 0.000079, l1: 0.000078, l2: 0.000112, l3: 0.000174, l4: 0.000448, l5: 0.000938, l6: 0.001331

[epoch: 433/1000, batch:   256/ 1052, ite: 113680] train loss: 0.004415, tar: 0.000137 
l0: 0.000244, l1: 0.000251, l2: 0.000274, l3: 0.000386, l4: 0.000842, l5: 0.002391, l6: 0.004104

[epoch: 433/1000, batch:   336/ 1052, ite: 113700] train loss: 0.004415, tar: 0.000137 
l0: 0.000077, l1: 0.000081, l2: 0.000126, l3: 0.000225, l4: 0.000393, l5: 0.000599, l6: 0.001170

[epoch: 433/1000, batch:   416/ 1052, ite: 113720] train loss: 0.004414, tar: 0.000137 
l0: 0.000188, l1: 0.000195, l2: 0.000231, l3: 0.000405, l4: 0.000877, l5: 0.002094, l6: 0.003389

[epoch: 433/1000, batch:   496/ 1052, ite: 113740] train loss: 0.004413, tar: 0.000137 
l0: 0.000048, l1: 0.000046, l2: 0.000070, l3: 0.000146, l4: 0.000312, l5: 0.000754, l6: 0.000887

[epoch: 433/1000, batch:   576/ 1052, ite: 113760] train loss: 0.004412, tar: 0.000137 
l0: 0.000165, l1: 0.000176, l2: 0.000223, l3: 0.000248, l4: 0.000440, l5: 0.000971, l6: 0.002641

[epoch: 433/1000, batch:   656/ 1052, ite: 113780] train loss: 0.004412, tar: 0.000137 
l0: 0.000166, l1: 0.000165, l2: 0.000197, l3: 0.000224, l4: 0.000363, l5: 0.001202, l6: 0.002071

[epoch: 433/1000, batch:   736/ 1052, ite: 113800] train loss: 0.004413, tar: 0.000137 
l0: 0.000048, l1: 0.000048, l2: 0.000077, l3: 0.000174, l4: 0.000386, l5: 0.000735, l6: 0.001375

[epoch: 433/1000, batch:   816/ 1052, ite: 113820] train loss: 0.004414, tar: 0.000137 
l0: 0.000180, l1: 0.000183, l2: 0.000218, l3: 0.000282, l4: 0.000366, l5: 0.001053, l6: 0.002037

[epoch: 433/1000, batch:   896/ 1052, ite: 113840] train loss: 0.004414, tar: 0.000137 
l0: 0.000089, l1: 0.000090, l2: 0.000140, l3: 0.000187, l4: 0.000370, l5: 0.000800, l6: 0.001400

[epoch: 433/1000, batch:   976/ 1052, ite: 113860] train loss: 0.004414, tar: 0.000137 
[Epoch 433/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000161, l1: 0.000162, l2: 0.000197, l3: 0.000255, l4: 0.000321, l5: 0.000784, l6: 0.001438

[epoch: 434/1000, batch:     4/ 1052, ite: 113880] train loss: 0.004413, tar: 0.000137 
l0: 0.000132, l1: 0.000136, l2: 0.000156, l3: 0.000230, l4: 0.000540, l5: 0.001166, l6: 0.001253

[epoch: 434/1000, batch:    84/ 1052, ite: 113900] train loss: 0.004413, tar: 0.000137 
l0: 0.000053, l1: 0.000054, l2: 0.000070, l3: 0.000121, l4: 0.000219, l5: 0.000599, l6: 0.001072

[epoch: 434/1000, batch:   164/ 1052, ite: 113920] train loss: 0.004412, tar: 0.000137 
l0: 0.000056, l1: 0.000056, l2: 0.000080, l3: 0.000110, l4: 0.000182, l5: 0.000721, l6: 0.001423

[epoch: 434/1000, batch:   244/ 1052, ite: 113940] train loss: 0.004412, tar: 0.000137 
l0: 0.000202, l1: 0.000205, l2: 0.000276, l3: 0.000554, l4: 0.001259, l5: 0.001627, l6: 0.003901

[epoch: 434/1000, batch:   324/ 1052, ite: 113960] train loss: 0.004414, tar: 0.000137 
l0: 0.000106, l1: 0.000118, l2: 0.000113, l3: 0.000144, l4: 0.000446, l5: 0.000856, l6: 0.001156

[epoch: 434/1000, batch:   404/ 1052, ite: 113980] train loss: 0.004414, tar: 0.000137 
l0: 0.000058, l1: 0.000059, l2: 0.000084, l3: 0.000160, l4: 0.000353, l5: 0.001031, l6: 0.001410

[epoch: 434/1000, batch:   484/ 1052, ite: 114000] train loss: 0.004414, tar: 0.000137 
l0: 0.000103, l1: 0.000102, l2: 0.000186, l3: 0.000247, l4: 0.000636, l5: 0.001450, l6: 0.001788

[epoch: 434/1000, batch:   564/ 1052, ite: 114020] train loss: 0.004416, tar: 0.000137 
l0: 0.000091, l1: 0.000092, l2: 0.000128, l3: 0.000278, l4: 0.000665, l5: 0.001457, l6: 0.002304

[epoch: 434/1000, batch:   644/ 1052, ite: 114040] train loss: 0.004416, tar: 0.000137 
l0: 0.000048, l1: 0.000046, l2: 0.000087, l3: 0.000133, l4: 0.000370, l5: 0.000758, l6: 0.001662

[epoch: 434/1000, batch:   724/ 1052, ite: 114060] train loss: 0.004415, tar: 0.000137 
l0: 0.000071, l1: 0.000071, l2: 0.000090, l3: 0.000165, l4: 0.000429, l5: 0.000883, l6: 0.001094

[epoch: 434/1000, batch:   804/ 1052, ite: 114080] train loss: 0.004414, tar: 0.000137 
l0: 0.000219, l1: 0.000221, l2: 0.000275, l3: 0.000432, l4: 0.000663, l5: 0.001369, l6: 0.003348

[epoch: 434/1000, batch:   884/ 1052, ite: 114100] train loss: 0.004414, tar: 0.000137 
l0: 0.000137, l1: 0.000136, l2: 0.000159, l3: 0.000212, l4: 0.000426, l5: 0.001087, l6: 0.002276

[epoch: 434/1000, batch:   964/ 1052, ite: 114120] train loss: 0.004412, tar: 0.000137 
l0: 0.000113, l1: 0.000108, l2: 0.000108, l3: 0.000167, l4: 0.000362, l5: 0.001015, l6: 0.001467

[epoch: 434/1000, batch:  1044/ 1052, ite: 114140] train loss: 0.004413, tar: 0.000137 
[Epoch 434/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000051, l1: 0.000051, l2: 0.000061, l3: 0.000098, l4: 0.000176, l5: 0.000636, l6: 0.001139

[epoch: 435/1000, batch:    72/ 1052, ite: 114160] train loss: 0.004412, tar: 0.000137 
l0: 0.000108, l1: 0.000110, l2: 0.000182, l3: 0.000315, l4: 0.000512, l5: 0.001329, l6: 0.003018

[epoch: 435/1000, batch:   152/ 1052, ite: 114180] train loss: 0.004412, tar: 0.000137 
l0: 0.000203, l1: 0.000208, l2: 0.000228, l3: 0.000296, l4: 0.000542, l5: 0.001080, l6: 0.002227

[epoch: 435/1000, batch:   232/ 1052, ite: 114200] train loss: 0.004412, tar: 0.000137 
l0: 0.000084, l1: 0.000084, l2: 0.000121, l3: 0.000154, l4: 0.000382, l5: 0.000908, l6: 0.001392

[epoch: 435/1000, batch:   312/ 1052, ite: 114220] train loss: 0.004412, tar: 0.000137 
l0: 0.000094, l1: 0.000094, l2: 0.000114, l3: 0.000199, l4: 0.000397, l5: 0.001257, l6: 0.002419

[epoch: 435/1000, batch:   392/ 1052, ite: 114240] train loss: 0.004412, tar: 0.000137 
l0: 0.000120, l1: 0.000120, l2: 0.000149, l3: 0.000224, l4: 0.000395, l5: 0.001053, l6: 0.001352

[epoch: 435/1000, batch:   472/ 1052, ite: 114260] train loss: 0.004410, tar: 0.000137 
l0: 0.000110, l1: 0.000110, l2: 0.000148, l3: 0.000138, l4: 0.000404, l5: 0.000830, l6: 0.001163

[epoch: 435/1000, batch:   552/ 1052, ite: 114280] train loss: 0.004411, tar: 0.000137 
l0: 0.000150, l1: 0.000151, l2: 0.000161, l3: 0.000240, l4: 0.000281, l5: 0.000774, l6: 0.001982

[epoch: 435/1000, batch:   632/ 1052, ite: 114300] train loss: 0.004411, tar: 0.000137 
l0: 0.000060, l1: 0.000062, l2: 0.000074, l3: 0.000162, l4: 0.000424, l5: 0.000615, l6: 0.001236

[epoch: 435/1000, batch:   712/ 1052, ite: 114320] train loss: 0.004412, tar: 0.000137 
l0: 0.000070, l1: 0.000068, l2: 0.000128, l3: 0.000205, l4: 0.000453, l5: 0.000861, l6: 0.001668

[epoch: 435/1000, batch:   792/ 1052, ite: 114340] train loss: 0.004412, tar: 0.000137 
l0: 0.000159, l1: 0.000166, l2: 0.000215, l3: 0.000372, l4: 0.000874, l5: 0.001617, l6: 0.003752

[epoch: 435/1000, batch:   872/ 1052, ite: 114360] train loss: 0.004411, tar: 0.000137 
l0: 0.000139, l1: 0.000143, l2: 0.000212, l3: 0.000254, l4: 0.000755, l5: 0.001902, l6: 0.002460

[epoch: 435/1000, batch:   952/ 1052, ite: 114380] train loss: 0.004411, tar: 0.000137 
l0: 0.000070, l1: 0.000070, l2: 0.000104, l3: 0.000276, l4: 0.000574, l5: 0.001195, l6: 0.002065

[epoch: 435/1000, batch:  1032/ 1052, ite: 114400] train loss: 0.004411, tar: 0.000136 
[Epoch 435/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000136, l1: 0.000133, l2: 0.000186, l3: 0.000266, l4: 0.000568, l5: 0.001556, l6: 0.002524

[epoch: 436/1000, batch:    60/ 1052, ite: 114420] train loss: 0.004410, tar: 0.000136 
l0: 0.000190, l1: 0.000191, l2: 0.000205, l3: 0.000325, l4: 0.000535, l5: 0.001459, l6: 0.002415

[epoch: 436/1000, batch:   140/ 1052, ite: 114440] train loss: 0.004412, tar: 0.000136 
l0: 0.000141, l1: 0.000135, l2: 0.000182, l3: 0.000233, l4: 0.000463, l5: 0.000746, l6: 0.001701

[epoch: 436/1000, batch:   220/ 1052, ite: 114460] train loss: 0.004411, tar: 0.000136 
l0: 0.000053, l1: 0.000051, l2: 0.000111, l3: 0.000211, l4: 0.000248, l5: 0.000738, l6: 0.001627

[epoch: 436/1000, batch:   300/ 1052, ite: 114480] train loss: 0.004410, tar: 0.000136 
l0: 0.000151, l1: 0.000148, l2: 0.000198, l3: 0.000335, l4: 0.000793, l5: 0.001595, l6: 0.001667

[epoch: 436/1000, batch:   380/ 1052, ite: 114500] train loss: 0.004409, tar: 0.000136 
l0: 0.000183, l1: 0.000183, l2: 0.000221, l3: 0.000431, l4: 0.000735, l5: 0.001488, l6: 0.001909

[epoch: 436/1000, batch:   460/ 1052, ite: 114520] train loss: 0.004409, tar: 0.000136 
l0: 0.000197, l1: 0.000197, l2: 0.000221, l3: 0.000336, l4: 0.000651, l5: 0.001469, l6: 0.001855

[epoch: 436/1000, batch:   540/ 1052, ite: 114540] train loss: 0.004410, tar: 0.000137 
l0: 0.000332, l1: 0.000345, l2: 0.000405, l3: 0.000434, l4: 0.000715, l5: 0.001033, l6: 0.001731

[epoch: 436/1000, batch:   620/ 1052, ite: 114560] train loss: 0.004413, tar: 0.000137 
l0: 0.000190, l1: 0.000198, l2: 0.000243, l3: 0.000314, l4: 0.000469, l5: 0.001371, l6: 0.001600

[epoch: 436/1000, batch:   700/ 1052, ite: 114580] train loss: 0.004415, tar: 0.000137 
l0: 0.000153, l1: 0.000154, l2: 0.000191, l3: 0.000347, l4: 0.000558, l5: 0.001085, l6: 0.002583

[epoch: 436/1000, batch:   780/ 1052, ite: 114600] train loss: 0.004417, tar: 0.000137 
l0: 0.000160, l1: 0.000156, l2: 0.000173, l3: 0.000322, l4: 0.000627, l5: 0.001443, l6: 0.002437

[epoch: 436/1000, batch:   860/ 1052, ite: 114620] train loss: 0.004416, tar: 0.000137 
l0: 0.000212, l1: 0.000219, l2: 0.000244, l3: 0.000260, l4: 0.000599, l5: 0.001876, l6: 0.002922

[epoch: 436/1000, batch:   940/ 1052, ite: 114640] train loss: 0.004419, tar: 0.000138 
l0: 0.000084, l1: 0.000085, l2: 0.000115, l3: 0.000170, l4: 0.000488, l5: 0.001071, l6: 0.001310

[epoch: 436/1000, batch:  1020/ 1052, ite: 114660] train loss: 0.004417, tar: 0.000138 
[Epoch 436/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000241, l1: 0.000246, l2: 0.000251, l3: 0.000448, l4: 0.000911, l5: 0.002179, l6: 0.003747

[epoch: 437/1000, batch:    48/ 1052, ite: 114680] train loss: 0.004418, tar: 0.000138 
l0: 0.000095, l1: 0.000096, l2: 0.000165, l3: 0.000280, l4: 0.000608, l5: 0.001046, l6: 0.001578

[epoch: 437/1000, batch:   128/ 1052, ite: 114700] train loss: 0.004419, tar: 0.000138 
l0: 0.000179, l1: 0.000180, l2: 0.000206, l3: 0.000335, l4: 0.000809, l5: 0.001613, l6: 0.002408

[epoch: 437/1000, batch:   208/ 1052, ite: 114720] train loss: 0.004420, tar: 0.000138 
l0: 0.000079, l1: 0.000079, l2: 0.000125, l3: 0.000188, l4: 0.000353, l5: 0.000626, l6: 0.001409

[epoch: 437/1000, batch:   288/ 1052, ite: 114740] train loss: 0.004420, tar: 0.000138 
l0: 0.000277, l1: 0.000283, l2: 0.000253, l3: 0.000340, l4: 0.000544, l5: 0.001297, l6: 0.001959

[epoch: 437/1000, batch:   368/ 1052, ite: 114760] train loss: 0.004420, tar: 0.000138 
l0: 0.000052, l1: 0.000050, l2: 0.000093, l3: 0.000168, l4: 0.000407, l5: 0.000719, l6: 0.001429

[epoch: 437/1000, batch:   448/ 1052, ite: 114780] train loss: 0.004420, tar: 0.000138 
l0: 0.000078, l1: 0.000075, l2: 0.000116, l3: 0.000192, l4: 0.000326, l5: 0.000986, l6: 0.001789

[epoch: 437/1000, batch:   528/ 1052, ite: 114800] train loss: 0.004421, tar: 0.000138 
l0: 0.000154, l1: 0.000159, l2: 0.000184, l3: 0.000296, l4: 0.000524, l5: 0.001160, l6: 0.002806

[epoch: 437/1000, batch:   608/ 1052, ite: 114820] train loss: 0.004421, tar: 0.000138 
l0: 0.000087, l1: 0.000090, l2: 0.000112, l3: 0.000195, l4: 0.000371, l5: 0.000688, l6: 0.001177

[epoch: 437/1000, batch:   688/ 1052, ite: 114840] train loss: 0.004423, tar: 0.000138 
l0: 0.000121, l1: 0.000121, l2: 0.000148, l3: 0.000211, l4: 0.000377, l5: 0.001173, l6: 0.001563

[epoch: 437/1000, batch:   768/ 1052, ite: 114860] train loss: 0.004422, tar: 0.000138 
l0: 0.000059, l1: 0.000061, l2: 0.000077, l3: 0.000152, l4: 0.000468, l5: 0.000963, l6: 0.001373

[epoch: 437/1000, batch:   848/ 1052, ite: 114880] train loss: 0.004421, tar: 0.000138 
l0: 0.000106, l1: 0.000106, l2: 0.000132, l3: 0.000197, l4: 0.000403, l5: 0.001081, l6: 0.001923

[epoch: 437/1000, batch:   928/ 1052, ite: 114900] train loss: 0.004420, tar: 0.000138 
l0: 0.000117, l1: 0.000115, l2: 0.000181, l3: 0.000291, l4: 0.000495, l5: 0.000579, l6: 0.001491

[epoch: 437/1000, batch:  1008/ 1052, ite: 114920] train loss: 0.004420, tar: 0.000138 
[Epoch 437/1000] Test loss: 0.016, Test target loss: 0.002
l0: 0.000125, l1: 0.000123, l2: 0.000188, l3: 0.000408, l4: 0.000708, l5: 0.001130, l6: 0.002526

[epoch: 438/1000, batch:    36/ 1052, ite: 114940] train loss: 0.004420, tar: 0.000138 
l0: 0.000132, l1: 0.000138, l2: 0.000171, l3: 0.000342, l4: 0.000506, l5: 0.001157, l6: 0.002286

[epoch: 438/1000, batch:   116/ 1052, ite: 114960] train loss: 0.004419, tar: 0.000138 
l0: 0.000210, l1: 0.000209, l2: 0.000267, l3: 0.000374, l4: 0.000760, l5: 0.001148, l6: 0.002301

[epoch: 438/1000, batch:   196/ 1052, ite: 114980] train loss: 0.004418, tar: 0.000138 
l0: 0.000366, l1: 0.000357, l2: 0.000408, l3: 0.000497, l4: 0.000568, l5: 0.001483, l6: 0.001943

[epoch: 438/1000, batch:   276/ 1052, ite: 115000] train loss: 0.004418, tar: 0.000138 
l0: 0.000147, l1: 0.000150, l2: 0.000169, l3: 0.000223, l4: 0.000392, l5: 0.001043, l6: 0.001744

[epoch: 438/1000, batch:   356/ 1052, ite: 115020] train loss: 0.004418, tar: 0.000138 
l0: 0.000147, l1: 0.000150, l2: 0.000174, l3: 0.000319, l4: 0.000603, l5: 0.001256, l6: 0.002167

[epoch: 438/1000, batch:   436/ 1052, ite: 115040] train loss: 0.004418, tar: 0.000138 
l0: 0.000070, l1: 0.000077, l2: 0.000081, l3: 0.000120, l4: 0.000368, l5: 0.000852, l6: 0.002132

[epoch: 438/1000, batch:   516/ 1052, ite: 115060] train loss: 0.004418, tar: 0.000138 
l0: 0.000158, l1: 0.000163, l2: 0.000155, l3: 0.000240, l4: 0.000443, l5: 0.001098, l6: 0.001730

[epoch: 438/1000, batch:   596/ 1052, ite: 115080] train loss: 0.004418, tar: 0.000138 
l0: 0.000064, l1: 0.000063, l2: 0.000106, l3: 0.000253, l4: 0.000479, l5: 0.000998, l6: 0.002054

[epoch: 438/1000, batch:   676/ 1052, ite: 115100] train loss: 0.004418, tar: 0.000138 
l0: 0.000057, l1: 0.000062, l2: 0.000053, l3: 0.000095, l4: 0.000515, l5: 0.000989, l6: 0.001614

[epoch: 438/1000, batch:   756/ 1052, ite: 115120] train loss: 0.004418, tar: 0.000138 
l0: 0.000088, l1: 0.000086, l2: 0.000141, l3: 0.000262, l4: 0.000501, l5: 0.000897, l6: 0.001512

[epoch: 438/1000, batch:   836/ 1052, ite: 115140] train loss: 0.004418, tar: 0.000138 
l0: 0.000226, l1: 0.000222, l2: 0.000269, l3: 0.000285, l4: 0.000459, l5: 0.000957, l6: 0.002023

[epoch: 438/1000, batch:   916/ 1052, ite: 115160] train loss: 0.004418, tar: 0.000138 
l0: 0.000103, l1: 0.000102, l2: 0.000166, l3: 0.000206, l4: 0.000469, l5: 0.001090, l6: 0.001697

[epoch: 438/1000, batch:   996/ 1052, ite: 115180] train loss: 0.004419, tar: 0.000138 
[Epoch 438/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000166, l1: 0.000177, l2: 0.000209, l3: 0.000244, l4: 0.000387, l5: 0.000871, l6: 0.002175

[epoch: 439/1000, batch:    24/ 1052, ite: 115200] train loss: 0.004419, tar: 0.000138 
l0: 0.000137, l1: 0.000136, l2: 0.000174, l3: 0.000226, l4: 0.000350, l5: 0.000996, l6: 0.001815

[epoch: 439/1000, batch:   104/ 1052, ite: 115220] train loss: 0.004419, tar: 0.000138 
l0: 0.000133, l1: 0.000136, l2: 0.000155, l3: 0.000254, l4: 0.000538, l5: 0.001163, l6: 0.001384

[epoch: 439/1000, batch:   184/ 1052, ite: 115240] train loss: 0.004419, tar: 0.000138 
l0: 0.000075, l1: 0.000074, l2: 0.000108, l3: 0.000151, l4: 0.000244, l5: 0.000753, l6: 0.000783

[epoch: 439/1000, batch:   264/ 1052, ite: 115260] train loss: 0.004419, tar: 0.000138 
l0: 0.000405, l1: 0.000424, l2: 0.000353, l3: 0.000399, l4: 0.000896, l5: 0.001770, l6: 0.002641

[epoch: 439/1000, batch:   344/ 1052, ite: 115280] train loss: 0.004419, tar: 0.000138 
l0: 0.000107, l1: 0.000104, l2: 0.000136, l3: 0.000296, l4: 0.000504, l5: 0.001325, l6: 0.002483

[epoch: 439/1000, batch:   424/ 1052, ite: 115300] train loss: 0.004419, tar: 0.000138 
l0: 0.000073, l1: 0.000077, l2: 0.000091, l3: 0.000145, l4: 0.000340, l5: 0.000947, l6: 0.001649

[epoch: 439/1000, batch:   504/ 1052, ite: 115320] train loss: 0.004418, tar: 0.000138 
l0: 0.000113, l1: 0.000113, l2: 0.000152, l3: 0.000324, l4: 0.000444, l5: 0.000999, l6: 0.001485

[epoch: 439/1000, batch:   584/ 1052, ite: 115340] train loss: 0.004418, tar: 0.000138 
l0: 0.000171, l1: 0.000176, l2: 0.000267, l3: 0.000569, l4: 0.001143, l5: 0.002009, l6: 0.003463

[epoch: 439/1000, batch:   664/ 1052, ite: 115360] train loss: 0.004418, tar: 0.000137 
l0: 0.000104, l1: 0.000104, l2: 0.000151, l3: 0.000216, l4: 0.000429, l5: 0.001025, l6: 0.001501

[epoch: 439/1000, batch:   744/ 1052, ite: 115380] train loss: 0.004418, tar: 0.000137 
l0: 0.000073, l1: 0.000067, l2: 0.000114, l3: 0.000162, l4: 0.000498, l5: 0.001127, l6: 0.002060

[epoch: 439/1000, batch:   824/ 1052, ite: 115400] train loss: 0.004416, tar: 0.000137 
l0: 0.000109, l1: 0.000111, l2: 0.000149, l3: 0.000225, l4: 0.000717, l5: 0.001314, l6: 0.002566

[epoch: 439/1000, batch:   904/ 1052, ite: 115420] train loss: 0.004416, tar: 0.000137 
l0: 0.000113, l1: 0.000118, l2: 0.000146, l3: 0.000269, l4: 0.000523, l5: 0.001067, l6: 0.002096

[epoch: 439/1000, batch:   984/ 1052, ite: 115440] train loss: 0.004417, tar: 0.000137 
[Epoch 439/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000072, l1: 0.000075, l2: 0.000102, l3: 0.000211, l4: 0.000459, l5: 0.001289, l6: 0.002550

[epoch: 440/1000, batch:    12/ 1052, ite: 115460] train loss: 0.004416, tar: 0.000137 
l0: 0.000141, l1: 0.000141, l2: 0.000234, l3: 0.000437, l4: 0.000749, l5: 0.001767, l6: 0.003177

[epoch: 440/1000, batch:    92/ 1052, ite: 115480] train loss: 0.004415, tar: 0.000137 
l0: 0.000053, l1: 0.000055, l2: 0.000090, l3: 0.000234, l4: 0.000482, l5: 0.000904, l6: 0.001834

[epoch: 440/1000, batch:   172/ 1052, ite: 115500] train loss: 0.004414, tar: 0.000137 
l0: 0.000078, l1: 0.000079, l2: 0.000119, l3: 0.000266, l4: 0.000640, l5: 0.001605, l6: 0.002013

[epoch: 440/1000, batch:   252/ 1052, ite: 115520] train loss: 0.004413, tar: 0.000137 
l0: 0.000180, l1: 0.000183, l2: 0.000200, l3: 0.000296, l4: 0.000555, l5: 0.001189, l6: 0.003218

[epoch: 440/1000, batch:   332/ 1052, ite: 115540] train loss: 0.004414, tar: 0.000137 
l0: 0.000278, l1: 0.000282, l2: 0.000337, l3: 0.000520, l4: 0.000994, l5: 0.001844, l6: 0.003444

[epoch: 440/1000, batch:   412/ 1052, ite: 115560] train loss: 0.004414, tar: 0.000137 
l0: 0.000068, l1: 0.000067, l2: 0.000091, l3: 0.000149, l4: 0.000408, l5: 0.000770, l6: 0.001316

[epoch: 440/1000, batch:   492/ 1052, ite: 115580] train loss: 0.004413, tar: 0.000137 
l0: 0.000081, l1: 0.000084, l2: 0.000114, l3: 0.000212, l4: 0.000551, l5: 0.001324, l6: 0.001570

[epoch: 440/1000, batch:   572/ 1052, ite: 115600] train loss: 0.004413, tar: 0.000137 
l0: 0.000115, l1: 0.000117, l2: 0.000132, l3: 0.000194, l4: 0.000388, l5: 0.000766, l6: 0.001857

[epoch: 440/1000, batch:   652/ 1052, ite: 115620] train loss: 0.004413, tar: 0.000137 
l0: 0.000104, l1: 0.000099, l2: 0.000188, l3: 0.000276, l4: 0.000527, l5: 0.000848, l6: 0.002696

[epoch: 440/1000, batch:   732/ 1052, ite: 115640] train loss: 0.004413, tar: 0.000137 
l0: 0.000088, l1: 0.000085, l2: 0.000178, l3: 0.000233, l4: 0.000483, l5: 0.001026, l6: 0.001615

[epoch: 440/1000, batch:   812/ 1052, ite: 115660] train loss: 0.004412, tar: 0.000137 
l0: 0.000129, l1: 0.000131, l2: 0.000156, l3: 0.000221, l4: 0.000477, l5: 0.001207, l6: 0.002454

[epoch: 440/1000, batch:   892/ 1052, ite: 115680] train loss: 0.004413, tar: 0.000137 
l0: 0.000161, l1: 0.000157, l2: 0.000213, l3: 0.000387, l4: 0.000546, l5: 0.001001, l6: 0.002295

[epoch: 440/1000, batch:   972/ 1052, ite: 115700] train loss: 0.004414, tar: 0.000137 
l0: 0.000100, l1: 0.000100, l2: 0.000191, l3: 0.000284, l4: 0.000513, l5: 0.000863, l6: 0.002056

[epoch: 440/1000, batch:  1052/ 1052, ite: 115720] train loss: 0.004414, tar: 0.000137 
[Epoch 440/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000128, l1: 0.000130, l2: 0.000143, l3: 0.000255, l4: 0.000478, l5: 0.000855, l6: 0.002576

[epoch: 441/1000, batch:    80/ 1052, ite: 115740] train loss: 0.004410, tar: 0.000114 
l0: 0.000059, l1: 0.000058, l2: 0.000104, l3: 0.000185, l4: 0.000340, l5: 0.001018, l6: 0.002093

[epoch: 441/1000, batch:   160/ 1052, ite: 115760] train loss: 0.004555, tar: 0.000113 
l0: 0.000169, l1: 0.000170, l2: 0.000186, l3: 0.000275, l4: 0.000570, l5: 0.001075, l6: 0.002409

[epoch: 441/1000, batch:   240/ 1052, ite: 115780] train loss: 0.004359, tar: 0.000115 
l0: 0.000080, l1: 0.000083, l2: 0.000127, l3: 0.000164, l4: 0.000494, l5: 0.001404, l6: 0.001413

[epoch: 441/1000, batch:   320/ 1052, ite: 115800] train loss: 0.004241, tar: 0.000112 
l0: 0.000142, l1: 0.000145, l2: 0.000189, l3: 0.000219, l4: 0.000724, l5: 0.001294, l6: 0.001851

[epoch: 441/1000, batch:   400/ 1052, ite: 115820] train loss: 0.004234, tar: 0.000111 
l0: 0.000146, l1: 0.000150, l2: 0.000223, l3: 0.000335, l4: 0.000796, l5: 0.000788, l6: 0.002240

[epoch: 441/1000, batch:   480/ 1052, ite: 115840] train loss: 0.004166, tar: 0.000110 
l0: 0.000156, l1: 0.000156, l2: 0.000206, l3: 0.000293, l4: 0.000470, l5: 0.001002, l6: 0.001486

[epoch: 441/1000, batch:   560/ 1052, ite: 115860] train loss: 0.004244, tar: 0.000116 
l0: 0.000251, l1: 0.000258, l2: 0.000304, l3: 0.000401, l4: 0.000853, l5: 0.001597, l6: 0.002426

[epoch: 441/1000, batch:   640/ 1052, ite: 115880] train loss: 0.004377, tar: 0.000119 
l0: 0.000008, l1: 0.000008, l2: 0.000025, l3: 0.000048, l4: 0.000116, l5: 0.000209, l6: 0.000343

[epoch: 441/1000, batch:   720/ 1052, ite: 115900] train loss: 0.004366, tar: 0.000118 
l0: 0.000093, l1: 0.000090, l2: 0.000152, l3: 0.000208, l4: 0.000497, l5: 0.000731, l6: 0.001216

[epoch: 441/1000, batch:   800/ 1052, ite: 115920] train loss: 0.004312, tar: 0.000117 
l0: 0.000092, l1: 0.000091, l2: 0.000085, l3: 0.000145, l4: 0.000274, l5: 0.000630, l6: 0.000656

[epoch: 441/1000, batch:   880/ 1052, ite: 115940] train loss: 0.004326, tar: 0.000118 
l0: 0.000056, l1: 0.000059, l2: 0.000084, l3: 0.000218, l4: 0.000340, l5: 0.000682, l6: 0.001378

[epoch: 441/1000, batch:   960/ 1052, ite: 115960] train loss: 0.004292, tar: 0.000117 
l0: 0.000124, l1: 0.000125, l2: 0.000143, l3: 0.000231, l4: 0.000413, l5: 0.001289, l6: 0.001856

[epoch: 441/1000, batch:  1040/ 1052, ite: 115980] train loss: 0.004306, tar: 0.000118 
[Epoch 441/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000155, l1: 0.000160, l2: 0.000209, l3: 0.000280, l4: 0.000811, l5: 0.001732, l6: 0.002831

[epoch: 442/1000, batch:    68/ 1052, ite: 116000] train loss: 0.004295, tar: 0.000118 
l0: 0.000213, l1: 0.000214, l2: 0.000384, l3: 0.000637, l4: 0.001118, l5: 0.002346, l6: 0.004433

[epoch: 442/1000, batch:   148/ 1052, ite: 116020] train loss: 0.004304, tar: 0.000117 
l0: 0.000257, l1: 0.000258, l2: 0.000325, l3: 0.000494, l4: 0.001169, l5: 0.003699, l6: 0.005583

[epoch: 442/1000, batch:   228/ 1052, ite: 116040] train loss: 0.004347, tar: 0.000118 
l0: 0.000102, l1: 0.000103, l2: 0.000120, l3: 0.000155, l4: 0.000230, l5: 0.000971, l6: 0.001217

[epoch: 442/1000, batch:   308/ 1052, ite: 116060] train loss: 0.004388, tar: 0.000119 
l0: 0.000204, l1: 0.000202, l2: 0.000271, l3: 0.000441, l4: 0.000892, l5: 0.001432, l6: 0.003001

[epoch: 442/1000, batch:   388/ 1052, ite: 116080] train loss: 0.004384, tar: 0.000119 
l0: 0.000076, l1: 0.000079, l2: 0.000104, l3: 0.000258, l4: 0.000356, l5: 0.001267, l6: 0.001903

[epoch: 442/1000, batch:   468/ 1052, ite: 116100] train loss: 0.004347, tar: 0.000118 
l0: 0.000144, l1: 0.000144, l2: 0.000268, l3: 0.000349, l4: 0.000631, l5: 0.000984, l6: 0.002652

[epoch: 442/1000, batch:   548/ 1052, ite: 116120] train loss: 0.004343, tar: 0.000116 
l0: 0.000063, l1: 0.000063, l2: 0.000133, l3: 0.000263, l4: 0.000632, l5: 0.001251, l6: 0.002571

[epoch: 442/1000, batch:   628/ 1052, ite: 116140] train loss: 0.004316, tar: 0.000116 
l0: 0.000060, l1: 0.000060, l2: 0.000091, l3: 0.000141, l4: 0.000340, l5: 0.000742, l6: 0.001531

[epoch: 442/1000, batch:   708/ 1052, ite: 116160] train loss: 0.004320, tar: 0.000116 
l0: 0.000347, l1: 0.000347, l2: 0.000436, l3: 0.000623, l4: 0.000999, l5: 0.001350, l6: 0.003293

[epoch: 442/1000, batch:   788/ 1052, ite: 116180] train loss: 0.004336, tar: 0.000116 
l0: 0.000075, l1: 0.000073, l2: 0.000118, l3: 0.000226, l4: 0.000435, l5: 0.001368, l6: 0.002008

[epoch: 442/1000, batch:   868/ 1052, ite: 116200] train loss: 0.004313, tar: 0.000115 
l0: 0.000027, l1: 0.000027, l2: 0.000057, l3: 0.000152, l4: 0.000363, l5: 0.001122, l6: 0.001315

[epoch: 442/1000, batch:   948/ 1052, ite: 116220] train loss: 0.004300, tar: 0.000114 
l0: 0.000124, l1: 0.000128, l2: 0.000132, l3: 0.000241, l4: 0.000416, l5: 0.001124, l6: 0.002120

[epoch: 442/1000, batch:  1028/ 1052, ite: 116240] train loss: 0.004304, tar: 0.000114 
[Epoch 442/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000126, l1: 0.000121, l2: 0.000184, l3: 0.000249, l4: 0.000515, l5: 0.001246, l6: 0.001938

[epoch: 443/1000, batch:    56/ 1052, ite: 116260] train loss: 0.004307, tar: 0.000114 
l0: 0.000140, l1: 0.000142, l2: 0.000190, l3: 0.000243, l4: 0.000543, l5: 0.001375, l6: 0.003224

[epoch: 443/1000, batch:   136/ 1052, ite: 116280] train loss: 0.004315, tar: 0.000114 
l0: 0.000067, l1: 0.000071, l2: 0.000098, l3: 0.000198, l4: 0.000541, l5: 0.001200, l6: 0.001837

[epoch: 443/1000, batch:   216/ 1052, ite: 116300] train loss: 0.004338, tar: 0.000115 
l0: 0.000051, l1: 0.000047, l2: 0.000093, l3: 0.000149, l4: 0.000318, l5: 0.000801, l6: 0.001345

[epoch: 443/1000, batch:   296/ 1052, ite: 116320] train loss: 0.004346, tar: 0.000116 
l0: 0.000090, l1: 0.000089, l2: 0.000131, l3: 0.000217, l4: 0.000533, l5: 0.000962, l6: 0.001969

[epoch: 443/1000, batch:   376/ 1052, ite: 116340] train loss: 0.004337, tar: 0.000115 
l0: 0.000130, l1: 0.000136, l2: 0.000176, l3: 0.000272, l4: 0.000442, l5: 0.001014, l6: 0.002137

[epoch: 443/1000, batch:   456/ 1052, ite: 116360] train loss: 0.004329, tar: 0.000115 
l0: 0.000120, l1: 0.000120, l2: 0.000149, l3: 0.000244, l4: 0.000437, l5: 0.001174, l6: 0.001774

[epoch: 443/1000, batch:   536/ 1052, ite: 116380] train loss: 0.004326, tar: 0.000115 
l0: 0.000229, l1: 0.000229, l2: 0.000263, l3: 0.000530, l4: 0.000902, l5: 0.001700, l6: 0.002852

[epoch: 443/1000, batch:   616/ 1052, ite: 116400] train loss: 0.004339, tar: 0.000116 
l0: 0.000086, l1: 0.000085, l2: 0.000128, l3: 0.000374, l4: 0.000619, l5: 0.001509, l6: 0.002777

[epoch: 443/1000, batch:   696/ 1052, ite: 116420] train loss: 0.004331, tar: 0.000116 
l0: 0.000130, l1: 0.000128, l2: 0.000251, l3: 0.000548, l4: 0.000977, l5: 0.002307, l6: 0.002378

[epoch: 443/1000, batch:   776/ 1052, ite: 116440] train loss: 0.004337, tar: 0.000116 
l0: 0.000147, l1: 0.000149, l2: 0.000160, l3: 0.000285, l4: 0.000549, l5: 0.001174, l6: 0.001750

[epoch: 443/1000, batch:   856/ 1052, ite: 116460] train loss: 0.004333, tar: 0.000115 
l0: 0.000119, l1: 0.000119, l2: 0.000125, l3: 0.000213, l4: 0.000598, l5: 0.000941, l6: 0.001477

[epoch: 443/1000, batch:   936/ 1052, ite: 116480] train loss: 0.004328, tar: 0.000115 
l0: 0.000147, l1: 0.000145, l2: 0.000190, l3: 0.000329, l4: 0.000681, l5: 0.001045, l6: 0.002414

[epoch: 443/1000, batch:  1016/ 1052, ite: 116500] train loss: 0.004325, tar: 0.000115 
[Epoch 443/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000058, l1: 0.000058, l2: 0.000071, l3: 0.000162, l4: 0.000339, l5: 0.000543, l6: 0.000851

[epoch: 444/1000, batch:    44/ 1052, ite: 116520] train loss: 0.004320, tar: 0.000114 
l0: 0.000218, l1: 0.000217, l2: 0.000306, l3: 0.000384, l4: 0.000860, l5: 0.001401, l6: 0.001823

[epoch: 444/1000, batch:   124/ 1052, ite: 116540] train loss: 0.004316, tar: 0.000114 
l0: 0.000058, l1: 0.000057, l2: 0.000101, l3: 0.000280, l4: 0.000677, l5: 0.001262, l6: 0.001935

[epoch: 444/1000, batch:   204/ 1052, ite: 116560] train loss: 0.004314, tar: 0.000114 
l0: 0.000265, l1: 0.000262, l2: 0.000389, l3: 0.000538, l4: 0.001233, l5: 0.001908, l6: 0.003433

[epoch: 444/1000, batch:   284/ 1052, ite: 116580] train loss: 0.004311, tar: 0.000114 
l0: 0.000090, l1: 0.000090, l2: 0.000130, l3: 0.000225, l4: 0.000430, l5: 0.001033, l6: 0.001576

[epoch: 444/1000, batch:   364/ 1052, ite: 116600] train loss: 0.004319, tar: 0.000115 
l0: 0.000064, l1: 0.000064, l2: 0.000119, l3: 0.000199, l4: 0.000413, l5: 0.001090, l6: 0.001734

[epoch: 444/1000, batch:   444/ 1052, ite: 116620] train loss: 0.004320, tar: 0.000115 
l0: 0.000109, l1: 0.000111, l2: 0.000138, l3: 0.000275, l4: 0.000688, l5: 0.001393, l6: 0.001960

[epoch: 444/1000, batch:   524/ 1052, ite: 116640] train loss: 0.004324, tar: 0.000115 
l0: 0.000056, l1: 0.000056, l2: 0.000084, l3: 0.000234, l4: 0.000352, l5: 0.001085, l6: 0.001094

[epoch: 444/1000, batch:   604/ 1052, ite: 116660] train loss: 0.004320, tar: 0.000115 
l0: 0.000065, l1: 0.000065, l2: 0.000091, l3: 0.000243, l4: 0.000581, l5: 0.000521, l6: 0.001419

[epoch: 444/1000, batch:   684/ 1052, ite: 116680] train loss: 0.004311, tar: 0.000114 
l0: 0.000122, l1: 0.000120, l2: 0.000189, l3: 0.000338, l4: 0.000683, l5: 0.001902, l6: 0.003006

[epoch: 444/1000, batch:   764/ 1052, ite: 116700] train loss: 0.004313, tar: 0.000114 
l0: 0.000076, l1: 0.000079, l2: 0.000100, l3: 0.000234, l4: 0.000670, l5: 0.001252, l6: 0.001297

[epoch: 444/1000, batch:   844/ 1052, ite: 116720] train loss: 0.004313, tar: 0.000114 
l0: 0.000141, l1: 0.000139, l2: 0.000256, l3: 0.000603, l4: 0.001170, l5: 0.002257, l6: 0.004223

[epoch: 444/1000, batch:   924/ 1052, ite: 116740] train loss: 0.004310, tar: 0.000114 
l0: 0.000135, l1: 0.000137, l2: 0.000183, l3: 0.000251, l4: 0.000563, l5: 0.001549, l6: 0.003206

[epoch: 444/1000, batch:  1004/ 1052, ite: 116760] train loss: 0.004317, tar: 0.000115 
[Epoch 444/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000097, l1: 0.000101, l2: 0.000137, l3: 0.000298, l4: 0.000526, l5: 0.002038, l6: 0.003655

[epoch: 445/1000, batch:    32/ 1052, ite: 116780] train loss: 0.004328, tar: 0.000115 
l0: 0.000058, l1: 0.000058, l2: 0.000081, l3: 0.000149, l4: 0.000453, l5: 0.000986, l6: 0.001594

[epoch: 445/1000, batch:   112/ 1052, ite: 116800] train loss: 0.004327, tar: 0.000115 
l0: 0.000060, l1: 0.000059, l2: 0.000092, l3: 0.000159, l4: 0.000492, l5: 0.000926, l6: 0.001228

[epoch: 445/1000, batch:   192/ 1052, ite: 116820] train loss: 0.004334, tar: 0.000116 
l0: 0.000050, l1: 0.000049, l2: 0.000093, l3: 0.000119, l4: 0.000282, l5: 0.000637, l6: 0.000949

[epoch: 445/1000, batch:   272/ 1052, ite: 116840] train loss: 0.004337, tar: 0.000116 
l0: 0.000092, l1: 0.000090, l2: 0.000127, l3: 0.000276, l4: 0.000357, l5: 0.000871, l6: 0.001425

[epoch: 445/1000, batch:   352/ 1052, ite: 116860] train loss: 0.004334, tar: 0.000116 
l0: 0.000116, l1: 0.000117, l2: 0.000140, l3: 0.000178, l4: 0.000395, l5: 0.001276, l6: 0.001314

[epoch: 445/1000, batch:   432/ 1052, ite: 116880] train loss: 0.004342, tar: 0.000116 
l0: 0.000132, l1: 0.000131, l2: 0.000135, l3: 0.000200, l4: 0.000394, l5: 0.000842, l6: 0.001290

[epoch: 445/1000, batch:   512/ 1052, ite: 116900] train loss: 0.004335, tar: 0.000116 
l0: 0.000096, l1: 0.000097, l2: 0.000117, l3: 0.000173, l4: 0.000399, l5: 0.000784, l6: 0.001373

[epoch: 445/1000, batch:   592/ 1052, ite: 116920] train loss: 0.004338, tar: 0.000117 
l0: 0.000086, l1: 0.000084, l2: 0.000120, l3: 0.000173, l4: 0.000514, l5: 0.001257, l6: 0.001466

[epoch: 445/1000, batch:   672/ 1052, ite: 116940] train loss: 0.004333, tar: 0.000116 
l0: 0.000174, l1: 0.000178, l2: 0.000198, l3: 0.000247, l4: 0.000477, l5: 0.000660, l6: 0.001217

[epoch: 445/1000, batch:   752/ 1052, ite: 116960] train loss: 0.004324, tar: 0.000116 
l0: 0.000071, l1: 0.000073, l2: 0.000113, l3: 0.000196, l4: 0.000607, l5: 0.001526, l6: 0.002188

[epoch: 445/1000, batch:   832/ 1052, ite: 116980] train loss: 0.004322, tar: 0.000116 
l0: 0.000084, l1: 0.000084, l2: 0.000127, l3: 0.000202, l4: 0.000312, l5: 0.001080, l6: 0.002254

[epoch: 445/1000, batch:   912/ 1052, ite: 117000] train loss: 0.004327, tar: 0.000117 
l0: 0.000076, l1: 0.000076, l2: 0.000097, l3: 0.000175, l4: 0.000385, l5: 0.000832, l6: 0.002397

[epoch: 445/1000, batch:   992/ 1052, ite: 117020] train loss: 0.004325, tar: 0.000116 
[Epoch 445/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000084, l1: 0.000081, l2: 0.000158, l3: 0.000231, l4: 0.000569, l5: 0.001077, l6: 0.002185

[epoch: 446/1000, batch:    20/ 1052, ite: 117040] train loss: 0.004325, tar: 0.000117 
l0: 0.000086, l1: 0.000085, l2: 0.000145, l3: 0.000222, l4: 0.000494, l5: 0.000614, l6: 0.002157

[epoch: 446/1000, batch:   100/ 1052, ite: 117060] train loss: 0.004323, tar: 0.000116 
l0: 0.000094, l1: 0.000098, l2: 0.000108, l3: 0.000173, l4: 0.000556, l5: 0.000879, l6: 0.001532

[epoch: 446/1000, batch:   180/ 1052, ite: 117080] train loss: 0.004330, tar: 0.000117 
l0: 0.000120, l1: 0.000120, l2: 0.000178, l3: 0.000289, l4: 0.000639, l5: 0.001415, l6: 0.003214

[epoch: 446/1000, batch:   260/ 1052, ite: 117100] train loss: 0.004334, tar: 0.000117 
l0: 0.000150, l1: 0.000150, l2: 0.000228, l3: 0.000374, l4: 0.000844, l5: 0.001479, l6: 0.002473

[epoch: 446/1000, batch:   340/ 1052, ite: 117120] train loss: 0.004330, tar: 0.000117 
l0: 0.000154, l1: 0.000141, l2: 0.000230, l3: 0.000460, l4: 0.000781, l5: 0.001758, l6: 0.002554

[epoch: 446/1000, batch:   420/ 1052, ite: 117140] train loss: 0.004336, tar: 0.000118 
l0: 0.000100, l1: 0.000104, l2: 0.000116, l3: 0.000128, l4: 0.000195, l5: 0.000515, l6: 0.000796

[epoch: 446/1000, batch:   500/ 1052, ite: 117160] train loss: 0.004330, tar: 0.000117 
l0: 0.000074, l1: 0.000073, l2: 0.000109, l3: 0.000216, l4: 0.000454, l5: 0.000886, l6: 0.001822

[epoch: 446/1000, batch:   580/ 1052, ite: 117180] train loss: 0.004332, tar: 0.000117 
l0: 0.000053, l1: 0.000055, l2: 0.000076, l3: 0.000147, l4: 0.000535, l5: 0.001280, l6: 0.002016

[epoch: 446/1000, batch:   660/ 1052, ite: 117200] train loss: 0.004325, tar: 0.000117 
l0: 0.000093, l1: 0.000097, l2: 0.000158, l3: 0.000285, l4: 0.000671, l5: 0.001115, l6: 0.002005

[epoch: 446/1000, batch:   740/ 1052, ite: 117220] train loss: 0.004327, tar: 0.000117 
l0: 0.000271, l1: 0.000262, l2: 0.000367, l3: 0.000362, l4: 0.000848, l5: 0.002077, l6: 0.002629

[epoch: 446/1000, batch:   820/ 1052, ite: 117240] train loss: 0.004327, tar: 0.000117 
l0: 0.000065, l1: 0.000065, l2: 0.000105, l3: 0.000144, l4: 0.000213, l5: 0.000698, l6: 0.001077

[epoch: 446/1000, batch:   900/ 1052, ite: 117260] train loss: 0.004325, tar: 0.000117 
l0: 0.000100, l1: 0.000099, l2: 0.000195, l3: 0.000466, l4: 0.000859, l5: 0.001279, l6: 0.001964

[epoch: 446/1000, batch:   980/ 1052, ite: 117280] train loss: 0.004330, tar: 0.000117 
[Epoch 446/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000073, l1: 0.000072, l2: 0.000081, l3: 0.000116, l4: 0.000217, l5: 0.000474, l6: 0.000887

[epoch: 447/1000, batch:     8/ 1052, ite: 117300] train loss: 0.004328, tar: 0.000117 
l0: 0.000166, l1: 0.000172, l2: 0.000166, l3: 0.000315, l4: 0.000526, l5: 0.001443, l6: 0.002445

[epoch: 447/1000, batch:    88/ 1052, ite: 117320] train loss: 0.004326, tar: 0.000117 
l0: 0.000104, l1: 0.000106, l2: 0.000139, l3: 0.000315, l4: 0.000529, l5: 0.000874, l6: 0.002103

[epoch: 447/1000, batch:   168/ 1052, ite: 117340] train loss: 0.004320, tar: 0.000117 
l0: 0.000146, l1: 0.000149, l2: 0.000168, l3: 0.000262, l4: 0.000538, l5: 0.001143, l6: 0.001954

[epoch: 447/1000, batch:   248/ 1052, ite: 117360] train loss: 0.004331, tar: 0.000117 
l0: 0.000043, l1: 0.000042, l2: 0.000115, l3: 0.000212, l4: 0.000262, l5: 0.001211, l6: 0.001337

[epoch: 447/1000, batch:   328/ 1052, ite: 117380] train loss: 0.004325, tar: 0.000117 
l0: 0.000179, l1: 0.000184, l2: 0.000211, l3: 0.000335, l4: 0.000702, l5: 0.001724, l6: 0.003875

[epoch: 447/1000, batch:   408/ 1052, ite: 117400] train loss: 0.004317, tar: 0.000116 
l0: 0.000066, l1: 0.000067, l2: 0.000062, l3: 0.000096, l4: 0.000223, l5: 0.000378, l6: 0.001127

[epoch: 447/1000, batch:   488/ 1052, ite: 117420] train loss: 0.004315, tar: 0.000116 
l0: 0.000074, l1: 0.000076, l2: 0.000095, l3: 0.000190, l4: 0.000499, l5: 0.001027, l6: 0.001531

[epoch: 447/1000, batch:   568/ 1052, ite: 117440] train loss: 0.004310, tar: 0.000116 
l0: 0.000148, l1: 0.000150, l2: 0.000214, l3: 0.000310, l4: 0.000769, l5: 0.001114, l6: 0.001865

[epoch: 447/1000, batch:   648/ 1052, ite: 117460] train loss: 0.004315, tar: 0.000116 
l0: 0.000101, l1: 0.000103, l2: 0.000115, l3: 0.000168, l4: 0.000335, l5: 0.001111, l6: 0.001466

[epoch: 447/1000, batch:   728/ 1052, ite: 117480] train loss: 0.004319, tar: 0.000116 
l0: 0.000111, l1: 0.000109, l2: 0.000141, l3: 0.000242, l4: 0.000511, l5: 0.001376, l6: 0.002558

[epoch: 447/1000, batch:   808/ 1052, ite: 117500] train loss: 0.004324, tar: 0.000117 
l0: 0.000174, l1: 0.000180, l2: 0.000233, l3: 0.000352, l4: 0.000645, l5: 0.001507, l6: 0.002159

[epoch: 447/1000, batch:   888/ 1052, ite: 117520] train loss: 0.004326, tar: 0.000117 
l0: 0.000065, l1: 0.000065, l2: 0.000087, l3: 0.000177, l4: 0.000299, l5: 0.000728, l6: 0.001193

[epoch: 447/1000, batch:   968/ 1052, ite: 117540] train loss: 0.004323, tar: 0.000117 
l0: 0.000154, l1: 0.000150, l2: 0.000198, l3: 0.000220, l4: 0.000352, l5: 0.000952, l6: 0.002156

[epoch: 447/1000, batch:  1048/ 1052, ite: 117560] train loss: 0.004325, tar: 0.000117 
[Epoch 447/1000] Test loss: 0.016, Test target loss: 0.002
l0: 0.000287, l1: 0.000286, l2: 0.000308, l3: 0.000428, l4: 0.000569, l5: 0.001655, l6: 0.001714

[epoch: 448/1000, batch:    76/ 1052, ite: 117580] train loss: 0.004322, tar: 0.000117 
l0: 0.000108, l1: 0.000107, l2: 0.000139, l3: 0.000227, l4: 0.000383, l5: 0.000740, l6: 0.001951

[epoch: 448/1000, batch:   156/ 1052, ite: 117600] train loss: 0.004323, tar: 0.000117 
l0: 0.000039, l1: 0.000040, l2: 0.000054, l3: 0.000126, l4: 0.000293, l5: 0.000737, l6: 0.000956

[epoch: 448/1000, batch:   236/ 1052, ite: 117620] train loss: 0.004318, tar: 0.000117 
l0: 0.000104, l1: 0.000108, l2: 0.000137, l3: 0.000174, l4: 0.000500, l5: 0.000606, l6: 0.001338

[epoch: 448/1000, batch:   316/ 1052, ite: 117640] train loss: 0.004320, tar: 0.000117 
l0: 0.000154, l1: 0.000150, l2: 0.000224, l3: 0.000243, l4: 0.000690, l5: 0.001280, l6: 0.002932

[epoch: 448/1000, batch:   396/ 1052, ite: 117660] train loss: 0.004326, tar: 0.000117 
l0: 0.000090, l1: 0.000094, l2: 0.000115, l3: 0.000162, l4: 0.000346, l5: 0.000732, l6: 0.001249

[epoch: 448/1000, batch:   476/ 1052, ite: 117680] train loss: 0.004335, tar: 0.000117 
l0: 0.000189, l1: 0.000185, l2: 0.000253, l3: 0.000360, l4: 0.000518, l5: 0.001339, l6: 0.002245

[epoch: 448/1000, batch:   556/ 1052, ite: 117700] train loss: 0.004332, tar: 0.000117 
l0: 0.000079, l1: 0.000077, l2: 0.000114, l3: 0.000187, l4: 0.000325, l5: 0.001123, l6: 0.001332

[epoch: 448/1000, batch:   636/ 1052, ite: 117720] train loss: 0.004331, tar: 0.000117 
l0: 0.000115, l1: 0.000099, l2: 0.000167, l3: 0.000302, l4: 0.000509, l5: 0.001076, l6: 0.001651

[epoch: 448/1000, batch:   716/ 1052, ite: 117740] train loss: 0.004334, tar: 0.000118 
l0: 0.000035, l1: 0.000037, l2: 0.000063, l3: 0.000163, l4: 0.000604, l5: 0.000731, l6: 0.001094

[epoch: 448/1000, batch:   796/ 1052, ite: 117760] train loss: 0.004331, tar: 0.000117 
l0: 0.000113, l1: 0.000116, l2: 0.000147, l3: 0.000271, l4: 0.000528, l5: 0.001177, l6: 0.001885

[epoch: 448/1000, batch:   876/ 1052, ite: 117780] train loss: 0.004331, tar: 0.000117 
l0: 0.000145, l1: 0.000155, l2: 0.000179, l3: 0.000352, l4: 0.000699, l5: 0.001001, l6: 0.002672

[epoch: 448/1000, batch:   956/ 1052, ite: 117800] train loss: 0.004328, tar: 0.000117 
l0: 0.000088, l1: 0.000085, l2: 0.000147, l3: 0.000241, l4: 0.000520, l5: 0.001000, l6: 0.001875

[epoch: 448/1000, batch:  1036/ 1052, ite: 117820] train loss: 0.004325, tar: 0.000117 
[Epoch 448/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000140, l1: 0.000144, l2: 0.000176, l3: 0.000308, l4: 0.000621, l5: 0.001101, l6: 0.001914

[epoch: 449/1000, batch:    64/ 1052, ite: 117840] train loss: 0.004326, tar: 0.000117 
l0: 0.000064, l1: 0.000064, l2: 0.000121, l3: 0.000195, l4: 0.000539, l5: 0.001128, l6: 0.001523

[epoch: 449/1000, batch:   144/ 1052, ite: 117860] train loss: 0.004322, tar: 0.000117 
l0: 0.000138, l1: 0.000138, l2: 0.000192, l3: 0.000380, l4: 0.000818, l5: 0.001246, l6: 0.002878

[epoch: 449/1000, batch:   224/ 1052, ite: 117880] train loss: 0.004321, tar: 0.000117 
l0: 0.000070, l1: 0.000068, l2: 0.000086, l3: 0.000189, l4: 0.000484, l5: 0.000984, l6: 0.000870

[epoch: 449/1000, batch:   304/ 1052, ite: 117900] train loss: 0.004316, tar: 0.000117 
l0: 0.000130, l1: 0.000133, l2: 0.000155, l3: 0.000246, l4: 0.000523, l5: 0.001056, l6: 0.002157

[epoch: 449/1000, batch:   384/ 1052, ite: 117920] train loss: 0.004317, tar: 0.000117 
l0: 0.000021, l1: 0.000023, l2: 0.000035, l3: 0.000091, l4: 0.000395, l5: 0.001054, l6: 0.001405

[epoch: 449/1000, batch:   464/ 1052, ite: 117940] train loss: 0.004311, tar: 0.000117 
l0: 0.000142, l1: 0.000139, l2: 0.000219, l3: 0.000387, l4: 0.000783, l5: 0.001135, l6: 0.002299

[epoch: 449/1000, batch:   544/ 1052, ite: 117960] train loss: 0.004307, tar: 0.000117 
l0: 0.000031, l1: 0.000032, l2: 0.000057, l3: 0.000128, l4: 0.000381, l5: 0.000995, l6: 0.001104

[epoch: 449/1000, batch:   624/ 1052, ite: 117980] train loss: 0.004307, tar: 0.000116 
l0: 0.000189, l1: 0.000180, l2: 0.000274, l3: 0.000400, l4: 0.000576, l5: 0.001376, l6: 0.002645

[epoch: 449/1000, batch:   704/ 1052, ite: 118000] train loss: 0.004312, tar: 0.000117 
l0: 0.000096, l1: 0.000099, l2: 0.000116, l3: 0.000195, l4: 0.000361, l5: 0.000842, l6: 0.001713

[epoch: 449/1000, batch:   784/ 1052, ite: 118020] train loss: 0.004315, tar: 0.000117 
l0: 0.000101, l1: 0.000105, l2: 0.000123, l3: 0.000266, l4: 0.000426, l5: 0.000847, l6: 0.001163

[epoch: 449/1000, batch:   864/ 1052, ite: 118040] train loss: 0.004314, tar: 0.000117 
l0: 0.000136, l1: 0.000139, l2: 0.000180, l3: 0.000261, l4: 0.000422, l5: 0.000727, l6: 0.001912

[epoch: 449/1000, batch:   944/ 1052, ite: 118060] train loss: 0.004318, tar: 0.000117 
l0: 0.000050, l1: 0.000052, l2: 0.000089, l3: 0.000133, l4: 0.000325, l5: 0.000905, l6: 0.001763

[epoch: 449/1000, batch:  1024/ 1052, ite: 118080] train loss: 0.004324, tar: 0.000118 
[Epoch 449/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000064, l1: 0.000063, l2: 0.000101, l3: 0.000178, l4: 0.000445, l5: 0.000962, l6: 0.001656

[epoch: 450/1000, batch:    52/ 1052, ite: 118100] train loss: 0.004325, tar: 0.000118 
l0: 0.000067, l1: 0.000065, l2: 0.000108, l3: 0.000236, l4: 0.000533, l5: 0.001075, l6: 0.001935

[epoch: 450/1000, batch:   132/ 1052, ite: 118120] train loss: 0.004327, tar: 0.000118 
l0: 0.000178, l1: 0.000179, l2: 0.000245, l3: 0.000393, l4: 0.000790, l5: 0.001458, l6: 0.003431

[epoch: 450/1000, batch:   212/ 1052, ite: 118140] train loss: 0.004330, tar: 0.000118 
l0: 0.000071, l1: 0.000071, l2: 0.000102, l3: 0.000155, l4: 0.000309, l5: 0.000501, l6: 0.001143

[epoch: 450/1000, batch:   292/ 1052, ite: 118160] train loss: 0.004328, tar: 0.000118 
l0: 0.000170, l1: 0.000179, l2: 0.000182, l3: 0.000256, l4: 0.000493, l5: 0.000742, l6: 0.002336

[epoch: 450/1000, batch:   372/ 1052, ite: 118180] train loss: 0.004328, tar: 0.000118 
l0: 0.000120, l1: 0.000126, l2: 0.000174, l3: 0.000294, l4: 0.000659, l5: 0.001471, l6: 0.001280

[epoch: 450/1000, batch:   452/ 1052, ite: 118200] train loss: 0.004322, tar: 0.000117 
l0: 0.000064, l1: 0.000065, l2: 0.000078, l3: 0.000165, l4: 0.000348, l5: 0.000786, l6: 0.001744

[epoch: 450/1000, batch:   532/ 1052, ite: 118220] train loss: 0.004322, tar: 0.000117 
l0: 0.000114, l1: 0.000118, l2: 0.000159, l3: 0.000363, l4: 0.000647, l5: 0.001742, l6: 0.002942

[epoch: 450/1000, batch:   612/ 1052, ite: 118240] train loss: 0.004320, tar: 0.000117 
l0: 0.000151, l1: 0.000153, l2: 0.000169, l3: 0.000244, l4: 0.000498, l5: 0.001324, l6: 0.003350

[epoch: 450/1000, batch:   692/ 1052, ite: 118260] train loss: 0.004322, tar: 0.000117 
l0: 0.000180, l1: 0.000178, l2: 0.000228, l3: 0.000351, l4: 0.000652, l5: 0.001580, l6: 0.002923

[epoch: 450/1000, batch:   772/ 1052, ite: 118280] train loss: 0.004327, tar: 0.000117 
l0: 0.000120, l1: 0.000121, l2: 0.000165, l3: 0.000246, l4: 0.000495, l5: 0.001252, l6: 0.001222

[epoch: 450/1000, batch:   852/ 1052, ite: 118300] train loss: 0.004326, tar: 0.000117 
l0: 0.000065, l1: 0.000067, l2: 0.000106, l3: 0.000177, l4: 0.000283, l5: 0.001011, l6: 0.001877

[epoch: 450/1000, batch:   932/ 1052, ite: 118320] train loss: 0.004323, tar: 0.000117 
l0: 0.000132, l1: 0.000135, l2: 0.000177, l3: 0.000274, l4: 0.000501, l5: 0.000675, l6: 0.001457

[epoch: 450/1000, batch:  1012/ 1052, ite: 118340] train loss: 0.004322, tar: 0.000117 
[Epoch 450/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000064, l1: 0.000065, l2: 0.000081, l3: 0.000133, l4: 0.000426, l5: 0.000889, l6: 0.001240

[epoch: 451/1000, batch:    40/ 1052, ite: 118360] train loss: 0.004322, tar: 0.000117 
l0: 0.000131, l1: 0.000132, l2: 0.000178, l3: 0.000259, l4: 0.000448, l5: 0.001428, l6: 0.002852

[epoch: 451/1000, batch:   120/ 1052, ite: 118380] train loss: 0.004317, tar: 0.000117 
l0: 0.000106, l1: 0.000104, l2: 0.000148, l3: 0.000225, l4: 0.000397, l5: 0.001055, l6: 0.001417

[epoch: 451/1000, batch:   200/ 1052, ite: 118400] train loss: 0.004316, tar: 0.000117 
l0: 0.000046, l1: 0.000046, l2: 0.000071, l3: 0.000191, l4: 0.000610, l5: 0.001255, l6: 0.002173

[epoch: 451/1000, batch:   280/ 1052, ite: 118420] train loss: 0.004316, tar: 0.000117 
l0: 0.000135, l1: 0.000139, l2: 0.000182, l3: 0.000271, l4: 0.000605, l5: 0.001501, l6: 0.001940

[epoch: 451/1000, batch:   360/ 1052, ite: 118440] train loss: 0.004315, tar: 0.000117 
l0: 0.000052, l1: 0.000065, l2: 0.000076, l3: 0.000129, l4: 0.000168, l5: 0.000571, l6: 0.000893

[epoch: 451/1000, batch:   440/ 1052, ite: 118460] train loss: 0.004316, tar: 0.000117 
l0: 0.000102, l1: 0.000105, l2: 0.000131, l3: 0.000168, l4: 0.000425, l5: 0.000833, l6: 0.001626

[epoch: 451/1000, batch:   520/ 1052, ite: 118480] train loss: 0.004320, tar: 0.000117 
l0: 0.000104, l1: 0.000103, l2: 0.000168, l3: 0.000265, l4: 0.000495, l5: 0.000895, l6: 0.002312

[epoch: 451/1000, batch:   600/ 1052, ite: 118500] train loss: 0.004318, tar: 0.000117 
l0: 0.000125, l1: 0.000127, l2: 0.000142, l3: 0.000275, l4: 0.000667, l5: 0.002027, l6: 0.002816

[epoch: 451/1000, batch:   680/ 1052, ite: 118520] train loss: 0.004319, tar: 0.000117 
l0: 0.000273, l1: 0.000274, l2: 0.000310, l3: 0.000430, l4: 0.000785, l5: 0.002040, l6: 0.003677

[epoch: 451/1000, batch:   760/ 1052, ite: 118540] train loss: 0.004319, tar: 0.000117 
l0: 0.000171, l1: 0.000175, l2: 0.000214, l3: 0.000317, l4: 0.000662, l5: 0.001358, l6: 0.002658

[epoch: 451/1000, batch:   840/ 1052, ite: 118560] train loss: 0.004322, tar: 0.000117 
l0: 0.000080, l1: 0.000078, l2: 0.000124, l3: 0.000189, l4: 0.000428, l5: 0.000884, l6: 0.001597

[epoch: 451/1000, batch:   920/ 1052, ite: 118580] train loss: 0.004324, tar: 0.000117 
l0: 0.000038, l1: 0.000038, l2: 0.000051, l3: 0.000119, l4: 0.000367, l5: 0.000805, l6: 0.000986

[epoch: 451/1000, batch:  1000/ 1052, ite: 118600] train loss: 0.004325, tar: 0.000117 
[Epoch 451/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000087, l1: 0.000088, l2: 0.000088, l3: 0.000127, l4: 0.000442, l5: 0.000613, l6: 0.001063

[epoch: 452/1000, batch:    28/ 1052, ite: 118620] train loss: 0.004326, tar: 0.000117 
l0: 0.000046, l1: 0.000049, l2: 0.000056, l3: 0.000089, l4: 0.000140, l5: 0.000416, l6: 0.000269

[epoch: 452/1000, batch:   108/ 1052, ite: 118640] train loss: 0.004325, tar: 0.000117 
l0: 0.000113, l1: 0.000115, l2: 0.000132, l3: 0.000189, l4: 0.000432, l5: 0.000905, l6: 0.001185

[epoch: 452/1000, batch:   188/ 1052, ite: 118660] train loss: 0.004326, tar: 0.000117 
l0: 0.000243, l1: 0.000249, l2: 0.000307, l3: 0.000582, l4: 0.001107, l5: 0.002204, l6: 0.003650

[epoch: 452/1000, batch:   268/ 1052, ite: 118680] train loss: 0.004325, tar: 0.000117 
l0: 0.000074, l1: 0.000071, l2: 0.000097, l3: 0.000166, l4: 0.000307, l5: 0.000728, l6: 0.001246

[epoch: 452/1000, batch:   348/ 1052, ite: 118700] train loss: 0.004320, tar: 0.000117 
l0: 0.000043, l1: 0.000042, l2: 0.000076, l3: 0.000108, l4: 0.000448, l5: 0.000427, l6: 0.001412

[epoch: 452/1000, batch:   428/ 1052, ite: 118720] train loss: 0.004317, tar: 0.000117 
l0: 0.000064, l1: 0.000064, l2: 0.000089, l3: 0.000154, l4: 0.000375, l5: 0.000919, l6: 0.001162

[epoch: 452/1000, batch:   508/ 1052, ite: 118740] train loss: 0.004317, tar: 0.000117 
l0: 0.000083, l1: 0.000083, l2: 0.000101, l3: 0.000206, l4: 0.000387, l5: 0.000804, l6: 0.001453

[epoch: 452/1000, batch:   588/ 1052, ite: 118760] train loss: 0.004319, tar: 0.000117 
l0: 0.000042, l1: 0.000042, l2: 0.000076, l3: 0.000137, l4: 0.000368, l5: 0.000995, l6: 0.001365

[epoch: 452/1000, batch:   668/ 1052, ite: 118780] train loss: 0.004326, tar: 0.000117 
l0: 0.000211, l1: 0.000220, l2: 0.000222, l3: 0.000278, l4: 0.000651, l5: 0.001297, l6: 0.002649

[epoch: 452/1000, batch:   748/ 1052, ite: 118800] train loss: 0.004327, tar: 0.000117 
l0: 0.000168, l1: 0.000180, l2: 0.000312, l3: 0.000484, l4: 0.000896, l5: 0.002073, l6: 0.004314

[epoch: 452/1000, batch:   828/ 1052, ite: 118820] train loss: 0.004325, tar: 0.000117 
l0: 0.000253, l1: 0.000257, l2: 0.000252, l3: 0.000262, l4: 0.000487, l5: 0.001126, l6: 0.001688

[epoch: 452/1000, batch:   908/ 1052, ite: 118840] train loss: 0.004327, tar: 0.000117 
l0: 0.000259, l1: 0.000267, l2: 0.000330, l3: 0.000568, l4: 0.001073, l5: 0.002204, l6: 0.004342

[epoch: 452/1000, batch:   988/ 1052, ite: 118860] train loss: 0.004328, tar: 0.000117 
[Epoch 452/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000218, l1: 0.000215, l2: 0.000258, l3: 0.000513, l4: 0.000911, l5: 0.001496, l6: 0.002711

[epoch: 453/1000, batch:    16/ 1052, ite: 118880] train loss: 0.004328, tar: 0.000117 
l0: 0.000105, l1: 0.000104, l2: 0.000175, l3: 0.000437, l4: 0.000606, l5: 0.001569, l6: 0.002114

[epoch: 453/1000, batch:    96/ 1052, ite: 118900] train loss: 0.004328, tar: 0.000117 
l0: 0.000044, l1: 0.000042, l2: 0.000074, l3: 0.000127, l4: 0.000263, l5: 0.000973, l6: 0.001286

[epoch: 453/1000, batch:   176/ 1052, ite: 118920] train loss: 0.004330, tar: 0.000117 
l0: 0.000052, l1: 0.000054, l2: 0.000079, l3: 0.000139, l4: 0.000299, l5: 0.000660, l6: 0.001851

[epoch: 453/1000, batch:   256/ 1052, ite: 118940] train loss: 0.004328, tar: 0.000117 
l0: 0.000221, l1: 0.000223, l2: 0.000217, l3: 0.000253, l4: 0.000449, l5: 0.000949, l6: 0.001378

[epoch: 453/1000, batch:   336/ 1052, ite: 118960] train loss: 0.004328, tar: 0.000117 
l0: 0.000137, l1: 0.000130, l2: 0.000201, l3: 0.000289, l4: 0.000821, l5: 0.001513, l6: 0.002258

[epoch: 453/1000, batch:   416/ 1052, ite: 118980] train loss: 0.004331, tar: 0.000117 
l0: 0.000110, l1: 0.000115, l2: 0.000186, l3: 0.000278, l4: 0.000434, l5: 0.000847, l6: 0.001648

[epoch: 453/1000, batch:   496/ 1052, ite: 119000] train loss: 0.004329, tar: 0.000117 
l0: 0.000073, l1: 0.000074, l2: 0.000160, l3: 0.000347, l4: 0.000743, l5: 0.001385, l6: 0.002361

[epoch: 453/1000, batch:   576/ 1052, ite: 119020] train loss: 0.004329, tar: 0.000117 
l0: 0.000167, l1: 0.000169, l2: 0.000272, l3: 0.000416, l4: 0.000810, l5: 0.001813, l6: 0.002864

[epoch: 453/1000, batch:   656/ 1052, ite: 119040] train loss: 0.004331, tar: 0.000117 
l0: 0.000091, l1: 0.000088, l2: 0.000146, l3: 0.000205, l4: 0.000493, l5: 0.001140, l6: 0.002038

[epoch: 453/1000, batch:   736/ 1052, ite: 119060] train loss: 0.004329, tar: 0.000117 
l0: 0.000028, l1: 0.000030, l2: 0.000031, l3: 0.000094, l4: 0.000329, l5: 0.000382, l6: 0.000742

[epoch: 453/1000, batch:   816/ 1052, ite: 119080] train loss: 0.004325, tar: 0.000117 
l0: 0.000045, l1: 0.000045, l2: 0.000066, l3: 0.000108, l4: 0.000352, l5: 0.000863, l6: 0.001349

[epoch: 453/1000, batch:   896/ 1052, ite: 119100] train loss: 0.004327, tar: 0.000117 
l0: 0.000102, l1: 0.000101, l2: 0.000092, l3: 0.000134, l4: 0.000298, l5: 0.000810, l6: 0.001348

[epoch: 453/1000, batch:   976/ 1052, ite: 119120] train loss: 0.004326, tar: 0.000117 
[Epoch 453/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000107, l1: 0.000106, l2: 0.000159, l3: 0.000274, l4: 0.000540, l5: 0.001966, l6: 0.002300

[epoch: 454/1000, batch:     4/ 1052, ite: 119140] train loss: 0.004326, tar: 0.000117 
l0: 0.000181, l1: 0.000182, l2: 0.000238, l3: 0.000357, l4: 0.000785, l5: 0.001419, l6: 0.003097

[epoch: 454/1000, batch:    84/ 1052, ite: 119160] train loss: 0.004326, tar: 0.000117 
l0: 0.000108, l1: 0.000109, l2: 0.000210, l3: 0.000517, l4: 0.000935, l5: 0.002079, l6: 0.004286

[epoch: 454/1000, batch:   164/ 1052, ite: 119180] train loss: 0.004329, tar: 0.000117 
l0: 0.000043, l1: 0.000041, l2: 0.000072, l3: 0.000193, l4: 0.000458, l5: 0.000713, l6: 0.001205

[epoch: 454/1000, batch:   244/ 1052, ite: 119200] train loss: 0.004325, tar: 0.000117 
l0: 0.000206, l1: 0.000210, l2: 0.000248, l3: 0.000287, l4: 0.000527, l5: 0.001040, l6: 0.002039

[epoch: 454/1000, batch:   324/ 1052, ite: 119220] train loss: 0.004325, tar: 0.000117 
l0: 0.000073, l1: 0.000073, l2: 0.000086, l3: 0.000154, l4: 0.000399, l5: 0.000543, l6: 0.001666

[epoch: 454/1000, batch:   404/ 1052, ite: 119240] train loss: 0.004322, tar: 0.000117 
l0: 0.000089, l1: 0.000089, l2: 0.000137, l3: 0.000179, l4: 0.000473, l5: 0.000688, l6: 0.001501

[epoch: 454/1000, batch:   484/ 1052, ite: 119260] train loss: 0.004324, tar: 0.000117 
l0: 0.000312, l1: 0.000325, l2: 0.000376, l3: 0.000674, l4: 0.001169, l5: 0.002106, l6: 0.004160

[epoch: 454/1000, batch:   564/ 1052, ite: 119280] train loss: 0.004326, tar: 0.000117 
l0: 0.000043, l1: 0.000045, l2: 0.000044, l3: 0.000101, l4: 0.000161, l5: 0.000516, l6: 0.000500

[epoch: 454/1000, batch:   644/ 1052, ite: 119300] train loss: 0.004325, tar: 0.000117 
l0: 0.000074, l1: 0.000075, l2: 0.000138, l3: 0.000184, l4: 0.000627, l5: 0.000867, l6: 0.002010

[epoch: 454/1000, batch:   724/ 1052, ite: 119320] train loss: 0.004325, tar: 0.000117 
l0: 0.000176, l1: 0.000181, l2: 0.000205, l3: 0.000398, l4: 0.000748, l5: 0.001650, l6: 0.002791

[epoch: 454/1000, batch:   804/ 1052, ite: 119340] train loss: 0.004325, tar: 0.000117 
l0: 0.000064, l1: 0.000065, l2: 0.000109, l3: 0.000156, l4: 0.000317, l5: 0.000920, l6: 0.001502

[epoch: 454/1000, batch:   884/ 1052, ite: 119360] train loss: 0.004326, tar: 0.000117 
l0: 0.000057, l1: 0.000060, l2: 0.000054, l3: 0.000069, l4: 0.000310, l5: 0.000407, l6: 0.000842

[epoch: 454/1000, batch:   964/ 1052, ite: 119380] train loss: 0.004324, tar: 0.000117 
l0: 0.000065, l1: 0.000065, l2: 0.000081, l3: 0.000129, l4: 0.000318, l5: 0.000942, l6: 0.001508

[epoch: 454/1000, batch:  1044/ 1052, ite: 119400] train loss: 0.004326, tar: 0.000117 
[Epoch 454/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000115, l1: 0.000114, l2: 0.000163, l3: 0.000269, l4: 0.000430, l5: 0.001084, l6: 0.002251

[epoch: 455/1000, batch:    72/ 1052, ite: 119420] train loss: 0.004324, tar: 0.000117 
l0: 0.000117, l1: 0.000116, l2: 0.000226, l3: 0.000488, l4: 0.001054, l5: 0.001812, l6: 0.002973

[epoch: 455/1000, batch:   152/ 1052, ite: 119440] train loss: 0.004325, tar: 0.000117 
l0: 0.000141, l1: 0.000142, l2: 0.000242, l3: 0.000449, l4: 0.000727, l5: 0.001436, l6: 0.002750

[epoch: 455/1000, batch:   232/ 1052, ite: 119460] train loss: 0.004327, tar: 0.000117 
l0: 0.000122, l1: 0.000126, l2: 0.000162, l3: 0.000382, l4: 0.000772, l5: 0.001184, l6: 0.002051

[epoch: 455/1000, batch:   312/ 1052, ite: 119480] train loss: 0.004326, tar: 0.000117 
l0: 0.000122, l1: 0.000126, l2: 0.000148, l3: 0.000173, l4: 0.000512, l5: 0.001286, l6: 0.001610

[epoch: 455/1000, batch:   392/ 1052, ite: 119500] train loss: 0.004324, tar: 0.000117 
l0: 0.000185, l1: 0.000182, l2: 0.000271, l3: 0.000369, l4: 0.000661, l5: 0.001649, l6: 0.002423

[epoch: 455/1000, batch:   472/ 1052, ite: 119520] train loss: 0.004325, tar: 0.000117 
l0: 0.000094, l1: 0.000095, l2: 0.000131, l3: 0.000153, l4: 0.000304, l5: 0.001058, l6: 0.001611

[epoch: 455/1000, batch:   552/ 1052, ite: 119540] train loss: 0.004322, tar: 0.000116 
l0: 0.000105, l1: 0.000103, l2: 0.000152, l3: 0.000306, l4: 0.000681, l5: 0.001141, l6: 0.002196

[epoch: 455/1000, batch:   632/ 1052, ite: 119560] train loss: 0.004321, tar: 0.000116 
l0: 0.000020, l1: 0.000019, l2: 0.000047, l3: 0.000151, l4: 0.000569, l5: 0.000682, l6: 0.001571

[epoch: 455/1000, batch:   712/ 1052, ite: 119580] train loss: 0.004325, tar: 0.000116 
l0: 0.000105, l1: 0.000105, l2: 0.000106, l3: 0.000158, l4: 0.000254, l5: 0.000798, l6: 0.001039

[epoch: 455/1000, batch:   792/ 1052, ite: 119600] train loss: 0.004324, tar: 0.000116 
l0: 0.000165, l1: 0.000167, l2: 0.000216, l3: 0.000371, l4: 0.000564, l5: 0.001360, l6: 0.002273

[epoch: 455/1000, batch:   872/ 1052, ite: 119620] train loss: 0.004320, tar: 0.000116 
l0: 0.000085, l1: 0.000087, l2: 0.000113, l3: 0.000206, l4: 0.000416, l5: 0.000968, l6: 0.001822

[epoch: 455/1000, batch:   952/ 1052, ite: 119640] train loss: 0.004319, tar: 0.000116 
l0: 0.000114, l1: 0.000116, l2: 0.000125, l3: 0.000161, l4: 0.000402, l5: 0.000404, l6: 0.001313

[epoch: 455/1000, batch:  1032/ 1052, ite: 119660] train loss: 0.004318, tar: 0.000116 
[Epoch 455/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000071, l1: 0.000073, l2: 0.000103, l3: 0.000180, l4: 0.000511, l5: 0.001048, l6: 0.001892

[epoch: 456/1000, batch:    60/ 1052, ite: 119680] train loss: 0.004317, tar: 0.000116 
l0: 0.000059, l1: 0.000060, l2: 0.000097, l3: 0.000202, l4: 0.000474, l5: 0.000989, l6: 0.001476

[epoch: 456/1000, batch:   140/ 1052, ite: 119700] train loss: 0.004317, tar: 0.000116 
l0: 0.000096, l1: 0.000097, l2: 0.000148, l3: 0.000244, l4: 0.000413, l5: 0.001242, l6: 0.002184

[epoch: 456/1000, batch:   220/ 1052, ite: 119720] train loss: 0.004318, tar: 0.000116 
l0: 0.000042, l1: 0.000041, l2: 0.000084, l3: 0.000129, l4: 0.000264, l5: 0.000493, l6: 0.001242

[epoch: 456/1000, batch:   300/ 1052, ite: 119740] train loss: 0.004318, tar: 0.000116 
l0: 0.000158, l1: 0.000155, l2: 0.000211, l3: 0.000274, l4: 0.000425, l5: 0.001130, l6: 0.001853

[epoch: 456/1000, batch:   380/ 1052, ite: 119760] train loss: 0.004318, tar: 0.000116 
l0: 0.000082, l1: 0.000080, l2: 0.000131, l3: 0.000216, l4: 0.000406, l5: 0.001110, l6: 0.001937

[epoch: 456/1000, batch:   460/ 1052, ite: 119780] train loss: 0.004317, tar: 0.000116 
l0: 0.000102, l1: 0.000102, l2: 0.000161, l3: 0.000215, l4: 0.000386, l5: 0.000913, l6: 0.002215

[epoch: 456/1000, batch:   540/ 1052, ite: 119800] train loss: 0.004316, tar: 0.000116 
l0: 0.000024, l1: 0.000025, l2: 0.000042, l3: 0.000095, l4: 0.000334, l5: 0.000779, l6: 0.001472

[epoch: 456/1000, batch:   620/ 1052, ite: 119820] train loss: 0.004318, tar: 0.000116 
l0: 0.000111, l1: 0.000111, l2: 0.000160, l3: 0.000281, l4: 0.000721, l5: 0.001780, l6: 0.002358

[epoch: 456/1000, batch:   700/ 1052, ite: 119840] train loss: 0.004320, tar: 0.000116 
l0: 0.000127, l1: 0.000127, l2: 0.000180, l3: 0.000282, l4: 0.000426, l5: 0.001055, l6: 0.002076

[epoch: 456/1000, batch:   780/ 1052, ite: 119860] train loss: 0.004322, tar: 0.000116 
l0: 0.000102, l1: 0.000105, l2: 0.000121, l3: 0.000190, l4: 0.000395, l5: 0.000778, l6: 0.001467

[epoch: 456/1000, batch:   860/ 1052, ite: 119880] train loss: 0.004321, tar: 0.000116 
l0: 0.000267, l1: 0.000263, l2: 0.000278, l3: 0.000270, l4: 0.000384, l5: 0.000844, l6: 0.001190

[epoch: 456/1000, batch:   940/ 1052, ite: 119900] train loss: 0.004320, tar: 0.000116 
l0: 0.000029, l1: 0.000030, l2: 0.000044, l3: 0.000101, l4: 0.000233, l5: 0.000801, l6: 0.000719

[epoch: 456/1000, batch:  1020/ 1052, ite: 119920] train loss: 0.004318, tar: 0.000116 
[Epoch 456/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000099, l1: 0.000097, l2: 0.000143, l3: 0.000218, l4: 0.000336, l5: 0.000939, l6: 0.001265

[epoch: 457/1000, batch:    48/ 1052, ite: 119940] train loss: 0.004319, tar: 0.000116 
l0: 0.000091, l1: 0.000089, l2: 0.000185, l3: 0.000294, l4: 0.000715, l5: 0.000954, l6: 0.001790

[epoch: 457/1000, batch:   128/ 1052, ite: 119960] train loss: 0.004316, tar: 0.000116 
l0: 0.000097, l1: 0.000098, l2: 0.000134, l3: 0.000198, l4: 0.000384, l5: 0.001102, l6: 0.002084

[epoch: 457/1000, batch:   208/ 1052, ite: 119980] train loss: 0.004314, tar: 0.000115 
l0: 0.000156, l1: 0.000153, l2: 0.000202, l3: 0.000300, l4: 0.000749, l5: 0.001725, l6: 0.003222

[epoch: 457/1000, batch:   288/ 1052, ite: 120000] train loss: 0.004314, tar: 0.000115 
l0: 0.000064, l1: 0.000062, l2: 0.000141, l3: 0.000216, l4: 0.000565, l5: 0.001107, l6: 0.000747

[epoch: 457/1000, batch:   368/ 1052, ite: 120020] train loss: 0.004310, tar: 0.000115 
l0: 0.000100, l1: 0.000097, l2: 0.000128, l3: 0.000223, l4: 0.000395, l5: 0.001111, l6: 0.001890

[epoch: 457/1000, batch:   448/ 1052, ite: 120040] train loss: 0.004312, tar: 0.000115 
l0: 0.000119, l1: 0.000119, l2: 0.000176, l3: 0.000346, l4: 0.000723, l5: 0.001425, l6: 0.002662

[epoch: 457/1000, batch:   528/ 1052, ite: 120060] train loss: 0.004314, tar: 0.000115 
l0: 0.000114, l1: 0.000118, l2: 0.000147, l3: 0.000199, l4: 0.000635, l5: 0.001430, l6: 0.002531

[epoch: 457/1000, batch:   608/ 1052, ite: 120080] train loss: 0.004315, tar: 0.000115 
l0: 0.000136, l1: 0.000138, l2: 0.000156, l3: 0.000193, l4: 0.000469, l5: 0.001149, l6: 0.002052

[epoch: 457/1000, batch:   688/ 1052, ite: 120100] train loss: 0.004313, tar: 0.000115 
l0: 0.000086, l1: 0.000086, l2: 0.000121, l3: 0.000170, l4: 0.000226, l5: 0.000695, l6: 0.001180

[epoch: 457/1000, batch:   768/ 1052, ite: 120120] train loss: 0.004314, tar: 0.000115 
l0: 0.000117, l1: 0.000115, l2: 0.000189, l3: 0.000254, l4: 0.000464, l5: 0.001049, l6: 0.003315

[epoch: 457/1000, batch:   848/ 1052, ite: 120140] train loss: 0.004316, tar: 0.000115 
l0: 0.000095, l1: 0.000096, l2: 0.000118, l3: 0.000201, l4: 0.000380, l5: 0.001139, l6: 0.001309

[epoch: 457/1000, batch:   928/ 1052, ite: 120160] train loss: 0.004317, tar: 0.000115 
l0: 0.000066, l1: 0.000067, l2: 0.000083, l3: 0.000105, l4: 0.000277, l5: 0.000565, l6: 0.001354

[epoch: 457/1000, batch:  1008/ 1052, ite: 120180] train loss: 0.004317, tar: 0.000115 
[Epoch 457/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000116, l1: 0.000120, l2: 0.000140, l3: 0.000245, l4: 0.000631, l5: 0.000890, l6: 0.001746

[epoch: 458/1000, batch:    36/ 1052, ite: 120200] train loss: 0.004317, tar: 0.000115 
l0: 0.000051, l1: 0.000054, l2: 0.000067, l3: 0.000120, l4: 0.000338, l5: 0.001007, l6: 0.001168

[epoch: 458/1000, batch:   116/ 1052, ite: 120220] train loss: 0.004319, tar: 0.000115 
l0: 0.000107, l1: 0.000113, l2: 0.000113, l3: 0.000184, l4: 0.000468, l5: 0.000996, l6: 0.001796

[epoch: 458/1000, batch:   196/ 1052, ite: 120240] train loss: 0.004320, tar: 0.000115 
l0: 0.000075, l1: 0.000075, l2: 0.000095, l3: 0.000170, l4: 0.000274, l5: 0.000705, l6: 0.001220

[epoch: 458/1000, batch:   276/ 1052, ite: 120260] train loss: 0.004318, tar: 0.000115 
l0: 0.000068, l1: 0.000069, l2: 0.000115, l3: 0.000191, l4: 0.000506, l5: 0.000707, l6: 0.001336

[epoch: 458/1000, batch:   356/ 1052, ite: 120280] train loss: 0.004317, tar: 0.000115 
l0: 0.000155, l1: 0.000152, l2: 0.000146, l3: 0.000233, l4: 0.000363, l5: 0.001246, l6: 0.002071

[epoch: 458/1000, batch:   436/ 1052, ite: 120300] train loss: 0.004316, tar: 0.000115 
l0: 0.000040, l1: 0.000040, l2: 0.000075, l3: 0.000200, l4: 0.000486, l5: 0.000941, l6: 0.001705

[epoch: 458/1000, batch:   516/ 1052, ite: 120320] train loss: 0.004314, tar: 0.000115 
l0: 0.000043, l1: 0.000043, l2: 0.000076, l3: 0.000172, l4: 0.000359, l5: 0.000741, l6: 0.001538

[epoch: 458/1000, batch:   596/ 1052, ite: 120340] train loss: 0.004316, tar: 0.000115 
l0: 0.000056, l1: 0.000056, l2: 0.000077, l3: 0.000163, l4: 0.000292, l5: 0.000696, l6: 0.001696

[epoch: 458/1000, batch:   676/ 1052, ite: 120360] train loss: 0.004316, tar: 0.000115 
l0: 0.000143, l1: 0.000142, l2: 0.000205, l3: 0.000374, l4: 0.000810, l5: 0.001568, l6: 0.002461

[epoch: 458/1000, batch:   756/ 1052, ite: 120380] train loss: 0.004316, tar: 0.000115 
l0: 0.000066, l1: 0.000066, l2: 0.000081, l3: 0.000215, l4: 0.000438, l5: 0.001022, l6: 0.001231

[epoch: 458/1000, batch:   836/ 1052, ite: 120400] train loss: 0.004315, tar: 0.000115 
l0: 0.000160, l1: 0.000164, l2: 0.000199, l3: 0.000285, l4: 0.000566, l5: 0.001359, l6: 0.003573

[epoch: 458/1000, batch:   916/ 1052, ite: 120420] train loss: 0.004314, tar: 0.000115 
l0: 0.000191, l1: 0.000191, l2: 0.000273, l3: 0.000346, l4: 0.000604, l5: 0.000950, l6: 0.002936

[epoch: 458/1000, batch:   996/ 1052, ite: 120440] train loss: 0.004318, tar: 0.000115 
[Epoch 458/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000114, l1: 0.000110, l2: 0.000163, l3: 0.000306, l4: 0.000418, l5: 0.000925, l6: 0.001574

[epoch: 459/1000, batch:    24/ 1052, ite: 120460] train loss: 0.004315, tar: 0.000115 
l0: 0.000083, l1: 0.000082, l2: 0.000105, l3: 0.000212, l4: 0.000278, l5: 0.000865, l6: 0.001524

[epoch: 459/1000, batch:   104/ 1052, ite: 120480] train loss: 0.004316, tar: 0.000115 
l0: 0.000127, l1: 0.000132, l2: 0.000215, l3: 0.000538, l4: 0.000761, l5: 0.001376, l6: 0.002180

[epoch: 459/1000, batch:   184/ 1052, ite: 120500] train loss: 0.004318, tar: 0.000115 
l0: 0.000096, l1: 0.000097, l2: 0.000115, l3: 0.000141, l4: 0.000448, l5: 0.000605, l6: 0.001029

[epoch: 459/1000, batch:   264/ 1052, ite: 120520] train loss: 0.004315, tar: 0.000115 
l0: 0.000099, l1: 0.000099, l2: 0.000169, l3: 0.000209, l4: 0.000337, l5: 0.000876, l6: 0.002131

[epoch: 459/1000, batch:   344/ 1052, ite: 120540] train loss: 0.004314, tar: 0.000115 
l0: 0.000063, l1: 0.000062, l2: 0.000110, l3: 0.000169, l4: 0.000352, l5: 0.000848, l6: 0.001957

[epoch: 459/1000, batch:   424/ 1052, ite: 120560] train loss: 0.004313, tar: 0.000115 
l0: 0.000221, l1: 0.000225, l2: 0.000286, l3: 0.000381, l4: 0.000740, l5: 0.001355, l6: 0.002545

[epoch: 459/1000, batch:   504/ 1052, ite: 120580] train loss: 0.004314, tar: 0.000115 
l0: 0.000069, l1: 0.000065, l2: 0.000112, l3: 0.000190, l4: 0.000237, l5: 0.000693, l6: 0.001211

[epoch: 459/1000, batch:   584/ 1052, ite: 120600] train loss: 0.004313, tar: 0.000115 
l0: 0.000148, l1: 0.000153, l2: 0.000159, l3: 0.000252, l4: 0.000625, l5: 0.001309, l6: 0.002807

[epoch: 459/1000, batch:   664/ 1052, ite: 120620] train loss: 0.004313, tar: 0.000115 
l0: 0.000119, l1: 0.000118, l2: 0.000157, l3: 0.000179, l4: 0.000486, l5: 0.001081, l6: 0.002094

[epoch: 459/1000, batch:   744/ 1052, ite: 120640] train loss: 0.004314, tar: 0.000115 
l0: 0.000125, l1: 0.000128, l2: 0.000176, l3: 0.000399, l4: 0.000565, l5: 0.001208, l6: 0.002661

[epoch: 459/1000, batch:   824/ 1052, ite: 120660] train loss: 0.004314, tar: 0.000115 
l0: 0.000128, l1: 0.000129, l2: 0.000189, l3: 0.000390, l4: 0.000830, l5: 0.001735, l6: 0.002186

[epoch: 459/1000, batch:   904/ 1052, ite: 120680] train loss: 0.004312, tar: 0.000114 
l0: 0.000150, l1: 0.000146, l2: 0.000196, l3: 0.000268, l4: 0.000408, l5: 0.000915, l6: 0.001436

[epoch: 459/1000, batch:   984/ 1052, ite: 120700] train loss: 0.004313, tar: 0.000114 
[Epoch 459/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000044, l1: 0.000043, l2: 0.000100, l3: 0.000141, l4: 0.000454, l5: 0.001110, l6: 0.001418

[epoch: 460/1000, batch:    12/ 1052, ite: 120720] train loss: 0.004313, tar: 0.000115 
l0: 0.000055, l1: 0.000056, l2: 0.000092, l3: 0.000212, l4: 0.000354, l5: 0.000821, l6: 0.001290

[epoch: 460/1000, batch:    92/ 1052, ite: 120740] train loss: 0.004310, tar: 0.000114 
l0: 0.000046, l1: 0.000047, l2: 0.000096, l3: 0.000320, l4: 0.000486, l5: 0.000975, l6: 0.001447

[epoch: 460/1000, batch:   172/ 1052, ite: 120760] train loss: 0.004309, tar: 0.000114 
l0: 0.000098, l1: 0.000097, l2: 0.000147, l3: 0.000209, l4: 0.000391, l5: 0.000848, l6: 0.001230

[epoch: 460/1000, batch:   252/ 1052, ite: 120780] train loss: 0.004307, tar: 0.000114 
l0: 0.000090, l1: 0.000090, l2: 0.000158, l3: 0.000307, l4: 0.000569, l5: 0.001331, l6: 0.002795

[epoch: 460/1000, batch:   332/ 1052, ite: 120800] train loss: 0.004310, tar: 0.000114 
l0: 0.000154, l1: 0.000162, l2: 0.000198, l3: 0.000261, l4: 0.000474, l5: 0.001132, l6: 0.001478

[epoch: 460/1000, batch:   412/ 1052, ite: 120820] train loss: 0.004312, tar: 0.000114 
l0: 0.000077, l1: 0.000076, l2: 0.000107, l3: 0.000152, l4: 0.000392, l5: 0.000837, l6: 0.001561

[epoch: 460/1000, batch:   492/ 1052, ite: 120840] train loss: 0.004313, tar: 0.000114 
l0: 0.000055, l1: 0.000053, l2: 0.000107, l3: 0.000145, l4: 0.000580, l5: 0.001267, l6: 0.002179

[epoch: 460/1000, batch:   572/ 1052, ite: 120860] train loss: 0.004315, tar: 0.000114 
l0: 0.000043, l1: 0.000045, l2: 0.000044, l3: 0.000117, l4: 0.000315, l5: 0.000343, l6: 0.000885

[epoch: 460/1000, batch:   652/ 1052, ite: 120880] train loss: 0.004314, tar: 0.000114 
l0: 0.000098, l1: 0.000099, l2: 0.000135, l3: 0.000242, l4: 0.000495, l5: 0.001682, l6: 0.004002

[epoch: 460/1000, batch:   732/ 1052, ite: 120900] train loss: 0.004315, tar: 0.000114 
l0: 0.000135, l1: 0.000137, l2: 0.000164, l3: 0.000400, l4: 0.000911, l5: 0.001669, l6: 0.002642

[epoch: 460/1000, batch:   812/ 1052, ite: 120920] train loss: 0.004316, tar: 0.000114 
l0: 0.000111, l1: 0.000112, l2: 0.000138, l3: 0.000219, l4: 0.000458, l5: 0.000778, l6: 0.001211

[epoch: 460/1000, batch:   892/ 1052, ite: 120940] train loss: 0.004315, tar: 0.000114 
l0: 0.000147, l1: 0.000150, l2: 0.000149, l3: 0.000291, l4: 0.000415, l5: 0.001073, l6: 0.002793

[epoch: 460/1000, batch:   972/ 1052, ite: 120960] train loss: 0.004314, tar: 0.000114 
l0: 0.000136, l1: 0.000139, l2: 0.000153, l3: 0.000234, l4: 0.000361, l5: 0.000796, l6: 0.001304

[epoch: 460/1000, batch:  1052/ 1052, ite: 120980] train loss: 0.004314, tar: 0.000114 
[Epoch 460/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000086, l1: 0.000086, l2: 0.000119, l3: 0.000247, l4: 0.000623, l5: 0.000943, l6: 0.002125

[epoch: 461/1000, batch:    80/ 1052, ite: 121000] train loss: 0.004314, tar: 0.000114 
l0: 0.000105, l1: 0.000111, l2: 0.000113, l3: 0.000216, l4: 0.000342, l5: 0.000890, l6: 0.001632

[epoch: 461/1000, batch:   160/ 1052, ite: 121020] train loss: 0.004314, tar: 0.000114 
l0: 0.000107, l1: 0.000109, l2: 0.000144, l3: 0.000225, l4: 0.000480, l5: 0.001573, l6: 0.002741

[epoch: 461/1000, batch:   240/ 1052, ite: 121040] train loss: 0.004315, tar: 0.000114 
l0: 0.000115, l1: 0.000119, l2: 0.000139, l3: 0.000243, l4: 0.000557, l5: 0.001324, l6: 0.002054

[epoch: 461/1000, batch:   320/ 1052, ite: 121060] train loss: 0.004315, tar: 0.000114 
l0: 0.000042, l1: 0.000043, l2: 0.000058, l3: 0.000098, l4: 0.000407, l5: 0.000476, l6: 0.001779

[epoch: 461/1000, batch:   400/ 1052, ite: 121080] train loss: 0.004317, tar: 0.000114 
l0: 0.000274, l1: 0.000275, l2: 0.000319, l3: 0.000448, l4: 0.000768, l5: 0.001249, l6: 0.003237

[epoch: 461/1000, batch:   480/ 1052, ite: 121100] train loss: 0.004317, tar: 0.000114 
l0: 0.000104, l1: 0.000108, l2: 0.000159, l3: 0.000528, l4: 0.000962, l5: 0.001763, l6: 0.003444

[epoch: 461/1000, batch:   560/ 1052, ite: 121120] train loss: 0.004317, tar: 0.000114 
l0: 0.000247, l1: 0.000262, l2: 0.000331, l3: 0.000519, l4: 0.001280, l5: 0.002063, l6: 0.003327

[epoch: 461/1000, batch:   640/ 1052, ite: 121140] train loss: 0.004316, tar: 0.000114 
l0: 0.000131, l1: 0.000131, l2: 0.000178, l3: 0.000280, l4: 0.000819, l5: 0.001544, l6: 0.003567

[epoch: 461/1000, batch:   720/ 1052, ite: 121160] train loss: 0.004316, tar: 0.000114 
l0: 0.000055, l1: 0.000055, l2: 0.000112, l3: 0.000163, l4: 0.000429, l5: 0.001135, l6: 0.002361

[epoch: 461/1000, batch:   800/ 1052, ite: 121180] train loss: 0.004313, tar: 0.000114 
l0: 0.000057, l1: 0.000062, l2: 0.000072, l3: 0.000134, l4: 0.000357, l5: 0.001022, l6: 0.001575

[epoch: 461/1000, batch:   880/ 1052, ite: 121200] train loss: 0.004312, tar: 0.000114 
l0: 0.000149, l1: 0.000152, l2: 0.000233, l3: 0.000477, l4: 0.000719, l5: 0.001496, l6: 0.003105

[epoch: 461/1000, batch:   960/ 1052, ite: 121220] train loss: 0.004313, tar: 0.000114 
l0: 0.000106, l1: 0.000107, l2: 0.000144, l3: 0.000286, l4: 0.000534, l5: 0.001224, l6: 0.002511

[epoch: 461/1000, batch:  1040/ 1052, ite: 121240] train loss: 0.004313, tar: 0.000114 
[Epoch 461/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000233, l1: 0.000240, l2: 0.000343, l3: 0.000513, l4: 0.000716, l5: 0.002069, l6: 0.003723

[epoch: 462/1000, batch:    68/ 1052, ite: 121260] train loss: 0.004312, tar: 0.000114 
l0: 0.000089, l1: 0.000094, l2: 0.000124, l3: 0.000176, l4: 0.000456, l5: 0.001132, l6: 0.001870

[epoch: 462/1000, batch:   148/ 1052, ite: 121280] train loss: 0.004311, tar: 0.000114 
l0: 0.000044, l1: 0.000043, l2: 0.000081, l3: 0.000192, l4: 0.000498, l5: 0.000860, l6: 0.001339

[epoch: 462/1000, batch:   228/ 1052, ite: 121300] train loss: 0.004310, tar: 0.000114 
l0: 0.000086, l1: 0.000085, l2: 0.000163, l3: 0.000374, l4: 0.000773, l5: 0.001367, l6: 0.002322

[epoch: 462/1000, batch:   308/ 1052, ite: 121320] train loss: 0.004310, tar: 0.000114 
l0: 0.000062, l1: 0.000063, l2: 0.000102, l3: 0.000130, l4: 0.000301, l5: 0.001067, l6: 0.001846

[epoch: 462/1000, batch:   388/ 1052, ite: 121340] train loss: 0.004311, tar: 0.000114 
l0: 0.000092, l1: 0.000089, l2: 0.000120, l3: 0.000191, l4: 0.000405, l5: 0.001098, l6: 0.001586

[epoch: 462/1000, batch:   468/ 1052, ite: 121360] train loss: 0.004310, tar: 0.000114 
l0: 0.000104, l1: 0.000107, l2: 0.000132, l3: 0.000157, l4: 0.000389, l5: 0.001010, l6: 0.001857

[epoch: 462/1000, batch:   548/ 1052, ite: 121380] train loss: 0.004310, tar: 0.000114 
l0: 0.000106, l1: 0.000103, l2: 0.000120, l3: 0.000193, l4: 0.000451, l5: 0.000648, l6: 0.001271

[epoch: 462/1000, batch:   628/ 1052, ite: 121400] train loss: 0.004309, tar: 0.000114 
l0: 0.000135, l1: 0.000136, l2: 0.000178, l3: 0.000368, l4: 0.000798, l5: 0.001865, l6: 0.002800

[epoch: 462/1000, batch:   708/ 1052, ite: 121420] train loss: 0.004309, tar: 0.000114 
l0: 0.000150, l1: 0.000154, l2: 0.000175, l3: 0.000330, l4: 0.000610, l5: 0.001359, l6: 0.002036

[epoch: 462/1000, batch:   788/ 1052, ite: 121440] train loss: 0.004309, tar: 0.000114 
l0: 0.000051, l1: 0.000051, l2: 0.000113, l3: 0.000366, l4: 0.000671, l5: 0.001415, l6: 0.002531

[epoch: 462/1000, batch:   868/ 1052, ite: 121460] train loss: 0.004309, tar: 0.000114 
l0: 0.000058, l1: 0.000059, l2: 0.000087, l3: 0.000153, l4: 0.000527, l5: 0.001174, l6: 0.001817

[epoch: 462/1000, batch:   948/ 1052, ite: 121480] train loss: 0.004310, tar: 0.000114 
l0: 0.000146, l1: 0.000151, l2: 0.000179, l3: 0.000307, l4: 0.000589, l5: 0.000949, l6: 0.001699

[epoch: 462/1000, batch:  1028/ 1052, ite: 121500] train loss: 0.004310, tar: 0.000114 
[Epoch 462/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000452, l1: 0.000455, l2: 0.000516, l3: 0.000622, l4: 0.000930, l5: 0.001531, l6: 0.002443

[epoch: 463/1000, batch:    56/ 1052, ite: 121520] train loss: 0.004310, tar: 0.000114 
l0: 0.000094, l1: 0.000088, l2: 0.000137, l3: 0.000223, l4: 0.000309, l5: 0.000976, l6: 0.001851

[epoch: 463/1000, batch:   136/ 1052, ite: 121540] train loss: 0.004308, tar: 0.000114 
l0: 0.000068, l1: 0.000066, l2: 0.000139, l3: 0.000285, l4: 0.000497, l5: 0.000799, l6: 0.001328

[epoch: 463/1000, batch:   216/ 1052, ite: 121560] train loss: 0.004306, tar: 0.000114 
l0: 0.000079, l1: 0.000077, l2: 0.000143, l3: 0.000197, l4: 0.000407, l5: 0.001047, l6: 0.002347

[epoch: 463/1000, batch:   296/ 1052, ite: 121580] train loss: 0.004305, tar: 0.000114 
l0: 0.000071, l1: 0.000070, l2: 0.000119, l3: 0.000196, l4: 0.000566, l5: 0.000971, l6: 0.001580

[epoch: 463/1000, batch:   376/ 1052, ite: 121600] train loss: 0.004305, tar: 0.000114 
l0: 0.000159, l1: 0.000160, l2: 0.000164, l3: 0.000288, l4: 0.000581, l5: 0.001314, l6: 0.001404

[epoch: 463/1000, batch:   456/ 1052, ite: 121620] train loss: 0.004305, tar: 0.000114 
l0: 0.000148, l1: 0.000146, l2: 0.000198, l3: 0.000290, l4: 0.000648, l5: 0.001477, l6: 0.003620

[epoch: 463/1000, batch:   536/ 1052, ite: 121640] train loss: 0.004307, tar: 0.000114 
l0: 0.000040, l1: 0.000042, l2: 0.000059, l3: 0.000112, l4: 0.000449, l5: 0.000759, l6: 0.001798

[epoch: 463/1000, batch:   616/ 1052, ite: 121660] train loss: 0.004306, tar: 0.000114 
l0: 0.000042, l1: 0.000044, l2: 0.000070, l3: 0.000132, l4: 0.000350, l5: 0.000706, l6: 0.001007

[epoch: 463/1000, batch:   696/ 1052, ite: 121680] train loss: 0.004307, tar: 0.000114 
l0: 0.000073, l1: 0.000074, l2: 0.000111, l3: 0.000140, l4: 0.000462, l5: 0.000599, l6: 0.001748

[epoch: 463/1000, batch:   776/ 1052, ite: 121700] train loss: 0.004308, tar: 0.000114 
l0: 0.000048, l1: 0.000048, l2: 0.000127, l3: 0.000235, l4: 0.000379, l5: 0.001221, l6: 0.002158

[epoch: 463/1000, batch:   856/ 1052, ite: 121720] train loss: 0.004307, tar: 0.000114 
l0: 0.000092, l1: 0.000089, l2: 0.000135, l3: 0.000295, l4: 0.000600, l5: 0.000944, l6: 0.001656

[epoch: 463/1000, batch:   936/ 1052, ite: 121740] train loss: 0.004308, tar: 0.000114 
l0: 0.000108, l1: 0.000112, l2: 0.000143, l3: 0.000212, l4: 0.000483, l5: 0.001120, l6: 0.001865

[epoch: 463/1000, batch:  1016/ 1052, ite: 121760] train loss: 0.004309, tar: 0.000114 
[Epoch 463/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000076, l1: 0.000078, l2: 0.000080, l3: 0.000129, l4: 0.000390, l5: 0.001043, l6: 0.001554

[epoch: 464/1000, batch:    44/ 1052, ite: 121780] train loss: 0.004308, tar: 0.000114 
l0: 0.000093, l1: 0.000093, l2: 0.000114, l3: 0.000166, l4: 0.000414, l5: 0.000618, l6: 0.001555

[epoch: 464/1000, batch:   124/ 1052, ite: 121800] train loss: 0.004310, tar: 0.000114 
l0: 0.000115, l1: 0.000117, l2: 0.000123, l3: 0.000158, l4: 0.000373, l5: 0.000795, l6: 0.001363

[epoch: 464/1000, batch:   204/ 1052, ite: 121820] train loss: 0.004311, tar: 0.000114 
l0: 0.000103, l1: 0.000103, l2: 0.000153, l3: 0.000242, l4: 0.000473, l5: 0.001689, l6: 0.002468

[epoch: 464/1000, batch:   284/ 1052, ite: 121840] train loss: 0.004312, tar: 0.000114 
l0: 0.000054, l1: 0.000053, l2: 0.000095, l3: 0.000251, l4: 0.000643, l5: 0.001717, l6: 0.002140

[epoch: 464/1000, batch:   364/ 1052, ite: 121860] train loss: 0.004312, tar: 0.000114 
l0: 0.000169, l1: 0.000168, l2: 0.000204, l3: 0.000437, l4: 0.000887, l5: 0.001412, l6: 0.003102

[epoch: 464/1000, batch:   444/ 1052, ite: 121880] train loss: 0.004312, tar: 0.000114 
l0: 0.000130, l1: 0.000130, l2: 0.000165, l3: 0.000234, l4: 0.000350, l5: 0.000722, l6: 0.001602

[epoch: 464/1000, batch:   524/ 1052, ite: 121900] train loss: 0.004310, tar: 0.000114 
l0: 0.000115, l1: 0.000120, l2: 0.000136, l3: 0.000176, l4: 0.000402, l5: 0.000999, l6: 0.001863

[epoch: 464/1000, batch:   604/ 1052, ite: 121920] train loss: 0.004310, tar: 0.000114 
l0: 0.000051, l1: 0.000053, l2: 0.000115, l3: 0.000185, l4: 0.000457, l5: 0.001205, l6: 0.002065

[epoch: 464/1000, batch:   684/ 1052, ite: 121940] train loss: 0.004312, tar: 0.000114 
l0: 0.000045, l1: 0.000046, l2: 0.000059, l3: 0.000206, l4: 0.000309, l5: 0.001032, l6: 0.001357

[epoch: 464/1000, batch:   764/ 1052, ite: 121960] train loss: 0.004313, tar: 0.000114 
l0: 0.000030, l1: 0.000031, l2: 0.000056, l3: 0.000153, l4: 0.000262, l5: 0.000864, l6: 0.001154

[epoch: 464/1000, batch:   844/ 1052, ite: 121980] train loss: 0.004312, tar: 0.000114 
l0: 0.000240, l1: 0.000235, l2: 0.000271, l3: 0.000494, l4: 0.000572, l5: 0.001274, l6: 0.002111

[epoch: 464/1000, batch:   924/ 1052, ite: 122000] train loss: 0.004312, tar: 0.000114 
l0: 0.000233, l1: 0.000252, l2: 0.000165, l3: 0.000274, l4: 0.000588, l5: 0.001516, l6: 0.001896

[epoch: 464/1000, batch:  1004/ 1052, ite: 122020] train loss: 0.004311, tar: 0.000114 
[Epoch 464/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000078, l1: 0.000074, l2: 0.000138, l3: 0.000249, l4: 0.000721, l5: 0.001169, l6: 0.001865

[epoch: 465/1000, batch:    32/ 1052, ite: 122040] train loss: 0.004311, tar: 0.000114 
l0: 0.000086, l1: 0.000090, l2: 0.000106, l3: 0.000186, l4: 0.000432, l5: 0.001256, l6: 0.001657

[epoch: 465/1000, batch:   112/ 1052, ite: 122060] train loss: 0.004310, tar: 0.000113 
l0: 0.000047, l1: 0.000046, l2: 0.000079, l3: 0.000115, l4: 0.000300, l5: 0.000383, l6: 0.000945

[epoch: 465/1000, batch:   192/ 1052, ite: 122080] train loss: 0.004309, tar: 0.000113 
l0: 0.000072, l1: 0.000070, l2: 0.000118, l3: 0.000213, l4: 0.000443, l5: 0.000935, l6: 0.001519

[epoch: 465/1000, batch:   272/ 1052, ite: 122100] train loss: 0.004311, tar: 0.000113 
l0: 0.000185, l1: 0.000192, l2: 0.000313, l3: 0.000523, l4: 0.001487, l5: 0.002018, l6: 0.003620

[epoch: 465/1000, batch:   352/ 1052, ite: 122120] train loss: 0.004311, tar: 0.000113 
l0: 0.000103, l1: 0.000104, l2: 0.000155, l3: 0.000271, l4: 0.000436, l5: 0.001272, l6: 0.003022

[epoch: 465/1000, batch:   432/ 1052, ite: 122140] train loss: 0.004312, tar: 0.000113 
l0: 0.000043, l1: 0.000046, l2: 0.000074, l3: 0.000152, l4: 0.000435, l5: 0.000814, l6: 0.001455

[epoch: 465/1000, batch:   512/ 1052, ite: 122160] train loss: 0.004312, tar: 0.000113 
l0: 0.000025, l1: 0.000027, l2: 0.000037, l3: 0.000079, l4: 0.000344, l5: 0.000603, l6: 0.001234

[epoch: 465/1000, batch:   592/ 1052, ite: 122180] train loss: 0.004312, tar: 0.000113 
l0: 0.000050, l1: 0.000050, l2: 0.000071, l3: 0.000137, l4: 0.000311, l5: 0.000797, l6: 0.001274

[epoch: 465/1000, batch:   672/ 1052, ite: 122200] train loss: 0.004310, tar: 0.000113 
l0: 0.000081, l1: 0.000081, l2: 0.000141, l3: 0.000294, l4: 0.000635, l5: 0.001113, l6: 0.002824

[epoch: 465/1000, batch:   752/ 1052, ite: 122220] train loss: 0.004309, tar: 0.000113 
l0: 0.000105, l1: 0.000107, l2: 0.000152, l3: 0.000271, l4: 0.000708, l5: 0.001241, l6: 0.002290

[epoch: 465/1000, batch:   832/ 1052, ite: 122240] train loss: 0.004309, tar: 0.000113 
l0: 0.000079, l1: 0.000077, l2: 0.000121, l3: 0.000222, l4: 0.000333, l5: 0.001079, l6: 0.001157

[epoch: 465/1000, batch:   912/ 1052, ite: 122260] train loss: 0.004307, tar: 0.000113 
l0: 0.000119, l1: 0.000117, l2: 0.000201, l3: 0.000375, l4: 0.000601, l5: 0.001456, l6: 0.003528

[epoch: 465/1000, batch:   992/ 1052, ite: 122280] train loss: 0.004307, tar: 0.000113 
[Epoch 465/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000132, l1: 0.000132, l2: 0.000213, l3: 0.000327, l4: 0.000495, l5: 0.001107, l6: 0.001937

[epoch: 466/1000, batch:    20/ 1052, ite: 122300] train loss: 0.004309, tar: 0.000113 
l0: 0.000066, l1: 0.000065, l2: 0.000089, l3: 0.000148, l4: 0.000298, l5: 0.001115, l6: 0.001281

[epoch: 466/1000, batch:   100/ 1052, ite: 122320] train loss: 0.004308, tar: 0.000113 
l0: 0.000119, l1: 0.000118, l2: 0.000177, l3: 0.000247, l4: 0.000701, l5: 0.001362, l6: 0.002227

[epoch: 466/1000, batch:   180/ 1052, ite: 122340] train loss: 0.004307, tar: 0.000113 
l0: 0.000082, l1: 0.000081, l2: 0.000156, l3: 0.000333, l4: 0.000554, l5: 0.001205, l6: 0.001841

[epoch: 466/1000, batch:   260/ 1052, ite: 122360] train loss: 0.004306, tar: 0.000113 
l0: 0.000130, l1: 0.000130, l2: 0.000181, l3: 0.000349, l4: 0.000561, l5: 0.001336, l6: 0.002562

[epoch: 466/1000, batch:   340/ 1052, ite: 122380] train loss: 0.004307, tar: 0.000113 
l0: 0.000076, l1: 0.000087, l2: 0.000101, l3: 0.000343, l4: 0.000517, l5: 0.001069, l6: 0.001543

[epoch: 466/1000, batch:   420/ 1052, ite: 122400] train loss: 0.004306, tar: 0.000113 
l0: 0.000108, l1: 0.000108, l2: 0.000150, l3: 0.000220, l4: 0.000556, l5: 0.000975, l6: 0.002298

[epoch: 466/1000, batch:   500/ 1052, ite: 122420] train loss: 0.004304, tar: 0.000113 
l0: 0.000162, l1: 0.000167, l2: 0.000210, l3: 0.000331, l4: 0.000833, l5: 0.001936, l6: 0.003910

[epoch: 466/1000, batch:   580/ 1052, ite: 122440] train loss: 0.004304, tar: 0.000113 
l0: 0.000082, l1: 0.000081, l2: 0.000120, l3: 0.000200, l4: 0.000316, l5: 0.000789, l6: 0.001232

[epoch: 466/1000, batch:   660/ 1052, ite: 122460] train loss: 0.004304, tar: 0.000113 
l0: 0.000155, l1: 0.000159, l2: 0.000203, l3: 0.000384, l4: 0.000977, l5: 0.002490, l6: 0.005177

[epoch: 466/1000, batch:   740/ 1052, ite: 122480] train loss: 0.004305, tar: 0.000113 
l0: 0.000079, l1: 0.000082, l2: 0.000079, l3: 0.000096, l4: 0.000206, l5: 0.000673, l6: 0.000981

[epoch: 466/1000, batch:   820/ 1052, ite: 122500] train loss: 0.004306, tar: 0.000113 
l0: 0.000115, l1: 0.000115, l2: 0.000160, l3: 0.000205, l4: 0.000497, l5: 0.001439, l6: 0.002876

[epoch: 466/1000, batch:   900/ 1052, ite: 122520] train loss: 0.004306, tar: 0.000113 
l0: 0.000151, l1: 0.000151, l2: 0.000221, l3: 0.000442, l4: 0.000757, l5: 0.002418, l6: 0.003123

[epoch: 466/1000, batch:   980/ 1052, ite: 122540] train loss: 0.004307, tar: 0.000113 
[Epoch 466/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000109, l1: 0.000106, l2: 0.000172, l3: 0.000248, l4: 0.000626, l5: 0.000845, l6: 0.001775

[epoch: 467/1000, batch:     8/ 1052, ite: 122560] train loss: 0.004306, tar: 0.000113 
l0: 0.000065, l1: 0.000062, l2: 0.000106, l3: 0.000194, l4: 0.000454, l5: 0.000781, l6: 0.001409

[epoch: 467/1000, batch:    88/ 1052, ite: 122580] train loss: 0.004308, tar: 0.000113 
l0: 0.000045, l1: 0.000045, l2: 0.000073, l3: 0.000139, l4: 0.000534, l5: 0.001060, l6: 0.001488

[epoch: 467/1000, batch:   168/ 1052, ite: 122600] train loss: 0.004309, tar: 0.000113 
l0: 0.000049, l1: 0.000048, l2: 0.000111, l3: 0.000211, l4: 0.000386, l5: 0.000747, l6: 0.001343

[epoch: 467/1000, batch:   248/ 1052, ite: 122620] train loss: 0.004307, tar: 0.000113 
l0: 0.000024, l1: 0.000026, l2: 0.000036, l3: 0.000091, l4: 0.000175, l5: 0.000379, l6: 0.000788

[epoch: 467/1000, batch:   328/ 1052, ite: 122640] train loss: 0.004305, tar: 0.000113 
l0: 0.000088, l1: 0.000085, l2: 0.000099, l3: 0.000242, l4: 0.000397, l5: 0.000727, l6: 0.001424

[epoch: 467/1000, batch:   408/ 1052, ite: 122660] train loss: 0.004305, tar: 0.000113 
l0: 0.000132, l1: 0.000132, l2: 0.000160, l3: 0.000228, l4: 0.000467, l5: 0.001375, l6: 0.002634

[epoch: 467/1000, batch:   488/ 1052, ite: 122680] train loss: 0.004304, tar: 0.000113 
l0: 0.000089, l1: 0.000087, l2: 0.000139, l3: 0.000231, l4: 0.000601, l5: 0.001383, l6: 0.002757

[epoch: 467/1000, batch:   568/ 1052, ite: 122700] train loss: 0.004304, tar: 0.000113 
l0: 0.000064, l1: 0.000065, l2: 0.000097, l3: 0.000268, l4: 0.000496, l5: 0.001033, l6: 0.001317

[epoch: 467/1000, batch:   648/ 1052, ite: 122720] train loss: 0.004303, tar: 0.000113 
l0: 0.000131, l1: 0.000136, l2: 0.000206, l3: 0.000349, l4: 0.000540, l5: 0.001212, l6: 0.002154

[epoch: 467/1000, batch:   728/ 1052, ite: 122740] train loss: 0.004303, tar: 0.000112 
l0: 0.000281, l1: 0.000279, l2: 0.000397, l3: 0.000459, l4: 0.000688, l5: 0.001566, l6: 0.005003

[epoch: 467/1000, batch:   808/ 1052, ite: 122760] train loss: 0.004303, tar: 0.000113 
l0: 0.000161, l1: 0.000157, l2: 0.000255, l3: 0.000436, l4: 0.001064, l5: 0.002488, l6: 0.003579

[epoch: 467/1000, batch:   888/ 1052, ite: 122780] train loss: 0.004303, tar: 0.000112 
l0: 0.000099, l1: 0.000099, l2: 0.000146, l3: 0.000379, l4: 0.000905, l5: 0.001931, l6: 0.001992

[epoch: 467/1000, batch:   968/ 1052, ite: 122800] train loss: 0.004302, tar: 0.000112 
l0: 0.000097, l1: 0.000095, l2: 0.000167, l3: 0.000410, l4: 0.000723, l5: 0.001626, l6: 0.002032

[epoch: 467/1000, batch:  1048/ 1052, ite: 122820] train loss: 0.004305, tar: 0.000112 
[Epoch 467/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000116, l1: 0.000120, l2: 0.000130, l3: 0.000246, l4: 0.000452, l5: 0.001127, l6: 0.002385

[epoch: 468/1000, batch:    76/ 1052, ite: 122840] train loss: 0.004304, tar: 0.000112 
l0: 0.000070, l1: 0.000070, l2: 0.000113, l3: 0.000198, l4: 0.000398, l5: 0.000681, l6: 0.001361

[epoch: 468/1000, batch:   156/ 1052, ite: 122860] train loss: 0.004303, tar: 0.000112 
l0: 0.000118, l1: 0.000118, l2: 0.000164, l3: 0.000239, l4: 0.000401, l5: 0.001022, l6: 0.001777

[epoch: 468/1000, batch:   236/ 1052, ite: 122880] train loss: 0.004301, tar: 0.000112 
l0: 0.000129, l1: 0.000128, l2: 0.000213, l3: 0.000360, l4: 0.000677, l5: 0.001539, l6: 0.002280

[epoch: 468/1000, batch:   316/ 1052, ite: 122900] train loss: 0.004302, tar: 0.000112 
l0: 0.000098, l1: 0.000099, l2: 0.000139, l3: 0.000263, l4: 0.000564, l5: 0.000792, l6: 0.001869

[epoch: 468/1000, batch:   396/ 1052, ite: 122920] train loss: 0.004303, tar: 0.000112 
l0: 0.000125, l1: 0.000124, l2: 0.000172, l3: 0.000325, l4: 0.000708, l5: 0.001414, l6: 0.001718

[epoch: 468/1000, batch:   476/ 1052, ite: 122940] train loss: 0.004303, tar: 0.000112 
l0: 0.000053, l1: 0.000052, l2: 0.000084, l3: 0.000172, l4: 0.000385, l5: 0.000798, l6: 0.001765

[epoch: 468/1000, batch:   556/ 1052, ite: 122960] train loss: 0.004303, tar: 0.000112 
l0: 0.000088, l1: 0.000088, l2: 0.000131, l3: 0.000183, l4: 0.000436, l5: 0.000790, l6: 0.002147

[epoch: 468/1000, batch:   636/ 1052, ite: 122980] train loss: 0.004305, tar: 0.000112 
l0: 0.000158, l1: 0.000157, l2: 0.000198, l3: 0.000294, l4: 0.000717, l5: 0.001551, l6: 0.002084

[epoch: 468/1000, batch:   716/ 1052, ite: 123000] train loss: 0.004306, tar: 0.000112 
l0: 0.000105, l1: 0.000107, l2: 0.000102, l3: 0.000135, l4: 0.000432, l5: 0.000585, l6: 0.001245

[epoch: 468/1000, batch:   796/ 1052, ite: 123020] train loss: 0.004306, tar: 0.000112 
l0: 0.000063, l1: 0.000063, l2: 0.000096, l3: 0.000141, l4: 0.000365, l5: 0.001006, l6: 0.001665

[epoch: 468/1000, batch:   876/ 1052, ite: 123040] train loss: 0.004307, tar: 0.000112 
l0: 0.000121, l1: 0.000125, l2: 0.000147, l3: 0.000287, l4: 0.000417, l5: 0.000962, l6: 0.001713

[epoch: 468/1000, batch:   956/ 1052, ite: 123060] train loss: 0.004306, tar: 0.000112 
l0: 0.000115, l1: 0.000118, l2: 0.000143, l3: 0.000227, l4: 0.000451, l5: 0.001150, l6: 0.002244

[epoch: 468/1000, batch:  1036/ 1052, ite: 123080] train loss: 0.004305, tar: 0.000112 
[Epoch 468/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000109, l1: 0.000110, l2: 0.000126, l3: 0.000212, l4: 0.000581, l5: 0.001123, l6: 0.001722

[epoch: 469/1000, batch:    64/ 1052, ite: 123100] train loss: 0.004306, tar: 0.000112 
l0: 0.000058, l1: 0.000056, l2: 0.000125, l3: 0.000225, l4: 0.000423, l5: 0.000963, l6: 0.002439

[epoch: 469/1000, batch:   144/ 1052, ite: 123120] train loss: 0.004306, tar: 0.000112 
l0: 0.000047, l1: 0.000046, l2: 0.000089, l3: 0.000185, l4: 0.000210, l5: 0.000772, l6: 0.000993

[epoch: 469/1000, batch:   224/ 1052, ite: 123140] train loss: 0.004306, tar: 0.000112 
l0: 0.000051, l1: 0.000049, l2: 0.000113, l3: 0.000209, l4: 0.000770, l5: 0.001296, l6: 0.001761

[epoch: 469/1000, batch:   304/ 1052, ite: 123160] train loss: 0.004308, tar: 0.000112 
l0: 0.000357, l1: 0.000376, l2: 0.000408, l3: 0.000504, l4: 0.000781, l5: 0.001563, l6: 0.003787

[epoch: 469/1000, batch:   384/ 1052, ite: 123180] train loss: 0.004307, tar: 0.000112 
l0: 0.000084, l1: 0.000085, l2: 0.000114, l3: 0.000164, l4: 0.000294, l5: 0.000832, l6: 0.001065

[epoch: 469/1000, batch:   464/ 1052, ite: 123200] train loss: 0.004306, tar: 0.000112 
l0: 0.000047, l1: 0.000046, l2: 0.000107, l3: 0.000188, l4: 0.000427, l5: 0.000756, l6: 0.001487

[epoch: 469/1000, batch:   544/ 1052, ite: 123220] train loss: 0.004306, tar: 0.000112 
l0: 0.000064, l1: 0.000065, l2: 0.000082, l3: 0.000166, l4: 0.000363, l5: 0.000765, l6: 0.001161

[epoch: 469/1000, batch:   624/ 1052, ite: 123240] train loss: 0.004306, tar: 0.000112 
l0: 0.000090, l1: 0.000095, l2: 0.000121, l3: 0.000180, l4: 0.000358, l5: 0.000803, l6: 0.000711

[epoch: 469/1000, batch:   704/ 1052, ite: 123260] train loss: 0.004305, tar: 0.000112 
l0: 0.000080, l1: 0.000084, l2: 0.000107, l3: 0.000183, l4: 0.000386, l5: 0.001020, l6: 0.001216

[epoch: 469/1000, batch:   784/ 1052, ite: 123280] train loss: 0.004306, tar: 0.000112 
l0: 0.000056, l1: 0.000054, l2: 0.000077, l3: 0.000183, l4: 0.000486, l5: 0.000974, l6: 0.001464

[epoch: 469/1000, batch:   864/ 1052, ite: 123300] train loss: 0.004306, tar: 0.000113 
l0: 0.000160, l1: 0.000160, l2: 0.000309, l3: 0.000400, l4: 0.000666, l5: 0.002038, l6: 0.002956

[epoch: 469/1000, batch:   944/ 1052, ite: 123320] train loss: 0.004307, tar: 0.000113 
l0: 0.000096, l1: 0.000102, l2: 0.000099, l3: 0.000152, l4: 0.000324, l5: 0.000656, l6: 0.001478

[epoch: 469/1000, batch:  1024/ 1052, ite: 123340] train loss: 0.004307, tar: 0.000113 
[Epoch 469/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000034, l1: 0.000033, l2: 0.000062, l3: 0.000125, l4: 0.000351, l5: 0.001230, l6: 0.002127

[epoch: 470/1000, batch:    52/ 1052, ite: 123360] train loss: 0.004307, tar: 0.000113 
l0: 0.000191, l1: 0.000197, l2: 0.000213, l3: 0.000307, l4: 0.000586, l5: 0.001088, l6: 0.001853

[epoch: 470/1000, batch:   132/ 1052, ite: 123380] train loss: 0.004307, tar: 0.000113 
l0: 0.000123, l1: 0.000118, l2: 0.000153, l3: 0.000296, l4: 0.000556, l5: 0.000949, l6: 0.002135

[epoch: 470/1000, batch:   212/ 1052, ite: 123400] train loss: 0.004306, tar: 0.000113 
l0: 0.000120, l1: 0.000125, l2: 0.000146, l3: 0.000185, l4: 0.000285, l5: 0.000837, l6: 0.001841

[epoch: 470/1000, batch:   292/ 1052, ite: 123420] train loss: 0.004306, tar: 0.000113 
l0: 0.000156, l1: 0.000164, l2: 0.000216, l3: 0.000332, l4: 0.000492, l5: 0.001154, l6: 0.002144

[epoch: 470/1000, batch:   372/ 1052, ite: 123440] train loss: 0.004305, tar: 0.000112 
l0: 0.000090, l1: 0.000091, l2: 0.000136, l3: 0.000265, l4: 0.000499, l5: 0.001166, l6: 0.002175

[epoch: 470/1000, batch:   452/ 1052, ite: 123460] train loss: 0.004306, tar: 0.000113 
l0: 0.000082, l1: 0.000083, l2: 0.000135, l3: 0.000182, l4: 0.000482, l5: 0.001280, l6: 0.002549

[epoch: 470/1000, batch:   532/ 1052, ite: 123480] train loss: 0.004307, tar: 0.000113 
l0: 0.000125, l1: 0.000130, l2: 0.000123, l3: 0.000155, l4: 0.000420, l5: 0.000538, l6: 0.001308

[epoch: 470/1000, batch:   612/ 1052, ite: 123500] train loss: 0.004306, tar: 0.000112 
l0: 0.000213, l1: 0.000221, l2: 0.000245, l3: 0.000233, l4: 0.000552, l5: 0.000970, l6: 0.001902

[epoch: 470/1000, batch:   692/ 1052, ite: 123520] train loss: 0.004305, tar: 0.000112 
l0: 0.000140, l1: 0.000135, l2: 0.000215, l3: 0.000336, l4: 0.000661, l5: 0.000992, l6: 0.002291

[epoch: 470/1000, batch:   772/ 1052, ite: 123540] train loss: 0.004305, tar: 0.000112 
l0: 0.000159, l1: 0.000175, l2: 0.000215, l3: 0.000327, l4: 0.000517, l5: 0.000672, l6: 0.001565

[epoch: 470/1000, batch:   852/ 1052, ite: 123560] train loss: 0.004306, tar: 0.000112 
l0: 0.000162, l1: 0.000170, l2: 0.000178, l3: 0.000245, l4: 0.000456, l5: 0.001339, l6: 0.001909

[epoch: 470/1000, batch:   932/ 1052, ite: 123580] train loss: 0.004305, tar: 0.000112 
l0: 0.000157, l1: 0.000155, l2: 0.000214, l3: 0.000406, l4: 0.000768, l5: 0.002055, l6: 0.003769

[epoch: 470/1000, batch:  1012/ 1052, ite: 123600] train loss: 0.004305, tar: 0.000112 
[Epoch 470/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000135, l1: 0.000132, l2: 0.000179, l3: 0.000270, l4: 0.000449, l5: 0.000803, l6: 0.002280

[epoch: 471/1000, batch:    40/ 1052, ite: 123620] train loss: 0.004306, tar: 0.000112 
l0: 0.000059, l1: 0.000060, l2: 0.000080, l3: 0.000109, l4: 0.000231, l5: 0.000384, l6: 0.000864

[epoch: 471/1000, batch:   120/ 1052, ite: 123640] train loss: 0.004306, tar: 0.000112 
l0: 0.000221, l1: 0.000229, l2: 0.000244, l3: 0.000323, l4: 0.000889, l5: 0.001499, l6: 0.002395

[epoch: 471/1000, batch:   200/ 1052, ite: 123660] train loss: 0.004309, tar: 0.000113 
l0: 0.000138, l1: 0.000146, l2: 0.000204, l3: 0.000234, l4: 0.000463, l5: 0.000796, l6: 0.001431

[epoch: 471/1000, batch:   280/ 1052, ite: 123680] train loss: 0.004309, tar: 0.000113 
l0: 0.000224, l1: 0.000230, l2: 0.000328, l3: 0.000503, l4: 0.000847, l5: 0.002567, l6: 0.003085

[epoch: 471/1000, batch:   360/ 1052, ite: 123700] train loss: 0.004308, tar: 0.000113 
l0: 0.000106, l1: 0.000106, l2: 0.000209, l3: 0.000292, l4: 0.000443, l5: 0.001156, l6: 0.002338

[epoch: 471/1000, batch:   440/ 1052, ite: 123720] train loss: 0.004309, tar: 0.000113 
l0: 0.000100, l1: 0.000102, l2: 0.000180, l3: 0.000501, l4: 0.000881, l5: 0.002245, l6: 0.002988

[epoch: 471/1000, batch:   520/ 1052, ite: 123740] train loss: 0.004310, tar: 0.000113 
l0: 0.000028, l1: 0.000025, l2: 0.000086, l3: 0.000166, l4: 0.000506, l5: 0.000795, l6: 0.000960

[epoch: 471/1000, batch:   600/ 1052, ite: 123760] train loss: 0.004310, tar: 0.000113 
l0: 0.000173, l1: 0.000169, l2: 0.000209, l3: 0.000274, l4: 0.000502, l5: 0.001165, l6: 0.002205

[epoch: 471/1000, batch:   680/ 1052, ite: 123780] train loss: 0.004311, tar: 0.000113 
l0: 0.000112, l1: 0.000115, l2: 0.000197, l3: 0.000372, l4: 0.000759, l5: 0.001290, l6: 0.002675

[epoch: 471/1000, batch:   760/ 1052, ite: 123800] train loss: 0.004310, tar: 0.000113 
l0: 0.000039, l1: 0.000037, l2: 0.000059, l3: 0.000133, l4: 0.000405, l5: 0.000999, l6: 0.001150

[epoch: 471/1000, batch:   840/ 1052, ite: 123820] train loss: 0.004309, tar: 0.000113 
l0: 0.000127, l1: 0.000123, l2: 0.000210, l3: 0.000521, l4: 0.000853, l5: 0.001410, l6: 0.002323

[epoch: 471/1000, batch:   920/ 1052, ite: 123840] train loss: 0.004309, tar: 0.000113 
l0: 0.000100, l1: 0.000101, l2: 0.000163, l3: 0.000301, l4: 0.000594, l5: 0.001016, l6: 0.002614

[epoch: 471/1000, batch:  1000/ 1052, ite: 123860] train loss: 0.004310, tar: 0.000113 
[Epoch 471/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000134, l1: 0.000152, l2: 0.000161, l3: 0.000250, l4: 0.000400, l5: 0.000650, l6: 0.001785

[epoch: 472/1000, batch:    28/ 1052, ite: 123880] train loss: 0.004310, tar: 0.000113 
l0: 0.000124, l1: 0.000127, l2: 0.000164, l3: 0.000250, l4: 0.000500, l5: 0.001184, l6: 0.001399

[epoch: 472/1000, batch:   108/ 1052, ite: 123900] train loss: 0.004311, tar: 0.000113 
l0: 0.000192, l1: 0.000191, l2: 0.000204, l3: 0.000294, l4: 0.000592, l5: 0.001393, l6: 0.003604

[epoch: 472/1000, batch:   188/ 1052, ite: 123920] train loss: 0.004312, tar: 0.000113 
l0: 0.000107, l1: 0.000105, l2: 0.000200, l3: 0.000419, l4: 0.000928, l5: 0.001898, l6: 0.002631

[epoch: 472/1000, batch:   268/ 1052, ite: 123940] train loss: 0.004312, tar: 0.000113 
l0: 0.000204, l1: 0.000218, l2: 0.000240, l3: 0.000316, l4: 0.000677, l5: 0.001232, l6: 0.002766

[epoch: 472/1000, batch:   348/ 1052, ite: 123960] train loss: 0.004312, tar: 0.000113 
l0: 0.000104, l1: 0.000102, l2: 0.000149, l3: 0.000197, l4: 0.000547, l5: 0.000633, l6: 0.001791

[epoch: 472/1000, batch:   428/ 1052, ite: 123980] train loss: 0.004312, tar: 0.000113 
l0: 0.000072, l1: 0.000072, l2: 0.000106, l3: 0.000167, l4: 0.000719, l5: 0.001260, l6: 0.002091

[epoch: 472/1000, batch:   508/ 1052, ite: 124000] train loss: 0.004312, tar: 0.000113 
l0: 0.000101, l1: 0.000100, l2: 0.000141, l3: 0.000282, l4: 0.000523, l5: 0.001094, l6: 0.002849

[epoch: 472/1000, batch:   588/ 1052, ite: 124020] train loss: 0.004312, tar: 0.000113 
l0: 0.000250, l1: 0.000246, l2: 0.000288, l3: 0.000412, l4: 0.000539, l5: 0.001036, l6: 0.002181

[epoch: 472/1000, batch:   668/ 1052, ite: 124040] train loss: 0.004312, tar: 0.000113 
l0: 0.000102, l1: 0.000102, l2: 0.000145, l3: 0.000243, l4: 0.000407, l5: 0.000920, l6: 0.001563

[epoch: 472/1000, batch:   748/ 1052, ite: 124060] train loss: 0.004313, tar: 0.000113 
l0: 0.000050, l1: 0.000049, l2: 0.000075, l3: 0.000169, l4: 0.000345, l5: 0.000992, l6: 0.001512

[epoch: 472/1000, batch:   828/ 1052, ite: 124080] train loss: 0.004313, tar: 0.000113 
l0: 0.000108, l1: 0.000110, l2: 0.000149, l3: 0.000263, l4: 0.000427, l5: 0.001090, l6: 0.002062

[epoch: 472/1000, batch:   908/ 1052, ite: 124100] train loss: 0.004312, tar: 0.000113 
l0: 0.000047, l1: 0.000043, l2: 0.000113, l3: 0.000114, l4: 0.000400, l5: 0.000871, l6: 0.001307

[epoch: 472/1000, batch:   988/ 1052, ite: 124120] train loss: 0.004312, tar: 0.000113 
[Epoch 472/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000173, l1: 0.000175, l2: 0.000263, l3: 0.000327, l4: 0.000657, l5: 0.002199, l6: 0.003085

[epoch: 473/1000, batch:    16/ 1052, ite: 124140] train loss: 0.004314, tar: 0.000113 
l0: 0.000063, l1: 0.000060, l2: 0.000098, l3: 0.000226, l4: 0.000340, l5: 0.000852, l6: 0.001587

[epoch: 473/1000, batch:    96/ 1052, ite: 124160] train loss: 0.004313, tar: 0.000113 
l0: 0.000091, l1: 0.000099, l2: 0.000085, l3: 0.000156, l4: 0.000444, l5: 0.000886, l6: 0.001875

[epoch: 473/1000, batch:   176/ 1052, ite: 124180] train loss: 0.004313, tar: 0.000113 
l0: 0.000143, l1: 0.000148, l2: 0.000186, l3: 0.000358, l4: 0.000798, l5: 0.001427, l6: 0.002627

[epoch: 473/1000, batch:   256/ 1052, ite: 124200] train loss: 0.004312, tar: 0.000113 
l0: 0.000210, l1: 0.000210, l2: 0.000266, l3: 0.000349, l4: 0.000737, l5: 0.001729, l6: 0.004223

[epoch: 473/1000, batch:   336/ 1052, ite: 124220] train loss: 0.004313, tar: 0.000113 
l0: 0.000041, l1: 0.000038, l2: 0.000079, l3: 0.000201, l4: 0.000330, l5: 0.000577, l6: 0.001146

[epoch: 473/1000, batch:   416/ 1052, ite: 124240] train loss: 0.004314, tar: 0.000113 
l0: 0.000186, l1: 0.000184, l2: 0.000263, l3: 0.000393, l4: 0.000636, l5: 0.001110, l6: 0.002469

[epoch: 473/1000, batch:   496/ 1052, ite: 124260] train loss: 0.004313, tar: 0.000113 
l0: 0.000037, l1: 0.000038, l2: 0.000063, l3: 0.000142, l4: 0.000391, l5: 0.000664, l6: 0.001067

[epoch: 473/1000, batch:   576/ 1052, ite: 124280] train loss: 0.004312, tar: 0.000113 
l0: 0.000104, l1: 0.000108, l2: 0.000166, l3: 0.000334, l4: 0.000603, l5: 0.001377, l6: 0.002401

[epoch: 473/1000, batch:   656/ 1052, ite: 124300] train loss: 0.004311, tar: 0.000113 
l0: 0.000061, l1: 0.000062, l2: 0.000128, l3: 0.000188, l4: 0.000447, l5: 0.001314, l6: 0.003130

[epoch: 473/1000, batch:   736/ 1052, ite: 124320] train loss: 0.004311, tar: 0.000113 
l0: 0.000145, l1: 0.000147, l2: 0.000195, l3: 0.000262, l4: 0.000722, l5: 0.001368, l6: 0.002377

[epoch: 473/1000, batch:   816/ 1052, ite: 124340] train loss: 0.004311, tar: 0.000113 
l0: 0.000079, l1: 0.000080, l2: 0.000086, l3: 0.000160, l4: 0.000425, l5: 0.000647, l6: 0.001621

[epoch: 473/1000, batch:   896/ 1052, ite: 124360] train loss: 0.004311, tar: 0.000113 
l0: 0.000047, l1: 0.000048, l2: 0.000053, l3: 0.000092, l4: 0.000258, l5: 0.000645, l6: 0.000951

[epoch: 473/1000, batch:   976/ 1052, ite: 124380] train loss: 0.004311, tar: 0.000113 
[Epoch 473/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000030, l1: 0.000030, l2: 0.000062, l3: 0.000118, l4: 0.000331, l5: 0.000889, l6: 0.001290

[epoch: 474/1000, batch:     4/ 1052, ite: 124400] train loss: 0.004311, tar: 0.000113 
l0: 0.000064, l1: 0.000063, l2: 0.000166, l3: 0.000288, l4: 0.000608, l5: 0.001304, l6: 0.002279

[epoch: 474/1000, batch:    84/ 1052, ite: 124420] train loss: 0.004311, tar: 0.000113 
l0: 0.000143, l1: 0.000145, l2: 0.000232, l3: 0.000305, l4: 0.000551, l5: 0.001402, l6: 0.002047

[epoch: 474/1000, batch:   164/ 1052, ite: 124440] train loss: 0.004310, tar: 0.000113 
l0: 0.000075, l1: 0.000079, l2: 0.000113, l3: 0.000175, l4: 0.000376, l5: 0.001099, l6: 0.002730

[epoch: 474/1000, batch:   244/ 1052, ite: 124460] train loss: 0.004310, tar: 0.000113 
l0: 0.000113, l1: 0.000115, l2: 0.000167, l3: 0.000223, l4: 0.000462, l5: 0.000960, l6: 0.002378

[epoch: 474/1000, batch:   324/ 1052, ite: 124480] train loss: 0.004309, tar: 0.000112 
l0: 0.000070, l1: 0.000066, l2: 0.000084, l3: 0.000107, l4: 0.000406, l5: 0.000913, l6: 0.001055

[epoch: 474/1000, batch:   404/ 1052, ite: 124500] train loss: 0.004308, tar: 0.000112 
l0: 0.000137, l1: 0.000134, l2: 0.000234, l3: 0.000474, l4: 0.000869, l5: 0.001216, l6: 0.002406

[epoch: 474/1000, batch:   484/ 1052, ite: 124520] train loss: 0.004308, tar: 0.000112 
l0: 0.000067, l1: 0.000067, l2: 0.000119, l3: 0.000200, l4: 0.000423, l5: 0.001029, l6: 0.001393

[epoch: 474/1000, batch:   564/ 1052, ite: 124540] train loss: 0.004308, tar: 0.000112 
l0: 0.000070, l1: 0.000074, l2: 0.000112, l3: 0.000164, l4: 0.000400, l5: 0.001368, l6: 0.002697

[epoch: 474/1000, batch:   644/ 1052, ite: 124560] train loss: 0.004308, tar: 0.000112 
l0: 0.000063, l1: 0.000064, l2: 0.000147, l3: 0.000362, l4: 0.000618, l5: 0.000863, l6: 0.001550

[epoch: 474/1000, batch:   724/ 1052, ite: 124580] train loss: 0.004307, tar: 0.000112 
l0: 0.000021, l1: 0.000022, l2: 0.000056, l3: 0.000114, l4: 0.000297, l5: 0.000698, l6: 0.001547

[epoch: 474/1000, batch:   804/ 1052, ite: 124600] train loss: 0.004308, tar: 0.000112 
l0: 0.000082, l1: 0.000083, l2: 0.000127, l3: 0.000244, l4: 0.000512, l5: 0.000811, l6: 0.001855

[epoch: 474/1000, batch:   884/ 1052, ite: 124620] train loss: 0.004308, tar: 0.000112 
l0: 0.000064, l1: 0.000064, l2: 0.000081, l3: 0.000152, l4: 0.000541, l5: 0.001510, l6: 0.001756

[epoch: 474/1000, batch:   964/ 1052, ite: 124640] train loss: 0.004307, tar: 0.000112 
l0: 0.000207, l1: 0.000205, l2: 0.000270, l3: 0.000380, l4: 0.000845, l5: 0.001853, l6: 0.003165

[epoch: 474/1000, batch:  1044/ 1052, ite: 124660] train loss: 0.004308, tar: 0.000112 
[Epoch 474/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000066, l1: 0.000066, l2: 0.000099, l3: 0.000186, l4: 0.000437, l5: 0.001278, l6: 0.001221

[epoch: 475/1000, batch:    72/ 1052, ite: 124680] train loss: 0.004308, tar: 0.000112 
l0: 0.000101, l1: 0.000100, l2: 0.000151, l3: 0.000260, l4: 0.000486, l5: 0.000803, l6: 0.001981

[epoch: 475/1000, batch:   152/ 1052, ite: 124700] train loss: 0.004307, tar: 0.000112 
l0: 0.000075, l1: 0.000074, l2: 0.000116, l3: 0.000256, l4: 0.000476, l5: 0.001288, l6: 0.002128

[epoch: 475/1000, batch:   232/ 1052, ite: 124720] train loss: 0.004307, tar: 0.000112 
l0: 0.000047, l1: 0.000046, l2: 0.000082, l3: 0.000114, l4: 0.000288, l5: 0.000634, l6: 0.001356

[epoch: 475/1000, batch:   312/ 1052, ite: 124740] train loss: 0.004306, tar: 0.000112 
l0: 0.000088, l1: 0.000092, l2: 0.000137, l3: 0.000289, l4: 0.000650, l5: 0.001287, l6: 0.002128

[epoch: 475/1000, batch:   392/ 1052, ite: 124760] train loss: 0.004305, tar: 0.000112 
l0: 0.000097, l1: 0.000095, l2: 0.000198, l3: 0.000273, l4: 0.000648, l5: 0.001421, l6: 0.001822

[epoch: 475/1000, batch:   472/ 1052, ite: 124780] train loss: 0.004306, tar: 0.000112 
l0: 0.000024, l1: 0.000024, l2: 0.000031, l3: 0.000053, l4: 0.000135, l5: 0.000196, l6: 0.000719

[epoch: 475/1000, batch:   552/ 1052, ite: 124800] train loss: 0.004306, tar: 0.000112 
l0: 0.000160, l1: 0.000163, l2: 0.000251, l3: 0.000366, l4: 0.000665, l5: 0.002035, l6: 0.003182

[epoch: 475/1000, batch:   632/ 1052, ite: 124820] train loss: 0.004307, tar: 0.000112 
l0: 0.000098, l1: 0.000100, l2: 0.000135, l3: 0.000352, l4: 0.000590, l5: 0.001240, l6: 0.003115

[epoch: 475/1000, batch:   712/ 1052, ite: 124840] train loss: 0.004306, tar: 0.000112 
l0: 0.000078, l1: 0.000081, l2: 0.000128, l3: 0.000241, l4: 0.000579, l5: 0.001744, l6: 0.001972

[epoch: 475/1000, batch:   792/ 1052, ite: 124860] train loss: 0.004306, tar: 0.000112 
l0: 0.000097, l1: 0.000101, l2: 0.000168, l3: 0.000235, l4: 0.000525, l5: 0.001212, l6: 0.002783

[epoch: 475/1000, batch:   872/ 1052, ite: 124880] train loss: 0.004306, tar: 0.000112 
l0: 0.000156, l1: 0.000158, l2: 0.000229, l3: 0.000426, l4: 0.000869, l5: 0.001693, l6: 0.002644

[epoch: 475/1000, batch:   952/ 1052, ite: 124900] train loss: 0.004307, tar: 0.000112 
l0: 0.000262, l1: 0.000258, l2: 0.000258, l3: 0.000395, l4: 0.000518, l5: 0.001126, l6: 0.002485

[epoch: 475/1000, batch:  1032/ 1052, ite: 124920] train loss: 0.004306, tar: 0.000112 
[Epoch 475/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000157, l1: 0.000157, l2: 0.000183, l3: 0.000231, l4: 0.000372, l5: 0.000989, l6: 0.003278

[epoch: 476/1000, batch:    60/ 1052, ite: 124940] train loss: 0.004307, tar: 0.000112 
l0: 0.000069, l1: 0.000070, l2: 0.000087, l3: 0.000154, l4: 0.000275, l5: 0.001024, l6: 0.002233

[epoch: 476/1000, batch:   140/ 1052, ite: 124960] train loss: 0.004307, tar: 0.000112 
l0: 0.000068, l1: 0.000067, l2: 0.000112, l3: 0.000196, l4: 0.000447, l5: 0.000662, l6: 0.001282

[epoch: 476/1000, batch:   220/ 1052, ite: 124980] train loss: 0.004306, tar: 0.000112 
l0: 0.000084, l1: 0.000082, l2: 0.000084, l3: 0.000143, l4: 0.000403, l5: 0.000841, l6: 0.001692

[epoch: 476/1000, batch:   300/ 1052, ite: 125000] train loss: 0.004306, tar: 0.000112 
l0: 0.000037, l1: 0.000037, l2: 0.000161, l3: 0.000330, l4: 0.000813, l5: 0.001879, l6: 0.003814

[epoch: 476/1000, batch:   380/ 1052, ite: 125020] train loss: 0.004307, tar: 0.000112 
l0: 0.000098, l1: 0.000103, l2: 0.000198, l3: 0.000412, l4: 0.000824, l5: 0.001146, l6: 0.002517

[epoch: 476/1000, batch:   460/ 1052, ite: 125040] train loss: 0.004308, tar: 0.000112 
l0: 0.000043, l1: 0.000041, l2: 0.000094, l3: 0.000209, l4: 0.000450, l5: 0.000837, l6: 0.001922

[epoch: 476/1000, batch:   540/ 1052, ite: 125060] train loss: 0.004306, tar: 0.000112 
l0: 0.000038, l1: 0.000036, l2: 0.000079, l3: 0.000151, l4: 0.000491, l5: 0.000854, l6: 0.001582

[epoch: 476/1000, batch:   620/ 1052, ite: 125080] train loss: 0.004306, tar: 0.000111 
l0: 0.000087, l1: 0.000089, l2: 0.000110, l3: 0.000197, l4: 0.000417, l5: 0.000803, l6: 0.002310

[epoch: 476/1000, batch:   700/ 1052, ite: 125100] train loss: 0.004305, tar: 0.000111 
l0: 0.000165, l1: 0.000172, l2: 0.000186, l3: 0.000306, l4: 0.000739, l5: 0.001501, l6: 0.001747

[epoch: 476/1000, batch:   780/ 1052, ite: 125120] train loss: 0.004304, tar: 0.000111 
l0: 0.000107, l1: 0.000111, l2: 0.000133, l3: 0.000218, l4: 0.000529, l5: 0.001052, l6: 0.002399

[epoch: 476/1000, batch:   860/ 1052, ite: 125140] train loss: 0.004304, tar: 0.000111 
l0: 0.000033, l1: 0.000034, l2: 0.000079, l3: 0.000133, l4: 0.000613, l5: 0.000895, l6: 0.002125

[epoch: 476/1000, batch:   940/ 1052, ite: 125160] train loss: 0.004304, tar: 0.000111 
l0: 0.000039, l1: 0.000039, l2: 0.000064, l3: 0.000143, l4: 0.000447, l5: 0.000956, l6: 0.001206

[epoch: 476/1000, batch:  1020/ 1052, ite: 125180] train loss: 0.004303, tar: 0.000111 
[Epoch 476/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000126, l1: 0.000124, l2: 0.000186, l3: 0.000214, l4: 0.000538, l5: 0.001605, l6: 0.002852

[epoch: 477/1000, batch:    48/ 1052, ite: 125200] train loss: 0.004303, tar: 0.000111 
l0: 0.000113, l1: 0.000112, l2: 0.000138, l3: 0.000217, l4: 0.000506, l5: 0.001128, l6: 0.001600

[epoch: 477/1000, batch:   128/ 1052, ite: 125220] train loss: 0.004303, tar: 0.000111 
l0: 0.000093, l1: 0.000093, l2: 0.000124, l3: 0.000246, l4: 0.000315, l5: 0.000859, l6: 0.001622

[epoch: 477/1000, batch:   208/ 1052, ite: 125240] train loss: 0.004302, tar: 0.000111 
l0: 0.000059, l1: 0.000058, l2: 0.000137, l3: 0.000172, l4: 0.000345, l5: 0.001224, l6: 0.002123

[epoch: 477/1000, batch:   288/ 1052, ite: 125260] train loss: 0.004301, tar: 0.000111 
l0: 0.000110, l1: 0.000115, l2: 0.000156, l3: 0.000208, l4: 0.000443, l5: 0.001946, l6: 0.002783

[epoch: 477/1000, batch:   368/ 1052, ite: 125280] train loss: 0.004301, tar: 0.000111 
l0: 0.000055, l1: 0.000055, l2: 0.000114, l3: 0.000272, l4: 0.000332, l5: 0.000984, l6: 0.001224

[epoch: 477/1000, batch:   448/ 1052, ite: 125300] train loss: 0.004301, tar: 0.000111 
l0: 0.000086, l1: 0.000085, l2: 0.000150, l3: 0.000227, l4: 0.000325, l5: 0.000601, l6: 0.001702

[epoch: 477/1000, batch:   528/ 1052, ite: 125320] train loss: 0.004301, tar: 0.000111 
l0: 0.000077, l1: 0.000076, l2: 0.000107, l3: 0.000215, l4: 0.000385, l5: 0.000616, l6: 0.000906

[epoch: 477/1000, batch:   608/ 1052, ite: 125340] train loss: 0.004303, tar: 0.000111 
l0: 0.000071, l1: 0.000074, l2: 0.000103, l3: 0.000223, l4: 0.000413, l5: 0.000693, l6: 0.002009

[epoch: 477/1000, batch:   688/ 1052, ite: 125360] train loss: 0.004302, tar: 0.000111 
l0: 0.000043, l1: 0.000043, l2: 0.000075, l3: 0.000212, l4: 0.000650, l5: 0.001306, l6: 0.002368

[epoch: 477/1000, batch:   768/ 1052, ite: 125380] train loss: 0.004302, tar: 0.000111 
l0: 0.000068, l1: 0.000068, l2: 0.000104, l3: 0.000172, l4: 0.000317, l5: 0.000889, l6: 0.001552

[epoch: 477/1000, batch:   848/ 1052, ite: 125400] train loss: 0.004302, tar: 0.000111 
l0: 0.000153, l1: 0.000152, l2: 0.000208, l3: 0.000377, l4: 0.000526, l5: 0.000922, l6: 0.001048

[epoch: 477/1000, batch:   928/ 1052, ite: 125420] train loss: 0.004301, tar: 0.000111 
l0: 0.000060, l1: 0.000060, l2: 0.000081, l3: 0.000131, l4: 0.000401, l5: 0.000738, l6: 0.001490

[epoch: 477/1000, batch:  1008/ 1052, ite: 125440] train loss: 0.004300, tar: 0.000111 
[Epoch 477/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000187, l1: 0.000189, l2: 0.000207, l3: 0.000299, l4: 0.000550, l5: 0.001131, l6: 0.002371

[epoch: 478/1000, batch:    36/ 1052, ite: 125460] train loss: 0.004302, tar: 0.000111 
l0: 0.000026, l1: 0.000026, l2: 0.000084, l3: 0.000273, l4: 0.000496, l5: 0.001294, l6: 0.001876

[epoch: 478/1000, batch:   116/ 1052, ite: 125480] train loss: 0.004302, tar: 0.000111 
l0: 0.000038, l1: 0.000039, l2: 0.000049, l3: 0.000106, l4: 0.000365, l5: 0.000556, l6: 0.000934

[epoch: 478/1000, batch:   196/ 1052, ite: 125500] train loss: 0.004301, tar: 0.000111 
l0: 0.000099, l1: 0.000099, l2: 0.000120, l3: 0.000224, l4: 0.000491, l5: 0.000845, l6: 0.002181

[epoch: 478/1000, batch:   276/ 1052, ite: 125520] train loss: 0.004301, tar: 0.000111 
l0: 0.000033, l1: 0.000035, l2: 0.000068, l3: 0.000144, l4: 0.000432, l5: 0.000740, l6: 0.002235

[epoch: 478/1000, batch:   356/ 1052, ite: 125540] train loss: 0.004300, tar: 0.000111 
l0: 0.000041, l1: 0.000041, l2: 0.000100, l3: 0.000337, l4: 0.000540, l5: 0.001370, l6: 0.002053

[epoch: 478/1000, batch:   436/ 1052, ite: 125560] train loss: 0.004299, tar: 0.000111 
l0: 0.000092, l1: 0.000091, l2: 0.000117, l3: 0.000232, l4: 0.000423, l5: 0.000625, l6: 0.001571

[epoch: 478/1000, batch:   516/ 1052, ite: 125580] train loss: 0.004300, tar: 0.000111 
l0: 0.000100, l1: 0.000101, l2: 0.000167, l3: 0.000260, l4: 0.000379, l5: 0.000521, l6: 0.000951

[epoch: 478/1000, batch:   596/ 1052, ite: 125600] train loss: 0.004299, tar: 0.000110 
l0: 0.000178, l1: 0.000181, l2: 0.000210, l3: 0.000370, l4: 0.000573, l5: 0.001591, l6: 0.001748

[epoch: 478/1000, batch:   676/ 1052, ite: 125620] train loss: 0.004299, tar: 0.000110 
l0: 0.000040, l1: 0.000042, l2: 0.000060, l3: 0.000101, l4: 0.000285, l5: 0.000641, l6: 0.001392

[epoch: 478/1000, batch:   756/ 1052, ite: 125640] train loss: 0.004298, tar: 0.000110 
l0: 0.000177, l1: 0.000179, l2: 0.000204, l3: 0.000319, l4: 0.000589, l5: 0.001722, l6: 0.004056

[epoch: 478/1000, batch:   836/ 1052, ite: 125660] train loss: 0.004299, tar: 0.000110 
l0: 0.000081, l1: 0.000080, l2: 0.000137, l3: 0.000284, l4: 0.000591, l5: 0.001489, l6: 0.002225

[epoch: 478/1000, batch:   916/ 1052, ite: 125680] train loss: 0.004298, tar: 0.000110 
l0: 0.000113, l1: 0.000115, l2: 0.000213, l3: 0.000389, l4: 0.000869, l5: 0.001243, l6: 0.002342

[epoch: 478/1000, batch:   996/ 1052, ite: 125700] train loss: 0.004299, tar: 0.000110 
[Epoch 478/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000039, l1: 0.000041, l2: 0.000061, l3: 0.000173, l4: 0.000846, l5: 0.001127, l6: 0.002064

[epoch: 479/1000, batch:    24/ 1052, ite: 125720] train loss: 0.004298, tar: 0.000110 
l0: 0.000056, l1: 0.000057, l2: 0.000116, l3: 0.000185, l4: 0.000460, l5: 0.001034, l6: 0.002336

[epoch: 479/1000, batch:   104/ 1052, ite: 125740] train loss: 0.004298, tar: 0.000110 
l0: 0.000096, l1: 0.000094, l2: 0.000168, l3: 0.000314, l4: 0.000615, l5: 0.001162, l6: 0.003033

[epoch: 479/1000, batch:   184/ 1052, ite: 125760] train loss: 0.004298, tar: 0.000110 
l0: 0.000213, l1: 0.000218, l2: 0.000254, l3: 0.000376, l4: 0.000823, l5: 0.001917, l6: 0.003705

[epoch: 479/1000, batch:   264/ 1052, ite: 125780] train loss: 0.004298, tar: 0.000110 
l0: 0.000123, l1: 0.000122, l2: 0.000148, l3: 0.000199, l4: 0.000528, l5: 0.000979, l6: 0.002529

[epoch: 479/1000, batch:   344/ 1052, ite: 125800] train loss: 0.004298, tar: 0.000110 
l0: 0.000030, l1: 0.000031, l2: 0.000068, l3: 0.000123, l4: 0.000306, l5: 0.000974, l6: 0.002684

[epoch: 479/1000, batch:   424/ 1052, ite: 125820] train loss: 0.004298, tar: 0.000110 
l0: 0.000128, l1: 0.000131, l2: 0.000150, l3: 0.000269, l4: 0.000466, l5: 0.001117, l6: 0.001869

[epoch: 479/1000, batch:   504/ 1052, ite: 125840] train loss: 0.004298, tar: 0.000110 
l0: 0.000178, l1: 0.000175, l2: 0.000259, l3: 0.000508, l4: 0.000894, l5: 0.001456, l6: 0.002625

[epoch: 479/1000, batch:   584/ 1052, ite: 125860] train loss: 0.004298, tar: 0.000110 
l0: 0.000188, l1: 0.000188, l2: 0.000237, l3: 0.000444, l4: 0.000990, l5: 0.001887, l6: 0.004049

[epoch: 479/1000, batch:   664/ 1052, ite: 125880] train loss: 0.004299, tar: 0.000110 
l0: 0.000081, l1: 0.000082, l2: 0.000137, l3: 0.000345, l4: 0.000746, l5: 0.001257, l6: 0.001670

[epoch: 479/1000, batch:   744/ 1052, ite: 125900] train loss: 0.004299, tar: 0.000110 
l0: 0.000151, l1: 0.000152, l2: 0.000227, l3: 0.000372, l4: 0.000779, l5: 0.001760, l6: 0.002738

[epoch: 479/1000, batch:   824/ 1052, ite: 125920] train loss: 0.004299, tar: 0.000110 
l0: 0.000090, l1: 0.000090, l2: 0.000141, l3: 0.000226, l4: 0.000484, l5: 0.001127, l6: 0.002193

[epoch: 479/1000, batch:   904/ 1052, ite: 125940] train loss: 0.004299, tar: 0.000110 
l0: 0.000167, l1: 0.000169, l2: 0.000217, l3: 0.000435, l4: 0.000676, l5: 0.001608, l6: 0.003385

[epoch: 479/1000, batch:   984/ 1052, ite: 125960] train loss: 0.004298, tar: 0.000110 
[Epoch 479/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000153, l1: 0.000159, l2: 0.000195, l3: 0.000382, l4: 0.000822, l5: 0.001538, l6: 0.002914

[epoch: 480/1000, batch:    12/ 1052, ite: 125980] train loss: 0.004297, tar: 0.000110 
l0: 0.000093, l1: 0.000095, l2: 0.000156, l3: 0.000281, l4: 0.000494, l5: 0.000866, l6: 0.001637

[epoch: 480/1000, batch:    92/ 1052, ite: 126000] train loss: 0.004297, tar: 0.000110 
l0: 0.000050, l1: 0.000052, l2: 0.000084, l3: 0.000201, l4: 0.000588, l5: 0.001355, l6: 0.002410

[epoch: 480/1000, batch:   172/ 1052, ite: 126020] train loss: 0.004297, tar: 0.000110 
l0: 0.000056, l1: 0.000053, l2: 0.000110, l3: 0.000169, l4: 0.000292, l5: 0.000980, l6: 0.001687

[epoch: 480/1000, batch:   252/ 1052, ite: 126040] train loss: 0.004297, tar: 0.000110 
l0: 0.000051, l1: 0.000048, l2: 0.000097, l3: 0.000153, l4: 0.000251, l5: 0.000776, l6: 0.001530

[epoch: 480/1000, batch:   332/ 1052, ite: 126060] train loss: 0.004296, tar: 0.000110 
l0: 0.000029, l1: 0.000034, l2: 0.000044, l3: 0.000150, l4: 0.000490, l5: 0.000647, l6: 0.001152

[epoch: 480/1000, batch:   412/ 1052, ite: 126080] train loss: 0.004295, tar: 0.000110 
l0: 0.000058, l1: 0.000058, l2: 0.000081, l3: 0.000133, l4: 0.000215, l5: 0.000874, l6: 0.001163

[epoch: 480/1000, batch:   492/ 1052, ite: 126100] train loss: 0.004294, tar: 0.000110 
l0: 0.000103, l1: 0.000095, l2: 0.000178, l3: 0.000275, l4: 0.000512, l5: 0.001190, l6: 0.001287

[epoch: 480/1000, batch:   572/ 1052, ite: 126120] train loss: 0.004294, tar: 0.000110 
l0: 0.000078, l1: 0.000081, l2: 0.000157, l3: 0.000259, l4: 0.000466, l5: 0.001278, l6: 0.003198

[epoch: 480/1000, batch:   652/ 1052, ite: 126140] train loss: 0.004294, tar: 0.000110 
l0: 0.000107, l1: 0.000106, l2: 0.000159, l3: 0.000257, l4: 0.000481, l5: 0.001602, l6: 0.002353

[epoch: 480/1000, batch:   732/ 1052, ite: 126160] train loss: 0.004294, tar: 0.000110 
l0: 0.000069, l1: 0.000073, l2: 0.000095, l3: 0.000149, l4: 0.000393, l5: 0.000977, l6: 0.001412

[epoch: 480/1000, batch:   812/ 1052, ite: 126180] train loss: 0.004294, tar: 0.000110 
l0: 0.000093, l1: 0.000095, l2: 0.000150, l3: 0.000250, l4: 0.000673, l5: 0.001101, l6: 0.001965

[epoch: 480/1000, batch:   892/ 1052, ite: 126200] train loss: 0.004293, tar: 0.000110 
l0: 0.000061, l1: 0.000063, l2: 0.000074, l3: 0.000114, l4: 0.000322, l5: 0.000840, l6: 0.001404

[epoch: 480/1000, batch:   972/ 1052, ite: 126220] train loss: 0.004293, tar: 0.000110 
l0: 0.000097, l1: 0.000096, l2: 0.000120, l3: 0.000228, l4: 0.000531, l5: 0.001288, l6: 0.001476

[epoch: 480/1000, batch:  1052/ 1052, ite: 126240] train loss: 0.004295, tar: 0.000110 
[Epoch 480/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000046, l1: 0.000047, l2: 0.000079, l3: 0.000173, l4: 0.000262, l5: 0.000913, l6: 0.001813

[epoch: 481/1000, batch:    80/ 1052, ite: 126260] train loss: 0.004381, tar: 0.000118 
l0: 0.000051, l1: 0.000052, l2: 0.000099, l3: 0.000407, l4: 0.000951, l5: 0.001648, l6: 0.002191

[epoch: 481/1000, batch:   160/ 1052, ite: 126280] train loss: 0.004240, tar: 0.000100 
l0: 0.000151, l1: 0.000153, l2: 0.000185, l3: 0.000290, l4: 0.000503, l5: 0.001024, l6: 0.002074

[epoch: 481/1000, batch:   240/ 1052, ite: 126300] train loss: 0.004244, tar: 0.000102 
l0: 0.000086, l1: 0.000083, l2: 0.000188, l3: 0.000272, l4: 0.000508, l5: 0.001378, l6: 0.002614

[epoch: 481/1000, batch:   320/ 1052, ite: 126320] train loss: 0.004173, tar: 0.000098 
l0: 0.000060, l1: 0.000059, l2: 0.000115, l3: 0.000187, l4: 0.000489, l5: 0.000779, l6: 0.001918

[epoch: 481/1000, batch:   400/ 1052, ite: 126340] train loss: 0.004125, tar: 0.000096 
l0: 0.000098, l1: 0.000095, l2: 0.000110, l3: 0.000222, l4: 0.000397, l5: 0.001118, l6: 0.001615

[epoch: 481/1000, batch:   480/ 1052, ite: 126360] train loss: 0.004195, tar: 0.000096 
l0: 0.000108, l1: 0.000110, l2: 0.000173, l3: 0.000426, l4: 0.000648, l5: 0.001695, l6: 0.003386

[epoch: 481/1000, batch:   560/ 1052, ite: 126380] train loss: 0.004209, tar: 0.000098 
l0: 0.000187, l1: 0.000188, l2: 0.000181, l3: 0.000316, l4: 0.000410, l5: 0.000883, l6: 0.001256

[epoch: 481/1000, batch:   640/ 1052, ite: 126400] train loss: 0.004228, tar: 0.000102 
l0: 0.000151, l1: 0.000146, l2: 0.000203, l3: 0.000294, l4: 0.000753, l5: 0.001306, l6: 0.002332

[epoch: 481/1000, batch:   720/ 1052, ite: 126420] train loss: 0.004364, tar: 0.000114 
l0: 0.000178, l1: 0.000187, l2: 0.000230, l3: 0.000316, l4: 0.000656, l5: 0.001697, l6: 0.003104

[epoch: 481/1000, batch:   800/ 1052, ite: 126440] train loss: 0.004409, tar: 0.000122 
l0: 0.000157, l1: 0.000148, l2: 0.000203, l3: 0.000369, l4: 0.000753, l5: 0.001373, l6: 0.001921

[epoch: 481/1000, batch:   880/ 1052, ite: 126460] train loss: 0.004412, tar: 0.000127 
l0: 0.000208, l1: 0.000202, l2: 0.000283, l3: 0.000392, l4: 0.000629, l5: 0.001326, l6: 0.002121

[epoch: 481/1000, batch:   960/ 1052, ite: 126480] train loss: 0.004419, tar: 0.000130 
l0: 0.000124, l1: 0.000124, l2: 0.000156, l3: 0.000242, l4: 0.000408, l5: 0.000958, l6: 0.001911

[epoch: 481/1000, batch:  1040/ 1052, ite: 126500] train loss: 0.004408, tar: 0.000132 
[Epoch 481/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000179, l1: 0.000191, l2: 0.000250, l3: 0.000298, l4: 0.000473, l5: 0.000790, l6: 0.001510

[epoch: 482/1000, batch:    68/ 1052, ite: 126520] train loss: 0.004454, tar: 0.000135 
l0: 0.000474, l1: 0.000475, l2: 0.000619, l3: 0.000618, l4: 0.000698, l5: 0.001775, l6: 0.003816

[epoch: 482/1000, batch:   148/ 1052, ite: 126540] train loss: 0.004475, tar: 0.000141 
l0: 0.000109, l1: 0.000105, l2: 0.000137, l3: 0.000175, l4: 0.000383, l5: 0.000897, l6: 0.001350

[epoch: 482/1000, batch:   228/ 1052, ite: 126560] train loss: 0.004572, tar: 0.000149 
l0: 0.000081, l1: 0.000082, l2: 0.000110, l3: 0.000175, l4: 0.000354, l5: 0.000984, l6: 0.001489

[epoch: 482/1000, batch:   308/ 1052, ite: 126580] train loss: 0.004599, tar: 0.000150 
l0: 0.000092, l1: 0.000090, l2: 0.000121, l3: 0.000203, l4: 0.000559, l5: 0.000804, l6: 0.001143

[epoch: 482/1000, batch:   388/ 1052, ite: 126600] train loss: 0.004617, tar: 0.000151 
l0: 0.000122, l1: 0.000117, l2: 0.000184, l3: 0.000284, l4: 0.000515, l5: 0.001184, l6: 0.002162

[epoch: 482/1000, batch:   468/ 1052, ite: 126620] train loss: 0.004611, tar: 0.000152 
l0: 0.000175, l1: 0.000170, l2: 0.000225, l3: 0.000543, l4: 0.000963, l5: 0.002323, l6: 0.002941

[epoch: 482/1000, batch:   548/ 1052, ite: 126640] train loss: 0.004607, tar: 0.000152 
l0: 0.000212, l1: 0.000214, l2: 0.000224, l3: 0.000398, l4: 0.000780, l5: 0.002052, l6: 0.003288

[epoch: 482/1000, batch:   628/ 1052, ite: 126660] train loss: 0.004615, tar: 0.000154 
l0: 0.000167, l1: 0.000161, l2: 0.000194, l3: 0.000257, l4: 0.000580, l5: 0.001572, l6: 0.002048

[epoch: 482/1000, batch:   708/ 1052, ite: 126680] train loss: 0.004616, tar: 0.000155 
l0: 0.000088, l1: 0.000087, l2: 0.000167, l3: 0.000324, l4: 0.000546, l5: 0.001261, l6: 0.002496

[epoch: 482/1000, batch:   788/ 1052, ite: 126700] train loss: 0.004599, tar: 0.000154 
l0: 0.000147, l1: 0.000136, l2: 0.000187, l3: 0.000380, l4: 0.000702, l5: 0.001302, l6: 0.002902

[epoch: 482/1000, batch:   868/ 1052, ite: 126720] train loss: 0.004587, tar: 0.000154 
l0: 0.000144, l1: 0.000141, l2: 0.000155, l3: 0.000185, l4: 0.000348, l5: 0.000464, l6: 0.000943

[epoch: 482/1000, batch:   948/ 1052, ite: 126740] train loss: 0.004566, tar: 0.000153 
l0: 0.000156, l1: 0.000159, l2: 0.000203, l3: 0.000219, l4: 0.000313, l5: 0.000993, l6: 0.001996

[epoch: 482/1000, batch:  1028/ 1052, ite: 126760] train loss: 0.004544, tar: 0.000153 
[Epoch 482/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000329, l1: 0.000333, l2: 0.000388, l3: 0.000554, l4: 0.000927, l5: 0.001840, l6: 0.003387

[epoch: 483/1000, batch:    56/ 1052, ite: 126780] train loss: 0.004551, tar: 0.000152 
l0: 0.000296, l1: 0.000329, l2: 0.000353, l3: 0.000428, l4: 0.000665, l5: 0.001227, l6: 0.001412

[epoch: 483/1000, batch:   136/ 1052, ite: 126800] train loss: 0.004636, tar: 0.000167 
l0: 0.000443, l1: 0.000469, l2: 0.000563, l3: 0.000527, l4: 0.000954, l5: 0.001888, l6: 0.002921

[epoch: 483/1000, batch:   216/ 1052, ite: 126820] train loss: 0.004716, tar: 0.000179 
l0: 0.000404, l1: 0.000470, l2: 0.000439, l3: 0.000336, l4: 0.000696, l5: 0.000907, l6: 0.002080

[epoch: 483/1000, batch:   296/ 1052, ite: 126840] train loss: 0.004757, tar: 0.000189 
l0: 0.001344, l1: 0.001425, l2: 0.001429, l3: 0.001264, l4: 0.001917, l5: 0.002981, l6: 0.006312

[epoch: 483/1000, batch:   376/ 1052, ite: 126860] train loss: 0.004796, tar: 0.000196 
l0: 0.000606, l1: 0.000676, l2: 0.000654, l3: 0.000782, l4: 0.001392, l5: 0.002187, l6: 0.003768

[epoch: 483/1000, batch:   456/ 1052, ite: 126880] train loss: 0.005391, tar: 0.000265 
l0: 0.000187, l1: 0.000197, l2: 0.000217, l3: 0.000250, l4: 0.000448, l5: 0.000701, l6: 0.001308

[epoch: 483/1000, batch:   536/ 1052, ite: 126900] train loss: 0.005422, tar: 0.000271 
l0: 0.000287, l1: 0.000296, l2: 0.000284, l3: 0.000324, l4: 0.000600, l5: 0.000980, l6: 0.001425

[epoch: 483/1000, batch:   616/ 1052, ite: 126920] train loss: 0.005431, tar: 0.000274 
l0: 0.000116, l1: 0.000108, l2: 0.000111, l3: 0.000185, l4: 0.000332, l5: 0.000826, l6: 0.001346

[epoch: 483/1000, batch:   696/ 1052, ite: 126940] train loss: 0.005422, tar: 0.000275 
l0: 0.000785, l1: 0.000959, l2: 0.000896, l3: 0.000750, l4: 0.000882, l5: 0.002151, l6: 0.003025

[epoch: 483/1000, batch:   776/ 1052, ite: 126960] train loss: 0.005439, tar: 0.000277 
l0: 0.000192, l1: 0.000216, l2: 0.000277, l3: 0.000202, l4: 0.000421, l5: 0.000579, l6: 0.001260

[epoch: 483/1000, batch:   856/ 1052, ite: 126980] train loss: 0.005447, tar: 0.000277 
l0: 0.000188, l1: 0.000190, l2: 0.000218, l3: 0.000279, l4: 0.000620, l5: 0.001022, l6: 0.001536

[epoch: 483/1000, batch:   936/ 1052, ite: 127000] train loss: 0.005421, tar: 0.000276 
l0: 0.000142, l1: 0.000134, l2: 0.000205, l3: 0.000269, l4: 0.000400, l5: 0.000920, l6: 0.001523

[epoch: 483/1000, batch:  1016/ 1052, ite: 127020] train loss: 0.005413, tar: 0.000276 
[Epoch 483/1000] Test loss: 0.011, Test target loss: 0.001
l0: 0.000239, l1: 0.000233, l2: 0.000308, l3: 0.000414, l4: 0.000650, l5: 0.001187, l6: 0.001629

[epoch: 484/1000, batch:    44/ 1052, ite: 127040] train loss: 0.005405, tar: 0.000276 
l0: 0.000208, l1: 0.000216, l2: 0.000205, l3: 0.000338, l4: 0.000497, l5: 0.000978, l6: 0.002162

[epoch: 484/1000, batch:   124/ 1052, ite: 127060] train loss: 0.005389, tar: 0.000275 
l0: 0.000080, l1: 0.000078, l2: 0.000102, l3: 0.000189, l4: 0.000404, l5: 0.000732, l6: 0.001125

[epoch: 484/1000, batch:   204/ 1052, ite: 127080] train loss: 0.005372, tar: 0.000273 
l0: 0.000140, l1: 0.000146, l2: 0.000156, l3: 0.000239, l4: 0.000457, l5: 0.001086, l6: 0.001403

[epoch: 484/1000, batch:   284/ 1052, ite: 127100] train loss: 0.005375, tar: 0.000272 
l0: 0.000087, l1: 0.000077, l2: 0.000100, l3: 0.000198, l4: 0.000417, l5: 0.000927, l6: 0.002158

[epoch: 484/1000, batch:   364/ 1052, ite: 127120] train loss: 0.005363, tar: 0.000270 
l0: 0.000181, l1: 0.000162, l2: 0.000221, l3: 0.000420, l4: 0.000712, l5: 0.001254, l6: 0.002626

[epoch: 484/1000, batch:   444/ 1052, ite: 127140] train loss: 0.005360, tar: 0.000269 
l0: 0.000281, l1: 0.000266, l2: 0.000315, l3: 0.000525, l4: 0.000837, l5: 0.001970, l6: 0.003039

[epoch: 484/1000, batch:   524/ 1052, ite: 127160] train loss: 0.005344, tar: 0.000267 
l0: 0.000354, l1: 0.000341, l2: 0.000411, l3: 0.000624, l4: 0.001320, l5: 0.001927, l6: 0.004144

[epoch: 484/1000, batch:   604/ 1052, ite: 127180] train loss: 0.005336, tar: 0.000266 
l0: 0.000262, l1: 0.000259, l2: 0.000284, l3: 0.000393, l4: 0.000898, l5: 0.001973, l6: 0.003836

[epoch: 484/1000, batch:   684/ 1052, ite: 127200] train loss: 0.005329, tar: 0.000265 
l0: 0.000118, l1: 0.000103, l2: 0.000219, l3: 0.000435, l4: 0.000693, l5: 0.001436, l6: 0.001883

[epoch: 484/1000, batch:   764/ 1052, ite: 127220] train loss: 0.005319, tar: 0.000263 
l0: 0.000114, l1: 0.000110, l2: 0.000124, l3: 0.000198, l4: 0.000593, l5: 0.001484, l6: 0.002255

[epoch: 484/1000, batch:   844/ 1052, ite: 127240] train loss: 0.005293, tar: 0.000261 
l0: 0.000104, l1: 0.000103, l2: 0.000135, l3: 0.000177, l4: 0.000444, l5: 0.000587, l6: 0.001214

[epoch: 484/1000, batch:   924/ 1052, ite: 127260] train loss: 0.005284, tar: 0.000260 
l0: 0.000128, l1: 0.000131, l2: 0.000138, l3: 0.000297, l4: 0.000579, l5: 0.000903, l6: 0.001323

[epoch: 484/1000, batch:  1004/ 1052, ite: 127280] train loss: 0.005264, tar: 0.000258 
[Epoch 484/1000] Test loss: 0.010, Test target loss: 0.001
l0: 0.000126, l1: 0.000129, l2: 0.000179, l3: 0.000305, l4: 0.000502, l5: 0.001013, l6: 0.001805

[epoch: 485/1000, batch:    32/ 1052, ite: 127300] train loss: 0.005276, tar: 0.000259 
l0: 0.000279, l1: 0.000303, l2: 0.000315, l3: 0.000391, l4: 0.000737, l5: 0.001046, l6: 0.001567

[epoch: 485/1000, batch:   112/ 1052, ite: 127320] train loss: 0.005259, tar: 0.000258 
l0: 0.000241, l1: 0.000225, l2: 0.000335, l3: 0.000454, l4: 0.000729, l5: 0.001668, l6: 0.002670

[epoch: 485/1000, batch:   192/ 1052, ite: 127340] train loss: 0.005262, tar: 0.000257 
l0: 0.000273, l1: 0.000292, l2: 0.000265, l3: 0.000365, l4: 0.000630, l5: 0.000878, l6: 0.001605

[epoch: 485/1000, batch:   272/ 1052, ite: 127360] train loss: 0.005244, tar: 0.000256 
l0: 0.000239, l1: 0.000233, l2: 0.000261, l3: 0.000401, l4: 0.000742, l5: 0.001717, l6: 0.003244

[epoch: 485/1000, batch:   352/ 1052, ite: 127380] train loss: 0.005241, tar: 0.000254 
l0: 0.000122, l1: 0.000120, l2: 0.000147, l3: 0.000216, l4: 0.000390, l5: 0.001095, l6: 0.001469

[epoch: 485/1000, batch:   432/ 1052, ite: 127400] train loss: 0.005226, tar: 0.000253 
l0: 0.000175, l1: 0.000173, l2: 0.000185, l3: 0.000302, l4: 0.000633, l5: 0.001982, l6: 0.003543

[epoch: 485/1000, batch:   512/ 1052, ite: 127420] train loss: 0.005209, tar: 0.000251 
l0: 0.000416, l1: 0.000440, l2: 0.000441, l3: 0.000658, l4: 0.001160, l5: 0.002940, l6: 0.005027

[epoch: 485/1000, batch:   592/ 1052, ite: 127440] train loss: 0.005201, tar: 0.000249 
l0: 0.000097, l1: 0.000092, l2: 0.000131, l3: 0.000204, l4: 0.000573, l5: 0.001070, l6: 0.001792

[epoch: 485/1000, batch:   672/ 1052, ite: 127460] train loss: 0.005181, tar: 0.000247 
l0: 0.000184, l1: 0.000179, l2: 0.000203, l3: 0.000334, l4: 0.000638, l5: 0.001366, l6: 0.001903

[epoch: 485/1000, batch:   752/ 1052, ite: 127480] train loss: 0.005171, tar: 0.000246 
l0: 0.000074, l1: 0.000075, l2: 0.000087, l3: 0.000139, l4: 0.000433, l5: 0.001095, l6: 0.002067

[epoch: 485/1000, batch:   832/ 1052, ite: 127500] train loss: 0.005158, tar: 0.000244 
l0: 0.000093, l1: 0.000087, l2: 0.000124, l3: 0.000228, l4: 0.000409, l5: 0.001205, l6: 0.001998

[epoch: 485/1000, batch:   912/ 1052, ite: 127520] train loss: 0.005151, tar: 0.000243 
l0: 0.000117, l1: 0.000111, l2: 0.000165, l3: 0.000319, l4: 0.000528, l5: 0.001504, l6: 0.002367

[epoch: 485/1000, batch:   992/ 1052, ite: 127540] train loss: 0.005148, tar: 0.000241 
[Epoch 485/1000] Test loss: 0.012, Test target loss: 0.001
l0: 0.000192, l1: 0.000197, l2: 0.000220, l3: 0.000336, l4: 0.000591, l5: 0.001399, l6: 0.003424

[epoch: 486/1000, batch:    20/ 1052, ite: 127560] train loss: 0.005139, tar: 0.000240 
l0: 0.000116, l1: 0.000107, l2: 0.000143, l3: 0.000291, l4: 0.000633, l5: 0.001496, l6: 0.002256

[epoch: 486/1000, batch:   100/ 1052, ite: 127580] train loss: 0.005126, tar: 0.000238 
l0: 0.000106, l1: 0.000104, l2: 0.000130, l3: 0.000199, l4: 0.000545, l5: 0.000915, l6: 0.002210

[epoch: 486/1000, batch:   180/ 1052, ite: 127600] train loss: 0.005111, tar: 0.000236 
l0: 0.000140, l1: 0.000142, l2: 0.000161, l3: 0.000256, l4: 0.000348, l5: 0.000992, l6: 0.001531

[epoch: 486/1000, batch:   260/ 1052, ite: 127620] train loss: 0.005098, tar: 0.000235 
l0: 0.000115, l1: 0.000127, l2: 0.000147, l3: 0.000164, l4: 0.000243, l5: 0.000745, l6: 0.001513

[epoch: 486/1000, batch:   340/ 1052, ite: 127640] train loss: 0.005085, tar: 0.000233 
l0: 0.000059, l1: 0.000056, l2: 0.000108, l3: 0.000197, l4: 0.000344, l5: 0.000878, l6: 0.001725

[epoch: 486/1000, batch:   420/ 1052, ite: 127660] train loss: 0.005078, tar: 0.000232 
l0: 0.000165, l1: 0.000156, l2: 0.000246, l3: 0.000580, l4: 0.001002, l5: 0.001826, l6: 0.003107

[epoch: 486/1000, batch:   500/ 1052, ite: 127680] train loss: 0.005066, tar: 0.000230 
l0: 0.000110, l1: 0.000109, l2: 0.000142, l3: 0.000206, l4: 0.000383, l5: 0.000933, l6: 0.001467

[epoch: 486/1000, batch:   580/ 1052, ite: 127700] train loss: 0.005056, tar: 0.000229 
l0: 0.000101, l1: 0.000104, l2: 0.000113, l3: 0.000215, l4: 0.000297, l5: 0.000973, l6: 0.001125

[epoch: 486/1000, batch:   660/ 1052, ite: 127720] train loss: 0.005045, tar: 0.000228 
l0: 0.000092, l1: 0.000093, l2: 0.000124, l3: 0.000186, l4: 0.000446, l5: 0.001261, l6: 0.002343

[epoch: 486/1000, batch:   740/ 1052, ite: 127740] train loss: 0.005040, tar: 0.000226 
l0: 0.000106, l1: 0.000103, l2: 0.000147, l3: 0.000362, l4: 0.000706, l5: 0.001085, l6: 0.001446

[epoch: 486/1000, batch:   820/ 1052, ite: 127760] train loss: 0.005032, tar: 0.000225 
l0: 0.000128, l1: 0.000122, l2: 0.000175, l3: 0.000317, l4: 0.000515, l5: 0.000944, l6: 0.002056

[epoch: 486/1000, batch:   900/ 1052, ite: 127780] train loss: 0.005032, tar: 0.000224 
l0: 0.000097, l1: 0.000096, l2: 0.000125, l3: 0.000190, l4: 0.000400, l5: 0.000573, l6: 0.001442

[epoch: 486/1000, batch:   980/ 1052, ite: 127800] train loss: 0.005023, tar: 0.000223 
[Epoch 486/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000188, l1: 0.000184, l2: 0.000269, l3: 0.000329, l4: 0.000596, l5: 0.002018, l6: 0.003250

[epoch: 487/1000, batch:     8/ 1052, ite: 127820] train loss: 0.005022, tar: 0.000222 
l0: 0.000229, l1: 0.000229, l2: 0.000301, l3: 0.000352, l4: 0.000570, l5: 0.001064, l6: 0.002407

[epoch: 487/1000, batch:    88/ 1052, ite: 127840] train loss: 0.005017, tar: 0.000222 
l0: 0.000123, l1: 0.000127, l2: 0.000151, l3: 0.000243, l4: 0.000372, l5: 0.000939, l6: 0.001708

[epoch: 487/1000, batch:   168/ 1052, ite: 127860] train loss: 0.005014, tar: 0.000221 
l0: 0.000095, l1: 0.000091, l2: 0.000127, l3: 0.000200, l4: 0.000560, l5: 0.001005, l6: 0.001622

[epoch: 487/1000, batch:   248/ 1052, ite: 127880] train loss: 0.005002, tar: 0.000219 
l0: 0.000114, l1: 0.000117, l2: 0.000133, l3: 0.000211, l4: 0.000507, l5: 0.001537, l6: 0.001936

[epoch: 487/1000, batch:   328/ 1052, ite: 127900] train loss: 0.004993, tar: 0.000218 
l0: 0.000051, l1: 0.000047, l2: 0.000067, l3: 0.000119, l4: 0.000304, l5: 0.000731, l6: 0.001355

[epoch: 487/1000, batch:   408/ 1052, ite: 127920] train loss: 0.004986, tar: 0.000217 
l0: 0.000195, l1: 0.000191, l2: 0.000300, l3: 0.000411, l4: 0.001075, l5: 0.002070, l6: 0.002774

[epoch: 487/1000, batch:   488/ 1052, ite: 127940] train loss: 0.004984, tar: 0.000216 
l0: 0.000033, l1: 0.000034, l2: 0.000054, l3: 0.000128, l4: 0.000259, l5: 0.000480, l6: 0.000631

[epoch: 487/1000, batch:   568/ 1052, ite: 127960] train loss: 0.004975, tar: 0.000215 
l0: 0.000171, l1: 0.000175, l2: 0.000216, l3: 0.000280, l4: 0.000651, l5: 0.000998, l6: 0.002096

[epoch: 487/1000, batch:   648/ 1052, ite: 127980] train loss: 0.004963, tar: 0.000213 
l0: 0.000075, l1: 0.000080, l2: 0.000104, l3: 0.000136, l4: 0.000257, l5: 0.000414, l6: 0.001291

[epoch: 487/1000, batch:   728/ 1052, ite: 128000] train loss: 0.004956, tar: 0.000212 
l0: 0.000201, l1: 0.000198, l2: 0.000274, l3: 0.000446, l4: 0.000715, l5: 0.001776, l6: 0.001509

[epoch: 487/1000, batch:   808/ 1052, ite: 128020] train loss: 0.004952, tar: 0.000211 
l0: 0.000096, l1: 0.000087, l2: 0.000140, l3: 0.000218, l4: 0.000690, l5: 0.001465, l6: 0.002589

[epoch: 487/1000, batch:   888/ 1052, ite: 128040] train loss: 0.004942, tar: 0.000210 
l0: 0.000123, l1: 0.000113, l2: 0.000156, l3: 0.000333, l4: 0.000662, l5: 0.001444, l6: 0.002411

[epoch: 487/1000, batch:   968/ 1052, ite: 128060] train loss: 0.004936, tar: 0.000209 
l0: 0.000209, l1: 0.000210, l2: 0.000229, l3: 0.000393, l4: 0.000776, l5: 0.001546, l6: 0.003358

[epoch: 487/1000, batch:  1048/ 1052, ite: 128080] train loss: 0.004934, tar: 0.000209 
[Epoch 487/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000065, l1: 0.000072, l2: 0.000135, l3: 0.000224, l4: 0.000320, l5: 0.000827, l6: 0.001728

[epoch: 488/1000, batch:    76/ 1052, ite: 128100] train loss: 0.004933, tar: 0.000208 
l0: 0.000116, l1: 0.000111, l2: 0.000171, l3: 0.000264, l4: 0.000540, l5: 0.001234, l6: 0.002925

[epoch: 488/1000, batch:   156/ 1052, ite: 128120] train loss: 0.004928, tar: 0.000208 
l0: 0.000280, l1: 0.000275, l2: 0.000389, l3: 0.000476, l4: 0.000855, l5: 0.002421, l6: 0.002955

[epoch: 488/1000, batch:   236/ 1052, ite: 128140] train loss: 0.004929, tar: 0.000207 
l0: 0.000100, l1: 0.000096, l2: 0.000177, l3: 0.000410, l4: 0.000787, l5: 0.001215, l6: 0.002268

[epoch: 488/1000, batch:   316/ 1052, ite: 128160] train loss: 0.004928, tar: 0.000206 
l0: 0.000072, l1: 0.000062, l2: 0.000135, l3: 0.000293, l4: 0.000598, l5: 0.000687, l6: 0.001785

[epoch: 488/1000, batch:   396/ 1052, ite: 128180] train loss: 0.004925, tar: 0.000205 
l0: 0.000089, l1: 0.000085, l2: 0.000124, l3: 0.000228, l4: 0.000389, l5: 0.000920, l6: 0.001605

[epoch: 488/1000, batch:   476/ 1052, ite: 128200] train loss: 0.004914, tar: 0.000204 
l0: 0.000127, l1: 0.000132, l2: 0.000149, l3: 0.000208, l4: 0.000650, l5: 0.001326, l6: 0.001670

[epoch: 488/1000, batch:   556/ 1052, ite: 128220] train loss: 0.004917, tar: 0.000204 
l0: 0.000028, l1: 0.000023, l2: 0.000047, l3: 0.000155, l4: 0.000311, l5: 0.000900, l6: 0.001653

[epoch: 488/1000, batch:   636/ 1052, ite: 128240] train loss: 0.004907, tar: 0.000203 
l0: 0.000090, l1: 0.000097, l2: 0.000116, l3: 0.000171, l4: 0.000361, l5: 0.000745, l6: 0.002311

[epoch: 488/1000, batch:   716/ 1052, ite: 128260] train loss: 0.004906, tar: 0.000202 
l0: 0.000140, l1: 0.000133, l2: 0.000204, l3: 0.000316, l4: 0.000710, l5: 0.001713, l6: 0.002985

[epoch: 488/1000, batch:   796/ 1052, ite: 128280] train loss: 0.004904, tar: 0.000201 
l0: 0.000051, l1: 0.000049, l2: 0.000072, l3: 0.000117, l4: 0.000282, l5: 0.000942, l6: 0.001454

[epoch: 488/1000, batch:   876/ 1052, ite: 128300] train loss: 0.004893, tar: 0.000200 
l0: 0.000034, l1: 0.000034, l2: 0.000059, l3: 0.000104, l4: 0.000256, l5: 0.000328, l6: 0.001158

[epoch: 488/1000, batch:   956/ 1052, ite: 128320] train loss: 0.004881, tar: 0.000199 
l0: 0.000036, l1: 0.000035, l2: 0.000066, l3: 0.000119, l4: 0.000231, l5: 0.000552, l6: 0.000696

[epoch: 488/1000, batch:  1036/ 1052, ite: 128340] train loss: 0.004866, tar: 0.000198 
[Epoch 488/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000054, l1: 0.000054, l2: 0.000083, l3: 0.000171, l4: 0.000400, l5: 0.000711, l6: 0.001111

[epoch: 489/1000, batch:    64/ 1052, ite: 128360] train loss: 0.004862, tar: 0.000197 
l0: 0.000250, l1: 0.000251, l2: 0.000311, l3: 0.000412, l4: 0.000673, l5: 0.001004, l6: 0.002478

[epoch: 489/1000, batch:   144/ 1052, ite: 128380] train loss: 0.004854, tar: 0.000196 
l0: 0.000099, l1: 0.000099, l2: 0.000160, l3: 0.000264, l4: 0.000372, l5: 0.000747, l6: 0.001197

[epoch: 489/1000, batch:   224/ 1052, ite: 128400] train loss: 0.004852, tar: 0.000196 
l0: 0.000275, l1: 0.000273, l2: 0.000375, l3: 0.000454, l4: 0.000766, l5: 0.001749, l6: 0.001771

[epoch: 489/1000, batch:   304/ 1052, ite: 128420] train loss: 0.004845, tar: 0.000195 
l0: 0.000078, l1: 0.000080, l2: 0.000161, l3: 0.000290, l4: 0.000394, l5: 0.001104, l6: 0.002526

[epoch: 489/1000, batch:   384/ 1052, ite: 128440] train loss: 0.004844, tar: 0.000194 
l0: 0.000069, l1: 0.000061, l2: 0.000089, l3: 0.000151, l4: 0.000387, l5: 0.001037, l6: 0.001646

[epoch: 489/1000, batch:   464/ 1052, ite: 128460] train loss: 0.004842, tar: 0.000193 
l0: 0.000111, l1: 0.000107, l2: 0.000178, l3: 0.000289, l4: 0.000542, l5: 0.000950, l6: 0.001686

[epoch: 489/1000, batch:   544/ 1052, ite: 128480] train loss: 0.004837, tar: 0.000192 
l0: 0.000116, l1: 0.000110, l2: 0.000194, l3: 0.000357, l4: 0.000753, l5: 0.001590, l6: 0.002485

[epoch: 489/1000, batch:   624/ 1052, ite: 128500] train loss: 0.004830, tar: 0.000192 
l0: 0.000165, l1: 0.000159, l2: 0.000205, l3: 0.000342, l4: 0.000673, l5: 0.001200, l6: 0.002154

[epoch: 489/1000, batch:   704/ 1052, ite: 128520] train loss: 0.004823, tar: 0.000191 
l0: 0.000118, l1: 0.000118, l2: 0.000175, l3: 0.000211, l4: 0.000851, l5: 0.001374, l6: 0.002273

[epoch: 489/1000, batch:   784/ 1052, ite: 128540] train loss: 0.004823, tar: 0.000190 
l0: 0.000087, l1: 0.000090, l2: 0.000115, l3: 0.000198, l4: 0.000456, l5: 0.001191, l6: 0.001713

[epoch: 489/1000, batch:   864/ 1052, ite: 128560] train loss: 0.004821, tar: 0.000190 
l0: 0.000094, l1: 0.000095, l2: 0.000156, l3: 0.000346, l4: 0.000851, l5: 0.001502, l6: 0.002547

[epoch: 489/1000, batch:   944/ 1052, ite: 128580] train loss: 0.004816, tar: 0.000189 
l0: 0.000026, l1: 0.000027, l2: 0.000054, l3: 0.000088, l4: 0.000346, l5: 0.000526, l6: 0.000915

[epoch: 489/1000, batch:  1024/ 1052, ite: 128600] train loss: 0.004809, tar: 0.000188 
[Epoch 489/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000163, l1: 0.000163, l2: 0.000237, l3: 0.000404, l4: 0.000931, l5: 0.001776, l6: 0.003924

[epoch: 490/1000, batch:    52/ 1052, ite: 128620] train loss: 0.004805, tar: 0.000187 
l0: 0.000059, l1: 0.000060, l2: 0.000069, l3: 0.000142, l4: 0.000403, l5: 0.001073, l6: 0.001648

[epoch: 490/1000, batch:   132/ 1052, ite: 128640] train loss: 0.004799, tar: 0.000187 
l0: 0.000114, l1: 0.000109, l2: 0.000164, l3: 0.000280, l4: 0.000745, l5: 0.001391, l6: 0.003145

[epoch: 490/1000, batch:   212/ 1052, ite: 128660] train loss: 0.004791, tar: 0.000186 
l0: 0.000067, l1: 0.000062, l2: 0.000127, l3: 0.000256, l4: 0.000617, l5: 0.001267, l6: 0.001468

[epoch: 490/1000, batch:   292/ 1052, ite: 128680] train loss: 0.004787, tar: 0.000185 
l0: 0.000104, l1: 0.000096, l2: 0.000177, l3: 0.000407, l4: 0.000543, l5: 0.001058, l6: 0.001535

[epoch: 490/1000, batch:   372/ 1052, ite: 128700] train loss: 0.004777, tar: 0.000184 
l0: 0.000096, l1: 0.000095, l2: 0.000138, l3: 0.000200, l4: 0.000313, l5: 0.001007, l6: 0.001521

[epoch: 490/1000, batch:   452/ 1052, ite: 128720] train loss: 0.004774, tar: 0.000184 
l0: 0.000185, l1: 0.000186, l2: 0.000245, l3: 0.000417, l4: 0.000854, l5: 0.002598, l6: 0.005246

[epoch: 490/1000, batch:   532/ 1052, ite: 128740] train loss: 0.004770, tar: 0.000183 
l0: 0.000078, l1: 0.000086, l2: 0.000089, l3: 0.000135, l4: 0.000368, l5: 0.000675, l6: 0.001985

[epoch: 490/1000, batch:   612/ 1052, ite: 128760] train loss: 0.004764, tar: 0.000182 
l0: 0.000156, l1: 0.000151, l2: 0.000294, l3: 0.000376, l4: 0.000644, l5: 0.001023, l6: 0.001625

[epoch: 490/1000, batch:   692/ 1052, ite: 128780] train loss: 0.004765, tar: 0.000181 
l0: 0.000142, l1: 0.000139, l2: 0.000181, l3: 0.000356, l4: 0.000695, l5: 0.001311, l6: 0.002245

[epoch: 490/1000, batch:   772/ 1052, ite: 128800] train loss: 0.004761, tar: 0.000181 
l0: 0.000092, l1: 0.000096, l2: 0.000199, l3: 0.000465, l4: 0.001012, l5: 0.002387, l6: 0.003841

[epoch: 490/1000, batch:   852/ 1052, ite: 128820] train loss: 0.004756, tar: 0.000180 
l0: 0.000051, l1: 0.000051, l2: 0.000072, l3: 0.000110, l4: 0.000321, l5: 0.000637, l6: 0.001332

[epoch: 490/1000, batch:   932/ 1052, ite: 128840] train loss: 0.004755, tar: 0.000180 
l0: 0.000210, l1: 0.000199, l2: 0.000250, l3: 0.000416, l4: 0.000732, l5: 0.001532, l6: 0.002323

[epoch: 490/1000, batch:  1012/ 1052, ite: 128860] train loss: 0.004752, tar: 0.000179 
[Epoch 490/1000] Test loss: 0.013, Test target loss: 0.002
l0: 0.000074, l1: 0.000069, l2: 0.000097, l3: 0.000194, l4: 0.000376, l5: 0.001112, l6: 0.001590

[epoch: 491/1000, batch:    40/ 1052, ite: 128880] train loss: 0.004754, tar: 0.000179 
l0: 0.000104, l1: 0.000103, l2: 0.000137, l3: 0.000236, l4: 0.000547, l5: 0.001070, l6: 0.002535

[epoch: 491/1000, batch:   120/ 1052, ite: 128900] train loss: 0.004748, tar: 0.000178 
l0: 0.000091, l1: 0.000085, l2: 0.000138, l3: 0.000274, l4: 0.000820, l5: 0.001926, l6: 0.002654

[epoch: 491/1000, batch:   200/ 1052, ite: 128920] train loss: 0.004744, tar: 0.000178 
l0: 0.000113, l1: 0.000109, l2: 0.000154, l3: 0.000270, l4: 0.000389, l5: 0.000726, l6: 0.001312

[epoch: 491/1000, batch:   280/ 1052, ite: 128940] train loss: 0.004738, tar: 0.000177 
l0: 0.000024, l1: 0.000020, l2: 0.000054, l3: 0.000123, l4: 0.000297, l5: 0.000774, l6: 0.001658

[epoch: 491/1000, batch:   360/ 1052, ite: 128960] train loss: 0.004733, tar: 0.000176 
l0: 0.000134, l1: 0.000131, l2: 0.000156, l3: 0.000239, l4: 0.000474, l5: 0.000936, l6: 0.002454

[epoch: 491/1000, batch:   440/ 1052, ite: 128980] train loss: 0.004727, tar: 0.000176 
l0: 0.000074, l1: 0.000073, l2: 0.000112, l3: 0.000209, l4: 0.000666, l5: 0.001515, l6: 0.002103

[epoch: 491/1000, batch:   520/ 1052, ite: 129000] train loss: 0.004722, tar: 0.000175 
l0: 0.000099, l1: 0.000094, l2: 0.000147, l3: 0.000287, l4: 0.000756, l5: 0.001665, l6: 0.002814

[epoch: 491/1000, batch:   600/ 1052, ite: 129020] train loss: 0.004718, tar: 0.000174 
l0: 0.000045, l1: 0.000043, l2: 0.000066, l3: 0.000105, l4: 0.000247, l5: 0.000712, l6: 0.001241

[epoch: 491/1000, batch:   680/ 1052, ite: 129040] train loss: 0.004717, tar: 0.000174 
l0: 0.000027, l1: 0.000029, l2: 0.000042, l3: 0.000111, l4: 0.000332, l5: 0.000608, l6: 0.001309

[epoch: 491/1000, batch:   760/ 1052, ite: 129060] train loss: 0.004712, tar: 0.000173 
l0: 0.000074, l1: 0.000076, l2: 0.000108, l3: 0.000137, l4: 0.000307, l5: 0.000663, l6: 0.001343

[epoch: 491/1000, batch:   840/ 1052, ite: 129080] train loss: 0.004707, tar: 0.000173 
l0: 0.000051, l1: 0.000050, l2: 0.000068, l3: 0.000129, l4: 0.000571, l5: 0.001248, l6: 0.000894

[epoch: 491/1000, batch:   920/ 1052, ite: 129100] train loss: 0.004703, tar: 0.000172 
l0: 0.000040, l1: 0.000039, l2: 0.000058, l3: 0.000182, l4: 0.000570, l5: 0.001010, l6: 0.001832

[epoch: 491/1000, batch:  1000/ 1052, ite: 129120] train loss: 0.004702, tar: 0.000171 
[Epoch 491/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000035, l1: 0.000037, l2: 0.000054, l3: 0.000096, l4: 0.000251, l5: 0.000867, l6: 0.001568

[epoch: 492/1000, batch:    28/ 1052, ite: 129140] train loss: 0.004697, tar: 0.000171 
l0: 0.000087, l1: 0.000090, l2: 0.000113, l3: 0.000171, l4: 0.000365, l5: 0.000853, l6: 0.001483

[epoch: 492/1000, batch:   108/ 1052, ite: 129160] train loss: 0.004692, tar: 0.000170 
l0: 0.000047, l1: 0.000049, l2: 0.000086, l3: 0.000178, l4: 0.000378, l5: 0.000944, l6: 0.002452

[epoch: 492/1000, batch:   188/ 1052, ite: 129180] train loss: 0.004686, tar: 0.000170 
l0: 0.000118, l1: 0.000127, l2: 0.000147, l3: 0.000213, l4: 0.000330, l5: 0.001093, l6: 0.001352

[epoch: 492/1000, batch:   268/ 1052, ite: 129200] train loss: 0.004677, tar: 0.000169 
l0: 0.000031, l1: 0.000030, l2: 0.000040, l3: 0.000122, l4: 0.000322, l5: 0.000481, l6: 0.001417

[epoch: 492/1000, batch:   348/ 1052, ite: 129220] train loss: 0.004670, tar: 0.000168 
l0: 0.000169, l1: 0.000176, l2: 0.000250, l3: 0.000465, l4: 0.000867, l5: 0.001681, l6: 0.002459

[epoch: 492/1000, batch:   428/ 1052, ite: 129240] train loss: 0.004670, tar: 0.000168 
l0: 0.000139, l1: 0.000139, l2: 0.000192, l3: 0.000344, l4: 0.000591, l5: 0.001562, l6: 0.002411

[epoch: 492/1000, batch:   508/ 1052, ite: 129260] train loss: 0.004667, tar: 0.000167 
l0: 0.000082, l1: 0.000086, l2: 0.000089, l3: 0.000149, l4: 0.000364, l5: 0.000932, l6: 0.001157

[epoch: 492/1000, batch:   588/ 1052, ite: 129280] train loss: 0.004663, tar: 0.000167 
l0: 0.000080, l1: 0.000082, l2: 0.000117, l3: 0.000255, l4: 0.000618, l5: 0.001323, l6: 0.002622

[epoch: 492/1000, batch:   668/ 1052, ite: 129300] train loss: 0.004662, tar: 0.000167 
l0: 0.000113, l1: 0.000117, l2: 0.000144, l3: 0.000200, l4: 0.000464, l5: 0.001328, l6: 0.001464

[epoch: 492/1000, batch:   748/ 1052, ite: 129320] train loss: 0.004662, tar: 0.000166 
l0: 0.000062, l1: 0.000056, l2: 0.000119, l3: 0.000254, l4: 0.000580, l5: 0.001852, l6: 0.002045

[epoch: 492/1000, batch:   828/ 1052, ite: 129340] train loss: 0.004662, tar: 0.000166 
l0: 0.000060, l1: 0.000057, l2: 0.000112, l3: 0.000205, l4: 0.000444, l5: 0.000820, l6: 0.001676

[epoch: 492/1000, batch:   908/ 1052, ite: 129360] train loss: 0.004658, tar: 0.000165 
l0: 0.000117, l1: 0.000116, l2: 0.000166, l3: 0.000200, l4: 0.000389, l5: 0.001122, l6: 0.001386

[epoch: 492/1000, batch:   988/ 1052, ite: 129380] train loss: 0.004660, tar: 0.000165 
[Epoch 492/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000070, l1: 0.000074, l2: 0.000093, l3: 0.000114, l4: 0.000355, l5: 0.000899, l6: 0.001281

[epoch: 493/1000, batch:    16/ 1052, ite: 129400] train loss: 0.004656, tar: 0.000164 
l0: 0.000046, l1: 0.000043, l2: 0.000074, l3: 0.000154, l4: 0.000354, l5: 0.000900, l6: 0.001237

[epoch: 493/1000, batch:    96/ 1052, ite: 129420] train loss: 0.004652, tar: 0.000164 
l0: 0.000117, l1: 0.000119, l2: 0.000172, l3: 0.000286, l4: 0.000563, l5: 0.001045, l6: 0.001161

[epoch: 493/1000, batch:   176/ 1052, ite: 129440] train loss: 0.004649, tar: 0.000164 
l0: 0.000074, l1: 0.000068, l2: 0.000131, l3: 0.000251, l4: 0.000708, l5: 0.001380, l6: 0.001806

[epoch: 493/1000, batch:   256/ 1052, ite: 129460] train loss: 0.004647, tar: 0.000163 
l0: 0.000060, l1: 0.000054, l2: 0.000142, l3: 0.000225, l4: 0.000418, l5: 0.001041, l6: 0.001632

[epoch: 493/1000, batch:   336/ 1052, ite: 129480] train loss: 0.004643, tar: 0.000163 
l0: 0.000173, l1: 0.000167, l2: 0.000298, l3: 0.000567, l4: 0.000844, l5: 0.001381, l6: 0.002712

[epoch: 493/1000, batch:   416/ 1052, ite: 129500] train loss: 0.004642, tar: 0.000162 
l0: 0.000140, l1: 0.000144, l2: 0.000166, l3: 0.000249, l4: 0.000677, l5: 0.000833, l6: 0.001812

[epoch: 493/1000, batch:   496/ 1052, ite: 129520] train loss: 0.004641, tar: 0.000162 
l0: 0.000047, l1: 0.000047, l2: 0.000077, l3: 0.000197, l4: 0.000319, l5: 0.000865, l6: 0.001143

[epoch: 493/1000, batch:   576/ 1052, ite: 129540] train loss: 0.004639, tar: 0.000161 
l0: 0.000071, l1: 0.000069, l2: 0.000128, l3: 0.000348, l4: 0.000699, l5: 0.001139, l6: 0.002885

[epoch: 493/1000, batch:   656/ 1052, ite: 129560] train loss: 0.004638, tar: 0.000161 
l0: 0.000058, l1: 0.000059, l2: 0.000071, l3: 0.000139, l4: 0.000290, l5: 0.000721, l6: 0.001728

[epoch: 493/1000, batch:   736/ 1052, ite: 129580] train loss: 0.004634, tar: 0.000161 
l0: 0.000127, l1: 0.000127, l2: 0.000150, l3: 0.000236, l4: 0.000399, l5: 0.000867, l6: 0.001020

[epoch: 493/1000, batch:   816/ 1052, ite: 129600] train loss: 0.004631, tar: 0.000160 
l0: 0.000172, l1: 0.000199, l2: 0.000184, l3: 0.000293, l4: 0.000687, l5: 0.001003, l6: 0.001677

[epoch: 493/1000, batch:   896/ 1052, ite: 129620] train loss: 0.004627, tar: 0.000160 
l0: 0.000086, l1: 0.000088, l2: 0.000131, l3: 0.000187, l4: 0.000492, l5: 0.001401, l6: 0.002626

[epoch: 493/1000, batch:   976/ 1052, ite: 129640] train loss: 0.004622, tar: 0.000159 
[Epoch 493/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000026, l1: 0.000026, l2: 0.000065, l3: 0.000127, l4: 0.000276, l5: 0.000576, l6: 0.002070

[epoch: 494/1000, batch:     4/ 1052, ite: 129660] train loss: 0.004622, tar: 0.000159 
l0: 0.000044, l1: 0.000048, l2: 0.000052, l3: 0.000084, l4: 0.000203, l5: 0.000565, l6: 0.000906

[epoch: 494/1000, batch:    84/ 1052, ite: 129680] train loss: 0.004621, tar: 0.000159 
l0: 0.000077, l1: 0.000073, l2: 0.000127, l3: 0.000228, l4: 0.000471, l5: 0.001027, l6: 0.001880

[epoch: 494/1000, batch:   164/ 1052, ite: 129700] train loss: 0.004616, tar: 0.000158 
l0: 0.000070, l1: 0.000069, l2: 0.000131, l3: 0.000191, l4: 0.000331, l5: 0.000893, l6: 0.001848

[epoch: 494/1000, batch:   244/ 1052, ite: 129720] train loss: 0.004617, tar: 0.000158 
l0: 0.000050, l1: 0.000047, l2: 0.000106, l3: 0.000207, l4: 0.000359, l5: 0.000997, l6: 0.002112

[epoch: 494/1000, batch:   324/ 1052, ite: 129740] train loss: 0.004614, tar: 0.000157 
l0: 0.000080, l1: 0.000082, l2: 0.000113, l3: 0.000195, l4: 0.000380, l5: 0.000839, l6: 0.001244

[epoch: 494/1000, batch:   404/ 1052, ite: 129760] train loss: 0.004611, tar: 0.000157 
l0: 0.000061, l1: 0.000061, l2: 0.000089, l3: 0.000177, l4: 0.000434, l5: 0.000985, l6: 0.001775

[epoch: 494/1000, batch:   484/ 1052, ite: 129780] train loss: 0.004605, tar: 0.000157 
l0: 0.000134, l1: 0.000135, l2: 0.000196, l3: 0.000300, l4: 0.000617, l5: 0.001542, l6: 0.002142

[epoch: 494/1000, batch:   564/ 1052, ite: 129800] train loss: 0.004602, tar: 0.000156 
l0: 0.000060, l1: 0.000058, l2: 0.000103, l3: 0.000238, l4: 0.000710, l5: 0.001134, l6: 0.002726

[epoch: 494/1000, batch:   644/ 1052, ite: 129820] train loss: 0.004598, tar: 0.000156 
l0: 0.000064, l1: 0.000068, l2: 0.000109, l3: 0.000201, l4: 0.000374, l5: 0.000887, l6: 0.001565

[epoch: 494/1000, batch:   724/ 1052, ite: 129840] train loss: 0.004595, tar: 0.000155 
l0: 0.000203, l1: 0.000212, l2: 0.000199, l3: 0.000312, l4: 0.000761, l5: 0.001182, l6: 0.003235

[epoch: 494/1000, batch:   804/ 1052, ite: 129860] train loss: 0.004593, tar: 0.000155 
l0: 0.000062, l1: 0.000056, l2: 0.000123, l3: 0.000270, l4: 0.000571, l5: 0.000891, l6: 0.001926

[epoch: 494/1000, batch:   884/ 1052, ite: 129880] train loss: 0.004593, tar: 0.000155 
l0: 0.000057, l1: 0.000053, l2: 0.000110, l3: 0.000211, l4: 0.000607, l5: 0.001015, l6: 0.001195

[epoch: 494/1000, batch:   964/ 1052, ite: 129900] train loss: 0.004592, tar: 0.000155 
l0: 0.000043, l1: 0.000040, l2: 0.000082, l3: 0.000152, l4: 0.000410, l5: 0.001003, l6: 0.001835

[epoch: 494/1000, batch:  1044/ 1052, ite: 129920] train loss: 0.004590, tar: 0.000154 
[Epoch 494/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000045, l1: 0.000045, l2: 0.000050, l3: 0.000129, l4: 0.000473, l5: 0.000940, l6: 0.001979

[epoch: 495/1000, batch:    72/ 1052, ite: 129940] train loss: 0.004591, tar: 0.000154 
l0: 0.000063, l1: 0.000060, l2: 0.000095, l3: 0.000247, l4: 0.000343, l5: 0.001017, l6: 0.001677

[epoch: 495/1000, batch:   152/ 1052, ite: 129960] train loss: 0.004589, tar: 0.000154 
l0: 0.000035, l1: 0.000035, l2: 0.000117, l3: 0.000395, l4: 0.000808, l5: 0.001931, l6: 0.003403

[epoch: 495/1000, batch:   232/ 1052, ite: 129980] train loss: 0.004584, tar: 0.000153 
l0: 0.000195, l1: 0.000204, l2: 0.000228, l3: 0.000242, l4: 0.000337, l5: 0.001407, l6: 0.002040

[epoch: 495/1000, batch:   312/ 1052, ite: 130000] train loss: 0.004583, tar: 0.000153 
l0: 0.000079, l1: 0.000078, l2: 0.000102, l3: 0.000210, l4: 0.000417, l5: 0.000835, l6: 0.001176

[epoch: 495/1000, batch:   392/ 1052, ite: 130020] train loss: 0.004579, tar: 0.000153 
l0: 0.000067, l1: 0.000071, l2: 0.000092, l3: 0.000151, l4: 0.000333, l5: 0.000818, l6: 0.001719

[epoch: 495/1000, batch:   472/ 1052, ite: 130040] train loss: 0.004579, tar: 0.000152 
l0: 0.000015, l1: 0.000013, l2: 0.000028, l3: 0.000110, l4: 0.000266, l5: 0.000644, l6: 0.001175

[epoch: 495/1000, batch:   552/ 1052, ite: 130060] train loss: 0.004574, tar: 0.000152 
l0: 0.000169, l1: 0.000176, l2: 0.000198, l3: 0.000308, l4: 0.000775, l5: 0.001836, l6: 0.003699

[epoch: 495/1000, batch:   632/ 1052, ite: 130080] train loss: 0.004575, tar: 0.000152 
l0: 0.000073, l1: 0.000069, l2: 0.000101, l3: 0.000177, l4: 0.000341, l5: 0.000615, l6: 0.001155

[epoch: 495/1000, batch:   712/ 1052, ite: 130100] train loss: 0.004573, tar: 0.000151 
l0: 0.000059, l1: 0.000060, l2: 0.000074, l3: 0.000115, l4: 0.000259, l5: 0.000405, l6: 0.000917

[epoch: 495/1000, batch:   792/ 1052, ite: 130120] train loss: 0.004571, tar: 0.000151 
l0: 0.000086, l1: 0.000084, l2: 0.000139, l3: 0.000178, l4: 0.000396, l5: 0.000963, l6: 0.002943

[epoch: 495/1000, batch:   872/ 1052, ite: 130140] train loss: 0.004571, tar: 0.000151 
l0: 0.000082, l1: 0.000084, l2: 0.000128, l3: 0.000233, l4: 0.000490, l5: 0.000803, l6: 0.002051

[epoch: 495/1000, batch:   952/ 1052, ite: 130160] train loss: 0.004569, tar: 0.000150 
l0: 0.000117, l1: 0.000118, l2: 0.000147, l3: 0.000172, l4: 0.000384, l5: 0.000816, l6: 0.001517

[epoch: 495/1000, batch:  1032/ 1052, ite: 130180] train loss: 0.004567, tar: 0.000150 
[Epoch 495/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000027, l1: 0.000027, l2: 0.000083, l3: 0.000369, l4: 0.000637, l5: 0.001190, l6: 0.002226

[epoch: 496/1000, batch:    60/ 1052, ite: 130200] train loss: 0.004567, tar: 0.000150 
l0: 0.000093, l1: 0.000091, l2: 0.000158, l3: 0.000259, l4: 0.000911, l5: 0.001775, l6: 0.002195

[epoch: 496/1000, batch:   140/ 1052, ite: 130220] train loss: 0.004566, tar: 0.000149 
l0: 0.000077, l1: 0.000078, l2: 0.000111, l3: 0.000147, l4: 0.000408, l5: 0.001279, l6: 0.002493

[epoch: 496/1000, batch:   220/ 1052, ite: 130240] train loss: 0.004567, tar: 0.000149 
l0: 0.000142, l1: 0.000139, l2: 0.000186, l3: 0.000335, l4: 0.000546, l5: 0.001808, l6: 0.002826

[epoch: 496/1000, batch:   300/ 1052, ite: 130260] train loss: 0.004566, tar: 0.000149 
l0: 0.000154, l1: 0.000153, l2: 0.000257, l3: 0.000417, l4: 0.000739, l5: 0.001796, l6: 0.003051

[epoch: 496/1000, batch:   380/ 1052, ite: 130280] train loss: 0.004564, tar: 0.000148 
l0: 0.000189, l1: 0.000185, l2: 0.000274, l3: 0.000418, l4: 0.000841, l5: 0.001211, l6: 0.003068

[epoch: 496/1000, batch:   460/ 1052, ite: 130300] train loss: 0.004562, tar: 0.000148 
l0: 0.000037, l1: 0.000037, l2: 0.000053, l3: 0.000112, l4: 0.000269, l5: 0.000940, l6: 0.001233

[epoch: 496/1000, batch:   540/ 1052, ite: 130320] train loss: 0.004563, tar: 0.000148 
l0: 0.000044, l1: 0.000045, l2: 0.000069, l3: 0.000167, l4: 0.000344, l5: 0.000797, l6: 0.001394

[epoch: 496/1000, batch:   620/ 1052, ite: 130340] train loss: 0.004561, tar: 0.000147 
l0: 0.000156, l1: 0.000154, l2: 0.000202, l3: 0.000325, l4: 0.000613, l5: 0.001194, l6: 0.001869

[epoch: 496/1000, batch:   700/ 1052, ite: 130360] train loss: 0.004557, tar: 0.000147 
l0: 0.000036, l1: 0.000036, l2: 0.000044, l3: 0.000119, l4: 0.000203, l5: 0.000783, l6: 0.000922

[epoch: 496/1000, batch:   780/ 1052, ite: 130380] train loss: 0.004555, tar: 0.000147 
l0: 0.000027, l1: 0.000028, l2: 0.000058, l3: 0.000136, l4: 0.000587, l5: 0.001288, l6: 0.001643

[epoch: 496/1000, batch:   860/ 1052, ite: 130400] train loss: 0.004552, tar: 0.000147 
l0: 0.000144, l1: 0.000146, l2: 0.000166, l3: 0.000268, l4: 0.000481, l5: 0.001390, l6: 0.002685

[epoch: 496/1000, batch:   940/ 1052, ite: 130420] train loss: 0.004550, tar: 0.000146 
l0: 0.000054, l1: 0.000055, l2: 0.000078, l3: 0.000148, l4: 0.000432, l5: 0.000803, l6: 0.001979

[epoch: 496/1000, batch:  1020/ 1052, ite: 130440] train loss: 0.004547, tar: 0.000146 
[Epoch 496/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000163, l1: 0.000158, l2: 0.000236, l3: 0.000415, l4: 0.000513, l5: 0.000987, l6: 0.001624

[epoch: 497/1000, batch:    48/ 1052, ite: 130460] train loss: 0.004544, tar: 0.000146 
l0: 0.000050, l1: 0.000048, l2: 0.000084, l3: 0.000217, l4: 0.000653, l5: 0.001365, l6: 0.001909

[epoch: 497/1000, batch:   128/ 1052, ite: 130480] train loss: 0.004545, tar: 0.000145 
l0: 0.000036, l1: 0.000035, l2: 0.000063, l3: 0.000167, l4: 0.000456, l5: 0.000715, l6: 0.001359

[epoch: 497/1000, batch:   208/ 1052, ite: 130500] train loss: 0.004543, tar: 0.000145 
l0: 0.000106, l1: 0.000105, l2: 0.000147, l3: 0.000244, l4: 0.000474, l5: 0.001230, l6: 0.002462

[epoch: 497/1000, batch:   288/ 1052, ite: 130520] train loss: 0.004541, tar: 0.000145 
l0: 0.000077, l1: 0.000074, l2: 0.000191, l3: 0.000514, l4: 0.000991, l5: 0.002897, l6: 0.005189

[epoch: 497/1000, batch:   368/ 1052, ite: 130540] train loss: 0.004538, tar: 0.000145 
l0: 0.000044, l1: 0.000046, l2: 0.000065, l3: 0.000171, l4: 0.000493, l5: 0.001340, l6: 0.002423

[epoch: 497/1000, batch:   448/ 1052, ite: 130560] train loss: 0.004533, tar: 0.000144 
l0: 0.000160, l1: 0.000155, l2: 0.000262, l3: 0.000387, l4: 0.000664, l5: 0.001726, l6: 0.003120

[epoch: 497/1000, batch:   528/ 1052, ite: 130580] train loss: 0.004533, tar: 0.000144 
l0: 0.000076, l1: 0.000078, l2: 0.000091, l3: 0.000153, l4: 0.000359, l5: 0.000891, l6: 0.001611

[epoch: 497/1000, batch:   608/ 1052, ite: 130600] train loss: 0.004533, tar: 0.000144 
l0: 0.000135, l1: 0.000140, l2: 0.000188, l3: 0.000343, l4: 0.000633, l5: 0.002024, l6: 0.003660

[epoch: 497/1000, batch:   688/ 1052, ite: 130620] train loss: 0.004531, tar: 0.000143 
l0: 0.000099, l1: 0.000102, l2: 0.000116, l3: 0.000186, l4: 0.000649, l5: 0.000965, l6: 0.002355

[epoch: 497/1000, batch:   768/ 1052, ite: 130640] train loss: 0.004529, tar: 0.000143 
l0: 0.000063, l1: 0.000063, l2: 0.000089, l3: 0.000163, l4: 0.000299, l5: 0.001159, l6: 0.002070

[epoch: 497/1000, batch:   848/ 1052, ite: 130660] train loss: 0.004528, tar: 0.000143 
l0: 0.000070, l1: 0.000069, l2: 0.000094, l3: 0.000200, l4: 0.000515, l5: 0.000798, l6: 0.001400

[epoch: 497/1000, batch:   928/ 1052, ite: 130680] train loss: 0.004526, tar: 0.000143 
l0: 0.000144, l1: 0.000151, l2: 0.000231, l3: 0.000453, l4: 0.000907, l5: 0.001738, l6: 0.003898

[epoch: 497/1000, batch:  1008/ 1052, ite: 130700] train loss: 0.004527, tar: 0.000142 
[Epoch 497/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000049, l1: 0.000052, l2: 0.000087, l3: 0.000168, l4: 0.000322, l5: 0.000874, l6: 0.001702

[epoch: 498/1000, batch:    36/ 1052, ite: 130720] train loss: 0.004527, tar: 0.000142 
l0: 0.000097, l1: 0.000098, l2: 0.000131, l3: 0.000175, l4: 0.000477, l5: 0.000910, l6: 0.001411

[epoch: 498/1000, batch:   116/ 1052, ite: 130740] train loss: 0.004527, tar: 0.000142 
l0: 0.000039, l1: 0.000039, l2: 0.000045, l3: 0.000110, l4: 0.000308, l5: 0.000488, l6: 0.001608

[epoch: 498/1000, batch:   196/ 1052, ite: 130760] train loss: 0.004526, tar: 0.000142 
l0: 0.000073, l1: 0.000074, l2: 0.000114, l3: 0.000250, l4: 0.000522, l5: 0.001250, l6: 0.001735

[epoch: 498/1000, batch:   276/ 1052, ite: 130780] train loss: 0.004524, tar: 0.000142 
l0: 0.000148, l1: 0.000147, l2: 0.000240, l3: 0.000404, l4: 0.001013, l5: 0.002308, l6: 0.003698

[epoch: 498/1000, batch:   356/ 1052, ite: 130800] train loss: 0.004523, tar: 0.000141 
l0: 0.000130, l1: 0.000129, l2: 0.000189, l3: 0.000331, l4: 0.000584, l5: 0.000988, l6: 0.002101

[epoch: 498/1000, batch:   436/ 1052, ite: 130820] train loss: 0.004525, tar: 0.000141 
l0: 0.000102, l1: 0.000106, l2: 0.000167, l3: 0.000358, l4: 0.000781, l5: 0.001145, l6: 0.002383

[epoch: 498/1000, batch:   516/ 1052, ite: 130840] train loss: 0.004526, tar: 0.000141 
l0: 0.000025, l1: 0.000025, l2: 0.000054, l3: 0.000110, l4: 0.000403, l5: 0.000562, l6: 0.001011

[epoch: 498/1000, batch:   596/ 1052, ite: 130860] train loss: 0.004524, tar: 0.000141 
l0: 0.000049, l1: 0.000051, l2: 0.000067, l3: 0.000126, l4: 0.000190, l5: 0.000778, l6: 0.001676

[epoch: 498/1000, batch:   676/ 1052, ite: 130880] train loss: 0.004521, tar: 0.000141 
l0: 0.000145, l1: 0.000149, l2: 0.000263, l3: 0.000436, l4: 0.000542, l5: 0.001160, l6: 0.002032

[epoch: 498/1000, batch:   756/ 1052, ite: 130900] train loss: 0.004518, tar: 0.000140 
l0: 0.000068, l1: 0.000072, l2: 0.000098, l3: 0.000224, l4: 0.000433, l5: 0.001098, l6: 0.001488

[epoch: 498/1000, batch:   836/ 1052, ite: 130920] train loss: 0.004517, tar: 0.000140 
l0: 0.000102, l1: 0.000104, l2: 0.000162, l3: 0.000343, l4: 0.000574, l5: 0.001380, l6: 0.002027

[epoch: 498/1000, batch:   916/ 1052, ite: 130940] train loss: 0.004513, tar: 0.000140 
l0: 0.000058, l1: 0.000056, l2: 0.000112, l3: 0.000348, l4: 0.000783, l5: 0.001193, l6: 0.002233

[epoch: 498/1000, batch:   996/ 1052, ite: 130960] train loss: 0.004512, tar: 0.000139 
[Epoch 498/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000082, l1: 0.000086, l2: 0.000117, l3: 0.000166, l4: 0.000390, l5: 0.001377, l6: 0.001841

[epoch: 499/1000, batch:    24/ 1052, ite: 130980] train loss: 0.004509, tar: 0.000139 
l0: 0.000121, l1: 0.000121, l2: 0.000152, l3: 0.000385, l4: 0.000737, l5: 0.002311, l6: 0.003564

[epoch: 499/1000, batch:   104/ 1052, ite: 131000] train loss: 0.004510, tar: 0.000139 
l0: 0.000133, l1: 0.000126, l2: 0.000216, l3: 0.000539, l4: 0.000720, l5: 0.001673, l6: 0.001945

[epoch: 499/1000, batch:   184/ 1052, ite: 131020] train loss: 0.004510, tar: 0.000139 
l0: 0.000065, l1: 0.000063, l2: 0.000132, l3: 0.000263, l4: 0.000363, l5: 0.001048, l6: 0.001884

[epoch: 499/1000, batch:   264/ 1052, ite: 131040] train loss: 0.004508, tar: 0.000139 
l0: 0.000090, l1: 0.000085, l2: 0.000169, l3: 0.000307, l4: 0.000554, l5: 0.001211, l6: 0.001464

[epoch: 499/1000, batch:   344/ 1052, ite: 131060] train loss: 0.004505, tar: 0.000138 
l0: 0.000053, l1: 0.000055, l2: 0.000066, l3: 0.000111, l4: 0.000288, l5: 0.000744, l6: 0.001163

[epoch: 499/1000, batch:   424/ 1052, ite: 131080] train loss: 0.004504, tar: 0.000138 
l0: 0.000206, l1: 0.000206, l2: 0.000314, l3: 0.000593, l4: 0.000902, l5: 0.002347, l6: 0.003806

[epoch: 499/1000, batch:   504/ 1052, ite: 131100] train loss: 0.004502, tar: 0.000138 
l0: 0.000062, l1: 0.000060, l2: 0.000129, l3: 0.000287, l4: 0.000499, l5: 0.001176, l6: 0.002743

[epoch: 499/1000, batch:   584/ 1052, ite: 131120] train loss: 0.004499, tar: 0.000138 
l0: 0.000155, l1: 0.000151, l2: 0.000283, l3: 0.000564, l4: 0.001205, l5: 0.002903, l6: 0.005136

[epoch: 499/1000, batch:   664/ 1052, ite: 131140] train loss: 0.004498, tar: 0.000138 
l0: 0.000040, l1: 0.000042, l2: 0.000069, l3: 0.000164, l4: 0.000302, l5: 0.000703, l6: 0.001872

[epoch: 499/1000, batch:   744/ 1052, ite: 131160] train loss: 0.004496, tar: 0.000137 
l0: 0.000058, l1: 0.000062, l2: 0.000047, l3: 0.000099, l4: 0.000291, l5: 0.000619, l6: 0.001244

[epoch: 499/1000, batch:   824/ 1052, ite: 131180] train loss: 0.004494, tar: 0.000137 
l0: 0.000109, l1: 0.000117, l2: 0.000110, l3: 0.000144, l4: 0.000401, l5: 0.001074, l6: 0.001470

[epoch: 499/1000, batch:   904/ 1052, ite: 131200] train loss: 0.004491, tar: 0.000137 
l0: 0.000102, l1: 0.000111, l2: 0.000109, l3: 0.000200, l4: 0.000527, l5: 0.001192, l6: 0.002811

[epoch: 499/1000, batch:   984/ 1052, ite: 131220] train loss: 0.004488, tar: 0.000137 
[Epoch 499/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000045, l1: 0.000045, l2: 0.000084, l3: 0.000255, l4: 0.000496, l5: 0.001309, l6: 0.002440

[epoch: 500/1000, batch:    12/ 1052, ite: 131240] train loss: 0.004489, tar: 0.000136 
l0: 0.000066, l1: 0.000070, l2: 0.000094, l3: 0.000238, l4: 0.000883, l5: 0.001512, l6: 0.003298

[epoch: 500/1000, batch:    92/ 1052, ite: 131260] train loss: 0.004488, tar: 0.000136 
l0: 0.000126, l1: 0.000125, l2: 0.000231, l3: 0.000381, l4: 0.000827, l5: 0.001144, l6: 0.002871

[epoch: 500/1000, batch:   172/ 1052, ite: 131280] train loss: 0.004488, tar: 0.000136 
l0: 0.000014, l1: 0.000014, l2: 0.000067, l3: 0.000152, l4: 0.000344, l5: 0.000395, l6: 0.001554

[epoch: 500/1000, batch:   252/ 1052, ite: 131300] train loss: 0.004488, tar: 0.000136 
l0: 0.000081, l1: 0.000082, l2: 0.000121, l3: 0.000191, l4: 0.000372, l5: 0.001195, l6: 0.001616

[epoch: 500/1000, batch:   332/ 1052, ite: 131320] train loss: 0.004485, tar: 0.000136 
l0: 0.000155, l1: 0.000156, l2: 0.000230, l3: 0.000314, l4: 0.000798, l5: 0.001611, l6: 0.002372

[epoch: 500/1000, batch:   412/ 1052, ite: 131340] train loss: 0.004486, tar: 0.000135 
l0: 0.000054, l1: 0.000053, l2: 0.000077, l3: 0.000129, l4: 0.000301, l5: 0.000713, l6: 0.001458

[epoch: 500/1000, batch:   492/ 1052, ite: 131360] train loss: 0.004485, tar: 0.000135 
l0: 0.000129, l1: 0.000131, l2: 0.000174, l3: 0.000289, l4: 0.000642, l5: 0.000933, l6: 0.001745

[epoch: 500/1000, batch:   572/ 1052, ite: 131380] train loss: 0.004483, tar: 0.000135 
l0: 0.000054, l1: 0.000052, l2: 0.000098, l3: 0.000129, l4: 0.000307, l5: 0.000870, l6: 0.001374

[epoch: 500/1000, batch:   652/ 1052, ite: 131400] train loss: 0.004480, tar: 0.000135 
l0: 0.000072, l1: 0.000072, l2: 0.000091, l3: 0.000191, l4: 0.000293, l5: 0.000711, l6: 0.001401

[epoch: 500/1000, batch:   732/ 1052, ite: 131420] train loss: 0.004479, tar: 0.000135 
l0: 0.000088, l1: 0.000092, l2: 0.000126, l3: 0.000236, l4: 0.000657, l5: 0.001000, l6: 0.001932

[epoch: 500/1000, batch:   812/ 1052, ite: 131440] train loss: 0.004478, tar: 0.000135 
l0: 0.000122, l1: 0.000129, l2: 0.000187, l3: 0.000422, l4: 0.000925, l5: 0.001986, l6: 0.002184

[epoch: 500/1000, batch:   892/ 1052, ite: 131460] train loss: 0.004476, tar: 0.000134 
l0: 0.000100, l1: 0.000099, l2: 0.000169, l3: 0.000218, l4: 0.000585, l5: 0.001184, l6: 0.002789

[epoch: 500/1000, batch:   972/ 1052, ite: 131480] train loss: 0.004474, tar: 0.000134 
l0: 0.000062, l1: 0.000062, l2: 0.000095, l3: 0.000146, l4: 0.000293, l5: 0.000891, l6: 0.001651

[epoch: 500/1000, batch:  1052/ 1052, ite: 131500] train loss: 0.004474, tar: 0.000134 
[Epoch 500/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000091, l1: 0.000100, l2: 0.000091, l3: 0.000083, l4: 0.000351, l5: 0.000981, l6: 0.001322

[epoch: 501/1000, batch:    80/ 1052, ite: 131520] train loss: 0.004472, tar: 0.000134 
l0: 0.000126, l1: 0.000125, l2: 0.000166, l3: 0.000235, l4: 0.000581, l5: 0.000966, l6: 0.001841

[epoch: 501/1000, batch:   160/ 1052, ite: 131540] train loss: 0.004470, tar: 0.000134 
l0: 0.000110, l1: 0.000110, l2: 0.000159, l3: 0.000226, l4: 0.000498, l5: 0.001123, l6: 0.001983

[epoch: 501/1000, batch:   240/ 1052, ite: 131560] train loss: 0.004470, tar: 0.000134 
l0: 0.000123, l1: 0.000127, l2: 0.000210, l3: 0.000340, l4: 0.000537, l5: 0.001562, l6: 0.003346

[epoch: 501/1000, batch:   320/ 1052, ite: 131580] train loss: 0.004470, tar: 0.000133 
l0: 0.000093, l1: 0.000091, l2: 0.000123, l3: 0.000165, l4: 0.000278, l5: 0.000900, l6: 0.001948

[epoch: 501/1000, batch:   400/ 1052, ite: 131600] train loss: 0.004467, tar: 0.000133 
l0: 0.000078, l1: 0.000077, l2: 0.000159, l3: 0.000237, l4: 0.000421, l5: 0.001214, l6: 0.001509

[epoch: 501/1000, batch:   480/ 1052, ite: 131620] train loss: 0.004465, tar: 0.000133 
l0: 0.000100, l1: 0.000100, l2: 0.000114, l3: 0.000153, l4: 0.000388, l5: 0.000999, l6: 0.001276

[epoch: 501/1000, batch:   560/ 1052, ite: 131640] train loss: 0.004465, tar: 0.000133 
l0: 0.000076, l1: 0.000074, l2: 0.000133, l3: 0.000192, l4: 0.000240, l5: 0.000616, l6: 0.001282

[epoch: 501/1000, batch:   640/ 1052, ite: 131660] train loss: 0.004463, tar: 0.000133 
l0: 0.000084, l1: 0.000083, l2: 0.000131, l3: 0.000307, l4: 0.000496, l5: 0.001079, l6: 0.002422

[epoch: 501/1000, batch:   720/ 1052, ite: 131680] train loss: 0.004459, tar: 0.000133 
l0: 0.000048, l1: 0.000047, l2: 0.000097, l3: 0.000178, l4: 0.000458, l5: 0.000724, l6: 0.001912

[epoch: 501/1000, batch:   800/ 1052, ite: 131700] train loss: 0.004460, tar: 0.000132 
l0: 0.000104, l1: 0.000101, l2: 0.000165, l3: 0.000235, l4: 0.000382, l5: 0.001056, l6: 0.001250

[epoch: 501/1000, batch:   880/ 1052, ite: 131720] train loss: 0.004460, tar: 0.000132 
l0: 0.000118, l1: 0.000123, l2: 0.000141, l3: 0.000322, l4: 0.000696, l5: 0.001677, l6: 0.003141

[epoch: 501/1000, batch:   960/ 1052, ite: 131740] train loss: 0.004459, tar: 0.000132 
l0: 0.000084, l1: 0.000085, l2: 0.000159, l3: 0.000248, l4: 0.000464, l5: 0.001612, l6: 0.003234

[epoch: 501/1000, batch:  1040/ 1052, ite: 131760] train loss: 0.004460, tar: 0.000132 
[Epoch 501/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000044, l1: 0.000046, l2: 0.000094, l3: 0.000260, l4: 0.000460, l5: 0.001481, l6: 0.001299

[epoch: 502/1000, batch:    68/ 1052, ite: 131780] train loss: 0.004461, tar: 0.000132 
l0: 0.000162, l1: 0.000170, l2: 0.000162, l3: 0.000260, l4: 0.000761, l5: 0.001863, l6: 0.002629

[epoch: 502/1000, batch:   148/ 1052, ite: 131800] train loss: 0.004458, tar: 0.000132 
l0: 0.000049, l1: 0.000046, l2: 0.000070, l3: 0.000140, l4: 0.000372, l5: 0.000885, l6: 0.001610

[epoch: 502/1000, batch:   228/ 1052, ite: 131820] train loss: 0.004457, tar: 0.000131 
l0: 0.000092, l1: 0.000088, l2: 0.000193, l3: 0.000231, l4: 0.000400, l5: 0.000980, l6: 0.001345

[epoch: 502/1000, batch:   308/ 1052, ite: 131840] train loss: 0.004455, tar: 0.000131 
l0: 0.000074, l1: 0.000076, l2: 0.000096, l3: 0.000156, l4: 0.000335, l5: 0.000898, l6: 0.001384

[epoch: 502/1000, batch:   388/ 1052, ite: 131860] train loss: 0.004453, tar: 0.000131 
l0: 0.000089, l1: 0.000092, l2: 0.000159, l3: 0.000267, l4: 0.000673, l5: 0.001086, l6: 0.002127

[epoch: 502/1000, batch:   468/ 1052, ite: 131880] train loss: 0.004455, tar: 0.000131 
l0: 0.000064, l1: 0.000065, l2: 0.000123, l3: 0.000341, l4: 0.000625, l5: 0.000995, l6: 0.002211

[epoch: 502/1000, batch:   548/ 1052, ite: 131900] train loss: 0.004455, tar: 0.000131 
l0: 0.000147, l1: 0.000156, l2: 0.000199, l3: 0.000368, l4: 0.000773, l5: 0.001126, l6: 0.001839

[epoch: 502/1000, batch:   628/ 1052, ite: 131920] train loss: 0.004454, tar: 0.000131 
l0: 0.000066, l1: 0.000065, l2: 0.000107, l3: 0.000205, l4: 0.000349, l5: 0.000872, l6: 0.001832

[epoch: 502/1000, batch:   708/ 1052, ite: 131940] train loss: 0.004455, tar: 0.000131 
l0: 0.000059, l1: 0.000055, l2: 0.000176, l3: 0.000624, l4: 0.001204, l5: 0.002229, l6: 0.003483

[epoch: 502/1000, batch:   788/ 1052, ite: 131960] train loss: 0.004454, tar: 0.000130 
l0: 0.000017, l1: 0.000018, l2: 0.000028, l3: 0.000084, l4: 0.000201, l5: 0.000579, l6: 0.001101

[epoch: 502/1000, batch:   868/ 1052, ite: 131980] train loss: 0.004451, tar: 0.000130 
l0: 0.000070, l1: 0.000069, l2: 0.000117, l3: 0.000171, l4: 0.000500, l5: 0.001155, l6: 0.001751

[epoch: 502/1000, batch:   948/ 1052, ite: 132000] train loss: 0.004451, tar: 0.000130 
l0: 0.000070, l1: 0.000068, l2: 0.000164, l3: 0.000298, l4: 0.000531, l5: 0.001202, l6: 0.002622

[epoch: 502/1000, batch:  1028/ 1052, ite: 132020] train loss: 0.004452, tar: 0.000130 
[Epoch 502/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000015, l1: 0.000016, l2: 0.000044, l3: 0.000160, l4: 0.000426, l5: 0.000807, l6: 0.000863

[epoch: 503/1000, batch:    56/ 1052, ite: 132040] train loss: 0.004451, tar: 0.000130 
l0: 0.000133, l1: 0.000132, l2: 0.000164, l3: 0.000293, l4: 0.000603, l5: 0.001000, l6: 0.002035

[epoch: 503/1000, batch:   136/ 1052, ite: 132060] train loss: 0.004449, tar: 0.000130 
l0: 0.000088, l1: 0.000089, l2: 0.000128, l3: 0.000205, l4: 0.000540, l5: 0.001403, l6: 0.002577

[epoch: 503/1000, batch:   216/ 1052, ite: 132080] train loss: 0.004450, tar: 0.000130 
l0: 0.000082, l1: 0.000079, l2: 0.000161, l3: 0.000281, l4: 0.000483, l5: 0.001171, l6: 0.002058

[epoch: 503/1000, batch:   296/ 1052, ite: 132100] train loss: 0.004447, tar: 0.000129 
l0: 0.000030, l1: 0.000028, l2: 0.000073, l3: 0.000133, l4: 0.000407, l5: 0.000788, l6: 0.000970

[epoch: 503/1000, batch:   376/ 1052, ite: 132120] train loss: 0.004443, tar: 0.000129 
l0: 0.000044, l1: 0.000046, l2: 0.000106, l3: 0.000216, l4: 0.000392, l5: 0.000737, l6: 0.001289

[epoch: 503/1000, batch:   456/ 1052, ite: 132140] train loss: 0.004444, tar: 0.000129 
l0: 0.000095, l1: 0.000098, l2: 0.000182, l3: 0.000455, l4: 0.000977, l5: 0.001533, l6: 0.002868

[epoch: 503/1000, batch:   536/ 1052, ite: 132160] train loss: 0.004444, tar: 0.000129 
l0: 0.000112, l1: 0.000112, l2: 0.000159, l3: 0.000187, l4: 0.000369, l5: 0.000814, l6: 0.001395

[epoch: 503/1000, batch:   616/ 1052, ite: 132180] train loss: 0.004444, tar: 0.000129 
l0: 0.000033, l1: 0.000031, l2: 0.000089, l3: 0.000404, l4: 0.000560, l5: 0.001184, l6: 0.001987

[epoch: 503/1000, batch:   696/ 1052, ite: 132200] train loss: 0.004443, tar: 0.000129 
l0: 0.000095, l1: 0.000096, l2: 0.000117, l3: 0.000185, l4: 0.000437, l5: 0.001053, l6: 0.001400

[epoch: 503/1000, batch:   776/ 1052, ite: 132220] train loss: 0.004443, tar: 0.000129 
l0: 0.000198, l1: 0.000202, l2: 0.000300, l3: 0.000608, l4: 0.000973, l5: 0.001916, l6: 0.003424

[epoch: 503/1000, batch:   856/ 1052, ite: 132240] train loss: 0.004442, tar: 0.000129 
l0: 0.000022, l1: 0.000023, l2: 0.000038, l3: 0.000089, l4: 0.000305, l5: 0.001124, l6: 0.001258

[epoch: 503/1000, batch:   936/ 1052, ite: 132260] train loss: 0.004442, tar: 0.000128 
l0: 0.000055, l1: 0.000053, l2: 0.000104, l3: 0.000180, l4: 0.000342, l5: 0.000913, l6: 0.001663

[epoch: 503/1000, batch:  1016/ 1052, ite: 132280] train loss: 0.004440, tar: 0.000128 
[Epoch 503/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000086, l1: 0.000093, l2: 0.000112, l3: 0.000187, l4: 0.000540, l5: 0.001859, l6: 0.003023

[epoch: 504/1000, batch:    44/ 1052, ite: 132300] train loss: 0.004439, tar: 0.000128 
l0: 0.000298, l1: 0.000304, l2: 0.000323, l3: 0.000533, l4: 0.000786, l5: 0.001849, l6: 0.002698

[epoch: 504/1000, batch:   124/ 1052, ite: 132320] train loss: 0.004441, tar: 0.000128 
l0: 0.000070, l1: 0.000075, l2: 0.000121, l3: 0.000218, l4: 0.000423, l5: 0.001235, l6: 0.002334

[epoch: 504/1000, batch:   204/ 1052, ite: 132340] train loss: 0.004439, tar: 0.000128 
l0: 0.000016, l1: 0.000017, l2: 0.000018, l3: 0.000063, l4: 0.000211, l5: 0.000755, l6: 0.001048

[epoch: 504/1000, batch:   284/ 1052, ite: 132360] train loss: 0.004438, tar: 0.000128 
l0: 0.000113, l1: 0.000115, l2: 0.000134, l3: 0.000201, l4: 0.000456, l5: 0.000966, l6: 0.001919

[epoch: 504/1000, batch:   364/ 1052, ite: 132380] train loss: 0.004439, tar: 0.000128 
l0: 0.000113, l1: 0.000115, l2: 0.000155, l3: 0.000317, l4: 0.000745, l5: 0.001507, l6: 0.002633

[epoch: 504/1000, batch:   444/ 1052, ite: 132400] train loss: 0.004438, tar: 0.000128 
l0: 0.000192, l1: 0.000195, l2: 0.000240, l3: 0.000313, l4: 0.001064, l5: 0.001522, l6: 0.002636

[epoch: 504/1000, batch:   524/ 1052, ite: 132420] train loss: 0.004437, tar: 0.000128 
l0: 0.000029, l1: 0.000030, l2: 0.000062, l3: 0.000142, l4: 0.000386, l5: 0.000464, l6: 0.001358

[epoch: 504/1000, batch:   604/ 1052, ite: 132440] train loss: 0.004437, tar: 0.000128 
l0: 0.000079, l1: 0.000081, l2: 0.000098, l3: 0.000323, l4: 0.000393, l5: 0.000953, l6: 0.001401

[epoch: 504/1000, batch:   684/ 1052, ite: 132460] train loss: 0.004435, tar: 0.000127 
l0: 0.000173, l1: 0.000175, l2: 0.000189, l3: 0.000313, l4: 0.000692, l5: 0.001936, l6: 0.003274

[epoch: 504/1000, batch:   764/ 1052, ite: 132480] train loss: 0.004435, tar: 0.000127 
l0: 0.000067, l1: 0.000065, l2: 0.000092, l3: 0.000171, l4: 0.000406, l5: 0.000728, l6: 0.001529

[epoch: 504/1000, batch:   844/ 1052, ite: 132500] train loss: 0.004434, tar: 0.000127 
l0: 0.000027, l1: 0.000025, l2: 0.000045, l3: 0.000137, l4: 0.000377, l5: 0.000655, l6: 0.001269

[epoch: 504/1000, batch:   924/ 1052, ite: 132520] train loss: 0.004434, tar: 0.000127 
l0: 0.000097, l1: 0.000099, l2: 0.000203, l3: 0.000482, l4: 0.001212, l5: 0.002526, l6: 0.002935

[epoch: 504/1000, batch:  1004/ 1052, ite: 132540] train loss: 0.004433, tar: 0.000127 
[Epoch 504/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000068, l1: 0.000070, l2: 0.000076, l3: 0.000098, l4: 0.000268, l5: 0.000575, l6: 0.000820

[epoch: 505/1000, batch:    32/ 1052, ite: 132560] train loss: 0.004433, tar: 0.000127 
l0: 0.000058, l1: 0.000056, l2: 0.000112, l3: 0.000204, l4: 0.000443, l5: 0.000905, l6: 0.002072

[epoch: 505/1000, batch:   112/ 1052, ite: 132580] train loss: 0.004431, tar: 0.000127 
l0: 0.000057, l1: 0.000055, l2: 0.000114, l3: 0.000204, l4: 0.000421, l5: 0.001085, l6: 0.001668

[epoch: 505/1000, batch:   192/ 1052, ite: 132600] train loss: 0.004430, tar: 0.000127 
l0: 0.000034, l1: 0.000031, l2: 0.000111, l3: 0.000250, l4: 0.000761, l5: 0.001323, l6: 0.001652

[epoch: 505/1000, batch:   272/ 1052, ite: 132620] train loss: 0.004430, tar: 0.000127 
l0: 0.000075, l1: 0.000074, l2: 0.000132, l3: 0.000194, l4: 0.000375, l5: 0.000616, l6: 0.001324

[epoch: 505/1000, batch:   352/ 1052, ite: 132640] train loss: 0.004430, tar: 0.000126 
l0: 0.000079, l1: 0.000079, l2: 0.000111, l3: 0.000232, l4: 0.000555, l5: 0.001417, l6: 0.001729

[epoch: 505/1000, batch:   432/ 1052, ite: 132660] train loss: 0.004429, tar: 0.000126 
l0: 0.000081, l1: 0.000078, l2: 0.000149, l3: 0.000236, l4: 0.000580, l5: 0.000913, l6: 0.001914

[epoch: 505/1000, batch:   512/ 1052, ite: 132680] train loss: 0.004429, tar: 0.000126 
l0: 0.000042, l1: 0.000044, l2: 0.000072, l3: 0.000154, l4: 0.000433, l5: 0.000930, l6: 0.002146

[epoch: 505/1000, batch:   592/ 1052, ite: 132700] train loss: 0.004428, tar: 0.000126 
l0: 0.000045, l1: 0.000046, l2: 0.000092, l3: 0.000231, l4: 0.000454, l5: 0.000958, l6: 0.001628

[epoch: 505/1000, batch:   672/ 1052, ite: 132720] train loss: 0.004426, tar: 0.000126 
l0: 0.000071, l1: 0.000069, l2: 0.000130, l3: 0.000245, l4: 0.000457, l5: 0.000994, l6: 0.001638

[epoch: 505/1000, batch:   752/ 1052, ite: 132740] train loss: 0.004425, tar: 0.000126 
l0: 0.000074, l1: 0.000075, l2: 0.000131, l3: 0.000260, l4: 0.000639, l5: 0.001109, l6: 0.003466

[epoch: 505/1000, batch:   832/ 1052, ite: 132760] train loss: 0.004423, tar: 0.000126 
l0: 0.000096, l1: 0.000093, l2: 0.000216, l3: 0.000457, l4: 0.001122, l5: 0.002311, l6: 0.003404

[epoch: 505/1000, batch:   912/ 1052, ite: 132780] train loss: 0.004422, tar: 0.000126 
l0: 0.000252, l1: 0.000260, l2: 0.000336, l3: 0.000475, l4: 0.000915, l5: 0.003831, l6: 0.004650

[epoch: 505/1000, batch:   992/ 1052, ite: 132800] train loss: 0.004422, tar: 0.000125 
[Epoch 505/1000] Test loss: 0.016, Test target loss: 0.002
l0: 0.000094, l1: 0.000099, l2: 0.000111, l3: 0.000197, l4: 0.000406, l5: 0.001028, l6: 0.001517

[epoch: 506/1000, batch:    20/ 1052, ite: 132820] train loss: 0.004422, tar: 0.000125 
l0: 0.000086, l1: 0.000092, l2: 0.000108, l3: 0.000246, l4: 0.000512, l5: 0.001230, l6: 0.001162

[epoch: 506/1000, batch:   100/ 1052, ite: 132840] train loss: 0.004421, tar: 0.000125 
l0: 0.000085, l1: 0.000085, l2: 0.000133, l3: 0.000234, l4: 0.000462, l5: 0.000795, l6: 0.000824

[epoch: 506/1000, batch:   180/ 1052, ite: 132860] train loss: 0.004422, tar: 0.000125 
l0: 0.000033, l1: 0.000033, l2: 0.000054, l3: 0.000107, l4: 0.000367, l5: 0.000877, l6: 0.001245

[epoch: 506/1000, batch:   260/ 1052, ite: 132880] train loss: 0.004420, tar: 0.000125 
l0: 0.000159, l1: 0.000173, l2: 0.000165, l3: 0.000262, l4: 0.000828, l5: 0.000984, l6: 0.002264

[epoch: 506/1000, batch:   340/ 1052, ite: 132900] train loss: 0.004420, tar: 0.000125 
l0: 0.000034, l1: 0.000035, l2: 0.000078, l3: 0.000103, l4: 0.000296, l5: 0.001042, l6: 0.001035

[epoch: 506/1000, batch:   420/ 1052, ite: 132920] train loss: 0.004420, tar: 0.000125 
l0: 0.000103, l1: 0.000107, l2: 0.000149, l3: 0.000293, l4: 0.000706, l5: 0.001472, l6: 0.001904

[epoch: 506/1000, batch:   500/ 1052, ite: 132940] train loss: 0.004418, tar: 0.000125 
l0: 0.000063, l1: 0.000064, l2: 0.000059, l3: 0.000102, l4: 0.000493, l5: 0.000593, l6: 0.001276

[epoch: 506/1000, batch:   580/ 1052, ite: 132960] train loss: 0.004419, tar: 0.000125 
l0: 0.000039, l1: 0.000039, l2: 0.000089, l3: 0.000242, l4: 0.000741, l5: 0.001360, l6: 0.001714

[epoch: 506/1000, batch:   660/ 1052, ite: 132980] train loss: 0.004416, tar: 0.000125 
l0: 0.000045, l1: 0.000045, l2: 0.000054, l3: 0.000133, l4: 0.000345, l5: 0.000679, l6: 0.001409

[epoch: 506/1000, batch:   740/ 1052, ite: 133000] train loss: 0.004414, tar: 0.000124 
l0: 0.000131, l1: 0.000133, l2: 0.000189, l3: 0.000358, l4: 0.000766, l5: 0.001375, l6: 0.003458

[epoch: 506/1000, batch:   820/ 1052, ite: 133020] train loss: 0.004415, tar: 0.000124 
l0: 0.000080, l1: 0.000084, l2: 0.000129, l3: 0.000183, l4: 0.000342, l5: 0.001178, l6: 0.001966

[epoch: 506/1000, batch:   900/ 1052, ite: 133040] train loss: 0.004415, tar: 0.000124 
l0: 0.000147, l1: 0.000150, l2: 0.000175, l3: 0.000345, l4: 0.000660, l5: 0.001326, l6: 0.002970

[epoch: 506/1000, batch:   980/ 1052, ite: 133060] train loss: 0.004414, tar: 0.000124 
[Epoch 506/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000054, l1: 0.000054, l2: 0.000103, l3: 0.000190, l4: 0.000364, l5: 0.001188, l6: 0.001441

[epoch: 507/1000, batch:     8/ 1052, ite: 133080] train loss: 0.004412, tar: 0.000124 
l0: 0.000067, l1: 0.000064, l2: 0.000108, l3: 0.000195, l4: 0.000272, l5: 0.000608, l6: 0.000932

[epoch: 507/1000, batch:    88/ 1052, ite: 133100] train loss: 0.004412, tar: 0.000124 
l0: 0.000120, l1: 0.000120, l2: 0.000188, l3: 0.000412, l4: 0.000579, l5: 0.001177, l6: 0.002657

[epoch: 507/1000, batch:   168/ 1052, ite: 133120] train loss: 0.004410, tar: 0.000124 
l0: 0.000131, l1: 0.000128, l2: 0.000228, l3: 0.000402, l4: 0.000813, l5: 0.002382, l6: 0.004313

[epoch: 507/1000, batch:   248/ 1052, ite: 133140] train loss: 0.004410, tar: 0.000124 
l0: 0.000054, l1: 0.000052, l2: 0.000112, l3: 0.000262, l4: 0.000574, l5: 0.001353, l6: 0.001367

[epoch: 507/1000, batch:   328/ 1052, ite: 133160] train loss: 0.004408, tar: 0.000124 
l0: 0.000127, l1: 0.000121, l2: 0.000205, l3: 0.000388, l4: 0.000713, l5: 0.001405, l6: 0.002604

[epoch: 507/1000, batch:   408/ 1052, ite: 133180] train loss: 0.004407, tar: 0.000124 
l0: 0.000056, l1: 0.000057, l2: 0.000089, l3: 0.000137, l4: 0.000346, l5: 0.000944, l6: 0.001303

[epoch: 507/1000, batch:   488/ 1052, ite: 133200] train loss: 0.004406, tar: 0.000123 
l0: 0.000053, l1: 0.000053, l2: 0.000105, l3: 0.000212, l4: 0.000430, l5: 0.000952, l6: 0.002048

[epoch: 507/1000, batch:   568/ 1052, ite: 133220] train loss: 0.004405, tar: 0.000123 
l0: 0.000065, l1: 0.000063, l2: 0.000144, l3: 0.000421, l4: 0.001165, l5: 0.001702, l6: 0.003132

[epoch: 507/1000, batch:   648/ 1052, ite: 133240] train loss: 0.004405, tar: 0.000123 
l0: 0.000183, l1: 0.000181, l2: 0.000247, l3: 0.000464, l4: 0.000907, l5: 0.001644, l6: 0.003315

[epoch: 507/1000, batch:   728/ 1052, ite: 133260] train loss: 0.004404, tar: 0.000123 
l0: 0.000022, l1: 0.000022, l2: 0.000058, l3: 0.000191, l4: 0.000378, l5: 0.000874, l6: 0.000974

[epoch: 507/1000, batch:   808/ 1052, ite: 133280] train loss: 0.004404, tar: 0.000123 
l0: 0.000227, l1: 0.000224, l2: 0.000279, l3: 0.000376, l4: 0.000453, l5: 0.001071, l6: 0.003169

[epoch: 507/1000, batch:   888/ 1052, ite: 133300] train loss: 0.004404, tar: 0.000123 
l0: 0.000128, l1: 0.000135, l2: 0.000159, l3: 0.000346, l4: 0.000931, l5: 0.002112, l6: 0.004074

[epoch: 507/1000, batch:   968/ 1052, ite: 133320] train loss: 0.004404, tar: 0.000123 
l0: 0.000056, l1: 0.000057, l2: 0.000089, l3: 0.000209, l4: 0.000688, l5: 0.000993, l6: 0.001906

[epoch: 507/1000, batch:  1048/ 1052, ite: 133340] train loss: 0.004406, tar: 0.000123 
[Epoch 507/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000040, l1: 0.000041, l2: 0.000070, l3: 0.000169, l4: 0.000594, l5: 0.001487, l6: 0.001966

[epoch: 508/1000, batch:    76/ 1052, ite: 133360] train loss: 0.004404, tar: 0.000123 
l0: 0.000067, l1: 0.000067, l2: 0.000108, l3: 0.000192, l4: 0.000512, l5: 0.001094, l6: 0.001378

[epoch: 508/1000, batch:   156/ 1052, ite: 133380] train loss: 0.004403, tar: 0.000123 
l0: 0.000108, l1: 0.000109, l2: 0.000241, l3: 0.000342, l4: 0.000774, l5: 0.002034, l6: 0.003015

[epoch: 508/1000, batch:   236/ 1052, ite: 133400] train loss: 0.004403, tar: 0.000122 
l0: 0.000070, l1: 0.000070, l2: 0.000120, l3: 0.000179, l4: 0.000421, l5: 0.000749, l6: 0.001396

[epoch: 508/1000, batch:   316/ 1052, ite: 133420] train loss: 0.004401, tar: 0.000122 
l0: 0.000041, l1: 0.000040, l2: 0.000100, l3: 0.000196, l4: 0.000396, l5: 0.000908, l6: 0.001605

[epoch: 508/1000, batch:   396/ 1052, ite: 133440] train loss: 0.004401, tar: 0.000122 
l0: 0.000037, l1: 0.000039, l2: 0.000061, l3: 0.000123, l4: 0.000276, l5: 0.000561, l6: 0.000785

[epoch: 508/1000, batch:   476/ 1052, ite: 133460] train loss: 0.004398, tar: 0.000122 
l0: 0.000174, l1: 0.000173, l2: 0.000224, l3: 0.000339, l4: 0.000749, l5: 0.001878, l6: 0.003177

[epoch: 508/1000, batch:   556/ 1052, ite: 133480] train loss: 0.004399, tar: 0.000122 
l0: 0.000088, l1: 0.000088, l2: 0.000196, l3: 0.000458, l4: 0.000982, l5: 0.002260, l6: 0.002551

[epoch: 508/1000, batch:   636/ 1052, ite: 133500] train loss: 0.004397, tar: 0.000122 
l0: 0.000070, l1: 0.000066, l2: 0.000125, l3: 0.000185, l4: 0.000404, l5: 0.001358, l6: 0.002153

[epoch: 508/1000, batch:   716/ 1052, ite: 133520] train loss: 0.004397, tar: 0.000122 
l0: 0.000045, l1: 0.000047, l2: 0.000055, l3: 0.000162, l4: 0.000559, l5: 0.000654, l6: 0.001422

[epoch: 508/1000, batch:   796/ 1052, ite: 133540] train loss: 0.004396, tar: 0.000122 
l0: 0.000155, l1: 0.000160, l2: 0.000190, l3: 0.000274, l4: 0.000390, l5: 0.001105, l6: 0.001754

[epoch: 508/1000, batch:   876/ 1052, ite: 133560] train loss: 0.004395, tar: 0.000122 
l0: 0.000116, l1: 0.000112, l2: 0.000175, l3: 0.000329, l4: 0.000694, l5: 0.001511, l6: 0.002360

[epoch: 508/1000, batch:   956/ 1052, ite: 133580] train loss: 0.004397, tar: 0.000122 
l0: 0.000092, l1: 0.000093, l2: 0.000124, l3: 0.000239, l4: 0.000372, l5: 0.001019, l6: 0.001724

[epoch: 508/1000, batch:  1036/ 1052, ite: 133600] train loss: 0.004399, tar: 0.000122 
[Epoch 508/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000105, l1: 0.000110, l2: 0.000137, l3: 0.000235, l4: 0.000541, l5: 0.001129, l6: 0.001604

[epoch: 509/1000, batch:    64/ 1052, ite: 133620] train loss: 0.004398, tar: 0.000122 
l0: 0.000106, l1: 0.000104, l2: 0.000161, l3: 0.000267, l4: 0.000342, l5: 0.000936, l6: 0.001533

[epoch: 509/1000, batch:   144/ 1052, ite: 133640] train loss: 0.004398, tar: 0.000122 
l0: 0.000146, l1: 0.000146, l2: 0.000203, l3: 0.000345, l4: 0.000881, l5: 0.001587, l6: 0.002752

[epoch: 509/1000, batch:   224/ 1052, ite: 133660] train loss: 0.004396, tar: 0.000121 
l0: 0.000094, l1: 0.000092, l2: 0.000156, l3: 0.000353, l4: 0.000593, l5: 0.001222, l6: 0.002493

[epoch: 509/1000, batch:   304/ 1052, ite: 133680] train loss: 0.004395, tar: 0.000121 
l0: 0.000068, l1: 0.000066, l2: 0.000225, l3: 0.000501, l4: 0.000892, l5: 0.001743, l6: 0.002930

[epoch: 509/1000, batch:   384/ 1052, ite: 133700] train loss: 0.004395, tar: 0.000121 
l0: 0.000100, l1: 0.000102, l2: 0.000150, l3: 0.000266, l4: 0.000592, l5: 0.001201, l6: 0.002144

[epoch: 509/1000, batch:   464/ 1052, ite: 133720] train loss: 0.004395, tar: 0.000121 
l0: 0.000046, l1: 0.000047, l2: 0.000081, l3: 0.000149, l4: 0.000460, l5: 0.000877, l6: 0.001968

[epoch: 509/1000, batch:   544/ 1052, ite: 133740] train loss: 0.004392, tar: 0.000121 
l0: 0.000019, l1: 0.000020, l2: 0.000041, l3: 0.000146, l4: 0.000211, l5: 0.000465, l6: 0.001208

[epoch: 509/1000, batch:   624/ 1052, ite: 133760] train loss: 0.004393, tar: 0.000121 
l0: 0.000077, l1: 0.000074, l2: 0.000171, l3: 0.000449, l4: 0.000702, l5: 0.001702, l6: 0.003802

[epoch: 509/1000, batch:   704/ 1052, ite: 133780] train loss: 0.004393, tar: 0.000121 
l0: 0.000238, l1: 0.000241, l2: 0.000251, l3: 0.000319, l4: 0.000812, l5: 0.002007, l6: 0.002814

[epoch: 509/1000, batch:   784/ 1052, ite: 133800] train loss: 0.004391, tar: 0.000121 
l0: 0.000061, l1: 0.000060, l2: 0.000101, l3: 0.000151, l4: 0.000286, l5: 0.000871, l6: 0.001935

[epoch: 509/1000, batch:   864/ 1052, ite: 133820] train loss: 0.004391, tar: 0.000121 
l0: 0.000039, l1: 0.000038, l2: 0.000082, l3: 0.000115, l4: 0.000350, l5: 0.000628, l6: 0.001083

[epoch: 509/1000, batch:   944/ 1052, ite: 133840] train loss: 0.004390, tar: 0.000121 
l0: 0.000088, l1: 0.000091, l2: 0.000144, l3: 0.000338, l4: 0.000786, l5: 0.002081, l6: 0.003123

[epoch: 509/1000, batch:  1024/ 1052, ite: 133860] train loss: 0.004391, tar: 0.000121 
[Epoch 509/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000256, l1: 0.000256, l2: 0.000271, l3: 0.000409, l4: 0.000604, l5: 0.001369, l6: 0.003041

[epoch: 510/1000, batch:    52/ 1052, ite: 133880] train loss: 0.004392, tar: 0.000121 
l0: 0.000039, l1: 0.000039, l2: 0.000059, l3: 0.000124, l4: 0.000380, l5: 0.000903, l6: 0.001191

[epoch: 510/1000, batch:   132/ 1052, ite: 133900] train loss: 0.004391, tar: 0.000120 
l0: 0.000065, l1: 0.000068, l2: 0.000095, l3: 0.000171, l4: 0.000333, l5: 0.001066, l6: 0.001388

[epoch: 510/1000, batch:   212/ 1052, ite: 133920] train loss: 0.004391, tar: 0.000120 
l0: 0.000099, l1: 0.000107, l2: 0.000134, l3: 0.000182, l4: 0.000483, l5: 0.001431, l6: 0.001890

[epoch: 510/1000, batch:   292/ 1052, ite: 133940] train loss: 0.004390, tar: 0.000120 
l0: 0.000082, l1: 0.000085, l2: 0.000120, l3: 0.000196, l4: 0.000428, l5: 0.001158, l6: 0.001325

[epoch: 510/1000, batch:   372/ 1052, ite: 133960] train loss: 0.004388, tar: 0.000120 
l0: 0.000153, l1: 0.000152, l2: 0.000295, l3: 0.000474, l4: 0.000707, l5: 0.001670, l6: 0.003176

[epoch: 510/1000, batch:   452/ 1052, ite: 133980] train loss: 0.004387, tar: 0.000120 
l0: 0.000062, l1: 0.000062, l2: 0.000124, l3: 0.000232, l4: 0.000435, l5: 0.001402, l6: 0.002211

[epoch: 510/1000, batch:   532/ 1052, ite: 134000] train loss: 0.004386, tar: 0.000120 
l0: 0.000081, l1: 0.000082, l2: 0.000155, l3: 0.000252, l4: 0.000859, l5: 0.001385, l6: 0.002451

[epoch: 510/1000, batch:   612/ 1052, ite: 134020] train loss: 0.004384, tar: 0.000120 
l0: 0.000081, l1: 0.000081, l2: 0.000130, l3: 0.000255, l4: 0.000886, l5: 0.001076, l6: 0.002071

[epoch: 510/1000, batch:   692/ 1052, ite: 134040] train loss: 0.004383, tar: 0.000120 
l0: 0.000078, l1: 0.000076, l2: 0.000152, l3: 0.000251, l4: 0.000541, l5: 0.001047, l6: 0.002375

[epoch: 510/1000, batch:   772/ 1052, ite: 134060] train loss: 0.004383, tar: 0.000120 
l0: 0.000013, l1: 0.000014, l2: 0.000046, l3: 0.000143, l4: 0.000334, l5: 0.000953, l6: 0.001400

[epoch: 510/1000, batch:   852/ 1052, ite: 134080] train loss: 0.004384, tar: 0.000120 
l0: 0.000043, l1: 0.000044, l2: 0.000076, l3: 0.000135, l4: 0.000266, l5: 0.000887, l6: 0.001652

[epoch: 510/1000, batch:   932/ 1052, ite: 134100] train loss: 0.004384, tar: 0.000120 
l0: 0.000046, l1: 0.000048, l2: 0.000115, l3: 0.000455, l4: 0.001070, l5: 0.001880, l6: 0.003474

[epoch: 510/1000, batch:  1012/ 1052, ite: 134120] train loss: 0.004385, tar: 0.000119 
[Epoch 510/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000180, l1: 0.000175, l2: 0.000227, l3: 0.000235, l4: 0.000391, l5: 0.000664, l6: 0.001205

[epoch: 511/1000, batch:    40/ 1052, ite: 134140] train loss: 0.004385, tar: 0.000119 
l0: 0.000163, l1: 0.000167, l2: 0.000228, l3: 0.000369, l4: 0.000480, l5: 0.001313, l6: 0.002226

[epoch: 511/1000, batch:   120/ 1052, ite: 134160] train loss: 0.004384, tar: 0.000119 
l0: 0.000032, l1: 0.000032, l2: 0.000068, l3: 0.000132, l4: 0.000343, l5: 0.000690, l6: 0.001194

[epoch: 511/1000, batch:   200/ 1052, ite: 134180] train loss: 0.004381, tar: 0.000119 
l0: 0.000111, l1: 0.000115, l2: 0.000149, l3: 0.000272, l4: 0.000564, l5: 0.000858, l6: 0.001351

[epoch: 511/1000, batch:   280/ 1052, ite: 134200] train loss: 0.004380, tar: 0.000119 
l0: 0.000019, l1: 0.000018, l2: 0.000070, l3: 0.000123, l4: 0.000297, l5: 0.000794, l6: 0.001349

[epoch: 511/1000, batch:   360/ 1052, ite: 134220] train loss: 0.004379, tar: 0.000119 
l0: 0.000050, l1: 0.000048, l2: 0.000076, l3: 0.000166, l4: 0.000355, l5: 0.000744, l6: 0.001640

[epoch: 511/1000, batch:   440/ 1052, ite: 134240] train loss: 0.004378, tar: 0.000119 
l0: 0.000048, l1: 0.000050, l2: 0.000053, l3: 0.000125, l4: 0.000236, l5: 0.000411, l6: 0.001079

[epoch: 511/1000, batch:   520/ 1052, ite: 134260] train loss: 0.004377, tar: 0.000119 
l0: 0.000127, l1: 0.000128, l2: 0.000168, l3: 0.000339, l4: 0.000660, l5: 0.000863, l6: 0.001489

[epoch: 511/1000, batch:   600/ 1052, ite: 134280] train loss: 0.004379, tar: 0.000119 
l0: 0.000123, l1: 0.000121, l2: 0.000193, l3: 0.000473, l4: 0.001099, l5: 0.001774, l6: 0.003635

[epoch: 511/1000, batch:   680/ 1052, ite: 134300] train loss: 0.004379, tar: 0.000119 
l0: 0.000076, l1: 0.000074, l2: 0.000164, l3: 0.000338, l4: 0.000767, l5: 0.000994, l6: 0.001374

[epoch: 511/1000, batch:   760/ 1052, ite: 134320] train loss: 0.004380, tar: 0.000119 
l0: 0.000117, l1: 0.000121, l2: 0.000183, l3: 0.000458, l4: 0.000856, l5: 0.001922, l6: 0.003479

[epoch: 511/1000, batch:   840/ 1052, ite: 134340] train loss: 0.004377, tar: 0.000119 
l0: 0.000096, l1: 0.000099, l2: 0.000125, l3: 0.000175, l4: 0.000441, l5: 0.000827, l6: 0.002024

[epoch: 511/1000, batch:   920/ 1052, ite: 134360] train loss: 0.004378, tar: 0.000119 
l0: 0.000096, l1: 0.000101, l2: 0.000123, l3: 0.000259, l4: 0.000562, l5: 0.000569, l6: 0.002089

[epoch: 511/1000, batch:  1000/ 1052, ite: 134380] train loss: 0.004377, tar: 0.000119 
[Epoch 511/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000100, l1: 0.000102, l2: 0.000142, l3: 0.000240, l4: 0.000558, l5: 0.000860, l6: 0.002327

[epoch: 512/1000, batch:    28/ 1052, ite: 134400] train loss: 0.004377, tar: 0.000118 
l0: 0.000062, l1: 0.000063, l2: 0.000116, l3: 0.000194, l4: 0.000325, l5: 0.000761, l6: 0.001641

[epoch: 512/1000, batch:   108/ 1052, ite: 134420] train loss: 0.004375, tar: 0.000118 
l0: 0.000055, l1: 0.000061, l2: 0.000092, l3: 0.000204, l4: 0.000488, l5: 0.001148, l6: 0.001549

[epoch: 512/1000, batch:   188/ 1052, ite: 134440] train loss: 0.004376, tar: 0.000118 
l0: 0.000103, l1: 0.000105, l2: 0.000153, l3: 0.000282, l4: 0.000416, l5: 0.001266, l6: 0.002067

[epoch: 512/1000, batch:   268/ 1052, ite: 134460] train loss: 0.004377, tar: 0.000118 
l0: 0.000075, l1: 0.000075, l2: 0.000094, l3: 0.000124, l4: 0.000290, l5: 0.000697, l6: 0.001550

[epoch: 512/1000, batch:   348/ 1052, ite: 134480] train loss: 0.004376, tar: 0.000118 
l0: 0.000141, l1: 0.000139, l2: 0.000193, l3: 0.000243, l4: 0.000486, l5: 0.001647, l6: 0.002506

[epoch: 512/1000, batch:   428/ 1052, ite: 134500] train loss: 0.004377, tar: 0.000118 
l0: 0.000082, l1: 0.000083, l2: 0.000122, l3: 0.000246, l4: 0.000505, l5: 0.000988, l6: 0.002353

[epoch: 512/1000, batch:   508/ 1052, ite: 134520] train loss: 0.004376, tar: 0.000118 
l0: 0.000149, l1: 0.000152, l2: 0.000154, l3: 0.000206, l4: 0.000483, l5: 0.000911, l6: 0.002121

[epoch: 512/1000, batch:   588/ 1052, ite: 134540] train loss: 0.004376, tar: 0.000118 
l0: 0.000043, l1: 0.000041, l2: 0.000066, l3: 0.000100, l4: 0.000256, l5: 0.000327, l6: 0.000642

[epoch: 512/1000, batch:   668/ 1052, ite: 134560] train loss: 0.004374, tar: 0.000118 
l0: 0.000119, l1: 0.000123, l2: 0.000136, l3: 0.000173, l4: 0.000262, l5: 0.000507, l6: 0.001053

[epoch: 512/1000, batch:   748/ 1052, ite: 134580] train loss: 0.004374, tar: 0.000118 
l0: 0.000078, l1: 0.000077, l2: 0.000118, l3: 0.000195, l4: 0.000626, l5: 0.001920, l6: 0.002669

[epoch: 512/1000, batch:   828/ 1052, ite: 134600] train loss: 0.004374, tar: 0.000118 
l0: 0.000049, l1: 0.000053, l2: 0.000078, l3: 0.000301, l4: 0.000925, l5: 0.001520, l6: 0.002758

[epoch: 512/1000, batch:   908/ 1052, ite: 134620] train loss: 0.004374, tar: 0.000118 
l0: 0.000096, l1: 0.000093, l2: 0.000150, l3: 0.000208, l4: 0.000285, l5: 0.000949, l6: 0.001150

[epoch: 512/1000, batch:   988/ 1052, ite: 134640] train loss: 0.004373, tar: 0.000118 
[Epoch 512/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000028, l1: 0.000026, l2: 0.000101, l3: 0.000199, l4: 0.000299, l5: 0.000743, l6: 0.001117

[epoch: 513/1000, batch:    16/ 1052, ite: 134660] train loss: 0.004371, tar: 0.000118 
l0: 0.000093, l1: 0.000095, l2: 0.000156, l3: 0.000353, l4: 0.001060, l5: 0.002264, l6: 0.003702

[epoch: 513/1000, batch:    96/ 1052, ite: 134680] train loss: 0.004373, tar: 0.000117 
l0: 0.000056, l1: 0.000055, l2: 0.000095, l3: 0.000163, l4: 0.000376, l5: 0.000652, l6: 0.001007

[epoch: 513/1000, batch:   176/ 1052, ite: 134700] train loss: 0.004373, tar: 0.000117 
l0: 0.000136, l1: 0.000138, l2: 0.000188, l3: 0.000213, l4: 0.000456, l5: 0.001191, l6: 0.002621

[epoch: 513/1000, batch:   256/ 1052, ite: 134720] train loss: 0.004374, tar: 0.000118 
l0: 0.000055, l1: 0.000056, l2: 0.000098, l3: 0.000171, l4: 0.000358, l5: 0.001482, l6: 0.001865

[epoch: 513/1000, batch:   336/ 1052, ite: 134740] train loss: 0.004374, tar: 0.000118 
l0: 0.000186, l1: 0.000188, l2: 0.000235, l3: 0.000417, l4: 0.000687, l5: 0.001490, l6: 0.003150

[epoch: 513/1000, batch:   416/ 1052, ite: 134760] train loss: 0.004375, tar: 0.000118 
l0: 0.000071, l1: 0.000071, l2: 0.000123, l3: 0.000212, l4: 0.000394, l5: 0.001141, l6: 0.002164

[epoch: 513/1000, batch:   496/ 1052, ite: 134780] train loss: 0.004373, tar: 0.000117 
l0: 0.000089, l1: 0.000088, l2: 0.000189, l3: 0.000383, l4: 0.000825, l5: 0.001325, l6: 0.001967

[epoch: 513/1000, batch:   576/ 1052, ite: 134800] train loss: 0.004372, tar: 0.000117 
l0: 0.000097, l1: 0.000102, l2: 0.000093, l3: 0.000233, l4: 0.000377, l5: 0.001269, l6: 0.001823

[epoch: 513/1000, batch:   656/ 1052, ite: 134820] train loss: 0.004372, tar: 0.000117 
l0: 0.000133, l1: 0.000136, l2: 0.000168, l3: 0.000270, l4: 0.000495, l5: 0.001375, l6: 0.002829

[epoch: 513/1000, batch:   736/ 1052, ite: 134840] train loss: 0.004371, tar: 0.000117 
l0: 0.000044, l1: 0.000044, l2: 0.000110, l3: 0.000180, l4: 0.000478, l5: 0.000974, l6: 0.001537

[epoch: 513/1000, batch:   816/ 1052, ite: 134860] train loss: 0.004369, tar: 0.000117 
l0: 0.000092, l1: 0.000094, l2: 0.000125, l3: 0.000175, l4: 0.000377, l5: 0.000973, l6: 0.002275

[epoch: 513/1000, batch:   896/ 1052, ite: 134880] train loss: 0.004369, tar: 0.000117 
l0: 0.000131, l1: 0.000142, l2: 0.000165, l3: 0.000298, l4: 0.000776, l5: 0.001204, l6: 0.002387

[epoch: 513/1000, batch:   976/ 1052, ite: 134900] train loss: 0.004368, tar: 0.000117 
[Epoch 513/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000074, l1: 0.000074, l2: 0.000114, l3: 0.000150, l4: 0.000553, l5: 0.001370, l6: 0.002725

[epoch: 514/1000, batch:     4/ 1052, ite: 134920] train loss: 0.004368, tar: 0.000117 
l0: 0.000109, l1: 0.000104, l2: 0.000152, l3: 0.000239, l4: 0.000312, l5: 0.001050, l6: 0.002638

[epoch: 514/1000, batch:    84/ 1052, ite: 134940] train loss: 0.004367, tar: 0.000117 
l0: 0.000124, l1: 0.000123, l2: 0.000264, l3: 0.000563, l4: 0.001038, l5: 0.002361, l6: 0.003702

[epoch: 514/1000, batch:   164/ 1052, ite: 134960] train loss: 0.004367, tar: 0.000117 
l0: 0.000126, l1: 0.000128, l2: 0.000212, l3: 0.000348, l4: 0.000780, l5: 0.001418, l6: 0.002054

[epoch: 514/1000, batch:   244/ 1052, ite: 134980] train loss: 0.004367, tar: 0.000117 
l0: 0.000128, l1: 0.000131, l2: 0.000177, l3: 0.000317, l4: 0.000489, l5: 0.000971, l6: 0.001544

[epoch: 514/1000, batch:   324/ 1052, ite: 135000] train loss: 0.004366, tar: 0.000117 
l0: 0.000058, l1: 0.000058, l2: 0.000088, l3: 0.000144, l4: 0.000388, l5: 0.000668, l6: 0.001331

[epoch: 514/1000, batch:   404/ 1052, ite: 135020] train loss: 0.004366, tar: 0.000117 
l0: 0.000021, l1: 0.000020, l2: 0.000079, l3: 0.000179, l4: 0.000408, l5: 0.000809, l6: 0.001616

[epoch: 514/1000, batch:   484/ 1052, ite: 135040] train loss: 0.004364, tar: 0.000117 
l0: 0.000041, l1: 0.000041, l2: 0.000068, l3: 0.000115, l4: 0.000339, l5: 0.000995, l6: 0.000944

[epoch: 514/1000, batch:   564/ 1052, ite: 135060] train loss: 0.004364, tar: 0.000116 
l0: 0.000073, l1: 0.000071, l2: 0.000114, l3: 0.000227, l4: 0.000465, l5: 0.000818, l6: 0.001974

[epoch: 514/1000, batch:   644/ 1052, ite: 135080] train loss: 0.004365, tar: 0.000116 
l0: 0.000104, l1: 0.000104, l2: 0.000154, l3: 0.000204, l4: 0.000404, l5: 0.001261, l6: 0.002144

[epoch: 514/1000, batch:   724/ 1052, ite: 135100] train loss: 0.004365, tar: 0.000116 
l0: 0.000003, l1: 0.000004, l2: 0.000029, l3: 0.000104, l4: 0.000334, l5: 0.000628, l6: 0.000945

[epoch: 514/1000, batch:   804/ 1052, ite: 135120] train loss: 0.004364, tar: 0.000116 
l0: 0.000045, l1: 0.000044, l2: 0.000104, l3: 0.000196, l4: 0.000448, l5: 0.000433, l6: 0.001469

[epoch: 514/1000, batch:   884/ 1052, ite: 135140] train loss: 0.004363, tar: 0.000116 
l0: 0.000071, l1: 0.000075, l2: 0.000076, l3: 0.000079, l4: 0.000350, l5: 0.000956, l6: 0.001512

[epoch: 514/1000, batch:   964/ 1052, ite: 135160] train loss: 0.004363, tar: 0.000116 
l0: 0.000282, l1: 0.000268, l2: 0.000319, l3: 0.000496, l4: 0.001136, l5: 0.001870, l6: 0.002745

[epoch: 514/1000, batch:  1044/ 1052, ite: 135180] train loss: 0.004362, tar: 0.000116 
[Epoch 514/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000053, l1: 0.000051, l2: 0.000101, l3: 0.000209, l4: 0.000512, l5: 0.001145, l6: 0.002073

[epoch: 515/1000, batch:    72/ 1052, ite: 135200] train loss: 0.004362, tar: 0.000116 
l0: 0.000078, l1: 0.000080, l2: 0.000098, l3: 0.000197, l4: 0.000504, l5: 0.001030, l6: 0.001933

[epoch: 515/1000, batch:   152/ 1052, ite: 135220] train loss: 0.004362, tar: 0.000116 
l0: 0.000039, l1: 0.000041, l2: 0.000070, l3: 0.000145, l4: 0.000249, l5: 0.000644, l6: 0.001661

[epoch: 515/1000, batch:   232/ 1052, ite: 135240] train loss: 0.004362, tar: 0.000116 
l0: 0.000070, l1: 0.000067, l2: 0.000118, l3: 0.000255, l4: 0.000517, l5: 0.001221, l6: 0.001916

[epoch: 515/1000, batch:   312/ 1052, ite: 135260] train loss: 0.004360, tar: 0.000116 
l0: 0.000069, l1: 0.000069, l2: 0.000157, l3: 0.000296, l4: 0.001024, l5: 0.001280, l6: 0.002717

[epoch: 515/1000, batch:   392/ 1052, ite: 135280] train loss: 0.004359, tar: 0.000116 
l0: 0.000062, l1: 0.000063, l2: 0.000122, l3: 0.000283, l4: 0.000482, l5: 0.001229, l6: 0.002145

[epoch: 515/1000, batch:   472/ 1052, ite: 135300] train loss: 0.004359, tar: 0.000116 
l0: 0.000045, l1: 0.000046, l2: 0.000070, l3: 0.000139, l4: 0.000502, l5: 0.001124, l6: 0.001887

[epoch: 515/1000, batch:   552/ 1052, ite: 135320] train loss: 0.004359, tar: 0.000116 
l0: 0.000049, l1: 0.000050, l2: 0.000107, l3: 0.000172, l4: 0.000386, l5: 0.000903, l6: 0.002141

[epoch: 515/1000, batch:   632/ 1052, ite: 135340] train loss: 0.004360, tar: 0.000116 
l0: 0.000103, l1: 0.000102, l2: 0.000156, l3: 0.000356, l4: 0.000673, l5: 0.001896, l6: 0.003846

[epoch: 515/1000, batch:   712/ 1052, ite: 135360] train loss: 0.004360, tar: 0.000115 
l0: 0.000063, l1: 0.000067, l2: 0.000153, l3: 0.000239, l4: 0.000521, l5: 0.000759, l6: 0.001321

[epoch: 515/1000, batch:   792/ 1052, ite: 135380] train loss: 0.004359, tar: 0.000115 
l0: 0.000068, l1: 0.000067, l2: 0.000132, l3: 0.000216, l4: 0.000375, l5: 0.001133, l6: 0.002338

[epoch: 515/1000, batch:   872/ 1052, ite: 135400] train loss: 0.004360, tar: 0.000115 
l0: 0.000049, l1: 0.000047, l2: 0.000105, l3: 0.000237, l4: 0.000466, l5: 0.000748, l6: 0.001195

[epoch: 515/1000, batch:   952/ 1052, ite: 135420] train loss: 0.004358, tar: 0.000115 
l0: 0.000073, l1: 0.000073, l2: 0.000095, l3: 0.000182, l4: 0.000305, l5: 0.001043, l6: 0.001843

[epoch: 515/1000, batch:  1032/ 1052, ite: 135440] train loss: 0.004358, tar: 0.000115 
[Epoch 515/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000012, l1: 0.000013, l2: 0.000033, l3: 0.000081, l4: 0.000163, l5: 0.000426, l6: 0.001330

[epoch: 516/1000, batch:    60/ 1052, ite: 135460] train loss: 0.004358, tar: 0.000115 
l0: 0.000088, l1: 0.000088, l2: 0.000136, l3: 0.000280, l4: 0.000649, l5: 0.001660, l6: 0.003225

[epoch: 516/1000, batch:   140/ 1052, ite: 135480] train loss: 0.004359, tar: 0.000115 
l0: 0.000041, l1: 0.000041, l2: 0.000057, l3: 0.000173, l4: 0.000530, l5: 0.001101, l6: 0.001330

[epoch: 516/1000, batch:   220/ 1052, ite: 135500] train loss: 0.004357, tar: 0.000115 
l0: 0.000034, l1: 0.000033, l2: 0.000123, l3: 0.000266, l4: 0.000437, l5: 0.000914, l6: 0.001819

[epoch: 516/1000, batch:   300/ 1052, ite: 135520] train loss: 0.004357, tar: 0.000115 
l0: 0.000081, l1: 0.000082, l2: 0.000105, l3: 0.000213, l4: 0.000434, l5: 0.001499, l6: 0.003206

[epoch: 516/1000, batch:   380/ 1052, ite: 135540] train loss: 0.004356, tar: 0.000115 
l0: 0.000034, l1: 0.000035, l2: 0.000035, l3: 0.000093, l4: 0.000229, l5: 0.000539, l6: 0.000736

[epoch: 516/1000, batch:   460/ 1052, ite: 135560] train loss: 0.004355, tar: 0.000115 
l0: 0.000091, l1: 0.000090, l2: 0.000149, l3: 0.000233, l4: 0.001015, l5: 0.001303, l6: 0.002933

[epoch: 516/1000, batch:   540/ 1052, ite: 135580] train loss: 0.004356, tar: 0.000115 
l0: 0.000033, l1: 0.000035, l2: 0.000087, l3: 0.000184, l4: 0.000342, l5: 0.000764, l6: 0.001370

[epoch: 516/1000, batch:   620/ 1052, ite: 135600] train loss: 0.004354, tar: 0.000115 
l0: 0.000078, l1: 0.000080, l2: 0.000142, l3: 0.000318, l4: 0.000754, l5: 0.001491, l6: 0.002617

[epoch: 516/1000, batch:   700/ 1052, ite: 135620] train loss: 0.004354, tar: 0.000115 
l0: 0.000055, l1: 0.000054, l2: 0.000094, l3: 0.000107, l4: 0.000218, l5: 0.000593, l6: 0.001271

[epoch: 516/1000, batch:   780/ 1052, ite: 135640] train loss: 0.004353, tar: 0.000114 
l0: 0.000156, l1: 0.000156, l2: 0.000151, l3: 0.000175, l4: 0.000285, l5: 0.000784, l6: 0.001375

[epoch: 516/1000, batch:   860/ 1052, ite: 135660] train loss: 0.004352, tar: 0.000114 
l0: 0.000064, l1: 0.000064, l2: 0.000093, l3: 0.000174, l4: 0.000499, l5: 0.001006, l6: 0.002020

[epoch: 516/1000, batch:   940/ 1052, ite: 135680] train loss: 0.004352, tar: 0.000114 
l0: 0.000090, l1: 0.000091, l2: 0.000125, l3: 0.000198, l4: 0.000384, l5: 0.001029, l6: 0.001975

[epoch: 516/1000, batch:  1020/ 1052, ite: 135700] train loss: 0.004352, tar: 0.000114 
[Epoch 516/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000168, l1: 0.000162, l2: 0.000181, l3: 0.000273, l4: 0.000584, l5: 0.001024, l6: 0.001299

[epoch: 517/1000, batch:    48/ 1052, ite: 135720] train loss: 0.004352, tar: 0.000114 
l0: 0.000036, l1: 0.000036, l2: 0.000067, l3: 0.000111, l4: 0.000453, l5: 0.000781, l6: 0.001538

[epoch: 517/1000, batch:   128/ 1052, ite: 135740] train loss: 0.004351, tar: 0.000114 
l0: 0.000030, l1: 0.000030, l2: 0.000070, l3: 0.000174, l4: 0.000384, l5: 0.001254, l6: 0.002351

[epoch: 517/1000, batch:   208/ 1052, ite: 135760] train loss: 0.004349, tar: 0.000114 
l0: 0.000019, l1: 0.000019, l2: 0.000043, l3: 0.000106, l4: 0.000267, l5: 0.000868, l6: 0.001254

[epoch: 517/1000, batch:   288/ 1052, ite: 135780] train loss: 0.004350, tar: 0.000114 
l0: 0.000037, l1: 0.000037, l2: 0.000070, l3: 0.000171, l4: 0.000366, l5: 0.000675, l6: 0.001336

[epoch: 517/1000, batch:   368/ 1052, ite: 135800] train loss: 0.004350, tar: 0.000114 
l0: 0.000212, l1: 0.000204, l2: 0.000232, l3: 0.000255, l4: 0.000479, l5: 0.001074, l6: 0.002184

[epoch: 517/1000, batch:   448/ 1052, ite: 135820] train loss: 0.004350, tar: 0.000114 
l0: 0.000022, l1: 0.000022, l2: 0.000050, l3: 0.000169, l4: 0.000308, l5: 0.000759, l6: 0.001278

[epoch: 517/1000, batch:   528/ 1052, ite: 135840] train loss: 0.004349, tar: 0.000114 
l0: 0.000065, l1: 0.000068, l2: 0.000100, l3: 0.000274, l4: 0.000604, l5: 0.001109, l6: 0.002253

[epoch: 517/1000, batch:   608/ 1052, ite: 135860] train loss: 0.004349, tar: 0.000114 
l0: 0.000068, l1: 0.000067, l2: 0.000127, l3: 0.000195, l4: 0.000284, l5: 0.001022, l6: 0.001516

[epoch: 517/1000, batch:   688/ 1052, ite: 135880] train loss: 0.004348, tar: 0.000114 
l0: 0.000158, l1: 0.000161, l2: 0.000199, l3: 0.000294, l4: 0.000468, l5: 0.001402, l6: 0.001665

[epoch: 517/1000, batch:   768/ 1052, ite: 135900] train loss: 0.004348, tar: 0.000114 
l0: 0.000058, l1: 0.000058, l2: 0.000076, l3: 0.000141, l4: 0.000305, l5: 0.000842, l6: 0.001762

[epoch: 517/1000, batch:   848/ 1052, ite: 135920] train loss: 0.004347, tar: 0.000114 
l0: 0.000038, l1: 0.000039, l2: 0.000065, l3: 0.000184, l4: 0.000471, l5: 0.000528, l6: 0.001340

[epoch: 517/1000, batch:   928/ 1052, ite: 135940] train loss: 0.004347, tar: 0.000113 
l0: 0.000076, l1: 0.000076, l2: 0.000119, l3: 0.000195, l4: 0.000519, l5: 0.000783, l6: 0.001530

[epoch: 517/1000, batch:  1008/ 1052, ite: 135960] train loss: 0.004346, tar: 0.000113 
[Epoch 517/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000058, l1: 0.000059, l2: 0.000085, l3: 0.000203, l4: 0.000406, l5: 0.000858, l6: 0.001123

[epoch: 518/1000, batch:    36/ 1052, ite: 135980] train loss: 0.004346, tar: 0.000113 
l0: 0.000060, l1: 0.000061, l2: 0.000083, l3: 0.000215, l4: 0.000539, l5: 0.001674, l6: 0.001534

[epoch: 518/1000, batch:   116/ 1052, ite: 136000] train loss: 0.004345, tar: 0.000113 
l0: 0.000070, l1: 0.000072, l2: 0.000096, l3: 0.000136, l4: 0.000344, l5: 0.000936, l6: 0.001424

[epoch: 518/1000, batch:   196/ 1052, ite: 136020] train loss: 0.004344, tar: 0.000113 
l0: 0.000089, l1: 0.000087, l2: 0.000146, l3: 0.000284, l4: 0.000755, l5: 0.001447, l6: 0.002595

[epoch: 518/1000, batch:   276/ 1052, ite: 136040] train loss: 0.004343, tar: 0.000113 
l0: 0.000077, l1: 0.000079, l2: 0.000067, l3: 0.000126, l4: 0.000354, l5: 0.000826, l6: 0.002167

[epoch: 518/1000, batch:   356/ 1052, ite: 136060] train loss: 0.004342, tar: 0.000113 
l0: 0.000070, l1: 0.000075, l2: 0.000107, l3: 0.000217, l4: 0.000605, l5: 0.000921, l6: 0.002522

[epoch: 518/1000, batch:   436/ 1052, ite: 136080] train loss: 0.004341, tar: 0.000113 
l0: 0.000098, l1: 0.000100, l2: 0.000122, l3: 0.000157, l4: 0.000394, l5: 0.001026, l6: 0.001201

[epoch: 518/1000, batch:   516/ 1052, ite: 136100] train loss: 0.004341, tar: 0.000113 
l0: 0.000061, l1: 0.000060, l2: 0.000110, l3: 0.000161, l4: 0.000407, l5: 0.000811, l6: 0.001089

[epoch: 518/1000, batch:   596/ 1052, ite: 136120] train loss: 0.004341, tar: 0.000113 
l0: 0.000053, l1: 0.000054, l2: 0.000111, l3: 0.000206, l4: 0.000648, l5: 0.001302, l6: 0.002004

[epoch: 518/1000, batch:   676/ 1052, ite: 136140] train loss: 0.004342, tar: 0.000113 
l0: 0.000175, l1: 0.000176, l2: 0.000273, l3: 0.000523, l4: 0.000721, l5: 0.000923, l6: 0.002514

[epoch: 518/1000, batch:   756/ 1052, ite: 136160] train loss: 0.004342, tar: 0.000113 
l0: 0.000056, l1: 0.000057, l2: 0.000142, l3: 0.000265, l4: 0.000657, l5: 0.000889, l6: 0.001553

[epoch: 518/1000, batch:   836/ 1052, ite: 136180] train loss: 0.004342, tar: 0.000113 
l0: 0.000122, l1: 0.000124, l2: 0.000136, l3: 0.000254, l4: 0.000681, l5: 0.001463, l6: 0.002645

[epoch: 518/1000, batch:   916/ 1052, ite: 136200] train loss: 0.004342, tar: 0.000113 
l0: 0.000166, l1: 0.000166, l2: 0.000213, l3: 0.000287, l4: 0.000551, l5: 0.001075, l6: 0.002250

[epoch: 518/1000, batch:   996/ 1052, ite: 136220] train loss: 0.004342, tar: 0.000113 
[Epoch 518/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000050, l1: 0.000048, l2: 0.000144, l3: 0.000332, l4: 0.000976, l5: 0.002041, l6: 0.002957

[epoch: 519/1000, batch:    24/ 1052, ite: 136240] train loss: 0.004341, tar: 0.000113 
l0: 0.000176, l1: 0.000177, l2: 0.000224, l3: 0.000303, l4: 0.000603, l5: 0.001551, l6: 0.002983

[epoch: 519/1000, batch:   104/ 1052, ite: 136260] train loss: 0.004341, tar: 0.000113 
l0: 0.000063, l1: 0.000065, l2: 0.000101, l3: 0.000253, l4: 0.000434, l5: 0.001094, l6: 0.002421

[epoch: 519/1000, batch:   184/ 1052, ite: 136280] train loss: 0.004341, tar: 0.000113 
l0: 0.000057, l1: 0.000059, l2: 0.000107, l3: 0.000223, l4: 0.000501, l5: 0.001377, l6: 0.003051

[epoch: 519/1000, batch:   264/ 1052, ite: 136300] train loss: 0.004341, tar: 0.000112 
l0: 0.000069, l1: 0.000072, l2: 0.000072, l3: 0.000125, l4: 0.000400, l5: 0.000843, l6: 0.001208

[epoch: 519/1000, batch:   344/ 1052, ite: 136320] train loss: 0.004341, tar: 0.000112 
l0: 0.000074, l1: 0.000074, l2: 0.000102, l3: 0.000154, l4: 0.000311, l5: 0.000844, l6: 0.001337

[epoch: 519/1000, batch:   424/ 1052, ite: 136340] train loss: 0.004342, tar: 0.000112 
l0: 0.000121, l1: 0.000121, l2: 0.000156, l3: 0.000216, l4: 0.000528, l5: 0.001058, l6: 0.002422

[epoch: 519/1000, batch:   504/ 1052, ite: 136360] train loss: 0.004342, tar: 0.000112 
l0: 0.000053, l1: 0.000054, l2: 0.000078, l3: 0.000258, l4: 0.000474, l5: 0.001110, l6: 0.002091

[epoch: 519/1000, batch:   584/ 1052, ite: 136380] train loss: 0.004341, tar: 0.000112 
l0: 0.000023, l1: 0.000024, l2: 0.000067, l3: 0.000106, l4: 0.000373, l5: 0.000605, l6: 0.001007

[epoch: 519/1000, batch:   664/ 1052, ite: 136400] train loss: 0.004340, tar: 0.000112 
l0: 0.000071, l1: 0.000069, l2: 0.000099, l3: 0.000165, l4: 0.000572, l5: 0.000888, l6: 0.001113

[epoch: 519/1000, batch:   744/ 1052, ite: 136420] train loss: 0.004340, tar: 0.000112 
l0: 0.000056, l1: 0.000057, l2: 0.000093, l3: 0.000205, l4: 0.000381, l5: 0.000795, l6: 0.001143

[epoch: 519/1000, batch:   824/ 1052, ite: 136440] train loss: 0.004340, tar: 0.000112 
l0: 0.000043, l1: 0.000046, l2: 0.000082, l3: 0.000194, l4: 0.000465, l5: 0.000887, l6: 0.001600

[epoch: 519/1000, batch:   904/ 1052, ite: 136460] train loss: 0.004340, tar: 0.000112 
l0: 0.000072, l1: 0.000073, l2: 0.000078, l3: 0.000179, l4: 0.000388, l5: 0.001249, l6: 0.001438

[epoch: 519/1000, batch:   984/ 1052, ite: 136480] train loss: 0.004339, tar: 0.000112 
[Epoch 519/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000094, l1: 0.000094, l2: 0.000119, l3: 0.000195, l4: 0.000390, l5: 0.001034, l6: 0.001672

[epoch: 520/1000, batch:    12/ 1052, ite: 136500] train loss: 0.004338, tar: 0.000112 
l0: 0.000045, l1: 0.000042, l2: 0.000101, l3: 0.000175, l4: 0.000430, l5: 0.000892, l6: 0.001902

[epoch: 520/1000, batch:    92/ 1052, ite: 136520] train loss: 0.004338, tar: 0.000112 
l0: 0.000020, l1: 0.000020, l2: 0.000090, l3: 0.000385, l4: 0.000782, l5: 0.001359, l6: 0.003000

[epoch: 520/1000, batch:   172/ 1052, ite: 136540] train loss: 0.004338, tar: 0.000112 
l0: 0.000057, l1: 0.000058, l2: 0.000094, l3: 0.000185, l4: 0.000413, l5: 0.001027, l6: 0.001240

[epoch: 520/1000, batch:   252/ 1052, ite: 136560] train loss: 0.004338, tar: 0.000112 
l0: 0.000074, l1: 0.000071, l2: 0.000144, l3: 0.000217, l4: 0.000476, l5: 0.001038, l6: 0.001624

[epoch: 520/1000, batch:   332/ 1052, ite: 136580] train loss: 0.004338, tar: 0.000112 
l0: 0.000035, l1: 0.000036, l2: 0.000075, l3: 0.000102, l4: 0.000390, l5: 0.000878, l6: 0.001512

[epoch: 520/1000, batch:   412/ 1052, ite: 136600] train loss: 0.004336, tar: 0.000112 
l0: 0.000025, l1: 0.000024, l2: 0.000084, l3: 0.000189, l4: 0.000303, l5: 0.000967, l6: 0.001629

[epoch: 520/1000, batch:   492/ 1052, ite: 136620] train loss: 0.004335, tar: 0.000112 
l0: 0.000033, l1: 0.000034, l2: 0.000066, l3: 0.000174, l4: 0.000388, l5: 0.001245, l6: 0.001333

[epoch: 520/1000, batch:   572/ 1052, ite: 136640] train loss: 0.004335, tar: 0.000112 
l0: 0.000065, l1: 0.000065, l2: 0.000117, l3: 0.000176, l4: 0.000284, l5: 0.000727, l6: 0.001345

[epoch: 520/1000, batch:   652/ 1052, ite: 136660] train loss: 0.004335, tar: 0.000111 
l0: 0.000065, l1: 0.000065, l2: 0.000124, l3: 0.000188, l4: 0.000332, l5: 0.001067, l6: 0.002109

[epoch: 520/1000, batch:   732/ 1052, ite: 136680] train loss: 0.004335, tar: 0.000111 
l0: 0.000083, l1: 0.000085, l2: 0.000110, l3: 0.000233, l4: 0.000461, l5: 0.001373, l6: 0.001970

[epoch: 520/1000, batch:   812/ 1052, ite: 136700] train loss: 0.004335, tar: 0.000111 
l0: 0.000043, l1: 0.000045, l2: 0.000114, l3: 0.000311, l4: 0.000534, l5: 0.000850, l6: 0.001609

[epoch: 520/1000, batch:   892/ 1052, ite: 136720] train loss: 0.004335, tar: 0.000111 
l0: 0.000074, l1: 0.000073, l2: 0.000134, l3: 0.000191, l4: 0.000472, l5: 0.000941, l6: 0.001498

[epoch: 520/1000, batch:   972/ 1052, ite: 136740] train loss: 0.004334, tar: 0.000111 
l0: 0.000042, l1: 0.000041, l2: 0.000082, l3: 0.000179, l4: 0.000384, l5: 0.000546, l6: 0.002780

[epoch: 520/1000, batch:  1052/ 1052, ite: 136760] train loss: 0.004334, tar: 0.000111 
[Epoch 520/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000072, l1: 0.000074, l2: 0.000113, l3: 0.000226, l4: 0.000531, l5: 0.000526, l6: 0.001509

[epoch: 521/1000, batch:    80/ 1052, ite: 136780] train loss: 0.004882, tar: 0.000113 
l0: 0.000079, l1: 0.000083, l2: 0.000124, l3: 0.000205, l4: 0.000524, l5: 0.002086, l6: 0.003234

[epoch: 521/1000, batch:   160/ 1052, ite: 136800] train loss: 0.004667, tar: 0.000099 
l0: 0.000128, l1: 0.000132, l2: 0.000236, l3: 0.000392, l4: 0.000751, l5: 0.001508, l6: 0.003698

[epoch: 521/1000, batch:   240/ 1052, ite: 136820] train loss: 0.004342, tar: 0.000090 
l0: 0.000076, l1: 0.000076, l2: 0.000146, l3: 0.000268, l4: 0.000528, l5: 0.000892, l6: 0.003177

[epoch: 521/1000, batch:   320/ 1052, ite: 136840] train loss: 0.004153, tar: 0.000084 
l0: 0.000154, l1: 0.000150, l2: 0.000166, l3: 0.000230, l4: 0.000514, l5: 0.001222, l6: 0.002012

[epoch: 521/1000, batch:   400/ 1052, ite: 136860] train loss: 0.004068, tar: 0.000083 
l0: 0.000055, l1: 0.000055, l2: 0.000103, l3: 0.000202, l4: 0.000315, l5: 0.000861, l6: 0.000885

[epoch: 521/1000, batch:   480/ 1052, ite: 136880] train loss: 0.004097, tar: 0.000087 
l0: 0.000046, l1: 0.000048, l2: 0.000079, l3: 0.000179, l4: 0.000524, l5: 0.000719, l6: 0.001212

[epoch: 521/1000, batch:   560/ 1052, ite: 136900] train loss: 0.004106, tar: 0.000088 
l0: 0.000092, l1: 0.000096, l2: 0.000120, l3: 0.000222, l4: 0.000332, l5: 0.001040, l6: 0.002473

[epoch: 521/1000, batch:   640/ 1052, ite: 136920] train loss: 0.004069, tar: 0.000085 
l0: 0.000092, l1: 0.000092, l2: 0.000146, l3: 0.000455, l4: 0.000937, l5: 0.001606, l6: 0.002449

[epoch: 521/1000, batch:   720/ 1052, ite: 136940] train loss: 0.004122, tar: 0.000085 
l0: 0.000135, l1: 0.000138, l2: 0.000156, l3: 0.000215, l4: 0.000472, l5: 0.000770, l6: 0.002279

[epoch: 521/1000, batch:   800/ 1052, ite: 136960] train loss: 0.004132, tar: 0.000085 
l0: 0.000064, l1: 0.000063, l2: 0.000113, l3: 0.000256, l4: 0.000493, l5: 0.000704, l6: 0.001406

[epoch: 521/1000, batch:   880/ 1052, ite: 136980] train loss: 0.004104, tar: 0.000084 
l0: 0.000079, l1: 0.000076, l2: 0.000184, l3: 0.000345, l4: 0.000645, l5: 0.001125, l6: 0.002599

[epoch: 521/1000, batch:   960/ 1052, ite: 137000] train loss: 0.004088, tar: 0.000083 
l0: 0.000074, l1: 0.000077, l2: 0.000080, l3: 0.000126, l4: 0.000178, l5: 0.000642, l6: 0.001173

[epoch: 521/1000, batch:  1040/ 1052, ite: 137020] train loss: 0.004076, tar: 0.000082 
[Epoch 521/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000056, l1: 0.000053, l2: 0.000105, l3: 0.000208, l4: 0.000341, l5: 0.000994, l6: 0.002370

[epoch: 522/1000, batch:    68/ 1052, ite: 137040] train loss: 0.004088, tar: 0.000082 
l0: 0.000069, l1: 0.000070, l2: 0.000104, l3: 0.000151, l4: 0.000461, l5: 0.000878, l6: 0.001892

[epoch: 522/1000, batch:   148/ 1052, ite: 137060] train loss: 0.004075, tar: 0.000082 
l0: 0.000078, l1: 0.000078, l2: 0.000164, l3: 0.000327, l4: 0.000727, l5: 0.001128, l6: 0.001975

[epoch: 522/1000, batch:   228/ 1052, ite: 137080] train loss: 0.004085, tar: 0.000083 
l0: 0.000094, l1: 0.000096, l2: 0.000099, l3: 0.000234, l4: 0.000446, l5: 0.000978, l6: 0.001310

[epoch: 522/1000, batch:   308/ 1052, ite: 137100] train loss: 0.004082, tar: 0.000083 
l0: 0.000096, l1: 0.000097, l2: 0.000179, l3: 0.000297, l4: 0.000555, l5: 0.001061, l6: 0.003137

[epoch: 522/1000, batch:   388/ 1052, ite: 137120] train loss: 0.004090, tar: 0.000084 
l0: 0.000121, l1: 0.000122, l2: 0.000138, l3: 0.000255, l4: 0.000392, l5: 0.000779, l6: 0.001448

[epoch: 522/1000, batch:   468/ 1052, ite: 137140] train loss: 0.004117, tar: 0.000084 
l0: 0.000067, l1: 0.000063, l2: 0.000176, l3: 0.000307, l4: 0.000582, l5: 0.001355, l6: 0.002577

[epoch: 522/1000, batch:   548/ 1052, ite: 137160] train loss: 0.004148, tar: 0.000085 
l0: 0.000075, l1: 0.000077, l2: 0.000104, l3: 0.000174, l4: 0.000324, l5: 0.001091, l6: 0.001658

[epoch: 522/1000, batch:   628/ 1052, ite: 137180] train loss: 0.004147, tar: 0.000085 
l0: 0.000121, l1: 0.000121, l2: 0.000218, l3: 0.000304, l4: 0.000643, l5: 0.001337, l6: 0.002641

[epoch: 522/1000, batch:   708/ 1052, ite: 137200] train loss: 0.004127, tar: 0.000084 
l0: 0.000250, l1: 0.000250, l2: 0.000320, l3: 0.000471, l4: 0.000944, l5: 0.002495, l6: 0.003674

[epoch: 522/1000, batch:   788/ 1052, ite: 137220] train loss: 0.004133, tar: 0.000084 
l0: 0.000132, l1: 0.000141, l2: 0.000157, l3: 0.000239, l4: 0.000496, l5: 0.000725, l6: 0.001788

[epoch: 522/1000, batch:   868/ 1052, ite: 137240] train loss: 0.004126, tar: 0.000084 
l0: 0.000065, l1: 0.000068, l2: 0.000082, l3: 0.000186, l4: 0.000499, l5: 0.000875, l6: 0.001432

[epoch: 522/1000, batch:   948/ 1052, ite: 137260] train loss: 0.004121, tar: 0.000084 
l0: 0.000044, l1: 0.000046, l2: 0.000071, l3: 0.000149, l4: 0.000356, l5: 0.001383, l6: 0.002908

[epoch: 522/1000, batch:  1028/ 1052, ite: 137280] train loss: 0.004115, tar: 0.000083 
[Epoch 522/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000046, l1: 0.000044, l2: 0.000093, l3: 0.000188, l4: 0.000414, l5: 0.000866, l6: 0.001718

[epoch: 523/1000, batch:    56/ 1052, ite: 137300] train loss: 0.004097, tar: 0.000083 
l0: 0.000091, l1: 0.000092, l2: 0.000130, l3: 0.000193, l4: 0.000563, l5: 0.001296, l6: 0.002833

[epoch: 523/1000, batch:   136/ 1052, ite: 137320] train loss: 0.004097, tar: 0.000082 
l0: 0.000020, l1: 0.000020, l2: 0.000049, l3: 0.000102, l4: 0.000286, l5: 0.000924, l6: 0.001522

[epoch: 523/1000, batch:   216/ 1052, ite: 137340] train loss: 0.004076, tar: 0.000082 
l0: 0.000150, l1: 0.000147, l2: 0.000203, l3: 0.000352, l4: 0.000410, l5: 0.000839, l6: 0.002363

[epoch: 523/1000, batch:   296/ 1052, ite: 137360] train loss: 0.004079, tar: 0.000082 
l0: 0.000175, l1: 0.000164, l2: 0.000233, l3: 0.000473, l4: 0.000704, l5: 0.001269, l6: 0.002447

[epoch: 523/1000, batch:   376/ 1052, ite: 137380] train loss: 0.004088, tar: 0.000082 
l0: 0.000036, l1: 0.000036, l2: 0.000077, l3: 0.000200, l4: 0.000666, l5: 0.001021, l6: 0.001690

[epoch: 523/1000, batch:   456/ 1052, ite: 137400] train loss: 0.004090, tar: 0.000082 
l0: 0.000178, l1: 0.000182, l2: 0.000177, l3: 0.000388, l4: 0.000913, l5: 0.001883, l6: 0.003712

[epoch: 523/1000, batch:   536/ 1052, ite: 137420] train loss: 0.004086, tar: 0.000082 
l0: 0.000072, l1: 0.000074, l2: 0.000093, l3: 0.000135, l4: 0.000297, l5: 0.000840, l6: 0.000897

[epoch: 523/1000, batch:   616/ 1052, ite: 137440] train loss: 0.004103, tar: 0.000082 
l0: 0.000089, l1: 0.000090, l2: 0.000113, l3: 0.000152, l4: 0.000484, l5: 0.001056, l6: 0.001730

[epoch: 523/1000, batch:   696/ 1052, ite: 137460] train loss: 0.004104, tar: 0.000083 
l0: 0.000113, l1: 0.000116, l2: 0.000168, l3: 0.000293, l4: 0.000577, l5: 0.001280, l6: 0.002709

[epoch: 523/1000, batch:   776/ 1052, ite: 137480] train loss: 0.004115, tar: 0.000083 
l0: 0.000095, l1: 0.000097, l2: 0.000106, l3: 0.000255, l4: 0.000537, l5: 0.000810, l6: 0.001596

[epoch: 523/1000, batch:   856/ 1052, ite: 137500] train loss: 0.004102, tar: 0.000082 
l0: 0.000096, l1: 0.000102, l2: 0.000157, l3: 0.000430, l4: 0.000642, l5: 0.001432, l6: 0.002238

[epoch: 523/1000, batch:   936/ 1052, ite: 137520] train loss: 0.004112, tar: 0.000082 
l0: 0.000120, l1: 0.000116, l2: 0.000227, l3: 0.000444, l4: 0.000907, l5: 0.001728, l6: 0.004037

[epoch: 523/1000, batch:  1016/ 1052, ite: 137540] train loss: 0.004114, tar: 0.000082 
[Epoch 523/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000154, l1: 0.000156, l2: 0.000211, l3: 0.000380, l4: 0.000642, l5: 0.001236, l6: 0.001905

[epoch: 524/1000, batch:    44/ 1052, ite: 137560] train loss: 0.004111, tar: 0.000083 
l0: 0.000040, l1: 0.000041, l2: 0.000113, l3: 0.000217, l4: 0.000536, l5: 0.000781, l6: 0.001405

[epoch: 524/1000, batch:   124/ 1052, ite: 137580] train loss: 0.004109, tar: 0.000083 
l0: 0.000051, l1: 0.000049, l2: 0.000076, l3: 0.000174, l4: 0.000389, l5: 0.000767, l6: 0.001698

[epoch: 524/1000, batch:   204/ 1052, ite: 137600] train loss: 0.004107, tar: 0.000083 
l0: 0.000109, l1: 0.000112, l2: 0.000145, l3: 0.000219, l4: 0.000368, l5: 0.001137, l6: 0.001269

[epoch: 524/1000, batch:   284/ 1052, ite: 137620] train loss: 0.004099, tar: 0.000082 
l0: 0.000054, l1: 0.000055, l2: 0.000084, l3: 0.000196, l4: 0.000500, l5: 0.001385, l6: 0.002182

[epoch: 524/1000, batch:   364/ 1052, ite: 137640] train loss: 0.004108, tar: 0.000082 
l0: 0.000090, l1: 0.000086, l2: 0.000155, l3: 0.000473, l4: 0.001215, l5: 0.001592, l6: 0.002553

[epoch: 524/1000, batch:   444/ 1052, ite: 137660] train loss: 0.004106, tar: 0.000082 
l0: 0.000100, l1: 0.000097, l2: 0.000150, l3: 0.000194, l4: 0.000391, l5: 0.000810, l6: 0.001423

[epoch: 524/1000, batch:   524/ 1052, ite: 137680] train loss: 0.004097, tar: 0.000082 
l0: 0.000085, l1: 0.000086, l2: 0.000150, l3: 0.000210, l4: 0.000443, l5: 0.001110, l6: 0.001333

[epoch: 524/1000, batch:   604/ 1052, ite: 137700] train loss: 0.004101, tar: 0.000082 
l0: 0.000077, l1: 0.000074, l2: 0.000106, l3: 0.000192, l4: 0.000453, l5: 0.000749, l6: 0.001611

[epoch: 524/1000, batch:   684/ 1052, ite: 137720] train loss: 0.004096, tar: 0.000082 
l0: 0.000085, l1: 0.000086, l2: 0.000130, l3: 0.000241, l4: 0.000602, l5: 0.000925, l6: 0.001915

[epoch: 524/1000, batch:   764/ 1052, ite: 137740] train loss: 0.004102, tar: 0.000082 
l0: 0.000033, l1: 0.000032, l2: 0.000057, l3: 0.000129, l4: 0.000291, l5: 0.000700, l6: 0.001298

[epoch: 524/1000, batch:   844/ 1052, ite: 137760] train loss: 0.004118, tar: 0.000082 
l0: 0.000095, l1: 0.000095, l2: 0.000153, l3: 0.000212, l4: 0.000363, l5: 0.001190, l6: 0.001362

[epoch: 524/1000, batch:   924/ 1052, ite: 137780] train loss: 0.004130, tar: 0.000083 
l0: 0.000016, l1: 0.000016, l2: 0.000035, l3: 0.000080, l4: 0.000307, l5: 0.000669, l6: 0.001333

[epoch: 524/1000, batch:  1004/ 1052, ite: 137800] train loss: 0.004127, tar: 0.000083 
[Epoch 524/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000074, l1: 0.000078, l2: 0.000123, l3: 0.000184, l4: 0.000758, l5: 0.001325, l6: 0.001814

[epoch: 525/1000, batch:    32/ 1052, ite: 137820] train loss: 0.004123, tar: 0.000083 
l0: 0.000122, l1: 0.000123, l2: 0.000140, l3: 0.000190, l4: 0.000416, l5: 0.001021, l6: 0.001598

[epoch: 525/1000, batch:   112/ 1052, ite: 137840] train loss: 0.004122, tar: 0.000083 
l0: 0.000015, l1: 0.000013, l2: 0.000095, l3: 0.000188, l4: 0.000291, l5: 0.000815, l6: 0.001771

[epoch: 525/1000, batch:   192/ 1052, ite: 137860] train loss: 0.004123, tar: 0.000083 
l0: 0.000116, l1: 0.000122, l2: 0.000155, l3: 0.000235, l4: 0.000584, l5: 0.001061, l6: 0.003192

[epoch: 525/1000, batch:   272/ 1052, ite: 137880] train loss: 0.004127, tar: 0.000083 
l0: 0.000054, l1: 0.000053, l2: 0.000107, l3: 0.000301, l4: 0.000539, l5: 0.001339, l6: 0.002013

[epoch: 525/1000, batch:   352/ 1052, ite: 137900] train loss: 0.004129, tar: 0.000083 
l0: 0.000045, l1: 0.000048, l2: 0.000089, l3: 0.000151, l4: 0.000330, l5: 0.000972, l6: 0.001784

[epoch: 525/1000, batch:   432/ 1052, ite: 137920] train loss: 0.004129, tar: 0.000083 
l0: 0.000107, l1: 0.000112, l2: 0.000116, l3: 0.000184, l4: 0.000576, l5: 0.001046, l6: 0.002026

[epoch: 525/1000, batch:   512/ 1052, ite: 137940] train loss: 0.004126, tar: 0.000083 
l0: 0.000059, l1: 0.000060, l2: 0.000093, l3: 0.000222, l4: 0.000604, l5: 0.001229, l6: 0.002144

[epoch: 525/1000, batch:   592/ 1052, ite: 137960] train loss: 0.004134, tar: 0.000083 
l0: 0.000037, l1: 0.000037, l2: 0.000111, l3: 0.000267, l4: 0.000431, l5: 0.001254, l6: 0.002817

[epoch: 525/1000, batch:   672/ 1052, ite: 137980] train loss: 0.004127, tar: 0.000083 
l0: 0.000034, l1: 0.000034, l2: 0.000048, l3: 0.000070, l4: 0.000434, l5: 0.000893, l6: 0.000919

[epoch: 525/1000, batch:   752/ 1052, ite: 138000] train loss: 0.004134, tar: 0.000083 
l0: 0.000129, l1: 0.000130, l2: 0.000186, l3: 0.000296, l4: 0.000568, l5: 0.001435, l6: 0.002774

[epoch: 525/1000, batch:   832/ 1052, ite: 138020] train loss: 0.004135, tar: 0.000083 
l0: 0.000112, l1: 0.000107, l2: 0.000145, l3: 0.000230, l4: 0.000456, l5: 0.000786, l6: 0.001704

[epoch: 525/1000, batch:   912/ 1052, ite: 138040] train loss: 0.004138, tar: 0.000083 
l0: 0.000071, l1: 0.000071, l2: 0.000082, l3: 0.000132, l4: 0.000370, l5: 0.000612, l6: 0.000984

[epoch: 525/1000, batch:   992/ 1052, ite: 138060] train loss: 0.004129, tar: 0.000083 
[Epoch 525/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000124, l1: 0.000121, l2: 0.000179, l3: 0.000194, l4: 0.000338, l5: 0.000797, l6: 0.001689

[epoch: 526/1000, batch:    20/ 1052, ite: 138080] train loss: 0.004131, tar: 0.000083 
l0: 0.000136, l1: 0.000149, l2: 0.000081, l3: 0.000183, l4: 0.000282, l5: 0.000670, l6: 0.001474

[epoch: 526/1000, batch:   100/ 1052, ite: 138100] train loss: 0.004133, tar: 0.000083 
l0: 0.000110, l1: 0.000112, l2: 0.000117, l3: 0.000229, l4: 0.000531, l5: 0.001146, l6: 0.001566

[epoch: 526/1000, batch:   180/ 1052, ite: 138120] train loss: 0.004137, tar: 0.000083 
l0: 0.000091, l1: 0.000093, l2: 0.000163, l3: 0.000260, l4: 0.000626, l5: 0.000973, l6: 0.002101

[epoch: 526/1000, batch:   260/ 1052, ite: 138140] train loss: 0.004131, tar: 0.000082 
l0: 0.000050, l1: 0.000053, l2: 0.000095, l3: 0.000201, l4: 0.000574, l5: 0.000981, l6: 0.002189

[epoch: 526/1000, batch:   340/ 1052, ite: 138160] train loss: 0.004124, tar: 0.000082 
l0: 0.000089, l1: 0.000088, l2: 0.000125, l3: 0.000203, l4: 0.000533, l5: 0.001291, l6: 0.001982

[epoch: 526/1000, batch:   420/ 1052, ite: 138180] train loss: 0.004122, tar: 0.000082 
l0: 0.000176, l1: 0.000177, l2: 0.000190, l3: 0.000237, l4: 0.000513, l5: 0.000618, l6: 0.002173

[epoch: 526/1000, batch:   500/ 1052, ite: 138200] train loss: 0.004124, tar: 0.000082 
l0: 0.000075, l1: 0.000075, l2: 0.000164, l3: 0.000263, l4: 0.000718, l5: 0.001092, l6: 0.001970

[epoch: 526/1000, batch:   580/ 1052, ite: 138220] train loss: 0.004125, tar: 0.000082 
l0: 0.000031, l1: 0.000035, l2: 0.000059, l3: 0.000148, l4: 0.000579, l5: 0.000710, l6: 0.001438

[epoch: 526/1000, batch:   660/ 1052, ite: 138240] train loss: 0.004129, tar: 0.000082 
l0: 0.000117, l1: 0.000123, l2: 0.000142, l3: 0.000255, l4: 0.000378, l5: 0.001402, l6: 0.001397

[epoch: 526/1000, batch:   740/ 1052, ite: 138260] train loss: 0.004124, tar: 0.000082 
l0: 0.000007, l1: 0.000007, l2: 0.000030, l3: 0.000055, l4: 0.000302, l5: 0.000708, l6: 0.001182

[epoch: 526/1000, batch:   820/ 1052, ite: 138280] train loss: 0.004126, tar: 0.000082 
l0: 0.000091, l1: 0.000089, l2: 0.000115, l3: 0.000215, l4: 0.000569, l5: 0.001031, l6: 0.001643

[epoch: 526/1000, batch:   900/ 1052, ite: 138300] train loss: 0.004120, tar: 0.000082 
l0: 0.000107, l1: 0.000110, l2: 0.000163, l3: 0.000384, l4: 0.000536, l5: 0.000746, l6: 0.001312

[epoch: 526/1000, batch:   980/ 1052, ite: 138320] train loss: 0.004129, tar: 0.000082 
[Epoch 526/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000034, l1: 0.000034, l2: 0.000063, l3: 0.000184, l4: 0.000279, l5: 0.000890, l6: 0.001320

[epoch: 527/1000, batch:     8/ 1052, ite: 138340] train loss: 0.004134, tar: 0.000082 
l0: 0.000141, l1: 0.000140, l2: 0.000257, l3: 0.000622, l4: 0.001196, l5: 0.002431, l6: 0.003160

[epoch: 527/1000, batch:    88/ 1052, ite: 138360] train loss: 0.004131, tar: 0.000082 
l0: 0.000093, l1: 0.000101, l2: 0.000128, l3: 0.000342, l4: 0.000642, l5: 0.001533, l6: 0.002429

[epoch: 527/1000, batch:   168/ 1052, ite: 138380] train loss: 0.004127, tar: 0.000081 
l0: 0.000055, l1: 0.000059, l2: 0.000078, l3: 0.000177, l4: 0.000469, l5: 0.000872, l6: 0.002219

[epoch: 527/1000, batch:   248/ 1052, ite: 138400] train loss: 0.004126, tar: 0.000081 
l0: 0.000097, l1: 0.000098, l2: 0.000147, l3: 0.000236, l4: 0.000381, l5: 0.000955, l6: 0.002462

[epoch: 527/1000, batch:   328/ 1052, ite: 138420] train loss: 0.004125, tar: 0.000081 
l0: 0.000044, l1: 0.000045, l2: 0.000094, l3: 0.000148, l4: 0.000382, l5: 0.000972, l6: 0.001253

[epoch: 527/1000, batch:   408/ 1052, ite: 138440] train loss: 0.004129, tar: 0.000081 
l0: 0.000044, l1: 0.000044, l2: 0.000083, l3: 0.000176, l4: 0.000262, l5: 0.001557, l6: 0.002180

[epoch: 527/1000, batch:   488/ 1052, ite: 138460] train loss: 0.004134, tar: 0.000082 
l0: 0.000067, l1: 0.000070, l2: 0.000124, l3: 0.000238, l4: 0.000470, l5: 0.000980, l6: 0.002737

[epoch: 527/1000, batch:   568/ 1052, ite: 138480] train loss: 0.004139, tar: 0.000082 
l0: 0.000054, l1: 0.000055, l2: 0.000112, l3: 0.000219, l4: 0.000582, l5: 0.001049, l6: 0.002402

[epoch: 527/1000, batch:   648/ 1052, ite: 138500] train loss: 0.004138, tar: 0.000082 
l0: 0.000077, l1: 0.000079, l2: 0.000116, l3: 0.000202, l4: 0.000706, l5: 0.001602, l6: 0.002931

[epoch: 527/1000, batch:   728/ 1052, ite: 138520] train loss: 0.004136, tar: 0.000082 
l0: 0.000122, l1: 0.000118, l2: 0.000222, l3: 0.000335, l4: 0.000686, l5: 0.001214, l6: 0.003278

[epoch: 527/1000, batch:   808/ 1052, ite: 138540] train loss: 0.004129, tar: 0.000081 
l0: 0.000130, l1: 0.000132, l2: 0.000210, l3: 0.000390, l4: 0.000959, l5: 0.003300, l6: 0.005301

[epoch: 527/1000, batch:   888/ 1052, ite: 138560] train loss: 0.004132, tar: 0.000081 
l0: 0.000023, l1: 0.000024, l2: 0.000114, l3: 0.000169, l4: 0.000358, l5: 0.000957, l6: 0.001517

[epoch: 527/1000, batch:   968/ 1052, ite: 138580] train loss: 0.004131, tar: 0.000081 
l0: 0.000061, l1: 0.000061, l2: 0.000084, l3: 0.000169, l4: 0.000403, l5: 0.001208, l6: 0.001426

[epoch: 527/1000, batch:  1048/ 1052, ite: 138600] train loss: 0.004132, tar: 0.000081 
[Epoch 527/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000074, l1: 0.000074, l2: 0.000186, l3: 0.000437, l4: 0.000637, l5: 0.001255, l6: 0.001477

[epoch: 528/1000, batch:    76/ 1052, ite: 138620] train loss: 0.004139, tar: 0.000082 
l0: 0.000033, l1: 0.000031, l2: 0.000058, l3: 0.000121, l4: 0.000445, l5: 0.000932, l6: 0.001510

[epoch: 528/1000, batch:   156/ 1052, ite: 138640] train loss: 0.004136, tar: 0.000081 
l0: 0.000047, l1: 0.000050, l2: 0.000061, l3: 0.000212, l4: 0.000394, l5: 0.000859, l6: 0.001155

[epoch: 528/1000, batch:   236/ 1052, ite: 138660] train loss: 0.004135, tar: 0.000081 
l0: 0.000053, l1: 0.000054, l2: 0.000099, l3: 0.000246, l4: 0.000472, l5: 0.001439, l6: 0.002662

[epoch: 528/1000, batch:   316/ 1052, ite: 138680] train loss: 0.004132, tar: 0.000081 
l0: 0.000047, l1: 0.000044, l2: 0.000124, l3: 0.000338, l4: 0.000462, l5: 0.001091, l6: 0.001419

[epoch: 528/1000, batch:   396/ 1052, ite: 138700] train loss: 0.004134, tar: 0.000081 
l0: 0.000030, l1: 0.000031, l2: 0.000039, l3: 0.000089, l4: 0.000282, l5: 0.000749, l6: 0.000981

[epoch: 528/1000, batch:   476/ 1052, ite: 138720] train loss: 0.004134, tar: 0.000081 
l0: 0.000121, l1: 0.000132, l2: 0.000165, l3: 0.000189, l4: 0.000452, l5: 0.000928, l6: 0.001714

[epoch: 528/1000, batch:   556/ 1052, ite: 138740] train loss: 0.004138, tar: 0.000081 
l0: 0.000158, l1: 0.000162, l2: 0.000206, l3: 0.000453, l4: 0.001289, l5: 0.002661, l6: 0.002941

[epoch: 528/1000, batch:   636/ 1052, ite: 138760] train loss: 0.004138, tar: 0.000081 
l0: 0.000157, l1: 0.000161, l2: 0.000172, l3: 0.000275, l4: 0.000565, l5: 0.001205, l6: 0.001473

[epoch: 528/1000, batch:   716/ 1052, ite: 138780] train loss: 0.004140, tar: 0.000081 
l0: 0.000063, l1: 0.000064, l2: 0.000119, l3: 0.000262, l4: 0.000430, l5: 0.000890, l6: 0.001082

[epoch: 528/1000, batch:   796/ 1052, ite: 138800] train loss: 0.004133, tar: 0.000081 
l0: 0.000007, l1: 0.000006, l2: 0.000023, l3: 0.000083, l4: 0.000221, l5: 0.000496, l6: 0.000714

[epoch: 528/1000, batch:   876/ 1052, ite: 138820] train loss: 0.004130, tar: 0.000081 
l0: 0.000078, l1: 0.000083, l2: 0.000135, l3: 0.000293, l4: 0.000616, l5: 0.001636, l6: 0.003164

[epoch: 528/1000, batch:   956/ 1052, ite: 138840] train loss: 0.004132, tar: 0.000081 
l0: 0.000080, l1: 0.000082, l2: 0.000117, l3: 0.000191, l4: 0.000485, l5: 0.001195, l6: 0.001868

[epoch: 528/1000, batch:  1036/ 1052, ite: 138860] train loss: 0.004136, tar: 0.000081 
[Epoch 528/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000046, l1: 0.000047, l2: 0.000072, l3: 0.000137, l4: 0.000399, l5: 0.001084, l6: 0.001433

[epoch: 529/1000, batch:    64/ 1052, ite: 138880] train loss: 0.004135, tar: 0.000081 
l0: 0.000162, l1: 0.000168, l2: 0.000196, l3: 0.000280, l4: 0.000665, l5: 0.001402, l6: 0.003245

[epoch: 529/1000, batch:   144/ 1052, ite: 138900] train loss: 0.004137, tar: 0.000081 
l0: 0.000051, l1: 0.000050, l2: 0.000124, l3: 0.000266, l4: 0.000602, l5: 0.001164, l6: 0.002547

[epoch: 529/1000, batch:   224/ 1052, ite: 138920] train loss: 0.004135, tar: 0.000081 
l0: 0.000115, l1: 0.000120, l2: 0.000244, l3: 0.000448, l4: 0.000994, l5: 0.001839, l6: 0.003192

[epoch: 529/1000, batch:   304/ 1052, ite: 138940] train loss: 0.004136, tar: 0.000081 
l0: 0.000031, l1: 0.000030, l2: 0.000053, l3: 0.000083, l4: 0.000315, l5: 0.000763, l6: 0.000795

[epoch: 529/1000, batch:   384/ 1052, ite: 138960] train loss: 0.004135, tar: 0.000081 
l0: 0.000059, l1: 0.000060, l2: 0.000099, l3: 0.000147, l4: 0.000341, l5: 0.000656, l6: 0.001765

[epoch: 529/1000, batch:   464/ 1052, ite: 138980] train loss: 0.004130, tar: 0.000081 
l0: 0.000053, l1: 0.000051, l2: 0.000095, l3: 0.000153, l4: 0.000366, l5: 0.000645, l6: 0.001869

[epoch: 529/1000, batch:   544/ 1052, ite: 139000] train loss: 0.004133, tar: 0.000081 
l0: 0.000042, l1: 0.000040, l2: 0.000085, l3: 0.000182, l4: 0.000227, l5: 0.000668, l6: 0.001558

[epoch: 529/1000, batch:   624/ 1052, ite: 139020] train loss: 0.004130, tar: 0.000081 
l0: 0.000038, l1: 0.000039, l2: 0.000059, l3: 0.000113, l4: 0.000429, l5: 0.000900, l6: 0.001307

[epoch: 529/1000, batch:   704/ 1052, ite: 139040] train loss: 0.004131, tar: 0.000081 
l0: 0.000147, l1: 0.000146, l2: 0.000213, l3: 0.000377, l4: 0.000597, l5: 0.001474, l6: 0.003498

[epoch: 529/1000, batch:   784/ 1052, ite: 139060] train loss: 0.004137, tar: 0.000081 
l0: 0.000137, l1: 0.000138, l2: 0.000181, l3: 0.000275, l4: 0.000566, l5: 0.001608, l6: 0.001816

[epoch: 529/1000, batch:   864/ 1052, ite: 139080] train loss: 0.004133, tar: 0.000081 
l0: 0.000057, l1: 0.000060, l2: 0.000098, l3: 0.000185, l4: 0.000494, l5: 0.000940, l6: 0.001259

[epoch: 529/1000, batch:   944/ 1052, ite: 139100] train loss: 0.004135, tar: 0.000081 
l0: 0.000116, l1: 0.000118, l2: 0.000170, l3: 0.000254, l4: 0.000446, l5: 0.001398, l6: 0.001680

[epoch: 529/1000, batch:  1024/ 1052, ite: 139120] train loss: 0.004136, tar: 0.000081 
[Epoch 529/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000064, l1: 0.000065, l2: 0.000086, l3: 0.000196, l4: 0.000344, l5: 0.000596, l6: 0.001080

[epoch: 530/1000, batch:    52/ 1052, ite: 139140] train loss: 0.004139, tar: 0.000081 
l0: 0.000032, l1: 0.000031, l2: 0.000067, l3: 0.000133, l4: 0.000433, l5: 0.001219, l6: 0.001904

[epoch: 530/1000, batch:   132/ 1052, ite: 139160] train loss: 0.004144, tar: 0.000081 
l0: 0.000138, l1: 0.000138, l2: 0.000205, l3: 0.000395, l4: 0.000767, l5: 0.003313, l6: 0.005112

[epoch: 530/1000, batch:   212/ 1052, ite: 139180] train loss: 0.004143, tar: 0.000081 
l0: 0.000218, l1: 0.000215, l2: 0.000319, l3: 0.000513, l4: 0.000903, l5: 0.001714, l6: 0.003257

[epoch: 530/1000, batch:   292/ 1052, ite: 139200] train loss: 0.004142, tar: 0.000081 
l0: 0.000107, l1: 0.000107, l2: 0.000134, l3: 0.000439, l4: 0.000752, l5: 0.001172, l6: 0.001920

[epoch: 530/1000, batch:   372/ 1052, ite: 139220] train loss: 0.004139, tar: 0.000081 
l0: 0.000049, l1: 0.000052, l2: 0.000061, l3: 0.000149, l4: 0.000573, l5: 0.001330, l6: 0.001606

[epoch: 530/1000, batch:   452/ 1052, ite: 139240] train loss: 0.004142, tar: 0.000081 
l0: 0.000069, l1: 0.000068, l2: 0.000110, l3: 0.000207, l4: 0.000402, l5: 0.001089, l6: 0.001966

[epoch: 530/1000, batch:   532/ 1052, ite: 139260] train loss: 0.004143, tar: 0.000081 
l0: 0.000082, l1: 0.000082, l2: 0.000105, l3: 0.000134, l4: 0.000356, l5: 0.001041, l6: 0.001538

[epoch: 530/1000, batch:   612/ 1052, ite: 139280] train loss: 0.004140, tar: 0.000081 
l0: 0.000059, l1: 0.000057, l2: 0.000097, l3: 0.000130, l4: 0.000394, l5: 0.000631, l6: 0.001454

[epoch: 530/1000, batch:   692/ 1052, ite: 139300] train loss: 0.004140, tar: 0.000081 
l0: 0.000086, l1: 0.000083, l2: 0.000116, l3: 0.000228, l4: 0.000823, l5: 0.001517, l6: 0.002092

[epoch: 530/1000, batch:   772/ 1052, ite: 139320] train loss: 0.004141, tar: 0.000081 
l0: 0.000069, l1: 0.000070, l2: 0.000104, l3: 0.000198, l4: 0.000455, l5: 0.001062, l6: 0.001251

[epoch: 530/1000, batch:   852/ 1052, ite: 139340] train loss: 0.004138, tar: 0.000081 
l0: 0.000023, l1: 0.000023, l2: 0.000032, l3: 0.000068, l4: 0.000254, l5: 0.000350, l6: 0.000801

[epoch: 530/1000, batch:   932/ 1052, ite: 139360] train loss: 0.004138, tar: 0.000081 
l0: 0.000133, l1: 0.000140, l2: 0.000193, l3: 0.000345, l4: 0.000674, l5: 0.002727, l6: 0.002734

[epoch: 530/1000, batch:  1012/ 1052, ite: 139380] train loss: 0.004141, tar: 0.000081 
[Epoch 530/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000227, l1: 0.000229, l2: 0.000289, l3: 0.000507, l4: 0.000756, l5: 0.002159, l6: 0.002668

[epoch: 531/1000, batch:    40/ 1052, ite: 139400] train loss: 0.004147, tar: 0.000081 
l0: 0.000073, l1: 0.000071, l2: 0.000134, l3: 0.000280, l4: 0.000502, l5: 0.001263, l6: 0.002221

[epoch: 531/1000, batch:   120/ 1052, ite: 139420] train loss: 0.004151, tar: 0.000081 
l0: 0.000051, l1: 0.000050, l2: 0.000125, l3: 0.000288, l4: 0.000666, l5: 0.001265, l6: 0.001229

[epoch: 531/1000, batch:   200/ 1052, ite: 139440] train loss: 0.004148, tar: 0.000081 
l0: 0.000063, l1: 0.000062, l2: 0.000117, l3: 0.000249, l4: 0.000583, l5: 0.001206, l6: 0.002455

[epoch: 531/1000, batch:   280/ 1052, ite: 139460] train loss: 0.004145, tar: 0.000081 
l0: 0.000064, l1: 0.000072, l2: 0.000081, l3: 0.000145, l4: 0.000298, l5: 0.000522, l6: 0.001575

[epoch: 531/1000, batch:   360/ 1052, ite: 139480] train loss: 0.004143, tar: 0.000081 
l0: 0.000122, l1: 0.000126, l2: 0.000178, l3: 0.000262, l4: 0.000642, l5: 0.001326, l6: 0.002797

[epoch: 531/1000, batch:   440/ 1052, ite: 139500] train loss: 0.004145, tar: 0.000081 
l0: 0.000129, l1: 0.000132, l2: 0.000156, l3: 0.000276, l4: 0.000484, l5: 0.000765, l6: 0.002056

[epoch: 531/1000, batch:   520/ 1052, ite: 139520] train loss: 0.004142, tar: 0.000081 
l0: 0.000058, l1: 0.000057, l2: 0.000089, l3: 0.000138, l4: 0.000354, l5: 0.000780, l6: 0.000761

[epoch: 531/1000, batch:   600/ 1052, ite: 139540] train loss: 0.004139, tar: 0.000081 
l0: 0.000032, l1: 0.000033, l2: 0.000060, l3: 0.000098, l4: 0.000238, l5: 0.001202, l6: 0.001638

[epoch: 531/1000, batch:   680/ 1052, ite: 139560] train loss: 0.004138, tar: 0.000081 
l0: 0.000073, l1: 0.000074, l2: 0.000075, l3: 0.000131, l4: 0.000409, l5: 0.001205, l6: 0.002170

[epoch: 531/1000, batch:   760/ 1052, ite: 139580] train loss: 0.004134, tar: 0.000081 
l0: 0.000067, l1: 0.000064, l2: 0.000165, l3: 0.000426, l4: 0.000811, l5: 0.002014, l6: 0.003215

[epoch: 531/1000, batch:   840/ 1052, ite: 139600] train loss: 0.004136, tar: 0.000081 
l0: 0.000051, l1: 0.000052, l2: 0.000127, l3: 0.000249, l4: 0.000417, l5: 0.001558, l6: 0.001703

[epoch: 531/1000, batch:   920/ 1052, ite: 139620] train loss: 0.004139, tar: 0.000081 
l0: 0.000046, l1: 0.000050, l2: 0.000080, l3: 0.000147, l4: 0.000350, l5: 0.001021, l6: 0.001195

[epoch: 531/1000, batch:  1000/ 1052, ite: 139640] train loss: 0.004139, tar: 0.000081 
[Epoch 531/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000062, l1: 0.000061, l2: 0.000108, l3: 0.000282, l4: 0.000562, l5: 0.001250, l6: 0.001361

[epoch: 532/1000, batch:    28/ 1052, ite: 139660] train loss: 0.004139, tar: 0.000081 
l0: 0.000050, l1: 0.000047, l2: 0.000078, l3: 0.000158, l4: 0.000270, l5: 0.000658, l6: 0.001081

[epoch: 532/1000, batch:   108/ 1052, ite: 139680] train loss: 0.004138, tar: 0.000081 
l0: 0.000047, l1: 0.000050, l2: 0.000101, l3: 0.000178, l4: 0.000362, l5: 0.001384, l6: 0.002621

[epoch: 532/1000, batch:   188/ 1052, ite: 139700] train loss: 0.004134, tar: 0.000080 
l0: 0.000079, l1: 0.000074, l2: 0.000121, l3: 0.000222, l4: 0.000388, l5: 0.001087, l6: 0.001735

[epoch: 532/1000, batch:   268/ 1052, ite: 139720] train loss: 0.004134, tar: 0.000080 
l0: 0.000029, l1: 0.000031, l2: 0.000094, l3: 0.000196, l4: 0.000511, l5: 0.001215, l6: 0.002125

[epoch: 532/1000, batch:   348/ 1052, ite: 139740] train loss: 0.004134, tar: 0.000080 
l0: 0.000076, l1: 0.000079, l2: 0.000144, l3: 0.000274, l4: 0.000657, l5: 0.001369, l6: 0.001517

[epoch: 532/1000, batch:   428/ 1052, ite: 139760] train loss: 0.004136, tar: 0.000080 
l0: 0.000050, l1: 0.000053, l2: 0.000046, l3: 0.000098, l4: 0.000299, l5: 0.001059, l6: 0.000981

[epoch: 532/1000, batch:   508/ 1052, ite: 139780] train loss: 0.004135, tar: 0.000080 
l0: 0.000106, l1: 0.000108, l2: 0.000146, l3: 0.000347, l4: 0.000641, l5: 0.001434, l6: 0.002296

[epoch: 532/1000, batch:   588/ 1052, ite: 139800] train loss: 0.004137, tar: 0.000080 
l0: 0.000095, l1: 0.000099, l2: 0.000099, l3: 0.000145, l4: 0.000382, l5: 0.001031, l6: 0.002706

[epoch: 532/1000, batch:   668/ 1052, ite: 139820] train loss: 0.004138, tar: 0.000080 
l0: 0.000050, l1: 0.000052, l2: 0.000065, l3: 0.000148, l4: 0.000257, l5: 0.000647, l6: 0.000975

[epoch: 532/1000, batch:   748/ 1052, ite: 139840] train loss: 0.004137, tar: 0.000080 
l0: 0.000036, l1: 0.000036, l2: 0.000062, l3: 0.000112, l4: 0.000479, l5: 0.000547, l6: 0.001202

[epoch: 532/1000, batch:   828/ 1052, ite: 139860] train loss: 0.004131, tar: 0.000080 
l0: 0.000151, l1: 0.000152, l2: 0.000193, l3: 0.000333, l4: 0.000623, l5: 0.001474, l6: 0.002814

[epoch: 532/1000, batch:   908/ 1052, ite: 139880] train loss: 0.004136, tar: 0.000080 
l0: 0.000146, l1: 0.000157, l2: 0.000170, l3: 0.000261, l4: 0.000370, l5: 0.001041, l6: 0.001781

[epoch: 532/1000, batch:   988/ 1052, ite: 139900] train loss: 0.004136, tar: 0.000080 
[Epoch 532/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000078, l1: 0.000077, l2: 0.000121, l3: 0.000185, l4: 0.000455, l5: 0.001004, l6: 0.001779

[epoch: 533/1000, batch:    16/ 1052, ite: 139920] train loss: 0.004139, tar: 0.000080 
l0: 0.000072, l1: 0.000076, l2: 0.000081, l3: 0.000186, l4: 0.000582, l5: 0.001261, l6: 0.002239

[epoch: 533/1000, batch:    96/ 1052, ite: 139940] train loss: 0.004142, tar: 0.000080 
l0: 0.000023, l1: 0.000024, l2: 0.000033, l3: 0.000061, l4: 0.000256, l5: 0.000740, l6: 0.000550

[epoch: 533/1000, batch:   176/ 1052, ite: 139960] train loss: 0.004139, tar: 0.000080 
l0: 0.000053, l1: 0.000053, l2: 0.000121, l3: 0.000260, l4: 0.000724, l5: 0.001469, l6: 0.002376

[epoch: 533/1000, batch:   256/ 1052, ite: 139980] train loss: 0.004142, tar: 0.000081 
l0: 0.000085, l1: 0.000089, l2: 0.000128, l3: 0.000185, l4: 0.000370, l5: 0.000860, l6: 0.002532

[epoch: 533/1000, batch:   336/ 1052, ite: 140000] train loss: 0.004144, tar: 0.000081 
l0: 0.000043, l1: 0.000044, l2: 0.000063, l3: 0.000215, l4: 0.000451, l5: 0.000808, l6: 0.001540

[epoch: 533/1000, batch:   416/ 1052, ite: 140020] train loss: 0.004145, tar: 0.000081 
l0: 0.000138, l1: 0.000143, l2: 0.000194, l3: 0.000343, l4: 0.000988, l5: 0.002339, l6: 0.003604

[epoch: 533/1000, batch:   496/ 1052, ite: 140040] train loss: 0.004145, tar: 0.000080 
l0: 0.000191, l1: 0.000190, l2: 0.000242, l3: 0.000309, l4: 0.000692, l5: 0.001319, l6: 0.001785

[epoch: 533/1000, batch:   576/ 1052, ite: 140060] train loss: 0.004145, tar: 0.000080 
l0: 0.000034, l1: 0.000035, l2: 0.000037, l3: 0.000105, l4: 0.000277, l5: 0.000682, l6: 0.001346

[epoch: 533/1000, batch:   656/ 1052, ite: 140080] train loss: 0.004145, tar: 0.000080 
l0: 0.000092, l1: 0.000090, l2: 0.000108, l3: 0.000243, l4: 0.000464, l5: 0.000662, l6: 0.000901

[epoch: 533/1000, batch:   736/ 1052, ite: 140100] train loss: 0.004143, tar: 0.000080 
l0: 0.000096, l1: 0.000098, l2: 0.000127, l3: 0.000240, l4: 0.000431, l5: 0.001285, l6: 0.002150

[epoch: 533/1000, batch:   816/ 1052, ite: 140120] train loss: 0.004144, tar: 0.000080 
l0: 0.000214, l1: 0.000213, l2: 0.000268, l3: 0.000442, l4: 0.000783, l5: 0.001487, l6: 0.002923

[epoch: 533/1000, batch:   896/ 1052, ite: 140140] train loss: 0.004147, tar: 0.000081 
l0: 0.000046, l1: 0.000049, l2: 0.000072, l3: 0.000366, l4: 0.000627, l5: 0.000903, l6: 0.001551

[epoch: 533/1000, batch:   976/ 1052, ite: 140160] train loss: 0.004146, tar: 0.000081 
[Epoch 533/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000118, l1: 0.000119, l2: 0.000165, l3: 0.000199, l4: 0.000340, l5: 0.000616, l6: 0.001787

[epoch: 534/1000, batch:     4/ 1052, ite: 140180] train loss: 0.004142, tar: 0.000080 
l0: 0.000258, l1: 0.000261, l2: 0.000290, l3: 0.000369, l4: 0.000632, l5: 0.001577, l6: 0.001785

[epoch: 534/1000, batch:    84/ 1052, ite: 140200] train loss: 0.004144, tar: 0.000081 
l0: 0.000129, l1: 0.000133, l2: 0.000147, l3: 0.000187, l4: 0.000310, l5: 0.000835, l6: 0.001912

[epoch: 534/1000, batch:   164/ 1052, ite: 140220] train loss: 0.004144, tar: 0.000081 
l0: 0.000087, l1: 0.000089, l2: 0.000142, l3: 0.000242, l4: 0.000516, l5: 0.001102, l6: 0.003821

[epoch: 534/1000, batch:   244/ 1052, ite: 140240] train loss: 0.004144, tar: 0.000081 
l0: 0.000031, l1: 0.000031, l2: 0.000068, l3: 0.000102, l4: 0.000331, l5: 0.000834, l6: 0.000884

[epoch: 534/1000, batch:   324/ 1052, ite: 140260] train loss: 0.004141, tar: 0.000080 
l0: 0.000026, l1: 0.000026, l2: 0.000054, l3: 0.000115, l4: 0.000198, l5: 0.000864, l6: 0.000813

[epoch: 534/1000, batch:   404/ 1052, ite: 140280] train loss: 0.004141, tar: 0.000080 
l0: 0.000115, l1: 0.000117, l2: 0.000213, l3: 0.000413, l4: 0.001041, l5: 0.002103, l6: 0.003321

[epoch: 534/1000, batch:   484/ 1052, ite: 140300] train loss: 0.004145, tar: 0.000081 
l0: 0.001594, l1: 0.001705, l2: 0.001957, l3: 0.001042, l4: 0.000851, l5: 0.001892, l6: 0.004070

[epoch: 534/1000, batch:   564/ 1052, ite: 140320] train loss: 0.004152, tar: 0.000081 
l0: 0.000479, l1: 0.000503, l2: 0.000593, l3: 0.000785, l4: 0.001220, l5: 0.002846, l6: 0.003757

[epoch: 534/1000, batch:   644/ 1052, ite: 140340] train loss: 0.004161, tar: 0.000083 
l0: 0.000498, l1: 0.000889, l2: 0.000660, l3: 0.000562, l4: 0.000679, l5: 0.001265, l6: 0.001829

[epoch: 534/1000, batch:   724/ 1052, ite: 140360] train loss: 0.004174, tar: 0.000086 
l0: 0.000428, l1: 0.000469, l2: 0.000454, l3: 0.000511, l4: 0.000551, l5: 0.001153, l6: 0.003047

[epoch: 534/1000, batch:   804/ 1052, ite: 140380] train loss: 0.004189, tar: 0.000088 
l0: 0.000198, l1: 0.000204, l2: 0.000223, l3: 0.000286, l4: 0.000473, l5: 0.000659, l6: 0.001414

[epoch: 534/1000, batch:   884/ 1052, ite: 140400] train loss: 0.004194, tar: 0.000089 
l0: 0.000347, l1: 0.000331, l2: 0.000369, l3: 0.000361, l4: 0.000796, l5: 0.001356, l6: 0.001691

[epoch: 534/1000, batch:   964/ 1052, ite: 140420] train loss: 0.004217, tar: 0.000094 
l0: 0.000448, l1: 0.000612, l2: 0.000566, l3: 0.000846, l4: 0.000871, l5: 0.001214, l6: 0.002104

[epoch: 534/1000, batch:  1044/ 1052, ite: 140440] train loss: 0.004231, tar: 0.000096 
[Epoch 534/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000676, l1: 0.001076, l2: 0.000950, l3: 0.000588, l4: 0.000362, l5: 0.000830, l6: 0.001392

[epoch: 535/1000, batch:    72/ 1052, ite: 140460] train loss: 0.004243, tar: 0.000098 
l0: 0.000337, l1: 0.000380, l2: 0.000406, l3: 0.000325, l4: 0.000435, l5: 0.000995, l6: 0.001546

[epoch: 535/1000, batch:   152/ 1052, ite: 140480] train loss: 0.004251, tar: 0.000100 
l0: 0.000148, l1: 0.000147, l2: 0.000149, l3: 0.000190, l4: 0.000281, l5: 0.000715, l6: 0.001291

[epoch: 535/1000, batch:   232/ 1052, ite: 140500] train loss: 0.004259, tar: 0.000101 
l0: 0.000374, l1: 0.000428, l2: 0.000444, l3: 0.000458, l4: 0.000912, l5: 0.001932, l6: 0.002824

[epoch: 535/1000, batch:   312/ 1052, ite: 140520] train loss: 0.004267, tar: 0.000102 
l0: 0.000151, l1: 0.000144, l2: 0.000154, l3: 0.000208, l4: 0.000386, l5: 0.001195, l6: 0.002095

[epoch: 535/1000, batch:   392/ 1052, ite: 140540] train loss: 0.004274, tar: 0.000103 
l0: 0.000139, l1: 0.000168, l2: 0.000138, l3: 0.000160, l4: 0.000310, l5: 0.001181, l6: 0.001844

[epoch: 535/1000, batch:   472/ 1052, ite: 140560] train loss: 0.004278, tar: 0.000104 
l0: 0.000144, l1: 0.000148, l2: 0.000158, l3: 0.000259, l4: 0.000436, l5: 0.001093, l6: 0.001994

[epoch: 535/1000, batch:   552/ 1052, ite: 140580] train loss: 0.004279, tar: 0.000104 
l0: 0.000118, l1: 0.000105, l2: 0.000115, l3: 0.000213, l4: 0.000290, l5: 0.000755, l6: 0.001535

[epoch: 535/1000, batch:   632/ 1052, ite: 140600] train loss: 0.004277, tar: 0.000105 
l0: 0.000239, l1: 0.000223, l2: 0.000271, l3: 0.000425, l4: 0.000758, l5: 0.001230, l6: 0.003331

[epoch: 535/1000, batch:   712/ 1052, ite: 140620] train loss: 0.004280, tar: 0.000105 
l0: 0.000168, l1: 0.000151, l2: 0.000189, l3: 0.000469, l4: 0.000955, l5: 0.002075, l6: 0.002033

[epoch: 535/1000, batch:   792/ 1052, ite: 140640] train loss: 0.004285, tar: 0.000106 
l0: 0.000104, l1: 0.000100, l2: 0.000114, l3: 0.000153, l4: 0.000499, l5: 0.000864, l6: 0.002090

[epoch: 535/1000, batch:   872/ 1052, ite: 140660] train loss: 0.004287, tar: 0.000107 
l0: 0.000097, l1: 0.000091, l2: 0.000133, l3: 0.000264, l4: 0.000546, l5: 0.001315, l6: 0.001359

[epoch: 535/1000, batch:   952/ 1052, ite: 140680] train loss: 0.004292, tar: 0.000107 
l0: 0.000221, l1: 0.000216, l2: 0.000304, l3: 0.000295, l4: 0.000633, l5: 0.000992, l6: 0.001995

[epoch: 535/1000, batch:  1032/ 1052, ite: 140700] train loss: 0.004292, tar: 0.000108 
[Epoch 535/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000051, l1: 0.000052, l2: 0.000057, l3: 0.000098, l4: 0.000213, l5: 0.000749, l6: 0.001019

[epoch: 536/1000, batch:    60/ 1052, ite: 140720] train loss: 0.004295, tar: 0.000108 
l0: 0.000135, l1: 0.000136, l2: 0.000130, l3: 0.000215, l4: 0.000457, l5: 0.000798, l6: 0.001472

[epoch: 536/1000, batch:   140/ 1052, ite: 140740] train loss: 0.004292, tar: 0.000108 
l0: 0.000208, l1: 0.000192, l2: 0.000244, l3: 0.000297, l4: 0.000562, l5: 0.001139, l6: 0.002214

[epoch: 536/1000, batch:   220/ 1052, ite: 140760] train loss: 0.004294, tar: 0.000109 
l0: 0.000047, l1: 0.000044, l2: 0.000057, l3: 0.000110, l4: 0.000280, l5: 0.000632, l6: 0.000612

[epoch: 536/1000, batch:   300/ 1052, ite: 140780] train loss: 0.004294, tar: 0.000109 
l0: 0.000189, l1: 0.000201, l2: 0.000197, l3: 0.000259, l4: 0.000532, l5: 0.001429, l6: 0.003211

[epoch: 536/1000, batch:   380/ 1052, ite: 140800] train loss: 0.004296, tar: 0.000109 
l0: 0.000270, l1: 0.000274, l2: 0.000269, l3: 0.000404, l4: 0.000819, l5: 0.001402, l6: 0.001989

[epoch: 536/1000, batch:   460/ 1052, ite: 140820] train loss: 0.004301, tar: 0.000110 
l0: 0.000108, l1: 0.000113, l2: 0.000134, l3: 0.000159, l4: 0.000393, l5: 0.000808, l6: 0.001188

[epoch: 536/1000, batch:   540/ 1052, ite: 140840] train loss: 0.004301, tar: 0.000110 
l0: 0.000093, l1: 0.000094, l2: 0.000110, l3: 0.000166, l4: 0.000325, l5: 0.000546, l6: 0.001158

[epoch: 536/1000, batch:   620/ 1052, ite: 140860] train loss: 0.004302, tar: 0.000110 
l0: 0.000147, l1: 0.000181, l2: 0.000163, l3: 0.000213, l4: 0.000477, l5: 0.001084, l6: 0.001461

[epoch: 536/1000, batch:   700/ 1052, ite: 140880] train loss: 0.004304, tar: 0.000110 
l0: 0.000185, l1: 0.000162, l2: 0.000209, l3: 0.000508, l4: 0.001078, l5: 0.002013, l6: 0.003303

[epoch: 536/1000, batch:   780/ 1052, ite: 140900] train loss: 0.004308, tar: 0.000110 
l0: 0.000047, l1: 0.000049, l2: 0.000073, l3: 0.000148, l4: 0.000273, l5: 0.000808, l6: 0.000892

[epoch: 536/1000, batch:   860/ 1052, ite: 140920] train loss: 0.004309, tar: 0.000111 
l0: 0.000107, l1: 0.000096, l2: 0.000159, l3: 0.000264, l4: 0.000598, l5: 0.001511, l6: 0.002227

[epoch: 536/1000, batch:   940/ 1052, ite: 140940] train loss: 0.004307, tar: 0.000111 
l0: 0.000089, l1: 0.000077, l2: 0.000144, l3: 0.000266, l4: 0.000709, l5: 0.001193, l6: 0.001880

[epoch: 536/1000, batch:  1020/ 1052, ite: 140960] train loss: 0.004306, tar: 0.000111 
[Epoch 536/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000176, l1: 0.000158, l2: 0.000132, l3: 0.000217, l4: 0.000309, l5: 0.000955, l6: 0.000921

[epoch: 537/1000, batch:    48/ 1052, ite: 140980] train loss: 0.004307, tar: 0.000111 
l0: 0.000051, l1: 0.000055, l2: 0.000075, l3: 0.000137, l4: 0.000330, l5: 0.001101, l6: 0.001667

[epoch: 537/1000, batch:   128/ 1052, ite: 141000] train loss: 0.004305, tar: 0.000111 
l0: 0.000055, l1: 0.000049, l2: 0.000087, l3: 0.000146, l4: 0.000435, l5: 0.000972, l6: 0.001272

[epoch: 537/1000, batch:   208/ 1052, ite: 141020] train loss: 0.004304, tar: 0.000111 
l0: 0.000087, l1: 0.000088, l2: 0.000110, l3: 0.000170, l4: 0.000359, l5: 0.001146, l6: 0.001018

[epoch: 537/1000, batch:   288/ 1052, ite: 141040] train loss: 0.004307, tar: 0.000111 
l0: 0.000183, l1: 0.000199, l2: 0.000278, l3: 0.000318, l4: 0.000614, l5: 0.000699, l6: 0.001553

[epoch: 537/1000, batch:   368/ 1052, ite: 141060] train loss: 0.004307, tar: 0.000111 
l0: 0.000112, l1: 0.000106, l2: 0.000122, l3: 0.000276, l4: 0.000634, l5: 0.001497, l6: 0.002905

[epoch: 537/1000, batch:   448/ 1052, ite: 141080] train loss: 0.004306, tar: 0.000111 
l0: 0.000163, l1: 0.000178, l2: 0.000177, l3: 0.000290, l4: 0.000447, l5: 0.001020, l6: 0.001146

[epoch: 537/1000, batch:   528/ 1052, ite: 141100] train loss: 0.004306, tar: 0.000111 
l0: 0.000014, l1: 0.000012, l2: 0.000028, l3: 0.000067, l4: 0.000236, l5: 0.000568, l6: 0.000779

[epoch: 537/1000, batch:   608/ 1052, ite: 141120] train loss: 0.004307, tar: 0.000111 
l0: 0.000139, l1: 0.000137, l2: 0.000193, l3: 0.000311, l4: 0.000640, l5: 0.000994, l6: 0.002226

[epoch: 537/1000, batch:   688/ 1052, ite: 141140] train loss: 0.004307, tar: 0.000111 
l0: 0.000099, l1: 0.000095, l2: 0.000139, l3: 0.000222, l4: 0.000549, l5: 0.001338, l6: 0.002561

[epoch: 537/1000, batch:   768/ 1052, ite: 141160] train loss: 0.004307, tar: 0.000111 
l0: 0.000144, l1: 0.000135, l2: 0.000233, l3: 0.000360, l4: 0.000566, l5: 0.001113, l6: 0.002196

[epoch: 537/1000, batch:   848/ 1052, ite: 141180] train loss: 0.004307, tar: 0.000111 
l0: 0.000137, l1: 0.000131, l2: 0.000197, l3: 0.000281, l4: 0.000606, l5: 0.001269, l6: 0.001512

[epoch: 537/1000, batch:   928/ 1052, ite: 141200] train loss: 0.004308, tar: 0.000111 
l0: 0.000063, l1: 0.000062, l2: 0.000090, l3: 0.000150, l4: 0.000383, l5: 0.001097, l6: 0.001778

[epoch: 537/1000, batch:  1008/ 1052, ite: 141220] train loss: 0.004308, tar: 0.000111 
[Epoch 537/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000076, l1: 0.000065, l2: 0.000102, l3: 0.000201, l4: 0.000537, l5: 0.000938, l6: 0.001889

[epoch: 538/1000, batch:    36/ 1052, ite: 141240] train loss: 0.004309, tar: 0.000111 
l0: 0.000030, l1: 0.000029, l2: 0.000041, l3: 0.000095, l4: 0.000179, l5: 0.000488, l6: 0.000711

[epoch: 538/1000, batch:   116/ 1052, ite: 141260] train loss: 0.004308, tar: 0.000111 
l0: 0.000124, l1: 0.000131, l2: 0.000162, l3: 0.000247, l4: 0.000394, l5: 0.001182, l6: 0.001648

[epoch: 538/1000, batch:   196/ 1052, ite: 141280] train loss: 0.004307, tar: 0.000111 
l0: 0.000092, l1: 0.000075, l2: 0.000134, l3: 0.000291, l4: 0.000589, l5: 0.001616, l6: 0.002976

[epoch: 538/1000, batch:   276/ 1052, ite: 141300] train loss: 0.004308, tar: 0.000111 
l0: 0.000100, l1: 0.000107, l2: 0.000141, l3: 0.000249, l4: 0.000493, l5: 0.000957, l6: 0.001167

[epoch: 538/1000, batch:   356/ 1052, ite: 141320] train loss: 0.004306, tar: 0.000111 
l0: 0.000084, l1: 0.000080, l2: 0.000131, l3: 0.000268, l4: 0.000461, l5: 0.000540, l6: 0.002057

[epoch: 538/1000, batch:   436/ 1052, ite: 141340] train loss: 0.004306, tar: 0.000111 
l0: 0.000058, l1: 0.000067, l2: 0.000059, l3: 0.000117, l4: 0.000496, l5: 0.000962, l6: 0.001819

[epoch: 538/1000, batch:   516/ 1052, ite: 141360] train loss: 0.004306, tar: 0.000111 
l0: 0.000086, l1: 0.000074, l2: 0.000155, l3: 0.000369, l4: 0.000697, l5: 0.001174, l6: 0.002918

[epoch: 538/1000, batch:   596/ 1052, ite: 141380] train loss: 0.004304, tar: 0.000111 
l0: 0.000035, l1: 0.000032, l2: 0.000055, l3: 0.000127, l4: 0.000365, l5: 0.001233, l6: 0.001911

[epoch: 538/1000, batch:   676/ 1052, ite: 141400] train loss: 0.004304, tar: 0.000111 
l0: 0.000038, l1: 0.000037, l2: 0.000052, l3: 0.000126, l4: 0.000332, l5: 0.000514, l6: 0.001383

[epoch: 538/1000, batch:   756/ 1052, ite: 141420] train loss: 0.004303, tar: 0.000111 
l0: 0.000069, l1: 0.000065, l2: 0.000108, l3: 0.000182, l4: 0.000497, l5: 0.000973, l6: 0.001662

[epoch: 538/1000, batch:   836/ 1052, ite: 141440] train loss: 0.004303, tar: 0.000111 
l0: 0.000083, l1: 0.000084, l2: 0.000097, l3: 0.000195, l4: 0.000460, l5: 0.000991, l6: 0.002114

[epoch: 538/1000, batch:   916/ 1052, ite: 141460] train loss: 0.004306, tar: 0.000111 
l0: 0.000047, l1: 0.000042, l2: 0.000099, l3: 0.000214, l4: 0.000606, l5: 0.000812, l6: 0.001361

[epoch: 538/1000, batch:   996/ 1052, ite: 141480] train loss: 0.004305, tar: 0.000111 
[Epoch 538/1000] Test loss: 0.016, Test target loss: 0.002
l0: 0.000040, l1: 0.000045, l2: 0.000064, l3: 0.000087, l4: 0.000205, l5: 0.000520, l6: 0.000691

[epoch: 539/1000, batch:    24/ 1052, ite: 141500] train loss: 0.004306, tar: 0.000111 
l0: 0.000049, l1: 0.000046, l2: 0.000089, l3: 0.000162, l4: 0.000411, l5: 0.000859, l6: 0.001572

[epoch: 539/1000, batch:   104/ 1052, ite: 141520] train loss: 0.004309, tar: 0.000111 
l0: 0.000072, l1: 0.000073, l2: 0.000116, l3: 0.000170, l4: 0.000368, l5: 0.000854, l6: 0.001340

[epoch: 539/1000, batch:   184/ 1052, ite: 141540] train loss: 0.004309, tar: 0.000111 
l0: 0.000029, l1: 0.000028, l2: 0.000073, l3: 0.000158, l4: 0.000314, l5: 0.000830, l6: 0.001471

[epoch: 539/1000, batch:   264/ 1052, ite: 141560] train loss: 0.004307, tar: 0.000110 
l0: 0.000050, l1: 0.000049, l2: 0.000060, l3: 0.000201, l4: 0.000490, l5: 0.000924, l6: 0.002140

[epoch: 539/1000, batch:   344/ 1052, ite: 141580] train loss: 0.004308, tar: 0.000110 
l0: 0.000055, l1: 0.000056, l2: 0.000069, l3: 0.000146, l4: 0.000428, l5: 0.000813, l6: 0.001476

[epoch: 539/1000, batch:   424/ 1052, ite: 141600] train loss: 0.004307, tar: 0.000110 
l0: 0.000049, l1: 0.000046, l2: 0.000069, l3: 0.000122, l4: 0.000367, l5: 0.001187, l6: 0.002391

[epoch: 539/1000, batch:   504/ 1052, ite: 141620] train loss: 0.004305, tar: 0.000110 
l0: 0.000071, l1: 0.000067, l2: 0.000106, l3: 0.000142, l4: 0.000244, l5: 0.000836, l6: 0.001263

[epoch: 539/1000, batch:   584/ 1052, ite: 141640] train loss: 0.004306, tar: 0.000110 
l0: 0.000147, l1: 0.000152, l2: 0.000214, l3: 0.000296, l4: 0.000609, l5: 0.001299, l6: 0.002439

[epoch: 539/1000, batch:   664/ 1052, ite: 141660] train loss: 0.004307, tar: 0.000110 
l0: 0.000041, l1: 0.000042, l2: 0.000051, l3: 0.000093, l4: 0.000266, l5: 0.000346, l6: 0.000789

[epoch: 539/1000, batch:   744/ 1052, ite: 141680] train loss: 0.004306, tar: 0.000110 
l0: 0.000070, l1: 0.000070, l2: 0.000094, l3: 0.000171, l4: 0.000270, l5: 0.000899, l6: 0.001677

[epoch: 539/1000, batch:   824/ 1052, ite: 141700] train loss: 0.004305, tar: 0.000110 
l0: 0.000070, l1: 0.000067, l2: 0.000101, l3: 0.000155, l4: 0.000396, l5: 0.000643, l6: 0.001222

[epoch: 539/1000, batch:   904/ 1052, ite: 141720] train loss: 0.004307, tar: 0.000110 
l0: 0.000069, l1: 0.000072, l2: 0.000146, l3: 0.000206, l4: 0.000589, l5: 0.001051, l6: 0.001633

[epoch: 539/1000, batch:   984/ 1052, ite: 141740] train loss: 0.004305, tar: 0.000110 
[Epoch 539/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000221, l1: 0.000254, l2: 0.000277, l3: 0.000300, l4: 0.000744, l5: 0.001635, l6: 0.002413

[epoch: 540/1000, batch:    12/ 1052, ite: 141760] train loss: 0.004303, tar: 0.000110 
l0: 0.000070, l1: 0.000066, l2: 0.000102, l3: 0.000234, l4: 0.000567, l5: 0.000953, l6: 0.001393

[epoch: 540/1000, batch:    92/ 1052, ite: 141780] train loss: 0.004303, tar: 0.000109 
l0: 0.000009, l1: 0.000007, l2: 0.000021, l3: 0.000064, l4: 0.000126, l5: 0.000272, l6: 0.000564

[epoch: 540/1000, batch:   172/ 1052, ite: 141800] train loss: 0.004301, tar: 0.000109 
l0: 0.000079, l1: 0.000074, l2: 0.000108, l3: 0.000178, l4: 0.000396, l5: 0.000726, l6: 0.000894

[epoch: 540/1000, batch:   252/ 1052, ite: 141820] train loss: 0.004300, tar: 0.000109 
l0: 0.000032, l1: 0.000027, l2: 0.000082, l3: 0.000243, l4: 0.000482, l5: 0.001015, l6: 0.001555

[epoch: 540/1000, batch:   332/ 1052, ite: 141840] train loss: 0.004299, tar: 0.000109 
l0: 0.000062, l1: 0.000060, l2: 0.000095, l3: 0.000160, l4: 0.000291, l5: 0.001086, l6: 0.001805

[epoch: 540/1000, batch:   412/ 1052, ite: 141860] train loss: 0.004298, tar: 0.000109 
l0: 0.000128, l1: 0.000128, l2: 0.000193, l3: 0.000257, l4: 0.000542, l5: 0.001008, l6: 0.001967

[epoch: 540/1000, batch:   492/ 1052, ite: 141880] train loss: 0.004296, tar: 0.000109 
l0: 0.000036, l1: 0.000035, l2: 0.000032, l3: 0.000058, l4: 0.000161, l5: 0.000186, l6: 0.000592

[epoch: 540/1000, batch:   572/ 1052, ite: 141900] train loss: 0.004293, tar: 0.000109 
l0: 0.000169, l1: 0.000170, l2: 0.000184, l3: 0.000414, l4: 0.000808, l5: 0.001714, l6: 0.002523

[epoch: 540/1000, batch:   652/ 1052, ite: 141920] train loss: 0.004296, tar: 0.000109 
l0: 0.000061, l1: 0.000056, l2: 0.000134, l3: 0.000258, l4: 0.000881, l5: 0.001988, l6: 0.002244

[epoch: 540/1000, batch:   732/ 1052, ite: 141940] train loss: 0.004294, tar: 0.000109 
l0: 0.000050, l1: 0.000050, l2: 0.000083, l3: 0.000170, l4: 0.000244, l5: 0.000685, l6: 0.001474

[epoch: 540/1000, batch:   812/ 1052, ite: 141960] train loss: 0.004297, tar: 0.000109 
l0: 0.000021, l1: 0.000017, l2: 0.000041, l3: 0.000104, l4: 0.000237, l5: 0.000636, l6: 0.000648

[epoch: 540/1000, batch:   892/ 1052, ite: 141980] train loss: 0.004297, tar: 0.000109 
l0: 0.000097, l1: 0.000098, l2: 0.000144, l3: 0.000336, l4: 0.000740, l5: 0.001330, l6: 0.001378

[epoch: 540/1000, batch:   972/ 1052, ite: 142000] train loss: 0.004297, tar: 0.000108 
l0: 0.000070, l1: 0.000071, l2: 0.000143, l3: 0.000381, l4: 0.000930, l5: 0.001749, l6: 0.003176

[epoch: 540/1000, batch:  1052/ 1052, ite: 142020] train loss: 0.004296, tar: 0.000108 
[Epoch 540/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000121, l1: 0.000125, l2: 0.000159, l3: 0.000298, l4: 0.000771, l5: 0.001720, l6: 0.002492

[epoch: 541/1000, batch:    80/ 1052, ite: 142040] train loss: 0.004296, tar: 0.000108 
l0: 0.000044, l1: 0.000040, l2: 0.000079, l3: 0.000170, l4: 0.000603, l5: 0.000830, l6: 0.002366

[epoch: 541/1000, batch:   160/ 1052, ite: 142060] train loss: 0.004298, tar: 0.000108 
l0: 0.000027, l1: 0.000026, l2: 0.000041, l3: 0.000115, l4: 0.000366, l5: 0.000973, l6: 0.001053

[epoch: 541/1000, batch:   240/ 1052, ite: 142080] train loss: 0.004298, tar: 0.000108 
l0: 0.000052, l1: 0.000047, l2: 0.000074, l3: 0.000191, l4: 0.000330, l5: 0.000592, l6: 0.001164

[epoch: 541/1000, batch:   320/ 1052, ite: 142100] train loss: 0.004296, tar: 0.000108 
l0: 0.000087, l1: 0.000087, l2: 0.000125, l3: 0.000232, l4: 0.000558, l5: 0.000985, l6: 0.001485

[epoch: 541/1000, batch:   400/ 1052, ite: 142120] train loss: 0.004294, tar: 0.000108 
l0: 0.000091, l1: 0.000093, l2: 0.000123, l3: 0.000279, l4: 0.000597, l5: 0.000937, l6: 0.001725

[epoch: 541/1000, batch:   480/ 1052, ite: 142140] train loss: 0.004292, tar: 0.000108 
l0: 0.000050, l1: 0.000049, l2: 0.000069, l3: 0.000127, l4: 0.000211, l5: 0.000378, l6: 0.000935

[epoch: 541/1000, batch:   560/ 1052, ite: 142160] train loss: 0.004290, tar: 0.000107 
l0: 0.000057, l1: 0.000060, l2: 0.000115, l3: 0.000164, l4: 0.000291, l5: 0.000878, l6: 0.001615

[epoch: 541/1000, batch:   640/ 1052, ite: 142180] train loss: 0.004292, tar: 0.000107 
l0: 0.000051, l1: 0.000049, l2: 0.000086, l3: 0.000241, l4: 0.000503, l5: 0.001789, l6: 0.003237

[epoch: 541/1000, batch:   720/ 1052, ite: 142200] train loss: 0.004292, tar: 0.000107 
l0: 0.000063, l1: 0.000063, l2: 0.000130, l3: 0.000306, l4: 0.000545, l5: 0.001156, l6: 0.002166

[epoch: 541/1000, batch:   800/ 1052, ite: 142220] train loss: 0.004290, tar: 0.000107 
l0: 0.000046, l1: 0.000046, l2: 0.000090, l3: 0.000214, l4: 0.000728, l5: 0.001482, l6: 0.002394

[epoch: 541/1000, batch:   880/ 1052, ite: 142240] train loss: 0.004289, tar: 0.000107 
l0: 0.000054, l1: 0.000050, l2: 0.000088, l3: 0.000189, l4: 0.000456, l5: 0.001116, l6: 0.001730

[epoch: 541/1000, batch:   960/ 1052, ite: 142260] train loss: 0.004290, tar: 0.000107 
l0: 0.000057, l1: 0.000053, l2: 0.000090, l3: 0.000191, l4: 0.000539, l5: 0.000940, l6: 0.002584

[epoch: 541/1000, batch:  1040/ 1052, ite: 142280] train loss: 0.004290, tar: 0.000107 
[Epoch 541/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000105, l1: 0.000101, l2: 0.000149, l3: 0.000233, l4: 0.000435, l5: 0.000920, l6: 0.001427

[epoch: 542/1000, batch:    68/ 1052, ite: 142300] train loss: 0.004289, tar: 0.000107 
l0: 0.000068, l1: 0.000064, l2: 0.000105, l3: 0.000287, l4: 0.000623, l5: 0.000938, l6: 0.001351

[epoch: 542/1000, batch:   148/ 1052, ite: 142320] train loss: 0.004287, tar: 0.000107 
l0: 0.000055, l1: 0.000053, l2: 0.000097, l3: 0.000161, l4: 0.000406, l5: 0.001115, l6: 0.001962

[epoch: 542/1000, batch:   228/ 1052, ite: 142340] train loss: 0.004287, tar: 0.000107 
l0: 0.000068, l1: 0.000065, l2: 0.000136, l3: 0.000235, l4: 0.000530, l5: 0.001259, l6: 0.002368

[epoch: 542/1000, batch:   308/ 1052, ite: 142360] train loss: 0.004287, tar: 0.000106 
l0: 0.000093, l1: 0.000094, l2: 0.000136, l3: 0.000243, l4: 0.000490, l5: 0.000667, l6: 0.001558

[epoch: 542/1000, batch:   388/ 1052, ite: 142380] train loss: 0.004287, tar: 0.000106 
l0: 0.000097, l1: 0.000096, l2: 0.000178, l3: 0.000255, l4: 0.000425, l5: 0.001026, l6: 0.001748

[epoch: 542/1000, batch:   468/ 1052, ite: 142400] train loss: 0.004288, tar: 0.000106 
l0: 0.000085, l1: 0.000086, l2: 0.000100, l3: 0.000317, l4: 0.000593, l5: 0.001540, l6: 0.002065

[epoch: 542/1000, batch:   548/ 1052, ite: 142420] train loss: 0.004290, tar: 0.000106 
l0: 0.000042, l1: 0.000041, l2: 0.000071, l3: 0.000109, l4: 0.000167, l5: 0.000552, l6: 0.001071

[epoch: 542/1000, batch:   628/ 1052, ite: 142440] train loss: 0.004289, tar: 0.000106 
l0: 0.000092, l1: 0.000097, l2: 0.000127, l3: 0.000224, l4: 0.000537, l5: 0.001360, l6: 0.001443

[epoch: 542/1000, batch:   708/ 1052, ite: 142460] train loss: 0.004289, tar: 0.000106 
l0: 0.000067, l1: 0.000066, l2: 0.000096, l3: 0.000154, l4: 0.000306, l5: 0.001061, l6: 0.002106

[epoch: 542/1000, batch:   788/ 1052, ite: 142480] train loss: 0.004289, tar: 0.000106 
l0: 0.000057, l1: 0.000061, l2: 0.000075, l3: 0.000133, l4: 0.000253, l5: 0.000917, l6: 0.001757

[epoch: 542/1000, batch:   868/ 1052, ite: 142500] train loss: 0.004288, tar: 0.000106 
l0: 0.000058, l1: 0.000055, l2: 0.000090, l3: 0.000222, l4: 0.000305, l5: 0.000868, l6: 0.001797

[epoch: 542/1000, batch:   948/ 1052, ite: 142520] train loss: 0.004287, tar: 0.000106 
l0: 0.000037, l1: 0.000036, l2: 0.000047, l3: 0.000083, l4: 0.000286, l5: 0.000755, l6: 0.001390

[epoch: 542/1000, batch:  1028/ 1052, ite: 142540] train loss: 0.004286, tar: 0.000106 
[Epoch 542/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000115, l1: 0.000122, l2: 0.000118, l3: 0.000154, l4: 0.000223, l5: 0.001164, l6: 0.001723

[epoch: 543/1000, batch:    56/ 1052, ite: 142560] train loss: 0.004287, tar: 0.000105 
l0: 0.000033, l1: 0.000031, l2: 0.000068, l3: 0.000100, l4: 0.000241, l5: 0.000409, l6: 0.000793

[epoch: 543/1000, batch:   136/ 1052, ite: 142580] train loss: 0.004285, tar: 0.000105 
l0: 0.000070, l1: 0.000067, l2: 0.000109, l3: 0.000220, l4: 0.000554, l5: 0.001276, l6: 0.002043

[epoch: 543/1000, batch:   216/ 1052, ite: 142600] train loss: 0.004282, tar: 0.000105 
l0: 0.000034, l1: 0.000032, l2: 0.000093, l3: 0.000152, l4: 0.000460, l5: 0.001342, l6: 0.002195

[epoch: 543/1000, batch:   296/ 1052, ite: 142620] train loss: 0.004281, tar: 0.000105 
l0: 0.000069, l1: 0.000065, l2: 0.000126, l3: 0.000249, l4: 0.000426, l5: 0.001123, l6: 0.002279

[epoch: 543/1000, batch:   376/ 1052, ite: 142640] train loss: 0.004279, tar: 0.000105 
l0: 0.000039, l1: 0.000038, l2: 0.000079, l3: 0.000202, l4: 0.000401, l5: 0.001042, l6: 0.001615

[epoch: 543/1000, batch:   456/ 1052, ite: 142660] train loss: 0.004279, tar: 0.000105 
l0: 0.000046, l1: 0.000045, l2: 0.000088, l3: 0.000198, l4: 0.000480, l5: 0.001160, l6: 0.001383

[epoch: 543/1000, batch:   536/ 1052, ite: 142680] train loss: 0.004277, tar: 0.000105 
l0: 0.000034, l1: 0.000029, l2: 0.000067, l3: 0.000157, l4: 0.000466, l5: 0.001007, l6: 0.001172

[epoch: 543/1000, batch:   616/ 1052, ite: 142700] train loss: 0.004276, tar: 0.000105 
l0: 0.000045, l1: 0.000043, l2: 0.000092, l3: 0.000141, l4: 0.000278, l5: 0.001052, l6: 0.001903

[epoch: 543/1000, batch:   696/ 1052, ite: 142720] train loss: 0.004279, tar: 0.000104 
l0: 0.000079, l1: 0.000077, l2: 0.000120, l3: 0.000209, l4: 0.000497, l5: 0.001227, l6: 0.002386

[epoch: 543/1000, batch:   776/ 1052, ite: 142740] train loss: 0.004280, tar: 0.000104 
l0: 0.000088, l1: 0.000096, l2: 0.000076, l3: 0.000106, l4: 0.000248, l5: 0.000769, l6: 0.001229

[epoch: 543/1000, batch:   856/ 1052, ite: 142760] train loss: 0.004278, tar: 0.000104 
l0: 0.000108, l1: 0.000108, l2: 0.000174, l3: 0.000397, l4: 0.001079, l5: 0.002649, l6: 0.004032

[epoch: 543/1000, batch:   936/ 1052, ite: 142780] train loss: 0.004278, tar: 0.000104 
l0: 0.000089, l1: 0.000093, l2: 0.000102, l3: 0.000181, l4: 0.000502, l5: 0.000908, l6: 0.001662

[epoch: 543/1000, batch:  1016/ 1052, ite: 142800] train loss: 0.004278, tar: 0.000104 
[Epoch 543/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000132, l1: 0.000139, l2: 0.000165, l3: 0.000233, l4: 0.000476, l5: 0.000820, l6: 0.002478

[epoch: 544/1000, batch:    44/ 1052, ite: 142820] train loss: 0.004277, tar: 0.000104 
l0: 0.000454, l1: 0.000446, l2: 0.000539, l3: 0.000601, l4: 0.000898, l5: 0.002188, l6: 0.003282

[epoch: 544/1000, batch:   124/ 1052, ite: 142840] train loss: 0.004276, tar: 0.000104 
l0: 0.000098, l1: 0.000103, l2: 0.000151, l3: 0.000256, l4: 0.000476, l5: 0.001513, l6: 0.003450

[epoch: 544/1000, batch:   204/ 1052, ite: 142860] train loss: 0.004275, tar: 0.000104 
l0: 0.000217, l1: 0.000216, l2: 0.000230, l3: 0.000347, l4: 0.000438, l5: 0.000868, l6: 0.001478

[epoch: 544/1000, batch:   284/ 1052, ite: 142880] train loss: 0.004274, tar: 0.000104 
l0: 0.000043, l1: 0.000040, l2: 0.000071, l3: 0.000163, l4: 0.000430, l5: 0.000586, l6: 0.000779

[epoch: 544/1000, batch:   364/ 1052, ite: 142900] train loss: 0.004274, tar: 0.000104 
l0: 0.000036, l1: 0.000039, l2: 0.000091, l3: 0.000120, l4: 0.000378, l5: 0.000829, l6: 0.000970

[epoch: 544/1000, batch:   444/ 1052, ite: 142920] train loss: 0.004273, tar: 0.000103 
l0: 0.000021, l1: 0.000020, l2: 0.000054, l3: 0.000170, l4: 0.000357, l5: 0.001467, l6: 0.002343

[epoch: 544/1000, batch:   524/ 1052, ite: 142940] train loss: 0.004273, tar: 0.000103 
l0: 0.000039, l1: 0.000037, l2: 0.000059, l3: 0.000084, l4: 0.000293, l5: 0.000332, l6: 0.000929

[epoch: 544/1000, batch:   604/ 1052, ite: 142960] train loss: 0.004272, tar: 0.000103 
l0: 0.000050, l1: 0.000047, l2: 0.000141, l3: 0.000373, l4: 0.000748, l5: 0.001765, l6: 0.002925

[epoch: 544/1000, batch:   684/ 1052, ite: 142980] train loss: 0.004272, tar: 0.000103 
l0: 0.000077, l1: 0.000077, l2: 0.000112, l3: 0.000242, l4: 0.000595, l5: 0.001429, l6: 0.002690

[epoch: 544/1000, batch:   764/ 1052, ite: 143000] train loss: 0.004273, tar: 0.000103 
l0: 0.000041, l1: 0.000040, l2: 0.000071, l3: 0.000174, l4: 0.000599, l5: 0.000993, l6: 0.002426

[epoch: 544/1000, batch:   844/ 1052, ite: 143020] train loss: 0.004271, tar: 0.000103 
l0: 0.000024, l1: 0.000021, l2: 0.000075, l3: 0.000158, l4: 0.000297, l5: 0.000732, l6: 0.001866

[epoch: 544/1000, batch:   924/ 1052, ite: 143040] train loss: 0.004271, tar: 0.000103 
l0: 0.000043, l1: 0.000044, l2: 0.000078, l3: 0.000226, l4: 0.000595, l5: 0.001065, l6: 0.001862

[epoch: 544/1000, batch:  1004/ 1052, ite: 143060] train loss: 0.004270, tar: 0.000103 
[Epoch 544/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000056, l1: 0.000056, l2: 0.000090, l3: 0.000185, l4: 0.000414, l5: 0.001157, l6: 0.002229

[epoch: 545/1000, batch:    32/ 1052, ite: 143080] train loss: 0.004271, tar: 0.000103 
l0: 0.000177, l1: 0.000187, l2: 0.000279, l3: 0.000370, l4: 0.000964, l5: 0.002064, l6: 0.004906

[epoch: 545/1000, batch:   112/ 1052, ite: 143100] train loss: 0.004271, tar: 0.000102 
l0: 0.000059, l1: 0.000063, l2: 0.000097, l3: 0.000206, l4: 0.000511, l5: 0.001186, l6: 0.001851

[epoch: 545/1000, batch:   192/ 1052, ite: 143120] train loss: 0.004270, tar: 0.000102 
l0: 0.000068, l1: 0.000068, l2: 0.000115, l3: 0.000198, l4: 0.000430, l5: 0.000838, l6: 0.002787

[epoch: 545/1000, batch:   272/ 1052, ite: 143140] train loss: 0.004270, tar: 0.000102 
l0: 0.000045, l1: 0.000046, l2: 0.000047, l3: 0.000107, l4: 0.000364, l5: 0.000598, l6: 0.001069

[epoch: 545/1000, batch:   352/ 1052, ite: 143160] train loss: 0.004268, tar: 0.000102 
l0: 0.000083, l1: 0.000078, l2: 0.000146, l3: 0.000293, l4: 0.000526, l5: 0.001061, l6: 0.002544

[epoch: 545/1000, batch:   432/ 1052, ite: 143180] train loss: 0.004269, tar: 0.000102 
l0: 0.000062, l1: 0.000061, l2: 0.000104, l3: 0.000255, l4: 0.000358, l5: 0.000797, l6: 0.001450

[epoch: 545/1000, batch:   512/ 1052, ite: 143200] train loss: 0.004268, tar: 0.000102 
l0: 0.000039, l1: 0.000040, l2: 0.000098, l3: 0.000334, l4: 0.000715, l5: 0.001619, l6: 0.002640

[epoch: 545/1000, batch:   592/ 1052, ite: 143220] train loss: 0.004267, tar: 0.000102 
l0: 0.000087, l1: 0.000087, l2: 0.000126, l3: 0.000268, l4: 0.000550, l5: 0.001568, l6: 0.003815

[epoch: 545/1000, batch:   672/ 1052, ite: 143240] train loss: 0.004266, tar: 0.000102 
l0: 0.000054, l1: 0.000055, l2: 0.000101, l3: 0.000235, l4: 0.000421, l5: 0.000697, l6: 0.001251

[epoch: 545/1000, batch:   752/ 1052, ite: 143260] train loss: 0.004265, tar: 0.000102 
l0: 0.000029, l1: 0.000029, l2: 0.000045, l3: 0.000156, l4: 0.000475, l5: 0.001028, l6: 0.001042

[epoch: 545/1000, batch:   832/ 1052, ite: 143280] train loss: 0.004265, tar: 0.000101 
l0: 0.000050, l1: 0.000056, l2: 0.000059, l3: 0.000080, l4: 0.000161, l5: 0.000565, l6: 0.000508

[epoch: 545/1000, batch:   912/ 1052, ite: 143300] train loss: 0.004263, tar: 0.000101 
l0: 0.000027, l1: 0.000027, l2: 0.000064, l3: 0.000143, l4: 0.000396, l5: 0.000865, l6: 0.002125

[epoch: 545/1000, batch:   992/ 1052, ite: 143320] train loss: 0.004264, tar: 0.000101 
[Epoch 545/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000136, l1: 0.000136, l2: 0.000181, l3: 0.000319, l4: 0.000586, l5: 0.001602, l6: 0.001874

[epoch: 546/1000, batch:    20/ 1052, ite: 143340] train loss: 0.004263, tar: 0.000101 
l0: 0.000156, l1: 0.000160, l2: 0.000274, l3: 0.000391, l4: 0.000770, l5: 0.001328, l6: 0.002678

[epoch: 546/1000, batch:   100/ 1052, ite: 143360] train loss: 0.004263, tar: 0.000101 
l0: 0.000041, l1: 0.000042, l2: 0.000059, l3: 0.000119, l4: 0.000349, l5: 0.000988, l6: 0.001451

[epoch: 546/1000, batch:   180/ 1052, ite: 143380] train loss: 0.004261, tar: 0.000101 
l0: 0.000046, l1: 0.000045, l2: 0.000090, l3: 0.000302, l4: 0.000673, l5: 0.001019, l6: 0.001925

[epoch: 546/1000, batch:   260/ 1052, ite: 143400] train loss: 0.004261, tar: 0.000101 
l0: 0.000047, l1: 0.000045, l2: 0.000087, l3: 0.000181, l4: 0.000445, l5: 0.001075, l6: 0.001763

[epoch: 546/1000, batch:   340/ 1052, ite: 143420] train loss: 0.004261, tar: 0.000101 
l0: 0.000019, l1: 0.000017, l2: 0.000083, l3: 0.000125, l4: 0.000337, l5: 0.000925, l6: 0.001271

[epoch: 546/1000, batch:   420/ 1052, ite: 143440] train loss: 0.004261, tar: 0.000101 
l0: 0.000067, l1: 0.000067, l2: 0.000087, l3: 0.000172, l4: 0.000448, l5: 0.001067, l6: 0.001995

[epoch: 546/1000, batch:   500/ 1052, ite: 143460] train loss: 0.004259, tar: 0.000101 
l0: 0.000090, l1: 0.000087, l2: 0.000212, l3: 0.000400, l4: 0.000837, l5: 0.001644, l6: 0.003106

[epoch: 546/1000, batch:   580/ 1052, ite: 143480] train loss: 0.004258, tar: 0.000100 
l0: 0.000173, l1: 0.000178, l2: 0.000258, l3: 0.000367, l4: 0.000870, l5: 0.002090, l6: 0.003612

[epoch: 546/1000, batch:   660/ 1052, ite: 143500] train loss: 0.004261, tar: 0.000100 
l0: 0.000019, l1: 0.000019, l2: 0.000030, l3: 0.000104, l4: 0.000247, l5: 0.000591, l6: 0.001177

[epoch: 546/1000, batch:   740/ 1052, ite: 143520] train loss: 0.004260, tar: 0.000100 
l0: 0.000056, l1: 0.000055, l2: 0.000106, l3: 0.000211, l4: 0.000510, l5: 0.000879, l6: 0.001244

[epoch: 546/1000, batch:   820/ 1052, ite: 143540] train loss: 0.004258, tar: 0.000100 
l0: 0.000048, l1: 0.000048, l2: 0.000069, l3: 0.000156, l4: 0.000306, l5: 0.000697, l6: 0.001554

[epoch: 546/1000, batch:   900/ 1052, ite: 143560] train loss: 0.004258, tar: 0.000100 
l0: 0.000023, l1: 0.000023, l2: 0.000054, l3: 0.000164, l4: 0.000445, l5: 0.001243, l6: 0.002716

[epoch: 546/1000, batch:   980/ 1052, ite: 143580] train loss: 0.004258, tar: 0.000100 
[Epoch 546/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000074, l1: 0.000078, l2: 0.000091, l3: 0.000143, l4: 0.000275, l5: 0.000813, l6: 0.001842

[epoch: 547/1000, batch:     8/ 1052, ite: 143600] train loss: 0.004256, tar: 0.000100 
l0: 0.000048, l1: 0.000047, l2: 0.000090, l3: 0.000279, l4: 0.000443, l5: 0.001155, l6: 0.001224

[epoch: 547/1000, batch:    88/ 1052, ite: 143620] train loss: 0.004257, tar: 0.000100 
l0: 0.000082, l1: 0.000080, l2: 0.000130, l3: 0.000241, l4: 0.000500, l5: 0.001514, l6: 0.001348

[epoch: 547/1000, batch:   168/ 1052, ite: 143640] train loss: 0.004256, tar: 0.000100 
l0: 0.000031, l1: 0.000030, l2: 0.000068, l3: 0.000151, l4: 0.000536, l5: 0.001082, l6: 0.001944

[epoch: 547/1000, batch:   248/ 1052, ite: 143660] train loss: 0.004257, tar: 0.000100 
l0: 0.000023, l1: 0.000024, l2: 0.000044, l3: 0.000105, l4: 0.000272, l5: 0.000793, l6: 0.001617

[epoch: 547/1000, batch:   328/ 1052, ite: 143680] train loss: 0.004257, tar: 0.000100 
l0: 0.000095, l1: 0.000093, l2: 0.000192, l3: 0.000329, l4: 0.000697, l5: 0.001301, l6: 0.001933

[epoch: 547/1000, batch:   408/ 1052, ite: 143700] train loss: 0.004256, tar: 0.000100 
l0: 0.000046, l1: 0.000047, l2: 0.000040, l3: 0.000095, l4: 0.000243, l5: 0.000670, l6: 0.000387

[epoch: 547/1000, batch:   488/ 1052, ite: 143720] train loss: 0.004256, tar: 0.000099 
l0: 0.000094, l1: 0.000095, l2: 0.000170, l3: 0.000307, l4: 0.000712, l5: 0.001261, l6: 0.002661

[epoch: 547/1000, batch:   568/ 1052, ite: 143740] train loss: 0.004256, tar: 0.000099 
l0: 0.000088, l1: 0.000086, l2: 0.000187, l3: 0.000348, l4: 0.000708, l5: 0.001511, l6: 0.003098

[epoch: 547/1000, batch:   648/ 1052, ite: 143760] train loss: 0.004256, tar: 0.000099 
l0: 0.000111, l1: 0.000116, l2: 0.000155, l3: 0.000262, l4: 0.000619, l5: 0.001639, l6: 0.001916

[epoch: 547/1000, batch:   728/ 1052, ite: 143780] train loss: 0.004256, tar: 0.000099 
l0: 0.000059, l1: 0.000060, l2: 0.000076, l3: 0.000133, l4: 0.000396, l5: 0.000930, l6: 0.001029

[epoch: 547/1000, batch:   808/ 1052, ite: 143800] train loss: 0.004255, tar: 0.000099 
l0: 0.000110, l1: 0.000114, l2: 0.000131, l3: 0.000246, l4: 0.000514, l5: 0.001029, l6: 0.002671

[epoch: 547/1000, batch:   888/ 1052, ite: 143820] train loss: 0.004255, tar: 0.000099 
l0: 0.000027, l1: 0.000029, l2: 0.000087, l3: 0.000204, l4: 0.000479, l5: 0.000774, l6: 0.001544

[epoch: 547/1000, batch:   968/ 1052, ite: 143840] train loss: 0.004253, tar: 0.000099 
l0: 0.000025, l1: 0.000026, l2: 0.000079, l3: 0.000206, l4: 0.000355, l5: 0.000782, l6: 0.001431

[epoch: 547/1000, batch:  1048/ 1052, ite: 143860] train loss: 0.004250, tar: 0.000099 
[Epoch 547/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000081, l1: 0.000082, l2: 0.000110, l3: 0.000184, l4: 0.000395, l5: 0.000993, l6: 0.002086

[epoch: 548/1000, batch:    76/ 1052, ite: 143880] train loss: 0.004251, tar: 0.000099 
l0: 0.000024, l1: 0.000023, l2: 0.000037, l3: 0.000108, l4: 0.000291, l5: 0.000805, l6: 0.001616

[epoch: 548/1000, batch:   156/ 1052, ite: 143900] train loss: 0.004251, tar: 0.000099 
l0: 0.000055, l1: 0.000053, l2: 0.000087, l3: 0.000283, l4: 0.000599, l5: 0.001430, l6: 0.002496

[epoch: 548/1000, batch:   236/ 1052, ite: 143920] train loss: 0.004250, tar: 0.000098 
l0: 0.000085, l1: 0.000087, l2: 0.000134, l3: 0.000246, l4: 0.000627, l5: 0.001559, l6: 0.002939

[epoch: 548/1000, batch:   316/ 1052, ite: 143940] train loss: 0.004250, tar: 0.000098 
l0: 0.000090, l1: 0.000088, l2: 0.000115, l3: 0.000200, l4: 0.000366, l5: 0.000717, l6: 0.001944

[epoch: 548/1000, batch:   396/ 1052, ite: 143960] train loss: 0.004251, tar: 0.000098 
l0: 0.000022, l1: 0.000022, l2: 0.000054, l3: 0.000108, l4: 0.000313, l5: 0.001046, l6: 0.001419

[epoch: 548/1000, batch:   476/ 1052, ite: 143980] train loss: 0.004251, tar: 0.000098 
l0: 0.000078, l1: 0.000075, l2: 0.000143, l3: 0.000340, l4: 0.000770, l5: 0.001530, l6: 0.001312

[epoch: 548/1000, batch:   556/ 1052, ite: 144000] train loss: 0.004249, tar: 0.000098 
l0: 0.000030, l1: 0.000030, l2: 0.000052, l3: 0.000090, l4: 0.000123, l5: 0.000729, l6: 0.001107

[epoch: 548/1000, batch:   636/ 1052, ite: 144020] train loss: 0.004248, tar: 0.000098 
l0: 0.000036, l1: 0.000036, l2: 0.000061, l3: 0.000177, l4: 0.000489, l5: 0.001150, l6: 0.001656

[epoch: 548/1000, batch:   716/ 1052, ite: 144040] train loss: 0.004247, tar: 0.000098 
l0: 0.000119, l1: 0.000119, l2: 0.000189, l3: 0.000325, l4: 0.000685, l5: 0.001042, l6: 0.002362

[epoch: 548/1000, batch:   796/ 1052, ite: 144060] train loss: 0.004247, tar: 0.000098 
l0: 0.000032, l1: 0.000032, l2: 0.000051, l3: 0.000128, l4: 0.000323, l5: 0.000867, l6: 0.001495

[epoch: 548/1000, batch:   876/ 1052, ite: 144080] train loss: 0.004246, tar: 0.000098 
l0: 0.000093, l1: 0.000095, l2: 0.000143, l3: 0.000251, l4: 0.000715, l5: 0.001963, l6: 0.002886

[epoch: 548/1000, batch:   956/ 1052, ite: 144100] train loss: 0.004245, tar: 0.000098 
l0: 0.000032, l1: 0.000030, l2: 0.000065, l3: 0.000174, l4: 0.000400, l5: 0.000887, l6: 0.001838

[epoch: 548/1000, batch:  1036/ 1052, ite: 144120] train loss: 0.004246, tar: 0.000098 
[Epoch 548/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000033, l1: 0.000034, l2: 0.000064, l3: 0.000133, l4: 0.000382, l5: 0.000921, l6: 0.000998

[epoch: 549/1000, batch:    64/ 1052, ite: 144140] train loss: 0.004246, tar: 0.000098 
l0: 0.000063, l1: 0.000061, l2: 0.000087, l3: 0.000139, l4: 0.000250, l5: 0.000676, l6: 0.001042

[epoch: 549/1000, batch:   144/ 1052, ite: 144160] train loss: 0.004244, tar: 0.000098 
l0: 0.000023, l1: 0.000024, l2: 0.000045, l3: 0.000085, l4: 0.000311, l5: 0.000729, l6: 0.001211

[epoch: 549/1000, batch:   224/ 1052, ite: 144180] train loss: 0.004244, tar: 0.000097 
l0: 0.000085, l1: 0.000085, l2: 0.000117, l3: 0.000206, l4: 0.000460, l5: 0.001362, l6: 0.002383

[epoch: 549/1000, batch:   304/ 1052, ite: 144200] train loss: 0.004245, tar: 0.000097 
l0: 0.000036, l1: 0.000035, l2: 0.000077, l3: 0.000119, l4: 0.000343, l5: 0.000605, l6: 0.001886

[epoch: 549/1000, batch:   384/ 1052, ite: 144220] train loss: 0.004245, tar: 0.000097 
l0: 0.000104, l1: 0.000107, l2: 0.000146, l3: 0.000259, l4: 0.000517, l5: 0.001267, l6: 0.002592

[epoch: 549/1000, batch:   464/ 1052, ite: 144240] train loss: 0.004245, tar: 0.000097 
l0: 0.000043, l1: 0.000047, l2: 0.000100, l3: 0.000257, l4: 0.000653, l5: 0.001283, l6: 0.002485

[epoch: 549/1000, batch:   544/ 1052, ite: 144260] train loss: 0.004244, tar: 0.000097 
l0: 0.000057, l1: 0.000060, l2: 0.000104, l3: 0.000225, l4: 0.000631, l5: 0.001187, l6: 0.001274

[epoch: 549/1000, batch:   624/ 1052, ite: 144280] train loss: 0.004244, tar: 0.000097 
l0: 0.000079, l1: 0.000079, l2: 0.000160, l3: 0.000454, l4: 0.001100, l5: 0.001977, l6: 0.003442

[epoch: 549/1000, batch:   704/ 1052, ite: 144300] train loss: 0.004243, tar: 0.000097 
l0: 0.000096, l1: 0.000096, l2: 0.000111, l3: 0.000204, l4: 0.000460, l5: 0.000987, l6: 0.001722

[epoch: 549/1000, batch:   784/ 1052, ite: 144320] train loss: 0.004242, tar: 0.000097 
l0: 0.000072, l1: 0.000067, l2: 0.000097, l3: 0.000173, l4: 0.000431, l5: 0.000996, l6: 0.001055

[epoch: 549/1000, batch:   864/ 1052, ite: 144340] train loss: 0.004241, tar: 0.000097 
l0: 0.000106, l1: 0.000110, l2: 0.000124, l3: 0.000205, l4: 0.000607, l5: 0.001207, l6: 0.003057

[epoch: 549/1000, batch:   944/ 1052, ite: 144360] train loss: 0.004241, tar: 0.000097 
l0: 0.000043, l1: 0.000044, l2: 0.000067, l3: 0.000103, l4: 0.000251, l5: 0.000738, l6: 0.001231

[epoch: 549/1000, batch:  1024/ 1052, ite: 144380] train loss: 0.004241, tar: 0.000097 
[Epoch 549/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000101, l1: 0.000109, l2: 0.000129, l3: 0.000211, l4: 0.000671, l5: 0.001934, l6: 0.003323

[epoch: 550/1000, batch:    52/ 1052, ite: 144400] train loss: 0.004241, tar: 0.000097 
l0: 0.000052, l1: 0.000054, l2: 0.000124, l3: 0.000305, l4: 0.000651, l5: 0.000772, l6: 0.001946

[epoch: 550/1000, batch:   132/ 1052, ite: 144420] train loss: 0.004240, tar: 0.000097 
l0: 0.000145, l1: 0.000136, l2: 0.000183, l3: 0.000268, l4: 0.000649, l5: 0.001304, l6: 0.002612

[epoch: 550/1000, batch:   212/ 1052, ite: 144440] train loss: 0.004241, tar: 0.000096 
l0: 0.000055, l1: 0.000056, l2: 0.000123, l3: 0.000339, l4: 0.000748, l5: 0.001372, l6: 0.003278

[epoch: 550/1000, batch:   292/ 1052, ite: 144460] train loss: 0.004243, tar: 0.000096 
l0: 0.000108, l1: 0.000109, l2: 0.000150, l3: 0.000274, l4: 0.000460, l5: 0.000913, l6: 0.002041

[epoch: 550/1000, batch:   372/ 1052, ite: 144480] train loss: 0.004243, tar: 0.000096 
l0: 0.000053, l1: 0.000054, l2: 0.000146, l3: 0.000292, l4: 0.000491, l5: 0.001152, l6: 0.001709

[epoch: 550/1000, batch:   452/ 1052, ite: 144500] train loss: 0.004242, tar: 0.000096 
l0: 0.000018, l1: 0.000019, l2: 0.000049, l3: 0.000214, l4: 0.000553, l5: 0.001090, l6: 0.001706

[epoch: 550/1000, batch:   532/ 1052, ite: 144520] train loss: 0.004240, tar: 0.000096 
l0: 0.000017, l1: 0.000019, l2: 0.000026, l3: 0.000065, l4: 0.000224, l5: 0.000800, l6: 0.000831

[epoch: 550/1000, batch:   612/ 1052, ite: 144540] train loss: 0.004240, tar: 0.000096 
l0: 0.000023, l1: 0.000025, l2: 0.000035, l3: 0.000065, l4: 0.000164, l5: 0.000515, l6: 0.000655

[epoch: 550/1000, batch:   692/ 1052, ite: 144560] train loss: 0.004239, tar: 0.000096 
l0: 0.000100, l1: 0.000099, l2: 0.000173, l3: 0.000370, l4: 0.000801, l5: 0.001663, l6: 0.003529

[epoch: 550/1000, batch:   772/ 1052, ite: 144580] train loss: 0.004240, tar: 0.000096 
l0: 0.000138, l1: 0.000139, l2: 0.000259, l3: 0.000455, l4: 0.000848, l5: 0.002206, l6: 0.005102

[epoch: 550/1000, batch:   852/ 1052, ite: 144600] train loss: 0.004239, tar: 0.000096 
l0: 0.000062, l1: 0.000061, l2: 0.000092, l3: 0.000154, l4: 0.000391, l5: 0.000717, l6: 0.001772

[epoch: 550/1000, batch:   932/ 1052, ite: 144620] train loss: 0.004239, tar: 0.000096 
l0: 0.000055, l1: 0.000054, l2: 0.000075, l3: 0.000141, l4: 0.000327, l5: 0.000950, l6: 0.001074

[epoch: 550/1000, batch:  1012/ 1052, ite: 144640] train loss: 0.004238, tar: 0.000096 
[Epoch 550/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000079, l1: 0.000083, l2: 0.000124, l3: 0.000353, l4: 0.000600, l5: 0.001409, l6: 0.003627

[epoch: 551/1000, batch:    40/ 1052, ite: 144660] train loss: 0.004237, tar: 0.000096 
l0: 0.000027, l1: 0.000025, l2: 0.000087, l3: 0.000239, l4: 0.000487, l5: 0.001086, l6: 0.001345

[epoch: 551/1000, batch:   120/ 1052, ite: 144680] train loss: 0.004236, tar: 0.000096 
l0: 0.000046, l1: 0.000043, l2: 0.000105, l3: 0.000264, l4: 0.000506, l5: 0.000875, l6: 0.001994

[epoch: 551/1000, batch:   200/ 1052, ite: 144700] train loss: 0.004235, tar: 0.000096 
l0: 0.000041, l1: 0.000042, l2: 0.000089, l3: 0.000225, l4: 0.000413, l5: 0.000835, l6: 0.001968

[epoch: 551/1000, batch:   280/ 1052, ite: 144720] train loss: 0.004235, tar: 0.000095 
l0: 0.000105, l1: 0.000104, l2: 0.000149, l3: 0.000236, l4: 0.000602, l5: 0.001060, l6: 0.001913

[epoch: 551/1000, batch:   360/ 1052, ite: 144740] train loss: 0.004236, tar: 0.000095 
l0: 0.000050, l1: 0.000052, l2: 0.000074, l3: 0.000156, l4: 0.000333, l5: 0.000925, l6: 0.001691

[epoch: 551/1000, batch:   440/ 1052, ite: 144760] train loss: 0.004235, tar: 0.000095 
l0: 0.000076, l1: 0.000077, l2: 0.000129, l3: 0.000216, l4: 0.000683, l5: 0.001190, l6: 0.001650

[epoch: 551/1000, batch:   520/ 1052, ite: 144780] train loss: 0.004236, tar: 0.000095 
l0: 0.000024, l1: 0.000024, l2: 0.000124, l3: 0.000425, l4: 0.000678, l5: 0.001687, l6: 0.002297

[epoch: 551/1000, batch:   600/ 1052, ite: 144800] train loss: 0.004236, tar: 0.000095 
l0: 0.000114, l1: 0.000112, l2: 0.000164, l3: 0.000291, l4: 0.000464, l5: 0.000722, l6: 0.001595

[epoch: 551/1000, batch:   680/ 1052, ite: 144820] train loss: 0.004236, tar: 0.000095 
l0: 0.000035, l1: 0.000035, l2: 0.000081, l3: 0.000154, l4: 0.000437, l5: 0.000937, l6: 0.001406

[epoch: 551/1000, batch:   760/ 1052, ite: 144840] train loss: 0.004235, tar: 0.000095 
l0: 0.000083, l1: 0.000074, l2: 0.000125, l3: 0.000226, l4: 0.000442, l5: 0.001231, l6: 0.002459

[epoch: 551/1000, batch:   840/ 1052, ite: 144860] train loss: 0.004235, tar: 0.000095 
l0: 0.000063, l1: 0.000063, l2: 0.000079, l3: 0.000206, l4: 0.000518, l5: 0.001511, l6: 0.002581

[epoch: 551/1000, batch:   920/ 1052, ite: 144880] train loss: 0.004235, tar: 0.000095 
l0: 0.000032, l1: 0.000031, l2: 0.000086, l3: 0.000168, l4: 0.000261, l5: 0.000731, l6: 0.002060

[epoch: 551/1000, batch:  1000/ 1052, ite: 144900] train loss: 0.004234, tar: 0.000095 
[Epoch 551/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000035, l1: 0.000035, l2: 0.000074, l3: 0.000168, l4: 0.000426, l5: 0.000900, l6: 0.001303

[epoch: 552/1000, batch:    28/ 1052, ite: 144920] train loss: 0.004233, tar: 0.000095 
l0: 0.000016, l1: 0.000017, l2: 0.000050, l3: 0.000106, l4: 0.000272, l5: 0.000676, l6: 0.000671

[epoch: 552/1000, batch:   108/ 1052, ite: 144940] train loss: 0.004232, tar: 0.000095 
l0: 0.000055, l1: 0.000055, l2: 0.000087, l3: 0.000235, l4: 0.000434, l5: 0.001143, l6: 0.002014

[epoch: 552/1000, batch:   188/ 1052, ite: 144960] train loss: 0.004231, tar: 0.000095 
l0: 0.000051, l1: 0.000050, l2: 0.000083, l3: 0.000143, l4: 0.000333, l5: 0.000916, l6: 0.001345

[epoch: 552/1000, batch:   268/ 1052, ite: 144980] train loss: 0.004230, tar: 0.000095 
l0: 0.000100, l1: 0.000100, l2: 0.000128, l3: 0.000274, l4: 0.000809, l5: 0.001896, l6: 0.002456

[epoch: 552/1000, batch:   348/ 1052, ite: 145000] train loss: 0.004230, tar: 0.000095 
l0: 0.000003, l1: 0.000003, l2: 0.000021, l3: 0.000076, l4: 0.000183, l5: 0.000783, l6: 0.001029

[epoch: 552/1000, batch:   428/ 1052, ite: 145020] train loss: 0.004229, tar: 0.000094 
l0: 0.000040, l1: 0.000041, l2: 0.000079, l3: 0.000216, l4: 0.000456, l5: 0.000820, l6: 0.001729

[epoch: 552/1000, batch:   508/ 1052, ite: 145040] train loss: 0.004229, tar: 0.000094 
l0: 0.000029, l1: 0.000029, l2: 0.000053, l3: 0.000092, l4: 0.000351, l5: 0.000817, l6: 0.001223

[epoch: 552/1000, batch:   588/ 1052, ite: 145060] train loss: 0.004229, tar: 0.000094 
l0: 0.000121, l1: 0.000121, l2: 0.000133, l3: 0.000220, l4: 0.000687, l5: 0.001540, l6: 0.003006

[epoch: 552/1000, batch:   668/ 1052, ite: 145080] train loss: 0.004229, tar: 0.000094 
l0: 0.000113, l1: 0.000114, l2: 0.000190, l3: 0.000401, l4: 0.001042, l5: 0.001722, l6: 0.003151

[epoch: 552/1000, batch:   748/ 1052, ite: 145100] train loss: 0.004230, tar: 0.000094 
l0: 0.000038, l1: 0.000039, l2: 0.000073, l3: 0.000160, l4: 0.000279, l5: 0.001087, l6: 0.001542

[epoch: 552/1000, batch:   828/ 1052, ite: 145120] train loss: 0.004231, tar: 0.000094 
l0: 0.000039, l1: 0.000040, l2: 0.000054, l3: 0.000170, l4: 0.000289, l5: 0.000786, l6: 0.001328

[epoch: 552/1000, batch:   908/ 1052, ite: 145140] train loss: 0.004230, tar: 0.000094 
l0: 0.000086, l1: 0.000084, l2: 0.000183, l3: 0.000291, l4: 0.000617, l5: 0.001643, l6: 0.001903

[epoch: 552/1000, batch:   988/ 1052, ite: 145160] train loss: 0.004230, tar: 0.000094 
[Epoch 552/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000039, l1: 0.000040, l2: 0.000068, l3: 0.000126, l4: 0.000295, l5: 0.000962, l6: 0.001529

[epoch: 553/1000, batch:    16/ 1052, ite: 145180] train loss: 0.004230, tar: 0.000094 
l0: 0.000069, l1: 0.000068, l2: 0.000137, l3: 0.000235, l4: 0.000370, l5: 0.000954, l6: 0.002101

[epoch: 553/1000, batch:    96/ 1052, ite: 145200] train loss: 0.004230, tar: 0.000094 
l0: 0.000143, l1: 0.000142, l2: 0.000236, l3: 0.000350, l4: 0.000907, l5: 0.002223, l6: 0.003497

[epoch: 553/1000, batch:   176/ 1052, ite: 145220] train loss: 0.004231, tar: 0.000094 
l0: 0.000065, l1: 0.000062, l2: 0.000128, l3: 0.000290, l4: 0.000442, l5: 0.000831, l6: 0.002588

[epoch: 553/1000, batch:   256/ 1052, ite: 145240] train loss: 0.004229, tar: 0.000094 
l0: 0.000162, l1: 0.000163, l2: 0.000233, l3: 0.000379, l4: 0.000484, l5: 0.001208, l6: 0.002121

[epoch: 553/1000, batch:   336/ 1052, ite: 145260] train loss: 0.004228, tar: 0.000094 
l0: 0.000074, l1: 0.000076, l2: 0.000136, l3: 0.000232, l4: 0.000453, l5: 0.001095, l6: 0.003328

[epoch: 553/1000, batch:   416/ 1052, ite: 145280] train loss: 0.004229, tar: 0.000094 
l0: 0.000055, l1: 0.000055, l2: 0.000074, l3: 0.000147, l4: 0.000344, l5: 0.000500, l6: 0.001197

[epoch: 553/1000, batch:   496/ 1052, ite: 145300] train loss: 0.004229, tar: 0.000094 
l0: 0.000041, l1: 0.000039, l2: 0.000105, l3: 0.000379, l4: 0.000886, l5: 0.001166, l6: 0.002257

[epoch: 553/1000, batch:   576/ 1052, ite: 145320] train loss: 0.004229, tar: 0.000094 
l0: 0.000058, l1: 0.000059, l2: 0.000093, l3: 0.000145, l4: 0.000352, l5: 0.001081, l6: 0.001457

[epoch: 553/1000, batch:   656/ 1052, ite: 145340] train loss: 0.004228, tar: 0.000094 
l0: 0.000093, l1: 0.000090, l2: 0.000192, l3: 0.000294, l4: 0.001162, l5: 0.001816, l6: 0.002950

[epoch: 553/1000, batch:   736/ 1052, ite: 145360] train loss: 0.004228, tar: 0.000094 
l0: 0.000067, l1: 0.000069, l2: 0.000082, l3: 0.000121, l4: 0.000543, l5: 0.001220, l6: 0.001860

[epoch: 553/1000, batch:   816/ 1052, ite: 145380] train loss: 0.004228, tar: 0.000094 
l0: 0.000042, l1: 0.000043, l2: 0.000058, l3: 0.000174, l4: 0.000316, l5: 0.000920, l6: 0.001403

[epoch: 553/1000, batch:   896/ 1052, ite: 145400] train loss: 0.004227, tar: 0.000094 
l0: 0.000025, l1: 0.000023, l2: 0.000111, l3: 0.000315, l4: 0.000810, l5: 0.001917, l6: 0.002735

[epoch: 553/1000, batch:   976/ 1052, ite: 145420] train loss: 0.004227, tar: 0.000093 
[Epoch 553/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000041, l1: 0.000042, l2: 0.000088, l3: 0.000174, l4: 0.000348, l5: 0.001094, l6: 0.002008

[epoch: 554/1000, batch:     4/ 1052, ite: 145440] train loss: 0.004226, tar: 0.000093 
l0: 0.000085, l1: 0.000084, l2: 0.000124, l3: 0.000256, l4: 0.000360, l5: 0.001163, l6: 0.001649

[epoch: 554/1000, batch:    84/ 1052, ite: 145460] train loss: 0.004225, tar: 0.000093 
l0: 0.000130, l1: 0.000129, l2: 0.000175, l3: 0.000261, l4: 0.000392, l5: 0.001053, l6: 0.001441

[epoch: 554/1000, batch:   164/ 1052, ite: 145480] train loss: 0.004226, tar: 0.000093 
l0: 0.000065, l1: 0.000068, l2: 0.000073, l3: 0.000152, l4: 0.000314, l5: 0.001194, l6: 0.001661

[epoch: 554/1000, batch:   244/ 1052, ite: 145500] train loss: 0.004225, tar: 0.000093 
l0: 0.000062, l1: 0.000061, l2: 0.000086, l3: 0.000213, l4: 0.000312, l5: 0.000875, l6: 0.001320

[epoch: 554/1000, batch:   324/ 1052, ite: 145520] train loss: 0.004224, tar: 0.000093 
l0: 0.000066, l1: 0.000065, l2: 0.000112, l3: 0.000183, l4: 0.000326, l5: 0.001393, l6: 0.001977

[epoch: 554/1000, batch:   404/ 1052, ite: 145540] train loss: 0.004224, tar: 0.000093 
l0: 0.000044, l1: 0.000042, l2: 0.000117, l3: 0.000219, l4: 0.000343, l5: 0.001208, l6: 0.002095

[epoch: 554/1000, batch:   484/ 1052, ite: 145560] train loss: 0.004224, tar: 0.000093 
l0: 0.000055, l1: 0.000056, l2: 0.000094, l3: 0.000159, l4: 0.000296, l5: 0.000755, l6: 0.001017

[epoch: 554/1000, batch:   564/ 1052, ite: 145580] train loss: 0.004225, tar: 0.000093 
l0: 0.000062, l1: 0.000061, l2: 0.000104, l3: 0.000371, l4: 0.000541, l5: 0.001172, l6: 0.001125

[epoch: 554/1000, batch:   644/ 1052, ite: 145600] train loss: 0.004225, tar: 0.000093 
l0: 0.000029, l1: 0.000028, l2: 0.000080, l3: 0.000144, l4: 0.000399, l5: 0.000791, l6: 0.001606

[epoch: 554/1000, batch:   724/ 1052, ite: 145620] train loss: 0.004223, tar: 0.000093 
l0: 0.000101, l1: 0.000110, l2: 0.000145, l3: 0.000186, l4: 0.000312, l5: 0.000663, l6: 0.001248

[epoch: 554/1000, batch:   804/ 1052, ite: 145640] train loss: 0.004223, tar: 0.000093 
l0: 0.000081, l1: 0.000082, l2: 0.000112, l3: 0.000167, l4: 0.000393, l5: 0.001338, l6: 0.002090

[epoch: 554/1000, batch:   884/ 1052, ite: 145660] train loss: 0.004224, tar: 0.000093 
l0: 0.000018, l1: 0.000019, l2: 0.000041, l3: 0.000128, l4: 0.000222, l5: 0.000718, l6: 0.001644

[epoch: 554/1000, batch:   964/ 1052, ite: 145680] train loss: 0.004224, tar: 0.000093 
l0: 0.000048, l1: 0.000046, l2: 0.000144, l3: 0.000336, l4: 0.000599, l5: 0.001354, l6: 0.001721

[epoch: 554/1000, batch:  1044/ 1052, ite: 145700] train loss: 0.004224, tar: 0.000093 
[Epoch 554/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000028, l1: 0.000029, l2: 0.000055, l3: 0.000145, l4: 0.000414, l5: 0.001383, l6: 0.001865

[epoch: 555/1000, batch:    72/ 1052, ite: 145720] train loss: 0.004223, tar: 0.000093 
l0: 0.000092, l1: 0.000093, l2: 0.000099, l3: 0.000142, l4: 0.000300, l5: 0.001006, l6: 0.001501

[epoch: 555/1000, batch:   152/ 1052, ite: 145740] train loss: 0.004222, tar: 0.000093 
l0: 0.000066, l1: 0.000068, l2: 0.000111, l3: 0.000263, l4: 0.000664, l5: 0.001009, l6: 0.002355

[epoch: 555/1000, batch:   232/ 1052, ite: 145760] train loss: 0.004221, tar: 0.000093 
l0: 0.000030, l1: 0.000031, l2: 0.000049, l3: 0.000090, l4: 0.000219, l5: 0.000794, l6: 0.001634

[epoch: 555/1000, batch:   312/ 1052, ite: 145780] train loss: 0.004222, tar: 0.000093 
l0: 0.000128, l1: 0.000131, l2: 0.000130, l3: 0.000233, l4: 0.000388, l5: 0.000821, l6: 0.002228

[epoch: 555/1000, batch:   392/ 1052, ite: 145800] train loss: 0.004223, tar: 0.000093 
l0: 0.000073, l1: 0.000077, l2: 0.000064, l3: 0.000134, l4: 0.000444, l5: 0.000691, l6: 0.001645

[epoch: 555/1000, batch:   472/ 1052, ite: 145820] train loss: 0.004222, tar: 0.000093 
l0: 0.000034, l1: 0.000034, l2: 0.000050, l3: 0.000121, l4: 0.000665, l5: 0.001279, l6: 0.001842

[epoch: 555/1000, batch:   552/ 1052, ite: 145840] train loss: 0.004222, tar: 0.000093 
l0: 0.000033, l1: 0.000036, l2: 0.000062, l3: 0.000210, l4: 0.000595, l5: 0.001003, l6: 0.001861

[epoch: 555/1000, batch:   632/ 1052, ite: 145860] train loss: 0.004222, tar: 0.000093 
l0: 0.000032, l1: 0.000032, l2: 0.000056, l3: 0.000183, l4: 0.000478, l5: 0.000649, l6: 0.001329

[epoch: 555/1000, batch:   712/ 1052, ite: 145880] train loss: 0.004221, tar: 0.000093 
l0: 0.000109, l1: 0.000109, l2: 0.000189, l3: 0.000310, l4: 0.000572, l5: 0.001226, l6: 0.002200

[epoch: 555/1000, batch:   792/ 1052, ite: 145900] train loss: 0.004220, tar: 0.000092 
l0: 0.000046, l1: 0.000046, l2: 0.000062, l3: 0.000158, l4: 0.000264, l5: 0.000938, l6: 0.001570

[epoch: 555/1000, batch:   872/ 1052, ite: 145920] train loss: 0.004220, tar: 0.000092 
l0: 0.000058, l1: 0.000058, l2: 0.000102, l3: 0.000255, l4: 0.000803, l5: 0.002084, l6: 0.002652

[epoch: 555/1000, batch:   952/ 1052, ite: 145940] train loss: 0.004221, tar: 0.000092 
l0: 0.000032, l1: 0.000034, l2: 0.000057, l3: 0.000169, l4: 0.000466, l5: 0.001332, l6: 0.002370

[epoch: 555/1000, batch:  1032/ 1052, ite: 145960] train loss: 0.004220, tar: 0.000092 
[Epoch 555/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000063, l1: 0.000062, l2: 0.000106, l3: 0.000267, l4: 0.000534, l5: 0.001037, l6: 0.001968

[epoch: 556/1000, batch:    60/ 1052, ite: 145980] train loss: 0.004219, tar: 0.000092 
l0: 0.000077, l1: 0.000078, l2: 0.000108, l3: 0.000242, l4: 0.000440, l5: 0.001260, l6: 0.001418

[epoch: 556/1000, batch:   140/ 1052, ite: 146000] train loss: 0.004219, tar: 0.000092 
l0: 0.000124, l1: 0.000122, l2: 0.000190, l3: 0.000441, l4: 0.001129, l5: 0.002313, l6: 0.003206

[epoch: 556/1000, batch:   220/ 1052, ite: 146020] train loss: 0.004219, tar: 0.000092 
l0: 0.000122, l1: 0.000124, l2: 0.000162, l3: 0.000365, l4: 0.000783, l5: 0.003272, l6: 0.003809

[epoch: 556/1000, batch:   300/ 1052, ite: 146040] train loss: 0.004218, tar: 0.000092 
l0: 0.000058, l1: 0.000060, l2: 0.000061, l3: 0.000125, l4: 0.000244, l5: 0.000906, l6: 0.001173

[epoch: 556/1000, batch:   380/ 1052, ite: 146060] train loss: 0.004218, tar: 0.000092 
l0: 0.000103, l1: 0.000099, l2: 0.000196, l3: 0.000367, l4: 0.000850, l5: 0.001511, l6: 0.001808

[epoch: 556/1000, batch:   460/ 1052, ite: 146080] train loss: 0.004218, tar: 0.000092 
l0: 0.000061, l1: 0.000060, l2: 0.000138, l3: 0.000395, l4: 0.000717, l5: 0.001805, l6: 0.002894

[epoch: 556/1000, batch:   540/ 1052, ite: 146100] train loss: 0.004218, tar: 0.000092 
l0: 0.000148, l1: 0.000149, l2: 0.000184, l3: 0.000272, l4: 0.000466, l5: 0.001036, l6: 0.001570

[epoch: 556/1000, batch:   620/ 1052, ite: 146120] train loss: 0.004218, tar: 0.000092 
l0: 0.000093, l1: 0.000098, l2: 0.000145, l3: 0.000386, l4: 0.001133, l5: 0.002194, l6: 0.004720

[epoch: 556/1000, batch:   700/ 1052, ite: 146140] train loss: 0.004217, tar: 0.000092 
l0: 0.000075, l1: 0.000077, l2: 0.000098, l3: 0.000235, l4: 0.000436, l5: 0.000906, l6: 0.001918

[epoch: 556/1000, batch:   780/ 1052, ite: 146160] train loss: 0.004216, tar: 0.000092 
l0: 0.000067, l1: 0.000070, l2: 0.000104, l3: 0.000162, l4: 0.000407, l5: 0.001524, l6: 0.002051

[epoch: 556/1000, batch:   860/ 1052, ite: 146180] train loss: 0.004216, tar: 0.000092 
l0: 0.000014, l1: 0.000015, l2: 0.000052, l3: 0.000146, l4: 0.000342, l5: 0.000829, l6: 0.001756

[epoch: 556/1000, batch:   940/ 1052, ite: 146200] train loss: 0.004216, tar: 0.000092 
l0: 0.000049, l1: 0.000047, l2: 0.000092, l3: 0.000214, l4: 0.000432, l5: 0.001030, l6: 0.001680

[epoch: 556/1000, batch:  1020/ 1052, ite: 146220] train loss: 0.004216, tar: 0.000092 
[Epoch 556/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000085, l1: 0.000087, l2: 0.000136, l3: 0.000279, l4: 0.000418, l5: 0.001392, l6: 0.001794

[epoch: 557/1000, batch:    48/ 1052, ite: 146240] train loss: 0.004217, tar: 0.000092 
l0: 0.000146, l1: 0.000148, l2: 0.000163, l3: 0.000239, l4: 0.000711, l5: 0.001243, l6: 0.002309

[epoch: 557/1000, batch:   128/ 1052, ite: 146260] train loss: 0.004217, tar: 0.000092 
l0: 0.000014, l1: 0.000014, l2: 0.000026, l3: 0.000077, l4: 0.000219, l5: 0.000586, l6: 0.001102

[epoch: 557/1000, batch:   208/ 1052, ite: 146280] train loss: 0.004216, tar: 0.000092 
l0: 0.000122, l1: 0.000122, l2: 0.000177, l3: 0.000331, l4: 0.000695, l5: 0.001651, l6: 0.002287

[epoch: 557/1000, batch:   288/ 1052, ite: 146300] train loss: 0.004215, tar: 0.000092 
l0: 0.000017, l1: 0.000017, l2: 0.000039, l3: 0.000099, l4: 0.000275, l5: 0.000832, l6: 0.001248

[epoch: 557/1000, batch:   368/ 1052, ite: 146320] train loss: 0.004216, tar: 0.000092 
l0: 0.000093, l1: 0.000096, l2: 0.000166, l3: 0.000375, l4: 0.000974, l5: 0.001812, l6: 0.003304

[epoch: 557/1000, batch:   448/ 1052, ite: 146340] train loss: 0.004215, tar: 0.000091 
l0: 0.000104, l1: 0.000108, l2: 0.000125, l3: 0.000284, l4: 0.000403, l5: 0.001204, l6: 0.002711

[epoch: 557/1000, batch:   528/ 1052, ite: 146360] train loss: 0.004215, tar: 0.000091 
l0: 0.000061, l1: 0.000060, l2: 0.000186, l3: 0.000300, l4: 0.000448, l5: 0.000796, l6: 0.001904

[epoch: 557/1000, batch:   608/ 1052, ite: 146380] train loss: 0.004214, tar: 0.000091 
l0: 0.000039, l1: 0.000037, l2: 0.000122, l3: 0.000417, l4: 0.001006, l5: 0.002333, l6: 0.002947

[epoch: 557/1000, batch:   688/ 1052, ite: 146400] train loss: 0.004214, tar: 0.000091 
l0: 0.000152, l1: 0.000151, l2: 0.000228, l3: 0.000351, l4: 0.000504, l5: 0.000916, l6: 0.003432

[epoch: 557/1000, batch:   768/ 1052, ite: 146420] train loss: 0.004215, tar: 0.000091 
l0: 0.000064, l1: 0.000066, l2: 0.000124, l3: 0.000206, l4: 0.000469, l5: 0.000772, l6: 0.001206

[epoch: 557/1000, batch:   848/ 1052, ite: 146440] train loss: 0.004216, tar: 0.000091 
l0: 0.000122, l1: 0.000126, l2: 0.000160, l3: 0.000445, l4: 0.000835, l5: 0.001742, l6: 0.001976

[epoch: 557/1000, batch:   928/ 1052, ite: 146460] train loss: 0.004216, tar: 0.000091 
l0: 0.000066, l1: 0.000065, l2: 0.000095, l3: 0.000114, l4: 0.000336, l5: 0.000566, l6: 0.001302

[epoch: 557/1000, batch:  1008/ 1052, ite: 146480] train loss: 0.004215, tar: 0.000091 
[Epoch 557/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000054, l1: 0.000054, l2: 0.000089, l3: 0.000204, l4: 0.000421, l5: 0.000993, l6: 0.002597

[epoch: 558/1000, batch:    36/ 1052, ite: 146500] train loss: 0.004215, tar: 0.000091 
l0: 0.000049, l1: 0.000047, l2: 0.000097, l3: 0.000172, l4: 0.000370, l5: 0.000769, l6: 0.001559

[epoch: 558/1000, batch:   116/ 1052, ite: 146520] train loss: 0.004215, tar: 0.000091 
l0: 0.000125, l1: 0.000123, l2: 0.000184, l3: 0.000255, l4: 0.000608, l5: 0.001091, l6: 0.002381

[epoch: 558/1000, batch:   196/ 1052, ite: 146540] train loss: 0.004215, tar: 0.000091 
l0: 0.000070, l1: 0.000071, l2: 0.000107, l3: 0.000179, l4: 0.000336, l5: 0.001088, l6: 0.001668

[epoch: 558/1000, batch:   276/ 1052, ite: 146560] train loss: 0.004215, tar: 0.000091 
l0: 0.000078, l1: 0.000078, l2: 0.000098, l3: 0.000167, l4: 0.000438, l5: 0.001229, l6: 0.001335

[epoch: 558/1000, batch:   356/ 1052, ite: 146580] train loss: 0.004215, tar: 0.000091 
l0: 0.000029, l1: 0.000028, l2: 0.000074, l3: 0.000158, l4: 0.000320, l5: 0.000468, l6: 0.001100

[epoch: 558/1000, batch:   436/ 1052, ite: 146600] train loss: 0.004216, tar: 0.000091 
l0: 0.000068, l1: 0.000067, l2: 0.000122, l3: 0.000310, l4: 0.000500, l5: 0.000763, l6: 0.001432

[epoch: 558/1000, batch:   516/ 1052, ite: 146620] train loss: 0.004216, tar: 0.000091 
l0: 0.000016, l1: 0.000017, l2: 0.000056, l3: 0.000129, l4: 0.000476, l5: 0.000888, l6: 0.001585

[epoch: 558/1000, batch:   596/ 1052, ite: 146640] train loss: 0.004216, tar: 0.000091 
l0: 0.000070, l1: 0.000068, l2: 0.000147, l3: 0.000233, l4: 0.000486, l5: 0.001072, l6: 0.002448

[epoch: 558/1000, batch:   676/ 1052, ite: 146660] train loss: 0.004214, tar: 0.000091 
l0: 0.000011, l1: 0.000012, l2: 0.000026, l3: 0.000087, l4: 0.000376, l5: 0.001439, l6: 0.001277

[epoch: 558/1000, batch:   756/ 1052, ite: 146680] train loss: 0.004213, tar: 0.000091 
l0: 0.000084, l1: 0.000082, l2: 0.000115, l3: 0.000255, l4: 0.000735, l5: 0.001588, l6: 0.002403

[epoch: 558/1000, batch:   836/ 1052, ite: 146700] train loss: 0.004213, tar: 0.000091 
l0: 0.000054, l1: 0.000057, l2: 0.000091, l3: 0.000219, l4: 0.000728, l5: 0.001437, l6: 0.002216

[epoch: 558/1000, batch:   916/ 1052, ite: 146720] train loss: 0.004213, tar: 0.000091 
l0: 0.000177, l1: 0.000180, l2: 0.000239, l3: 0.000408, l4: 0.000494, l5: 0.001378, l6: 0.002456

[epoch: 558/1000, batch:   996/ 1052, ite: 146740] train loss: 0.004213, tar: 0.000091 
[Epoch 558/1000] Test loss: 0.016, Test target loss: 0.002
l0: 0.000354, l1: 0.000382, l2: 0.000256, l3: 0.000336, l4: 0.000560, l5: 0.001123, l6: 0.001934

[epoch: 559/1000, batch:    24/ 1052, ite: 146760] train loss: 0.004213, tar: 0.000091 
l0: 0.000027, l1: 0.000027, l2: 0.000041, l3: 0.000107, l4: 0.000313, l5: 0.000563, l6: 0.001024

[epoch: 559/1000, batch:   104/ 1052, ite: 146780] train loss: 0.004213, tar: 0.000091 
l0: 0.000127, l1: 0.000132, l2: 0.000144, l3: 0.000287, l4: 0.000515, l5: 0.001078, l6: 0.001751

[epoch: 559/1000, batch:   184/ 1052, ite: 146800] train loss: 0.004212, tar: 0.000091 
l0: 0.000046, l1: 0.000044, l2: 0.000101, l3: 0.000167, l4: 0.000350, l5: 0.000820, l6: 0.001125

[epoch: 559/1000, batch:   264/ 1052, ite: 146820] train loss: 0.004212, tar: 0.000091 
l0: 0.000146, l1: 0.000151, l2: 0.000182, l3: 0.000334, l4: 0.000917, l5: 0.002134, l6: 0.003697

[epoch: 559/1000, batch:   344/ 1052, ite: 146840] train loss: 0.004212, tar: 0.000091 
l0: 0.000087, l1: 0.000091, l2: 0.000128, l3: 0.000217, l4: 0.000547, l5: 0.001556, l6: 0.003074

[epoch: 559/1000, batch:   424/ 1052, ite: 146860] train loss: 0.004212, tar: 0.000091 
l0: 0.000027, l1: 0.000029, l2: 0.000055, l3: 0.000156, l4: 0.000351, l5: 0.000836, l6: 0.000914

[epoch: 559/1000, batch:   504/ 1052, ite: 146880] train loss: 0.004211, tar: 0.000091 
l0: 0.000033, l1: 0.000034, l2: 0.000058, l3: 0.000142, l4: 0.000418, l5: 0.000655, l6: 0.001465

[epoch: 559/1000, batch:   584/ 1052, ite: 146900] train loss: 0.004210, tar: 0.000091 
l0: 0.000131, l1: 0.000125, l2: 0.000262, l3: 0.000408, l4: 0.000747, l5: 0.001200, l6: 0.003155

[epoch: 559/1000, batch:   664/ 1052, ite: 146920] train loss: 0.004211, tar: 0.000091 
l0: 0.000149, l1: 0.000142, l2: 0.000134, l3: 0.000231, l4: 0.000445, l5: 0.000801, l6: 0.001548

[epoch: 559/1000, batch:   744/ 1052, ite: 146940] train loss: 0.004211, tar: 0.000091 
l0: 0.000021, l1: 0.000022, l2: 0.000048, l3: 0.000129, l4: 0.000307, l5: 0.000926, l6: 0.001368

[epoch: 559/1000, batch:   824/ 1052, ite: 146960] train loss: 0.004210, tar: 0.000091 
l0: 0.000033, l1: 0.000034, l2: 0.000056, l3: 0.000114, l4: 0.000443, l5: 0.001130, l6: 0.002217

[epoch: 559/1000, batch:   904/ 1052, ite: 146980] train loss: 0.004211, tar: 0.000091 
l0: 0.000019, l1: 0.000018, l2: 0.000039, l3: 0.000093, l4: 0.000368, l5: 0.000902, l6: 0.001253

[epoch: 559/1000, batch:   984/ 1052, ite: 147000] train loss: 0.004211, tar: 0.000091 
[Epoch 559/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000092, l1: 0.000091, l2: 0.000122, l3: 0.000191, l4: 0.000332, l5: 0.000690, l6: 0.002432

[epoch: 560/1000, batch:    12/ 1052, ite: 147020] train loss: 0.004210, tar: 0.000090 
l0: 0.000051, l1: 0.000052, l2: 0.000075, l3: 0.000205, l4: 0.000453, l5: 0.000950, l6: 0.001217

[epoch: 560/1000, batch:    92/ 1052, ite: 147040] train loss: 0.004209, tar: 0.000090 
l0: 0.000135, l1: 0.000137, l2: 0.000276, l3: 0.000381, l4: 0.000722, l5: 0.001285, l6: 0.002996

[epoch: 560/1000, batch:   172/ 1052, ite: 147060] train loss: 0.004209, tar: 0.000090 
l0: 0.000096, l1: 0.000093, l2: 0.000147, l3: 0.000259, l4: 0.000429, l5: 0.001389, l6: 0.001317

[epoch: 560/1000, batch:   252/ 1052, ite: 147080] train loss: 0.004209, tar: 0.000090 
l0: 0.000075, l1: 0.000076, l2: 0.000157, l3: 0.000345, l4: 0.000923, l5: 0.002071, l6: 0.002545

[epoch: 560/1000, batch:   332/ 1052, ite: 147100] train loss: 0.004209, tar: 0.000090 
l0: 0.000037, l1: 0.000035, l2: 0.000092, l3: 0.000194, l4: 0.000415, l5: 0.000852, l6: 0.001584

[epoch: 560/1000, batch:   412/ 1052, ite: 147120] train loss: 0.004208, tar: 0.000090 
l0: 0.000066, l1: 0.000069, l2: 0.000067, l3: 0.000158, l4: 0.000440, l5: 0.000673, l6: 0.001750

[epoch: 560/1000, batch:   492/ 1052, ite: 147140] train loss: 0.004208, tar: 0.000090 
l0: 0.000160, l1: 0.000173, l2: 0.000177, l3: 0.000290, l4: 0.000562, l5: 0.000882, l6: 0.003178

[epoch: 560/1000, batch:   572/ 1052, ite: 147160] train loss: 0.004208, tar: 0.000090 
l0: 0.000083, l1: 0.000089, l2: 0.000115, l3: 0.000188, l4: 0.000391, l5: 0.001169, l6: 0.002033

[epoch: 560/1000, batch:   652/ 1052, ite: 147180] train loss: 0.004208, tar: 0.000090 
l0: 0.000075, l1: 0.000082, l2: 0.000150, l3: 0.000201, l4: 0.000349, l5: 0.000975, l6: 0.001972

[epoch: 560/1000, batch:   732/ 1052, ite: 147200] train loss: 0.004209, tar: 0.000090 
l0: 0.000070, l1: 0.000068, l2: 0.000127, l3: 0.000160, l4: 0.000289, l5: 0.000743, l6: 0.001572

[epoch: 560/1000, batch:   812/ 1052, ite: 147220] train loss: 0.004209, tar: 0.000090 
l0: 0.000066, l1: 0.000064, l2: 0.000121, l3: 0.000254, l4: 0.000520, l5: 0.001115, l6: 0.001962

[epoch: 560/1000, batch:   892/ 1052, ite: 147240] train loss: 0.004209, tar: 0.000090 
l0: 0.000048, l1: 0.000050, l2: 0.000086, l3: 0.000146, l4: 0.000233, l5: 0.000616, l6: 0.001188

[epoch: 560/1000, batch:   972/ 1052, ite: 147260] train loss: 0.004209, tar: 0.000090 
l0: 0.000035, l1: 0.000033, l2: 0.000076, l3: 0.000155, l4: 0.000225, l5: 0.000727, l6: 0.001306

[epoch: 560/1000, batch:  1052/ 1052, ite: 147280] train loss: 0.004208, tar: 0.000090 
[Epoch 560/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000045, l1: 0.000045, l2: 0.000124, l3: 0.000268, l4: 0.000488, l5: 0.001072, l6: 0.002005

[epoch: 561/1000, batch:    80/ 1052, ite: 147300] train loss: 0.004156, tar: 0.000060 
l0: 0.000073, l1: 0.000076, l2: 0.000078, l3: 0.000140, l4: 0.000265, l5: 0.000850, l6: 0.002066

[epoch: 561/1000, batch:   160/ 1052, ite: 147320] train loss: 0.003850, tar: 0.000056 
l0: 0.000089, l1: 0.000093, l2: 0.000096, l3: 0.000160, l4: 0.000298, l5: 0.000592, l6: 0.001372

[epoch: 561/1000, batch:   240/ 1052, ite: 147340] train loss: 0.004058, tar: 0.000067 
l0: 0.000011, l1: 0.000012, l2: 0.000033, l3: 0.000088, l4: 0.000342, l5: 0.000509, l6: 0.001097

[epoch: 561/1000, batch:   320/ 1052, ite: 147360] train loss: 0.003988, tar: 0.000068 
l0: 0.000099, l1: 0.000100, l2: 0.000235, l3: 0.000425, l4: 0.000800, l5: 0.002475, l6: 0.004363

[epoch: 561/1000, batch:   400/ 1052, ite: 147380] train loss: 0.004020, tar: 0.000068 
l0: 0.000074, l1: 0.000075, l2: 0.000100, l3: 0.000138, l4: 0.000408, l5: 0.000513, l6: 0.001374

[epoch: 561/1000, batch:   480/ 1052, ite: 147400] train loss: 0.004025, tar: 0.000066 
l0: 0.000028, l1: 0.000030, l2: 0.000050, l3: 0.000184, l4: 0.000520, l5: 0.000559, l6: 0.001603

[epoch: 561/1000, batch:   560/ 1052, ite: 147420] train loss: 0.004038, tar: 0.000067 
l0: 0.000040, l1: 0.000040, l2: 0.000060, l3: 0.000116, l4: 0.000467, l5: 0.001126, l6: 0.002031

[epoch: 561/1000, batch:   640/ 1052, ite: 147440] train loss: 0.004007, tar: 0.000065 
l0: 0.000066, l1: 0.000065, l2: 0.000129, l3: 0.000270, l4: 0.000714, l5: 0.001442, l6: 0.002002

[epoch: 561/1000, batch:   720/ 1052, ite: 147460] train loss: 0.003987, tar: 0.000066 
l0: 0.000039, l1: 0.000038, l2: 0.000087, l3: 0.000204, l4: 0.000436, l5: 0.000792, l6: 0.001370

[epoch: 561/1000, batch:   800/ 1052, ite: 147480] train loss: 0.004003, tar: 0.000066 
l0: 0.000049, l1: 0.000050, l2: 0.000113, l3: 0.000211, l4: 0.000549, l5: 0.000994, l6: 0.002677

[epoch: 561/1000, batch:   880/ 1052, ite: 147500] train loss: 0.004068, tar: 0.000069 
l0: 0.000136, l1: 0.000143, l2: 0.000140, l3: 0.000197, l4: 0.000380, l5: 0.001318, l6: 0.001569

[epoch: 561/1000, batch:   960/ 1052, ite: 147520] train loss: 0.004094, tar: 0.000069 
l0: 0.000138, l1: 0.000138, l2: 0.000215, l3: 0.000429, l4: 0.000607, l5: 0.001748, l6: 0.002504

[epoch: 561/1000, batch:  1040/ 1052, ite: 147540] train loss: 0.004073, tar: 0.000069 
[Epoch 561/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000072, l1: 0.000069, l2: 0.000131, l3: 0.000245, l4: 0.000723, l5: 0.001591, l6: 0.002847

[epoch: 562/1000, batch:    68/ 1052, ite: 147560] train loss: 0.004060, tar: 0.000068 
l0: 0.000031, l1: 0.000029, l2: 0.000062, l3: 0.000172, l4: 0.000439, l5: 0.001056, l6: 0.001604

[epoch: 562/1000, batch:   148/ 1052, ite: 147580] train loss: 0.004093, tar: 0.000068 
l0: 0.000010, l1: 0.000011, l2: 0.000053, l3: 0.000138, l4: 0.000302, l5: 0.000672, l6: 0.001036

[epoch: 562/1000, batch:   228/ 1052, ite: 147600] train loss: 0.004107, tar: 0.000068 
l0: 0.000005, l1: 0.000005, l2: 0.000027, l3: 0.000090, l4: 0.000234, l5: 0.000444, l6: 0.001375

[epoch: 562/1000, batch:   308/ 1052, ite: 147620] train loss: 0.004116, tar: 0.000069 
l0: 0.000034, l1: 0.000032, l2: 0.000076, l3: 0.000169, l4: 0.000377, l5: 0.001073, l6: 0.002001

[epoch: 562/1000, batch:   388/ 1052, ite: 147640] train loss: 0.004064, tar: 0.000068 
l0: 0.000127, l1: 0.000129, l2: 0.000223, l3: 0.000377, l4: 0.000672, l5: 0.001655, l6: 0.003362

[epoch: 562/1000, batch:   468/ 1052, ite: 147660] train loss: 0.004034, tar: 0.000067 
l0: 0.000040, l1: 0.000045, l2: 0.000087, l3: 0.000262, l4: 0.000559, l5: 0.001787, l6: 0.002321

[epoch: 562/1000, batch:   548/ 1052, ite: 147680] train loss: 0.004039, tar: 0.000068 
l0: 0.000036, l1: 0.000036, l2: 0.000036, l3: 0.000118, l4: 0.000301, l5: 0.000872, l6: 0.001201

[epoch: 562/1000, batch:   628/ 1052, ite: 147700] train loss: 0.004073, tar: 0.000069 
l0: 0.000143, l1: 0.000141, l2: 0.000247, l3: 0.000476, l4: 0.000794, l5: 0.001315, l6: 0.001976

[epoch: 562/1000, batch:   708/ 1052, ite: 147720] train loss: 0.004067, tar: 0.000069 
l0: 0.000073, l1: 0.000071, l2: 0.000101, l3: 0.000148, l4: 0.000373, l5: 0.000959, l6: 0.001780

[epoch: 562/1000, batch:   788/ 1052, ite: 147740] train loss: 0.004076, tar: 0.000069 
l0: 0.000085, l1: 0.000080, l2: 0.000173, l3: 0.000257, l4: 0.000590, l5: 0.000794, l6: 0.001206

[epoch: 562/1000, batch:   868/ 1052, ite: 147760] train loss: 0.004065, tar: 0.000068 
l0: 0.000043, l1: 0.000045, l2: 0.000097, l3: 0.000218, l4: 0.000405, l5: 0.000866, l6: 0.001280

[epoch: 562/1000, batch:   948/ 1052, ite: 147780] train loss: 0.004073, tar: 0.000069 
l0: 0.000151, l1: 0.000149, l2: 0.000195, l3: 0.000286, l4: 0.000718, l5: 0.001784, l6: 0.002434

[epoch: 562/1000, batch:  1028/ 1052, ite: 147800] train loss: 0.004069, tar: 0.000069 
[Epoch 562/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000061, l1: 0.000056, l2: 0.000134, l3: 0.000298, l4: 0.000789, l5: 0.001182, l6: 0.002012

[epoch: 563/1000, batch:    56/ 1052, ite: 147820] train loss: 0.004069, tar: 0.000069 
l0: 0.000043, l1: 0.000044, l2: 0.000054, l3: 0.000131, l4: 0.000304, l5: 0.000918, l6: 0.001628

[epoch: 563/1000, batch:   136/ 1052, ite: 147840] train loss: 0.004068, tar: 0.000068 
l0: 0.000101, l1: 0.000098, l2: 0.000101, l3: 0.000150, l4: 0.000485, l5: 0.000638, l6: 0.000988

[epoch: 563/1000, batch:   216/ 1052, ite: 147860] train loss: 0.004061, tar: 0.000069 
l0: 0.000031, l1: 0.000033, l2: 0.000092, l3: 0.000173, l4: 0.000403, l5: 0.001229, l6: 0.000846

[epoch: 563/1000, batch:   296/ 1052, ite: 147880] train loss: 0.004043, tar: 0.000069 
l0: 0.000035, l1: 0.000036, l2: 0.000061, l3: 0.000116, l4: 0.000217, l5: 0.000882, l6: 0.000907

[epoch: 563/1000, batch:   376/ 1052, ite: 147900] train loss: 0.004044, tar: 0.000069 
l0: 0.000157, l1: 0.000161, l2: 0.000221, l3: 0.000364, l4: 0.000532, l5: 0.001212, l6: 0.002672

[epoch: 563/1000, batch:   456/ 1052, ite: 147920] train loss: 0.004052, tar: 0.000069 
l0: 0.000073, l1: 0.000075, l2: 0.000127, l3: 0.000293, l4: 0.000648, l5: 0.000904, l6: 0.001794

[epoch: 563/1000, batch:   536/ 1052, ite: 147940] train loss: 0.004077, tar: 0.000070 
l0: 0.000016, l1: 0.000016, l2: 0.000043, l3: 0.000125, l4: 0.000331, l5: 0.000997, l6: 0.001454

[epoch: 563/1000, batch:   616/ 1052, ite: 147960] train loss: 0.004083, tar: 0.000070 
l0: 0.000089, l1: 0.000092, l2: 0.000146, l3: 0.000268, l4: 0.000541, l5: 0.001216, l6: 0.003889

[epoch: 563/1000, batch:   696/ 1052, ite: 147980] train loss: 0.004088, tar: 0.000069 
l0: 0.000020, l1: 0.000021, l2: 0.000056, l3: 0.000194, l4: 0.000344, l5: 0.000866, l6: 0.001256

[epoch: 563/1000, batch:   776/ 1052, ite: 148000] train loss: 0.004084, tar: 0.000069 
l0: 0.000027, l1: 0.000027, l2: 0.000100, l3: 0.000255, l4: 0.000712, l5: 0.000963, l6: 0.002326

[epoch: 563/1000, batch:   856/ 1052, ite: 148020] train loss: 0.004090, tar: 0.000069 
l0: 0.000021, l1: 0.000022, l2: 0.000044, l3: 0.000171, l4: 0.000344, l5: 0.000823, l6: 0.001428

[epoch: 563/1000, batch:   936/ 1052, ite: 148040] train loss: 0.004079, tar: 0.000069 
l0: 0.000113, l1: 0.000109, l2: 0.000146, l3: 0.000284, l4: 0.000522, l5: 0.001642, l6: 0.003150

[epoch: 563/1000, batch:  1016/ 1052, ite: 148060] train loss: 0.004077, tar: 0.000069 
[Epoch 563/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000019, l1: 0.000019, l2: 0.000085, l3: 0.000174, l4: 0.000452, l5: 0.000922, l6: 0.002464

[epoch: 564/1000, batch:    44/ 1052, ite: 148080] train loss: 0.004075, tar: 0.000068 
l0: 0.000040, l1: 0.000040, l2: 0.000050, l3: 0.000122, l4: 0.000294, l5: 0.000568, l6: 0.001036

[epoch: 564/1000, batch:   124/ 1052, ite: 148100] train loss: 0.004072, tar: 0.000068 
l0: 0.000055, l1: 0.000056, l2: 0.000102, l3: 0.000207, l4: 0.000464, l5: 0.001111, l6: 0.002704

[epoch: 564/1000, batch:   204/ 1052, ite: 148120] train loss: 0.004085, tar: 0.000069 
l0: 0.000447, l1: 0.000445, l2: 0.000409, l3: 0.000519, l4: 0.000754, l5: 0.001355, l6: 0.002059

[epoch: 564/1000, batch:   284/ 1052, ite: 148140] train loss: 0.004089, tar: 0.000070 
l0: 0.000068, l1: 0.000066, l2: 0.000154, l3: 0.000408, l4: 0.000792, l5: 0.001566, l6: 0.002947

[epoch: 564/1000, batch:   364/ 1052, ite: 148160] train loss: 0.004086, tar: 0.000070 
l0: 0.000118, l1: 0.000122, l2: 0.000157, l3: 0.000257, l4: 0.000455, l5: 0.001146, l6: 0.001795

[epoch: 564/1000, batch:   444/ 1052, ite: 148180] train loss: 0.004072, tar: 0.000070 
l0: 0.000157, l1: 0.000158, l2: 0.000242, l3: 0.000379, l4: 0.000900, l5: 0.001361, l6: 0.003722

[epoch: 564/1000, batch:   524/ 1052, ite: 148200] train loss: 0.004088, tar: 0.000070 
l0: 0.000035, l1: 0.000034, l2: 0.000059, l3: 0.000121, l4: 0.000338, l5: 0.000608, l6: 0.001511

[epoch: 564/1000, batch:   604/ 1052, ite: 148220] train loss: 0.004080, tar: 0.000070 
l0: 0.000095, l1: 0.000096, l2: 0.000145, l3: 0.000259, l4: 0.000699, l5: 0.001560, l6: 0.003192

[epoch: 564/1000, batch:   684/ 1052, ite: 148240] train loss: 0.004076, tar: 0.000069 
l0: 0.000032, l1: 0.000035, l2: 0.000039, l3: 0.000096, l4: 0.000216, l5: 0.000615, l6: 0.000718

[epoch: 564/1000, batch:   764/ 1052, ite: 148260] train loss: 0.004066, tar: 0.000070 
l0: 0.000010, l1: 0.000010, l2: 0.000045, l3: 0.000129, l4: 0.000249, l5: 0.000688, l6: 0.001702

[epoch: 564/1000, batch:   844/ 1052, ite: 148280] train loss: 0.004077, tar: 0.000070 
l0: 0.000029, l1: 0.000028, l2: 0.000058, l3: 0.000187, l4: 0.000376, l5: 0.001314, l6: 0.002361

[epoch: 564/1000, batch:   924/ 1052, ite: 148300] train loss: 0.004075, tar: 0.000069 
l0: 0.000052, l1: 0.000053, l2: 0.000090, l3: 0.000189, l4: 0.000345, l5: 0.001571, l6: 0.002952

[epoch: 564/1000, batch:  1004/ 1052, ite: 148320] train loss: 0.004073, tar: 0.000069 
[Epoch 564/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000125, l1: 0.000123, l2: 0.000173, l3: 0.000307, l4: 0.000696, l5: 0.001198, l6: 0.001902

[epoch: 565/1000, batch:    32/ 1052, ite: 148340] train loss: 0.004082, tar: 0.000070 
l0: 0.000041, l1: 0.000041, l2: 0.000072, l3: 0.000126, l4: 0.000347, l5: 0.001357, l6: 0.001314

[epoch: 565/1000, batch:   112/ 1052, ite: 148360] train loss: 0.004076, tar: 0.000070 
l0: 0.000034, l1: 0.000034, l2: 0.000086, l3: 0.000213, l4: 0.000452, l5: 0.001146, l6: 0.001924

[epoch: 565/1000, batch:   192/ 1052, ite: 148380] train loss: 0.004076, tar: 0.000070 
l0: 0.000067, l1: 0.000069, l2: 0.000116, l3: 0.000225, l4: 0.000349, l5: 0.000905, l6: 0.001037

[epoch: 565/1000, batch:   272/ 1052, ite: 148400] train loss: 0.004081, tar: 0.000069 
l0: 0.000043, l1: 0.000041, l2: 0.000068, l3: 0.000144, l4: 0.000392, l5: 0.000914, l6: 0.001038

[epoch: 565/1000, batch:   352/ 1052, ite: 148420] train loss: 0.004093, tar: 0.000070 
l0: 0.000112, l1: 0.000122, l2: 0.000158, l3: 0.000233, l4: 0.000369, l5: 0.000735, l6: 0.001257

[epoch: 565/1000, batch:   432/ 1052, ite: 148440] train loss: 0.004093, tar: 0.000069 
l0: 0.000031, l1: 0.000030, l2: 0.000133, l3: 0.000240, l4: 0.000552, l5: 0.000864, l6: 0.001529

[epoch: 565/1000, batch:   512/ 1052, ite: 148460] train loss: 0.004092, tar: 0.000069 
l0: 0.000039, l1: 0.000037, l2: 0.000064, l3: 0.000157, l4: 0.000295, l5: 0.000708, l6: 0.001782

[epoch: 565/1000, batch:   592/ 1052, ite: 148480] train loss: 0.004083, tar: 0.000069 
l0: 0.000051, l1: 0.000054, l2: 0.000067, l3: 0.000149, l4: 0.000345, l5: 0.000958, l6: 0.001520

[epoch: 565/1000, batch:   672/ 1052, ite: 148500] train loss: 0.004085, tar: 0.000070 
l0: 0.000093, l1: 0.000093, l2: 0.000101, l3: 0.000234, l4: 0.000598, l5: 0.001294, l6: 0.002818

[epoch: 565/1000, batch:   752/ 1052, ite: 148520] train loss: 0.004095, tar: 0.000070 
l0: 0.000303, l1: 0.000304, l2: 0.000294, l3: 0.000383, l4: 0.000640, l5: 0.001624, l6: 0.002203

[epoch: 565/1000, batch:   832/ 1052, ite: 148540] train loss: 0.004096, tar: 0.000070 
l0: 0.000062, l1: 0.000063, l2: 0.000135, l3: 0.000190, l4: 0.000594, l5: 0.000806, l6: 0.001741

[epoch: 565/1000, batch:   912/ 1052, ite: 148560] train loss: 0.004090, tar: 0.000070 
l0: 0.000092, l1: 0.000090, l2: 0.000177, l3: 0.000387, l4: 0.000617, l5: 0.000983, l6: 0.001562

[epoch: 565/1000, batch:   992/ 1052, ite: 148580] train loss: 0.004089, tar: 0.000070 
[Epoch 565/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000040, l1: 0.000041, l2: 0.000103, l3: 0.000409, l4: 0.000846, l5: 0.001713, l6: 0.002830

[epoch: 566/1000, batch:    20/ 1052, ite: 148600] train loss: 0.004088, tar: 0.000070 
l0: 0.000065, l1: 0.000061, l2: 0.000086, l3: 0.000147, l4: 0.000364, l5: 0.000862, l6: 0.002061

[epoch: 566/1000, batch:   100/ 1052, ite: 148620] train loss: 0.004085, tar: 0.000070 
l0: 0.000042, l1: 0.000043, l2: 0.000096, l3: 0.000187, l4: 0.000365, l5: 0.000800, l6: 0.002590

[epoch: 566/1000, batch:   180/ 1052, ite: 148640] train loss: 0.004082, tar: 0.000070 
l0: 0.000034, l1: 0.000034, l2: 0.000116, l3: 0.000171, l4: 0.000372, l5: 0.001003, l6: 0.001147

[epoch: 566/1000, batch:   260/ 1052, ite: 148660] train loss: 0.004085, tar: 0.000069 
l0: 0.000015, l1: 0.000015, l2: 0.000062, l3: 0.000190, l4: 0.000464, l5: 0.000662, l6: 0.001869

[epoch: 566/1000, batch:   340/ 1052, ite: 148680] train loss: 0.004083, tar: 0.000069 
l0: 0.000015, l1: 0.000015, l2: 0.000051, l3: 0.000104, l4: 0.000327, l5: 0.000510, l6: 0.000657

[epoch: 566/1000, batch:   420/ 1052, ite: 148700] train loss: 0.004086, tar: 0.000069 
l0: 0.000054, l1: 0.000054, l2: 0.000101, l3: 0.000418, l4: 0.000572, l5: 0.001134, l6: 0.001935

[epoch: 566/1000, batch:   500/ 1052, ite: 148720] train loss: 0.004091, tar: 0.000070 
l0: 0.000083, l1: 0.000085, l2: 0.000109, l3: 0.000203, l4: 0.000313, l5: 0.001270, l6: 0.002094

[epoch: 566/1000, batch:   580/ 1052, ite: 148740] train loss: 0.004091, tar: 0.000070 
l0: 0.000039, l1: 0.000042, l2: 0.000072, l3: 0.000216, l4: 0.000494, l5: 0.001057, l6: 0.001428

[epoch: 566/1000, batch:   660/ 1052, ite: 148760] train loss: 0.004090, tar: 0.000070 
l0: 0.000041, l1: 0.000040, l2: 0.000092, l3: 0.000279, l4: 0.000451, l5: 0.001173, l6: 0.002193

[epoch: 566/1000, batch:   740/ 1052, ite: 148780] train loss: 0.004087, tar: 0.000069 
l0: 0.000056, l1: 0.000058, l2: 0.000081, l3: 0.000093, l4: 0.000458, l5: 0.000864, l6: 0.001671

[epoch: 566/1000, batch:   820/ 1052, ite: 148800] train loss: 0.004087, tar: 0.000069 
l0: 0.000034, l1: 0.000033, l2: 0.000093, l3: 0.000205, l4: 0.000498, l5: 0.001061, l6: 0.001734

[epoch: 566/1000, batch:   900/ 1052, ite: 148820] train loss: 0.004088, tar: 0.000070 
l0: 0.000049, l1: 0.000050, l2: 0.000082, l3: 0.000148, l4: 0.000301, l5: 0.001171, l6: 0.001439

[epoch: 566/1000, batch:   980/ 1052, ite: 148840] train loss: 0.004096, tar: 0.000070 
[Epoch 566/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000092, l1: 0.000093, l2: 0.000147, l3: 0.000284, l4: 0.000594, l5: 0.002193, l6: 0.002926

[epoch: 567/1000, batch:     8/ 1052, ite: 148860] train loss: 0.004096, tar: 0.000070 
l0: 0.000044, l1: 0.000044, l2: 0.000090, l3: 0.000215, l4: 0.000368, l5: 0.001286, l6: 0.002208

[epoch: 567/1000, batch:    88/ 1052, ite: 148880] train loss: 0.004087, tar: 0.000070 
l0: 0.000053, l1: 0.000051, l2: 0.000072, l3: 0.000126, l4: 0.000391, l5: 0.000878, l6: 0.001496

[epoch: 567/1000, batch:   168/ 1052, ite: 148900] train loss: 0.004089, tar: 0.000070 
l0: 0.000041, l1: 0.000043, l2: 0.000076, l3: 0.000107, l4: 0.000321, l5: 0.000470, l6: 0.001350

[epoch: 567/1000, batch:   248/ 1052, ite: 148920] train loss: 0.004090, tar: 0.000070 
l0: 0.000017, l1: 0.000018, l2: 0.000043, l3: 0.000172, l4: 0.000431, l5: 0.000900, l6: 0.001180

[epoch: 567/1000, batch:   328/ 1052, ite: 148940] train loss: 0.004092, tar: 0.000070 
l0: 0.000266, l1: 0.000267, l2: 0.000283, l3: 0.000409, l4: 0.001157, l5: 0.002007, l6: 0.003284

[epoch: 567/1000, batch:   408/ 1052, ite: 148960] train loss: 0.004094, tar: 0.000070 
l0: 0.000072, l1: 0.000075, l2: 0.000155, l3: 0.000237, l4: 0.000407, l5: 0.000892, l6: 0.002541

[epoch: 567/1000, batch:   488/ 1052, ite: 148980] train loss: 0.004098, tar: 0.000070 
l0: 0.000158, l1: 0.000161, l2: 0.000213, l3: 0.000291, l4: 0.000424, l5: 0.001005, l6: 0.003356

[epoch: 567/1000, batch:   568/ 1052, ite: 149000] train loss: 0.004101, tar: 0.000070 
l0: 0.000094, l1: 0.000093, l2: 0.000120, l3: 0.000152, l4: 0.000636, l5: 0.001262, l6: 0.002368

[epoch: 567/1000, batch:   648/ 1052, ite: 149020] train loss: 0.004108, tar: 0.000070 
l0: 0.000036, l1: 0.000036, l2: 0.000049, l3: 0.000081, l4: 0.000211, l5: 0.000478, l6: 0.000592

[epoch: 567/1000, batch:   728/ 1052, ite: 149040] train loss: 0.004103, tar: 0.000070 
l0: 0.000120, l1: 0.000120, l2: 0.000158, l3: 0.000277, l4: 0.000471, l5: 0.001178, l6: 0.002539

[epoch: 567/1000, batch:   808/ 1052, ite: 149060] train loss: 0.004102, tar: 0.000070 
l0: 0.000089, l1: 0.000089, l2: 0.000105, l3: 0.000181, l4: 0.000262, l5: 0.000915, l6: 0.001621

[epoch: 567/1000, batch:   888/ 1052, ite: 149080] train loss: 0.004105, tar: 0.000070 
l0: 0.000108, l1: 0.000108, l2: 0.000133, l3: 0.000179, l4: 0.000323, l5: 0.001072, l6: 0.002128

[epoch: 567/1000, batch:   968/ 1052, ite: 149100] train loss: 0.004107, tar: 0.000070 
l0: 0.000071, l1: 0.000071, l2: 0.000102, l3: 0.000161, l4: 0.000312, l5: 0.000543, l6: 0.001059

[epoch: 567/1000, batch:  1048/ 1052, ite: 149120] train loss: 0.004103, tar: 0.000070 
[Epoch 567/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000034, l1: 0.000034, l2: 0.000085, l3: 0.000217, l4: 0.000314, l5: 0.001225, l6: 0.002045

[epoch: 568/1000, batch:    76/ 1052, ite: 149140] train loss: 0.004101, tar: 0.000070 
l0: 0.000017, l1: 0.000019, l2: 0.000060, l3: 0.000157, l4: 0.000493, l5: 0.000607, l6: 0.001491

[epoch: 568/1000, batch:   156/ 1052, ite: 149160] train loss: 0.004102, tar: 0.000070 
l0: 0.000044, l1: 0.000043, l2: 0.000077, l3: 0.000158, l4: 0.000422, l5: 0.000810, l6: 0.001219

[epoch: 568/1000, batch:   236/ 1052, ite: 149180] train loss: 0.004095, tar: 0.000070 
l0: 0.000036, l1: 0.000039, l2: 0.000040, l3: 0.000103, l4: 0.000174, l5: 0.000421, l6: 0.000794

[epoch: 568/1000, batch:   316/ 1052, ite: 149200] train loss: 0.004092, tar: 0.000070 
l0: 0.000022, l1: 0.000023, l2: 0.000075, l3: 0.000169, l4: 0.000434, l5: 0.001035, l6: 0.001486

[epoch: 568/1000, batch:   396/ 1052, ite: 149220] train loss: 0.004092, tar: 0.000070 
l0: 0.000022, l1: 0.000022, l2: 0.000062, l3: 0.000127, l4: 0.000282, l5: 0.000998, l6: 0.001834

[epoch: 568/1000, batch:   476/ 1052, ite: 149240] train loss: 0.004094, tar: 0.000070 
l0: 0.000049, l1: 0.000052, l2: 0.000112, l3: 0.000235, l4: 0.000409, l5: 0.000959, l6: 0.002039

[epoch: 568/1000, batch:   556/ 1052, ite: 149260] train loss: 0.004096, tar: 0.000070 
l0: 0.000033, l1: 0.000032, l2: 0.000049, l3: 0.000180, l4: 0.000344, l5: 0.000768, l6: 0.002022

[epoch: 568/1000, batch:   636/ 1052, ite: 149280] train loss: 0.004098, tar: 0.000070 
l0: 0.000093, l1: 0.000092, l2: 0.000116, l3: 0.000252, l4: 0.000362, l5: 0.000612, l6: 0.002044

[epoch: 568/1000, batch:   716/ 1052, ite: 149300] train loss: 0.004098, tar: 0.000070 
l0: 0.000047, l1: 0.000045, l2: 0.000114, l3: 0.000264, l4: 0.000559, l5: 0.000880, l6: 0.002295

[epoch: 568/1000, batch:   796/ 1052, ite: 149320] train loss: 0.004099, tar: 0.000070 
l0: 0.000059, l1: 0.000060, l2: 0.000114, l3: 0.000340, l4: 0.000547, l5: 0.001344, l6: 0.002357

[epoch: 568/1000, batch:   876/ 1052, ite: 149340] train loss: 0.004100, tar: 0.000070 
l0: 0.000051, l1: 0.000046, l2: 0.000100, l3: 0.000198, l4: 0.000466, l5: 0.000838, l6: 0.001641

[epoch: 568/1000, batch:   956/ 1052, ite: 149360] train loss: 0.004105, tar: 0.000070 
l0: 0.000160, l1: 0.000158, l2: 0.000189, l3: 0.000316, l4: 0.000784, l5: 0.002092, l6: 0.002785

[epoch: 568/1000, batch:  1036/ 1052, ite: 149380] train loss: 0.004103, tar: 0.000070 
[Epoch 568/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000091, l1: 0.000091, l2: 0.000127, l3: 0.000224, l4: 0.000483, l5: 0.001233, l6: 0.002682

[epoch: 569/1000, batch:    64/ 1052, ite: 149400] train loss: 0.004102, tar: 0.000070 
l0: 0.000017, l1: 0.000017, l2: 0.000049, l3: 0.000138, l4: 0.000431, l5: 0.000955, l6: 0.001840

[epoch: 569/1000, batch:   144/ 1052, ite: 149420] train loss: 0.004101, tar: 0.000070 
l0: 0.000049, l1: 0.000050, l2: 0.000086, l3: 0.000307, l4: 0.000607, l5: 0.001241, l6: 0.002187

[epoch: 569/1000, batch:   224/ 1052, ite: 149440] train loss: 0.004099, tar: 0.000070 
l0: 0.000046, l1: 0.000046, l2: 0.000130, l3: 0.000186, l4: 0.000396, l5: 0.001028, l6: 0.001881

[epoch: 569/1000, batch:   304/ 1052, ite: 149460] train loss: 0.004100, tar: 0.000070 
l0: 0.000065, l1: 0.000069, l2: 0.000138, l3: 0.000280, l4: 0.000588, l5: 0.001696, l6: 0.002133

[epoch: 569/1000, batch:   384/ 1052, ite: 149480] train loss: 0.004098, tar: 0.000070 
l0: 0.000110, l1: 0.000105, l2: 0.000167, l3: 0.000303, l4: 0.000797, l5: 0.001196, l6: 0.002669

[epoch: 569/1000, batch:   464/ 1052, ite: 149500] train loss: 0.004105, tar: 0.000070 
l0: 0.000082, l1: 0.000092, l2: 0.000094, l3: 0.000135, l4: 0.000277, l5: 0.000855, l6: 0.001952

[epoch: 569/1000, batch:   544/ 1052, ite: 149520] train loss: 0.004105, tar: 0.000070 
l0: 0.000072, l1: 0.000075, l2: 0.000092, l3: 0.000139, l4: 0.000422, l5: 0.000648, l6: 0.001532

[epoch: 569/1000, batch:   624/ 1052, ite: 149540] train loss: 0.004105, tar: 0.000070 
l0: 0.000043, l1: 0.000043, l2: 0.000094, l3: 0.000177, l4: 0.000371, l5: 0.000870, l6: 0.002027

[epoch: 569/1000, batch:   704/ 1052, ite: 149560] train loss: 0.004103, tar: 0.000070 
l0: 0.000060, l1: 0.000059, l2: 0.000097, l3: 0.000159, l4: 0.000409, l5: 0.000849, l6: 0.001961

[epoch: 569/1000, batch:   784/ 1052, ite: 149580] train loss: 0.004105, tar: 0.000071 
l0: 0.000067, l1: 0.000066, l2: 0.000142, l3: 0.000410, l4: 0.000739, l5: 0.001250, l6: 0.001683

[epoch: 569/1000, batch:   864/ 1052, ite: 149600] train loss: 0.004108, tar: 0.000071 
l0: 0.000048, l1: 0.000049, l2: 0.000120, l3: 0.000198, l4: 0.000502, l5: 0.001277, l6: 0.001684

[epoch: 569/1000, batch:   944/ 1052, ite: 149620] train loss: 0.004110, tar: 0.000071 
l0: 0.000086, l1: 0.000084, l2: 0.000132, l3: 0.000182, l4: 0.000317, l5: 0.000851, l6: 0.001412

[epoch: 569/1000, batch:  1024/ 1052, ite: 149640] train loss: 0.004110, tar: 0.000072 
[Epoch 569/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000024, l1: 0.000021, l2: 0.000058, l3: 0.000151, l4: 0.000341, l5: 0.000852, l6: 0.001355

[epoch: 570/1000, batch:    52/ 1052, ite: 149660] train loss: 0.004111, tar: 0.000072 
l0: 0.000142, l1: 0.000147, l2: 0.000219, l3: 0.000450, l4: 0.000727, l5: 0.001817, l6: 0.002937

[epoch: 570/1000, batch:   132/ 1052, ite: 149680] train loss: 0.004112, tar: 0.000072 
l0: 0.000043, l1: 0.000041, l2: 0.000118, l3: 0.000331, l4: 0.000898, l5: 0.001349, l6: 0.002622

[epoch: 570/1000, batch:   212/ 1052, ite: 149700] train loss: 0.004115, tar: 0.000072 
l0: 0.000040, l1: 0.000041, l2: 0.000075, l3: 0.000158, l4: 0.000396, l5: 0.000739, l6: 0.001473

[epoch: 570/1000, batch:   292/ 1052, ite: 149720] train loss: 0.004115, tar: 0.000072 
l0: 0.000020, l1: 0.000018, l2: 0.000055, l3: 0.000191, l4: 0.000545, l5: 0.001388, l6: 0.001921

[epoch: 570/1000, batch:   372/ 1052, ite: 149740] train loss: 0.004112, tar: 0.000072 
l0: 0.000150, l1: 0.000157, l2: 0.000150, l3: 0.000172, l4: 0.000369, l5: 0.000730, l6: 0.001237

[epoch: 570/1000, batch:   452/ 1052, ite: 149760] train loss: 0.004115, tar: 0.000074 
l0: 0.000081, l1: 0.000086, l2: 0.000094, l3: 0.000154, l4: 0.000438, l5: 0.000525, l6: 0.001041

[epoch: 570/1000, batch:   532/ 1052, ite: 149780] train loss: 0.004130, tar: 0.000076 
l0: 0.000534, l1: 0.000596, l2: 0.000587, l3: 0.000642, l4: 0.001256, l5: 0.002523, l6: 0.003151

[epoch: 570/1000, batch:   612/ 1052, ite: 149800] train loss: 0.004138, tar: 0.000077 
l0: 0.000217, l1: 0.000228, l2: 0.000292, l3: 0.000422, l4: 0.000810, l5: 0.001286, l6: 0.001719

[epoch: 570/1000, batch:   692/ 1052, ite: 149820] train loss: 0.004144, tar: 0.000078 
l0: 0.000055, l1: 0.000051, l2: 0.000085, l3: 0.000136, l4: 0.000264, l5: 0.000632, l6: 0.001074

[epoch: 570/1000, batch:   772/ 1052, ite: 149840] train loss: 0.004145, tar: 0.000078 
l0: 0.000180, l1: 0.000175, l2: 0.000272, l3: 0.000348, l4: 0.000509, l5: 0.000856, l6: 0.001315

[epoch: 570/1000, batch:   852/ 1052, ite: 149860] train loss: 0.004145, tar: 0.000079 
l0: 0.000106, l1: 0.000105, l2: 0.000149, l3: 0.000251, l4: 0.000577, l5: 0.001327, l6: 0.002102

[epoch: 570/1000, batch:   932/ 1052, ite: 149880] train loss: 0.004148, tar: 0.000079 
l0: 0.000031, l1: 0.000028, l2: 0.000059, l3: 0.000161, l4: 0.000293, l5: 0.000829, l6: 0.001079

[epoch: 570/1000, batch:  1012/ 1052, ite: 149900] train loss: 0.004146, tar: 0.000079 
[Epoch 570/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000078, l1: 0.000073, l2: 0.000131, l3: 0.000207, l4: 0.000462, l5: 0.000666, l6: 0.002118

[epoch: 571/1000, batch:    40/ 1052, ite: 149920] train loss: 0.004150, tar: 0.000080 
l0: 0.000056, l1: 0.000060, l2: 0.000086, l3: 0.000154, l4: 0.000202, l5: 0.000752, l6: 0.001024

[epoch: 571/1000, batch:   120/ 1052, ite: 149940] train loss: 0.004152, tar: 0.000080 
l0: 0.000125, l1: 0.000123, l2: 0.000162, l3: 0.000259, l4: 0.000448, l5: 0.001000, l6: 0.002325

[epoch: 571/1000, batch:   200/ 1052, ite: 149960] train loss: 0.004155, tar: 0.000081 
l0: 0.000132, l1: 0.000137, l2: 0.000201, l3: 0.000265, l4: 0.000746, l5: 0.002016, l6: 0.002765

[epoch: 571/1000, batch:   280/ 1052, ite: 149980] train loss: 0.004157, tar: 0.000081 
l0: 0.000142, l1: 0.000140, l2: 0.000253, l3: 0.000506, l4: 0.000878, l5: 0.001675, l6: 0.002801

[epoch: 571/1000, batch:   360/ 1052, ite: 150000] train loss: 0.004157, tar: 0.000081 
l0: 0.000099, l1: 0.000095, l2: 0.000163, l3: 0.000195, l4: 0.000396, l5: 0.001118, l6: 0.001026

[epoch: 571/1000, batch:   440/ 1052, ite: 150020] train loss: 0.004162, tar: 0.000081 
l0: 0.000230, l1: 0.000244, l2: 0.000259, l3: 0.000381, l4: 0.000662, l5: 0.001351, l6: 0.002363

[epoch: 571/1000, batch:   520/ 1052, ite: 150040] train loss: 0.004160, tar: 0.000081 
l0: 0.000034, l1: 0.000028, l2: 0.000139, l3: 0.000241, l4: 0.000433, l5: 0.001123, l6: 0.002220

[epoch: 571/1000, batch:   600/ 1052, ite: 150060] train loss: 0.004158, tar: 0.000081 
l0: 0.000057, l1: 0.000059, l2: 0.000071, l3: 0.000096, l4: 0.000305, l5: 0.000682, l6: 0.001085

[epoch: 571/1000, batch:   680/ 1052, ite: 150080] train loss: 0.004157, tar: 0.000081 
l0: 0.000074, l1: 0.000070, l2: 0.000128, l3: 0.000240, l4: 0.000558, l5: 0.001671, l6: 0.002603

[epoch: 571/1000, batch:   760/ 1052, ite: 150100] train loss: 0.004158, tar: 0.000081 
l0: 0.000030, l1: 0.000028, l2: 0.000055, l3: 0.000130, l4: 0.000354, l5: 0.001159, l6: 0.001850

[epoch: 571/1000, batch:   840/ 1052, ite: 150120] train loss: 0.004159, tar: 0.000081 
l0: 0.000033, l1: 0.000036, l2: 0.000077, l3: 0.000160, l4: 0.000672, l5: 0.000855, l6: 0.001984

[epoch: 571/1000, batch:   920/ 1052, ite: 150140] train loss: 0.004157, tar: 0.000081 
l0: 0.000025, l1: 0.000024, l2: 0.000070, l3: 0.000155, l4: 0.000373, l5: 0.001168, l6: 0.001549

[epoch: 571/1000, batch:  1000/ 1052, ite: 150160] train loss: 0.004155, tar: 0.000081 
[Epoch 571/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000103, l1: 0.000113, l2: 0.000128, l3: 0.000220, l4: 0.000419, l5: 0.001073, l6: 0.002489

[epoch: 572/1000, batch:    28/ 1052, ite: 150180] train loss: 0.004157, tar: 0.000081 
l0: 0.000043, l1: 0.000042, l2: 0.000066, l3: 0.000158, l4: 0.000242, l5: 0.000780, l6: 0.001295

[epoch: 572/1000, batch:   108/ 1052, ite: 150200] train loss: 0.004157, tar: 0.000081 
l0: 0.000026, l1: 0.000028, l2: 0.000054, l3: 0.000151, l4: 0.000340, l5: 0.001031, l6: 0.001613

[epoch: 572/1000, batch:   188/ 1052, ite: 150220] train loss: 0.004156, tar: 0.000081 
l0: 0.000042, l1: 0.000043, l2: 0.000103, l3: 0.000281, l4: 0.000548, l5: 0.000860, l6: 0.002054

[epoch: 572/1000, batch:   268/ 1052, ite: 150240] train loss: 0.004158, tar: 0.000081 
l0: 0.000089, l1: 0.000094, l2: 0.000131, l3: 0.000233, l4: 0.000611, l5: 0.001437, l6: 0.002501

[epoch: 572/1000, batch:   348/ 1052, ite: 150260] train loss: 0.004156, tar: 0.000081 
l0: 0.000229, l1: 0.000223, l2: 0.000355, l3: 0.000512, l4: 0.000944, l5: 0.001901, l6: 0.003129

[epoch: 572/1000, batch:   428/ 1052, ite: 150280] train loss: 0.004156, tar: 0.000081 
l0: 0.000027, l1: 0.000027, l2: 0.000078, l3: 0.000186, l4: 0.000351, l5: 0.000834, l6: 0.001268

[epoch: 572/1000, batch:   508/ 1052, ite: 150300] train loss: 0.004160, tar: 0.000081 
l0: 0.000027, l1: 0.000027, l2: 0.000059, l3: 0.000140, l4: 0.000270, l5: 0.000885, l6: 0.001973

[epoch: 572/1000, batch:   588/ 1052, ite: 150320] train loss: 0.004157, tar: 0.000081 
l0: 0.000064, l1: 0.000065, l2: 0.000122, l3: 0.000321, l4: 0.000668, l5: 0.001356, l6: 0.001989

[epoch: 572/1000, batch:   668/ 1052, ite: 150340] train loss: 0.004158, tar: 0.000081 
l0: 0.000150, l1: 0.000159, l2: 0.000255, l3: 0.000490, l4: 0.001467, l5: 0.002561, l6: 0.004035

[epoch: 572/1000, batch:   748/ 1052, ite: 150360] train loss: 0.004157, tar: 0.000081 
l0: 0.000199, l1: 0.000208, l2: 0.000239, l3: 0.000324, l4: 0.000607, l5: 0.001617, l6: 0.002625

[epoch: 572/1000, batch:   828/ 1052, ite: 150380] train loss: 0.004155, tar: 0.000081 
l0: 0.000071, l1: 0.000067, l2: 0.000165, l3: 0.000272, l4: 0.000577, l5: 0.001498, l6: 0.003938

[epoch: 572/1000, batch:   908/ 1052, ite: 150400] train loss: 0.004155, tar: 0.000081 
l0: 0.000088, l1: 0.000092, l2: 0.000134, l3: 0.000201, l4: 0.000463, l5: 0.001022, l6: 0.001756

[epoch: 572/1000, batch:   988/ 1052, ite: 150420] train loss: 0.004152, tar: 0.000081 
[Epoch 572/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000068, l1: 0.000072, l2: 0.000106, l3: 0.000258, l4: 0.000564, l5: 0.000697, l6: 0.001584

[epoch: 573/1000, batch:    16/ 1052, ite: 150440] train loss: 0.004151, tar: 0.000081 
l0: 0.000031, l1: 0.000032, l2: 0.000126, l3: 0.000281, l4: 0.000501, l5: 0.001103, l6: 0.002296

[epoch: 573/1000, batch:    96/ 1052, ite: 150460] train loss: 0.004149, tar: 0.000081 
l0: 0.000110, l1: 0.000101, l2: 0.000122, l3: 0.000189, l4: 0.000460, l5: 0.000963, l6: 0.001178

[epoch: 573/1000, batch:   176/ 1052, ite: 150480] train loss: 0.004148, tar: 0.000080 
l0: 0.000105, l1: 0.000105, l2: 0.000160, l3: 0.000281, l4: 0.000560, l5: 0.001197, l6: 0.001764

[epoch: 573/1000, batch:   256/ 1052, ite: 150500] train loss: 0.004146, tar: 0.000080 
l0: 0.000015, l1: 0.000014, l2: 0.000045, l3: 0.000128, l4: 0.000450, l5: 0.000921, l6: 0.001721

[epoch: 573/1000, batch:   336/ 1052, ite: 150520] train loss: 0.004149, tar: 0.000080 
l0: 0.000032, l1: 0.000031, l2: 0.000046, l3: 0.000131, l4: 0.000217, l5: 0.000770, l6: 0.001190

[epoch: 573/1000, batch:   416/ 1052, ite: 150540] train loss: 0.004148, tar: 0.000080 
l0: 0.000018, l1: 0.000016, l2: 0.000072, l3: 0.000153, l4: 0.000392, l5: 0.000702, l6: 0.002176

[epoch: 573/1000, batch:   496/ 1052, ite: 150560] train loss: 0.004151, tar: 0.000080 
l0: 0.000081, l1: 0.000085, l2: 0.000092, l3: 0.000198, l4: 0.000362, l5: 0.000686, l6: 0.002287

[epoch: 573/1000, batch:   576/ 1052, ite: 150580] train loss: 0.004148, tar: 0.000080 
l0: 0.000048, l1: 0.000053, l2: 0.000088, l3: 0.000307, l4: 0.000739, l5: 0.001319, l6: 0.004019

[epoch: 573/1000, batch:   656/ 1052, ite: 150600] train loss: 0.004148, tar: 0.000080 
l0: 0.000080, l1: 0.000080, l2: 0.000161, l3: 0.000398, l4: 0.000659, l5: 0.001201, l6: 0.002497

[epoch: 573/1000, batch:   736/ 1052, ite: 150620] train loss: 0.004147, tar: 0.000080 
l0: 0.000078, l1: 0.000081, l2: 0.000091, l3: 0.000169, l4: 0.000422, l5: 0.000893, l6: 0.001728

[epoch: 573/1000, batch:   816/ 1052, ite: 150640] train loss: 0.004146, tar: 0.000080 
l0: 0.000005, l1: 0.000005, l2: 0.000032, l3: 0.000097, l4: 0.000358, l5: 0.001036, l6: 0.001328

[epoch: 573/1000, batch:   896/ 1052, ite: 150660] train loss: 0.004144, tar: 0.000080 
l0: 0.000047, l1: 0.000049, l2: 0.000080, l3: 0.000213, l4: 0.000644, l5: 0.001374, l6: 0.002127

[epoch: 573/1000, batch:   976/ 1052, ite: 150680] train loss: 0.004144, tar: 0.000080 
[Epoch 573/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000089, l1: 0.000093, l2: 0.000094, l3: 0.000261, l4: 0.000516, l5: 0.000912, l6: 0.002454

[epoch: 574/1000, batch:     4/ 1052, ite: 150700] train loss: 0.004145, tar: 0.000080 
l0: 0.000065, l1: 0.000066, l2: 0.000118, l3: 0.000235, l4: 0.000358, l5: 0.001047, l6: 0.002284

[epoch: 574/1000, batch:    84/ 1052, ite: 150720] train loss: 0.004145, tar: 0.000079 
l0: 0.000053, l1: 0.000056, l2: 0.000087, l3: 0.000228, l4: 0.000401, l5: 0.001067, l6: 0.001282

[epoch: 574/1000, batch:   164/ 1052, ite: 150740] train loss: 0.004146, tar: 0.000079 
l0: 0.000034, l1: 0.000036, l2: 0.000112, l3: 0.000220, l4: 0.000493, l5: 0.000810, l6: 0.001990

[epoch: 574/1000, batch:   244/ 1052, ite: 150760] train loss: 0.004147, tar: 0.000079 
l0: 0.000026, l1: 0.000026, l2: 0.000067, l3: 0.000188, l4: 0.000501, l5: 0.001269, l6: 0.002651

[epoch: 574/1000, batch:   324/ 1052, ite: 150780] train loss: 0.004150, tar: 0.000079 
l0: 0.000049, l1: 0.000050, l2: 0.000074, l3: 0.000161, l4: 0.000391, l5: 0.000597, l6: 0.001652

[epoch: 574/1000, batch:   404/ 1052, ite: 150800] train loss: 0.004151, tar: 0.000079 
l0: 0.000053, l1: 0.000054, l2: 0.000099, l3: 0.000182, l4: 0.000560, l5: 0.001325, l6: 0.002855

[epoch: 574/1000, batch:   484/ 1052, ite: 150820] train loss: 0.004149, tar: 0.000079 
l0: 0.000064, l1: 0.000063, l2: 0.000104, l3: 0.000198, l4: 0.000353, l5: 0.001041, l6: 0.001336

[epoch: 574/1000, batch:   564/ 1052, ite: 150840] train loss: 0.004148, tar: 0.000079 
l0: 0.000048, l1: 0.000048, l2: 0.000056, l3: 0.000128, l4: 0.000339, l5: 0.000867, l6: 0.001902

[epoch: 574/1000, batch:   644/ 1052, ite: 150860] train loss: 0.004146, tar: 0.000079 
l0: 0.000123, l1: 0.000127, l2: 0.000132, l3: 0.000186, l4: 0.000381, l5: 0.000861, l6: 0.002078

[epoch: 574/1000, batch:   724/ 1052, ite: 150880] train loss: 0.004150, tar: 0.000079 
l0: 0.000050, l1: 0.000049, l2: 0.000080, l3: 0.000147, l4: 0.000248, l5: 0.000675, l6: 0.001426

[epoch: 574/1000, batch:   804/ 1052, ite: 150900] train loss: 0.004148, tar: 0.000079 
l0: 0.000100, l1: 0.000103, l2: 0.000136, l3: 0.000255, l4: 0.000681, l5: 0.001590, l6: 0.003483

[epoch: 574/1000, batch:   884/ 1052, ite: 150920] train loss: 0.004145, tar: 0.000079 
l0: 0.000037, l1: 0.000037, l2: 0.000109, l3: 0.000219, l4: 0.000440, l5: 0.000896, l6: 0.001940

[epoch: 574/1000, batch:   964/ 1052, ite: 150940] train loss: 0.004145, tar: 0.000079 
l0: 0.000022, l1: 0.000023, l2: 0.000048, l3: 0.000080, l4: 0.000145, l5: 0.000569, l6: 0.001240

[epoch: 574/1000, batch:  1044/ 1052, ite: 150960] train loss: 0.004142, tar: 0.000079 
[Epoch 574/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000182, l1: 0.000183, l2: 0.000192, l3: 0.000335, l4: 0.000704, l5: 0.001743, l6: 0.003739

[epoch: 575/1000, batch:    72/ 1052, ite: 150980] train loss: 0.004143, tar: 0.000079 
l0: 0.000027, l1: 0.000028, l2: 0.000038, l3: 0.000113, l4: 0.000189, l5: 0.000995, l6: 0.001515

[epoch: 575/1000, batch:   152/ 1052, ite: 151000] train loss: 0.004144, tar: 0.000079 
l0: 0.000042, l1: 0.000043, l2: 0.000071, l3: 0.000274, l4: 0.000568, l5: 0.001107, l6: 0.001918

[epoch: 575/1000, batch:   232/ 1052, ite: 151020] train loss: 0.004140, tar: 0.000079 
l0: 0.000071, l1: 0.000071, l2: 0.000071, l3: 0.000199, l4: 0.000430, l5: 0.000931, l6: 0.001550

[epoch: 575/1000, batch:   312/ 1052, ite: 151040] train loss: 0.004142, tar: 0.000078 
l0: 0.000047, l1: 0.000048, l2: 0.000090, l3: 0.000203, l4: 0.000538, l5: 0.001291, l6: 0.003168

[epoch: 575/1000, batch:   392/ 1052, ite: 151060] train loss: 0.004141, tar: 0.000078 
l0: 0.000048, l1: 0.000047, l2: 0.000066, l3: 0.000155, l4: 0.000299, l5: 0.001143, l6: 0.001545

[epoch: 575/1000, batch:   472/ 1052, ite: 151080] train loss: 0.004141, tar: 0.000078 
l0: 0.000092, l1: 0.000092, l2: 0.000122, l3: 0.000244, l4: 0.000454, l5: 0.001374, l6: 0.001704

[epoch: 575/1000, batch:   552/ 1052, ite: 151100] train loss: 0.004140, tar: 0.000078 
l0: 0.000041, l1: 0.000044, l2: 0.000058, l3: 0.000098, l4: 0.000510, l5: 0.000729, l6: 0.001714

[epoch: 575/1000, batch:   632/ 1052, ite: 151120] train loss: 0.004140, tar: 0.000078 
l0: 0.000041, l1: 0.000040, l2: 0.000065, l3: 0.000160, l4: 0.000348, l5: 0.000733, l6: 0.001475

[epoch: 575/1000, batch:   712/ 1052, ite: 151140] train loss: 0.004136, tar: 0.000078 
l0: 0.000093, l1: 0.000096, l2: 0.000134, l3: 0.000210, l4: 0.000414, l5: 0.001294, l6: 0.002423

[epoch: 575/1000, batch:   792/ 1052, ite: 151160] train loss: 0.004137, tar: 0.000078 
l0: 0.000021, l1: 0.000022, l2: 0.000088, l3: 0.000167, l4: 0.000321, l5: 0.000640, l6: 0.001096

[epoch: 575/1000, batch:   872/ 1052, ite: 151180] train loss: 0.004135, tar: 0.000078 
l0: 0.000040, l1: 0.000040, l2: 0.000053, l3: 0.000088, l4: 0.000172, l5: 0.000712, l6: 0.001179

[epoch: 575/1000, batch:   952/ 1052, ite: 151200] train loss: 0.004137, tar: 0.000078 
l0: 0.000072, l1: 0.000073, l2: 0.000114, l3: 0.000279, l4: 0.000564, l5: 0.000955, l6: 0.001903

[epoch: 575/1000, batch:  1032/ 1052, ite: 151220] train loss: 0.004138, tar: 0.000078 
[Epoch 575/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000077, l1: 0.000078, l2: 0.000108, l3: 0.000181, l4: 0.000418, l5: 0.001587, l6: 0.003029

[epoch: 576/1000, batch:    60/ 1052, ite: 151240] train loss: 0.004140, tar: 0.000078 
l0: 0.000073, l1: 0.000071, l2: 0.000173, l3: 0.000232, l4: 0.000525, l5: 0.001272, l6: 0.001941

[epoch: 576/1000, batch:   140/ 1052, ite: 151260] train loss: 0.004139, tar: 0.000078 
l0: 0.000100, l1: 0.000099, l2: 0.000189, l3: 0.000427, l4: 0.000603, l5: 0.001527, l6: 0.002720

[epoch: 576/1000, batch:   220/ 1052, ite: 151280] train loss: 0.004138, tar: 0.000078 
l0: 0.000066, l1: 0.000067, l2: 0.000114, l3: 0.000151, l4: 0.000486, l5: 0.000889, l6: 0.002295

[epoch: 576/1000, batch:   300/ 1052, ite: 151300] train loss: 0.004140, tar: 0.000078 
l0: 0.000072, l1: 0.000077, l2: 0.000108, l3: 0.000244, l4: 0.000513, l5: 0.000962, l6: 0.001712

[epoch: 576/1000, batch:   380/ 1052, ite: 151320] train loss: 0.004140, tar: 0.000078 
l0: 0.000036, l1: 0.000037, l2: 0.000052, l3: 0.000147, l4: 0.000264, l5: 0.000517, l6: 0.001255

[epoch: 576/1000, batch:   460/ 1052, ite: 151340] train loss: 0.004137, tar: 0.000078 
l0: 0.000048, l1: 0.000048, l2: 0.000142, l3: 0.000252, l4: 0.000534, l5: 0.001770, l6: 0.003073

[epoch: 576/1000, batch:   540/ 1052, ite: 151360] train loss: 0.004135, tar: 0.000078 
l0: 0.000024, l1: 0.000027, l2: 0.000048, l3: 0.000106, l4: 0.000527, l5: 0.000751, l6: 0.001535

[epoch: 576/1000, batch:   620/ 1052, ite: 151380] train loss: 0.004137, tar: 0.000078 
l0: 0.000064, l1: 0.000065, l2: 0.000094, l3: 0.000209, l4: 0.000551, l5: 0.001472, l6: 0.001852

[epoch: 576/1000, batch:   700/ 1052, ite: 151400] train loss: 0.004137, tar: 0.000078 
l0: 0.000146, l1: 0.000151, l2: 0.000154, l3: 0.000218, l4: 0.000740, l5: 0.002031, l6: 0.004027

[epoch: 576/1000, batch:   780/ 1052, ite: 151420] train loss: 0.004135, tar: 0.000078 
l0: 0.000046, l1: 0.000049, l2: 0.000072, l3: 0.000225, l4: 0.000466, l5: 0.000819, l6: 0.001905

[epoch: 576/1000, batch:   860/ 1052, ite: 151440] train loss: 0.004134, tar: 0.000078 
l0: 0.000099, l1: 0.000102, l2: 0.000139, l3: 0.000247, l4: 0.000509, l5: 0.001314, l6: 0.002207

[epoch: 576/1000, batch:   940/ 1052, ite: 151460] train loss: 0.004136, tar: 0.000078 
l0: 0.000081, l1: 0.000076, l2: 0.000156, l3: 0.000259, l4: 0.000546, l5: 0.001331, l6: 0.002853

[epoch: 576/1000, batch:  1020/ 1052, ite: 151480] train loss: 0.004136, tar: 0.000078 
[Epoch 576/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000029, l1: 0.000028, l2: 0.000086, l3: 0.000288, l4: 0.000712, l5: 0.001802, l6: 0.002985

[epoch: 577/1000, batch:    48/ 1052, ite: 151500] train loss: 0.004138, tar: 0.000078 
l0: 0.000081, l1: 0.000080, l2: 0.000098, l3: 0.000203, l4: 0.000413, l5: 0.001039, l6: 0.001036

[epoch: 577/1000, batch:   128/ 1052, ite: 151520] train loss: 0.004140, tar: 0.000078 
l0: 0.000100, l1: 0.000101, l2: 0.000137, l3: 0.000324, l4: 0.000692, l5: 0.001561, l6: 0.002664

[epoch: 577/1000, batch:   208/ 1052, ite: 151540] train loss: 0.004136, tar: 0.000078 
l0: 0.000063, l1: 0.000062, l2: 0.000099, l3: 0.000159, l4: 0.000361, l5: 0.000670, l6: 0.001638

[epoch: 577/1000, batch:   288/ 1052, ite: 151560] train loss: 0.004135, tar: 0.000078 
l0: 0.000009, l1: 0.000009, l2: 0.000031, l3: 0.000112, l4: 0.000364, l5: 0.000569, l6: 0.001749

[epoch: 577/1000, batch:   368/ 1052, ite: 151580] train loss: 0.004135, tar: 0.000078 
l0: 0.000016, l1: 0.000016, l2: 0.000041, l3: 0.000093, l4: 0.000223, l5: 0.000599, l6: 0.001257

[epoch: 577/1000, batch:   448/ 1052, ite: 151600] train loss: 0.004135, tar: 0.000078 
l0: 0.000076, l1: 0.000081, l2: 0.000114, l3: 0.000212, l4: 0.000600, l5: 0.001031, l6: 0.002755

[epoch: 577/1000, batch:   528/ 1052, ite: 151620] train loss: 0.004135, tar: 0.000078 
l0: 0.000086, l1: 0.000088, l2: 0.000138, l3: 0.000239, l4: 0.000414, l5: 0.001214, l6: 0.002616

[epoch: 577/1000, batch:   608/ 1052, ite: 151640] train loss: 0.004135, tar: 0.000078 
l0: 0.000035, l1: 0.000036, l2: 0.000063, l3: 0.000111, l4: 0.000288, l5: 0.000482, l6: 0.001264

[epoch: 577/1000, batch:   688/ 1052, ite: 151660] train loss: 0.004137, tar: 0.000078 
l0: 0.000065, l1: 0.000065, l2: 0.000092, l3: 0.000096, l4: 0.000271, l5: 0.000942, l6: 0.001547

[epoch: 577/1000, batch:   768/ 1052, ite: 151680] train loss: 0.004135, tar: 0.000078 
l0: 0.000065, l1: 0.000067, l2: 0.000097, l3: 0.000198, l4: 0.000504, l5: 0.001023, l6: 0.001672

[epoch: 577/1000, batch:   848/ 1052, ite: 151700] train loss: 0.004135, tar: 0.000078 
l0: 0.000080, l1: 0.000077, l2: 0.000215, l3: 0.000407, l4: 0.000983, l5: 0.001407, l6: 0.003630

[epoch: 577/1000, batch:   928/ 1052, ite: 151720] train loss: 0.004135, tar: 0.000078 
l0: 0.000055, l1: 0.000055, l2: 0.000105, l3: 0.000208, l4: 0.000433, l5: 0.000668, l6: 0.001500

[epoch: 577/1000, batch:  1008/ 1052, ite: 151740] train loss: 0.004134, tar: 0.000078 
[Epoch 577/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000079, l1: 0.000080, l2: 0.000102, l3: 0.000217, l4: 0.000485, l5: 0.001603, l6: 0.002722

[epoch: 578/1000, batch:    36/ 1052, ite: 151760] train loss: 0.004133, tar: 0.000077 
l0: 0.000037, l1: 0.000036, l2: 0.000086, l3: 0.000160, l4: 0.000374, l5: 0.001112, l6: 0.002005

[epoch: 578/1000, batch:   116/ 1052, ite: 151780] train loss: 0.004132, tar: 0.000077 
l0: 0.000078, l1: 0.000079, l2: 0.000133, l3: 0.000201, l4: 0.000469, l5: 0.001207, l6: 0.003420

[epoch: 578/1000, batch:   196/ 1052, ite: 151800] train loss: 0.004131, tar: 0.000077 
l0: 0.000035, l1: 0.000037, l2: 0.000048, l3: 0.000124, l4: 0.000322, l5: 0.001055, l6: 0.001501

[epoch: 578/1000, batch:   276/ 1052, ite: 151820] train loss: 0.004134, tar: 0.000077 
l0: 0.000167, l1: 0.000177, l2: 0.000169, l3: 0.000179, l4: 0.000237, l5: 0.000372, l6: 0.000759

[epoch: 578/1000, batch:   356/ 1052, ite: 151840] train loss: 0.004135, tar: 0.000077 
l0: 0.000159, l1: 0.000161, l2: 0.000343, l3: 0.000511, l4: 0.000918, l5: 0.002488, l6: 0.004602

[epoch: 578/1000, batch:   436/ 1052, ite: 151860] train loss: 0.004137, tar: 0.000077 
l0: 0.000055, l1: 0.000055, l2: 0.000094, l3: 0.000173, l4: 0.000359, l5: 0.000962, l6: 0.002106

[epoch: 578/1000, batch:   516/ 1052, ite: 151880] train loss: 0.004134, tar: 0.000077 
l0: 0.000041, l1: 0.000045, l2: 0.000104, l3: 0.000235, l4: 0.000571, l5: 0.001409, l6: 0.001699

[epoch: 578/1000, batch:   596/ 1052, ite: 151900] train loss: 0.004133, tar: 0.000077 
l0: 0.000075, l1: 0.000075, l2: 0.000120, l3: 0.000165, l4: 0.000331, l5: 0.000557, l6: 0.001189

[epoch: 578/1000, batch:   676/ 1052, ite: 151920] train loss: 0.004131, tar: 0.000077 
l0: 0.000046, l1: 0.000046, l2: 0.000074, l3: 0.000197, l4: 0.000429, l5: 0.001339, l6: 0.002572

[epoch: 578/1000, batch:   756/ 1052, ite: 151940] train loss: 0.004129, tar: 0.000077 
l0: 0.000037, l1: 0.000035, l2: 0.000075, l3: 0.000214, l4: 0.000541, l5: 0.001084, l6: 0.002020

[epoch: 578/1000, batch:   836/ 1052, ite: 151960] train loss: 0.004128, tar: 0.000077 
l0: 0.000041, l1: 0.000038, l2: 0.000060, l3: 0.000125, l4: 0.000425, l5: 0.000660, l6: 0.001648

[epoch: 578/1000, batch:   916/ 1052, ite: 151980] train loss: 0.004128, tar: 0.000077 
l0: 0.000109, l1: 0.000107, l2: 0.000126, l3: 0.000159, l4: 0.000315, l5: 0.001027, l6: 0.001360

[epoch: 578/1000, batch:   996/ 1052, ite: 152000] train loss: 0.004126, tar: 0.000077 
[Epoch 578/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000074, l1: 0.000072, l2: 0.000092, l3: 0.000220, l4: 0.000527, l5: 0.001064, l6: 0.002199

[epoch: 579/1000, batch:    24/ 1052, ite: 152020] train loss: 0.004127, tar: 0.000077 
l0: 0.000060, l1: 0.000060, l2: 0.000141, l3: 0.000290, l4: 0.000603, l5: 0.001721, l6: 0.003294

[epoch: 579/1000, batch:   104/ 1052, ite: 152040] train loss: 0.004127, tar: 0.000077 
l0: 0.000085, l1: 0.000088, l2: 0.000132, l3: 0.000165, l4: 0.000487, l5: 0.000736, l6: 0.001394

[epoch: 579/1000, batch:   184/ 1052, ite: 152060] train loss: 0.004126, tar: 0.000077 
l0: 0.000046, l1: 0.000046, l2: 0.000074, l3: 0.000180, l4: 0.000376, l5: 0.001084, l6: 0.001518

[epoch: 579/1000, batch:   264/ 1052, ite: 152080] train loss: 0.004126, tar: 0.000077 
l0: 0.000076, l1: 0.000073, l2: 0.000113, l3: 0.000226, l4: 0.000447, l5: 0.001087, l6: 0.001631

[epoch: 579/1000, batch:   344/ 1052, ite: 152100] train loss: 0.004124, tar: 0.000077 
l0: 0.000033, l1: 0.000033, l2: 0.000062, l3: 0.000188, l4: 0.000521, l5: 0.000536, l6: 0.001030

[epoch: 579/1000, batch:   424/ 1052, ite: 152120] train loss: 0.004123, tar: 0.000076 
l0: 0.000067, l1: 0.000065, l2: 0.000125, l3: 0.000444, l4: 0.000918, l5: 0.001242, l6: 0.002701

[epoch: 579/1000, batch:   504/ 1052, ite: 152140] train loss: 0.004121, tar: 0.000076 
l0: 0.000081, l1: 0.000083, l2: 0.000126, l3: 0.000185, l4: 0.000572, l5: 0.001215, l6: 0.002316

[epoch: 579/1000, batch:   584/ 1052, ite: 152160] train loss: 0.004121, tar: 0.000076 
l0: 0.000071, l1: 0.000072, l2: 0.000124, l3: 0.000309, l4: 0.000698, l5: 0.001563, l6: 0.002103

[epoch: 579/1000, batch:   664/ 1052, ite: 152180] train loss: 0.004122, tar: 0.000076 
l0: 0.000051, l1: 0.000053, l2: 0.000086, l3: 0.000172, l4: 0.000327, l5: 0.000668, l6: 0.001386

[epoch: 579/1000, batch:   744/ 1052, ite: 152200] train loss: 0.004120, tar: 0.000076 
l0: 0.000029, l1: 0.000029, l2: 0.000048, l3: 0.000093, l4: 0.000241, l5: 0.000430, l6: 0.001589

[epoch: 579/1000, batch:   824/ 1052, ite: 152220] train loss: 0.004118, tar: 0.000076 
l0: 0.000063, l1: 0.000060, l2: 0.000115, l3: 0.000275, l4: 0.000688, l5: 0.001212, l6: 0.001998

[epoch: 579/1000, batch:   904/ 1052, ite: 152240] train loss: 0.004120, tar: 0.000076 
l0: 0.000049, l1: 0.000050, l2: 0.000118, l3: 0.000216, l4: 0.000428, l5: 0.000967, l6: 0.001928

[epoch: 579/1000, batch:   984/ 1052, ite: 152260] train loss: 0.004119, tar: 0.000076 
[Epoch 579/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000034, l1: 0.000035, l2: 0.000068, l3: 0.000188, l4: 0.000435, l5: 0.000794, l6: 0.001432

[epoch: 580/1000, batch:    12/ 1052, ite: 152280] train loss: 0.004120, tar: 0.000076 
l0: 0.000022, l1: 0.000023, l2: 0.000061, l3: 0.000341, l4: 0.000646, l5: 0.001425, l6: 0.002227

[epoch: 580/1000, batch:    92/ 1052, ite: 152300] train loss: 0.004120, tar: 0.000076 
l0: 0.000062, l1: 0.000062, l2: 0.000151, l3: 0.000303, l4: 0.000447, l5: 0.000979, l6: 0.002851

[epoch: 580/1000, batch:   172/ 1052, ite: 152320] train loss: 0.004120, tar: 0.000076 
l0: 0.000029, l1: 0.000031, l2: 0.000066, l3: 0.000153, l4: 0.000358, l5: 0.000893, l6: 0.001640

[epoch: 580/1000, batch:   252/ 1052, ite: 152340] train loss: 0.004120, tar: 0.000076 
l0: 0.000082, l1: 0.000083, l2: 0.000133, l3: 0.000233, l4: 0.000366, l5: 0.000985, l6: 0.002240

[epoch: 580/1000, batch:   332/ 1052, ite: 152360] train loss: 0.004121, tar: 0.000076 
l0: 0.000018, l1: 0.000017, l2: 0.000042, l3: 0.000118, l4: 0.000232, l5: 0.000521, l6: 0.001169

[epoch: 580/1000, batch:   412/ 1052, ite: 152380] train loss: 0.004120, tar: 0.000076 
l0: 0.000029, l1: 0.000031, l2: 0.000036, l3: 0.000128, l4: 0.000364, l5: 0.001078, l6: 0.001246

[epoch: 580/1000, batch:   492/ 1052, ite: 152400] train loss: 0.004119, tar: 0.000076 
l0: 0.000174, l1: 0.000186, l2: 0.000210, l3: 0.000284, l4: 0.000466, l5: 0.000973, l6: 0.002474

[epoch: 580/1000, batch:   572/ 1052, ite: 152420] train loss: 0.004122, tar: 0.000076 
l0: 0.000106, l1: 0.000109, l2: 0.000182, l3: 0.000447, l4: 0.000778, l5: 0.001511, l6: 0.002612

[epoch: 580/1000, batch:   652/ 1052, ite: 152440] train loss: 0.004121, tar: 0.000076 
l0: 0.000050, l1: 0.000054, l2: 0.000039, l3: 0.000126, l4: 0.000470, l5: 0.000891, l6: 0.001800

[epoch: 580/1000, batch:   732/ 1052, ite: 152460] train loss: 0.004121, tar: 0.000076 
l0: 0.000251, l1: 0.000264, l2: 0.000336, l3: 0.000383, l4: 0.000660, l5: 0.001791, l6: 0.003550

[epoch: 580/1000, batch:   812/ 1052, ite: 152480] train loss: 0.004122, tar: 0.000076 
l0: 0.000065, l1: 0.000067, l2: 0.000111, l3: 0.000236, l4: 0.000318, l5: 0.000640, l6: 0.001599

[epoch: 580/1000, batch:   892/ 1052, ite: 152500] train loss: 0.004123, tar: 0.000076 
l0: 0.000024, l1: 0.000024, l2: 0.000043, l3: 0.000092, l4: 0.000399, l5: 0.000984, l6: 0.001901

[epoch: 580/1000, batch:   972/ 1052, ite: 152520] train loss: 0.004123, tar: 0.000076 
l0: 0.000187, l1: 0.000192, l2: 0.000251, l3: 0.000491, l4: 0.001180, l5: 0.002405, l6: 0.004578

[epoch: 580/1000, batch:  1052/ 1052, ite: 152540] train loss: 0.004124, tar: 0.000076 
[Epoch 580/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000045, l1: 0.000043, l2: 0.000072, l3: 0.000145, l4: 0.000240, l5: 0.000365, l6: 0.001311

[epoch: 581/1000, batch:    80/ 1052, ite: 152560] train loss: 0.004123, tar: 0.000076 
l0: 0.000059, l1: 0.000062, l2: 0.000117, l3: 0.000263, l4: 0.000450, l5: 0.000979, l6: 0.002413

[epoch: 581/1000, batch:   160/ 1052, ite: 152580] train loss: 0.004122, tar: 0.000076 
l0: 0.000021, l1: 0.000023, l2: 0.000066, l3: 0.000165, l4: 0.000343, l5: 0.001031, l6: 0.001500

[epoch: 581/1000, batch:   240/ 1052, ite: 152600] train loss: 0.004124, tar: 0.000076 
l0: 0.000024, l1: 0.000025, l2: 0.000043, l3: 0.000075, l4: 0.000433, l5: 0.000787, l6: 0.001512

[epoch: 581/1000, batch:   320/ 1052, ite: 152620] train loss: 0.004123, tar: 0.000077 
l0: 0.000055, l1: 0.000057, l2: 0.000081, l3: 0.000111, l4: 0.000268, l5: 0.000681, l6: 0.001528

[epoch: 581/1000, batch:   400/ 1052, ite: 152640] train loss: 0.004124, tar: 0.000077 
l0: 0.000031, l1: 0.000029, l2: 0.000079, l3: 0.000166, l4: 0.000327, l5: 0.001065, l6: 0.002320

[epoch: 581/1000, batch:   480/ 1052, ite: 152660] train loss: 0.004124, tar: 0.000077 
l0: 0.000045, l1: 0.000042, l2: 0.000082, l3: 0.000154, l4: 0.000350, l5: 0.001306, l6: 0.002306

[epoch: 581/1000, batch:   560/ 1052, ite: 152680] train loss: 0.004125, tar: 0.000077 
l0: 0.000089, l1: 0.000091, l2: 0.000169, l3: 0.000368, l4: 0.000733, l5: 0.000826, l6: 0.002718

[epoch: 581/1000, batch:   640/ 1052, ite: 152700] train loss: 0.004126, tar: 0.000077 
l0: 0.000053, l1: 0.000051, l2: 0.000098, l3: 0.000170, l4: 0.000257, l5: 0.000882, l6: 0.001322

[epoch: 581/1000, batch:   720/ 1052, ite: 152720] train loss: 0.004125, tar: 0.000077 
l0: 0.000024, l1: 0.000024, l2: 0.000056, l3: 0.000154, l4: 0.000340, l5: 0.000784, l6: 0.001318

[epoch: 581/1000, batch:   800/ 1052, ite: 152740] train loss: 0.004127, tar: 0.000077 
l0: 0.000049, l1: 0.000049, l2: 0.000083, l3: 0.000193, l4: 0.000539, l5: 0.000978, l6: 0.001671

[epoch: 581/1000, batch:   880/ 1052, ite: 152760] train loss: 0.004127, tar: 0.000077 
l0: 0.000078, l1: 0.000079, l2: 0.000151, l3: 0.000320, l4: 0.000540, l5: 0.001317, l6: 0.002503

[epoch: 581/1000, batch:   960/ 1052, ite: 152780] train loss: 0.004127, tar: 0.000077 
l0: 0.000091, l1: 0.000097, l2: 0.000119, l3: 0.000201, l4: 0.000609, l5: 0.001505, l6: 0.001579

[epoch: 581/1000, batch:  1040/ 1052, ite: 152800] train loss: 0.004127, tar: 0.000076 
[Epoch 581/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000129, l1: 0.000136, l2: 0.000166, l3: 0.000184, l4: 0.000606, l5: 0.001400, l6: 0.003352

[epoch: 582/1000, batch:    68/ 1052, ite: 152820] train loss: 0.004127, tar: 0.000076 
l0: 0.000030, l1: 0.000040, l2: 0.000067, l3: 0.000140, l4: 0.000234, l5: 0.000451, l6: 0.001196

[epoch: 582/1000, batch:   148/ 1052, ite: 152840] train loss: 0.004125, tar: 0.000076 
l0: 0.000125, l1: 0.000128, l2: 0.000274, l3: 0.000496, l4: 0.001166, l5: 0.002342, l6: 0.004570

[epoch: 582/1000, batch:   228/ 1052, ite: 152860] train loss: 0.004124, tar: 0.000076 
l0: 0.000089, l1: 0.000090, l2: 0.000140, l3: 0.000244, l4: 0.000636, l5: 0.001315, l6: 0.001907

[epoch: 582/1000, batch:   308/ 1052, ite: 152880] train loss: 0.004125, tar: 0.000076 
l0: 0.000146, l1: 0.000152, l2: 0.000150, l3: 0.000285, l4: 0.000520, l5: 0.001008, l6: 0.002089

[epoch: 582/1000, batch:   388/ 1052, ite: 152900] train loss: 0.004127, tar: 0.000076 
l0: 0.000118, l1: 0.000124, l2: 0.000147, l3: 0.000296, l4: 0.000739, l5: 0.001561, l6: 0.003388

[epoch: 582/1000, batch:   468/ 1052, ite: 152920] train loss: 0.004129, tar: 0.000076 
l0: 0.000128, l1: 0.000132, l2: 0.000154, l3: 0.000251, l4: 0.000713, l5: 0.001727, l6: 0.002933

[epoch: 582/1000, batch:   548/ 1052, ite: 152940] train loss: 0.004130, tar: 0.000076 
l0: 0.000097, l1: 0.000094, l2: 0.000206, l3: 0.000382, l4: 0.000551, l5: 0.001210, l6: 0.002220

[epoch: 582/1000, batch:   628/ 1052, ite: 152960] train loss: 0.004129, tar: 0.000076 
l0: 0.000045, l1: 0.000048, l2: 0.000089, l3: 0.000155, l4: 0.000436, l5: 0.001180, l6: 0.001548

[epoch: 582/1000, batch:   708/ 1052, ite: 152980] train loss: 0.004128, tar: 0.000076 
l0: 0.000118, l1: 0.000121, l2: 0.000285, l3: 0.000471, l4: 0.000784, l5: 0.002426, l6: 0.004766

[epoch: 582/1000, batch:   788/ 1052, ite: 153000] train loss: 0.004129, tar: 0.000076 
l0: 0.000038, l1: 0.000035, l2: 0.000064, l3: 0.000199, l4: 0.000302, l5: 0.000775, l6: 0.000693

[epoch: 582/1000, batch:   868/ 1052, ite: 153020] train loss: 0.004128, tar: 0.000076 
l0: 0.000093, l1: 0.000092, l2: 0.000142, l3: 0.000273, l4: 0.000593, l5: 0.001181, l6: 0.001599

[epoch: 582/1000, batch:   948/ 1052, ite: 153040] train loss: 0.004126, tar: 0.000076 
l0: 0.000103, l1: 0.000103, l2: 0.000158, l3: 0.000419, l4: 0.000714, l5: 0.001813, l6: 0.003707

[epoch: 582/1000, batch:  1028/ 1052, ite: 153060] train loss: 0.004126, tar: 0.000076 
[Epoch 582/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000070, l1: 0.000073, l2: 0.000143, l3: 0.000367, l4: 0.000893, l5: 0.001997, l6: 0.003741

[epoch: 583/1000, batch:    56/ 1052, ite: 153080] train loss: 0.004126, tar: 0.000076 
l0: 0.000108, l1: 0.000109, l2: 0.000189, l3: 0.000294, l4: 0.000494, l5: 0.000987, l6: 0.001466

[epoch: 583/1000, batch:   136/ 1052, ite: 153100] train loss: 0.004126, tar: 0.000076 
l0: 0.000143, l1: 0.000143, l2: 0.000204, l3: 0.000294, l4: 0.000664, l5: 0.001076, l6: 0.002709

[epoch: 583/1000, batch:   216/ 1052, ite: 153120] train loss: 0.004125, tar: 0.000076 
l0: 0.000042, l1: 0.000042, l2: 0.000071, l3: 0.000179, l4: 0.000168, l5: 0.000699, l6: 0.001179

[epoch: 583/1000, batch:   296/ 1052, ite: 153140] train loss: 0.004124, tar: 0.000076 
l0: 0.000031, l1: 0.000030, l2: 0.000073, l3: 0.000194, l4: 0.000427, l5: 0.000845, l6: 0.001859

[epoch: 583/1000, batch:   376/ 1052, ite: 153160] train loss: 0.004122, tar: 0.000076 
l0: 0.000032, l1: 0.000034, l2: 0.000060, l3: 0.000189, l4: 0.000553, l5: 0.001841, l6: 0.001768

[epoch: 583/1000, batch:   456/ 1052, ite: 153180] train loss: 0.004122, tar: 0.000076 
l0: 0.000044, l1: 0.000043, l2: 0.000089, l3: 0.000284, l4: 0.000688, l5: 0.001876, l6: 0.003269

[epoch: 583/1000, batch:   536/ 1052, ite: 153200] train loss: 0.004122, tar: 0.000076 
l0: 0.000054, l1: 0.000056, l2: 0.000069, l3: 0.000137, l4: 0.000304, l5: 0.001083, l6: 0.002200

[epoch: 583/1000, batch:   616/ 1052, ite: 153220] train loss: 0.004123, tar: 0.000076 
l0: 0.000041, l1: 0.000042, l2: 0.000093, l3: 0.000190, l4: 0.000450, l5: 0.001137, l6: 0.001035

[epoch: 583/1000, batch:   696/ 1052, ite: 153240] train loss: 0.004123, tar: 0.000076 
l0: 0.000086, l1: 0.000086, l2: 0.000103, l3: 0.000143, l4: 0.000281, l5: 0.000673, l6: 0.001046

[epoch: 583/1000, batch:   776/ 1052, ite: 153260] train loss: 0.004121, tar: 0.000076 
l0: 0.000084, l1: 0.000083, l2: 0.000142, l3: 0.000311, l4: 0.000859, l5: 0.001798, l6: 0.003748

[epoch: 583/1000, batch:   856/ 1052, ite: 153280] train loss: 0.004120, tar: 0.000075 
l0: 0.000049, l1: 0.000053, l2: 0.000071, l3: 0.000168, l4: 0.000477, l5: 0.001295, l6: 0.001581

[epoch: 583/1000, batch:   936/ 1052, ite: 153300] train loss: 0.004121, tar: 0.000075 
l0: 0.000049, l1: 0.000048, l2: 0.000096, l3: 0.000204, l4: 0.000435, l5: 0.000867, l6: 0.001771

[epoch: 583/1000, batch:  1016/ 1052, ite: 153320] train loss: 0.004119, tar: 0.000075 
[Epoch 583/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000224, l1: 0.000195, l2: 0.000275, l3: 0.000465, l4: 0.000942, l5: 0.002551, l6: 0.003603

[epoch: 584/1000, batch:    44/ 1052, ite: 153340] train loss: 0.004120, tar: 0.000075 
l0: 0.000079, l1: 0.000079, l2: 0.000108, l3: 0.000262, l4: 0.000605, l5: 0.001137, l6: 0.002285

[epoch: 584/1000, batch:   124/ 1052, ite: 153360] train loss: 0.004120, tar: 0.000075 
l0: 0.000087, l1: 0.000085, l2: 0.000169, l3: 0.000448, l4: 0.000880, l5: 0.001458, l6: 0.002559

[epoch: 584/1000, batch:   204/ 1052, ite: 153380] train loss: 0.004119, tar: 0.000075 
l0: 0.000022, l1: 0.000024, l2: 0.000051, l3: 0.000160, l4: 0.000425, l5: 0.000868, l6: 0.001148

[epoch: 584/1000, batch:   284/ 1052, ite: 153400] train loss: 0.004117, tar: 0.000075 
l0: 0.000119, l1: 0.000121, l2: 0.000167, l3: 0.000295, l4: 0.000624, l5: 0.001407, l6: 0.002285

[epoch: 584/1000, batch:   364/ 1052, ite: 153420] train loss: 0.004116, tar: 0.000075 
l0: 0.000035, l1: 0.000033, l2: 0.000102, l3: 0.000189, l4: 0.000475, l5: 0.000840, l6: 0.001489

[epoch: 584/1000, batch:   444/ 1052, ite: 153440] train loss: 0.004117, tar: 0.000075 
l0: 0.000041, l1: 0.000046, l2: 0.000087, l3: 0.000232, l4: 0.000601, l5: 0.001340, l6: 0.002847

[epoch: 584/1000, batch:   524/ 1052, ite: 153460] train loss: 0.004117, tar: 0.000075 
l0: 0.000045, l1: 0.000046, l2: 0.000052, l3: 0.000101, l4: 0.000319, l5: 0.000717, l6: 0.001489

[epoch: 584/1000, batch:   604/ 1052, ite: 153480] train loss: 0.004118, tar: 0.000075 
l0: 0.000054, l1: 0.000057, l2: 0.000103, l3: 0.000199, l4: 0.000538, l5: 0.001331, l6: 0.001281

[epoch: 584/1000, batch:   684/ 1052, ite: 153500] train loss: 0.004117, tar: 0.000075 
l0: 0.000182, l1: 0.000184, l2: 0.000285, l3: 0.000506, l4: 0.001274, l5: 0.004155, l6: 0.006537

[epoch: 584/1000, batch:   764/ 1052, ite: 153520] train loss: 0.004121, tar: 0.000075 
l0: 0.000033, l1: 0.000033, l2: 0.000065, l3: 0.000096, l4: 0.000261, l5: 0.000518, l6: 0.001427

[epoch: 584/1000, batch:   844/ 1052, ite: 153540] train loss: 0.004120, tar: 0.000075 
l0: 0.000033, l1: 0.000034, l2: 0.000079, l3: 0.000130, l4: 0.000436, l5: 0.000990, l6: 0.002458

[epoch: 584/1000, batch:   924/ 1052, ite: 153560] train loss: 0.004118, tar: 0.000075 
l0: 0.000137, l1: 0.000129, l2: 0.000183, l3: 0.000337, l4: 0.000431, l5: 0.000959, l6: 0.001634

[epoch: 584/1000, batch:  1004/ 1052, ite: 153580] train loss: 0.004118, tar: 0.000075 
[Epoch 584/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000047, l1: 0.000045, l2: 0.000091, l3: 0.000148, l4: 0.000361, l5: 0.000921, l6: 0.002294

[epoch: 585/1000, batch:    32/ 1052, ite: 153600] train loss: 0.004116, tar: 0.000075 
l0: 0.000059, l1: 0.000062, l2: 0.000103, l3: 0.000198, l4: 0.000401, l5: 0.001105, l6: 0.001311

[epoch: 585/1000, batch:   112/ 1052, ite: 153620] train loss: 0.004116, tar: 0.000075 
l0: 0.000050, l1: 0.000049, l2: 0.000081, l3: 0.000209, l4: 0.000319, l5: 0.000698, l6: 0.001660

[epoch: 585/1000, batch:   192/ 1052, ite: 153640] train loss: 0.004115, tar: 0.000075 
l0: 0.000053, l1: 0.000054, l2: 0.000112, l3: 0.000217, l4: 0.000393, l5: 0.001039, l6: 0.001662

[epoch: 585/1000, batch:   272/ 1052, ite: 153660] train loss: 0.004115, tar: 0.000075 
l0: 0.000055, l1: 0.000055, l2: 0.000145, l3: 0.000450, l4: 0.000874, l5: 0.001293, l6: 0.002463

[epoch: 585/1000, batch:   352/ 1052, ite: 153680] train loss: 0.004116, tar: 0.000075 
l0: 0.000024, l1: 0.000024, l2: 0.000046, l3: 0.000166, l4: 0.000409, l5: 0.000847, l6: 0.001195

[epoch: 585/1000, batch:   432/ 1052, ite: 153700] train loss: 0.004115, tar: 0.000074 
l0: 0.000080, l1: 0.000083, l2: 0.000139, l3: 0.000311, l4: 0.000724, l5: 0.001859, l6: 0.003439

[epoch: 585/1000, batch:   512/ 1052, ite: 153720] train loss: 0.004115, tar: 0.000074 
l0: 0.000054, l1: 0.000054, l2: 0.000093, l3: 0.000164, l4: 0.000371, l5: 0.000621, l6: 0.001752

[epoch: 585/1000, batch:   592/ 1052, ite: 153740] train loss: 0.004115, tar: 0.000074 
l0: 0.000031, l1: 0.000029, l2: 0.000090, l3: 0.000178, l4: 0.000275, l5: 0.000964, l6: 0.001775

[epoch: 585/1000, batch:   672/ 1052, ite: 153760] train loss: 0.004114, tar: 0.000074 
l0: 0.000030, l1: 0.000030, l2: 0.000038, l3: 0.000121, l4: 0.000258, l5: 0.000773, l6: 0.001181

[epoch: 585/1000, batch:   752/ 1052, ite: 153780] train loss: 0.004113, tar: 0.000074 
l0: 0.000034, l1: 0.000035, l2: 0.000062, l3: 0.000108, l4: 0.000513, l5: 0.001210, l6: 0.001331

[epoch: 585/1000, batch:   832/ 1052, ite: 153800] train loss: 0.004114, tar: 0.000074 
l0: 0.000023, l1: 0.000023, l2: 0.000063, l3: 0.000148, l4: 0.000335, l5: 0.000478, l6: 0.001295

[epoch: 585/1000, batch:   912/ 1052, ite: 153820] train loss: 0.004113, tar: 0.000074 
l0: 0.000021, l1: 0.000021, l2: 0.000057, l3: 0.000092, l4: 0.000333, l5: 0.000707, l6: 0.000742

[epoch: 585/1000, batch:   992/ 1052, ite: 153840] train loss: 0.004112, tar: 0.000074 
[Epoch 585/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000137, l1: 0.000133, l2: 0.000184, l3: 0.000204, l4: 0.000311, l5: 0.000858, l6: 0.000856

[epoch: 586/1000, batch:    20/ 1052, ite: 153860] train loss: 0.004112, tar: 0.000074 
l0: 0.000041, l1: 0.000043, l2: 0.000120, l3: 0.000221, l4: 0.000573, l5: 0.001364, l6: 0.001991

[epoch: 586/1000, batch:   100/ 1052, ite: 153880] train loss: 0.004112, tar: 0.000074 
l0: 0.000203, l1: 0.000206, l2: 0.000277, l3: 0.000568, l4: 0.001251, l5: 0.002678, l6: 0.004296

[epoch: 586/1000, batch:   180/ 1052, ite: 153900] train loss: 0.004113, tar: 0.000074 
l0: 0.000051, l1: 0.000050, l2: 0.000099, l3: 0.000197, l4: 0.000279, l5: 0.001292, l6: 0.001369

[epoch: 586/1000, batch:   260/ 1052, ite: 153920] train loss: 0.004112, tar: 0.000074 
l0: 0.000165, l1: 0.000163, l2: 0.000245, l3: 0.000338, l4: 0.000536, l5: 0.000892, l6: 0.001441

[epoch: 586/1000, batch:   340/ 1052, ite: 153940] train loss: 0.004112, tar: 0.000074 
l0: 0.000031, l1: 0.000031, l2: 0.000088, l3: 0.000167, l4: 0.000315, l5: 0.000916, l6: 0.001430

[epoch: 586/1000, batch:   420/ 1052, ite: 153960] train loss: 0.004110, tar: 0.000074 
l0: 0.000035, l1: 0.000037, l2: 0.000053, l3: 0.000117, l4: 0.000432, l5: 0.000923, l6: 0.001759

[epoch: 586/1000, batch:   500/ 1052, ite: 153980] train loss: 0.004109, tar: 0.000074 
l0: 0.000071, l1: 0.000069, l2: 0.000118, l3: 0.000234, l4: 0.000571, l5: 0.001044, l6: 0.001716

[epoch: 586/1000, batch:   580/ 1052, ite: 154000] train loss: 0.004109, tar: 0.000074 
l0: 0.000046, l1: 0.000047, l2: 0.000087, l3: 0.000191, l4: 0.000431, l5: 0.000900, l6: 0.002081

[epoch: 586/1000, batch:   660/ 1052, ite: 154020] train loss: 0.004110, tar: 0.000074 
l0: 0.000049, l1: 0.000048, l2: 0.000115, l3: 0.000330, l4: 0.000857, l5: 0.002052, l6: 0.003012

[epoch: 586/1000, batch:   740/ 1052, ite: 154040] train loss: 0.004111, tar: 0.000074 
l0: 0.000097, l1: 0.000098, l2: 0.000098, l3: 0.000187, l4: 0.000397, l5: 0.000757, l6: 0.002287

[epoch: 586/1000, batch:   820/ 1052, ite: 154060] train loss: 0.004110, tar: 0.000074 
l0: 0.000018, l1: 0.000019, l2: 0.000058, l3: 0.000126, l4: 0.000193, l5: 0.000693, l6: 0.002106

[epoch: 586/1000, batch:   900/ 1052, ite: 154080] train loss: 0.004112, tar: 0.000074 
l0: 0.000081, l1: 0.000085, l2: 0.000128, l3: 0.000233, l4: 0.000461, l5: 0.001015, l6: 0.001793

[epoch: 586/1000, batch:   980/ 1052, ite: 154100] train loss: 0.004110, tar: 0.000074 
[Epoch 586/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000021, l1: 0.000021, l2: 0.000063, l3: 0.000185, l4: 0.000303, l5: 0.000677, l6: 0.001611

[epoch: 587/1000, batch:     8/ 1052, ite: 154120] train loss: 0.004111, tar: 0.000073 
l0: 0.000066, l1: 0.000067, l2: 0.000113, l3: 0.000295, l4: 0.000422, l5: 0.000970, l6: 0.002037

[epoch: 587/1000, batch:    88/ 1052, ite: 154140] train loss: 0.004111, tar: 0.000073 
l0: 0.000095, l1: 0.000095, l2: 0.000119, l3: 0.000202, l4: 0.000533, l5: 0.001364, l6: 0.002805

[epoch: 587/1000, batch:   168/ 1052, ite: 154160] train loss: 0.004110, tar: 0.000073 
l0: 0.000033, l1: 0.000033, l2: 0.000065, l3: 0.000180, l4: 0.000336, l5: 0.000924, l6: 0.000781

[epoch: 587/1000, batch:   248/ 1052, ite: 154180] train loss: 0.004110, tar: 0.000073 
l0: 0.000084, l1: 0.000084, l2: 0.000207, l3: 0.000346, l4: 0.001140, l5: 0.002049, l6: 0.003020

[epoch: 587/1000, batch:   328/ 1052, ite: 154200] train loss: 0.004112, tar: 0.000073 
l0: 0.000025, l1: 0.000025, l2: 0.000059, l3: 0.000279, l4: 0.000533, l5: 0.001114, l6: 0.002074

[epoch: 587/1000, batch:   408/ 1052, ite: 154220] train loss: 0.004111, tar: 0.000073 
l0: 0.000024, l1: 0.000024, l2: 0.000038, l3: 0.000084, l4: 0.000354, l5: 0.000773, l6: 0.001468

[epoch: 587/1000, batch:   488/ 1052, ite: 154240] train loss: 0.004110, tar: 0.000073 
l0: 0.000044, l1: 0.000045, l2: 0.000052, l3: 0.000089, l4: 0.000268, l5: 0.000677, l6: 0.001146

[epoch: 587/1000, batch:   568/ 1052, ite: 154260] train loss: 0.004110, tar: 0.000073 
l0: 0.000062, l1: 0.000061, l2: 0.000139, l3: 0.000330, l4: 0.001114, l5: 0.001791, l6: 0.003044

[epoch: 587/1000, batch:   648/ 1052, ite: 154280] train loss: 0.004109, tar: 0.000073 
l0: 0.000065, l1: 0.000068, l2: 0.000072, l3: 0.000219, l4: 0.000443, l5: 0.000780, l6: 0.001650

[epoch: 587/1000, batch:   728/ 1052, ite: 154300] train loss: 0.004110, tar: 0.000073 
l0: 0.000026, l1: 0.000026, l2: 0.000040, l3: 0.000107, l4: 0.000571, l5: 0.000860, l6: 0.001366

[epoch: 587/1000, batch:   808/ 1052, ite: 154320] train loss: 0.004108, tar: 0.000073 
l0: 0.000036, l1: 0.000040, l2: 0.000064, l3: 0.000154, l4: 0.000444, l5: 0.001008, l6: 0.002438

[epoch: 587/1000, batch:   888/ 1052, ite: 154340] train loss: 0.004109, tar: 0.000073 
l0: 0.000050, l1: 0.000050, l2: 0.000101, l3: 0.000214, l4: 0.000469, l5: 0.001262, l6: 0.002057

[epoch: 587/1000, batch:   968/ 1052, ite: 154360] train loss: 0.004108, tar: 0.000073 
l0: 0.000055, l1: 0.000051, l2: 0.000105, l3: 0.000174, l4: 0.000521, l5: 0.000915, l6: 0.001115

[epoch: 587/1000, batch:  1048/ 1052, ite: 154380] train loss: 0.004107, tar: 0.000073 
[Epoch 587/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000027, l1: 0.000026, l2: 0.000056, l3: 0.000164, l4: 0.000350, l5: 0.001173, l6: 0.001786

[epoch: 588/1000, batch:    76/ 1052, ite: 154400] train loss: 0.004106, tar: 0.000073 
l0: 0.000070, l1: 0.000072, l2: 0.000201, l3: 0.000430, l4: 0.000742, l5: 0.001502, l6: 0.002406

[epoch: 588/1000, batch:   156/ 1052, ite: 154420] train loss: 0.004106, tar: 0.000073 
l0: 0.000110, l1: 0.000112, l2: 0.000156, l3: 0.000449, l4: 0.000636, l5: 0.000969, l6: 0.001875

[epoch: 588/1000, batch:   236/ 1052, ite: 154440] train loss: 0.004106, tar: 0.000073 
l0: 0.000040, l1: 0.000041, l2: 0.000098, l3: 0.000172, l4: 0.000369, l5: 0.000965, l6: 0.001174

[epoch: 588/1000, batch:   316/ 1052, ite: 154460] train loss: 0.004107, tar: 0.000073 
l0: 0.000068, l1: 0.000068, l2: 0.000076, l3: 0.000116, l4: 0.000349, l5: 0.000886, l6: 0.000830

[epoch: 588/1000, batch:   396/ 1052, ite: 154480] train loss: 0.004106, tar: 0.000073 
l0: 0.000362, l1: 0.000344, l2: 0.000395, l3: 0.000458, l4: 0.000620, l5: 0.000672, l6: 0.001630

[epoch: 588/1000, batch:   476/ 1052, ite: 154500] train loss: 0.004107, tar: 0.000073 
l0: 0.000029, l1: 0.000028, l2: 0.000070, l3: 0.000197, l4: 0.000536, l5: 0.001364, l6: 0.001952

[epoch: 588/1000, batch:   556/ 1052, ite: 154520] train loss: 0.004106, tar: 0.000073 
l0: 0.000085, l1: 0.000087, l2: 0.000105, l3: 0.000134, l4: 0.000399, l5: 0.001284, l6: 0.001588

[epoch: 588/1000, batch:   636/ 1052, ite: 154540] train loss: 0.004106, tar: 0.000073 
l0: 0.000018, l1: 0.000017, l2: 0.000041, l3: 0.000079, l4: 0.000256, l5: 0.000553, l6: 0.001182

[epoch: 588/1000, batch:   716/ 1052, ite: 154560] train loss: 0.004105, tar: 0.000073 
l0: 0.000215, l1: 0.000214, l2: 0.000276, l3: 0.000416, l4: 0.000693, l5: 0.001484, l6: 0.003402

[epoch: 588/1000, batch:   796/ 1052, ite: 154580] train loss: 0.004106, tar: 0.000073 
l0: 0.000011, l1: 0.000011, l2: 0.000032, l3: 0.000125, l4: 0.000251, l5: 0.000636, l6: 0.001747

[epoch: 588/1000, batch:   876/ 1052, ite: 154600] train loss: 0.004105, tar: 0.000073 
l0: 0.000025, l1: 0.000024, l2: 0.000058, l3: 0.000142, l4: 0.000360, l5: 0.001270, l6: 0.001894

[epoch: 588/1000, batch:   956/ 1052, ite: 154620] train loss: 0.004106, tar: 0.000073 
l0: 0.000022, l1: 0.000023, l2: 0.000039, l3: 0.000087, l4: 0.000221, l5: 0.000751, l6: 0.001095

[epoch: 588/1000, batch:  1036/ 1052, ite: 154640] train loss: 0.004104, tar: 0.000073 
[Epoch 588/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000220, l1: 0.000205, l2: 0.000185, l3: 0.000221, l4: 0.000434, l5: 0.000958, l6: 0.002263

[epoch: 589/1000, batch:    64/ 1052, ite: 154660] train loss: 0.004104, tar: 0.000073 
l0: 0.000016, l1: 0.000015, l2: 0.000052, l3: 0.000132, l4: 0.000355, l5: 0.000711, l6: 0.001404

[epoch: 589/1000, batch:   144/ 1052, ite: 154680] train loss: 0.004105, tar: 0.000073 
l0: 0.000053, l1: 0.000051, l2: 0.000149, l3: 0.000227, l4: 0.000417, l5: 0.000961, l6: 0.002831

[epoch: 589/1000, batch:   224/ 1052, ite: 154700] train loss: 0.004104, tar: 0.000072 
l0: 0.000121, l1: 0.000120, l2: 0.000136, l3: 0.000237, l4: 0.000498, l5: 0.001018, l6: 0.002407

[epoch: 589/1000, batch:   304/ 1052, ite: 154720] train loss: 0.004102, tar: 0.000072 
l0: 0.000118, l1: 0.000122, l2: 0.000179, l3: 0.000306, l4: 0.000692, l5: 0.001575, l6: 0.002972

[epoch: 589/1000, batch:   384/ 1052, ite: 154740] train loss: 0.004103, tar: 0.000072 
l0: 0.000061, l1: 0.000060, l2: 0.000132, l3: 0.000259, l4: 0.000793, l5: 0.002616, l6: 0.004040

[epoch: 589/1000, batch:   464/ 1052, ite: 154760] train loss: 0.004105, tar: 0.000072 
l0: 0.000051, l1: 0.000052, l2: 0.000090, l3: 0.000191, l4: 0.000218, l5: 0.000498, l6: 0.000614

[epoch: 589/1000, batch:   544/ 1052, ite: 154780] train loss: 0.004105, tar: 0.000072 
l0: 0.000075, l1: 0.000077, l2: 0.000151, l3: 0.000224, l4: 0.000727, l5: 0.001433, l6: 0.001780

[epoch: 589/1000, batch:   624/ 1052, ite: 154800] train loss: 0.004105, tar: 0.000072 
l0: 0.000043, l1: 0.000044, l2: 0.000102, l3: 0.000242, l4: 0.000437, l5: 0.001237, l6: 0.001676

[epoch: 589/1000, batch:   704/ 1052, ite: 154820] train loss: 0.004104, tar: 0.000072 
l0: 0.000098, l1: 0.000096, l2: 0.000153, l3: 0.000467, l4: 0.000902, l5: 0.001674, l6: 0.002166

[epoch: 589/1000, batch:   784/ 1052, ite: 154840] train loss: 0.004104, tar: 0.000072 
l0: 0.000040, l1: 0.000040, l2: 0.000171, l3: 0.000244, l4: 0.000526, l5: 0.001145, l6: 0.001507

[epoch: 589/1000, batch:   864/ 1052, ite: 154860] train loss: 0.004104, tar: 0.000072 
l0: 0.000114, l1: 0.000111, l2: 0.000198, l3: 0.000282, l4: 0.000499, l5: 0.001022, l6: 0.001417

[epoch: 589/1000, batch:   944/ 1052, ite: 154880] train loss: 0.004103, tar: 0.000072 
l0: 0.000047, l1: 0.000047, l2: 0.000096, l3: 0.000201, l4: 0.000383, l5: 0.000847, l6: 0.001886

[epoch: 589/1000, batch:  1024/ 1052, ite: 154900] train loss: 0.004102, tar: 0.000072 
[Epoch 589/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000025, l1: 0.000025, l2: 0.000057, l3: 0.000140, l4: 0.000241, l5: 0.000828, l6: 0.000760

[epoch: 590/1000, batch:    52/ 1052, ite: 154920] train loss: 0.004102, tar: 0.000072 
l0: 0.000042, l1: 0.000039, l2: 0.000105, l3: 0.000223, l4: 0.000457, l5: 0.001165, l6: 0.001942

[epoch: 590/1000, batch:   132/ 1052, ite: 154940] train loss: 0.004101, tar: 0.000072 
l0: 0.000103, l1: 0.000106, l2: 0.000087, l3: 0.000135, l4: 0.000265, l5: 0.000598, l6: 0.000567

[epoch: 590/1000, batch:   212/ 1052, ite: 154960] train loss: 0.004101, tar: 0.000072 
l0: 0.000148, l1: 0.000149, l2: 0.000218, l3: 0.000409, l4: 0.000875, l5: 0.003678, l6: 0.004059

[epoch: 590/1000, batch:   292/ 1052, ite: 154980] train loss: 0.004102, tar: 0.000072 
l0: 0.000028, l1: 0.000027, l2: 0.000066, l3: 0.000218, l4: 0.000575, l5: 0.001107, l6: 0.001888

[epoch: 590/1000, batch:   372/ 1052, ite: 155000] train loss: 0.004101, tar: 0.000072 
l0: 0.000027, l1: 0.000026, l2: 0.000115, l3: 0.000309, l4: 0.000661, l5: 0.001769, l6: 0.002600

[epoch: 590/1000, batch:   452/ 1052, ite: 155020] train loss: 0.004100, tar: 0.000072 
l0: 0.000028, l1: 0.000027, l2: 0.000053, l3: 0.000165, l4: 0.000316, l5: 0.000889, l6: 0.001126

[epoch: 590/1000, batch:   532/ 1052, ite: 155040] train loss: 0.004101, tar: 0.000072 
l0: 0.000081, l1: 0.000079, l2: 0.000206, l3: 0.000491, l4: 0.000879, l5: 0.001581, l6: 0.002102

[epoch: 590/1000, batch:   612/ 1052, ite: 155060] train loss: 0.004100, tar: 0.000072 
l0: 0.000032, l1: 0.000033, l2: 0.000050, l3: 0.000101, l4: 0.000167, l5: 0.000848, l6: 0.001674

[epoch: 590/1000, batch:   692/ 1052, ite: 155080] train loss: 0.004101, tar: 0.000072 
l0: 0.000053, l1: 0.000054, l2: 0.000113, l3: 0.000226, l4: 0.000450, l5: 0.001896, l6: 0.002461

[epoch: 590/1000, batch:   772/ 1052, ite: 155100] train loss: 0.004102, tar: 0.000072 
l0: 0.000052, l1: 0.000054, l2: 0.000107, l3: 0.000320, l4: 0.000556, l5: 0.000994, l6: 0.001478

[epoch: 590/1000, batch:   852/ 1052, ite: 155120] train loss: 0.004101, tar: 0.000072 
l0: 0.000161, l1: 0.000164, l2: 0.000208, l3: 0.000411, l4: 0.000889, l5: 0.001676, l6: 0.002926

[epoch: 590/1000, batch:   932/ 1052, ite: 155140] train loss: 0.004101, tar: 0.000072 
l0: 0.000042, l1: 0.000042, l2: 0.000079, l3: 0.000165, l4: 0.000334, l5: 0.001002, l6: 0.001999

[epoch: 590/1000, batch:  1012/ 1052, ite: 155160] train loss: 0.004100, tar: 0.000072 
[Epoch 590/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000026, l1: 0.000028, l2: 0.000042, l3: 0.000138, l4: 0.000321, l5: 0.001116, l6: 0.002079

[epoch: 591/1000, batch:    40/ 1052, ite: 155180] train loss: 0.004100, tar: 0.000072 
l0: 0.000024, l1: 0.000024, l2: 0.000058, l3: 0.000154, l4: 0.000393, l5: 0.001036, l6: 0.001642

[epoch: 591/1000, batch:   120/ 1052, ite: 155200] train loss: 0.004100, tar: 0.000072 
l0: 0.000137, l1: 0.000143, l2: 0.000185, l3: 0.000311, l4: 0.000807, l5: 0.002167, l6: 0.004481

[epoch: 591/1000, batch:   200/ 1052, ite: 155220] train loss: 0.004100, tar: 0.000072 
l0: 0.000088, l1: 0.000087, l2: 0.000126, l3: 0.000264, l4: 0.000605, l5: 0.001097, l6: 0.001928

[epoch: 591/1000, batch:   280/ 1052, ite: 155240] train loss: 0.004099, tar: 0.000072 
l0: 0.000069, l1: 0.000071, l2: 0.000142, l3: 0.000249, l4: 0.000628, l5: 0.001070, l6: 0.002237

[epoch: 591/1000, batch:   360/ 1052, ite: 155260] train loss: 0.004099, tar: 0.000072 
l0: 0.000088, l1: 0.000087, l2: 0.000118, l3: 0.000247, l4: 0.000476, l5: 0.001334, l6: 0.001521

[epoch: 591/1000, batch:   440/ 1052, ite: 155280] train loss: 0.004099, tar: 0.000072 
l0: 0.000049, l1: 0.000049, l2: 0.000092, l3: 0.000235, l4: 0.000522, l5: 0.000801, l6: 0.001695

[epoch: 591/1000, batch:   520/ 1052, ite: 155300] train loss: 0.004098, tar: 0.000072 
l0: 0.000032, l1: 0.000030, l2: 0.000086, l3: 0.000136, l4: 0.000281, l5: 0.000632, l6: 0.001188

[epoch: 591/1000, batch:   600/ 1052, ite: 155320] train loss: 0.004097, tar: 0.000071 
l0: 0.000203, l1: 0.000201, l2: 0.000294, l3: 0.000483, l4: 0.001209, l5: 0.003036, l6: 0.005652

[epoch: 591/1000, batch:   680/ 1052, ite: 155340] train loss: 0.004097, tar: 0.000071 
l0: 0.000028, l1: 0.000029, l2: 0.000076, l3: 0.000183, l4: 0.000352, l5: 0.001041, l6: 0.001472

[epoch: 591/1000, batch:   760/ 1052, ite: 155360] train loss: 0.004099, tar: 0.000071 
l0: 0.000060, l1: 0.000059, l2: 0.000078, l3: 0.000116, l4: 0.000428, l5: 0.000805, l6: 0.002254

[epoch: 591/1000, batch:   840/ 1052, ite: 155380] train loss: 0.004100, tar: 0.000071 
l0: 0.000047, l1: 0.000047, l2: 0.000059, l3: 0.000235, l4: 0.000412, l5: 0.000823, l6: 0.001795

[epoch: 591/1000, batch:   920/ 1052, ite: 155400] train loss: 0.004102, tar: 0.000072 
l0: 0.000070, l1: 0.000072, l2: 0.000150, l3: 0.000332, l4: 0.000663, l5: 0.001562, l6: 0.002975

[epoch: 591/1000, batch:  1000/ 1052, ite: 155420] train loss: 0.004100, tar: 0.000071 
[Epoch 591/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000050, l1: 0.000049, l2: 0.000089, l3: 0.000193, l4: 0.000472, l5: 0.000983, l6: 0.001656

[epoch: 592/1000, batch:    28/ 1052, ite: 155440] train loss: 0.004099, tar: 0.000071 
l0: 0.000037, l1: 0.000040, l2: 0.000034, l3: 0.000101, l4: 0.000286, l5: 0.000969, l6: 0.001629

[epoch: 592/1000, batch:   108/ 1052, ite: 155460] train loss: 0.004099, tar: 0.000071 
l0: 0.000028, l1: 0.000030, l2: 0.000153, l3: 0.000548, l4: 0.001182, l5: 0.001908, l6: 0.002684

[epoch: 592/1000, batch:   188/ 1052, ite: 155480] train loss: 0.004099, tar: 0.000071 
l0: 0.000045, l1: 0.000045, l2: 0.000141, l3: 0.000378, l4: 0.000968, l5: 0.001238, l6: 0.002316

[epoch: 592/1000, batch:   268/ 1052, ite: 155500] train loss: 0.004100, tar: 0.000071 
l0: 0.000100, l1: 0.000097, l2: 0.000120, l3: 0.000258, l4: 0.000506, l5: 0.001489, l6: 0.002705

[epoch: 592/1000, batch:   348/ 1052, ite: 155520] train loss: 0.004100, tar: 0.000071 
l0: 0.000055, l1: 0.000056, l2: 0.000079, l3: 0.000244, l4: 0.000436, l5: 0.000867, l6: 0.001404

[epoch: 592/1000, batch:   428/ 1052, ite: 155540] train loss: 0.004099, tar: 0.000071 
l0: 0.000053, l1: 0.000053, l2: 0.000115, l3: 0.000241, l4: 0.000698, l5: 0.001473, l6: 0.003008

[epoch: 592/1000, batch:   508/ 1052, ite: 155560] train loss: 0.004099, tar: 0.000071 
l0: 0.000101, l1: 0.000106, l2: 0.000152, l3: 0.000238, l4: 0.000421, l5: 0.001145, l6: 0.002518

[epoch: 592/1000, batch:   588/ 1052, ite: 155580] train loss: 0.004100, tar: 0.000071 
l0: 0.000031, l1: 0.000031, l2: 0.000105, l3: 0.000183, l4: 0.000473, l5: 0.001096, l6: 0.002458

[epoch: 592/1000, batch:   668/ 1052, ite: 155600] train loss: 0.004099, tar: 0.000071 
l0: 0.000031, l1: 0.000032, l2: 0.000051, l3: 0.000224, l4: 0.000390, l5: 0.001173, l6: 0.001492

[epoch: 592/1000, batch:   748/ 1052, ite: 155620] train loss: 0.004099, tar: 0.000071 
l0: 0.000053, l1: 0.000052, l2: 0.000096, l3: 0.000175, l4: 0.000487, l5: 0.000620, l6: 0.001673

[epoch: 592/1000, batch:   828/ 1052, ite: 155640] train loss: 0.004100, tar: 0.000071 
l0: 0.000121, l1: 0.000126, l2: 0.000153, l3: 0.000225, l4: 0.000350, l5: 0.001244, l6: 0.001606

[epoch: 592/1000, batch:   908/ 1052, ite: 155660] train loss: 0.004100, tar: 0.000071 
l0: 0.000025, l1: 0.000022, l2: 0.000051, l3: 0.000140, l4: 0.000330, l5: 0.000637, l6: 0.001533

[epoch: 592/1000, batch:   988/ 1052, ite: 155680] train loss: 0.004100, tar: 0.000071 
[Epoch 592/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000042, l1: 0.000042, l2: 0.000061, l3: 0.000110, l4: 0.000303, l5: 0.000859, l6: 0.001076

[epoch: 593/1000, batch:    16/ 1052, ite: 155700] train loss: 0.004099, tar: 0.000071 
l0: 0.000181, l1: 0.000178, l2: 0.000162, l3: 0.000269, l4: 0.000774, l5: 0.001239, l6: 0.002694

[epoch: 593/1000, batch:    96/ 1052, ite: 155720] train loss: 0.004098, tar: 0.000071 
l0: 0.000061, l1: 0.000061, l2: 0.000102, l3: 0.000196, l4: 0.000390, l5: 0.001050, l6: 0.003789

[epoch: 593/1000, batch:   176/ 1052, ite: 155740] train loss: 0.004098, tar: 0.000071 
l0: 0.000055, l1: 0.000055, l2: 0.000064, l3: 0.000142, l4: 0.000336, l5: 0.000396, l6: 0.001076

[epoch: 593/1000, batch:   256/ 1052, ite: 155760] train loss: 0.004097, tar: 0.000071 
l0: 0.000010, l1: 0.000011, l2: 0.000041, l3: 0.000111, l4: 0.000545, l5: 0.001056, l6: 0.001596

[epoch: 593/1000, batch:   336/ 1052, ite: 155780] train loss: 0.004096, tar: 0.000071 
l0: 0.000058, l1: 0.000057, l2: 0.000107, l3: 0.000179, l4: 0.000492, l5: 0.001052, l6: 0.001689

[epoch: 593/1000, batch:   416/ 1052, ite: 155800] train loss: 0.004097, tar: 0.000071 
l0: 0.000021, l1: 0.000021, l2: 0.000059, l3: 0.000137, l4: 0.000343, l5: 0.000574, l6: 0.001190

[epoch: 593/1000, batch:   496/ 1052, ite: 155820] train loss: 0.004097, tar: 0.000071 
l0: 0.000064, l1: 0.000066, l2: 0.000116, l3: 0.000232, l4: 0.000605, l5: 0.001440, l6: 0.002098

[epoch: 593/1000, batch:   576/ 1052, ite: 155840] train loss: 0.004097, tar: 0.000071 
l0: 0.000039, l1: 0.000042, l2: 0.000070, l3: 0.000138, l4: 0.000418, l5: 0.000986, l6: 0.002576

[epoch: 593/1000, batch:   656/ 1052, ite: 155860] train loss: 0.004097, tar: 0.000071 
l0: 0.000093, l1: 0.000093, l2: 0.000131, l3: 0.000328, l4: 0.000887, l5: 0.001858, l6: 0.002653

[epoch: 593/1000, batch:   736/ 1052, ite: 155880] train loss: 0.004097, tar: 0.000071 
l0: 0.000023, l1: 0.000025, l2: 0.000040, l3: 0.000118, l4: 0.000326, l5: 0.000912, l6: 0.001387

[epoch: 593/1000, batch:   816/ 1052, ite: 155900] train loss: 0.004097, tar: 0.000071 
l0: 0.000171, l1: 0.000171, l2: 0.000267, l3: 0.000545, l4: 0.001286, l5: 0.001928, l6: 0.004200

[epoch: 593/1000, batch:   896/ 1052, ite: 155920] train loss: 0.004098, tar: 0.000071 
l0: 0.000105, l1: 0.000105, l2: 0.000110, l3: 0.000221, l4: 0.000559, l5: 0.001525, l6: 0.001960

[epoch: 593/1000, batch:   976/ 1052, ite: 155940] train loss: 0.004098, tar: 0.000071 
[Epoch 593/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000079, l1: 0.000078, l2: 0.000144, l3: 0.000245, l4: 0.000476, l5: 0.000671, l6: 0.001595

[epoch: 594/1000, batch:     4/ 1052, ite: 155960] train loss: 0.004098, tar: 0.000071 
l0: 0.000054, l1: 0.000055, l2: 0.000109, l3: 0.000289, l4: 0.000599, l5: 0.001625, l6: 0.002569

[epoch: 594/1000, batch:    84/ 1052, ite: 155980] train loss: 0.004098, tar: 0.000071 
l0: 0.000061, l1: 0.000063, l2: 0.000076, l3: 0.000191, l4: 0.000563, l5: 0.001507, l6: 0.001321

[epoch: 594/1000, batch:   164/ 1052, ite: 156000] train loss: 0.004099, tar: 0.000071 
l0: 0.000026, l1: 0.000026, l2: 0.000040, l3: 0.000117, l4: 0.000250, l5: 0.000677, l6: 0.001746

[epoch: 594/1000, batch:   244/ 1052, ite: 156020] train loss: 0.004097, tar: 0.000071 
l0: 0.000037, l1: 0.000038, l2: 0.000083, l3: 0.000182, l4: 0.000422, l5: 0.001299, l6: 0.001996

[epoch: 594/1000, batch:   324/ 1052, ite: 156040] train loss: 0.004097, tar: 0.000071 
l0: 0.000128, l1: 0.000136, l2: 0.000134, l3: 0.000149, l4: 0.000442, l5: 0.001113, l6: 0.001209

[epoch: 594/1000, batch:   404/ 1052, ite: 156060] train loss: 0.004097, tar: 0.000071 
l0: 0.000071, l1: 0.000070, l2: 0.000113, l3: 0.000287, l4: 0.000510, l5: 0.001076, l6: 0.001336

[epoch: 594/1000, batch:   484/ 1052, ite: 156080] train loss: 0.004096, tar: 0.000071 
l0: 0.000086, l1: 0.000087, l2: 0.000111, l3: 0.000178, l4: 0.000286, l5: 0.000428, l6: 0.001529

[epoch: 594/1000, batch:   564/ 1052, ite: 156100] train loss: 0.004095, tar: 0.000071 
l0: 0.000068, l1: 0.000069, l2: 0.000099, l3: 0.000176, l4: 0.000333, l5: 0.001028, l6: 0.002808

[epoch: 594/1000, batch:   644/ 1052, ite: 156120] train loss: 0.004096, tar: 0.000071 
l0: 0.000137, l1: 0.000134, l2: 0.000181, l3: 0.000250, l4: 0.000687, l5: 0.001356, l6: 0.002184

[epoch: 594/1000, batch:   724/ 1052, ite: 156140] train loss: 0.004096, tar: 0.000071 
l0: 0.000047, l1: 0.000045, l2: 0.000115, l3: 0.000299, l4: 0.000668, l5: 0.001444, l6: 0.002754

[epoch: 594/1000, batch:   804/ 1052, ite: 156160] train loss: 0.004096, tar: 0.000071 
l0: 0.000060, l1: 0.000062, l2: 0.000096, l3: 0.000160, l4: 0.000347, l5: 0.000882, l6: 0.001896

[epoch: 594/1000, batch:   884/ 1052, ite: 156180] train loss: 0.004096, tar: 0.000071 
l0: 0.000046, l1: 0.000045, l2: 0.000075, l3: 0.000126, l4: 0.000297, l5: 0.000626, l6: 0.000774

[epoch: 594/1000, batch:   964/ 1052, ite: 156200] train loss: 0.004097, tar: 0.000071 
l0: 0.000069, l1: 0.000067, l2: 0.000093, l3: 0.000174, l4: 0.000497, l5: 0.000920, l6: 0.001636

[epoch: 594/1000, batch:  1044/ 1052, ite: 156220] train loss: 0.004097, tar: 0.000071 
[Epoch 594/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000094, l1: 0.000093, l2: 0.000118, l3: 0.000218, l4: 0.000635, l5: 0.001243, l6: 0.003320

[epoch: 595/1000, batch:    72/ 1052, ite: 156240] train loss: 0.004096, tar: 0.000071 
l0: 0.000032, l1: 0.000030, l2: 0.000057, l3: 0.000175, l4: 0.000385, l5: 0.000943, l6: 0.001837

[epoch: 595/1000, batch:   152/ 1052, ite: 156260] train loss: 0.004097, tar: 0.000071 
l0: 0.000065, l1: 0.000067, l2: 0.000077, l3: 0.000136, l4: 0.000275, l5: 0.000865, l6: 0.001131

[epoch: 595/1000, batch:   232/ 1052, ite: 156280] train loss: 0.004097, tar: 0.000071 
l0: 0.000022, l1: 0.000023, l2: 0.000055, l3: 0.000129, l4: 0.000347, l5: 0.001136, l6: 0.001457

[epoch: 595/1000, batch:   312/ 1052, ite: 156300] train loss: 0.004097, tar: 0.000071 
l0: 0.000081, l1: 0.000083, l2: 0.000134, l3: 0.000215, l4: 0.000551, l5: 0.001075, l6: 0.002267

[epoch: 595/1000, batch:   392/ 1052, ite: 156320] train loss: 0.004097, tar: 0.000071 
l0: 0.000032, l1: 0.000032, l2: 0.000077, l3: 0.000255, l4: 0.000492, l5: 0.001404, l6: 0.002194

[epoch: 595/1000, batch:   472/ 1052, ite: 156340] train loss: 0.004097, tar: 0.000071 
l0: 0.000035, l1: 0.000033, l2: 0.000093, l3: 0.000234, l4: 0.000605, l5: 0.001469, l6: 0.002670

[epoch: 595/1000, batch:   552/ 1052, ite: 156360] train loss: 0.004097, tar: 0.000071 
l0: 0.000038, l1: 0.000038, l2: 0.000085, l3: 0.000238, l4: 0.000394, l5: 0.000754, l6: 0.001781

[epoch: 595/1000, batch:   632/ 1052, ite: 156380] train loss: 0.004096, tar: 0.000071 
l0: 0.000089, l1: 0.000091, l2: 0.000138, l3: 0.000315, l4: 0.001020, l5: 0.001990, l6: 0.003104

[epoch: 595/1000, batch:   712/ 1052, ite: 156400] train loss: 0.004095, tar: 0.000071 
l0: 0.000128, l1: 0.000138, l2: 0.000217, l3: 0.000472, l4: 0.000786, l5: 0.001854, l6: 0.003982

[epoch: 595/1000, batch:   792/ 1052, ite: 156420] train loss: 0.004095, tar: 0.000070 
l0: 0.000027, l1: 0.000028, l2: 0.000045, l3: 0.000108, l4: 0.000376, l5: 0.000776, l6: 0.001240

[epoch: 595/1000, batch:   872/ 1052, ite: 156440] train loss: 0.004095, tar: 0.000071 
l0: 0.000145, l1: 0.000143, l2: 0.000218, l3: 0.000287, l4: 0.000635, l5: 0.001263, l6: 0.002826

[epoch: 595/1000, batch:   952/ 1052, ite: 156460] train loss: 0.004096, tar: 0.000071 
l0: 0.000046, l1: 0.000047, l2: 0.000089, l3: 0.000170, l4: 0.000458, l5: 0.001303, l6: 0.001253

[epoch: 595/1000, batch:  1032/ 1052, ite: 156480] train loss: 0.004097, tar: 0.000071 
[Epoch 595/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000085, l1: 0.000085, l2: 0.000102, l3: 0.000158, l4: 0.000400, l5: 0.000867, l6: 0.001502

[epoch: 596/1000, batch:    60/ 1052, ite: 156500] train loss: 0.004097, tar: 0.000071 
l0: 0.000043, l1: 0.000042, l2: 0.000104, l3: 0.000320, l4: 0.000609, l5: 0.001125, l6: 0.002442

[epoch: 596/1000, batch:   140/ 1052, ite: 156520] train loss: 0.004097, tar: 0.000071 
l0: 0.000160, l1: 0.000159, l2: 0.000196, l3: 0.000308, l4: 0.000522, l5: 0.000908, l6: 0.001819

[epoch: 596/1000, batch:   220/ 1052, ite: 156540] train loss: 0.004099, tar: 0.000071 
l0: 0.000017, l1: 0.000017, l2: 0.000045, l3: 0.000095, l4: 0.000204, l5: 0.000276, l6: 0.000827

[epoch: 596/1000, batch:   300/ 1052, ite: 156560] train loss: 0.004098, tar: 0.000070 
l0: 0.000064, l1: 0.000065, l2: 0.000071, l3: 0.000156, l4: 0.000344, l5: 0.000538, l6: 0.001310

[epoch: 596/1000, batch:   380/ 1052, ite: 156580] train loss: 0.004097, tar: 0.000070 
l0: 0.000095, l1: 0.000099, l2: 0.000154, l3: 0.000231, l4: 0.000537, l5: 0.001895, l6: 0.003599

[epoch: 596/1000, batch:   460/ 1052, ite: 156600] train loss: 0.004097, tar: 0.000070 
l0: 0.000072, l1: 0.000067, l2: 0.000179, l3: 0.000350, l4: 0.000824, l5: 0.001399, l6: 0.003241

[epoch: 596/1000, batch:   540/ 1052, ite: 156620] train loss: 0.004097, tar: 0.000070 
l0: 0.000025, l1: 0.000027, l2: 0.000045, l3: 0.000114, l4: 0.000415, l5: 0.000857, l6: 0.001250

[epoch: 596/1000, batch:   620/ 1052, ite: 156640] train loss: 0.004097, tar: 0.000070 
l0: 0.000028, l1: 0.000027, l2: 0.000028, l3: 0.000085, l4: 0.000342, l5: 0.000560, l6: 0.000746

[epoch: 596/1000, batch:   700/ 1052, ite: 156660] train loss: 0.004097, tar: 0.000070 
l0: 0.000151, l1: 0.000152, l2: 0.000210, l3: 0.000419, l4: 0.000944, l5: 0.002020, l6: 0.003915

[epoch: 596/1000, batch:   780/ 1052, ite: 156680] train loss: 0.004098, tar: 0.000070 
l0: 0.000024, l1: 0.000024, l2: 0.000058, l3: 0.000173, l4: 0.000361, l5: 0.000548, l6: 0.001558

[epoch: 596/1000, batch:   860/ 1052, ite: 156700] train loss: 0.004098, tar: 0.000070 
l0: 0.000061, l1: 0.000064, l2: 0.000095, l3: 0.000182, l4: 0.000441, l5: 0.001032, l6: 0.001067

[epoch: 596/1000, batch:   940/ 1052, ite: 156720] train loss: 0.004097, tar: 0.000070 
l0: 0.000021, l1: 0.000020, l2: 0.000063, l3: 0.000135, l4: 0.000256, l5: 0.000971, l6: 0.001641

[epoch: 596/1000, batch:  1020/ 1052, ite: 156740] train loss: 0.004096, tar: 0.000070 
[Epoch 596/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000037, l1: 0.000037, l2: 0.000084, l3: 0.000224, l4: 0.000596, l5: 0.001563, l6: 0.002865

[epoch: 597/1000, batch:    48/ 1052, ite: 156760] train loss: 0.004097, tar: 0.000070 
l0: 0.000023, l1: 0.000024, l2: 0.000083, l3: 0.000409, l4: 0.000627, l5: 0.001497, l6: 0.002310

[epoch: 597/1000, batch:   128/ 1052, ite: 156780] train loss: 0.004097, tar: 0.000070 
l0: 0.000033, l1: 0.000035, l2: 0.000074, l3: 0.000125, l4: 0.000341, l5: 0.001119, l6: 0.001672

[epoch: 597/1000, batch:   208/ 1052, ite: 156800] train loss: 0.004097, tar: 0.000070 
l0: 0.000058, l1: 0.000057, l2: 0.000107, l3: 0.000266, l4: 0.000513, l5: 0.000991, l6: 0.002139

[epoch: 597/1000, batch:   288/ 1052, ite: 156820] train loss: 0.004095, tar: 0.000070 
l0: 0.000118, l1: 0.000120, l2: 0.000191, l3: 0.000291, l4: 0.000507, l5: 0.001763, l6: 0.002367

[epoch: 597/1000, batch:   368/ 1052, ite: 156840] train loss: 0.004095, tar: 0.000070 
l0: 0.000039, l1: 0.000040, l2: 0.000065, l3: 0.000106, l4: 0.000288, l5: 0.000828, l6: 0.001176

[epoch: 597/1000, batch:   448/ 1052, ite: 156860] train loss: 0.004095, tar: 0.000070 
l0: 0.000033, l1: 0.000030, l2: 0.000078, l3: 0.000110, l4: 0.000371, l5: 0.000908, l6: 0.001296

[epoch: 597/1000, batch:   528/ 1052, ite: 156880] train loss: 0.004094, tar: 0.000070 
l0: 0.000002, l1: 0.000002, l2: 0.000020, l3: 0.000080, l4: 0.000210, l5: 0.000539, l6: 0.000714

[epoch: 597/1000, batch:   608/ 1052, ite: 156900] train loss: 0.004093, tar: 0.000070 
l0: 0.000030, l1: 0.000030, l2: 0.000067, l3: 0.000181, l4: 0.000339, l5: 0.001080, l6: 0.001106

[epoch: 597/1000, batch:   688/ 1052, ite: 156920] train loss: 0.004093, tar: 0.000070 
l0: 0.000061, l1: 0.000063, l2: 0.000109, l3: 0.000259, l4: 0.000529, l5: 0.001688, l6: 0.003103

[epoch: 597/1000, batch:   768/ 1052, ite: 156940] train loss: 0.004094, tar: 0.000070 
l0: 0.000063, l1: 0.000062, l2: 0.000098, l3: 0.000210, l4: 0.000685, l5: 0.000871, l6: 0.001601

[epoch: 597/1000, batch:   848/ 1052, ite: 156960] train loss: 0.004094, tar: 0.000070 
l0: 0.000110, l1: 0.000111, l2: 0.000154, l3: 0.000277, l4: 0.000829, l5: 0.002127, l6: 0.002898

[epoch: 597/1000, batch:   928/ 1052, ite: 156980] train loss: 0.004094, tar: 0.000070 
l0: 0.000023, l1: 0.000022, l2: 0.000066, l3: 0.000185, l4: 0.000507, l5: 0.000718, l6: 0.001838

[epoch: 597/1000, batch:  1008/ 1052, ite: 157000] train loss: 0.004094, tar: 0.000070 
[Epoch 597/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000044, l1: 0.000043, l2: 0.000105, l3: 0.000232, l4: 0.000387, l5: 0.000743, l6: 0.001385

[epoch: 598/1000, batch:    36/ 1052, ite: 157020] train loss: 0.004094, tar: 0.000070 
l0: 0.000079, l1: 0.000081, l2: 0.000140, l3: 0.000226, l4: 0.000507, l5: 0.001476, l6: 0.002868

[epoch: 598/1000, batch:   116/ 1052, ite: 157040] train loss: 0.004093, tar: 0.000070 
l0: 0.000028, l1: 0.000028, l2: 0.000070, l3: 0.000188, l4: 0.000569, l5: 0.001608, l6: 0.002901

[epoch: 598/1000, batch:   196/ 1052, ite: 157060] train loss: 0.004093, tar: 0.000070 
l0: 0.000105, l1: 0.000102, l2: 0.000103, l3: 0.000177, l4: 0.000511, l5: 0.001052, l6: 0.001444

[epoch: 598/1000, batch:   276/ 1052, ite: 157080] train loss: 0.004093, tar: 0.000070 
l0: 0.000039, l1: 0.000039, l2: 0.000123, l3: 0.000276, l4: 0.000682, l5: 0.001395, l6: 0.002034

[epoch: 598/1000, batch:   356/ 1052, ite: 157100] train loss: 0.004094, tar: 0.000070 
l0: 0.000043, l1: 0.000044, l2: 0.000075, l3: 0.000185, l4: 0.000437, l5: 0.001098, l6: 0.001910

[epoch: 598/1000, batch:   436/ 1052, ite: 157120] train loss: 0.004093, tar: 0.000070 
l0: 0.000071, l1: 0.000072, l2: 0.000091, l3: 0.000155, l4: 0.000334, l5: 0.000681, l6: 0.001348

[epoch: 598/1000, batch:   516/ 1052, ite: 157140] train loss: 0.004093, tar: 0.000070 
l0: 0.000035, l1: 0.000034, l2: 0.000064, l3: 0.000093, l4: 0.000328, l5: 0.000836, l6: 0.001099

[epoch: 598/1000, batch:   596/ 1052, ite: 157160] train loss: 0.004092, tar: 0.000070 
l0: 0.000071, l1: 0.000072, l2: 0.000152, l3: 0.000357, l4: 0.000701, l5: 0.001632, l6: 0.003253

[epoch: 598/1000, batch:   676/ 1052, ite: 157180] train loss: 0.004093, tar: 0.000070 
l0: 0.000040, l1: 0.000042, l2: 0.000086, l3: 0.000196, l4: 0.000425, l5: 0.000717, l6: 0.001394

[epoch: 598/1000, batch:   756/ 1052, ite: 157200] train loss: 0.004093, tar: 0.000070 
l0: 0.000026, l1: 0.000025, l2: 0.000077, l3: 0.000145, l4: 0.000479, l5: 0.001246, l6: 0.001791

[epoch: 598/1000, batch:   836/ 1052, ite: 157220] train loss: 0.004092, tar: 0.000070 
l0: 0.000036, l1: 0.000039, l2: 0.000061, l3: 0.000328, l4: 0.000583, l5: 0.001565, l6: 0.001849

[epoch: 598/1000, batch:   916/ 1052, ite: 157240] train loss: 0.004093, tar: 0.000070 
l0: 0.000127, l1: 0.000123, l2: 0.000195, l3: 0.000366, l4: 0.000558, l5: 0.002045, l6: 0.002978

[epoch: 598/1000, batch:   996/ 1052, ite: 157260] train loss: 0.004092, tar: 0.000070 
[Epoch 598/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000022, l1: 0.000023, l2: 0.000058, l3: 0.000160, l4: 0.000405, l5: 0.000756, l6: 0.002250

[epoch: 599/1000, batch:    24/ 1052, ite: 157280] train loss: 0.004092, tar: 0.000070 
l0: 0.000075, l1: 0.000074, l2: 0.000133, l3: 0.000259, l4: 0.000468, l5: 0.000730, l6: 0.002538

[epoch: 599/1000, batch:   104/ 1052, ite: 157300] train loss: 0.004093, tar: 0.000070 
l0: 0.000029, l1: 0.000028, l2: 0.000102, l3: 0.000224, l4: 0.000303, l5: 0.000902, l6: 0.001733

[epoch: 599/1000, batch:   184/ 1052, ite: 157320] train loss: 0.004093, tar: 0.000070 
l0: 0.000063, l1: 0.000061, l2: 0.000100, l3: 0.000178, l4: 0.000341, l5: 0.001234, l6: 0.001378

[epoch: 599/1000, batch:   264/ 1052, ite: 157340] train loss: 0.004093, tar: 0.000070 
l0: 0.000045, l1: 0.000045, l2: 0.000056, l3: 0.000099, l4: 0.000236, l5: 0.000682, l6: 0.001267

[epoch: 599/1000, batch:   344/ 1052, ite: 157360] train loss: 0.004092, tar: 0.000070 
l0: 0.000030, l1: 0.000034, l2: 0.000033, l3: 0.000116, l4: 0.000264, l5: 0.000643, l6: 0.001231

[epoch: 599/1000, batch:   424/ 1052, ite: 157380] train loss: 0.004092, tar: 0.000070 
l0: 0.000156, l1: 0.000156, l2: 0.000273, l3: 0.000425, l4: 0.000712, l5: 0.001004, l6: 0.002981

[epoch: 599/1000, batch:   504/ 1052, ite: 157400] train loss: 0.004091, tar: 0.000070 
l0: 0.000045, l1: 0.000044, l2: 0.000079, l3: 0.000116, l4: 0.000312, l5: 0.000661, l6: 0.001089

[epoch: 599/1000, batch:   584/ 1052, ite: 157420] train loss: 0.004091, tar: 0.000070 
l0: 0.000063, l1: 0.000061, l2: 0.000085, l3: 0.000127, l4: 0.000275, l5: 0.000806, l6: 0.001282

[epoch: 599/1000, batch:   664/ 1052, ite: 157440] train loss: 0.004090, tar: 0.000070 
l0: 0.000185, l1: 0.000196, l2: 0.000179, l3: 0.000277, l4: 0.000720, l5: 0.000871, l6: 0.001789

[epoch: 599/1000, batch:   744/ 1052, ite: 157460] train loss: 0.004091, tar: 0.000070 
l0: 0.000085, l1: 0.000084, l2: 0.000111, l3: 0.000240, l4: 0.000470, l5: 0.000877, l6: 0.001379

[epoch: 599/1000, batch:   824/ 1052, ite: 157480] train loss: 0.004091, tar: 0.000070 
l0: 0.000068, l1: 0.000070, l2: 0.000130, l3: 0.000252, l4: 0.000648, l5: 0.001545, l6: 0.003282

[epoch: 599/1000, batch:   904/ 1052, ite: 157500] train loss: 0.004090, tar: 0.000070 
l0: 0.000021, l1: 0.000022, l2: 0.000033, l3: 0.000065, l4: 0.000326, l5: 0.000555, l6: 0.000977

[epoch: 599/1000, batch:   984/ 1052, ite: 157520] train loss: 0.004090, tar: 0.000070 
[Epoch 599/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000011, l1: 0.000011, l2: 0.000032, l3: 0.000124, l4: 0.000354, l5: 0.000579, l6: 0.001581

[epoch: 600/1000, batch:    12/ 1052, ite: 157540] train loss: 0.004089, tar: 0.000069 
l0: 0.000053, l1: 0.000053, l2: 0.000071, l3: 0.000180, l4: 0.000382, l5: 0.000707, l6: 0.001474

[epoch: 600/1000, batch:    92/ 1052, ite: 157560] train loss: 0.004089, tar: 0.000069 
l0: 0.000045, l1: 0.000047, l2: 0.000076, l3: 0.000153, l4: 0.000330, l5: 0.001288, l6: 0.002023

[epoch: 600/1000, batch:   172/ 1052, ite: 157580] train loss: 0.004088, tar: 0.000069 
l0: 0.000036, l1: 0.000036, l2: 0.000072, l3: 0.000155, l4: 0.000248, l5: 0.000849, l6: 0.000884

[epoch: 600/1000, batch:   252/ 1052, ite: 157600] train loss: 0.004089, tar: 0.000069 
l0: 0.000052, l1: 0.000053, l2: 0.000097, l3: 0.000166, l4: 0.000383, l5: 0.000828, l6: 0.001577

[epoch: 600/1000, batch:   332/ 1052, ite: 157620] train loss: 0.004087, tar: 0.000069 
l0: 0.000018, l1: 0.000019, l2: 0.000067, l3: 0.000155, l4: 0.000516, l5: 0.000962, l6: 0.001888

[epoch: 600/1000, batch:   412/ 1052, ite: 157640] train loss: 0.004086, tar: 0.000069 
l0: 0.000038, l1: 0.000037, l2: 0.000065, l3: 0.000175, l4: 0.000456, l5: 0.001079, l6: 0.002158

[epoch: 600/1000, batch:   492/ 1052, ite: 157660] train loss: 0.004086, tar: 0.000069 
l0: 0.000126, l1: 0.000134, l2: 0.000310, l3: 0.000510, l4: 0.000860, l5: 0.002055, l6: 0.003739

[epoch: 600/1000, batch:   572/ 1052, ite: 157680] train loss: 0.004087, tar: 0.000069 
l0: 0.000059, l1: 0.000060, l2: 0.000096, l3: 0.000146, l4: 0.000242, l5: 0.000519, l6: 0.001236

[epoch: 600/1000, batch:   652/ 1052, ite: 157700] train loss: 0.004087, tar: 0.000069 
l0: 0.000048, l1: 0.000050, l2: 0.000088, l3: 0.000167, l4: 0.000471, l5: 0.000957, l6: 0.002529

[epoch: 600/1000, batch:   732/ 1052, ite: 157720] train loss: 0.004087, tar: 0.000069 
l0: 0.000022, l1: 0.000026, l2: 0.000040, l3: 0.000138, l4: 0.000424, l5: 0.000436, l6: 0.001245

[epoch: 600/1000, batch:   812/ 1052, ite: 157740] train loss: 0.004087, tar: 0.000069 
l0: 0.000028, l1: 0.000032, l2: 0.000051, l3: 0.000134, l4: 0.000215, l5: 0.000700, l6: 0.001257

[epoch: 600/1000, batch:   892/ 1052, ite: 157760] train loss: 0.004087, tar: 0.000069 
l0: 0.000065, l1: 0.000061, l2: 0.000100, l3: 0.000246, l4: 0.000418, l5: 0.001214, l6: 0.002915

[epoch: 600/1000, batch:   972/ 1052, ite: 157780] train loss: 0.004088, tar: 0.000069 
l0: 0.000157, l1: 0.000152, l2: 0.000212, l3: 0.000421, l4: 0.000901, l5: 0.002438, l6: 0.004049

[epoch: 600/1000, batch:  1052/ 1052, ite: 157800] train loss: 0.004089, tar: 0.000069 
[Epoch 600/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000085, l1: 0.000086, l2: 0.000104, l3: 0.000266, l4: 0.000689, l5: 0.001951, l6: 0.003332

[epoch: 601/1000, batch:    80/ 1052, ite: 157820] train loss: 0.004183, tar: 0.000054 
l0: 0.000087, l1: 0.000086, l2: 0.000166, l3: 0.000335, l4: 0.000736, l5: 0.001140, l6: 0.002454

[epoch: 601/1000, batch:   160/ 1052, ite: 157840] train loss: 0.004061, tar: 0.000052 
l0: 0.000013, l1: 0.000011, l2: 0.000039, l3: 0.000135, l4: 0.000424, l5: 0.000891, l6: 0.001926

[epoch: 601/1000, batch:   240/ 1052, ite: 157860] train loss: 0.003926, tar: 0.000055 
l0: 0.000118, l1: 0.000123, l2: 0.000144, l3: 0.000202, l4: 0.000450, l5: 0.000880, l6: 0.001661

[epoch: 601/1000, batch:   320/ 1052, ite: 157880] train loss: 0.003903, tar: 0.000059 
l0: 0.000032, l1: 0.000032, l2: 0.000076, l3: 0.000207, l4: 0.000449, l5: 0.001026, l6: 0.001728

[epoch: 601/1000, batch:   400/ 1052, ite: 157900] train loss: 0.003891, tar: 0.000057 
l0: 0.000005, l1: 0.000006, l2: 0.000010, l3: 0.000077, l4: 0.000288, l5: 0.000710, l6: 0.001255

[epoch: 601/1000, batch:   480/ 1052, ite: 157920] train loss: 0.003973, tar: 0.000058 
l0: 0.000069, l1: 0.000069, l2: 0.000135, l3: 0.000254, l4: 0.000613, l5: 0.001147, l6: 0.001760

[epoch: 601/1000, batch:   560/ 1052, ite: 157940] train loss: 0.003982, tar: 0.000060 
l0: 0.000056, l1: 0.000053, l2: 0.000067, l3: 0.000140, l4: 0.000265, l5: 0.000688, l6: 0.001047

[epoch: 601/1000, batch:   640/ 1052, ite: 157960] train loss: 0.004002, tar: 0.000061 
l0: 0.000030, l1: 0.000033, l2: 0.000053, l3: 0.000101, l4: 0.000398, l5: 0.000887, l6: 0.001658

[epoch: 601/1000, batch:   720/ 1052, ite: 157980] train loss: 0.004023, tar: 0.000064 
l0: 0.000020, l1: 0.000020, l2: 0.000026, l3: 0.000049, l4: 0.000246, l5: 0.000817, l6: 0.001183

[epoch: 601/1000, batch:   800/ 1052, ite: 158000] train loss: 0.004076, tar: 0.000064 
l0: 0.000116, l1: 0.000118, l2: 0.000160, l3: 0.000264, l4: 0.000526, l5: 0.001067, l6: 0.001659

[epoch: 601/1000, batch:   880/ 1052, ite: 158020] train loss: 0.004083, tar: 0.000065 
l0: 0.000093, l1: 0.000095, l2: 0.000202, l3: 0.000518, l4: 0.001069, l5: 0.002054, l6: 0.002438

[epoch: 601/1000, batch:   960/ 1052, ite: 158040] train loss: 0.004105, tar: 0.000065 
l0: 0.000018, l1: 0.000019, l2: 0.000056, l3: 0.000147, l4: 0.000251, l5: 0.000886, l6: 0.001579

[epoch: 601/1000, batch:  1040/ 1052, ite: 158060] train loss: 0.004082, tar: 0.000064 
[Epoch 601/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000133, l1: 0.000137, l2: 0.000152, l3: 0.000225, l4: 0.000688, l5: 0.002448, l6: 0.004024

[epoch: 602/1000, batch:    68/ 1052, ite: 158080] train loss: 0.004070, tar: 0.000065 
l0: 0.000088, l1: 0.000091, l2: 0.000156, l3: 0.000193, l4: 0.000386, l5: 0.000892, l6: 0.001331

[epoch: 602/1000, batch:   148/ 1052, ite: 158100] train loss: 0.004083, tar: 0.000065 
l0: 0.000041, l1: 0.000043, l2: 0.000056, l3: 0.000116, l4: 0.000394, l5: 0.001040, l6: 0.001305

[epoch: 602/1000, batch:   228/ 1052, ite: 158120] train loss: 0.004089, tar: 0.000064 
l0: 0.000133, l1: 0.000133, l2: 0.000176, l3: 0.000246, l4: 0.000452, l5: 0.000802, l6: 0.002143

[epoch: 602/1000, batch:   308/ 1052, ite: 158140] train loss: 0.004069, tar: 0.000064 
l0: 0.000102, l1: 0.000100, l2: 0.000169, l3: 0.000376, l4: 0.000693, l5: 0.001185, l6: 0.002096

[epoch: 602/1000, batch:   388/ 1052, ite: 158160] train loss: 0.004081, tar: 0.000063 
l0: 0.000056, l1: 0.000054, l2: 0.000085, l3: 0.000183, l4: 0.000469, l5: 0.000945, l6: 0.002023

[epoch: 602/1000, batch:   468/ 1052, ite: 158180] train loss: 0.004092, tar: 0.000064 
l0: 0.000018, l1: 0.000019, l2: 0.000045, l3: 0.000102, l4: 0.000289, l5: 0.000861, l6: 0.000977

[epoch: 602/1000, batch:   548/ 1052, ite: 158200] train loss: 0.004057, tar: 0.000063 
l0: 0.000066, l1: 0.000065, l2: 0.000111, l3: 0.000234, l4: 0.000413, l5: 0.000912, l6: 0.002356

[epoch: 602/1000, batch:   628/ 1052, ite: 158220] train loss: 0.004031, tar: 0.000062 
l0: 0.000162, l1: 0.000153, l2: 0.000258, l3: 0.000595, l4: 0.001398, l5: 0.001897, l6: 0.002720

[epoch: 602/1000, batch:   708/ 1052, ite: 158240] train loss: 0.004032, tar: 0.000062 
l0: 0.000053, l1: 0.000054, l2: 0.000069, l3: 0.000144, l4: 0.000336, l5: 0.000880, l6: 0.001924

[epoch: 602/1000, batch:   788/ 1052, ite: 158260] train loss: 0.004041, tar: 0.000062 
l0: 0.000044, l1: 0.000043, l2: 0.000077, l3: 0.000201, l4: 0.000426, l5: 0.000750, l6: 0.002380

[epoch: 602/1000, batch:   868/ 1052, ite: 158280] train loss: 0.004052, tar: 0.000062 
l0: 0.000053, l1: 0.000057, l2: 0.000096, l3: 0.000194, l4: 0.000504, l5: 0.001118, l6: 0.002296

[epoch: 602/1000, batch:   948/ 1052, ite: 158300] train loss: 0.004045, tar: 0.000062 
l0: 0.000021, l1: 0.000023, l2: 0.000040, l3: 0.000044, l4: 0.000253, l5: 0.000702, l6: 0.000872

[epoch: 602/1000, batch:  1028/ 1052, ite: 158320] train loss: 0.004051, tar: 0.000062 
[Epoch 602/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000037, l1: 0.000038, l2: 0.000050, l3: 0.000109, l4: 0.000278, l5: 0.000335, l6: 0.001216

[epoch: 603/1000, batch:    56/ 1052, ite: 158340] train loss: 0.004049, tar: 0.000062 
l0: 0.000055, l1: 0.000055, l2: 0.000076, l3: 0.000068, l4: 0.000259, l5: 0.000577, l6: 0.001058

[epoch: 603/1000, batch:   136/ 1052, ite: 158360] train loss: 0.004048, tar: 0.000062 
l0: 0.000012, l1: 0.000012, l2: 0.000039, l3: 0.000115, l4: 0.000376, l5: 0.000811, l6: 0.001102

[epoch: 603/1000, batch:   216/ 1052, ite: 158380] train loss: 0.004043, tar: 0.000062 
l0: 0.000040, l1: 0.000039, l2: 0.000091, l3: 0.000185, l4: 0.000399, l5: 0.000966, l6: 0.001906

[epoch: 603/1000, batch:   296/ 1052, ite: 158400] train loss: 0.004030, tar: 0.000062 
l0: 0.000073, l1: 0.000072, l2: 0.000157, l3: 0.000235, l4: 0.000579, l5: 0.000831, l6: 0.002411

[epoch: 603/1000, batch:   376/ 1052, ite: 158420] train loss: 0.004025, tar: 0.000062 
l0: 0.000109, l1: 0.000112, l2: 0.000198, l3: 0.000291, l4: 0.000677, l5: 0.001371, l6: 0.002227

[epoch: 603/1000, batch:   456/ 1052, ite: 158440] train loss: 0.004026, tar: 0.000062 
l0: 0.000062, l1: 0.000064, l2: 0.000110, l3: 0.000400, l4: 0.001091, l5: 0.002148, l6: 0.003305

[epoch: 603/1000, batch:   536/ 1052, ite: 158460] train loss: 0.004041, tar: 0.000062 
l0: 0.000053, l1: 0.000054, l2: 0.000109, l3: 0.000187, l4: 0.000484, l5: 0.001183, l6: 0.001767

[epoch: 603/1000, batch:   616/ 1052, ite: 158480] train loss: 0.004046, tar: 0.000063 
l0: 0.000041, l1: 0.000042, l2: 0.000063, l3: 0.000098, l4: 0.000244, l5: 0.000594, l6: 0.001315

[epoch: 603/1000, batch:   696/ 1052, ite: 158500] train loss: 0.004056, tar: 0.000063 
l0: 0.000025, l1: 0.000026, l2: 0.000041, l3: 0.000166, l4: 0.000501, l5: 0.000904, l6: 0.001859

[epoch: 603/1000, batch:   776/ 1052, ite: 158520] train loss: 0.004045, tar: 0.000063 
l0: 0.000080, l1: 0.000081, l2: 0.000249, l3: 0.000467, l4: 0.000822, l5: 0.001172, l6: 0.004636

[epoch: 603/1000, batch:   856/ 1052, ite: 158540] train loss: 0.004049, tar: 0.000062 
l0: 0.000139, l1: 0.000139, l2: 0.000239, l3: 0.000450, l4: 0.000937, l5: 0.001870, l6: 0.003430

[epoch: 603/1000, batch:   936/ 1052, ite: 158560] train loss: 0.004056, tar: 0.000063 
l0: 0.000083, l1: 0.000085, l2: 0.000147, l3: 0.000269, l4: 0.000781, l5: 0.001832, l6: 0.002272

[epoch: 603/1000, batch:  1016/ 1052, ite: 158580] train loss: 0.004058, tar: 0.000063 
[Epoch 603/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000012, l1: 0.000013, l2: 0.000032, l3: 0.000061, l4: 0.000173, l5: 0.000548, l6: 0.000820

[epoch: 604/1000, batch:    44/ 1052, ite: 158600] train loss: 0.004057, tar: 0.000062 
l0: 0.000037, l1: 0.000038, l2: 0.000092, l3: 0.000232, l4: 0.000472, l5: 0.001134, l6: 0.002849

[epoch: 604/1000, batch:   124/ 1052, ite: 158620] train loss: 0.004056, tar: 0.000062 
l0: 0.000117, l1: 0.000116, l2: 0.000203, l3: 0.000407, l4: 0.001063, l5: 0.001111, l6: 0.002690

[epoch: 604/1000, batch:   204/ 1052, ite: 158640] train loss: 0.004065, tar: 0.000062 
l0: 0.000126, l1: 0.000124, l2: 0.000210, l3: 0.000292, l4: 0.000633, l5: 0.001916, l6: 0.003063

[epoch: 604/1000, batch:   284/ 1052, ite: 158660] train loss: 0.004070, tar: 0.000063 
l0: 0.000019, l1: 0.000019, l2: 0.000045, l3: 0.000119, l4: 0.000431, l5: 0.000713, l6: 0.001811

[epoch: 604/1000, batch:   364/ 1052, ite: 158680] train loss: 0.004065, tar: 0.000062 
l0: 0.000028, l1: 0.000030, l2: 0.000052, l3: 0.000122, l4: 0.000707, l5: 0.001155, l6: 0.002195

[epoch: 604/1000, batch:   444/ 1052, ite: 158700] train loss: 0.004062, tar: 0.000062 
l0: 0.000070, l1: 0.000072, l2: 0.000084, l3: 0.000226, l4: 0.000282, l5: 0.000607, l6: 0.001135

[epoch: 604/1000, batch:   524/ 1052, ite: 158720] train loss: 0.004057, tar: 0.000062 
l0: 0.000009, l1: 0.000009, l2: 0.000022, l3: 0.000105, l4: 0.000135, l5: 0.000619, l6: 0.001143

[epoch: 604/1000, batch:   604/ 1052, ite: 158740] train loss: 0.004054, tar: 0.000062 
l0: 0.000043, l1: 0.000047, l2: 0.000058, l3: 0.000129, l4: 0.000390, l5: 0.001016, l6: 0.001017

[epoch: 604/1000, batch:   684/ 1052, ite: 158760] train loss: 0.004053, tar: 0.000062 
l0: 0.000058, l1: 0.000058, l2: 0.000093, l3: 0.000153, l4: 0.000445, l5: 0.001105, l6: 0.001859

[epoch: 604/1000, batch:   764/ 1052, ite: 158780] train loss: 0.004057, tar: 0.000063 
l0: 0.000076, l1: 0.000077, l2: 0.000142, l3: 0.000313, l4: 0.000606, l5: 0.001165, l6: 0.002623

[epoch: 604/1000, batch:   844/ 1052, ite: 158800] train loss: 0.004049, tar: 0.000062 
l0: 0.000075, l1: 0.000073, l2: 0.000117, l3: 0.000225, l4: 0.000454, l5: 0.000964, l6: 0.001652

[epoch: 604/1000, batch:   924/ 1052, ite: 158820] train loss: 0.004045, tar: 0.000062 
l0: 0.000091, l1: 0.000093, l2: 0.000152, l3: 0.000358, l4: 0.000826, l5: 0.002360, l6: 0.002952

[epoch: 604/1000, batch:  1004/ 1052, ite: 158840] train loss: 0.004049, tar: 0.000062 
[Epoch 604/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000020, l1: 0.000021, l2: 0.000079, l3: 0.000167, l4: 0.000533, l5: 0.001156, l6: 0.001989

[epoch: 605/1000, batch:    32/ 1052, ite: 158860] train loss: 0.004049, tar: 0.000062 
l0: 0.000030, l1: 0.000032, l2: 0.000058, l3: 0.000113, l4: 0.000298, l5: 0.001134, l6: 0.001307

[epoch: 605/1000, batch:   112/ 1052, ite: 158880] train loss: 0.004054, tar: 0.000063 
l0: 0.000037, l1: 0.000035, l2: 0.000048, l3: 0.000142, l4: 0.000517, l5: 0.000473, l6: 0.001294

[epoch: 605/1000, batch:   192/ 1052, ite: 158900] train loss: 0.004047, tar: 0.000063 
l0: 0.000065, l1: 0.000070, l2: 0.000157, l3: 0.000257, l4: 0.000613, l5: 0.001502, l6: 0.003440

[epoch: 605/1000, batch:   272/ 1052, ite: 158920] train loss: 0.004053, tar: 0.000063 
l0: 0.000109, l1: 0.000114, l2: 0.000125, l3: 0.000215, l4: 0.000373, l5: 0.001876, l6: 0.001236

[epoch: 605/1000, batch:   352/ 1052, ite: 158940] train loss: 0.004061, tar: 0.000063 
l0: 0.000040, l1: 0.000040, l2: 0.000072, l3: 0.000145, l4: 0.000308, l5: 0.000462, l6: 0.001223

[epoch: 605/1000, batch:   432/ 1052, ite: 158960] train loss: 0.004056, tar: 0.000063 
l0: 0.000041, l1: 0.000039, l2: 0.000093, l3: 0.000233, l4: 0.000589, l5: 0.001091, l6: 0.002261

[epoch: 605/1000, batch:   512/ 1052, ite: 158980] train loss: 0.004057, tar: 0.000063 
l0: 0.000017, l1: 0.000018, l2: 0.000038, l3: 0.000111, l4: 0.000461, l5: 0.000859, l6: 0.001866

[epoch: 605/1000, batch:   592/ 1052, ite: 159000] train loss: 0.004055, tar: 0.000063 
l0: 0.000087, l1: 0.000087, l2: 0.000146, l3: 0.000203, l4: 0.000399, l5: 0.000788, l6: 0.001937

[epoch: 605/1000, batch:   672/ 1052, ite: 159020] train loss: 0.004049, tar: 0.000063 
l0: 0.000018, l1: 0.000018, l2: 0.000050, l3: 0.000161, l4: 0.000302, l5: 0.001021, l6: 0.001652

[epoch: 605/1000, batch:   752/ 1052, ite: 159040] train loss: 0.004045, tar: 0.000063 
l0: 0.000068, l1: 0.000070, l2: 0.000084, l3: 0.000201, l4: 0.000554, l5: 0.001017, l6: 0.001670

[epoch: 605/1000, batch:   832/ 1052, ite: 159060] train loss: 0.004040, tar: 0.000063 
l0: 0.000099, l1: 0.000099, l2: 0.000170, l3: 0.000347, l4: 0.000848, l5: 0.002004, l6: 0.002923

[epoch: 605/1000, batch:   912/ 1052, ite: 159080] train loss: 0.004047, tar: 0.000063 
l0: 0.000048, l1: 0.000047, l2: 0.000093, l3: 0.000211, l4: 0.000594, l5: 0.001413, l6: 0.002749

[epoch: 605/1000, batch:   992/ 1052, ite: 159100] train loss: 0.004058, tar: 0.000063 
[Epoch 605/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000038, l1: 0.000039, l2: 0.000107, l3: 0.000277, l4: 0.000614, l5: 0.001320, l6: 0.002344

[epoch: 606/1000, batch:    20/ 1052, ite: 159120] train loss: 0.004056, tar: 0.000063 
l0: 0.000042, l1: 0.000043, l2: 0.000104, l3: 0.000215, l4: 0.000444, l5: 0.001500, l6: 0.001721

[epoch: 606/1000, batch:   100/ 1052, ite: 159140] train loss: 0.004050, tar: 0.000063 
l0: 0.000027, l1: 0.000027, l2: 0.000048, l3: 0.000090, l4: 0.000341, l5: 0.000935, l6: 0.001374

[epoch: 606/1000, batch:   180/ 1052, ite: 159160] train loss: 0.004045, tar: 0.000063 
l0: 0.000035, l1: 0.000034, l2: 0.000052, l3: 0.000146, l4: 0.000427, l5: 0.001487, l6: 0.002714

[epoch: 606/1000, batch:   260/ 1052, ite: 159180] train loss: 0.004047, tar: 0.000063 
l0: 0.000092, l1: 0.000088, l2: 0.000183, l3: 0.000392, l4: 0.000925, l5: 0.001872, l6: 0.003526

[epoch: 606/1000, batch:   340/ 1052, ite: 159200] train loss: 0.004055, tar: 0.000063 
l0: 0.000074, l1: 0.000076, l2: 0.000105, l3: 0.000110, l4: 0.000252, l5: 0.000811, l6: 0.001367

[epoch: 606/1000, batch:   420/ 1052, ite: 159220] train loss: 0.004054, tar: 0.000063 
l0: 0.000028, l1: 0.000028, l2: 0.000090, l3: 0.000360, l4: 0.000956, l5: 0.001769, l6: 0.002677

[epoch: 606/1000, batch:   500/ 1052, ite: 159240] train loss: 0.004053, tar: 0.000063 
l0: 0.000044, l1: 0.000042, l2: 0.000060, l3: 0.000151, l4: 0.000325, l5: 0.000886, l6: 0.000831

[epoch: 606/1000, batch:   580/ 1052, ite: 159260] train loss: 0.004047, tar: 0.000063 
l0: 0.000026, l1: 0.000028, l2: 0.000073, l3: 0.000212, l4: 0.000527, l5: 0.001572, l6: 0.001905

[epoch: 606/1000, batch:   660/ 1052, ite: 159280] train loss: 0.004047, tar: 0.000062 
l0: 0.000033, l1: 0.000033, l2: 0.000117, l3: 0.000261, l4: 0.000544, l5: 0.000890, l6: 0.001680

[epoch: 606/1000, batch:   740/ 1052, ite: 159300] train loss: 0.004040, tar: 0.000062 
l0: 0.000236, l1: 0.000238, l2: 0.000231, l3: 0.000277, l4: 0.000548, l5: 0.001124, l6: 0.002765

[epoch: 606/1000, batch:   820/ 1052, ite: 159320] train loss: 0.004039, tar: 0.000062 
l0: 0.000064, l1: 0.000065, l2: 0.000111, l3: 0.000224, l4: 0.000384, l5: 0.000647, l6: 0.002231

[epoch: 606/1000, batch:   900/ 1052, ite: 159340] train loss: 0.004043, tar: 0.000062 
l0: 0.000042, l1: 0.000042, l2: 0.000074, l3: 0.000174, l4: 0.000526, l5: 0.000699, l6: 0.002564

[epoch: 606/1000, batch:   980/ 1052, ite: 159360] train loss: 0.004041, tar: 0.000062 
[Epoch 606/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000040, l1: 0.000041, l2: 0.000090, l3: 0.000181, l4: 0.000450, l5: 0.000612, l6: 0.001359

[epoch: 607/1000, batch:     8/ 1052, ite: 159380] train loss: 0.004043, tar: 0.000062 
l0: 0.000078, l1: 0.000078, l2: 0.000133, l3: 0.000245, l4: 0.000604, l5: 0.000937, l6: 0.001869

[epoch: 607/1000, batch:    88/ 1052, ite: 159400] train loss: 0.004047, tar: 0.000062 
l0: 0.000043, l1: 0.000044, l2: 0.000090, l3: 0.000218, l4: 0.000609, l5: 0.001144, l6: 0.001830

[epoch: 607/1000, batch:   168/ 1052, ite: 159420] train loss: 0.004049, tar: 0.000062 
l0: 0.000065, l1: 0.000067, l2: 0.000142, l3: 0.000264, l4: 0.000520, l5: 0.001462, l6: 0.001703

[epoch: 607/1000, batch:   248/ 1052, ite: 159440] train loss: 0.004054, tar: 0.000062 
l0: 0.000055, l1: 0.000054, l2: 0.000060, l3: 0.000129, l4: 0.000266, l5: 0.000960, l6: 0.000997

[epoch: 607/1000, batch:   328/ 1052, ite: 159460] train loss: 0.004053, tar: 0.000062 
l0: 0.000134, l1: 0.000138, l2: 0.000192, l3: 0.000406, l4: 0.000714, l5: 0.001333, l6: 0.003249

[epoch: 607/1000, batch:   408/ 1052, ite: 159480] train loss: 0.004055, tar: 0.000062 
l0: 0.000041, l1: 0.000043, l2: 0.000063, l3: 0.000148, l4: 0.000626, l5: 0.000932, l6: 0.002374

[epoch: 607/1000, batch:   488/ 1052, ite: 159500] train loss: 0.004054, tar: 0.000062 
l0: 0.000014, l1: 0.000015, l2: 0.000031, l3: 0.000109, l4: 0.000306, l5: 0.000773, l6: 0.001049

[epoch: 607/1000, batch:   568/ 1052, ite: 159520] train loss: 0.004047, tar: 0.000062 
l0: 0.000039, l1: 0.000042, l2: 0.000060, l3: 0.000135, l4: 0.000315, l5: 0.000575, l6: 0.000797

[epoch: 607/1000, batch:   648/ 1052, ite: 159540] train loss: 0.004052, tar: 0.000062 
l0: 0.000035, l1: 0.000034, l2: 0.000084, l3: 0.000195, l4: 0.000768, l5: 0.001205, l6: 0.001638

[epoch: 607/1000, batch:   728/ 1052, ite: 159560] train loss: 0.004047, tar: 0.000062 
l0: 0.000085, l1: 0.000086, l2: 0.000113, l3: 0.000210, l4: 0.000314, l5: 0.000993, l6: 0.001444

[epoch: 607/1000, batch:   808/ 1052, ite: 159580] train loss: 0.004048, tar: 0.000062 
l0: 0.000053, l1: 0.000054, l2: 0.000086, l3: 0.000150, l4: 0.000330, l5: 0.000669, l6: 0.001788

[epoch: 607/1000, batch:   888/ 1052, ite: 159600] train loss: 0.004045, tar: 0.000062 
l0: 0.000060, l1: 0.000065, l2: 0.000108, l3: 0.000266, l4: 0.000542, l5: 0.001462, l6: 0.002987

[epoch: 607/1000, batch:   968/ 1052, ite: 159620] train loss: 0.004040, tar: 0.000062 
l0: 0.000175, l1: 0.000177, l2: 0.000227, l3: 0.000420, l4: 0.000775, l5: 0.001555, l6: 0.004855

[epoch: 607/1000, batch:  1048/ 1052, ite: 159640] train loss: 0.004046, tar: 0.000062 
[Epoch 607/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000051, l1: 0.000050, l2: 0.000115, l3: 0.000240, l4: 0.000538, l5: 0.001043, l6: 0.002255

[epoch: 608/1000, batch:    76/ 1052, ite: 159660] train loss: 0.004052, tar: 0.000062 
l0: 0.000201, l1: 0.000201, l2: 0.000225, l3: 0.000499, l4: 0.001322, l5: 0.003298, l6: 0.005321

[epoch: 608/1000, batch:   156/ 1052, ite: 159680] train loss: 0.004052, tar: 0.000062 
l0: 0.000017, l1: 0.000019, l2: 0.000035, l3: 0.000098, l4: 0.000238, l5: 0.000951, l6: 0.001407

[epoch: 608/1000, batch:   236/ 1052, ite: 159700] train loss: 0.004053, tar: 0.000062 
l0: 0.000066, l1: 0.000065, l2: 0.000106, l3: 0.000217, l4: 0.000705, l5: 0.001414, l6: 0.001324

[epoch: 608/1000, batch:   316/ 1052, ite: 159720] train loss: 0.004050, tar: 0.000062 
l0: 0.000013, l1: 0.000014, l2: 0.000019, l3: 0.000076, l4: 0.000334, l5: 0.000890, l6: 0.001287

[epoch: 608/1000, batch:   396/ 1052, ite: 159740] train loss: 0.004045, tar: 0.000062 
l0: 0.000077, l1: 0.000077, l2: 0.000175, l3: 0.000308, l4: 0.000533, l5: 0.001254, l6: 0.002346

[epoch: 608/1000, batch:   476/ 1052, ite: 159760] train loss: 0.004044, tar: 0.000062 
l0: 0.000099, l1: 0.000098, l2: 0.000139, l3: 0.000259, l4: 0.000680, l5: 0.001293, l6: 0.002368

[epoch: 608/1000, batch:   556/ 1052, ite: 159780] train loss: 0.004047, tar: 0.000062 
l0: 0.000032, l1: 0.000033, l2: 0.000045, l3: 0.000095, l4: 0.000295, l5: 0.000510, l6: 0.001398

[epoch: 608/1000, batch:   636/ 1052, ite: 159800] train loss: 0.004043, tar: 0.000062 
l0: 0.000367, l1: 0.000349, l2: 0.000361, l3: 0.000427, l4: 0.000598, l5: 0.000862, l6: 0.001291

[epoch: 608/1000, batch:   716/ 1052, ite: 159820] train loss: 0.004038, tar: 0.000062 
l0: 0.000082, l1: 0.000081, l2: 0.000143, l3: 0.000262, l4: 0.000637, l5: 0.001637, l6: 0.002603

[epoch: 608/1000, batch:   796/ 1052, ite: 159840] train loss: 0.004038, tar: 0.000062 
l0: 0.000089, l1: 0.000087, l2: 0.000210, l3: 0.000433, l4: 0.000719, l5: 0.001482, l6: 0.002786

[epoch: 608/1000, batch:   876/ 1052, ite: 159860] train loss: 0.004043, tar: 0.000062 
l0: 0.000044, l1: 0.000047, l2: 0.000089, l3: 0.000184, l4: 0.000367, l5: 0.000846, l6: 0.001907

[epoch: 608/1000, batch:   956/ 1052, ite: 159880] train loss: 0.004043, tar: 0.000062 
l0: 0.000026, l1: 0.000026, l2: 0.000081, l3: 0.000182, l4: 0.000638, l5: 0.001518, l6: 0.003298

[epoch: 608/1000, batch:  1036/ 1052, ite: 159900] train loss: 0.004043, tar: 0.000062 
[Epoch 608/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000040, l1: 0.000041, l2: 0.000087, l3: 0.000159, l4: 0.000342, l5: 0.001189, l6: 0.002096

[epoch: 609/1000, batch:    64/ 1052, ite: 159920] train loss: 0.004038, tar: 0.000061 
l0: 0.000091, l1: 0.000092, l2: 0.000174, l3: 0.000335, l4: 0.000709, l5: 0.002100, l6: 0.003343

[epoch: 609/1000, batch:   144/ 1052, ite: 159940] train loss: 0.004032, tar: 0.000061 
l0: 0.000013, l1: 0.000013, l2: 0.000031, l3: 0.000081, l4: 0.000349, l5: 0.000723, l6: 0.001157

[epoch: 609/1000, batch:   224/ 1052, ite: 159960] train loss: 0.004027, tar: 0.000061 
l0: 0.000050, l1: 0.000055, l2: 0.000119, l3: 0.000254, l4: 0.000776, l5: 0.001258, l6: 0.002645

[epoch: 609/1000, batch:   304/ 1052, ite: 159980] train loss: 0.004027, tar: 0.000061 
l0: 0.000039, l1: 0.000036, l2: 0.000104, l3: 0.000256, l4: 0.000635, l5: 0.001266, l6: 0.002085

[epoch: 609/1000, batch:   384/ 1052, ite: 160000] train loss: 0.004026, tar: 0.000061 
l0: 0.000073, l1: 0.000072, l2: 0.000091, l3: 0.000199, l4: 0.000342, l5: 0.000796, l6: 0.002366

[epoch: 609/1000, batch:   464/ 1052, ite: 160020] train loss: 0.004030, tar: 0.000061 
l0: 0.000061, l1: 0.000059, l2: 0.000134, l3: 0.000289, l4: 0.000785, l5: 0.001531, l6: 0.003438

[epoch: 609/1000, batch:   544/ 1052, ite: 160040] train loss: 0.004034, tar: 0.000061 
l0: 0.000145, l1: 0.000148, l2: 0.000204, l3: 0.000264, l4: 0.000559, l5: 0.001240, l6: 0.002628

[epoch: 609/1000, batch:   624/ 1052, ite: 160060] train loss: 0.004033, tar: 0.000061 
l0: 0.000109, l1: 0.000108, l2: 0.000110, l3: 0.000263, l4: 0.000718, l5: 0.001713, l6: 0.002213

[epoch: 609/1000, batch:   704/ 1052, ite: 160080] train loss: 0.004035, tar: 0.000061 
l0: 0.000025, l1: 0.000020, l2: 0.000053, l3: 0.000139, l4: 0.000209, l5: 0.000676, l6: 0.001128

[epoch: 609/1000, batch:   784/ 1052, ite: 160100] train loss: 0.004032, tar: 0.000061 
l0: 0.000045, l1: 0.000042, l2: 0.000090, l3: 0.000170, l4: 0.000400, l5: 0.001037, l6: 0.002474

[epoch: 609/1000, batch:   864/ 1052, ite: 160120] train loss: 0.004033, tar: 0.000061 
l0: 0.000043, l1: 0.000043, l2: 0.000148, l3: 0.000305, l4: 0.000601, l5: 0.001070, l6: 0.002374

[epoch: 609/1000, batch:   944/ 1052, ite: 160140] train loss: 0.004034, tar: 0.000061 
l0: 0.000038, l1: 0.000038, l2: 0.000093, l3: 0.000164, l4: 0.000430, l5: 0.001012, l6: 0.001449

[epoch: 609/1000, batch:  1024/ 1052, ite: 160160] train loss: 0.004033, tar: 0.000061 
[Epoch 609/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000055, l1: 0.000055, l2: 0.000101, l3: 0.000272, l4: 0.000638, l5: 0.001377, l6: 0.002101

[epoch: 610/1000, batch:    52/ 1052, ite: 160180] train loss: 0.004030, tar: 0.000061 
l0: 0.000051, l1: 0.000049, l2: 0.000138, l3: 0.000263, l4: 0.000772, l5: 0.001885, l6: 0.002321

[epoch: 610/1000, batch:   132/ 1052, ite: 160200] train loss: 0.004032, tar: 0.000061 
l0: 0.000022, l1: 0.000024, l2: 0.000055, l3: 0.000130, l4: 0.000282, l5: 0.000793, l6: 0.001921

[epoch: 610/1000, batch:   212/ 1052, ite: 160220] train loss: 0.004034, tar: 0.000061 
l0: 0.000014, l1: 0.000013, l2: 0.000046, l3: 0.000151, l4: 0.000616, l5: 0.000978, l6: 0.001641

[epoch: 610/1000, batch:   292/ 1052, ite: 160240] train loss: 0.004036, tar: 0.000061 
l0: 0.000006, l1: 0.000007, l2: 0.000046, l3: 0.000329, l4: 0.000544, l5: 0.001088, l6: 0.001999

[epoch: 610/1000, batch:   372/ 1052, ite: 160260] train loss: 0.004033, tar: 0.000060 
l0: 0.000081, l1: 0.000078, l2: 0.000143, l3: 0.000197, l4: 0.000405, l5: 0.001056, l6: 0.001713

[epoch: 610/1000, batch:   452/ 1052, ite: 160280] train loss: 0.004031, tar: 0.000060 
l0: 0.000021, l1: 0.000022, l2: 0.000058, l3: 0.000138, l4: 0.000458, l5: 0.000792, l6: 0.001564

[epoch: 610/1000, batch:   532/ 1052, ite: 160300] train loss: 0.004030, tar: 0.000060 
l0: 0.000072, l1: 0.000077, l2: 0.000127, l3: 0.000208, l4: 0.000477, l5: 0.000962, l6: 0.002584

[epoch: 610/1000, batch:   612/ 1052, ite: 160320] train loss: 0.004027, tar: 0.000060 
l0: 0.000067, l1: 0.000073, l2: 0.000156, l3: 0.000232, l4: 0.000546, l5: 0.001051, l6: 0.001548

[epoch: 610/1000, batch:   692/ 1052, ite: 160340] train loss: 0.004024, tar: 0.000060 
l0: 0.000065, l1: 0.000069, l2: 0.000081, l3: 0.000149, l4: 0.000326, l5: 0.000934, l6: 0.002064

[epoch: 610/1000, batch:   772/ 1052, ite: 160360] train loss: 0.004022, tar: 0.000060 
l0: 0.000091, l1: 0.000096, l2: 0.000119, l3: 0.000170, l4: 0.000409, l5: 0.001065, l6: 0.002334

[epoch: 610/1000, batch:   852/ 1052, ite: 160380] train loss: 0.004024, tar: 0.000060 
l0: 0.000090, l1: 0.000093, l2: 0.000160, l3: 0.000283, l4: 0.000588, l5: 0.001245, l6: 0.002589

[epoch: 610/1000, batch:   932/ 1052, ite: 160400] train loss: 0.004027, tar: 0.000060 
l0: 0.000038, l1: 0.000040, l2: 0.000109, l3: 0.000301, l4: 0.000615, l5: 0.000964, l6: 0.002013

[epoch: 610/1000, batch:  1012/ 1052, ite: 160420] train loss: 0.004028, tar: 0.000060 
[Epoch 610/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000079, l1: 0.000081, l2: 0.000107, l3: 0.000340, l4: 0.001138, l5: 0.001253, l6: 0.003279

[epoch: 611/1000, batch:    40/ 1052, ite: 160440] train loss: 0.004031, tar: 0.000061 
l0: 0.000071, l1: 0.000070, l2: 0.000165, l3: 0.000366, l4: 0.000789, l5: 0.001406, l6: 0.002117

[epoch: 611/1000, batch:   120/ 1052, ite: 160460] train loss: 0.004029, tar: 0.000060 
l0: 0.000050, l1: 0.000048, l2: 0.000092, l3: 0.000238, l4: 0.000474, l5: 0.000653, l6: 0.001388

[epoch: 611/1000, batch:   200/ 1052, ite: 160480] train loss: 0.004028, tar: 0.000060 
l0: 0.000034, l1: 0.000035, l2: 0.000047, l3: 0.000177, l4: 0.000642, l5: 0.001712, l6: 0.001687

[epoch: 611/1000, batch:   280/ 1052, ite: 160500] train loss: 0.004026, tar: 0.000060 
l0: 0.000010, l1: 0.000010, l2: 0.000032, l3: 0.000088, l4: 0.000276, l5: 0.000574, l6: 0.001516

[epoch: 611/1000, batch:   360/ 1052, ite: 160520] train loss: 0.004026, tar: 0.000060 
l0: 0.000076, l1: 0.000079, l2: 0.000127, l3: 0.000281, l4: 0.000533, l5: 0.001015, l6: 0.001607

[epoch: 611/1000, batch:   440/ 1052, ite: 160540] train loss: 0.004028, tar: 0.000060 
l0: 0.000049, l1: 0.000048, l2: 0.000146, l3: 0.000274, l4: 0.000619, l5: 0.001082, l6: 0.002248

[epoch: 611/1000, batch:   520/ 1052, ite: 160560] train loss: 0.004026, tar: 0.000060 
l0: 0.000058, l1: 0.000058, l2: 0.000149, l3: 0.000279, l4: 0.000836, l5: 0.001894, l6: 0.002450

[epoch: 611/1000, batch:   600/ 1052, ite: 160580] train loss: 0.004028, tar: 0.000060 
l0: 0.000057, l1: 0.000056, l2: 0.000111, l3: 0.000206, l4: 0.000353, l5: 0.001130, l6: 0.001578

[epoch: 611/1000, batch:   680/ 1052, ite: 160600] train loss: 0.004031, tar: 0.000060 
l0: 0.000165, l1: 0.000168, l2: 0.000209, l3: 0.000329, l4: 0.000782, l5: 0.001471, l6: 0.003167

[epoch: 611/1000, batch:   760/ 1052, ite: 160620] train loss: 0.004033, tar: 0.000061 
l0: 0.000026, l1: 0.000026, l2: 0.000047, l3: 0.000095, l4: 0.000169, l5: 0.000558, l6: 0.001277

[epoch: 611/1000, batch:   840/ 1052, ite: 160640] train loss: 0.004034, tar: 0.000061 
l0: 0.000030, l1: 0.000032, l2: 0.000043, l3: 0.000124, l4: 0.000460, l5: 0.000945, l6: 0.001390

[epoch: 611/1000, batch:   920/ 1052, ite: 160660] train loss: 0.004038, tar: 0.000061 
l0: 0.000048, l1: 0.000046, l2: 0.000069, l3: 0.000182, l4: 0.000281, l5: 0.000390, l6: 0.000846

[epoch: 611/1000, batch:  1000/ 1052, ite: 160680] train loss: 0.004037, tar: 0.000061 
[Epoch 611/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000084, l1: 0.000088, l2: 0.000144, l3: 0.000265, l4: 0.000552, l5: 0.001226, l6: 0.001072

[epoch: 612/1000, batch:    28/ 1052, ite: 160700] train loss: 0.004033, tar: 0.000061 
l0: 0.000130, l1: 0.000131, l2: 0.000179, l3: 0.000283, l4: 0.000803, l5: 0.001393, l6: 0.002962

[epoch: 612/1000, batch:   108/ 1052, ite: 160720] train loss: 0.004031, tar: 0.000061 
l0: 0.000096, l1: 0.000098, l2: 0.000091, l3: 0.000127, l4: 0.000322, l5: 0.000835, l6: 0.002521

[epoch: 612/1000, batch:   188/ 1052, ite: 160740] train loss: 0.004033, tar: 0.000061 
l0: 0.000042, l1: 0.000041, l2: 0.000154, l3: 0.000248, l4: 0.000664, l5: 0.001260, l6: 0.001932

[epoch: 612/1000, batch:   268/ 1052, ite: 160760] train loss: 0.004035, tar: 0.000061 
l0: 0.000071, l1: 0.000075, l2: 0.000089, l3: 0.000153, l4: 0.000366, l5: 0.001391, l6: 0.001276

[epoch: 612/1000, batch:   348/ 1052, ite: 160780] train loss: 0.004035, tar: 0.000061 
l0: 0.000010, l1: 0.000011, l2: 0.000022, l3: 0.000076, l4: 0.000248, l5: 0.000362, l6: 0.000908

[epoch: 612/1000, batch:   428/ 1052, ite: 160800] train loss: 0.004032, tar: 0.000061 
l0: 0.000040, l1: 0.000039, l2: 0.000086, l3: 0.000190, l4: 0.000600, l5: 0.001265, l6: 0.002402

[epoch: 612/1000, batch:   508/ 1052, ite: 160820] train loss: 0.004031, tar: 0.000061 
l0: 0.000045, l1: 0.000044, l2: 0.000081, l3: 0.000182, l4: 0.000465, l5: 0.001251, l6: 0.001635

[epoch: 612/1000, batch:   588/ 1052, ite: 160840] train loss: 0.004030, tar: 0.000061 
l0: 0.000022, l1: 0.000022, l2: 0.000059, l3: 0.000179, l4: 0.000463, l5: 0.000916, l6: 0.001759

[epoch: 612/1000, batch:   668/ 1052, ite: 160860] train loss: 0.004028, tar: 0.000060 
l0: 0.000185, l1: 0.000193, l2: 0.000231, l3: 0.000596, l4: 0.001349, l5: 0.002219, l6: 0.004231

[epoch: 612/1000, batch:   748/ 1052, ite: 160880] train loss: 0.004031, tar: 0.000060 
l0: 0.000007, l1: 0.000006, l2: 0.000020, l3: 0.000107, l4: 0.000235, l5: 0.000773, l6: 0.001081

[epoch: 612/1000, batch:   828/ 1052, ite: 160900] train loss: 0.004029, tar: 0.000060 
l0: 0.000018, l1: 0.000017, l2: 0.000048, l3: 0.000083, l4: 0.000207, l5: 0.000446, l6: 0.000576

[epoch: 612/1000, batch:   908/ 1052, ite: 160920] train loss: 0.004029, tar: 0.000061 
l0: 0.000098, l1: 0.000102, l2: 0.000160, l3: 0.000231, l4: 0.000388, l5: 0.000920, l6: 0.003082

[epoch: 612/1000, batch:   988/ 1052, ite: 160940] train loss: 0.004032, tar: 0.000061 
[Epoch 612/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000012, l1: 0.000013, l2: 0.000024, l3: 0.000053, l4: 0.000187, l5: 0.000526, l6: 0.000848

[epoch: 613/1000, batch:    16/ 1052, ite: 160960] train loss: 0.004033, tar: 0.000061 
l0: 0.000046, l1: 0.000045, l2: 0.000081, l3: 0.000132, l4: 0.000368, l5: 0.000975, l6: 0.001397

[epoch: 613/1000, batch:    96/ 1052, ite: 160980] train loss: 0.004032, tar: 0.000061 
l0: 0.000057, l1: 0.000056, l2: 0.000103, l3: 0.000195, l4: 0.000387, l5: 0.000816, l6: 0.001261

[epoch: 613/1000, batch:   176/ 1052, ite: 161000] train loss: 0.004039, tar: 0.000062 
l0: 0.000207, l1: 0.000222, l2: 0.000253, l3: 0.000325, l4: 0.000517, l5: 0.001109, l6: 0.001664

[epoch: 613/1000, batch:   256/ 1052, ite: 161020] train loss: 0.004048, tar: 0.000064 
l0: 0.000111, l1: 0.000112, l2: 0.000143, l3: 0.000283, l4: 0.000454, l5: 0.000973, l6: 0.002477

[epoch: 613/1000, batch:   336/ 1052, ite: 161040] train loss: 0.004053, tar: 0.000065 
l0: 0.000081, l1: 0.000079, l2: 0.000099, l3: 0.000206, l4: 0.000452, l5: 0.001061, l6: 0.002832

[epoch: 613/1000, batch:   416/ 1052, ite: 161060] train loss: 0.004057, tar: 0.000066 
l0: 0.000127, l1: 0.000133, l2: 0.000163, l3: 0.000269, l4: 0.000505, l5: 0.001244, l6: 0.001747

[epoch: 613/1000, batch:   496/ 1052, ite: 161080] train loss: 0.004062, tar: 0.000066 
l0: 0.000098, l1: 0.000094, l2: 0.000136, l3: 0.000249, l4: 0.000528, l5: 0.000702, l6: 0.002204

[epoch: 613/1000, batch:   576/ 1052, ite: 161100] train loss: 0.004065, tar: 0.000067 
l0: 0.000290, l1: 0.000438, l2: 0.000503, l3: 0.000453, l4: 0.000962, l5: 0.001429, l6: 0.002179

[epoch: 613/1000, batch:   656/ 1052, ite: 161120] train loss: 0.004065, tar: 0.000067 
l0: 0.000080, l1: 0.000088, l2: 0.000108, l3: 0.000131, l4: 0.000343, l5: 0.000691, l6: 0.001777

[epoch: 613/1000, batch:   736/ 1052, ite: 161140] train loss: 0.004067, tar: 0.000068 
l0: 0.000127, l1: 0.000128, l2: 0.000159, l3: 0.000242, l4: 0.000399, l5: 0.000917, l6: 0.002149

[epoch: 613/1000, batch:   816/ 1052, ite: 161160] train loss: 0.004068, tar: 0.000068 
l0: 0.000071, l1: 0.000060, l2: 0.000082, l3: 0.000155, l4: 0.000474, l5: 0.000707, l6: 0.001041

[epoch: 613/1000, batch:   896/ 1052, ite: 161180] train loss: 0.004075, tar: 0.000069 
l0: 0.000155, l1: 0.000181, l2: 0.000190, l3: 0.000278, l4: 0.000515, l5: 0.000965, l6: 0.001776

[epoch: 613/1000, batch:   976/ 1052, ite: 161200] train loss: 0.004077, tar: 0.000070 
[Epoch 613/1000] Test loss: 0.014, Test target loss: 0.002
l0: 0.000228, l1: 0.000239, l2: 0.000270, l3: 0.000361, l4: 0.001027, l5: 0.002263, l6: 0.003735

[epoch: 614/1000, batch:     4/ 1052, ite: 161220] train loss: 0.004079, tar: 0.000070 
l0: 0.000112, l1: 0.000104, l2: 0.000152, l3: 0.000268, l4: 0.000432, l5: 0.001075, l6: 0.002568

[epoch: 614/1000, batch:    84/ 1052, ite: 161240] train loss: 0.004081, tar: 0.000071 
l0: 0.000086, l1: 0.000091, l2: 0.000134, l3: 0.000199, l4: 0.000436, l5: 0.001756, l6: 0.002662

[epoch: 614/1000, batch:   164/ 1052, ite: 161260] train loss: 0.004082, tar: 0.000071 
l0: 0.000095, l1: 0.000089, l2: 0.000141, l3: 0.000227, l4: 0.000568, l5: 0.000893, l6: 0.002631

[epoch: 614/1000, batch:   244/ 1052, ite: 161280] train loss: 0.004082, tar: 0.000071 
l0: 0.000115, l1: 0.000115, l2: 0.000145, l3: 0.000184, l4: 0.000618, l5: 0.001192, l6: 0.001300

[epoch: 614/1000, batch:   324/ 1052, ite: 161300] train loss: 0.004083, tar: 0.000071 
l0: 0.000071, l1: 0.000070, l2: 0.000181, l3: 0.000284, l4: 0.000423, l5: 0.001135, l6: 0.001536

[epoch: 614/1000, batch:   404/ 1052, ite: 161320] train loss: 0.004084, tar: 0.000071 
l0: 0.000071, l1: 0.000078, l2: 0.000119, l3: 0.000201, l4: 0.000526, l5: 0.001124, l6: 0.001720

[epoch: 614/1000, batch:   484/ 1052, ite: 161340] train loss: 0.004083, tar: 0.000071 
l0: 0.000108, l1: 0.000111, l2: 0.000135, l3: 0.000194, l4: 0.000466, l5: 0.001033, l6: 0.001527

[epoch: 614/1000, batch:   564/ 1052, ite: 161360] train loss: 0.004087, tar: 0.000071 
l0: 0.000079, l1: 0.000113, l2: 0.000119, l3: 0.000176, l4: 0.000409, l5: 0.000961, l6: 0.001275

[epoch: 614/1000, batch:   644/ 1052, ite: 161380] train loss: 0.004086, tar: 0.000072 
l0: 0.000112, l1: 0.000111, l2: 0.000175, l3: 0.000281, l4: 0.000508, l5: 0.001414, l6: 0.002684

[epoch: 614/1000, batch:   724/ 1052, ite: 161400] train loss: 0.004089, tar: 0.000072 
l0: 0.000318, l1: 0.000361, l2: 0.000410, l3: 0.000575, l4: 0.001084, l5: 0.001562, l6: 0.002769

[epoch: 614/1000, batch:   804/ 1052, ite: 161420] train loss: 0.004089, tar: 0.000072 
l0: 0.000034, l1: 0.000032, l2: 0.000071, l3: 0.000155, l4: 0.000346, l5: 0.000515, l6: 0.000728

[epoch: 614/1000, batch:   884/ 1052, ite: 161440] train loss: 0.004092, tar: 0.000072 
l0: 0.000086, l1: 0.000077, l2: 0.000190, l3: 0.000501, l4: 0.000691, l5: 0.001398, l6: 0.002264

[epoch: 614/1000, batch:   964/ 1052, ite: 161460] train loss: 0.004091, tar: 0.000072 
l0: 0.000059, l1: 0.000054, l2: 0.000103, l3: 0.000216, l4: 0.000516, l5: 0.000912, l6: 0.001521

[epoch: 614/1000, batch:  1044/ 1052, ite: 161480] train loss: 0.004090, tar: 0.000072 
[Epoch 614/1000] Test loss: 0.016, Test target loss: 0.002
l0: 0.000044, l1: 0.000047, l2: 0.000054, l3: 0.000088, l4: 0.000306, l5: 0.000584, l6: 0.001013

[epoch: 615/1000, batch:    72/ 1052, ite: 161500] train loss: 0.004091, tar: 0.000072 
l0: 0.000097, l1: 0.000096, l2: 0.000170, l3: 0.000248, l4: 0.000507, l5: 0.001305, l6: 0.002197

[epoch: 615/1000, batch:   152/ 1052, ite: 161520] train loss: 0.004091, tar: 0.000072 
l0: 0.000124, l1: 0.000125, l2: 0.000143, l3: 0.000287, l4: 0.000952, l5: 0.001668, l6: 0.002597

[epoch: 615/1000, batch:   232/ 1052, ite: 161540] train loss: 0.004095, tar: 0.000072 
l0: 0.000039, l1: 0.000044, l2: 0.000077, l3: 0.000121, l4: 0.000381, l5: 0.001087, l6: 0.000859

[epoch: 615/1000, batch:   312/ 1052, ite: 161560] train loss: 0.004096, tar: 0.000072 
l0: 0.000072, l1: 0.000064, l2: 0.000142, l3: 0.000277, l4: 0.000481, l5: 0.001247, l6: 0.001502

[epoch: 615/1000, batch:   392/ 1052, ite: 161580] train loss: 0.004097, tar: 0.000073 
l0: 0.000053, l1: 0.000053, l2: 0.000061, l3: 0.000160, l4: 0.000454, l5: 0.000812, l6: 0.002150

[epoch: 615/1000, batch:   472/ 1052, ite: 161600] train loss: 0.004095, tar: 0.000072 
l0: 0.000038, l1: 0.000036, l2: 0.000098, l3: 0.000177, l4: 0.000522, l5: 0.001467, l6: 0.002753

[epoch: 615/1000, batch:   552/ 1052, ite: 161620] train loss: 0.004094, tar: 0.000072 
l0: 0.000040, l1: 0.000038, l2: 0.000071, l3: 0.000251, l4: 0.000743, l5: 0.000978, l6: 0.001335

[epoch: 615/1000, batch:   632/ 1052, ite: 161640] train loss: 0.004092, tar: 0.000072 
l0: 0.000138, l1: 0.000151, l2: 0.000187, l3: 0.000313, l4: 0.000517, l5: 0.001268, l6: 0.002798

[epoch: 615/1000, batch:   712/ 1052, ite: 161660] train loss: 0.004094, tar: 0.000072 
l0: 0.000123, l1: 0.000118, l2: 0.000254, l3: 0.000417, l4: 0.000984, l5: 0.001902, l6: 0.003061

[epoch: 615/1000, batch:   792/ 1052, ite: 161680] train loss: 0.004091, tar: 0.000072 
l0: 0.000061, l1: 0.000064, l2: 0.000077, l3: 0.000197, l4: 0.000520, l5: 0.001022, l6: 0.002096

[epoch: 615/1000, batch:   872/ 1052, ite: 161700] train loss: 0.004090, tar: 0.000072 
l0: 0.000054, l1: 0.000057, l2: 0.000077, l3: 0.000237, l4: 0.000515, l5: 0.001153, l6: 0.001969

[epoch: 615/1000, batch:   952/ 1052, ite: 161720] train loss: 0.004091, tar: 0.000072 
l0: 0.000037, l1: 0.000035, l2: 0.000114, l3: 0.000260, l4: 0.000876, l5: 0.001858, l6: 0.003139

[epoch: 615/1000, batch:  1032/ 1052, ite: 161740] train loss: 0.004089, tar: 0.000072 
[Epoch 615/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000053, l1: 0.000051, l2: 0.000077, l3: 0.000173, l4: 0.000241, l5: 0.000850, l6: 0.001360

[epoch: 616/1000, batch:    60/ 1052, ite: 161760] train loss: 0.004092, tar: 0.000072 
l0: 0.000059, l1: 0.000058, l2: 0.000100, l3: 0.000179, l4: 0.000535, l5: 0.001717, l6: 0.001910

[epoch: 616/1000, batch:   140/ 1052, ite: 161780] train loss: 0.004093, tar: 0.000072 
l0: 0.000054, l1: 0.000050, l2: 0.000094, l3: 0.000244, l4: 0.000528, l5: 0.001191, l6: 0.001534

[epoch: 616/1000, batch:   220/ 1052, ite: 161800] train loss: 0.004093, tar: 0.000072 
l0: 0.000053, l1: 0.000053, l2: 0.000091, l3: 0.000245, l4: 0.000559, l5: 0.001225, l6: 0.001441

[epoch: 616/1000, batch:   300/ 1052, ite: 161820] train loss: 0.004093, tar: 0.000072 
l0: 0.000051, l1: 0.000049, l2: 0.000107, l3: 0.000198, l4: 0.000440, l5: 0.001046, l6: 0.002919

[epoch: 616/1000, batch:   380/ 1052, ite: 161840] train loss: 0.004091, tar: 0.000072 
l0: 0.000025, l1: 0.000025, l2: 0.000048, l3: 0.000116, l4: 0.000218, l5: 0.001004, l6: 0.001470

[epoch: 616/1000, batch:   460/ 1052, ite: 161860] train loss: 0.004090, tar: 0.000072 
l0: 0.000039, l1: 0.000036, l2: 0.000072, l3: 0.000138, l4: 0.000431, l5: 0.001052, l6: 0.001377

[epoch: 616/1000, batch:   540/ 1052, ite: 161880] train loss: 0.004088, tar: 0.000072 
l0: 0.000035, l1: 0.000035, l2: 0.000113, l3: 0.000211, l4: 0.000624, l5: 0.000934, l6: 0.002280

[epoch: 616/1000, batch:   620/ 1052, ite: 161900] train loss: 0.004091, tar: 0.000072 
l0: 0.000017, l1: 0.000015, l2: 0.000106, l3: 0.000330, l4: 0.000753, l5: 0.001137, l6: 0.003174

[epoch: 616/1000, batch:   700/ 1052, ite: 161920] train loss: 0.004091, tar: 0.000072 
l0: 0.000057, l1: 0.000059, l2: 0.000104, l3: 0.000344, l4: 0.000585, l5: 0.000685, l6: 0.001604

[epoch: 616/1000, batch:   780/ 1052, ite: 161940] train loss: 0.004090, tar: 0.000072 
l0: 0.000092, l1: 0.000088, l2: 0.000155, l3: 0.000309, l4: 0.000744, l5: 0.001531, l6: 0.001822

[epoch: 616/1000, batch:   860/ 1052, ite: 161960] train loss: 0.004089, tar: 0.000072 
l0: 0.000030, l1: 0.000032, l2: 0.000056, l3: 0.000147, l4: 0.000345, l5: 0.000812, l6: 0.001686

[epoch: 616/1000, batch:   940/ 1052, ite: 161980] train loss: 0.004087, tar: 0.000071 
l0: 0.000018, l1: 0.000019, l2: 0.000042, l3: 0.000125, l4: 0.000397, l5: 0.000627, l6: 0.002170

[epoch: 616/1000, batch:  1020/ 1052, ite: 162000] train loss: 0.004088, tar: 0.000071 
[Epoch 616/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000102, l1: 0.000104, l2: 0.000194, l3: 0.000262, l4: 0.000517, l5: 0.001007, l6: 0.002827

[epoch: 617/1000, batch:    48/ 1052, ite: 162020] train loss: 0.004088, tar: 0.000071 
l0: 0.000076, l1: 0.000075, l2: 0.000179, l3: 0.000294, l4: 0.000381, l5: 0.000904, l6: 0.001846

[epoch: 617/1000, batch:   128/ 1052, ite: 162040] train loss: 0.004089, tar: 0.000071 
l0: 0.000049, l1: 0.000049, l2: 0.000164, l3: 0.000407, l4: 0.000867, l5: 0.001484, l6: 0.002412

[epoch: 617/1000, batch:   208/ 1052, ite: 162060] train loss: 0.004088, tar: 0.000071 
l0: 0.000011, l1: 0.000008, l2: 0.000065, l3: 0.000227, l4: 0.000660, l5: 0.001289, l6: 0.002265

[epoch: 617/1000, batch:   288/ 1052, ite: 162080] train loss: 0.004089, tar: 0.000071 
l0: 0.000051, l1: 0.000050, l2: 0.000113, l3: 0.000198, l4: 0.000431, l5: 0.001228, l6: 0.002166

[epoch: 617/1000, batch:   368/ 1052, ite: 162100] train loss: 0.004088, tar: 0.000071 
l0: 0.000050, l1: 0.000050, l2: 0.000077, l3: 0.000127, l4: 0.000342, l5: 0.000967, l6: 0.001659

[epoch: 617/1000, batch:   448/ 1052, ite: 162120] train loss: 0.004088, tar: 0.000071 
l0: 0.000044, l1: 0.000041, l2: 0.000162, l3: 0.000436, l4: 0.000759, l5: 0.001425, l6: 0.002189

[epoch: 617/1000, batch:   528/ 1052, ite: 162140] train loss: 0.004088, tar: 0.000071 
l0: 0.000077, l1: 0.000079, l2: 0.000115, l3: 0.000253, l4: 0.000556, l5: 0.001344, l6: 0.001870

[epoch: 617/1000, batch:   608/ 1052, ite: 162160] train loss: 0.004087, tar: 0.000071 
l0: 0.000058, l1: 0.000057, l2: 0.000135, l3: 0.000237, l4: 0.000483, l5: 0.000816, l6: 0.001921

[epoch: 617/1000, batch:   688/ 1052, ite: 162180] train loss: 0.004085, tar: 0.000071 
l0: 0.000030, l1: 0.000031, l2: 0.000049, l3: 0.000143, l4: 0.000351, l5: 0.000600, l6: 0.001127

[epoch: 617/1000, batch:   768/ 1052, ite: 162200] train loss: 0.004084, tar: 0.000071 
l0: 0.000088, l1: 0.000086, l2: 0.000141, l3: 0.000253, l4: 0.000631, l5: 0.001505, l6: 0.002324

[epoch: 617/1000, batch:   848/ 1052, ite: 162220] train loss: 0.004085, tar: 0.000071 
l0: 0.000096, l1: 0.000097, l2: 0.000180, l3: 0.000421, l4: 0.000849, l5: 0.001523, l6: 0.002710

[epoch: 617/1000, batch:   928/ 1052, ite: 162240] train loss: 0.004082, tar: 0.000070 
l0: 0.000008, l1: 0.000007, l2: 0.000038, l3: 0.000135, l4: 0.000267, l5: 0.000586, l6: 0.001137

[epoch: 617/1000, batch:  1008/ 1052, ite: 162260] train loss: 0.004080, tar: 0.000070 
[Epoch 617/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000049, l1: 0.000048, l2: 0.000065, l3: 0.000100, l4: 0.000307, l5: 0.000664, l6: 0.001394

[epoch: 618/1000, batch:    36/ 1052, ite: 162280] train loss: 0.004080, tar: 0.000070 
l0: 0.000040, l1: 0.000041, l2: 0.000075, l3: 0.000179, l4: 0.000383, l5: 0.000832, l6: 0.002094

[epoch: 618/1000, batch:   116/ 1052, ite: 162300] train loss: 0.004080, tar: 0.000070 
l0: 0.000020, l1: 0.000021, l2: 0.000019, l3: 0.000059, l4: 0.000307, l5: 0.000476, l6: 0.000897

[epoch: 618/1000, batch:   196/ 1052, ite: 162320] train loss: 0.004078, tar: 0.000070 
l0: 0.000071, l1: 0.000075, l2: 0.000137, l3: 0.000265, l4: 0.000437, l5: 0.000997, l6: 0.001958

[epoch: 618/1000, batch:   276/ 1052, ite: 162340] train loss: 0.004079, tar: 0.000070 
l0: 0.000027, l1: 0.000028, l2: 0.000071, l3: 0.000145, l4: 0.000307, l5: 0.000915, l6: 0.001099

[epoch: 618/1000, batch:   356/ 1052, ite: 162360] train loss: 0.004077, tar: 0.000070 
l0: 0.000019, l1: 0.000018, l2: 0.000046, l3: 0.000094, l4: 0.000224, l5: 0.000671, l6: 0.001028

[epoch: 618/1000, batch:   436/ 1052, ite: 162380] train loss: 0.004075, tar: 0.000070 
l0: 0.000051, l1: 0.000052, l2: 0.000053, l3: 0.000166, l4: 0.000264, l5: 0.000557, l6: 0.000942

[epoch: 618/1000, batch:   516/ 1052, ite: 162400] train loss: 0.004074, tar: 0.000070 
l0: 0.000111, l1: 0.000111, l2: 0.000170, l3: 0.000329, l4: 0.000811, l5: 0.001296, l6: 0.003658

[epoch: 618/1000, batch:   596/ 1052, ite: 162420] train loss: 0.004075, tar: 0.000070 
l0: 0.000020, l1: 0.000019, l2: 0.000046, l3: 0.000133, l4: 0.000359, l5: 0.000829, l6: 0.001559

[epoch: 618/1000, batch:   676/ 1052, ite: 162440] train loss: 0.004073, tar: 0.000070 
l0: 0.000208, l1: 0.000206, l2: 0.000271, l3: 0.000368, l4: 0.000778, l5: 0.001191, l6: 0.003876

[epoch: 618/1000, batch:   756/ 1052, ite: 162460] train loss: 0.004074, tar: 0.000070 
l0: 0.000021, l1: 0.000023, l2: 0.000053, l3: 0.000167, l4: 0.000500, l5: 0.001323, l6: 0.002576

[epoch: 618/1000, batch:   836/ 1052, ite: 162480] train loss: 0.004073, tar: 0.000069 
l0: 0.000004, l1: 0.000011, l2: 0.000018, l3: 0.000169, l4: 0.000459, l5: 0.000518, l6: 0.001080

[epoch: 618/1000, batch:   916/ 1052, ite: 162500] train loss: 0.004075, tar: 0.000069 
l0: 0.000034, l1: 0.000034, l2: 0.000071, l3: 0.000175, l4: 0.000460, l5: 0.000690, l6: 0.001769

[epoch: 618/1000, batch:   996/ 1052, ite: 162520] train loss: 0.004074, tar: 0.000069 
[Epoch 618/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000026, l1: 0.000024, l2: 0.000092, l3: 0.000183, l4: 0.000517, l5: 0.001355, l6: 0.001249

[epoch: 619/1000, batch:    24/ 1052, ite: 162540] train loss: 0.004074, tar: 0.000069 
l0: 0.000063, l1: 0.000064, l2: 0.000144, l3: 0.000280, l4: 0.000523, l5: 0.001026, l6: 0.001848

[epoch: 619/1000, batch:   104/ 1052, ite: 162560] train loss: 0.004073, tar: 0.000069 
l0: 0.000049, l1: 0.000049, l2: 0.000101, l3: 0.000204, l4: 0.000500, l5: 0.001842, l6: 0.002204

[epoch: 619/1000, batch:   184/ 1052, ite: 162580] train loss: 0.004071, tar: 0.000069 
l0: 0.000025, l1: 0.000023, l2: 0.000113, l3: 0.000295, l4: 0.000500, l5: 0.001653, l6: 0.002512

[epoch: 619/1000, batch:   264/ 1052, ite: 162600] train loss: 0.004071, tar: 0.000069 
l0: 0.000005, l1: 0.000005, l2: 0.000023, l3: 0.000177, l4: 0.000639, l5: 0.001388, l6: 0.002108

[epoch: 619/1000, batch:   344/ 1052, ite: 162620] train loss: 0.004071, tar: 0.000069 
l0: 0.000031, l1: 0.000031, l2: 0.000059, l3: 0.000131, l4: 0.000403, l5: 0.000711, l6: 0.001844

[epoch: 619/1000, batch:   424/ 1052, ite: 162640] train loss: 0.004072, tar: 0.000069 
l0: 0.000012, l1: 0.000012, l2: 0.000080, l3: 0.000255, l4: 0.000735, l5: 0.001144, l6: 0.001709

[epoch: 619/1000, batch:   504/ 1052, ite: 162660] train loss: 0.004070, tar: 0.000069 
l0: 0.000075, l1: 0.000072, l2: 0.000128, l3: 0.000291, l4: 0.000495, l5: 0.001109, l6: 0.001903

[epoch: 619/1000, batch:   584/ 1052, ite: 162680] train loss: 0.004068, tar: 0.000068 
l0: 0.000068, l1: 0.000070, l2: 0.000124, l3: 0.000310, l4: 0.000610, l5: 0.001400, l6: 0.002338

[epoch: 619/1000, batch:   664/ 1052, ite: 162700] train loss: 0.004067, tar: 0.000068 
l0: 0.000030, l1: 0.000029, l2: 0.000078, l3: 0.000185, l4: 0.000441, l5: 0.000596, l6: 0.001566

[epoch: 619/1000, batch:   744/ 1052, ite: 162720] train loss: 0.004070, tar: 0.000068 
l0: 0.000057, l1: 0.000060, l2: 0.000106, l3: 0.000243, l4: 0.000532, l5: 0.000976, l6: 0.002484

[epoch: 619/1000, batch:   824/ 1052, ite: 162740] train loss: 0.004069, tar: 0.000068 
l0: 0.000039, l1: 0.000039, l2: 0.000101, l3: 0.000348, l4: 0.000592, l5: 0.001075, l6: 0.001425

[epoch: 619/1000, batch:   904/ 1052, ite: 162760] train loss: 0.004069, tar: 0.000068 
l0: 0.000053, l1: 0.000051, l2: 0.000111, l3: 0.000209, l4: 0.000365, l5: 0.001056, l6: 0.001506

[epoch: 619/1000, batch:   984/ 1052, ite: 162780] train loss: 0.004071, tar: 0.000068 
[Epoch 619/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000044, l1: 0.000044, l2: 0.000145, l3: 0.000231, l4: 0.000557, l5: 0.001304, l6: 0.002474

[epoch: 620/1000, batch:    12/ 1052, ite: 162800] train loss: 0.004070, tar: 0.000068 
l0: 0.000051, l1: 0.000055, l2: 0.000108, l3: 0.000221, l4: 0.000442, l5: 0.000783, l6: 0.002348

[epoch: 620/1000, batch:    92/ 1052, ite: 162820] train loss: 0.004070, tar: 0.000068 
l0: 0.000042, l1: 0.000045, l2: 0.000093, l3: 0.000209, l4: 0.000766, l5: 0.001454, l6: 0.002504

[epoch: 620/1000, batch:   172/ 1052, ite: 162840] train loss: 0.004069, tar: 0.000068 
l0: 0.000095, l1: 0.000097, l2: 0.000085, l3: 0.000172, l4: 0.000395, l5: 0.000631, l6: 0.001170

[epoch: 620/1000, batch:   252/ 1052, ite: 162860] train loss: 0.004069, tar: 0.000068 
l0: 0.000155, l1: 0.000154, l2: 0.000245, l3: 0.000351, l4: 0.000706, l5: 0.001039, l6: 0.003868

[epoch: 620/1000, batch:   332/ 1052, ite: 162880] train loss: 0.004071, tar: 0.000068 
l0: 0.000081, l1: 0.000096, l2: 0.000092, l3: 0.000098, l4: 0.000354, l5: 0.000705, l6: 0.001244

[epoch: 620/1000, batch:   412/ 1052, ite: 162900] train loss: 0.004074, tar: 0.000068 
l0: 0.000036, l1: 0.000038, l2: 0.000066, l3: 0.000110, l4: 0.000331, l5: 0.000955, l6: 0.001149

[epoch: 620/1000, batch:   492/ 1052, ite: 162920] train loss: 0.004074, tar: 0.000068 
l0: 0.000088, l1: 0.000094, l2: 0.000131, l3: 0.000266, l4: 0.000429, l5: 0.001289, l6: 0.002895

[epoch: 620/1000, batch:   572/ 1052, ite: 162940] train loss: 0.004073, tar: 0.000068 
l0: 0.000056, l1: 0.000056, l2: 0.000112, l3: 0.000306, l4: 0.000612, l5: 0.001587, l6: 0.001815

[epoch: 620/1000, batch:   652/ 1052, ite: 162960] train loss: 0.004075, tar: 0.000068 
l0: 0.000018, l1: 0.000019, l2: 0.000042, l3: 0.000093, l4: 0.000399, l5: 0.000967, l6: 0.001215

[epoch: 620/1000, batch:   732/ 1052, ite: 162980] train loss: 0.004073, tar: 0.000068 
l0: 0.000060, l1: 0.000059, l2: 0.000142, l3: 0.000315, l4: 0.000793, l5: 0.001470, l6: 0.002655

[epoch: 620/1000, batch:   812/ 1052, ite: 163000] train loss: 0.004074, tar: 0.000068 
l0: 0.000049, l1: 0.000049, l2: 0.000111, l3: 0.000382, l4: 0.000930, l5: 0.001755, l6: 0.002383

[epoch: 620/1000, batch:   892/ 1052, ite: 163020] train loss: 0.004074, tar: 0.000068 
l0: 0.000099, l1: 0.000103, l2: 0.000130, l3: 0.000212, l4: 0.000380, l5: 0.001158, l6: 0.003243

[epoch: 620/1000, batch:   972/ 1052, ite: 163040] train loss: 0.004075, tar: 0.000068 
l0: 0.000042, l1: 0.000041, l2: 0.000085, l3: 0.000188, l4: 0.000411, l5: 0.000856, l6: 0.001806

[epoch: 620/1000, batch:  1052/ 1052, ite: 163060] train loss: 0.004072, tar: 0.000068 
[Epoch 620/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000024, l1: 0.000028, l2: 0.000066, l3: 0.000154, l4: 0.000370, l5: 0.000934, l6: 0.001865

[epoch: 621/1000, batch:    80/ 1052, ite: 163080] train loss: 0.004072, tar: 0.000068 
l0: 0.000036, l1: 0.000036, l2: 0.000052, l3: 0.000153, l4: 0.000396, l5: 0.001087, l6: 0.001398

[epoch: 621/1000, batch:   160/ 1052, ite: 163100] train loss: 0.004069, tar: 0.000068 
l0: 0.000018, l1: 0.000017, l2: 0.000052, l3: 0.000117, l4: 0.000320, l5: 0.000858, l6: 0.001258

[epoch: 621/1000, batch:   240/ 1052, ite: 163120] train loss: 0.004071, tar: 0.000068 
l0: 0.000056, l1: 0.000055, l2: 0.000112, l3: 0.000211, l4: 0.000426, l5: 0.001331, l6: 0.001343

[epoch: 621/1000, batch:   320/ 1052, ite: 163140] train loss: 0.004070, tar: 0.000068 
l0: 0.000024, l1: 0.000023, l2: 0.000067, l3: 0.000202, l4: 0.000491, l5: 0.001251, l6: 0.002067

[epoch: 621/1000, batch:   400/ 1052, ite: 163160] train loss: 0.004070, tar: 0.000067 
l0: 0.000029, l1: 0.000027, l2: 0.000141, l3: 0.000354, l4: 0.000533, l5: 0.000927, l6: 0.002002

[epoch: 621/1000, batch:   480/ 1052, ite: 163180] train loss: 0.004069, tar: 0.000067 
l0: 0.000044, l1: 0.000047, l2: 0.000055, l3: 0.000117, l4: 0.000298, l5: 0.001010, l6: 0.001242

[epoch: 621/1000, batch:   560/ 1052, ite: 163200] train loss: 0.004068, tar: 0.000067 
l0: 0.000059, l1: 0.000062, l2: 0.000101, l3: 0.000221, l4: 0.000444, l5: 0.001189, l6: 0.002151

[epoch: 621/1000, batch:   640/ 1052, ite: 163220] train loss: 0.004067, tar: 0.000067 
l0: 0.000017, l1: 0.000017, l2: 0.000051, l3: 0.000160, l4: 0.000392, l5: 0.000693, l6: 0.001403

[epoch: 621/1000, batch:   720/ 1052, ite: 163240] train loss: 0.004068, tar: 0.000067 
l0: 0.000123, l1: 0.000124, l2: 0.000145, l3: 0.000197, l4: 0.000639, l5: 0.001396, l6: 0.003759

[epoch: 621/1000, batch:   800/ 1052, ite: 163260] train loss: 0.004069, tar: 0.000067 
l0: 0.000002, l1: 0.000002, l2: 0.000014, l3: 0.000050, l4: 0.000178, l5: 0.000328, l6: 0.000502

[epoch: 621/1000, batch:   880/ 1052, ite: 163280] train loss: 0.004067, tar: 0.000067 
l0: 0.000028, l1: 0.000028, l2: 0.000052, l3: 0.000081, l4: 0.000270, l5: 0.000719, l6: 0.001362

[epoch: 621/1000, batch:   960/ 1052, ite: 163300] train loss: 0.004068, tar: 0.000067 
l0: 0.000044, l1: 0.000045, l2: 0.000078, l3: 0.000134, l4: 0.000303, l5: 0.000487, l6: 0.001528

[epoch: 621/1000, batch:  1040/ 1052, ite: 163320] train loss: 0.004069, tar: 0.000067 
[Epoch 621/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000026, l1: 0.000022, l2: 0.000053, l3: 0.000144, l4: 0.000389, l5: 0.000594, l6: 0.001721

[epoch: 622/1000, batch:    68/ 1052, ite: 163340] train loss: 0.004069, tar: 0.000067 
l0: 0.000021, l1: 0.000020, l2: 0.000089, l3: 0.000333, l4: 0.000601, l5: 0.001037, l6: 0.001505

[epoch: 622/1000, batch:   148/ 1052, ite: 163360] train loss: 0.004066, tar: 0.000067 
l0: 0.000006, l1: 0.000007, l2: 0.000028, l3: 0.000153, l4: 0.000462, l5: 0.001972, l6: 0.002411

[epoch: 622/1000, batch:   228/ 1052, ite: 163380] train loss: 0.004068, tar: 0.000067 
l0: 0.000139, l1: 0.000147, l2: 0.000225, l3: 0.000256, l4: 0.000602, l5: 0.001720, l6: 0.002815

[epoch: 622/1000, batch:   308/ 1052, ite: 163400] train loss: 0.004068, tar: 0.000067 
l0: 0.000121, l1: 0.000122, l2: 0.000133, l3: 0.000197, l4: 0.000517, l5: 0.000630, l6: 0.001162

[epoch: 622/1000, batch:   388/ 1052, ite: 163420] train loss: 0.004067, tar: 0.000067 
l0: 0.000072, l1: 0.000075, l2: 0.000101, l3: 0.000183, l4: 0.000367, l5: 0.001005, l6: 0.001630

[epoch: 622/1000, batch:   468/ 1052, ite: 163440] train loss: 0.004067, tar: 0.000067 
l0: 0.000020, l1: 0.000020, l2: 0.000046, l3: 0.000136, l4: 0.000605, l5: 0.001297, l6: 0.002377

[epoch: 622/1000, batch:   548/ 1052, ite: 163460] train loss: 0.004065, tar: 0.000067 
l0: 0.000026, l1: 0.000025, l2: 0.000074, l3: 0.000236, l4: 0.000526, l5: 0.001193, l6: 0.001708

[epoch: 622/1000, batch:   628/ 1052, ite: 163480] train loss: 0.004065, tar: 0.000067 
l0: 0.000084, l1: 0.000082, l2: 0.000113, l3: 0.000186, l4: 0.000446, l5: 0.001150, l6: 0.001623

[epoch: 622/1000, batch:   708/ 1052, ite: 163500] train loss: 0.004064, tar: 0.000067 
l0: 0.000110, l1: 0.000106, l2: 0.000218, l3: 0.000385, l4: 0.000638, l5: 0.001058, l6: 0.001581

[epoch: 622/1000, batch:   788/ 1052, ite: 163520] train loss: 0.004063, tar: 0.000066 
l0: 0.000060, l1: 0.000059, l2: 0.000093, l3: 0.000264, l4: 0.000615, l5: 0.000955, l6: 0.002514

[epoch: 622/1000, batch:   868/ 1052, ite: 163540] train loss: 0.004066, tar: 0.000066 
l0: 0.000011, l1: 0.000012, l2: 0.000032, l3: 0.000125, l4: 0.000377, l5: 0.000778, l6: 0.001531

[epoch: 622/1000, batch:   948/ 1052, ite: 163560] train loss: 0.004066, tar: 0.000066 
l0: 0.000013, l1: 0.000014, l2: 0.000035, l3: 0.000095, l4: 0.000295, l5: 0.001223, l6: 0.000735

[epoch: 622/1000, batch:  1028/ 1052, ite: 163580] train loss: 0.004065, tar: 0.000066 
[Epoch 622/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000037, l1: 0.000040, l2: 0.000098, l3: 0.000222, l4: 0.000576, l5: 0.000981, l6: 0.002031

[epoch: 623/1000, batch:    56/ 1052, ite: 163600] train loss: 0.004064, tar: 0.000066 
l0: 0.000161, l1: 0.000169, l2: 0.000200, l3: 0.000439, l4: 0.000701, l5: 0.002070, l6: 0.003231

[epoch: 623/1000, batch:   136/ 1052, ite: 163620] train loss: 0.004067, tar: 0.000066 
l0: 0.000122, l1: 0.000122, l2: 0.000212, l3: 0.000416, l4: 0.000957, l5: 0.002475, l6: 0.002795

[epoch: 623/1000, batch:   216/ 1052, ite: 163640] train loss: 0.004068, tar: 0.000066 
l0: 0.000075, l1: 0.000078, l2: 0.000130, l3: 0.000253, l4: 0.000488, l5: 0.001087, l6: 0.003235

[epoch: 623/1000, batch:   296/ 1052, ite: 163660] train loss: 0.004068, tar: 0.000066 
l0: 0.000021, l1: 0.000021, l2: 0.000036, l3: 0.000096, l4: 0.000192, l5: 0.000787, l6: 0.001590

[epoch: 623/1000, batch:   376/ 1052, ite: 163680] train loss: 0.004065, tar: 0.000066 
l0: 0.000028, l1: 0.000029, l2: 0.000044, l3: 0.000096, l4: 0.000413, l5: 0.000822, l6: 0.001415

[epoch: 623/1000, batch:   456/ 1052, ite: 163700] train loss: 0.004063, tar: 0.000066 
l0: 0.000057, l1: 0.000056, l2: 0.000071, l3: 0.000175, l4: 0.000284, l5: 0.000803, l6: 0.000788

[epoch: 623/1000, batch:   536/ 1052, ite: 163720] train loss: 0.004063, tar: 0.000066 
l0: 0.000531, l1: 0.000523, l2: 0.000435, l3: 0.000499, l4: 0.000609, l5: 0.000874, l6: 0.002825

[epoch: 623/1000, batch:   616/ 1052, ite: 163740] train loss: 0.004064, tar: 0.000066 
l0: 0.000039, l1: 0.000038, l2: 0.000062, l3: 0.000181, l4: 0.000487, l5: 0.001055, l6: 0.001219

[epoch: 623/1000, batch:   696/ 1052, ite: 163760] train loss: 0.004062, tar: 0.000066 
l0: 0.000011, l1: 0.000010, l2: 0.000027, l3: 0.000100, l4: 0.000376, l5: 0.000603, l6: 0.001108

[epoch: 623/1000, batch:   776/ 1052, ite: 163780] train loss: 0.004061, tar: 0.000066 
l0: 0.000083, l1: 0.000081, l2: 0.000186, l3: 0.000322, l4: 0.000443, l5: 0.001010, l6: 0.002236

[epoch: 623/1000, batch:   856/ 1052, ite: 163800] train loss: 0.004060, tar: 0.000066 
l0: 0.000031, l1: 0.000032, l2: 0.000100, l3: 0.000175, l4: 0.000287, l5: 0.000884, l6: 0.002023

[epoch: 623/1000, batch:   936/ 1052, ite: 163820] train loss: 0.004060, tar: 0.000066 
l0: 0.000041, l1: 0.000042, l2: 0.000059, l3: 0.000107, l4: 0.000321, l5: 0.000701, l6: 0.001481

[epoch: 623/1000, batch:  1016/ 1052, ite: 163840] train loss: 0.004060, tar: 0.000066 
[Epoch 623/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000063, l1: 0.000063, l2: 0.000107, l3: 0.000224, l4: 0.000529, l5: 0.001021, l6: 0.001277

[epoch: 624/1000, batch:    44/ 1052, ite: 163860] train loss: 0.004060, tar: 0.000066 
l0: 0.000011, l1: 0.000012, l2: 0.000041, l3: 0.000123, l4: 0.000325, l5: 0.001091, l6: 0.002226

[epoch: 624/1000, batch:   124/ 1052, ite: 163880] train loss: 0.004059, tar: 0.000065 
l0: 0.000019, l1: 0.000020, l2: 0.000038, l3: 0.000105, l4: 0.000408, l5: 0.001015, l6: 0.001579

[epoch: 624/1000, batch:   204/ 1052, ite: 163900] train loss: 0.004060, tar: 0.000065 
l0: 0.000024, l1: 0.000022, l2: 0.000126, l3: 0.000270, l4: 0.000569, l5: 0.001097, l6: 0.002966

[epoch: 624/1000, batch:   284/ 1052, ite: 163920] train loss: 0.004061, tar: 0.000065 
l0: 0.000066, l1: 0.000068, l2: 0.000092, l3: 0.000145, l4: 0.000401, l5: 0.000931, l6: 0.001873

[epoch: 624/1000, batch:   364/ 1052, ite: 163940] train loss: 0.004061, tar: 0.000065 
l0: 0.000012, l1: 0.000012, l2: 0.000044, l3: 0.000091, l4: 0.000366, l5: 0.000768, l6: 0.001234

[epoch: 624/1000, batch:   444/ 1052, ite: 163960] train loss: 0.004061, tar: 0.000065 
l0: 0.000026, l1: 0.000025, l2: 0.000060, l3: 0.000141, l4: 0.000288, l5: 0.000592, l6: 0.000803

[epoch: 624/1000, batch:   524/ 1052, ite: 163980] train loss: 0.004060, tar: 0.000065 
l0: 0.000062, l1: 0.000062, l2: 0.000109, l3: 0.000160, l4: 0.000486, l5: 0.001595, l6: 0.001287

[epoch: 624/1000, batch:   604/ 1052, ite: 164000] train loss: 0.004059, tar: 0.000065 
l0: 0.000073, l1: 0.000080, l2: 0.000117, l3: 0.000198, l4: 0.000362, l5: 0.000966, l6: 0.001134

[epoch: 624/1000, batch:   684/ 1052, ite: 164020] train loss: 0.004057, tar: 0.000065 
l0: 0.000045, l1: 0.000045, l2: 0.000089, l3: 0.000287, l4: 0.000590, l5: 0.001867, l6: 0.002161

[epoch: 624/1000, batch:   764/ 1052, ite: 164040] train loss: 0.004056, tar: 0.000065 
l0: 0.000066, l1: 0.000062, l2: 0.000141, l3: 0.000329, l4: 0.000495, l5: 0.000952, l6: 0.001321

[epoch: 624/1000, batch:   844/ 1052, ite: 164060] train loss: 0.004056, tar: 0.000065 
l0: 0.000020, l1: 0.000021, l2: 0.000051, l3: 0.000108, l4: 0.000375, l5: 0.001358, l6: 0.002551

[epoch: 624/1000, batch:   924/ 1052, ite: 164080] train loss: 0.004056, tar: 0.000065 
l0: 0.000025, l1: 0.000027, l2: 0.000085, l3: 0.000191, l4: 0.000445, l5: 0.001440, l6: 0.003463

[epoch: 624/1000, batch:  1004/ 1052, ite: 164100] train loss: 0.004056, tar: 0.000065 
[Epoch 624/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000022, l1: 0.000023, l2: 0.000060, l3: 0.000135, l4: 0.000299, l5: 0.000726, l6: 0.001455

[epoch: 625/1000, batch:    32/ 1052, ite: 164120] train loss: 0.004057, tar: 0.000065 
l0: 0.000006, l1: 0.000006, l2: 0.000035, l3: 0.000132, l4: 0.000350, l5: 0.000634, l6: 0.001243

[epoch: 625/1000, batch:   112/ 1052, ite: 164140] train loss: 0.004054, tar: 0.000065 
l0: 0.000053, l1: 0.000050, l2: 0.000112, l3: 0.000204, l4: 0.000496, l5: 0.001111, l6: 0.002199

[epoch: 625/1000, batch:   192/ 1052, ite: 164160] train loss: 0.004054, tar: 0.000065 
l0: 0.000106, l1: 0.000108, l2: 0.000162, l3: 0.000409, l4: 0.001016, l5: 0.002128, l6: 0.003985

[epoch: 625/1000, batch:   272/ 1052, ite: 164180] train loss: 0.004053, tar: 0.000065 
l0: 0.000014, l1: 0.000013, l2: 0.000038, l3: 0.000153, l4: 0.000278, l5: 0.000446, l6: 0.001484

[epoch: 625/1000, batch:   352/ 1052, ite: 164200] train loss: 0.004053, tar: 0.000065 
l0: 0.000059, l1: 0.000055, l2: 0.000132, l3: 0.000308, l4: 0.000639, l5: 0.001332, l6: 0.002658

[epoch: 625/1000, batch:   432/ 1052, ite: 164220] train loss: 0.004053, tar: 0.000065 
l0: 0.000012, l1: 0.000011, l2: 0.000050, l3: 0.000105, l4: 0.000397, l5: 0.000649, l6: 0.001750

[epoch: 625/1000, batch:   512/ 1052, ite: 164240] train loss: 0.004054, tar: 0.000065 
l0: 0.000127, l1: 0.000128, l2: 0.000255, l3: 0.000593, l4: 0.001369, l5: 0.002483, l6: 0.004883

[epoch: 625/1000, batch:   592/ 1052, ite: 164260] train loss: 0.004054, tar: 0.000065 
l0: 0.000043, l1: 0.000040, l2: 0.000055, l3: 0.000113, l4: 0.000304, l5: 0.000681, l6: 0.001072

[epoch: 625/1000, batch:   672/ 1052, ite: 164280] train loss: 0.004055, tar: 0.000065 
l0: 0.000036, l1: 0.000038, l2: 0.000054, l3: 0.000117, l4: 0.000434, l5: 0.001208, l6: 0.001525

[epoch: 625/1000, batch:   752/ 1052, ite: 164300] train loss: 0.004056, tar: 0.000065 
l0: 0.000112, l1: 0.000117, l2: 0.000153, l3: 0.000264, l4: 0.000410, l5: 0.001028, l6: 0.002534

[epoch: 625/1000, batch:   832/ 1052, ite: 164320] train loss: 0.004057, tar: 0.000065 
l0: 0.000048, l1: 0.000049, l2: 0.000065, l3: 0.000201, l4: 0.000444, l5: 0.001129, l6: 0.002654

[epoch: 625/1000, batch:   912/ 1052, ite: 164340] train loss: 0.004057, tar: 0.000065 
l0: 0.000104, l1: 0.000107, l2: 0.000165, l3: 0.000272, l4: 0.000571, l5: 0.000978, l6: 0.001995

[epoch: 625/1000, batch:   992/ 1052, ite: 164360] train loss: 0.004058, tar: 0.000065 
[Epoch 625/1000] Test loss: 0.015, Test target loss: 0.002
l0: 0.000101, l1: 0.000105, l2: 0.000154, l3: 0.000164, l4: 0.000680, l5: 0.000816, l6: 0.002036

[epoch: 626/1000, batch:    20/ 1052, ite: 164380] train loss: 0.004059, tar: 0.000065 
l0: 0.000041, l1: 0.000041, l2: 0.000068, l3: 0.000135, l4: 0.000330, l5: 0.000912, l6: 0.002165

[epoch: 626/1000, batch:   100/ 1052, ite: 164400] train loss: 0.004058, tar: 0.000065 
l0: 0.000103, l1: 0.000101, l2: 0.000232, l3: 0.000420, l4: 0.001257, l5: 0.002232, l6: 0.004032

[epoch: 626/1000, batch:   180/ 1052, ite: 164420] train loss: 0.004060, tar: 0.000065 
l0: 0.000032, l1: 0.000033, l2: 0.000072, l3: 0.000136, l4: 0.000378, l5: 0.000822, l6: 0.001443

[epoch: 626/1000, batch:   260/ 1052, ite: 164440] train loss: 0.004060, tar: 0.000065 
l0: 0.000062, l1: 0.000068, l2: 0.000096, l3: 0.000209, l4: 0.000490, l5: 0.001209, l6: 0.001584

[epoch: 626/1000, batch:   340/ 1052, ite: 164460] train loss: 0.004062, tar: 0.000065 
l0: 0.000037, l1: 0.000038, l2: 0.000085, l3: 0.000188, l4: 0.000629, l5: 0.001448, l6: 0.002139

[epoch: 626/1000, batch:   420/ 1052, ite: 164480] train loss: 0.004062, tar: 0.000065 
l0: 0.000049, l1: 0.000048, l2: 0.000065, l3: 0.000167, l4: 0.000543, l5: 0.000764, l6: 0.002173

[epoch: 626/1000, batch:   500/ 1052, ite: 164500] train loss: 0.004063, tar: 0.000065 
l0: 0.000174, l1: 0.000181, l2: 0.000239, l3: 0.000386, l4: 0.000598, l5: 0.001588, l6: 0.002548

[epoch: 626/1000, batch:   580/ 1052, ite: 164520] train loss: 0.004060, tar: 0.000065 
l0: 0.000050, l1: 0.000051, l2: 0.000140, l3: 0.000255, l4: 0.000567, l5: 0.000993, l6: 0.001152

[epoch: 626/1000, batch:   660/ 1052, ite: 164540] train loss: 0.004060, tar: 0.000065 
l0: 0.000033, l1: 0.000034, l2: 0.000049, l3: 0.000100, l4: 0.000474, l5: 0.000389, l6: 0.001272

[epoch: 626/1000, batch:   740/ 1052, ite: 164560] train loss: 0.004060, tar: 0.000065 
l0: 0.000082, l1: 0.000082, l2: 0.000177, l3: 0.000417, l4: 0.000731, l5: 0.001816, l6: 0.002395

[epoch: 626/1000, batch:   820/ 1052, ite: 164580] train loss: 0.004060, tar: 0.000065 
l0: 0.000052, l1: 0.000052, l2: 0.000099, l3: 0.000209, l4: 0.000874, l5: 0.001383, l6: 0.002190

[epoch: 626/1000, batch:   900/ 1052, ite: 164600] train loss: 0.004060, tar: 0.000065 
l0: 0.000066, l1: 0.000066, l2: 0.000129, l3: 0.000214, l4: 0.000412, l5: 0.000796, l6: 0.001953

[epoch: 626/1000, batch:   980/ 1052, ite: 164620] train loss: 0.004060, tar: 0.000065 
[Epoch 626/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000051, l1: 0.000053, l2: 0.000079, l3: 0.000263, l4: 0.000556, l5: 0.000970, l6: 0.001817

[epoch: 627/1000, batch:     8/ 1052, ite: 164640] train loss: 0.004061, tar: 0.000065 
l0: 0.000003, l1: 0.000003, l2: 0.000022, l3: 0.000097, l4: 0.000323, l5: 0.000519, l6: 0.001333

[epoch: 627/1000, batch:    88/ 1052, ite: 164660] train loss: 0.004060, tar: 0.000065 
l0: 0.000030, l1: 0.000032, l2: 0.000054, l3: 0.000163, l4: 0.000513, l5: 0.000873, l6: 0.001376

[epoch: 627/1000, batch:   168/ 1052, ite: 164680] train loss: 0.004061, tar: 0.000065 
l0: 0.000031, l1: 0.000031, l2: 0.000058, l3: 0.000079, l4: 0.000405, l5: 0.000777, l6: 0.001691

[epoch: 627/1000, batch:   248/ 1052, ite: 164700] train loss: 0.004061, tar: 0.000065 
l0: 0.000045, l1: 0.000050, l2: 0.000072, l3: 0.000183, l4: 0.000354, l5: 0.001163, l6: 0.001197

[epoch: 627/1000, batch:   328/ 1052, ite: 164720] train loss: 0.004061, tar: 0.000065 
l0: 0.000046, l1: 0.000048, l2: 0.000079, l3: 0.000141, l4: 0.000342, l5: 0.000815, l6: 0.000889

[epoch: 627/1000, batch:   408/ 1052, ite: 164740] train loss: 0.004060, tar: 0.000065 
l0: 0.000035, l1: 0.000039, l2: 0.000051, l3: 0.000197, l4: 0.000539, l5: 0.000652, l6: 0.001952

[epoch: 627/1000, batch:   488/ 1052, ite: 164760] train loss: 0.004059, tar: 0.000065 
l0: 0.000040, l1: 0.000041, l2: 0.000043, l3: 0.000075, l4: 0.000288, l5: 0.000522, l6: 0.001661

[epoch: 627/1000, batch:   568/ 1052, ite: 164780] train loss: 0.004059, tar: 0.000065 
l0: 0.000017, l1: 0.000018, l2: 0.000046, l3: 0.000216, l4: 0.000446, l5: 0.000698, l6: 0.001166

[epoch: 627/1000, batch:   648/ 1052, ite: 164800] train loss: 0.004059, tar: 0.000065 
l0: 0.000026, l1: 0.000026, l2: 0.000056, l3: 0.000106, l4: 0.000428, l5: 0.000571, l6: 0.000975

[epoch: 627/1000, batch:   728/ 1052, ite: 164820] train loss: 0.004058, tar: 0.000065 
l0: 0.000101, l1: 0.000103, l2: 0.000175, l3: 0.000418, l4: 0.000760, l5: 0.001899, l6: 0.004346

[epoch: 627/1000, batch:   808/ 1052, ite: 164840] train loss: 0.004059, tar: 0.000065 
l0: 0.000109, l1: 0.000111, l2: 0.000154, l3: 0.000270, l4: 0.000503, l5: 0.001284, l6: 0.002376

[epoch: 627/1000, batch:   888/ 1052, ite: 164860] train loss: 0.004059, tar: 0.000065 
l0: 0.000043, l1: 0.000044, l2: 0.000065, l3: 0.000192, l4: 0.000316, l5: 0.000615, l6: 0.001770

[epoch: 627/1000, batch:   968/ 1052, ite: 164880] train loss: 0.004058, tar: 0.000065 
l0: 0.000042, l1: 0.000046, l2: 0.000057, l3: 0.000206, l4: 0.000466, l5: 0.001243, l6: 0.002578

[epoch: 627/1000, batch:  1048/ 1052, ite: 164900] train loss: 0.004058, tar: 0.000065 
[Epoch 627/1000] Test loss: 0.015, Test target loss: 0.003
l0: 0.000020, l1: 0.000021, l2: 0.000075, l3: 0.000147, l4: 0.000486, l5: 0.001222, l6: 0.001668

[epoch: 628/1000, batch:    76/ 1052, ite: 164920] train loss: 0.004058, tar: 0.000065 
l0: 0.000015, l1: 0.000015, l2: 0.000043, l3: 0.000125, l4: 0.000336, l5: 0.000794, l6: 0.001727

[epoch: 628/1000, batch:   156/ 1052, ite: 164940] train loss: 0.004058, tar: 0.000065 
l0: 0.000041, l1: 0.000046, l2: 0.000040, l3: 0.000107, l4: 0.000180, l5: 0.000810, l6: 0.002334

[epoch: 628/1000, batch:   236/ 1052, ite: 164960] train loss: 0.004058, tar: 0.000064 
l0: 0.000009, l1: 0.000010, l2: 0.000023, l3: 0.000068, l4: 0.000253, l5: 0.000552, l6: 0.000917

[epoch: 628/1000, batch:   316/ 1052, ite: 164980] train loss: 0.004058, tar: 0.000064 
l0: 0.000007, l1: 0.000007, l2: 0.000022, l3: 0.000068, l4: 0.000443, l5: 0.001071, l6: 0.001844

[epoch: 628/1000, batch:   396/ 1052, ite: 165000] train loss: 0.004058, tar: 0.000064 
l0: 0.000018, l1: 0.000020, l2: 0.000047, l3: 0.000072, l4: 0.000261, l5: 0.000978, l6: 0.001358

[epoch: 628/1000, batch:   476/ 1052, ite: 165020] train loss: 0.004056, tar: 0.000064 
l0: 0.000083, l1: 0.000085, l2: 0.000215, l3: 0.000337, l4: 0.000750, l5: 0.002363, l6: 0.003506

[epoch: 628/1000, batch:   556/ 1052, ite: 165040] train loss: 0.004055, tar: 0.000064 
l0: 0.000102, l1: 0.000106, l2: 0.000139, l3: 0.000283, l4: 0.000623, l5: 0.001518, l6: 0.001970

[epoch: 628/1000, batch:   636/ 1052, ite: 165060] train loss: 0.004055, tar: 0.000064 
l0: 0.000010, l1: 0.000010, l2: 0.000038, l3: 0.000121, l4: 0.000429, l5: 0.000921, l6: 0.001426

[epoch: 628/1000, batch:   716/ 1052, ite: 165080] train loss: 0.004055, tar: 0.000064 
l0: 0.000037, l1: 0.000038, l2: 0.000048, l3: 0.000086, l4: 0.000287, l5: 0.000888, l6: 0.001013

[epoch: 628/1000, batch:   796/ 1052, ite: 165100] train loss: 0.004054, tar: 0.000064 
l0: 0.000041, l1: 0.000045, l2: 0.000130, l3: 0.000277, l4: 0.000399, l5: 0.001400, l6: 0.003436

[epoch: 628/1000, batch:   876/ 1052, ite: 165120] train loss: 0.004054, tar: 0.000064 
l0: 0.000026, l1: 0.000027, l2: 0.000064, l3: 0.000171, l4: 0.000412, l5: 0.000662, l6: 0.001320

[epoch: 628/1000, batch:   956/ 1052, ite: 165140] train loss: 0.004054, tar: 0.000064 
l0: 0.000049, l1: 0.000048, l2: 0.000131, l3: 0.000198, l4: 0.000450, l5: 0.000672, l6: 0.001409

[epoch: 628/1000, batch:  1036/ 1052, ite: 165160] train loss: 0.004055, tar: 0.000064 
[Epoch 628/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000148, l1: 0.000152, l2: 0.000210, l3: 0.000388, l4: 0.000767, l5: 0.001749, l6: 0.003276

[epoch: 629/1000, batch:    64/ 1052, ite: 165180] train loss: 0.004056, tar: 0.000064 
l0: 0.000033, l1: 0.000031, l2: 0.000098, l3: 0.000353, l4: 0.000897, l5: 0.001520, l6: 0.002708

[epoch: 629/1000, batch:   144/ 1052, ite: 165200] train loss: 0.004056, tar: 0.000064 
l0: 0.000047, l1: 0.000048, l2: 0.000072, l3: 0.000114, l4: 0.000273, l5: 0.000702, l6: 0.001622

[epoch: 629/1000, batch:   224/ 1052, ite: 165220] train loss: 0.004055, tar: 0.000064 
l0: 0.000054, l1: 0.000057, l2: 0.000106, l3: 0.000236, l4: 0.000622, l5: 0.001299, l6: 0.003097

[epoch: 629/1000, batch:   304/ 1052, ite: 165240] train loss: 0.004053, tar: 0.000064 
l0: 0.000056, l1: 0.000054, l2: 0.000100, l3: 0.000195, l4: 0.000405, l5: 0.000926, l6: 0.001547

[epoch: 629/1000, batch:   384/ 1052, ite: 165260] train loss: 0.004053, tar: 0.000064 
l0: 0.000037, l1: 0.000038, l2: 0.000059, l3: 0.000138, l4: 0.000426, l5: 0.000661, l6: 0.001359

[epoch: 629/1000, batch:   464/ 1052, ite: 165280] train loss: 0.004054, tar: 0.000064 
l0: 0.000013, l1: 0.000017, l2: 0.000029, l3: 0.000100, l4: 0.000328, l5: 0.000635, l6: 0.000905

[epoch: 629/1000, batch:   544/ 1052, ite: 165300] train loss: 0.004053, tar: 0.000064 
l0: 0.000041, l1: 0.000042, l2: 0.000083, l3: 0.000132, l4: 0.000478, l5: 0.001576, l6: 0.002597

[epoch: 629/1000, batch:   624/ 1052, ite: 165320] train loss: 0.004053, tar: 0.000064 
l0: 0.000063, l1: 0.000061, l2: 0.000127, l3: 0.000284, l4: 0.000703, l5: 0.001507, l6: 0.004318

[epoch: 629/1000, batch:   704/ 1052, ite: 165340] train loss: 0.004054, tar: 0.000064 
l0: 0.000068, l1: 0.000069, l2: 0.000143, l3: 0.000365, l4: 0.000694, l5: 0.001674, l6: 0.002287

[epoch: 629/1000, batch:   784/ 1052, ite: 165360] train loss: 0.004052, tar: 0.000064 
l0: 0.000112, l1: 0.000113, l2: 0.000137, l3: 0.000251, l4: 0.000571, l5: 0.000929, l6: 0.002157

[epoch: 629/1000, batch:   864/ 1052, ite: 165380] train loss: 0.004053, tar: 0.000064 
l0: 0.000048, l1: 0.000051, l2: 0.000085, l3: 0.000148, l4: 0.000402, l5: 0.001092, l6: 0.002365

[epoch: 629/1000, batch:   944/ 1052, ite: 165400] train loss: 0.004054, tar: 0.000064 
l0: 0.000037, l1: 0.000038, l2: 0.000159, l3: 0.000277, l4: 0.000486, l5: 0.001554, l6: 0.003005

[epoch: 629/1000, batch:  1024/ 1052, ite: 165420] train loss: 0.004055, tar: 0.000063 
[Epoch 629/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000009, l1: 0.000011, l2: 0.000043, l3: 0.000154, l4: 0.000510, l5: 0.001116, l6: 0.001892

[epoch: 630/1000, batch:    52/ 1052, ite: 165440] train loss: 0.004054, tar: 0.000063 
l0: 0.000034, l1: 0.000036, l2: 0.000073, l3: 0.000247, l4: 0.000723, l5: 0.001342, l6: 0.002476

[epoch: 630/1000, batch:   132/ 1052, ite: 165460] train loss: 0.004054, tar: 0.000063 
l0: 0.000034, l1: 0.000037, l2: 0.000147, l3: 0.000349, l4: 0.000652, l5: 0.000741, l6: 0.002131

[epoch: 630/1000, batch:   212/ 1052, ite: 165480] train loss: 0.004053, tar: 0.000063 
l0: 0.000006, l1: 0.000006, l2: 0.000038, l3: 0.000082, l4: 0.000388, l5: 0.000657, l6: 0.001145

[epoch: 630/1000, batch:   292/ 1052, ite: 165500] train loss: 0.004053, tar: 0.000063 
l0: 0.000011, l1: 0.000009, l2: 0.000031, l3: 0.000074, l4: 0.000138, l5: 0.000614, l6: 0.000604

[epoch: 630/1000, batch:   372/ 1052, ite: 165520] train loss: 0.004052, tar: 0.000063 
l0: 0.000010, l1: 0.000010, l2: 0.000028, l3: 0.000071, l4: 0.000228, l5: 0.000915, l6: 0.001076

[epoch: 630/1000, batch:   452/ 1052, ite: 165540] train loss: 0.004051, tar: 0.000063 
l0: 0.000028, l1: 0.000028, l2: 0.000042, l3: 0.000130, l4: 0.000262, l5: 0.000926, l6: 0.002445

[epoch: 630/1000, batch:   532/ 1052, ite: 165560] train loss: 0.004051, tar: 0.000063 
l0: 0.000015, l1: 0.000016, l2: 0.000074, l3: 0.000216, l4: 0.000462, l5: 0.001446, l6: 0.002282

[epoch: 630/1000, batch:   612/ 1052, ite: 165580] train loss: 0.004052, tar: 0.000063 
l0: 0.000056, l1: 0.000055, l2: 0.000058, l3: 0.000101, l4: 0.000356, l5: 0.000877, l6: 0.001229

[epoch: 630/1000, batch:   692/ 1052, ite: 165600] train loss: 0.004052, tar: 0.000063 
l0: 0.000062, l1: 0.000065, l2: 0.000134, l3: 0.000222, l4: 0.000442, l5: 0.001147, l6: 0.002997

[epoch: 630/1000, batch:   772/ 1052, ite: 165620] train loss: 0.004052, tar: 0.000063 
l0: 0.000115, l1: 0.000121, l2: 0.000290, l3: 0.000448, l4: 0.000888, l5: 0.001264, l6: 0.001908

[epoch: 630/1000, batch:   852/ 1052, ite: 165640] train loss: 0.004053, tar: 0.000063 
l0: 0.000027, l1: 0.000028, l2: 0.000060, l3: 0.000195, l4: 0.000305, l5: 0.000877, l6: 0.001422

[epoch: 630/1000, batch:   932/ 1052, ite: 165660] train loss: 0.004052, tar: 0.000063 
l0: 0.000017, l1: 0.000018, l2: 0.000044, l3: 0.000087, l4: 0.000349, l5: 0.000861, l6: 0.000799

[epoch: 630/1000, batch:  1012/ 1052, ite: 165680] train loss: 0.004053, tar: 0.000063 
[Epoch 630/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000073, l1: 0.000073, l2: 0.000105, l3: 0.000177, l4: 0.000363, l5: 0.001012, l6: 0.002034

[epoch: 631/1000, batch:    40/ 1052, ite: 165700] train loss: 0.004052, tar: 0.000063 
l0: 0.000015, l1: 0.000018, l2: 0.000057, l3: 0.000177, l4: 0.000389, l5: 0.000701, l6: 0.001395

[epoch: 631/1000, batch:   120/ 1052, ite: 165720] train loss: 0.004053, tar: 0.000063 
l0: 0.000049, l1: 0.000048, l2: 0.000091, l3: 0.000129, l4: 0.000273, l5: 0.000882, l6: 0.001329

[epoch: 631/1000, batch:   200/ 1052, ite: 165740] train loss: 0.004053, tar: 0.000063 
l0: 0.000013, l1: 0.000013, l2: 0.000067, l3: 0.000170, l4: 0.000398, l5: 0.000801, l6: 0.001170

[epoch: 631/1000, batch:   280/ 1052, ite: 165760] train loss: 0.004053, tar: 0.000063 
l0: 0.000096, l1: 0.000091, l2: 0.000165, l3: 0.000257, l4: 0.000457, l5: 0.001399, l6: 0.002416

[epoch: 631/1000, batch:   360/ 1052, ite: 165780] train loss: 0.004054, tar: 0.000063 
l0: 0.000073, l1: 0.000073, l2: 0.000099, l3: 0.000135, l4: 0.000454, l5: 0.000931, l6: 0.001335

[epoch: 631/1000, batch:   440/ 1052, ite: 165800] train loss: 0.004053, tar: 0.000063 
l0: 0.000047, l1: 0.000044, l2: 0.000082, l3: 0.000155, l4: 0.000350, l5: 0.000875, l6: 0.001605

[epoch: 631/1000, batch:   520/ 1052, ite: 165820] train loss: 0.004053, tar: 0.000063 
l0: 0.000115, l1: 0.000108, l2: 0.000147, l3: 0.000243, l4: 0.000438, l5: 0.000933, l6: 0.001551

[epoch: 631/1000, batch:   600/ 1052, ite: 165840] train loss: 0.004052, tar: 0.000063 
l0: 0.000073, l1: 0.000071, l2: 0.000138, l3: 0.000262, l4: 0.000527, l5: 0.001065, l6: 0.002101

[epoch: 631/1000, batch:   680/ 1052, ite: 165860] train loss: 0.004053, tar: 0.000063 
l0: 0.000045, l1: 0.000046, l2: 0.000044, l3: 0.000191, l4: 0.000490, l5: 0.001362, l6: 0.001797

[epoch: 631/1000, batch:   760/ 1052, ite: 165880] train loss: 0.004052, tar: 0.000063 
l0: 0.000063, l1: 0.000065, l2: 0.000138, l3: 0.000413, l4: 0.000877, l5: 0.001484, l6: 0.002739

[epoch: 631/1000, batch:   840/ 1052, ite: 165900] train loss: 0.004051, tar: 0.000063 
l0: 0.000041, l1: 0.000041, l2: 0.000073, l3: 0.000180, l4: 0.000374, l5: 0.001377, l6: 0.002458

[epoch: 631/1000, batch:   920/ 1052, ite: 165920] train loss: 0.004053, tar: 0.000063 
l0: 0.000055, l1: 0.000055, l2: 0.000081, l3: 0.000184, l4: 0.000694, l5: 0.001361, l6: 0.002433

[epoch: 631/1000, batch:  1000/ 1052, ite: 165940] train loss: 0.004052, tar: 0.000063 
[Epoch 631/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000026, l1: 0.000026, l2: 0.000062, l3: 0.000149, l4: 0.000353, l5: 0.001221, l6: 0.001448

[epoch: 632/1000, batch:    28/ 1052, ite: 165960] train loss: 0.004051, tar: 0.000063 
l0: 0.000019, l1: 0.000019, l2: 0.000043, l3: 0.000142, l4: 0.000278, l5: 0.000327, l6: 0.001307

[epoch: 632/1000, batch:   108/ 1052, ite: 165980] train loss: 0.004051, tar: 0.000063 
l0: 0.000008, l1: 0.000008, l2: 0.000023, l3: 0.000069, l4: 0.000241, l5: 0.000625, l6: 0.000940

[epoch: 632/1000, batch:   188/ 1052, ite: 166000] train loss: 0.004049, tar: 0.000063 
l0: 0.000039, l1: 0.000039, l2: 0.000071, l3: 0.000143, l4: 0.000334, l5: 0.000723, l6: 0.001504

[epoch: 632/1000, batch:   268/ 1052, ite: 166020] train loss: 0.004048, tar: 0.000063 
l0: 0.000030, l1: 0.000032, l2: 0.000065, l3: 0.000133, l4: 0.000523, l5: 0.001651, l6: 0.002057

[epoch: 632/1000, batch:   348/ 1052, ite: 166040] train loss: 0.004049, tar: 0.000063 
l0: 0.000025, l1: 0.000025, l2: 0.000057, l3: 0.000135, l4: 0.000318, l5: 0.000613, l6: 0.000950

[epoch: 632/1000, batch:   428/ 1052, ite: 166060] train loss: 0.004049, tar: 0.000063 
l0: 0.000010, l1: 0.000014, l2: 0.000016, l3: 0.000096, l4: 0.000280, l5: 0.000515, l6: 0.000639

[epoch: 632/1000, batch:   508/ 1052, ite: 166080] train loss: 0.004049, tar: 0.000063 
l0: 0.000022, l1: 0.000022, l2: 0.000042, l3: 0.000145, l4: 0.000302, l5: 0.000832, l6: 0.002329

[epoch: 632/1000, batch:   588/ 1052, ite: 166100] train loss: 0.004048, tar: 0.000063 
l0: 0.000052, l1: 0.000052, l2: 0.000068, l3: 0.000115, l4: 0.000309, l5: 0.000948, l6: 0.001286

[epoch: 632/1000, batch:   668/ 1052, ite: 166120] train loss: 0.004047, tar: 0.000063 
l0: 0.000108, l1: 0.000109, l2: 0.000153, l3: 0.000201, l4: 0.000354, l5: 0.001381, l6: 0.001337

[epoch: 632/1000, batch:   748/ 1052, ite: 166140] train loss: 0.004047, tar: 0.000063 
l0: 0.000058, l1: 0.000060, l2: 0.000089, l3: 0.000134, l4: 0.000282, l5: 0.000816, l6: 0.001512

[epoch: 632/1000, batch:   828/ 1052, ite: 166160] train loss: 0.004048, tar: 0.000063 
l0: 0.000008, l1: 0.000008, l2: 0.000078, l3: 0.000143, l4: 0.000231, l5: 0.000468, l6: 0.000860

[epoch: 632/1000, batch:   908/ 1052, ite: 166180] train loss: 0.004048, tar: 0.000063 
l0: 0.000070, l1: 0.000074, l2: 0.000138, l3: 0.000391, l4: 0.000739, l5: 0.001433, l6: 0.002039

[epoch: 632/1000, batch:   988/ 1052, ite: 166200] train loss: 0.004048, tar: 0.000063 
[Epoch 632/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000005, l1: 0.000006, l2: 0.000033, l3: 0.000070, l4: 0.000108, l5: 0.000476, l6: 0.000746

[epoch: 633/1000, batch:    16/ 1052, ite: 166220] train loss: 0.004049, tar: 0.000063 
l0: 0.000036, l1: 0.000034, l2: 0.000069, l3: 0.000150, l4: 0.000402, l5: 0.000681, l6: 0.002205

[epoch: 633/1000, batch:    96/ 1052, ite: 166240] train loss: 0.004050, tar: 0.000062 
l0: 0.000055, l1: 0.000054, l2: 0.000085, l3: 0.000314, l4: 0.000718, l5: 0.001430, l6: 0.002505

[epoch: 633/1000, batch:   176/ 1052, ite: 166260] train loss: 0.004050, tar: 0.000063 
l0: 0.000068, l1: 0.000069, l2: 0.000113, l3: 0.000188, l4: 0.000459, l5: 0.001412, l6: 0.001923

[epoch: 633/1000, batch:   256/ 1052, ite: 166280] train loss: 0.004051, tar: 0.000063 
l0: 0.000042, l1: 0.000042, l2: 0.000073, l3: 0.000233, l4: 0.000449, l5: 0.001107, l6: 0.002118

[epoch: 633/1000, batch:   336/ 1052, ite: 166300] train loss: 0.004051, tar: 0.000063 
l0: 0.000042, l1: 0.000041, l2: 0.000076, l3: 0.000157, l4: 0.000567, l5: 0.001230, l6: 0.002221

[epoch: 633/1000, batch:   416/ 1052, ite: 166320] train loss: 0.004051, tar: 0.000062 
l0: 0.000038, l1: 0.000041, l2: 0.000054, l3: 0.000127, l4: 0.000396, l5: 0.000821, l6: 0.001715

[epoch: 633/1000, batch:   496/ 1052, ite: 166340] train loss: 0.004051, tar: 0.000062 
l0: 0.000046, l1: 0.000048, l2: 0.000107, l3: 0.000155, l4: 0.000446, l5: 0.000569, l6: 0.001888

[epoch: 633/1000, batch:   576/ 1052, ite: 166360] train loss: 0.004050, tar: 0.000062 
l0: 0.000025, l1: 0.000026, l2: 0.000072, l3: 0.000196, l4: 0.000405, l5: 0.000972, l6: 0.001843

[epoch: 633/1000, batch:   656/ 1052, ite: 166380] train loss: 0.004050, tar: 0.000062 
l0: 0.000028, l1: 0.000030, l2: 0.000059, l3: 0.000133, l4: 0.000292, l5: 0.000736, l6: 0.002282

[epoch: 633/1000, batch:   736/ 1052, ite: 166400] train loss: 0.004049, tar: 0.000062 
l0: 0.000394, l1: 0.000394, l2: 0.000300, l3: 0.000308, l4: 0.000313, l5: 0.000740, l6: 0.001497

[epoch: 633/1000, batch:   816/ 1052, ite: 166420] train loss: 0.004049, tar: 0.000062 
l0: 0.000028, l1: 0.000029, l2: 0.000107, l3: 0.000237, l4: 0.000571, l5: 0.001337, l6: 0.002648

[epoch: 633/1000, batch:   896/ 1052, ite: 166440] train loss: 0.004049, tar: 0.000062 
l0: 0.000031, l1: 0.000031, l2: 0.000112, l3: 0.000161, l4: 0.000299, l5: 0.000974, l6: 0.001251

[epoch: 633/1000, batch:   976/ 1052, ite: 166460] train loss: 0.004048, tar: 0.000062 
[Epoch 633/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000050, l1: 0.000053, l2: 0.000126, l3: 0.000413, l4: 0.000907, l5: 0.001253, l6: 0.002269

[epoch: 634/1000, batch:     4/ 1052, ite: 166480] train loss: 0.004048, tar: 0.000062 
l0: 0.000028, l1: 0.000030, l2: 0.000067, l3: 0.000140, l4: 0.000337, l5: 0.000621, l6: 0.002715

[epoch: 634/1000, batch:    84/ 1052, ite: 166500] train loss: 0.004049, tar: 0.000062 
l0: 0.000030, l1: 0.000029, l2: 0.000055, l3: 0.000137, l4: 0.000335, l5: 0.000574, l6: 0.001671

[epoch: 634/1000, batch:   164/ 1052, ite: 166520] train loss: 0.004048, tar: 0.000062 
l0: 0.000010, l1: 0.000011, l2: 0.000017, l3: 0.000097, l4: 0.000313, l5: 0.000766, l6: 0.001188

[epoch: 634/1000, batch:   244/ 1052, ite: 166540] train loss: 0.004048, tar: 0.000062 
l0: 0.000129, l1: 0.000129, l2: 0.000179, l3: 0.000399, l4: 0.001017, l5: 0.001829, l6: 0.002548

[epoch: 634/1000, batch:   324/ 1052, ite: 166560] train loss: 0.004048, tar: 0.000062 
l0: 0.000035, l1: 0.000036, l2: 0.000042, l3: 0.000110, l4: 0.000382, l5: 0.000963, l6: 0.001001

[epoch: 634/1000, batch:   404/ 1052, ite: 166580] train loss: 0.004047, tar: 0.000062 
l0: 0.000113, l1: 0.000118, l2: 0.000185, l3: 0.000344, l4: 0.000840, l5: 0.001385, l6: 0.002572

[epoch: 634/1000, batch:   484/ 1052, ite: 166600] train loss: 0.004047, tar: 0.000062 
l0: 0.000106, l1: 0.000105, l2: 0.000119, l3: 0.000149, l4: 0.000378, l5: 0.000747, l6: 0.001192

[epoch: 634/1000, batch:   564/ 1052, ite: 166620] train loss: 0.004047, tar: 0.000062 
l0: 0.000065, l1: 0.000064, l2: 0.000119, l3: 0.000309, l4: 0.000642, l5: 0.001356, l6: 0.003131

[epoch: 634/1000, batch:   644/ 1052, ite: 166640] train loss: 0.004047, tar: 0.000062 
l0: 0.000030, l1: 0.000033, l2: 0.000072, l3: 0.000171, l4: 0.000489, l5: 0.001880, l6: 0.002647

[epoch: 634/1000, batch:   724/ 1052, ite: 166660] train loss: 0.004046, tar: 0.000062 
l0: 0.000066, l1: 0.000073, l2: 0.000113, l3: 0.000245, l4: 0.000486, l5: 0.001691, l6: 0.003269

[epoch: 634/1000, batch:   804/ 1052, ite: 166680] train loss: 0.004046, tar: 0.000062 
l0: 0.000027, l1: 0.000027, l2: 0.000051, l3: 0.000124, l4: 0.000473, l5: 0.000898, l6: 0.002281

[epoch: 634/1000, batch:   884/ 1052, ite: 166700] train loss: 0.004047, tar: 0.000062 
l0: 0.000073, l1: 0.000073, l2: 0.000146, l3: 0.000282, l4: 0.000758, l5: 0.001654, l6: 0.002283

[epoch: 634/1000, batch:   964/ 1052, ite: 166720] train loss: 0.004047, tar: 0.000062 
l0: 0.000033, l1: 0.000033, l2: 0.000057, l3: 0.000207, l4: 0.000389, l5: 0.000903, l6: 0.001395

[epoch: 634/1000, batch:  1044/ 1052, ite: 166740] train loss: 0.004047, tar: 0.000062 
[Epoch 634/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000031, l1: 0.000032, l2: 0.000053, l3: 0.000174, l4: 0.000483, l5: 0.000935, l6: 0.001911

[epoch: 635/1000, batch:    72/ 1052, ite: 166760] train loss: 0.004046, tar: 0.000062 
l0: 0.000042, l1: 0.000043, l2: 0.000081, l3: 0.000113, l4: 0.000261, l5: 0.000543, l6: 0.001804

[epoch: 635/1000, batch:   152/ 1052, ite: 166780] train loss: 0.004046, tar: 0.000062 
l0: 0.000065, l1: 0.000067, l2: 0.000106, l3: 0.000196, l4: 0.000423, l5: 0.000889, l6: 0.003398

[epoch: 635/1000, batch:   232/ 1052, ite: 166800] train loss: 0.004046, tar: 0.000062 
l0: 0.000020, l1: 0.000021, l2: 0.000040, l3: 0.000105, l4: 0.000484, l5: 0.000697, l6: 0.001218

[epoch: 635/1000, batch:   312/ 1052, ite: 166820] train loss: 0.004046, tar: 0.000062 
l0: 0.000042, l1: 0.000043, l2: 0.000109, l3: 0.000390, l4: 0.001127, l5: 0.001532, l6: 0.002804

[epoch: 635/1000, batch:   392/ 1052, ite: 166840] train loss: 0.004045, tar: 0.000062 
l0: 0.000064, l1: 0.000060, l2: 0.000112, l3: 0.000191, l4: 0.000786, l5: 0.001224, l6: 0.002610

[epoch: 635/1000, batch:   472/ 1052, ite: 166860] train loss: 0.004045, tar: 0.000062 
l0: 0.000045, l1: 0.000048, l2: 0.000125, l3: 0.000261, l4: 0.000459, l5: 0.001264, l6: 0.002430

[epoch: 635/1000, batch:   552/ 1052, ite: 166880] train loss: 0.004045, tar: 0.000062 
l0: 0.000044, l1: 0.000043, l2: 0.000090, l3: 0.000214, l4: 0.000543, l5: 0.001011, l6: 0.002048

[epoch: 635/1000, batch:   632/ 1052, ite: 166900] train loss: 0.004045, tar: 0.000062 
l0: 0.000054, l1: 0.000055, l2: 0.000070, l3: 0.000213, l4: 0.000518, l5: 0.001648, l6: 0.003398

[epoch: 635/1000, batch:   712/ 1052, ite: 166920] train loss: 0.004045, tar: 0.000062 
l0: 0.000080, l1: 0.000077, l2: 0.000109, l3: 0.000222, l4: 0.000407, l5: 0.001045, l6: 0.002477

[epoch: 635/1000, batch:   792/ 1052, ite: 166940] train loss: 0.004045, tar: 0.000062 
l0: 0.000057, l1: 0.000051, l2: 0.000120, l3: 0.000176, l4: 0.000269, l5: 0.000613, l6: 0.001175

[epoch: 635/1000, batch:   872/ 1052, ite: 166960] train loss: 0.004044, tar: 0.000062 
l0: 0.000065, l1: 0.000067, l2: 0.000092, l3: 0.000215, l4: 0.000375, l5: 0.001154, l6: 0.002955

[epoch: 635/1000, batch:   952/ 1052, ite: 166980] train loss: 0.004044, tar: 0.000062 
l0: 0.000076, l1: 0.000076, l2: 0.000112, l3: 0.000255, l4: 0.000586, l5: 0.001580, l6: 0.002378

[epoch: 635/1000, batch:  1032/ 1052, ite: 167000] train loss: 0.004044, tar: 0.000062 
[Epoch 635/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000093, l1: 0.000094, l2: 0.000152, l3: 0.000308, l4: 0.000443, l5: 0.000966, l6: 0.002041

[epoch: 636/1000, batch:    60/ 1052, ite: 167020] train loss: 0.004045, tar: 0.000062 
l0: 0.000023, l1: 0.000024, l2: 0.000051, l3: 0.000120, l4: 0.000264, l5: 0.000795, l6: 0.001103

[epoch: 636/1000, batch:   140/ 1052, ite: 167040] train loss: 0.004045, tar: 0.000062 
l0: 0.000018, l1: 0.000019, l2: 0.000037, l3: 0.000127, l4: 0.000321, l5: 0.000907, l6: 0.001255

[epoch: 636/1000, batch:   220/ 1052, ite: 167060] train loss: 0.004045, tar: 0.000062 
l0: 0.000104, l1: 0.000103, l2: 0.000210, l3: 0.000405, l4: 0.000856, l5: 0.001941, l6: 0.003670

[epoch: 636/1000, batch:   300/ 1052, ite: 167080] train loss: 0.004046, tar: 0.000062 
l0: 0.000047, l1: 0.000050, l2: 0.000049, l3: 0.000134, l4: 0.000577, l5: 0.001342, l6: 0.002502

[epoch: 636/1000, batch:   380/ 1052, ite: 167100] train loss: 0.004046, tar: 0.000062 
l0: 0.000051, l1: 0.000050, l2: 0.000075, l3: 0.000148, l4: 0.000432, l5: 0.000677, l6: 0.001748

[epoch: 636/1000, batch:   460/ 1052, ite: 167120] train loss: 0.004045, tar: 0.000062 
l0: 0.000042, l1: 0.000043, l2: 0.000089, l3: 0.000281, l4: 0.000660, l5: 0.001507, l6: 0.002678

[epoch: 636/1000, batch:   540/ 1052, ite: 167140] train loss: 0.004046, tar: 0.000062 
l0: 0.000033, l1: 0.000034, l2: 0.000075, l3: 0.000305, l4: 0.000609, l5: 0.001434, l6: 0.002771

[epoch: 636/1000, batch:   620/ 1052, ite: 167160] train loss: 0.004047, tar: 0.000062 
l0: 0.000045, l1: 0.000046, l2: 0.000109, l3: 0.000207, l4: 0.000532, l5: 0.001163, l6: 0.002475

[epoch: 636/1000, batch:   700/ 1052, ite: 167180] train loss: 0.004046, tar: 0.000062 
l0: 0.000050, l1: 0.000049, l2: 0.000164, l3: 0.000347, l4: 0.000876, l5: 0.001281, l6: 0.002233

[epoch: 636/1000, batch:   780/ 1052, ite: 167200] train loss: 0.004045, tar: 0.000062 
l0: 0.000080, l1: 0.000084, l2: 0.000095, l3: 0.000180, l4: 0.000410, l5: 0.001175, l6: 0.001568

[epoch: 636/1000, batch:   860/ 1052, ite: 167220] train loss: 0.004045, tar: 0.000062 
l0: 0.000070, l1: 0.000068, l2: 0.000128, l3: 0.000208, l4: 0.000370, l5: 0.000856, l6: 0.001548

[epoch: 636/1000, batch:   940/ 1052, ite: 167240] train loss: 0.004045, tar: 0.000061 
l0: 0.000131, l1: 0.000139, l2: 0.000133, l3: 0.000302, l4: 0.000769, l5: 0.001318, l6: 0.002454

[epoch: 636/1000, batch:  1020/ 1052, ite: 167260] train loss: 0.004044, tar: 0.000061 
[Epoch 636/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000056, l1: 0.000056, l2: 0.000131, l3: 0.000332, l4: 0.000632, l5: 0.000837, l6: 0.002057

[epoch: 637/1000, batch:    48/ 1052, ite: 167280] train loss: 0.004044, tar: 0.000061 
l0: 0.000045, l1: 0.000042, l2: 0.000093, l3: 0.000205, l4: 0.000423, l5: 0.000884, l6: 0.002169

[epoch: 637/1000, batch:   128/ 1052, ite: 167300] train loss: 0.004043, tar: 0.000061 
l0: 0.000022, l1: 0.000022, l2: 0.000092, l3: 0.000210, l4: 0.000423, l5: 0.000772, l6: 0.001321

[epoch: 637/1000, batch:   208/ 1052, ite: 167320] train loss: 0.004043, tar: 0.000061 
l0: 0.000014, l1: 0.000015, l2: 0.000043, l3: 0.000098, l4: 0.000237, l5: 0.000501, l6: 0.000888

[epoch: 637/1000, batch:   288/ 1052, ite: 167340] train loss: 0.004042, tar: 0.000061 
l0: 0.000020, l1: 0.000022, l2: 0.000051, l3: 0.000143, l4: 0.000226, l5: 0.000932, l6: 0.001699

[epoch: 637/1000, batch:   368/ 1052, ite: 167360] train loss: 0.004043, tar: 0.000061 
l0: 0.000040, l1: 0.000044, l2: 0.000054, l3: 0.000121, l4: 0.000353, l5: 0.001149, l6: 0.001676

[epoch: 637/1000, batch:   448/ 1052, ite: 167380] train loss: 0.004043, tar: 0.000061 
l0: 0.000018, l1: 0.000015, l2: 0.000057, l3: 0.000090, l4: 0.000280, l5: 0.000880, l6: 0.001295

[epoch: 637/1000, batch:   528/ 1052, ite: 167400] train loss: 0.004044, tar: 0.000061 
l0: 0.000042, l1: 0.000043, l2: 0.000084, l3: 0.000162, l4: 0.000417, l5: 0.000805, l6: 0.001687

[epoch: 637/1000, batch:   608/ 1052, ite: 167420] train loss: 0.004045, tar: 0.000061 
l0: 0.000040, l1: 0.000038, l2: 0.000078, l3: 0.000131, l4: 0.000328, l5: 0.000967, l6: 0.001563

[epoch: 637/1000, batch:   688/ 1052, ite: 167440] train loss: 0.004044, tar: 0.000061 
l0: 0.000024, l1: 0.000025, l2: 0.000036, l3: 0.000118, l4: 0.000262, l5: 0.001118, l6: 0.001486

[epoch: 637/1000, batch:   768/ 1052, ite: 167460] train loss: 0.004045, tar: 0.000061 
l0: 0.000038, l1: 0.000038, l2: 0.000038, l3: 0.000069, l4: 0.000249, l5: 0.000331, l6: 0.001194

[epoch: 637/1000, batch:   848/ 1052, ite: 167480] train loss: 0.004044, tar: 0.000061 
l0: 0.000027, l1: 0.000028, l2: 0.000058, l3: 0.000158, l4: 0.000468, l5: 0.001354, l6: 0.002023

[epoch: 637/1000, batch:   928/ 1052, ite: 167500] train loss: 0.004044, tar: 0.000061 
l0: 0.000036, l1: 0.000038, l2: 0.000091, l3: 0.000210, l4: 0.000523, l5: 0.001797, l6: 0.003297

[epoch: 637/1000, batch:  1008/ 1052, ite: 167520] train loss: 0.004044, tar: 0.000061 
[Epoch 637/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000054, l1: 0.000059, l2: 0.000126, l3: 0.000346, l4: 0.001075, l5: 0.001687, l6: 0.003568

[epoch: 638/1000, batch:    36/ 1052, ite: 167540] train loss: 0.004045, tar: 0.000061 
l0: 0.000059, l1: 0.000060, l2: 0.000068, l3: 0.000117, l4: 0.000311, l5: 0.001049, l6: 0.001639

[epoch: 638/1000, batch:   116/ 1052, ite: 167560] train loss: 0.004046, tar: 0.000061 
l0: 0.000072, l1: 0.000072, l2: 0.000104, l3: 0.000293, l4: 0.000463, l5: 0.000901, l6: 0.002740

[epoch: 638/1000, batch:   196/ 1052, ite: 167580] train loss: 0.004045, tar: 0.000061 
l0: 0.000017, l1: 0.000018, l2: 0.000039, l3: 0.000122, l4: 0.000513, l5: 0.000698, l6: 0.001235

[epoch: 638/1000, batch:   276/ 1052, ite: 167600] train loss: 0.004043, tar: 0.000061 
l0: 0.000024, l1: 0.000023, l2: 0.000059, l3: 0.000210, l4: 0.000598, l5: 0.001595, l6: 0.002379

[epoch: 638/1000, batch:   356/ 1052, ite: 167620] train loss: 0.004043, tar: 0.000061 
l0: 0.000022, l1: 0.000022, l2: 0.000058, l3: 0.000160, l4: 0.000378, l5: 0.001081, l6: 0.001712

[epoch: 638/1000, batch:   436/ 1052, ite: 167640] train loss: 0.004042, tar: 0.000061 
l0: 0.000047, l1: 0.000048, l2: 0.000124, l3: 0.000343, l4: 0.000762, l5: 0.001689, l6: 0.003128

[epoch: 638/1000, batch:   516/ 1052, ite: 167660] train loss: 0.004043, tar: 0.000061 
l0: 0.000050, l1: 0.000047, l2: 0.000098, l3: 0.000253, l4: 0.000552, l5: 0.001142, l6: 0.002501

[epoch: 638/1000, batch:   596/ 1052, ite: 167680] train loss: 0.004043, tar: 0.000061 
l0: 0.000063, l1: 0.000069, l2: 0.000115, l3: 0.000181, l4: 0.000460, l5: 0.001068, l6: 0.002676

[epoch: 638/1000, batch:   676/ 1052, ite: 167700] train loss: 0.004043, tar: 0.000061 
l0: 0.000017, l1: 0.000016, l2: 0.000052, l3: 0.000127, l4: 0.000303, l5: 0.001076, l6: 0.001265

[epoch: 638/1000, batch:   756/ 1052, ite: 167720] train loss: 0.004043, tar: 0.000061 
l0: 0.000098, l1: 0.000094, l2: 0.000213, l3: 0.000388, l4: 0.000837, l5: 0.001717, l6: 0.004352

[epoch: 638/1000, batch:   836/ 1052, ite: 167740] train loss: 0.004043, tar: 0.000061 
l0: 0.000087, l1: 0.000087, l2: 0.000141, l3: 0.000233, l4: 0.000579, l5: 0.001241, l6: 0.001544

[epoch: 638/1000, batch:   916/ 1052, ite: 167760] train loss: 0.004043, tar: 0.000061 
l0: 0.000052, l1: 0.000053, l2: 0.000057, l3: 0.000143, l4: 0.000326, l5: 0.000961, l6: 0.001785

[epoch: 638/1000, batch:   996/ 1052, ite: 167780] train loss: 0.004043, tar: 0.000061 
[Epoch 638/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000023, l1: 0.000026, l2: 0.000045, l3: 0.000196, l4: 0.000329, l5: 0.000872, l6: 0.002252

[epoch: 639/1000, batch:    24/ 1052, ite: 167800] train loss: 0.004042, tar: 0.000061 
l0: 0.000094, l1: 0.000092, l2: 0.000138, l3: 0.000282, l4: 0.000665, l5: 0.001338, l6: 0.001258

[epoch: 639/1000, batch:   104/ 1052, ite: 167820] train loss: 0.004042, tar: 0.000061 
l0: 0.000057, l1: 0.000056, l2: 0.000090, l3: 0.000191, l4: 0.000451, l5: 0.000908, l6: 0.002532

[epoch: 639/1000, batch:   184/ 1052, ite: 167840] train loss: 0.004042, tar: 0.000061 
l0: 0.000053, l1: 0.000055, l2: 0.000090, l3: 0.000214, l4: 0.000518, l5: 0.001084, l6: 0.001617

[epoch: 639/1000, batch:   264/ 1052, ite: 167860] train loss: 0.004041, tar: 0.000061 
l0: 0.000032, l1: 0.000032, l2: 0.000063, l3: 0.000149, l4: 0.000284, l5: 0.000824, l6: 0.001447

[epoch: 639/1000, batch:   344/ 1052, ite: 167880] train loss: 0.004041, tar: 0.000061 
l0: 0.000035, l1: 0.000035, l2: 0.000063, l3: 0.000202, l4: 0.000546, l5: 0.001289, l6: 0.002091

[epoch: 639/1000, batch:   424/ 1052, ite: 167900] train loss: 0.004042, tar: 0.000061 
l0: 0.000035, l1: 0.000034, l2: 0.000097, l3: 0.000273, l4: 0.000631, l5: 0.001405, l6: 0.002597

[epoch: 639/1000, batch:   504/ 1052, ite: 167920] train loss: 0.004042, tar: 0.000061 
l0: 0.000072, l1: 0.000075, l2: 0.000185, l3: 0.000391, l4: 0.000563, l5: 0.001660, l6: 0.003867

[epoch: 639/1000, batch:   584/ 1052, ite: 167940] train loss: 0.004042, tar: 0.000061 
l0: 0.000038, l1: 0.000034, l2: 0.000063, l3: 0.000155, l4: 0.000318, l5: 0.000939, l6: 0.001336

[epoch: 639/1000, batch:   664/ 1052, ite: 167960] train loss: 0.004041, tar: 0.000061 
l0: 0.000024, l1: 0.000023, l2: 0.000065, l3: 0.000174, l4: 0.000411, l5: 0.000994, l6: 0.001997

[epoch: 639/1000, batch:   744/ 1052, ite: 167980] train loss: 0.004041, tar: 0.000061 
l0: 0.000034, l1: 0.000033, l2: 0.000081, l3: 0.000195, l4: 0.000602, l5: 0.001235, l6: 0.001807

[epoch: 639/1000, batch:   824/ 1052, ite: 168000] train loss: 0.004041, tar: 0.000061 
l0: 0.000028, l1: 0.000029, l2: 0.000065, l3: 0.000153, l4: 0.000450, l5: 0.001531, l6: 0.002537

[epoch: 639/1000, batch:   904/ 1052, ite: 168020] train loss: 0.004041, tar: 0.000061 
l0: 0.000073, l1: 0.000078, l2: 0.000133, l3: 0.000276, l4: 0.000532, l5: 0.001214, l6: 0.002686

[epoch: 639/1000, batch:   984/ 1052, ite: 168040] train loss: 0.004042, tar: 0.000061 
[Epoch 639/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000106, l1: 0.000107, l2: 0.000172, l3: 0.000283, l4: 0.000420, l5: 0.000802, l6: 0.001201

[epoch: 640/1000, batch:    12/ 1052, ite: 168060] train loss: 0.004042, tar: 0.000061 
l0: 0.000009, l1: 0.000010, l2: 0.000034, l3: 0.000100, l4: 0.000323, l5: 0.000603, l6: 0.001162

[epoch: 640/1000, batch:    92/ 1052, ite: 168080] train loss: 0.004041, tar: 0.000061 
l0: 0.000039, l1: 0.000035, l2: 0.000060, l3: 0.000147, l4: 0.000424, l5: 0.000637, l6: 0.001129

[epoch: 640/1000, batch:   172/ 1052, ite: 168100] train loss: 0.004040, tar: 0.000061 
l0: 0.000015, l1: 0.000018, l2: 0.000033, l3: 0.000116, l4: 0.000450, l5: 0.001184, l6: 0.001413

[epoch: 640/1000, batch:   252/ 1052, ite: 168120] train loss: 0.004039, tar: 0.000061 
l0: 0.000008, l1: 0.000009, l2: 0.000029, l3: 0.000151, l4: 0.000326, l5: 0.000788, l6: 0.001562

[epoch: 640/1000, batch:   332/ 1052, ite: 168140] train loss: 0.004040, tar: 0.000061 
l0: 0.000024, l1: 0.000026, l2: 0.000077, l3: 0.000316, l4: 0.000876, l5: 0.001556, l6: 0.001901

[epoch: 640/1000, batch:   412/ 1052, ite: 168160] train loss: 0.004040, tar: 0.000061 
l0: 0.000063, l1: 0.000065, l2: 0.000084, l3: 0.000167, l4: 0.000318, l5: 0.000879, l6: 0.002168

[epoch: 640/1000, batch:   492/ 1052, ite: 168180] train loss: 0.004040, tar: 0.000061 
l0: 0.000026, l1: 0.000027, l2: 0.000048, l3: 0.000168, l4: 0.000283, l5: 0.000897, l6: 0.001293

[epoch: 640/1000, batch:   572/ 1052, ite: 168200] train loss: 0.004041, tar: 0.000061 
l0: 0.000013, l1: 0.000013, l2: 0.000036, l3: 0.000085, l4: 0.000291, l5: 0.000889, l6: 0.001927

[epoch: 640/1000, batch:   652/ 1052, ite: 168220] train loss: 0.004040, tar: 0.000061 
l0: 0.000071, l1: 0.000073, l2: 0.000134, l3: 0.000339, l4: 0.000746, l5: 0.002161, l6: 0.003524

[epoch: 640/1000, batch:   732/ 1052, ite: 168240] train loss: 0.004041, tar: 0.000061 
l0: 0.000006, l1: 0.000006, l2: 0.000024, l3: 0.000089, l4: 0.000313, l5: 0.000767, l6: 0.001021

[epoch: 640/1000, batch:   812/ 1052, ite: 168260] train loss: 0.004040, tar: 0.000061 
l0: 0.000003, l1: 0.000003, l2: 0.000011, l3: 0.000081, l4: 0.000181, l5: 0.000867, l6: 0.001211

[epoch: 640/1000, batch:   892/ 1052, ite: 168280] train loss: 0.004040, tar: 0.000061 
l0: 0.000075, l1: 0.000074, l2: 0.000117, l3: 0.000338, l4: 0.000561, l5: 0.000512, l6: 0.001483

[epoch: 640/1000, batch:   972/ 1052, ite: 168300] train loss: 0.004040, tar: 0.000060 
l0: 0.000012, l1: 0.000012, l2: 0.000043, l3: 0.000137, l4: 0.000325, l5: 0.001058, l6: 0.001066

[epoch: 640/1000, batch:  1052/ 1052, ite: 168320] train loss: 0.004040, tar: 0.000060 
[Epoch 640/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000049, l1: 0.000050, l2: 0.000063, l3: 0.000148, l4: 0.000206, l5: 0.000562, l6: 0.001170

[epoch: 641/1000, batch:    80/ 1052, ite: 168340] train loss: 0.004136, tar: 0.000061 
l0: 0.000029, l1: 0.000027, l2: 0.000076, l3: 0.000358, l4: 0.000685, l5: 0.001604, l6: 0.002236

[epoch: 641/1000, batch:   160/ 1052, ite: 168360] train loss: 0.004187, tar: 0.000054 
l0: 0.000040, l1: 0.000037, l2: 0.000102, l3: 0.000292, l4: 0.000579, l5: 0.001372, l6: 0.002345

[epoch: 641/1000, batch:   240/ 1052, ite: 168380] train loss: 0.003982, tar: 0.000050 
l0: 0.000010, l1: 0.000010, l2: 0.000049, l3: 0.000153, l4: 0.000332, l5: 0.000810, l6: 0.001774

[epoch: 641/1000, batch:   320/ 1052, ite: 168400] train loss: 0.004040, tar: 0.000050 
l0: 0.000025, l1: 0.000026, l2: 0.000082, l3: 0.000160, l4: 0.000431, l5: 0.000764, l6: 0.001529

[epoch: 641/1000, batch:   400/ 1052, ite: 168420] train loss: 0.003999, tar: 0.000050 
l0: 0.000118, l1: 0.000118, l2: 0.000181, l3: 0.000273, l4: 0.000604, l5: 0.001349, l6: 0.001962

[epoch: 641/1000, batch:   480/ 1052, ite: 168440] train loss: 0.004002, tar: 0.000052 
l0: 0.000010, l1: 0.000009, l2: 0.000040, l3: 0.000130, l4: 0.000384, l5: 0.000904, l6: 0.001484

[epoch: 641/1000, batch:   560/ 1052, ite: 168460] train loss: 0.003989, tar: 0.000050 
l0: 0.000087, l1: 0.000088, l2: 0.000132, l3: 0.000307, l4: 0.000542, l5: 0.001376, l6: 0.003245

[epoch: 641/1000, batch:   640/ 1052, ite: 168480] train loss: 0.004083, tar: 0.000053 
l0: 0.000041, l1: 0.000043, l2: 0.000071, l3: 0.000144, l4: 0.000353, l5: 0.000767, l6: 0.001514

[epoch: 641/1000, batch:   720/ 1052, ite: 168500] train loss: 0.004092, tar: 0.000053 
l0: 0.000026, l1: 0.000027, l2: 0.000048, l3: 0.000078, l4: 0.000248, l5: 0.000613, l6: 0.000863

[epoch: 641/1000, batch:   800/ 1052, ite: 168520] train loss: 0.004071, tar: 0.000053 
l0: 0.000029, l1: 0.000031, l2: 0.000026, l3: 0.000054, l4: 0.000317, l5: 0.000521, l6: 0.001395

[epoch: 641/1000, batch:   880/ 1052, ite: 168540] train loss: 0.004009, tar: 0.000052 
l0: 0.000022, l1: 0.000023, l2: 0.000056, l3: 0.000133, l4: 0.000419, l5: 0.000719, l6: 0.001483

[epoch: 641/1000, batch:   960/ 1052, ite: 168560] train loss: 0.004001, tar: 0.000052 
l0: 0.000035, l1: 0.000042, l2: 0.000071, l3: 0.000221, l4: 0.000674, l5: 0.001589, l6: 0.003972

[epoch: 641/1000, batch:  1040/ 1052, ite: 168580] train loss: 0.004018, tar: 0.000052 
[Epoch 641/1000] Test loss: 0.016, Test target loss: 0.003
l0: 0.000037, l1: 0.000035, l2: 0.000114, l3: 0.000226, l4: 0.000436, l5: 0.000724, l6: 0.001010

[epoch: 642/1000, batch:    68/ 1052, ite: 168600] train loss: 0.004013, tar: 0.000052 
l0: 0.000023, l1: 0.000023, l2: 0.000069, l3: 0.000122, l4: 0.000289, l5: 0.001103, l6: 0.001037

[epoch: 642/1000, batch:   148/ 1052, ite: 168620] train loss: 0.004011, tar: 0.000053 
l0: 0.000097, l1: 0.000098, l2: 0.000211, l3: 0.000353, l4: 0.000744, l5: 0.001951, l6: 0.003715

[epoch: 642/1000, batch:   228/ 1052, ite: 168640] train loss: 0.004033, tar: 0.000053 
l0: 0.000140, l1: 0.000145, l2: 0.000279, l3: 0.000573, l4: 0.001224, l5: 0.002134, l6: 0.004497

[epoch: 642/1000, batch:   308/ 1052, ite: 168660] train loss: 0.004054, tar: 0.000053 
l0: 0.000032, l1: 0.000032, l2: 0.000055, l3: 0.000141, l4: 0.000349, l5: 0.000753, l6: 0.001395

[epoch: 642/1000, batch:   388/ 1052, ite: 168680] train loss: 0.004040, tar: 0.000053 
l0: 0.000045, l1: 0.000049, l2: 0.000063, l3: 0.000134, l4: 0.000423, l5: 0.000739, l6: 0.001267

[epoch: 642/1000, batch:   468/ 1052, ite: 168700] train loss: 0.004030, tar: 0.000054 
l0: 0.000048, l1: 0.000050, l2: 0.000062, l3: 0.000135, l4: 0.000360, l5: 0.001728, l6: 0.002282

[epoch: 642/1000, batch:   548/ 1052, ite: 168720] train loss: 0.004034, tar: 0.000053 
l0: 0.000064, l1: 0.000067, l2: 0.000113, l3: 0.000154, l4: 0.000446, l5: 0.001083, l6: 0.001948

[epoch: 642/1000, batch:   628/ 1052, ite: 168740] train loss: 0.004046, tar: 0.000053 
l0: 0.000050, l1: 0.000049, l2: 0.000130, l3: 0.000185, l4: 0.000334, l5: 0.000711, l6: 0.001844

[epoch: 642/1000, batch:   708/ 1052, ite: 168760] train loss: 0.004052, tar: 0.000053 
l0: 0.000022, l1: 0.000021, l2: 0.000051, l3: 0.000127, l4: 0.000278, l5: 0.001006, l6: 0.002124

[epoch: 642/1000, batch:   788/ 1052, ite: 168780] train loss: 0.004052, tar: 0.000053 
l0: 0.000125, l1: 0.000128, l2: 0.000193, l3: 0.000470, l4: 0.001222, l5: 0.002040, l6: 0.003447

[epoch: 642/1000, batch:   868/ 1052, ite: 168800] train loss: 0.004058, tar: 0.000053 
l0: 0.000026, l1: 0.000025, l2: 0.000069, l3: 0.000210, l4: 0.000404, l5: 0.000879, l6: 0.001682

[epoch: 642/1000, batch:   948/ 1052, ite: 168820] train loss: 0.004054, tar: 0.000053 
l0: 0.000066, l1: 0.000068, l2: 0.000055, l3: 0.000122, l4: 0.000228, l5: 0.000780, l6: 0.001169

[epoch: 642/1000, batch:  1028/ 1052, ite: 168840] train loss: 0.004056, tar: 0.000053 
[Epoch 642/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000003, l1: 0.000002, l2: 0.000006, l3: 0.000046, l4: 0.000134, l5: 0.000352, l6: 0.000837

[epoch: 643/1000, batch:    56/ 1052, ite: 168860] train loss: 0.004026, tar: 0.000053 
l0: 0.000020, l1: 0.000019, l2: 0.000091, l3: 0.000231, l4: 0.000799, l5: 0.001527, l6: 0.001627

[epoch: 643/1000, batch:   136/ 1052, ite: 168880] train loss: 0.004023, tar: 0.000053 
l0: 0.000047, l1: 0.000046, l2: 0.000089, l3: 0.000193, l4: 0.000416, l5: 0.001132, l6: 0.001201

[epoch: 643/1000, batch:   216/ 1052, ite: 168900] train loss: 0.004016, tar: 0.000053 
l0: 0.000029, l1: 0.000031, l2: 0.000076, l3: 0.000160, l4: 0.000414, l5: 0.000956, l6: 0.001921

[epoch: 643/1000, batch:   296/ 1052, ite: 168920] train loss: 0.004011, tar: 0.000052 
l0: 0.000030, l1: 0.000031, l2: 0.000087, l3: 0.000165, l4: 0.000549, l5: 0.001412, l6: 0.001841

[epoch: 643/1000, batch:   376/ 1052, ite: 168940] train loss: 0.004024, tar: 0.000052 
l0: 0.000024, l1: 0.000024, l2: 0.000087, l3: 0.000179, l4: 0.000374, l5: 0.001046, l6: 0.001400

[epoch: 643/1000, batch:   456/ 1052, ite: 168960] train loss: 0.004010, tar: 0.000052 
l0: 0.000093, l1: 0.000097, l2: 0.000153, l3: 0.000326, l4: 0.000718, l5: 0.001702, l6: 0.002264

[epoch: 643/1000, batch:   536/ 1052, ite: 168980] train loss: 0.004022, tar: 0.000052 
l0: 0.000041, l1: 0.000043, l2: 0.000070, l3: 0.000133, l4: 0.000450, l5: 0.000860, l6: 0.001364

[epoch: 643/1000, batch:   616/ 1052, ite: 169000] train loss: 0.004016, tar: 0.000052 
l0: 0.000025, l1: 0.000025, l2: 0.000090, l3: 0.000190, l4: 0.000517, l5: 0.001219, l6: 0.001624

[epoch: 643/1000, batch:   696/ 1052, ite: 169020] train loss: 0.004020, tar: 0.000052 
l0: 0.000048, l1: 0.000051, l2: 0.000084, l3: 0.000153, l4: 0.000371, l5: 0.001033, l6: 0.002098

[epoch: 643/1000, batch:   776/ 1052, ite: 169040] train loss: 0.004018, tar: 0.000052 
l0: 0.000075, l1: 0.000077, l2: 0.000124, l3: 0.000268, l4: 0.000760, l5: 0.001487, l6: 0.002875

[epoch: 643/1000, batch:   856/ 1052, ite: 169060] train loss: 0.004021, tar: 0.000052 
l0: 0.000067, l1: 0.000067, l2: 0.000197, l3: 0.000312, l4: 0.000779, l5: 0.000965, l6: 0.002169

[epoch: 643/1000, batch:   936/ 1052, ite: 169080] train loss: 0.004034, tar: 0.000052 
l0: 0.000090, l1: 0.000093, l2: 0.000184, l3: 0.000355, l4: 0.000962, l5: 0.002037, l6: 0.002225

[epoch: 643/1000, batch:  1016/ 1052, ite: 169100] train loss: 0.004018, tar: 0.000052 
[Epoch 643/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000067, l1: 0.000069, l2: 0.000129, l3: 0.000177, l4: 0.000667, l5: 0.001133, l6: 0.002522

[epoch: 644/1000, batch:    44/ 1052, ite: 169120] train loss: 0.004016, tar: 0.000052 
l0: 0.000092, l1: 0.000093, l2: 0.000144, l3: 0.000243, l4: 0.000446, l5: 0.001556, l6: 0.002254

[epoch: 644/1000, batch:   124/ 1052, ite: 169140] train loss: 0.004018, tar: 0.000052 
l0: 0.000027, l1: 0.000027, l2: 0.000057, l3: 0.000135, l4: 0.000310, l5: 0.001181, l6: 0.001477

[epoch: 644/1000, batch:   204/ 1052, ite: 169160] train loss: 0.004017, tar: 0.000052 
l0: 0.000014, l1: 0.000014, l2: 0.000050, l3: 0.000175, l4: 0.000314, l5: 0.001001, l6: 0.001368

[epoch: 644/1000, batch:   284/ 1052, ite: 169180] train loss: 0.004020, tar: 0.000052 
l0: 0.000077, l1: 0.000072, l2: 0.000223, l3: 0.000383, l4: 0.000694, l5: 0.001604, l6: 0.003718

[epoch: 644/1000, batch:   364/ 1052, ite: 169200] train loss: 0.004028, tar: 0.000052 
l0: 0.000036, l1: 0.000036, l2: 0.000102, l3: 0.000257, l4: 0.000465, l5: 0.001128, l6: 0.001209

[epoch: 644/1000, batch:   444/ 1052, ite: 169220] train loss: 0.004031, tar: 0.000051 
l0: 0.000031, l1: 0.000031, l2: 0.000087, l3: 0.000139, l4: 0.000254, l5: 0.001058, l6: 0.001627

[epoch: 644/1000, batch:   524/ 1052, ite: 169240] train loss: 0.004039, tar: 0.000052 
l0: 0.000048, l1: 0.000047, l2: 0.000129, l3: 0.000335, l4: 0.000905, l5: 0.001922, l6: 0.003166

[epoch: 644/1000, batch:   604/ 1052, ite: 169260] train loss: 0.004042, tar: 0.000052 
l0: 0.000012, l1: 0.000011, l2: 0.000062, l3: 0.000134, l4: 0.000759, l5: 0.000806, l6: 0.002186

[epoch: 644/1000, batch:   684/ 1052, ite: 169280] train loss: 0.004035, tar: 0.000051 
l0: 0.000010, l1: 0.000011, l2: 0.000037, l3: 0.000123, l4: 0.000346, l5: 0.000806, l6: 0.001094

[epoch: 644/1000, batch:   764/ 1052, ite: 169300] train loss: 0.004032, tar: 0.000052 
l0: 0.000017, l1: 0.000017, l2: 0.000045, l3: 0.000138, l4: 0.000401, l5: 0.000836, l6: 0.001258

[epoch: 644/1000, batch:   844/ 1052, ite: 169320] train loss: 0.004017, tar: 0.000052 
l0: 0.000037, l1: 0.000038, l2: 0.000062, l3: 0.000154, l4: 0.000358, l5: 0.000775, l6: 0.002210

[epoch: 644/1000, batch:   924/ 1052, ite: 169340] train loss: 0.004004, tar: 0.000052 
l0: 0.000078, l1: 0.000083, l2: 0.000193, l3: 0.000340, l4: 0.000416, l5: 0.000922, l6: 0.003722

[epoch: 644/1000, batch:  1004/ 1052, ite: 169360] train loss: 0.004004, tar: 0.000052 
[Epoch 644/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000011, l1: 0.000012, l2: 0.000045, l3: 0.000128, l4: 0.000280, l5: 0.000814, l6: 0.001643

[epoch: 645/1000, batch:    32/ 1052, ite: 169380] train loss: 0.004006, tar: 0.000052 
l0: 0.000105, l1: 0.000107, l2: 0.000130, l3: 0.000208, l4: 0.000371, l5: 0.001112, l6: 0.002226

[epoch: 645/1000, batch:   112/ 1052, ite: 169400] train loss: 0.004015, tar: 0.000052 
l0: 0.000014, l1: 0.000014, l2: 0.000055, l3: 0.000118, l4: 0.000434, l5: 0.001340, l6: 0.002550

[epoch: 645/1000, batch:   192/ 1052, ite: 169420] train loss: 0.004013, tar: 0.000052 
l0: 0.000018, l1: 0.000017, l2: 0.000051, l3: 0.000105, l4: 0.000254, l5: 0.000716, l6: 0.001191

[epoch: 645/1000, batch:   272/ 1052, ite: 169440] train loss: 0.004009, tar: 0.000052 
l0: 0.000011, l1: 0.000012, l2: 0.000024, l3: 0.000056, l4: 0.000243, l5: 0.000450, l6: 0.000600

[epoch: 645/1000, batch:   352/ 1052, ite: 169460] train loss: 0.004007, tar: 0.000052 
l0: 0.000029, l1: 0.000028, l2: 0.000057, l3: 0.000134, l4: 0.000350, l5: 0.000615, l6: 0.001395

[epoch: 645/1000, batch:   432/ 1052, ite: 169480] train loss: 0.004000, tar: 0.000052 
l0: 0.000037, l1: 0.000038, l2: 0.000081, l3: 0.000163, l4: 0.000486, l5: 0.000647, l6: 0.001769

[epoch: 645/1000, batch:   512/ 1052, ite: 169500] train loss: 0.003996, tar: 0.000052 
l0: 0.000106, l1: 0.000114, l2: 0.000173, l3: 0.000354, l4: 0.000799, l5: 0.001304, l6: 0.003144

[epoch: 645/1000, batch:   592/ 1052, ite: 169520] train loss: 0.003999, tar: 0.000052 
l0: 0.000034, l1: 0.000033, l2: 0.000064, l3: 0.000123, l4: 0.000304, l5: 0.000855, l6: 0.001501

[epoch: 645/1000, batch:   672/ 1052, ite: 169540] train loss: 0.003999, tar: 0.000052 
l0: 0.000022, l1: 0.000021, l2: 0.000077, l3: 0.000272, l4: 0.000627, l5: 0.001610, l6: 0.002006

[epoch: 645/1000, batch:   752/ 1052, ite: 169560] train loss: 0.004000, tar: 0.000052 
l0: 0.000016, l1: 0.000016, l2: 0.000064, l3: 0.000281, l4: 0.000706, l5: 0.001062, l6: 0.001914

[epoch: 645/1000, batch:   832/ 1052, ite: 169580] train loss: 0.004005, tar: 0.000052 
l0: 0.000077, l1: 0.000078, l2: 0.000120, l3: 0.000222, l4: 0.000787, l5: 0.002033, l6: 0.002796

[epoch: 645/1000, batch:   912/ 1052, ite: 169600] train loss: 0.004000, tar: 0.000052 
l0: 0.000088, l1: 0.000084, l2: 0.000141, l3: 0.000256, l4: 0.000431, l5: 0.000995, l6: 0.002537

[epoch: 645/1000, batch:   992/ 1052, ite: 169620] train loss: 0.004003, tar: 0.000052 
[Epoch 645/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000039, l1: 0.000038, l2: 0.000081, l3: 0.000117, l4: 0.000401, l5: 0.000915, l6: 0.001085

[epoch: 646/1000, batch:    20/ 1052, ite: 169640] train loss: 0.004007, tar: 0.000052 
l0: 0.000057, l1: 0.000057, l2: 0.000073, l3: 0.000137, l4: 0.000416, l5: 0.000809, l6: 0.001099

[epoch: 646/1000, batch:   100/ 1052, ite: 169660] train loss: 0.004001, tar: 0.000052 
l0: 0.000021, l1: 0.000022, l2: 0.000024, l3: 0.000072, l4: 0.000401, l5: 0.000493, l6: 0.001183

[epoch: 646/1000, batch:   180/ 1052, ite: 169680] train loss: 0.003994, tar: 0.000052 
l0: 0.000027, l1: 0.000029, l2: 0.000039, l3: 0.000128, l4: 0.000258, l5: 0.000767, l6: 0.001431

[epoch: 646/1000, batch:   260/ 1052, ite: 169700] train loss: 0.003997, tar: 0.000052 
l0: 0.000047, l1: 0.000046, l2: 0.000114, l3: 0.000171, l4: 0.000458, l5: 0.001179, l6: 0.001728

[epoch: 646/1000, batch:   340/ 1052, ite: 169720] train loss: 0.003991, tar: 0.000052 
l0: 0.000062, l1: 0.000060, l2: 0.000113, l3: 0.000265, l4: 0.000500, l5: 0.001197, l6: 0.002686

[epoch: 646/1000, batch:   420/ 1052, ite: 169740] train loss: 0.003990, tar: 0.000052 
l0: 0.000065, l1: 0.000066, l2: 0.000094, l3: 0.000145, l4: 0.000439, l5: 0.001032, l6: 0.003095

[epoch: 646/1000, batch:   500/ 1052, ite: 169760] train loss: 0.003999, tar: 0.000052 
l0: 0.000029, l1: 0.000029, l2: 0.000104, l3: 0.000233, l4: 0.000415, l5: 0.000765, l6: 0.002104

[epoch: 646/1000, batch:   580/ 1052, ite: 169780] train loss: 0.003997, tar: 0.000052 
l0: 0.000073, l1: 0.000076, l2: 0.000113, l3: 0.000185, l4: 0.000447, l5: 0.001276, l6: 0.003352

[epoch: 646/1000, batch:   660/ 1052, ite: 169800] train loss: 0.003995, tar: 0.000052 
l0: 0.000019, l1: 0.000017, l2: 0.000067, l3: 0.000190, l4: 0.000386, l5: 0.001161, l6: 0.002217

[epoch: 646/1000, batch:   740/ 1052, ite: 169820] train loss: 0.003992, tar: 0.000052 
l0: 0.000042, l1: 0.000041, l2: 0.000080, l3: 0.000168, l4: 0.000422, l5: 0.001118, l6: 0.001827

[epoch: 646/1000, batch:   820/ 1052, ite: 169840] train loss: 0.003992, tar: 0.000052 
l0: 0.000025, l1: 0.000025, l2: 0.000058, l3: 0.000107, l4: 0.000271, l5: 0.000573, l6: 0.001184

[epoch: 646/1000, batch:   900/ 1052, ite: 169860] train loss: 0.003994, tar: 0.000052 
l0: 0.000175, l1: 0.000170, l2: 0.000226, l3: 0.000335, l4: 0.000657, l5: 0.001318, l6: 0.002304

[epoch: 646/1000, batch:   980/ 1052, ite: 169880] train loss: 0.003999, tar: 0.000052 
[Epoch 646/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000018, l1: 0.000017, l2: 0.000051, l3: 0.000123, l4: 0.000423, l5: 0.000741, l6: 0.001630

[epoch: 647/1000, batch:     8/ 1052, ite: 169900] train loss: 0.003996, tar: 0.000052 
l0: 0.000056, l1: 0.000057, l2: 0.000085, l3: 0.000223, l4: 0.000747, l5: 0.002039, l6: 0.002931

[epoch: 647/1000, batch:    88/ 1052, ite: 169920] train loss: 0.004002, tar: 0.000052 
l0: 0.000012, l1: 0.000012, l2: 0.000029, l3: 0.000122, l4: 0.000280, l5: 0.000652, l6: 0.001519

[epoch: 647/1000, batch:   168/ 1052, ite: 169940] train loss: 0.004001, tar: 0.000051 
l0: 0.000037, l1: 0.000037, l2: 0.000067, l3: 0.000136, l4: 0.000423, l5: 0.000744, l6: 0.001443

[epoch: 647/1000, batch:   248/ 1052, ite: 169960] train loss: 0.003999, tar: 0.000051 
l0: 0.000025, l1: 0.000025, l2: 0.000072, l3: 0.000087, l4: 0.000260, l5: 0.000878, l6: 0.001587

[epoch: 647/1000, batch:   328/ 1052, ite: 169980] train loss: 0.003996, tar: 0.000051 
l0: 0.000023, l1: 0.000022, l2: 0.000074, l3: 0.000170, l4: 0.000424, l5: 0.000846, l6: 0.001410

[epoch: 647/1000, batch:   408/ 1052, ite: 170000] train loss: 0.003994, tar: 0.000051 
l0: 0.000051, l1: 0.000050, l2: 0.000083, l3: 0.000194, l4: 0.000452, l5: 0.001080, l6: 0.001432

[epoch: 647/1000, batch:   488/ 1052, ite: 170020] train loss: 0.003990, tar: 0.000051 
l0: 0.000038, l1: 0.000037, l2: 0.000087, l3: 0.000157, l4: 0.000472, l5: 0.001461, l6: 0.002121

[epoch: 647/1000, batch:   568/ 1052, ite: 170040] train loss: 0.003993, tar: 0.000051 
l0: 0.000042, l1: 0.000043, l2: 0.000058, l3: 0.000107, l4: 0.000269, l5: 0.000677, l6: 0.000866

[epoch: 647/1000, batch:   648/ 1052, ite: 170060] train loss: 0.003986, tar: 0.000051 
l0: 0.000038, l1: 0.000040, l2: 0.000086, l3: 0.000364, l4: 0.000760, l5: 0.001274, l6: 0.001717

[epoch: 647/1000, batch:   728/ 1052, ite: 170080] train loss: 0.003989, tar: 0.000051 
l0: 0.000054, l1: 0.000055, l2: 0.000121, l3: 0.000346, l4: 0.000666, l5: 0.001292, l6: 0.002415

[epoch: 647/1000, batch:   808/ 1052, ite: 170100] train loss: 0.003990, tar: 0.000051 
l0: 0.000008, l1: 0.000007, l2: 0.000047, l3: 0.000254, l4: 0.000404, l5: 0.000861, l6: 0.001375

[epoch: 647/1000, batch:   888/ 1052, ite: 170120] train loss: 0.003992, tar: 0.000051 
l0: 0.000066, l1: 0.000064, l2: 0.000107, l3: 0.000228, l4: 0.000525, l5: 0.001325, l6: 0.001687

[epoch: 647/1000, batch:   968/ 1052, ite: 170140] train loss: 0.003998, tar: 0.000051 
l0: 0.000056, l1: 0.000058, l2: 0.000113, l3: 0.000178, l4: 0.000422, l5: 0.001579, l6: 0.002701

[epoch: 647/1000, batch:  1048/ 1052, ite: 170160] train loss: 0.003998, tar: 0.000051 
[Epoch 647/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000391, l1: 0.000374, l2: 0.000467, l3: 0.000613, l4: 0.000765, l5: 0.001007, l6: 0.001932

[epoch: 648/1000, batch:    76/ 1052, ite: 170180] train loss: 0.003997, tar: 0.000051 
l0: 0.000031, l1: 0.000031, l2: 0.000063, l3: 0.000132, l4: 0.000300, l5: 0.000934, l6: 0.001886

[epoch: 648/1000, batch:   156/ 1052, ite: 170200] train loss: 0.003999, tar: 0.000051 
l0: 0.000019, l1: 0.000020, l2: 0.000036, l3: 0.000143, l4: 0.000455, l5: 0.000790, l6: 0.002288

[epoch: 648/1000, batch:   236/ 1052, ite: 170220] train loss: 0.003997, tar: 0.000051 
l0: 0.000035, l1: 0.000036, l2: 0.000093, l3: 0.000195, l4: 0.000338, l5: 0.000794, l6: 0.001862

[epoch: 648/1000, batch:   316/ 1052, ite: 170240] train loss: 0.003998, tar: 0.000051 
l0: 0.000027, l1: 0.000026, l2: 0.000068, l3: 0.000149, l4: 0.000278, l5: 0.000575, l6: 0.001299

[epoch: 648/1000, batch:   396/ 1052, ite: 170260] train loss: 0.003995, tar: 0.000051 
l0: 0.000163, l1: 0.000160, l2: 0.000173, l3: 0.000254, l4: 0.000354, l5: 0.000729, l6: 0.001127

[epoch: 648/1000, batch:   476/ 1052, ite: 170280] train loss: 0.003996, tar: 0.000051 
l0: 0.000016, l1: 0.000016, l2: 0.000048, l3: 0.000140, l4: 0.000540, l5: 0.001340, l6: 0.001721

[epoch: 648/1000, batch:   556/ 1052, ite: 170300] train loss: 0.004001, tar: 0.000051 
l0: 0.000030, l1: 0.000028, l2: 0.000078, l3: 0.000182, l4: 0.000475, l5: 0.001085, l6: 0.001683

[epoch: 648/1000, batch:   636/ 1052, ite: 170320] train loss: 0.004000, tar: 0.000051 
l0: 0.000064, l1: 0.000062, l2: 0.000085, l3: 0.000193, l4: 0.000517, l5: 0.000859, l6: 0.002087

[epoch: 648/1000, batch:   716/ 1052, ite: 170340] train loss: 0.003997, tar: 0.000051 
l0: 0.000159, l1: 0.000154, l2: 0.000255, l3: 0.000432, l4: 0.000658, l5: 0.000980, l6: 0.002006

[epoch: 648/1000, batch:   796/ 1052, ite: 170360] train loss: 0.003991, tar: 0.000051 
l0: 0.000018, l1: 0.000018, l2: 0.000030, l3: 0.000091, l4: 0.000221, l5: 0.000213, l6: 0.000705

[epoch: 648/1000, batch:   876/ 1052, ite: 170380] train loss: 0.003992, tar: 0.000051 
l0: 0.000028, l1: 0.000029, l2: 0.000043, l3: 0.000105, l4: 0.000284, l5: 0.001318, l6: 0.002622

[epoch: 648/1000, batch:   956/ 1052, ite: 170400] train loss: 0.003993, tar: 0.000051 
l0: 0.000046, l1: 0.000048, l2: 0.000101, l3: 0.000243, l4: 0.000464, l5: 0.001285, l6: 0.001786

[epoch: 648/1000, batch:  1036/ 1052, ite: 170420] train loss: 0.003994, tar: 0.000051 
[Epoch 648/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000019, l1: 0.000018, l2: 0.000038, l3: 0.000133, l4: 0.000352, l5: 0.000815, l6: 0.001507

[epoch: 649/1000, batch:    64/ 1052, ite: 170440] train loss: 0.003993, tar: 0.000051 
l0: 0.000021, l1: 0.000024, l2: 0.000047, l3: 0.000143, l4: 0.000429, l5: 0.001048, l6: 0.001896

[epoch: 649/1000, batch:   144/ 1052, ite: 170460] train loss: 0.003993, tar: 0.000051 
l0: 0.000052, l1: 0.000055, l2: 0.000100, l3: 0.000328, l4: 0.000507, l5: 0.001113, l6: 0.001769

[epoch: 649/1000, batch:   224/ 1052, ite: 170480] train loss: 0.003996, tar: 0.000051 
l0: 0.000012, l1: 0.000012, l2: 0.000045, l3: 0.000091, l4: 0.000412, l5: 0.000602, l6: 0.001062

[epoch: 649/1000, batch:   304/ 1052, ite: 170500] train loss: 0.003994, tar: 0.000051 
l0: 0.000059, l1: 0.000061, l2: 0.000111, l3: 0.000294, l4: 0.000894, l5: 0.002158, l6: 0.002718

[epoch: 649/1000, batch:   384/ 1052, ite: 170520] train loss: 0.003992, tar: 0.000051 
l0: 0.000021, l1: 0.000020, l2: 0.000074, l3: 0.000120, l4: 0.000275, l5: 0.000813, l6: 0.001327

[epoch: 649/1000, batch:   464/ 1052, ite: 170540] train loss: 0.003992, tar: 0.000051 
l0: 0.000026, l1: 0.000027, l2: 0.000058, l3: 0.000173, l4: 0.000416, l5: 0.000739, l6: 0.001810

[epoch: 649/1000, batch:   544/ 1052, ite: 170560] train loss: 0.003988, tar: 0.000051 
l0: 0.000059, l1: 0.000061, l2: 0.000125, l3: 0.000278, l4: 0.000474, l5: 0.001396, l6: 0.002483

[epoch: 649/1000, batch:   624/ 1052, ite: 170580] train loss: 0.003989, tar: 0.000051 
l0: 0.000066, l1: 0.000068, l2: 0.000087, l3: 0.000130, l4: 0.000652, l5: 0.001175, l6: 0.001682

[epoch: 649/1000, batch:   704/ 1052, ite: 170600] train loss: 0.003986, tar: 0.000051 
l0: 0.000113, l1: 0.000112, l2: 0.000175, l3: 0.000398, l4: 0.001030, l5: 0.001643, l6: 0.002750

[epoch: 649/1000, batch:   784/ 1052, ite: 170620] train loss: 0.003991, tar: 0.000051 
l0: 0.000027, l1: 0.000029, l2: 0.000036, l3: 0.000083, l4: 0.000344, l5: 0.000727, l6: 0.001358

[epoch: 649/1000, batch:   864/ 1052, ite: 170640] train loss: 0.003993, tar: 0.000051 
l0: 0.000014, l1: 0.000014, l2: 0.000040, l3: 0.000129, l4: 0.000312, l5: 0.001155, l6: 0.002102

[epoch: 649/1000, batch:   944/ 1052, ite: 170660] train loss: 0.003993, tar: 0.000051 
l0: 0.000054, l1: 0.000054, l2: 0.000159, l3: 0.000473, l4: 0.000891, l5: 0.001778, l6: 0.004145

[epoch: 649/1000, batch:  1024/ 1052, ite: 170680] train loss: 0.003997, tar: 0.000051 
[Epoch 649/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000024, l1: 0.000025, l2: 0.000073, l3: 0.000174, l4: 0.000266, l5: 0.000849, l6: 0.001971

[epoch: 650/1000, batch:    52/ 1052, ite: 170700] train loss: 0.003995, tar: 0.000051 
l0: 0.000101, l1: 0.000104, l2: 0.000166, l3: 0.000344, l4: 0.000663, l5: 0.001274, l6: 0.002185

[epoch: 650/1000, batch:   132/ 1052, ite: 170720] train loss: 0.003999, tar: 0.000051 
l0: 0.000040, l1: 0.000040, l2: 0.000135, l3: 0.000340, l4: 0.000590, l5: 0.001039, l6: 0.001774

[epoch: 650/1000, batch:   212/ 1052, ite: 170740] train loss: 0.003998, tar: 0.000051 
l0: 0.000096, l1: 0.000099, l2: 0.000104, l3: 0.000132, l4: 0.000252, l5: 0.000734, l6: 0.000901

[epoch: 650/1000, batch:   292/ 1052, ite: 170760] train loss: 0.004004, tar: 0.000051 
l0: 0.000026, l1: 0.000026, l2: 0.000081, l3: 0.000174, l4: 0.000361, l5: 0.001942, l6: 0.003196

[epoch: 650/1000, batch:   372/ 1052, ite: 170780] train loss: 0.004001, tar: 0.000051 
l0: 0.000078, l1: 0.000078, l2: 0.000125, l3: 0.000254, l4: 0.000467, l5: 0.001332, l6: 0.002000

[epoch: 650/1000, batch:   452/ 1052, ite: 170800] train loss: 0.004002, tar: 0.000051 
l0: 0.000033, l1: 0.000031, l2: 0.000082, l3: 0.000145, l4: 0.000231, l5: 0.001137, l6: 0.001455

[epoch: 650/1000, batch:   532/ 1052, ite: 170820] train loss: 0.004000, tar: 0.000051 
l0: 0.000067, l1: 0.000066, l2: 0.000143, l3: 0.000261, l4: 0.000463, l5: 0.001396, l6: 0.002320

[epoch: 650/1000, batch:   612/ 1052, ite: 170840] train loss: 0.004000, tar: 0.000051 
l0: 0.000071, l1: 0.000074, l2: 0.000149, l3: 0.000278, l4: 0.000603, l5: 0.001151, l6: 0.001913

[epoch: 650/1000, batch:   692/ 1052, ite: 170860] train loss: 0.004000, tar: 0.000051 
l0: 0.000055, l1: 0.000055, l2: 0.000089, l3: 0.000227, l4: 0.000526, l5: 0.001506, l6: 0.002841

[epoch: 650/1000, batch:   772/ 1052, ite: 170880] train loss: 0.003999, tar: 0.000051 
l0: 0.000033, l1: 0.000032, l2: 0.000055, l3: 0.000222, l4: 0.000661, l5: 0.002309, l6: 0.002966

[epoch: 650/1000, batch:   852/ 1052, ite: 170900] train loss: 0.004000, tar: 0.000051 
l0: 0.000070, l1: 0.000070, l2: 0.000149, l3: 0.000294, l4: 0.000376, l5: 0.000692, l6: 0.001686

[epoch: 650/1000, batch:   932/ 1052, ite: 170920] train loss: 0.004001, tar: 0.000051 
l0: 0.000078, l1: 0.000078, l2: 0.000238, l3: 0.000526, l4: 0.001323, l5: 0.002038, l6: 0.002901

[epoch: 650/1000, batch:  1012/ 1052, ite: 170940] train loss: 0.004002, tar: 0.000051 
[Epoch 650/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000076, l1: 0.000072, l2: 0.000127, l3: 0.000215, l4: 0.000388, l5: 0.000906, l6: 0.002036

[epoch: 651/1000, batch:    40/ 1052, ite: 170960] train loss: 0.003994, tar: 0.000051 
l0: 0.000040, l1: 0.000044, l2: 0.000072, l3: 0.000222, l4: 0.000627, l5: 0.001263, l6: 0.001830

[epoch: 651/1000, batch:   120/ 1052, ite: 170980] train loss: 0.003993, tar: 0.000051 
l0: 0.000042, l1: 0.000044, l2: 0.000086, l3: 0.000150, l4: 0.000332, l5: 0.000616, l6: 0.001199

[epoch: 651/1000, batch:   200/ 1052, ite: 171000] train loss: 0.003991, tar: 0.000051 
l0: 0.000047, l1: 0.000047, l2: 0.000094, l3: 0.000163, l4: 0.000316, l5: 0.001153, l6: 0.002162

[epoch: 651/1000, batch:   280/ 1052, ite: 171020] train loss: 0.003994, tar: 0.000051 
l0: 0.000167, l1: 0.000171, l2: 0.000238, l3: 0.000364, l4: 0.000459, l5: 0.001349, l6: 0.003136

[epoch: 651/1000, batch:   360/ 1052, ite: 171040] train loss: 0.003994, tar: 0.000051 
l0: 0.000022, l1: 0.000022, l2: 0.000056, l3: 0.000153, l4: 0.000317, l5: 0.000835, l6: 0.001789

[epoch: 651/1000, batch:   440/ 1052, ite: 171060] train loss: 0.003995, tar: 0.000051 
l0: 0.000041, l1: 0.000039, l2: 0.000076, l3: 0.000140, l4: 0.000548, l5: 0.001183, l6: 0.001480

[epoch: 651/1000, batch:   520/ 1052, ite: 171080] train loss: 0.003999, tar: 0.000051 
l0: 0.000010, l1: 0.000011, l2: 0.000045, l3: 0.000152, l4: 0.000311, l5: 0.000719, l6: 0.002205

[epoch: 651/1000, batch:   600/ 1052, ite: 171100] train loss: 0.004000, tar: 0.000051 
l0: 0.000050, l1: 0.000050, l2: 0.000082, l3: 0.000130, l4: 0.000302, l5: 0.001091, l6: 0.001663

[epoch: 651/1000, batch:   680/ 1052, ite: 171120] train loss: 0.004000, tar: 0.000051 
l0: 0.000035, l1: 0.000035, l2: 0.000094, l3: 0.000172, l4: 0.000367, l5: 0.001073, l6: 0.001941

[epoch: 651/1000, batch:   760/ 1052, ite: 171140] train loss: 0.004000, tar: 0.000051 
l0: 0.000044, l1: 0.000042, l2: 0.000088, l3: 0.000222, l4: 0.000480, l5: 0.001332, l6: 0.002247

[epoch: 651/1000, batch:   840/ 1052, ite: 171160] train loss: 0.003998, tar: 0.000051 
l0: 0.000019, l1: 0.000019, l2: 0.000027, l3: 0.000112, l4: 0.000300, l5: 0.000920, l6: 0.001461

[epoch: 651/1000, batch:   920/ 1052, ite: 171180] train loss: 0.004000, tar: 0.000051 
l0: 0.000035, l1: 0.000036, l2: 0.000091, l3: 0.000295, l4: 0.000556, l5: 0.001242, l6: 0.002116

[epoch: 651/1000, batch:  1000/ 1052, ite: 171200] train loss: 0.004000, tar: 0.000051 
[Epoch 651/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000063, l1: 0.000064, l2: 0.000095, l3: 0.000193, l4: 0.000584, l5: 0.001005, l6: 0.002242

[epoch: 652/1000, batch:    28/ 1052, ite: 171220] train loss: 0.003998, tar: 0.000051 
l0: 0.000092, l1: 0.000090, l2: 0.000166, l3: 0.000400, l4: 0.000625, l5: 0.001974, l6: 0.002726

[epoch: 652/1000, batch:   108/ 1052, ite: 171240] train loss: 0.004000, tar: 0.000051 
l0: 0.000023, l1: 0.000025, l2: 0.000061, l3: 0.000204, l4: 0.000391, l5: 0.000913, l6: 0.001297

[epoch: 652/1000, batch:   188/ 1052, ite: 171260] train loss: 0.003996, tar: 0.000051 
l0: 0.000040, l1: 0.000041, l2: 0.000049, l3: 0.000136, l4: 0.000362, l5: 0.000767, l6: 0.001583

[epoch: 652/1000, batch:   268/ 1052, ite: 171280] train loss: 0.003998, tar: 0.000051 
l0: 0.000264, l1: 0.000235, l2: 0.000201, l3: 0.000382, l4: 0.000688, l5: 0.001079, l6: 0.002645

[epoch: 652/1000, batch:   348/ 1052, ite: 171300] train loss: 0.003997, tar: 0.000051 
l0: 0.000011, l1: 0.000014, l2: 0.000040, l3: 0.000142, l4: 0.000330, l5: 0.000435, l6: 0.001218

[epoch: 652/1000, batch:   428/ 1052, ite: 171320] train loss: 0.003997, tar: 0.000051 
l0: 0.000021, l1: 0.000021, l2: 0.000097, l3: 0.000283, l4: 0.000645, l5: 0.001490, l6: 0.001855

[epoch: 652/1000, batch:   508/ 1052, ite: 171340] train loss: 0.003998, tar: 0.000051 
l0: 0.000083, l1: 0.000087, l2: 0.000121, l3: 0.000213, l4: 0.000526, l5: 0.001175, l6: 0.001461

[epoch: 652/1000, batch:   588/ 1052, ite: 171360] train loss: 0.003997, tar: 0.000051 
l0: 0.000076, l1: 0.000080, l2: 0.000103, l3: 0.000152, l4: 0.000433, l5: 0.000925, l6: 0.002295

[epoch: 652/1000, batch:   668/ 1052, ite: 171380] train loss: 0.003996, tar: 0.000051 
l0: 0.000010, l1: 0.000010, l2: 0.000041, l3: 0.000084, l4: 0.000233, l5: 0.000797, l6: 0.001215

[epoch: 652/1000, batch:   748/ 1052, ite: 171400] train loss: 0.003998, tar: 0.000051 
l0: 0.000034, l1: 0.000033, l2: 0.000035, l3: 0.000155, l4: 0.000260, l5: 0.000822, l6: 0.001837

[epoch: 652/1000, batch:   828/ 1052, ite: 171420] train loss: 0.003996, tar: 0.000051 
l0: 0.000016, l1: 0.000016, l2: 0.000063, l3: 0.000158, l4: 0.000246, l5: 0.000408, l6: 0.001217

[epoch: 652/1000, batch:   908/ 1052, ite: 171440] train loss: 0.003993, tar: 0.000051 
l0: 0.000063, l1: 0.000063, l2: 0.000139, l3: 0.000240, l4: 0.000578, l5: 0.001106, l6: 0.002188

[epoch: 652/1000, batch:   988/ 1052, ite: 171460] train loss: 0.003996, tar: 0.000051 
[Epoch 652/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000058, l1: 0.000063, l2: 0.000138, l3: 0.000361, l4: 0.000447, l5: 0.001209, l6: 0.001619

[epoch: 653/1000, batch:    16/ 1052, ite: 171480] train loss: 0.003994, tar: 0.000051 
l0: 0.000069, l1: 0.000067, l2: 0.000181, l3: 0.000392, l4: 0.000721, l5: 0.001255, l6: 0.003062

[epoch: 653/1000, batch:    96/ 1052, ite: 171500] train loss: 0.003994, tar: 0.000050 
l0: 0.000019, l1: 0.000017, l2: 0.000059, l3: 0.000222, l4: 0.000316, l5: 0.000859, l6: 0.001301

[epoch: 653/1000, batch:   176/ 1052, ite: 171520] train loss: 0.003993, tar: 0.000050 
l0: 0.000044, l1: 0.000044, l2: 0.000113, l3: 0.000201, l4: 0.000445, l5: 0.001534, l6: 0.003053

[epoch: 653/1000, batch:   256/ 1052, ite: 171540] train loss: 0.003993, tar: 0.000050 
l0: 0.000065, l1: 0.000066, l2: 0.000209, l3: 0.000410, l4: 0.000968, l5: 0.002212, l6: 0.002607

[epoch: 653/1000, batch:   336/ 1052, ite: 171560] train loss: 0.003996, tar: 0.000050 
l0: 0.000069, l1: 0.000067, l2: 0.000120, l3: 0.000322, l4: 0.000701, l5: 0.001283, l6: 0.002115

[epoch: 653/1000, batch:   416/ 1052, ite: 171580] train loss: 0.003996, tar: 0.000050 
l0: 0.000019, l1: 0.000021, l2: 0.000070, l3: 0.000180, l4: 0.000379, l5: 0.000921, l6: 0.001389

[epoch: 653/1000, batch:   496/ 1052, ite: 171600] train loss: 0.003997, tar: 0.000050 
l0: 0.000012, l1: 0.000012, l2: 0.000027, l3: 0.000116, l4: 0.000562, l5: 0.000781, l6: 0.001878

[epoch: 653/1000, batch:   576/ 1052, ite: 171620] train loss: 0.003997, tar: 0.000050 
l0: 0.000099, l1: 0.000102, l2: 0.000109, l3: 0.000243, l4: 0.000733, l5: 0.001474, l6: 0.002399

[epoch: 653/1000, batch:   656/ 1052, ite: 171640] train loss: 0.003997, tar: 0.000050 
l0: 0.000088, l1: 0.000094, l2: 0.000213, l3: 0.000384, l4: 0.000760, l5: 0.001790, l6: 0.003299

[epoch: 653/1000, batch:   736/ 1052, ite: 171660] train loss: 0.003999, tar: 0.000050 
l0: 0.000058, l1: 0.000059, l2: 0.000082, l3: 0.000207, l4: 0.000525, l5: 0.001024, l6: 0.002105

[epoch: 653/1000, batch:   816/ 1052, ite: 171680] train loss: 0.004002, tar: 0.000050 
l0: 0.000207, l1: 0.000208, l2: 0.000277, l3: 0.000412, l4: 0.000531, l5: 0.001225, l6: 0.002707

[epoch: 653/1000, batch:   896/ 1052, ite: 171700] train loss: 0.003997, tar: 0.000050 
l0: 0.000034, l1: 0.000033, l2: 0.000075, l3: 0.000254, l4: 0.000668, l5: 0.001432, l6: 0.002219

[epoch: 653/1000, batch:   976/ 1052, ite: 171720] train loss: 0.003999, tar: 0.000050 
[Epoch 653/1000] Test loss: 0.017, Test target loss: 0.003
l0: 0.000090, l1: 0.000091, l2: 0.000179, l3: 0.000283, l4: 0.000422, l5: 0.001034, l6: 0.001655

[epoch: 654/1000, batch:     4/ 1052, ite: 171740] train loss: 0.003996, tar: 0.000050 
l0: 0.000043, l1: 0.000043, l2: 0.000061, l3: 0.000154, l4: 0.000360, l5: 0.000903, l6: 0.001215

[epoch: 654/1000, batch:    84/ 1052, ite: 171760] train loss: 0.003994, tar: 0.000050 
l0: 0.000040, l1: 0.000040, l2: 0.000100, l3: 0.000265, l4: 0.000547, l5: 0.001491, l6: 0.001644

[epoch: 654/1000, batch:   164/ 1052, ite: 171780] train loss: 0.003997, tar: 0.000050 
l0: 0.000024, l1: 0.000025, l2: 0.000045, l3: 0.000085, l4: 0.000254, l5: 0.000651, l6: 0.000970

[epoch: 654/1000, batch:   244/ 1052, ite: 171800] train loss: 0.003998, tar: 0.000050 
l0: 0.000053, l1: 0.000054, l2: 0.000096, l3: 0.000293, l4: 0.000588, l5: 0.001318, l6: 0.001875

[epoch: 654/1000, batch:   324/ 1052, ite: 171820] train loss: 0.003994, tar: 0.000050 
l0: 0.000052, l1: 0.000051, l2: 0.000096, l3: 0.000121, l4: 0.000287, l5: 0.000668, l6: 0.001022

[epoch: 654/1000, batch:   404/ 1052, ite: 171840] train loss: 0.003993, tar: 0.000050 
l0: 0.000043, l1: 0.000044, l2: 0.000097, l3: 0.000252, l4: 0.000688, l5: 0.001319, l6: 0.002051

[epoch: 654/1000, batch:   484/ 1052, ite: 171860] train loss: 0.003994, tar: 0.000050 
l0: 0.000040, l1: 0.000037, l2: 0.000151, l3: 0.000406, l4: 0.000764, l5: 0.001981, l6: 0.002300

[epoch: 654/1000, batch:   564/ 1052, ite: 171880] train loss: 0.003995, tar: 0.000050 
l0: 0.000111, l1: 0.000110, l2: 0.000173, l3: 0.000278, l4: 0.000575, l5: 0.002311, l6: 0.003741

[epoch: 654/1000, batch:   644/ 1052, ite: 171900] train loss: 0.003996, tar: 0.000051 
l0: 0.000078, l1: 0.000081, l2: 0.000109, l3: 0.000341, l4: 0.000728, l5: 0.001776, l6: 0.002144

[epoch: 654/1000, batch:   724/ 1052, ite: 171920] train loss: 0.003997, tar: 0.000051 
l0: 0.000013, l1: 0.000014, l2: 0.000027, l3: 0.000066, l4: 0.000284, l5: 0.000728, l6: 0.001507

[epoch: 654/1000, batch:   804/ 1052, ite: 171940] train loss: 0.003997, tar: 0.000051 
l0: 0.000046, l1: 0.000049, l2: 0.000068, l3: 0.000115, l4: 0.000315, l5: 0.000931, l6: 0.001894

[epoch: 654/1000, batch:   884/ 1052, ite: 171960] train loss: 0.003998, tar: 0.000051 
l0: 0.000053, l1: 0.000052, l2: 0.000135, l3: 0.000408, l4: 0.000869, l5: 0.001521, l6: 0.003296

[epoch: 654/1000, batch:   964/ 1052, ite: 171980] train loss: 0.003999, tar: 0.000051 
l0: 0.000020, l1: 0.000020, l2: 0.000058, l3: 0.000206, l4: 0.000499, l5: 0.000744, l6: 0.001269

[epoch: 654/1000, batch:  1044/ 1052, ite: 172000] train loss: 0.003998, tar: 0.000051 
[Epoch 654/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000178, l1: 0.000182, l2: 0.000231, l3: 0.000429, l4: 0.001091, l5: 0.002407, l6: 0.004861

[epoch: 655/1000, batch:    72/ 1052, ite: 172020] train loss: 0.003999, tar: 0.000051 
l0: 0.000039, l1: 0.000040, l2: 0.000120, l3: 0.000234, l4: 0.000393, l5: 0.000796, l6: 0.001543

[epoch: 655/1000, batch:   152/ 1052, ite: 172040] train loss: 0.003999, tar: 0.000050 
l0: 0.000005, l1: 0.000004, l2: 0.000035, l3: 0.000098, l4: 0.000474, l5: 0.000999, l6: 0.001430

[epoch: 655/1000, batch:   232/ 1052, ite: 172060] train loss: 0.003999, tar: 0.000050 
l0: 0.000011, l1: 0.000013, l2: 0.000061, l3: 0.000204, l4: 0.000526, l5: 0.001259, l6: 0.002413

[epoch: 655/1000, batch:   312/ 1052, ite: 172080] train loss: 0.003999, tar: 0.000050 
l0: 0.000005, l1: 0.000005, l2: 0.000018, l3: 0.000038, l4: 0.000301, l5: 0.000680, l6: 0.001203

[epoch: 655/1000, batch:   392/ 1052, ite: 172100] train loss: 0.003999, tar: 0.000050 
l0: 0.000069, l1: 0.000072, l2: 0.000114, l3: 0.000277, l4: 0.000752, l5: 0.001511, l6: 0.002556

[epoch: 655/1000, batch:   472/ 1052, ite: 172120] train loss: 0.004001, tar: 0.000050 
l0: 0.000022, l1: 0.000023, l2: 0.000061, l3: 0.000153, l4: 0.000445, l5: 0.000761, l6: 0.001579

[epoch: 655/1000, batch:   552/ 1052, ite: 172140] train loss: 0.004000, tar: 0.000050 
l0: 0.000006, l1: 0.000006, l2: 0.000016, l3: 0.000057, l4: 0.000090, l5: 0.000301, l6: 0.000513

[epoch: 655/1000, batch:   632/ 1052, ite: 172160] train loss: 0.003999, tar: 0.000050 
l0: 0.000102, l1: 0.000101, l2: 0.000261, l3: 0.000458, l4: 0.000671, l5: 0.001453, l6: 0.003239

[epoch: 655/1000, batch:   712/ 1052, ite: 172180] train loss: 0.003996, tar: 0.000050 
l0: 0.000061, l1: 0.000062, l2: 0.000047, l3: 0.000099, l4: 0.000325, l5: 0.000547, l6: 0.001079

[epoch: 655/1000, batch:   792/ 1052, ite: 172200] train loss: 0.003996, tar: 0.000050 
l0: 0.000067, l1: 0.000065, l2: 0.000100, l3: 0.000224, l4: 0.000636, l5: 0.001195, l6: 0.002369

[epoch: 655/1000, batch:   872/ 1052, ite: 172220] train loss: 0.003995, tar: 0.000050 
l0: 0.000044, l1: 0.000046, l2: 0.000095, l3: 0.000161, l4: 0.000493, l5: 0.001163, l6: 0.001911

[epoch: 655/1000, batch:   952/ 1052, ite: 172240] train loss: 0.003996, tar: 0.000050 
l0: 0.000022, l1: 0.000021, l2: 0.000056, l3: 0.000125, l4: 0.000334, l5: 0.000776, l6: 0.001343

[epoch: 655/1000, batch:  1032/ 1052, ite: 172260] train loss: 0.003996, tar: 0.000050 
[Epoch 655/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000068, l1: 0.000067, l2: 0.000125, l3: 0.000315, l4: 0.000761, l5: 0.001373, l6: 0.002142

[epoch: 656/1000, batch:    60/ 1052, ite: 172280] train loss: 0.003994, tar: 0.000050 
l0: 0.000136, l1: 0.000133, l2: 0.000172, l3: 0.000272, l4: 0.000823, l5: 0.001191, l6: 0.003450

[epoch: 656/1000, batch:   140/ 1052, ite: 172300] train loss: 0.003993, tar: 0.000050 
l0: 0.000037, l1: 0.000035, l2: 0.000085, l3: 0.000131, l4: 0.000306, l5: 0.000708, l6: 0.001453

[epoch: 656/1000, batch:   220/ 1052, ite: 172320] train loss: 0.003990, tar: 0.000050 
l0: 0.000043, l1: 0.000042, l2: 0.000078, l3: 0.000142, l4: 0.000284, l5: 0.001115, l6: 0.001593

[epoch: 656/1000, batch:   300/ 1052, ite: 172340] train loss: 0.003991, tar: 0.000050 
l0: 0.000025, l1: 0.000024, l2: 0.000096, l3: 0.000137, l4: 0.000435, l5: 0.000632, l6: 0.002214

[epoch: 656/1000, batch:   380/ 1052, ite: 172360] train loss: 0.003991, tar: 0.000050 
l0: 0.000113, l1: 0.000112, l2: 0.000187, l3: 0.000310, l4: 0.000628, l5: 0.001503, l6: 0.002456

[epoch: 656/1000, batch:   460/ 1052, ite: 172380] train loss: 0.003991, tar: 0.000050 
l0: 0.000061, l1: 0.000063, l2: 0.000199, l3: 0.000635, l4: 0.001344, l5: 0.002259, l6: 0.003560

[epoch: 656/1000, batch:   540/ 1052, ite: 172400] train loss: 0.003991, tar: 0.000050 
l0: 0.000062, l1: 0.000061, l2: 0.000116, l3: 0.000256, l4: 0.000643, l5: 0.002047, l6: 0.002896

[epoch: 656/1000, batch:   620/ 1052, ite: 172420] train loss: 0.003992, tar: 0.000050 
l0: 0.000073, l1: 0.000071, l2: 0.000101, l3: 0.000167, l4: 0.000539, l5: 0.001367, l6: 0.002759

[epoch: 656/1000, batch:   700/ 1052, ite: 172440] train loss: 0.003994, tar: 0.000050 
l0: 0.000083, l1: 0.000084, l2: 0.000155, l3: 0.000221, l4: 0.000555, l5: 0.001077, l6: 0.001886

[epoch: 656/1000, batch:   780/ 1052, ite: 172460] train loss: 0.003993, tar: 0.000050 
l0: 0.000053, l1: 0.000052, l2: 0.000094, l3: 0.000242, l4: 0.000581, l5: 0.001210, l6: 0.003246

[epoch: 656/1000, batch:   860/ 1052, ite: 172480] train loss: 0.003993, tar: 0.000050 
l0: 0.000016, l1: 0.000016, l2: 0.000047, l3: 0.000130, l4: 0.000386, l5: 0.000683, l6: 0.002237

[epoch: 656/1000, batch:   940/ 1052, ite: 172500] train loss: 0.003992, tar: 0.000050 
l0: 0.000041, l1: 0.000042, l2: 0.000120, l3: 0.000215, l4: 0.000617, l5: 0.001230, l6: 0.003256

[epoch: 656/1000, batch:  1020/ 1052, ite: 172520] train loss: 0.003992, tar: 0.000050 
[Epoch 656/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000014, l1: 0.000015, l2: 0.000074, l3: 0.000251, l4: 0.000511, l5: 0.000898, l6: 0.001631

[epoch: 657/1000, batch:    48/ 1052, ite: 172540] train loss: 0.003992, tar: 0.000050 
l0: 0.000036, l1: 0.000034, l2: 0.000050, l3: 0.000066, l4: 0.000302, l5: 0.000618, l6: 0.001227

[epoch: 657/1000, batch:   128/ 1052, ite: 172560] train loss: 0.003990, tar: 0.000050 
l0: 0.000030, l1: 0.000032, l2: 0.000061, l3: 0.000167, l4: 0.000443, l5: 0.000913, l6: 0.001518

[epoch: 657/1000, batch:   208/ 1052, ite: 172580] train loss: 0.003989, tar: 0.000050 
l0: 0.000012, l1: 0.000012, l2: 0.000046, l3: 0.000156, l4: 0.000481, l5: 0.001091, l6: 0.002356

[epoch: 657/1000, batch:   288/ 1052, ite: 172600] train loss: 0.003989, tar: 0.000050 
l0: 0.000089, l1: 0.000094, l2: 0.000164, l3: 0.000409, l4: 0.000798, l5: 0.001623, l6: 0.003626

[epoch: 657/1000, batch:   368/ 1052, ite: 172620] train loss: 0.003989, tar: 0.000050 
l0: 0.000116, l1: 0.000114, l2: 0.000218, l3: 0.000420, l4: 0.001124, l5: 0.002019, l6: 0.004345

[epoch: 657/1000, batch:   448/ 1052, ite: 172640] train loss: 0.003992, tar: 0.000050 
l0: 0.000017, l1: 0.000016, l2: 0.000073, l3: 0.000189, l4: 0.000567, l5: 0.001036, l6: 0.002213

[epoch: 657/1000, batch:   528/ 1052, ite: 172660] train loss: 0.003991, tar: 0.000050 
l0: 0.000036, l1: 0.000035, l2: 0.000098, l3: 0.000176, l4: 0.000448, l5: 0.001166, l6: 0.001831

[epoch: 657/1000, batch:   608/ 1052, ite: 172680] train loss: 0.003991, tar: 0.000050 
l0: 0.000021, l1: 0.000022, l2: 0.000081, l3: 0.000146, l4: 0.000306, l5: 0.000442, l6: 0.001193

[epoch: 657/1000, batch:   688/ 1052, ite: 172700] train loss: 0.003990, tar: 0.000050 
l0: 0.000045, l1: 0.000044, l2: 0.000078, l3: 0.000123, l4: 0.000345, l5: 0.000932, l6: 0.001968

[epoch: 657/1000, batch:   768/ 1052, ite: 172720] train loss: 0.003988, tar: 0.000050 
l0: 0.000028, l1: 0.000029, l2: 0.000060, l3: 0.000090, l4: 0.000269, l5: 0.000909, l6: 0.001412

[epoch: 657/1000, batch:   848/ 1052, ite: 172740] train loss: 0.003989, tar: 0.000050 
l0: 0.000105, l1: 0.000104, l2: 0.000148, l3: 0.000323, l4: 0.000708, l5: 0.001494, l6: 0.001660

[epoch: 657/1000, batch:   928/ 1052, ite: 172760] train loss: 0.003987, tar: 0.000050 
l0: 0.000063, l1: 0.000067, l2: 0.000077, l3: 0.000145, l4: 0.000299, l5: 0.000479, l6: 0.000981

[epoch: 657/1000, batch:  1008/ 1052, ite: 172780] train loss: 0.003989, tar: 0.000050 
[Epoch 657/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000060, l1: 0.000066, l2: 0.000087, l3: 0.000184, l4: 0.000440, l5: 0.000803, l6: 0.001130

[epoch: 658/1000, batch:    36/ 1052, ite: 172800] train loss: 0.003990, tar: 0.000050 
l0: 0.000062, l1: 0.000064, l2: 0.000192, l3: 0.000462, l4: 0.001264, l5: 0.002859, l6: 0.005074

[epoch: 658/1000, batch:   116/ 1052, ite: 172820] train loss: 0.003990, tar: 0.000050 
l0: 0.000026, l1: 0.000026, l2: 0.000102, l3: 0.000321, l4: 0.000813, l5: 0.001804, l6: 0.002101

[epoch: 658/1000, batch:   196/ 1052, ite: 172840] train loss: 0.003993, tar: 0.000050 
l0: 0.000043, l1: 0.000042, l2: 0.000102, l3: 0.000179, l4: 0.000448, l5: 0.000607, l6: 0.001615

[epoch: 658/1000, batch:   276/ 1052, ite: 172860] train loss: 0.003992, tar: 0.000050 
l0: 0.000033, l1: 0.000034, l2: 0.000060, l3: 0.000105, l4: 0.000439, l5: 0.000694, l6: 0.001491

[epoch: 658/1000, batch:   356/ 1052, ite: 172880] train loss: 0.003993, tar: 0.000050 
l0: 0.000052, l1: 0.000047, l2: 0.000108, l3: 0.000232, l4: 0.000509, l5: 0.001124, l6: 0.001836

[epoch: 658/1000, batch:   436/ 1052, ite: 172900] train loss: 0.003993, tar: 0.000050 
l0: 0.000128, l1: 0.000132, l2: 0.000180, l3: 0.000325, l4: 0.000521, l5: 0.001377, l6: 0.004738

[epoch: 658/1000, batch:   516/ 1052, ite: 172920] train loss: 0.003995, tar: 0.000050 
l0: 0.000030, l1: 0.000029, l2: 0.000074, l3: 0.000196, l4: 0.000353, l5: 0.000695, l6: 0.001483

[epoch: 658/1000, batch:   596/ 1052, ite: 172940] train loss: 0.003996, tar: 0.000050 
l0: 0.000011, l1: 0.000011, l2: 0.000040, l3: 0.000098, l4: 0.000350, l5: 0.000535, l6: 0.001377

[epoch: 658/1000, batch:   676/ 1052, ite: 172960] train loss: 0.003995, tar: 0.000050 
l0: 0.000043, l1: 0.000045, l2: 0.000079, l3: 0.000105, l4: 0.000325, l5: 0.000680, l6: 0.001442

[epoch: 658/1000, batch:   756/ 1052, ite: 172980] train loss: 0.003994, tar: 0.000050 
l0: 0.000078, l1: 0.000075, l2: 0.000160, l3: 0.000243, l4: 0.000337, l5: 0.000752, l6: 0.001154

[epoch: 658/1000, batch:   836/ 1052, ite: 173000] train loss: 0.003996, tar: 0.000050 
l0: 0.000022, l1: 0.000022, l2: 0.000060, l3: 0.000142, l4: 0.000381, l5: 0.000882, l6: 0.001968

[epoch: 658/1000, batch:   916/ 1052, ite: 173020] train loss: 0.003995, tar: 0.000050 
l0: 0.000018, l1: 0.000019, l2: 0.000066, l3: 0.000153, l4: 0.000328, l5: 0.000913, l6: 0.001346

[epoch: 658/1000, batch:   996/ 1052, ite: 173040] train loss: 0.003993, tar: 0.000050 
[Epoch 658/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000151, l1: 0.000160, l2: 0.000152, l3: 0.000210, l4: 0.000524, l5: 0.001314, l6: 0.001675

[epoch: 659/1000, batch:    24/ 1052, ite: 173060] train loss: 0.003991, tar: 0.000050 
l0: 0.000022, l1: 0.000023, l2: 0.000092, l3: 0.000294, l4: 0.000706, l5: 0.001893, l6: 0.002270

[epoch: 659/1000, batch:   104/ 1052, ite: 173080] train loss: 0.003993, tar: 0.000050 
l0: 0.000077, l1: 0.000080, l2: 0.000168, l3: 0.000336, l4: 0.000691, l5: 0.001944, l6: 0.003275

[epoch: 659/1000, batch:   184/ 1052, ite: 173100] train loss: 0.003991, tar: 0.000050 
l0: 0.000008, l1: 0.000007, l2: 0.000037, l3: 0.000094, l4: 0.000556, l5: 0.000962, l6: 0.001569

[epoch: 659/1000, batch:   264/ 1052, ite: 173120] train loss: 0.003990, tar: 0.000050 
l0: 0.000022, l1: 0.000021, l2: 0.000044, l3: 0.000132, l4: 0.000158, l5: 0.000727, l6: 0.000970

[epoch: 659/1000, batch:   344/ 1052, ite: 173140] train loss: 0.003989, tar: 0.000050 
l0: 0.000048, l1: 0.000049, l2: 0.000064, l3: 0.000145, l4: 0.000395, l5: 0.000756, l6: 0.001551

[epoch: 659/1000, batch:   424/ 1052, ite: 173160] train loss: 0.003988, tar: 0.000050 
l0: 0.000011, l1: 0.000009, l2: 0.000029, l3: 0.000065, l4: 0.000189, l5: 0.000580, l6: 0.000969

[epoch: 659/1000, batch:   504/ 1052, ite: 173180] train loss: 0.003991, tar: 0.000050 
l0: 0.000051, l1: 0.000054, l2: 0.000068, l3: 0.000224, l4: 0.000429, l5: 0.000857, l6: 0.001782

[epoch: 659/1000, batch:   584/ 1052, ite: 173200] train loss: 0.003991, tar: 0.000050 
l0: 0.000050, l1: 0.000051, l2: 0.000070, l3: 0.000137, l4: 0.000318, l5: 0.000795, l6: 0.001194

[epoch: 659/1000, batch:   664/ 1052, ite: 173220] train loss: 0.003990, tar: 0.000050 
l0: 0.000000, l1: 0.000001, l2: 0.000005, l3: 0.000090, l4: 0.000432, l5: 0.000638, l6: 0.000996

[epoch: 659/1000, batch:   744/ 1052, ite: 173240] train loss: 0.003988, tar: 0.000050 
l0: 0.000059, l1: 0.000059, l2: 0.000161, l3: 0.000311, l4: 0.000727, l5: 0.002701, l6: 0.004541

[epoch: 659/1000, batch:   824/ 1052, ite: 173260] train loss: 0.003990, tar: 0.000050 
l0: 0.000015, l1: 0.000015, l2: 0.000067, l3: 0.000167, l4: 0.000437, l5: 0.000834, l6: 0.002156

[epoch: 659/1000, batch:   904/ 1052, ite: 173280] train loss: 0.003992, tar: 0.000050 
l0: 0.000001, l1: 0.000001, l2: 0.000023, l3: 0.000048, l4: 0.000230, l5: 0.000501, l6: 0.000847

[epoch: 659/1000, batch:   984/ 1052, ite: 173300] train loss: 0.003990, tar: 0.000050 
[Epoch 659/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000026, l1: 0.000029, l2: 0.000058, l3: 0.000114, l4: 0.000259, l5: 0.000836, l6: 0.002268

[epoch: 660/1000, batch:    12/ 1052, ite: 173320] train loss: 0.003991, tar: 0.000050 
l0: 0.000028, l1: 0.000029, l2: 0.000072, l3: 0.000167, l4: 0.000484, l5: 0.000726, l6: 0.000853

[epoch: 660/1000, batch:    92/ 1052, ite: 173340] train loss: 0.003991, tar: 0.000050 
l0: 0.000028, l1: 0.000030, l2: 0.000072, l3: 0.000214, l4: 0.000641, l5: 0.001378, l6: 0.001606

[epoch: 660/1000, batch:   172/ 1052, ite: 173360] train loss: 0.003994, tar: 0.000050 
l0: 0.000024, l1: 0.000023, l2: 0.000076, l3: 0.000256, l4: 0.000363, l5: 0.000800, l6: 0.001790

[epoch: 660/1000, batch:   252/ 1052, ite: 173380] train loss: 0.003995, tar: 0.000050 
l0: 0.000014, l1: 0.000015, l2: 0.000028, l3: 0.000066, l4: 0.000245, l5: 0.000744, l6: 0.001071

[epoch: 660/1000, batch:   332/ 1052, ite: 173400] train loss: 0.003994, tar: 0.000050 
l0: 0.000021, l1: 0.000021, l2: 0.000091, l3: 0.000515, l4: 0.001154, l5: 0.002361, l6: 0.003642

[epoch: 660/1000, batch:   412/ 1052, ite: 173420] train loss: 0.003995, tar: 0.000050 
l0: 0.000093, l1: 0.000095, l2: 0.000108, l3: 0.000238, l4: 0.000527, l5: 0.000992, l6: 0.001875

[epoch: 660/1000, batch:   492/ 1052, ite: 173440] train loss: 0.003992, tar: 0.000050 
l0: 0.000059, l1: 0.000060, l2: 0.000120, l3: 0.000284, l4: 0.000707, l5: 0.001054, l6: 0.002469

[epoch: 660/1000, batch:   572/ 1052, ite: 173460] train loss: 0.003993, tar: 0.000050 
l0: 0.000010, l1: 0.000010, l2: 0.000015, l3: 0.000059, l4: 0.000213, l5: 0.000388, l6: 0.000997

[epoch: 660/1000, batch:   652/ 1052, ite: 173480] train loss: 0.003993, tar: 0.000050 
l0: 0.000071, l1: 0.000071, l2: 0.000124, l3: 0.000260, l4: 0.000514, l5: 0.001394, l6: 0.003853

[epoch: 660/1000, batch:   732/ 1052, ite: 173500] train loss: 0.003995, tar: 0.000050 
l0: 0.000006, l1: 0.000007, l2: 0.000051, l3: 0.000141, l4: 0.000407, l5: 0.000861, l6: 0.001819

[epoch: 660/1000, batch:   812/ 1052, ite: 173520] train loss: 0.003994, tar: 0.000050 
l0: 0.000051, l1: 0.000050, l2: 0.000088, l3: 0.000189, l4: 0.000544, l5: 0.000871, l6: 0.003069

[epoch: 660/1000, batch:   892/ 1052, ite: 173540] train loss: 0.003992, tar: 0.000050 
l0: 0.000036, l1: 0.000037, l2: 0.000089, l3: 0.000168, l4: 0.000303, l5: 0.001022, l6: 0.001566

[epoch: 660/1000, batch:   972/ 1052, ite: 173560] train loss: 0.003991, tar: 0.000050 
l0: 0.000049, l1: 0.000052, l2: 0.000104, l3: 0.000191, l4: 0.000411, l5: 0.000984, l6: 0.002204

[epoch: 660/1000, batch:  1052/ 1052, ite: 173580] train loss: 0.003990, tar: 0.000050 
[Epoch 660/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000047, l1: 0.000051, l2: 0.000057, l3: 0.000147, l4: 0.000562, l5: 0.000981, l6: 0.001815

[epoch: 661/1000, batch:    80/ 1052, ite: 173600] train loss: 0.003990, tar: 0.000050 
l0: 0.000016, l1: 0.000017, l2: 0.000083, l3: 0.000215, l4: 0.000567, l5: 0.001274, l6: 0.002430

[epoch: 661/1000, batch:   160/ 1052, ite: 173620] train loss: 0.003989, tar: 0.000050 
l0: 0.000027, l1: 0.000026, l2: 0.000057, l3: 0.000121, l4: 0.000363, l5: 0.000841, l6: 0.001275

[epoch: 661/1000, batch:   240/ 1052, ite: 173640] train loss: 0.003987, tar: 0.000050 
l0: 0.000014, l1: 0.000015, l2: 0.000016, l3: 0.000046, l4: 0.000214, l5: 0.000810, l6: 0.001407

[epoch: 661/1000, batch:   320/ 1052, ite: 173660] train loss: 0.003986, tar: 0.000050 
l0: 0.000096, l1: 0.000095, l2: 0.000154, l3: 0.000260, l4: 0.000711, l5: 0.001509, l6: 0.002370

[epoch: 661/1000, batch:   400/ 1052, ite: 173680] train loss: 0.003987, tar: 0.000050 
l0: 0.000058, l1: 0.000059, l2: 0.000138, l3: 0.000307, l4: 0.000909, l5: 0.002659, l6: 0.003278

[epoch: 661/1000, batch:   480/ 1052, ite: 173700] train loss: 0.003988, tar: 0.000050 
l0: 0.000049, l1: 0.000051, l2: 0.000080, l3: 0.000157, l4: 0.000481, l5: 0.000892, l6: 0.001596

[epoch: 661/1000, batch:   560/ 1052, ite: 173720] train loss: 0.003988, tar: 0.000050 
l0: 0.000043, l1: 0.000042, l2: 0.000097, l3: 0.000134, l4: 0.000523, l5: 0.000409, l6: 0.001149

[epoch: 661/1000, batch:   640/ 1052, ite: 173740] train loss: 0.003987, tar: 0.000050 
l0: 0.000047, l1: 0.000045, l2: 0.000089, l3: 0.000185, l4: 0.000437, l5: 0.000987, l6: 0.001598

[epoch: 661/1000, batch:   720/ 1052, ite: 173760] train loss: 0.003986, tar: 0.000049 
l0: 0.000062, l1: 0.000063, l2: 0.000099, l3: 0.000213, l4: 0.000419, l5: 0.001076, l6: 0.002126

[epoch: 661/1000, batch:   800/ 1052, ite: 173780] train loss: 0.003988, tar: 0.000049 
l0: 0.000010, l1: 0.000010, l2: 0.000036, l3: 0.000108, l4: 0.000260, l5: 0.000761, l6: 0.001358

[epoch: 661/1000, batch:   880/ 1052, ite: 173800] train loss: 0.003989, tar: 0.000049 
l0: 0.000035, l1: 0.000036, l2: 0.000050, l3: 0.000152, l4: 0.000446, l5: 0.000903, l6: 0.001678

[epoch: 661/1000, batch:   960/ 1052, ite: 173820] train loss: 0.003989, tar: 0.000049 
l0: 0.000025, l1: 0.000024, l2: 0.000095, l3: 0.000241, l4: 0.000461, l5: 0.000984, l6: 0.001140

[epoch: 661/1000, batch:  1040/ 1052, ite: 173840] train loss: 0.003989, tar: 0.000049 
[Epoch 661/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000019, l1: 0.000020, l2: 0.000073, l3: 0.000173, l4: 0.000458, l5: 0.001644, l6: 0.002693

[epoch: 662/1000, batch:    68/ 1052, ite: 173860] train loss: 0.003988, tar: 0.000049 
l0: 0.000029, l1: 0.000027, l2: 0.000077, l3: 0.000190, l4: 0.000264, l5: 0.000657, l6: 0.001219

[epoch: 662/1000, batch:   148/ 1052, ite: 173880] train loss: 0.003989, tar: 0.000049 
l0: 0.000025, l1: 0.000026, l2: 0.000082, l3: 0.000172, l4: 0.000368, l5: 0.000802, l6: 0.001649

[epoch: 662/1000, batch:   228/ 1052, ite: 173900] train loss: 0.003989, tar: 0.000049 
l0: 0.000033, l1: 0.000032, l2: 0.000082, l3: 0.000190, l4: 0.000370, l5: 0.000580, l6: 0.001901

[epoch: 662/1000, batch:   308/ 1052, ite: 173920] train loss: 0.003992, tar: 0.000049 
l0: 0.000069, l1: 0.000070, l2: 0.000133, l3: 0.000374, l4: 0.000843, l5: 0.001382, l6: 0.003305

[epoch: 662/1000, batch:   388/ 1052, ite: 173940] train loss: 0.003992, tar: 0.000049 
l0: 0.000058, l1: 0.000060, l2: 0.000081, l3: 0.000182, l4: 0.000365, l5: 0.000705, l6: 0.001726

[epoch: 662/1000, batch:   468/ 1052, ite: 173960] train loss: 0.003992, tar: 0.000049 
l0: 0.000104, l1: 0.000106, l2: 0.000122, l3: 0.000231, l4: 0.000501, l5: 0.000924, l6: 0.001559

[epoch: 662/1000, batch:   548/ 1052, ite: 173980] train loss: 0.003992, tar: 0.000049 
l0: 0.000053, l1: 0.000053, l2: 0.000057, l3: 0.000156, l4: 0.000591, l5: 0.000801, l6: 0.001541

[epoch: 662/1000, batch:   628/ 1052, ite: 174000] train loss: 0.003993, tar: 0.000049 
l0: 0.000017, l1: 0.000017, l2: 0.000072, l3: 0.000131, l4: 0.000172, l5: 0.000521, l6: 0.001207

[epoch: 662/1000, batch:   708/ 1052, ite: 174020] train loss: 0.003992, tar: 0.000049 
l0: 0.000013, l1: 0.000015, l2: 0.000040, l3: 0.000124, l4: 0.000356, l5: 0.000887, l6: 0.002362

[epoch: 662/1000, batch:   788/ 1052, ite: 174040] train loss: 0.003991, tar: 0.000049 
l0: 0.000028, l1: 0.000027, l2: 0.000161, l3: 0.000360, l4: 0.000919, l5: 0.000990, l6: 0.002004

[epoch: 662/1000, batch:   868/ 1052, ite: 174060] train loss: 0.003988, tar: 0.000049 
l0: 0.000014, l1: 0.000014, l2: 0.000050, l3: 0.000118, l4: 0.000303, l5: 0.001046, l6: 0.001575

[epoch: 662/1000, batch:   948/ 1052, ite: 174080] train loss: 0.003988, tar: 0.000049 
l0: 0.000064, l1: 0.000063, l2: 0.000166, l3: 0.000552, l4: 0.000953, l5: 0.001848, l6: 0.003566

[epoch: 662/1000, batch:  1028/ 1052, ite: 174100] train loss: 0.003988, tar: 0.000049 
[Epoch 662/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000023, l1: 0.000023, l2: 0.000034, l3: 0.000119, l4: 0.000334, l5: 0.001330, l6: 0.001482

[epoch: 663/1000, batch:    56/ 1052, ite: 174120] train loss: 0.003988, tar: 0.000049 
l0: 0.000026, l1: 0.000027, l2: 0.000050, l3: 0.000152, l4: 0.000676, l5: 0.001437, l6: 0.001904

[epoch: 663/1000, batch:   136/ 1052, ite: 174140] train loss: 0.003988, tar: 0.000049 
l0: 0.000044, l1: 0.000044, l2: 0.000062, l3: 0.000127, l4: 0.000305, l5: 0.000869, l6: 0.001589

[epoch: 663/1000, batch:   216/ 1052, ite: 174160] train loss: 0.003990, tar: 0.000049 
l0: 0.000033, l1: 0.000035, l2: 0.000035, l3: 0.000162, l4: 0.000338, l5: 0.001081, l6: 0.001414

[epoch: 663/1000, batch:   296/ 1052, ite: 174180] train loss: 0.003989, tar: 0.000049 
l0: 0.000046, l1: 0.000047, l2: 0.000087, l3: 0.000183, l4: 0.000478, l5: 0.001854, l6: 0.002336

[epoch: 663/1000, batch:   376/ 1052, ite: 174200] train loss: 0.003991, tar: 0.000049 
l0: 0.000028, l1: 0.000028, l2: 0.000070, l3: 0.000209, l4: 0.000360, l5: 0.001201, l6: 0.002375

[epoch: 663/1000, batch:   456/ 1052, ite: 174220] train loss: 0.003991, tar: 0.000049 
l0: 0.000034, l1: 0.000030, l2: 0.000072, l3: 0.000170, l4: 0.000389, l5: 0.000750, l6: 0.001281

[epoch: 663/1000, batch:   536/ 1052, ite: 174240] train loss: 0.003989, tar: 0.000049 
l0: 0.000025, l1: 0.000025, l2: 0.000041, l3: 0.000153, l4: 0.000486, l5: 0.000514, l6: 0.001632

[epoch: 663/1000, batch:   616/ 1052, ite: 174260] train loss: 0.003988, tar: 0.000049 
l0: 0.000043, l1: 0.000045, l2: 0.000065, l3: 0.000150, l4: 0.000435, l5: 0.000510, l6: 0.002394

[epoch: 663/1000, batch:   696/ 1052, ite: 174280] train loss: 0.003986, tar: 0.000049 
l0: 0.000009, l1: 0.000010, l2: 0.000044, l3: 0.000110, l4: 0.000494, l5: 0.000912, l6: 0.002527

[epoch: 663/1000, batch:   776/ 1052, ite: 174300] train loss: 0.003987, tar: 0.000049 
l0: 0.000052, l1: 0.000052, l2: 0.000063, l3: 0.000122, l4: 0.000468, l5: 0.000975, l6: 0.001107

[epoch: 663/1000, batch:   856/ 1052, ite: 174320] train loss: 0.003986, tar: 0.000049 
l0: 0.000022, l1: 0.000022, l2: 0.000054, l3: 0.000143, l4: 0.000279, l5: 0.000771, l6: 0.001463

[epoch: 663/1000, batch:   936/ 1052, ite: 174340] train loss: 0.003986, tar: 0.000049 
l0: 0.000032, l1: 0.000031, l2: 0.000060, l3: 0.000162, l4: 0.000334, l5: 0.000837, l6: 0.001311

[epoch: 663/1000, batch:  1016/ 1052, ite: 174360] train loss: 0.003989, tar: 0.000049 
[Epoch 663/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000076, l1: 0.000080, l2: 0.000138, l3: 0.000231, l4: 0.000504, l5: 0.000968, l6: 0.002899

[epoch: 664/1000, batch:    44/ 1052, ite: 174380] train loss: 0.003988, tar: 0.000049 
l0: 0.000010, l1: 0.000009, l2: 0.000043, l3: 0.000116, l4: 0.000276, l5: 0.000729, l6: 0.001353

[epoch: 664/1000, batch:   124/ 1052, ite: 174400] train loss: 0.003987, tar: 0.000049 
l0: 0.000065, l1: 0.000066, l2: 0.000103, l3: 0.000142, l4: 0.000488, l5: 0.000893, l6: 0.001645

[epoch: 664/1000, batch:   204/ 1052, ite: 174420] train loss: 0.003987, tar: 0.000049 
l0: 0.000299, l1: 0.000248, l2: 0.000263, l3: 0.000404, l4: 0.000807, l5: 0.001784, l6: 0.001741

[epoch: 664/1000, batch:   284/ 1052, ite: 174440] train loss: 0.003989, tar: 0.000049 
l0: 0.000026, l1: 0.000026, l2: 0.000101, l3: 0.000249, l4: 0.000522, l5: 0.000985, l6: 0.001439

[epoch: 664/1000, batch:   364/ 1052, ite: 174460] train loss: 0.003989, tar: 0.000049 
l0: 0.000022, l1: 0.000022, l2: 0.000069, l3: 0.000196, l4: 0.000608, l5: 0.001598, l6: 0.002553

[epoch: 664/1000, batch:   444/ 1052, ite: 174480] train loss: 0.003988, tar: 0.000049 
l0: 0.000016, l1: 0.000016, l2: 0.000093, l3: 0.000189, l4: 0.000535, l5: 0.000842, l6: 0.001897

[epoch: 664/1000, batch:   524/ 1052, ite: 174500] train loss: 0.003989, tar: 0.000049 
l0: 0.000102, l1: 0.000106, l2: 0.000230, l3: 0.000361, l4: 0.000726, l5: 0.002289, l6: 0.004032

[epoch: 664/1000, batch:   604/ 1052, ite: 174520] train loss: 0.003989, tar: 0.000049 
l0: 0.000011, l1: 0.000011, l2: 0.000025, l3: 0.000089, l4: 0.000336, l5: 0.001163, l6: 0.001689

[epoch: 664/1000, batch:   684/ 1052, ite: 174540] train loss: 0.003988, tar: 0.000049 
l0: 0.000036, l1: 0.000035, l2: 0.000090, l3: 0.000151, l4: 0.000317, l5: 0.000711, l6: 0.001353

[epoch: 664/1000, batch:   764/ 1052, ite: 174560] train loss: 0.003987, tar: 0.000049 
l0: 0.000117, l1: 0.000111, l2: 0.000231, l3: 0.000372, l4: 0.000683, l5: 0.002210, l6: 0.003714

[epoch: 664/1000, batch:   844/ 1052, ite: 174580] train loss: 0.003988, tar: 0.000049 
l0: 0.000016, l1: 0.000015, l2: 0.000048, l3: 0.000093, l4: 0.000422, l5: 0.000332, l6: 0.000996

[epoch: 664/1000, batch:   924/ 1052, ite: 174600] train loss: 0.003989, tar: 0.000049 
l0: 0.000074, l1: 0.000076, l2: 0.000143, l3: 0.000414, l4: 0.001059, l5: 0.002025, l6: 0.003608

[epoch: 664/1000, batch:  1004/ 1052, ite: 174620] train loss: 0.003989, tar: 0.000049 
[Epoch 664/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000022, l1: 0.000022, l2: 0.000057, l3: 0.000222, l4: 0.000360, l5: 0.001381, l6: 0.001872

[epoch: 665/1000, batch:    32/ 1052, ite: 174640] train loss: 0.003989, tar: 0.000049 
l0: 0.000020, l1: 0.000021, l2: 0.000043, l3: 0.000093, l4: 0.000423, l5: 0.000658, l6: 0.001310

[epoch: 665/1000, batch:   112/ 1052, ite: 174660] train loss: 0.003988, tar: 0.000049 
l0: 0.000047, l1: 0.000047, l2: 0.000046, l3: 0.000118, l4: 0.000363, l5: 0.000737, l6: 0.001679

[epoch: 665/1000, batch:   192/ 1052, ite: 174680] train loss: 0.003988, tar: 0.000049 
l0: 0.000038, l1: 0.000039, l2: 0.000071, l3: 0.000102, l4: 0.000349, l5: 0.000725, l6: 0.001017

[epoch: 665/1000, batch:   272/ 1052, ite: 174700] train loss: 0.003989, tar: 0.000049 
l0: 0.000007, l1: 0.000007, l2: 0.000031, l3: 0.000078, l4: 0.000230, l5: 0.000770, l6: 0.001286

[epoch: 665/1000, batch:   352/ 1052, ite: 174720] train loss: 0.003989, tar: 0.000049 
l0: 0.000027, l1: 0.000030, l2: 0.000063, l3: 0.000109, l4: 0.000265, l5: 0.000694, l6: 0.000934

[epoch: 665/1000, batch:   432/ 1052, ite: 174740] train loss: 0.003989, tar: 0.000049 
l0: 0.000136, l1: 0.000137, l2: 0.000224, l3: 0.000477, l4: 0.000863, l5: 0.001263, l6: 0.001433

[epoch: 665/1000, batch:   512/ 1052, ite: 174760] train loss: 0.003989, tar: 0.000049 
l0: 0.000060, l1: 0.000062, l2: 0.000085, l3: 0.000223, l4: 0.000583, l5: 0.001548, l6: 0.002600

[epoch: 665/1000, batch:   592/ 1052, ite: 174780] train loss: 0.003988, tar: 0.000049 
l0: 0.000006, l1: 0.000007, l2: 0.000034, l3: 0.000103, l4: 0.000482, l5: 0.000811, l6: 0.001363

[epoch: 665/1000, batch:   672/ 1052, ite: 174800] train loss: 0.003987, tar: 0.000049 
l0: 0.000043, l1: 0.000042, l2: 0.000077, l3: 0.000136, l4: 0.000438, l5: 0.001179, l6: 0.001517

[epoch: 665/1000, batch:   752/ 1052, ite: 174820] train loss: 0.003986, tar: 0.000049 
l0: 0.000066, l1: 0.000064, l2: 0.000115, l3: 0.000279, l4: 0.000701, l5: 0.001275, l6: 0.003007

[epoch: 665/1000, batch:   832/ 1052, ite: 174840] train loss: 0.003986, tar: 0.000049 
l0: 0.000055, l1: 0.000060, l2: 0.000072, l3: 0.000223, l4: 0.000649, l5: 0.001684, l6: 0.003152

[epoch: 665/1000, batch:   912/ 1052, ite: 174860] train loss: 0.003987, tar: 0.000049 
l0: 0.000031, l1: 0.000034, l2: 0.000048, l3: 0.000107, l4: 0.000324, l5: 0.001063, l6: 0.001664

[epoch: 665/1000, batch:   992/ 1052, ite: 174880] train loss: 0.003986, tar: 0.000049 
[Epoch 665/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000120, l1: 0.000123, l2: 0.000193, l3: 0.000337, l4: 0.000578, l5: 0.001012, l6: 0.003940

[epoch: 666/1000, batch:    20/ 1052, ite: 174900] train loss: 0.003986, tar: 0.000049 
l0: 0.000052, l1: 0.000055, l2: 0.000134, l3: 0.000217, l4: 0.000475, l5: 0.001250, l6: 0.002034

[epoch: 666/1000, batch:   100/ 1052, ite: 174920] train loss: 0.003985, tar: 0.000049 
l0: 0.000037, l1: 0.000036, l2: 0.000097, l3: 0.000300, l4: 0.000513, l5: 0.001328, l6: 0.002421

[epoch: 666/1000, batch:   180/ 1052, ite: 174940] train loss: 0.003984, tar: 0.000049 
l0: 0.000026, l1: 0.000028, l2: 0.000129, l3: 0.000272, l4: 0.000519, l5: 0.001266, l6: 0.002842

[epoch: 666/1000, batch:   260/ 1052, ite: 174960] train loss: 0.003984, tar: 0.000049 
l0: 0.000037, l1: 0.000037, l2: 0.000073, l3: 0.000171, l4: 0.000424, l5: 0.001057, l6: 0.001592

[epoch: 666/1000, batch:   340/ 1052, ite: 174980] train loss: 0.003984, tar: 0.000049 
l0: 0.000031, l1: 0.000034, l2: 0.000096, l3: 0.000357, l4: 0.000628, l5: 0.001666, l6: 0.003211

[epoch: 666/1000, batch:   420/ 1052, ite: 175000] train loss: 0.003985, tar: 0.000049 
l0: 0.000019, l1: 0.000019, l2: 0.000027, l3: 0.000074, l4: 0.000304, l5: 0.000418, l6: 0.000981

[epoch: 666/1000, batch:   500/ 1052, ite: 175020] train loss: 0.003985, tar: 0.000049 
l0: 0.000007, l1: 0.000007, l2: 0.000069, l3: 0.000401, l4: 0.000673, l5: 0.001053, l6: 0.002722

[epoch: 666/1000, batch:   580/ 1052, ite: 175040] train loss: 0.003984, tar: 0.000049 
l0: 0.000062, l1: 0.000060, l2: 0.000114, l3: 0.000285, l4: 0.000613, l5: 0.001125, l6: 0.002656

[epoch: 666/1000, batch:   660/ 1052, ite: 175060] train loss: 0.003985, tar: 0.000049 
l0: 0.000040, l1: 0.000040, l2: 0.000071, l3: 0.000168, l4: 0.000385, l5: 0.001119, l6: 0.001700

[epoch: 666/1000, batch:   740/ 1052, ite: 175080] train loss: 0.003985, tar: 0.000049 
l0: 0.000018, l1: 0.000020, l2: 0.000090, l3: 0.000239, l4: 0.000470, l5: 0.000923, l6: 0.002212

[epoch: 666/1000, batch:   820/ 1052, ite: 175100] train loss: 0.003984, tar: 0.000049 
l0: 0.000060, l1: 0.000063, l2: 0.000071, l3: 0.000168, l4: 0.000385, l5: 0.001023, l6: 0.001695

[epoch: 666/1000, batch:   900/ 1052, ite: 175120] train loss: 0.003984, tar: 0.000049 
l0: 0.000008, l1: 0.000007, l2: 0.000030, l3: 0.000189, l4: 0.000507, l5: 0.001059, l6: 0.001327

[epoch: 666/1000, batch:   980/ 1052, ite: 175140] train loss: 0.003985, tar: 0.000049 
[Epoch 666/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000081, l1: 0.000085, l2: 0.000103, l3: 0.000189, l4: 0.000810, l5: 0.001311, l6: 0.002772

[epoch: 667/1000, batch:     8/ 1052, ite: 175160] train loss: 0.003986, tar: 0.000049 
l0: 0.000049, l1: 0.000050, l2: 0.000103, l3: 0.000212, l4: 0.000796, l5: 0.001346, l6: 0.001952

[epoch: 667/1000, batch:    88/ 1052, ite: 175180] train loss: 0.003985, tar: 0.000049 
l0: 0.000012, l1: 0.000012, l2: 0.000040, l3: 0.000131, l4: 0.000382, l5: 0.000761, l6: 0.001283

[epoch: 667/1000, batch:   168/ 1052, ite: 175200] train loss: 0.003986, tar: 0.000049 
l0: 0.000115, l1: 0.000120, l2: 0.000149, l3: 0.000320, l4: 0.000902, l5: 0.002023, l6: 0.002941

[epoch: 667/1000, batch:   248/ 1052, ite: 175220] train loss: 0.003985, tar: 0.000049 
l0: 0.000021, l1: 0.000022, l2: 0.000028, l3: 0.000126, l4: 0.000289, l5: 0.001191, l6: 0.002120

[epoch: 667/1000, batch:   328/ 1052, ite: 175240] train loss: 0.003985, tar: 0.000049 
l0: 0.000081, l1: 0.000084, l2: 0.000136, l3: 0.000333, l4: 0.000777, l5: 0.002498, l6: 0.002806

[epoch: 667/1000, batch:   408/ 1052, ite: 175260] train loss: 0.003985, tar: 0.000049 
l0: 0.000018, l1: 0.000018, l2: 0.000033, l3: 0.000095, l4: 0.000257, l5: 0.000491, l6: 0.001339

[epoch: 667/1000, batch:   488/ 1052, ite: 175280] train loss: 0.003985, tar: 0.000049 
l0: 0.000051, l1: 0.000052, l2: 0.000109, l3: 0.000355, l4: 0.000649, l5: 0.001725, l6: 0.003974

[epoch: 667/1000, batch:   568/ 1052, ite: 175300] train loss: 0.003984, tar: 0.000049 
l0: 0.000137, l1: 0.000139, l2: 0.000218, l3: 0.000363, l4: 0.000648, l5: 0.001946, l6: 0.003594

[epoch: 667/1000, batch:   648/ 1052, ite: 175320] train loss: 0.003984, tar: 0.000049 
l0: 0.000015, l1: 0.000014, l2: 0.000056, l3: 0.000200, l4: 0.000383, l5: 0.001099, l6: 0.002193

[epoch: 667/1000, batch:   728/ 1052, ite: 175340] train loss: 0.003985, tar: 0.000049 
l0: 0.000033, l1: 0.000031, l2: 0.000084, l3: 0.000130, l4: 0.000456, l5: 0.000737, l6: 0.001307

[epoch: 667/1000, batch:   808/ 1052, ite: 175360] train loss: 0.003985, tar: 0.000049 
l0: 0.000108, l1: 0.000109, l2: 0.000196, l3: 0.000429, l4: 0.000786, l5: 0.002394, l6: 0.004147

[epoch: 667/1000, batch:   888/ 1052, ite: 175380] train loss: 0.003985, tar: 0.000049 
l0: 0.000038, l1: 0.000040, l2: 0.000137, l3: 0.000280, l4: 0.000699, l5: 0.002105, l6: 0.003269

[epoch: 667/1000, batch:   968/ 1052, ite: 175400] train loss: 0.003985, tar: 0.000049 
l0: 0.000013, l1: 0.000014, l2: 0.000066, l3: 0.000173, l4: 0.000588, l5: 0.001331, l6: 0.002241

[epoch: 667/1000, batch:  1048/ 1052, ite: 175420] train loss: 0.003985, tar: 0.000049 
[Epoch 667/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000012, l1: 0.000010, l2: 0.000025, l3: 0.000092, l4: 0.000264, l5: 0.000366, l6: 0.000768

[epoch: 668/1000, batch:    76/ 1052, ite: 175440] train loss: 0.003985, tar: 0.000049 
l0: 0.000024, l1: 0.000025, l2: 0.000041, l3: 0.000095, l4: 0.000361, l5: 0.001087, l6: 0.001676

[epoch: 668/1000, batch:   156/ 1052, ite: 175460] train loss: 0.003984, tar: 0.000049 
l0: 0.000051, l1: 0.000057, l2: 0.000089, l3: 0.000155, l4: 0.000276, l5: 0.000442, l6: 0.001782

[epoch: 668/1000, batch:   236/ 1052, ite: 175480] train loss: 0.003983, tar: 0.000049 
l0: 0.000032, l1: 0.000029, l2: 0.000097, l3: 0.000165, l4: 0.000242, l5: 0.001188, l6: 0.001805

[epoch: 668/1000, batch:   316/ 1052, ite: 175500] train loss: 0.003983, tar: 0.000049 
l0: 0.000049, l1: 0.000048, l2: 0.000098, l3: 0.000210, l4: 0.000624, l5: 0.001832, l6: 0.002283

[epoch: 668/1000, batch:   396/ 1052, ite: 175520] train loss: 0.003982, tar: 0.000049 
l0: 0.000055, l1: 0.000057, l2: 0.000114, l3: 0.000254, l4: 0.000461, l5: 0.001528, l6: 0.002556

[epoch: 668/1000, batch:   476/ 1052, ite: 175540] train loss: 0.003981, tar: 0.000048 
l0: 0.000086, l1: 0.000084, l2: 0.000182, l3: 0.000309, l4: 0.000726, l5: 0.002296, l6: 0.003468

[epoch: 668/1000, batch:   556/ 1052, ite: 175560] train loss: 0.003983, tar: 0.000048 
l0: 0.000021, l1: 0.000020, l2: 0.000080, l3: 0.000147, l4: 0.000356, l5: 0.000727, l6: 0.001953

[epoch: 668/1000, batch:   636/ 1052, ite: 175580] train loss: 0.003983, tar: 0.000048 
l0: 0.000073, l1: 0.000072, l2: 0.000122, l3: 0.000309, l4: 0.000639, l5: 0.001365, l6: 0.002003

[epoch: 668/1000, batch:   716/ 1052, ite: 175600] train loss: 0.003982, tar: 0.000048 
l0: 0.000019, l1: 0.000020, l2: 0.000094, l3: 0.000207, l4: 0.000685, l5: 0.001543, l6: 0.002931

[epoch: 668/1000, batch:   796/ 1052, ite: 175620] train loss: 0.003983, tar: 0.000048 
l0: 0.000024, l1: 0.000025, l2: 0.000038, l3: 0.000123, l4: 0.000388, l5: 0.000807, l6: 0.001419

[epoch: 668/1000, batch:   876/ 1052, ite: 175640] train loss: 0.003983, tar: 0.000048 
l0: 0.000007, l1: 0.000008, l2: 0.000036, l3: 0.000096, l4: 0.000373, l5: 0.000437, l6: 0.001396

[epoch: 668/1000, batch:   956/ 1052, ite: 175660] train loss: 0.003981, tar: 0.000048 
l0: 0.000007, l1: 0.000007, l2: 0.000056, l3: 0.000130, l4: 0.000303, l5: 0.000704, l6: 0.001361

[epoch: 668/1000, batch:  1036/ 1052, ite: 175680] train loss: 0.003982, tar: 0.000048 
[Epoch 668/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000071, l1: 0.000072, l2: 0.000147, l3: 0.000325, l4: 0.000734, l5: 0.001378, l6: 0.002128

[epoch: 669/1000, batch:    64/ 1052, ite: 175700] train loss: 0.003981, tar: 0.000048 
l0: 0.000031, l1: 0.000030, l2: 0.000062, l3: 0.000179, l4: 0.000321, l5: 0.000794, l6: 0.001580

[epoch: 669/1000, batch:   144/ 1052, ite: 175720] train loss: 0.003982, tar: 0.000048 
l0: 0.000031, l1: 0.000030, l2: 0.000065, l3: 0.000123, l4: 0.000428, l5: 0.000952, l6: 0.002163

[epoch: 669/1000, batch:   224/ 1052, ite: 175740] train loss: 0.003981, tar: 0.000048 
l0: 0.000045, l1: 0.000043, l2: 0.000120, l3: 0.000283, l4: 0.000601, l5: 0.001215, l6: 0.001104

[epoch: 669/1000, batch:   304/ 1052, ite: 175760] train loss: 0.003981, tar: 0.000048 
l0: 0.000010, l1: 0.000010, l2: 0.000057, l3: 0.000147, l4: 0.000478, l5: 0.000659, l6: 0.001022

[epoch: 669/1000, batch:   384/ 1052, ite: 175780] train loss: 0.003980, tar: 0.000048 
l0: 0.000077, l1: 0.000079, l2: 0.000179, l3: 0.000408, l4: 0.000721, l5: 0.001478, l6: 0.002330

[epoch: 669/1000, batch:   464/ 1052, ite: 175800] train loss: 0.003980, tar: 0.000048 
l0: 0.000027, l1: 0.000027, l2: 0.000041, l3: 0.000119, l4: 0.000372, l5: 0.000662, l6: 0.001077

[epoch: 669/1000, batch:   544/ 1052, ite: 175820] train loss: 0.003980, tar: 0.000048 
l0: 0.000046, l1: 0.000046, l2: 0.000077, l3: 0.000155, l4: 0.000493, l5: 0.000670, l6: 0.001588

[epoch: 669/1000, batch:   624/ 1052, ite: 175840] train loss: 0.003980, tar: 0.000048 
l0: 0.000032, l1: 0.000032, l2: 0.000075, l3: 0.000141, l4: 0.000321, l5: 0.001323, l6: 0.002286

[epoch: 669/1000, batch:   704/ 1052, ite: 175860] train loss: 0.003979, tar: 0.000048 
l0: 0.000045, l1: 0.000046, l2: 0.000082, l3: 0.000215, l4: 0.000631, l5: 0.001701, l6: 0.002804

[epoch: 669/1000, batch:   784/ 1052, ite: 175880] train loss: 0.003979, tar: 0.000048 
l0: 0.000023, l1: 0.000019, l2: 0.000103, l3: 0.000142, l4: 0.000214, l5: 0.000536, l6: 0.000907

[epoch: 669/1000, batch:   864/ 1052, ite: 175900] train loss: 0.003978, tar: 0.000048 
l0: 0.000023, l1: 0.000020, l2: 0.000071, l3: 0.000265, l4: 0.000629, l5: 0.001405, l6: 0.001966

[epoch: 669/1000, batch:   944/ 1052, ite: 175920] train loss: 0.003980, tar: 0.000048 
l0: 0.000034, l1: 0.000033, l2: 0.000126, l3: 0.000294, l4: 0.000678, l5: 0.001490, l6: 0.003465

[epoch: 669/1000, batch:  1024/ 1052, ite: 175940] train loss: 0.003982, tar: 0.000048 
[Epoch 669/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000034, l1: 0.000038, l2: 0.000047, l3: 0.000131, l4: 0.000280, l5: 0.000634, l6: 0.002154

[epoch: 670/1000, batch:    52/ 1052, ite: 175960] train loss: 0.003981, tar: 0.000048 
l0: 0.000023, l1: 0.000024, l2: 0.000067, l3: 0.000141, l4: 0.000617, l5: 0.001182, l6: 0.001664

[epoch: 670/1000, batch:   132/ 1052, ite: 175980] train loss: 0.003980, tar: 0.000048 
l0: 0.000049, l1: 0.000049, l2: 0.000071, l3: 0.000093, l4: 0.000360, l5: 0.000784, l6: 0.001279

[epoch: 670/1000, batch:   212/ 1052, ite: 176000] train loss: 0.003981, tar: 0.000048 
l0: 0.000033, l1: 0.000034, l2: 0.000054, l3: 0.000145, l4: 0.000462, l5: 0.001986, l6: 0.002209

[epoch: 670/1000, batch:   292/ 1052, ite: 176020] train loss: 0.003979, tar: 0.000048 
l0: 0.000114, l1: 0.000113, l2: 0.000194, l3: 0.000405, l4: 0.000611, l5: 0.001589, l6: 0.002478

[epoch: 670/1000, batch:   372/ 1052, ite: 176040] train loss: 0.003981, tar: 0.000048 
l0: 0.000029, l1: 0.000028, l2: 0.000126, l3: 0.000466, l4: 0.000823, l5: 0.001757, l6: 0.002629

[epoch: 670/1000, batch:   452/ 1052, ite: 176060] train loss: 0.003983, tar: 0.000048 
l0: 0.000015, l1: 0.000015, l2: 0.000055, l3: 0.000226, l4: 0.000521, l5: 0.000845, l6: 0.001818

[epoch: 670/1000, batch:   532/ 1052, ite: 176080] train loss: 0.003982, tar: 0.000048 
l0: 0.000086, l1: 0.000088, l2: 0.000116, l3: 0.000248, l4: 0.000336, l5: 0.001227, l6: 0.002178

[epoch: 670/1000, batch:   612/ 1052, ite: 176100] train loss: 0.003982, tar: 0.000048 
l0: 0.000012, l1: 0.000016, l2: 0.000008, l3: 0.000037, l4: 0.000174, l5: 0.000648, l6: 0.001283

[epoch: 670/1000, batch:   692/ 1052, ite: 176120] train loss: 0.003981, tar: 0.000048 
l0: 0.000089, l1: 0.000088, l2: 0.000117, l3: 0.000178, l4: 0.000365, l5: 0.000842, l6: 0.002184

[epoch: 670/1000, batch:   772/ 1052, ite: 176140] train loss: 0.003981, tar: 0.000048 
l0: 0.000146, l1: 0.000147, l2: 0.000116, l3: 0.000265, l4: 0.000604, l5: 0.001034, l6: 0.001175

[epoch: 670/1000, batch:   852/ 1052, ite: 176160] train loss: 0.003982, tar: 0.000048 
l0: 0.000021, l1: 0.000020, l2: 0.000075, l3: 0.000417, l4: 0.000800, l5: 0.001549, l6: 0.001785

[epoch: 670/1000, batch:   932/ 1052, ite: 176180] train loss: 0.003982, tar: 0.000048 
l0: 0.000028, l1: 0.000028, l2: 0.000088, l3: 0.000274, l4: 0.000605, l5: 0.001939, l6: 0.002868

[epoch: 670/1000, batch:  1012/ 1052, ite: 176200] train loss: 0.003981, tar: 0.000048 
[Epoch 670/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000043, l1: 0.000041, l2: 0.000129, l3: 0.000347, l4: 0.000692, l5: 0.001175, l6: 0.001573

[epoch: 671/1000, batch:    40/ 1052, ite: 176220] train loss: 0.003980, tar: 0.000048 
l0: 0.000146, l1: 0.000144, l2: 0.000222, l3: 0.000456, l4: 0.000895, l5: 0.001725, l6: 0.003105

[epoch: 671/1000, batch:   120/ 1052, ite: 176240] train loss: 0.003981, tar: 0.000048 
l0: 0.000083, l1: 0.000085, l2: 0.000091, l3: 0.000141, l4: 0.000476, l5: 0.000989, l6: 0.002870

[epoch: 671/1000, batch:   200/ 1052, ite: 176260] train loss: 0.003981, tar: 0.000048 
l0: 0.000030, l1: 0.000032, l2: 0.000039, l3: 0.000113, l4: 0.000385, l5: 0.000629, l6: 0.001766

[epoch: 671/1000, batch:   280/ 1052, ite: 176280] train loss: 0.003982, tar: 0.000048 
l0: 0.000034, l1: 0.000033, l2: 0.000062, l3: 0.000181, l4: 0.000517, l5: 0.001397, l6: 0.001895

[epoch: 671/1000, batch:   360/ 1052, ite: 176300] train loss: 0.003981, tar: 0.000048 
l0: 0.000003, l1: 0.000003, l2: 0.000050, l3: 0.000122, l4: 0.000327, l5: 0.000730, l6: 0.001233

[epoch: 671/1000, batch:   440/ 1052, ite: 176320] train loss: 0.003981, tar: 0.000048 
l0: 0.000024, l1: 0.000025, l2: 0.000079, l3: 0.000215, l4: 0.000703, l5: 0.001551, l6: 0.003086

[epoch: 671/1000, batch:   520/ 1052, ite: 176340] train loss: 0.003981, tar: 0.000048 
l0: 0.000030, l1: 0.000027, l2: 0.000065, l3: 0.000186, l4: 0.000490, l5: 0.001182, l6: 0.002154

[epoch: 671/1000, batch:   600/ 1052, ite: 176360] train loss: 0.003981, tar: 0.000048 
l0: 0.000026, l1: 0.000028, l2: 0.000050, l3: 0.000188, l4: 0.000408, l5: 0.001161, l6: 0.002405

[epoch: 671/1000, batch:   680/ 1052, ite: 176380] train loss: 0.003981, tar: 0.000048 
l0: 0.000150, l1: 0.000149, l2: 0.000235, l3: 0.000444, l4: 0.001020, l5: 0.001804, l6: 0.003860

[epoch: 671/1000, batch:   760/ 1052, ite: 176400] train loss: 0.003983, tar: 0.000048 
l0: 0.000009, l1: 0.000011, l2: 0.000063, l3: 0.000242, l4: 0.000506, l5: 0.000979, l6: 0.001473

[epoch: 671/1000, batch:   840/ 1052, ite: 176420] train loss: 0.003983, tar: 0.000048 
l0: 0.000009, l1: 0.000009, l2: 0.000035, l3: 0.000147, l4: 0.000354, l5: 0.000488, l6: 0.000936

[epoch: 671/1000, batch:   920/ 1052, ite: 176440] train loss: 0.003981, tar: 0.000048 
l0: 0.000037, l1: 0.000035, l2: 0.000045, l3: 0.000098, l4: 0.000269, l5: 0.000529, l6: 0.000618

[epoch: 671/1000, batch:  1000/ 1052, ite: 176460] train loss: 0.003981, tar: 0.000048 
[Epoch 671/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000037, l1: 0.000037, l2: 0.000089, l3: 0.000259, l4: 0.000535, l5: 0.001436, l6: 0.002499

[epoch: 672/1000, batch:    28/ 1052, ite: 176480] train loss: 0.003982, tar: 0.000048 
l0: 0.000103, l1: 0.000105, l2: 0.000168, l3: 0.000556, l4: 0.001022, l5: 0.003642, l6: 0.005957

[epoch: 672/1000, batch:   108/ 1052, ite: 176500] train loss: 0.003983, tar: 0.000048 
l0: 0.000036, l1: 0.000039, l2: 0.000041, l3: 0.000090, l4: 0.000353, l5: 0.001309, l6: 0.000871

[epoch: 672/1000, batch:   188/ 1052, ite: 176520] train loss: 0.003984, tar: 0.000048 
l0: 0.000032, l1: 0.000033, l2: 0.000094, l3: 0.000246, l4: 0.000507, l5: 0.000728, l6: 0.002019

[epoch: 672/1000, batch:   268/ 1052, ite: 176540] train loss: 0.003983, tar: 0.000048 
l0: 0.000056, l1: 0.000051, l2: 0.000088, l3: 0.000224, l4: 0.000465, l5: 0.000796, l6: 0.001722

[epoch: 672/1000, batch:   348/ 1052, ite: 176560] train loss: 0.003982, tar: 0.000048 
l0: 0.000011, l1: 0.000010, l2: 0.000066, l3: 0.000155, l4: 0.000306, l5: 0.000827, l6: 0.001528

[epoch: 672/1000, batch:   428/ 1052, ite: 176580] train loss: 0.003981, tar: 0.000048 
l0: 0.000048, l1: 0.000050, l2: 0.000113, l3: 0.000278, l4: 0.000558, l5: 0.001185, l6: 0.001849

[epoch: 672/1000, batch:   508/ 1052, ite: 176600] train loss: 0.003981, tar: 0.000048 
l0: 0.000026, l1: 0.000027, l2: 0.000040, l3: 0.000120, l4: 0.000246, l5: 0.000540, l6: 0.001184

[epoch: 672/1000, batch:   588/ 1052, ite: 176620] train loss: 0.003980, tar: 0.000048 
l0: 0.000039, l1: 0.000041, l2: 0.000090, l3: 0.000156, l4: 0.000437, l5: 0.000986, l6: 0.001248

[epoch: 672/1000, batch:   668/ 1052, ite: 176640] train loss: 0.003980, tar: 0.000048 
l0: 0.000005, l1: 0.000006, l2: 0.000029, l3: 0.000148, l4: 0.000281, l5: 0.000757, l6: 0.000678

[epoch: 672/1000, batch:   748/ 1052, ite: 176660] train loss: 0.003979, tar: 0.000048 
l0: 0.000025, l1: 0.000025, l2: 0.000077, l3: 0.000128, l4: 0.000230, l5: 0.000722, l6: 0.001274

[epoch: 672/1000, batch:   828/ 1052, ite: 176680] train loss: 0.003979, tar: 0.000048 
l0: 0.000046, l1: 0.000045, l2: 0.000075, l3: 0.000216, l4: 0.000623, l5: 0.001099, l6: 0.002370

[epoch: 672/1000, batch:   908/ 1052, ite: 176700] train loss: 0.003980, tar: 0.000048 
l0: 0.000051, l1: 0.000053, l2: 0.000086, l3: 0.000209, l4: 0.000325, l5: 0.000911, l6: 0.001212

[epoch: 672/1000, batch:   988/ 1052, ite: 176720] train loss: 0.003980, tar: 0.000048 
[Epoch 672/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000032, l1: 0.000028, l2: 0.000048, l3: 0.000151, l4: 0.000353, l5: 0.000858, l6: 0.001073

[epoch: 673/1000, batch:    16/ 1052, ite: 176740] train loss: 0.003981, tar: 0.000048 
l0: 0.000032, l1: 0.000032, l2: 0.000122, l3: 0.000353, l4: 0.001190, l5: 0.001968, l6: 0.003742

[epoch: 673/1000, batch:    96/ 1052, ite: 176760] train loss: 0.003982, tar: 0.000048 
l0: 0.000033, l1: 0.000035, l2: 0.000066, l3: 0.000106, l4: 0.000321, l5: 0.000816, l6: 0.002100

[epoch: 673/1000, batch:   176/ 1052, ite: 176780] train loss: 0.003982, tar: 0.000048 
l0: 0.000019, l1: 0.000019, l2: 0.000066, l3: 0.000174, l4: 0.000416, l5: 0.000847, l6: 0.001427

[epoch: 673/1000, batch:   256/ 1052, ite: 176800] train loss: 0.003982, tar: 0.000048 
l0: 0.000091, l1: 0.000087, l2: 0.000231, l3: 0.000371, l4: 0.000795, l5: 0.001788, l6: 0.003506

[epoch: 673/1000, batch:   336/ 1052, ite: 176820] train loss: 0.003981, tar: 0.000048 
l0: 0.000049, l1: 0.000049, l2: 0.000111, l3: 0.000235, l4: 0.000523, l5: 0.000933, l6: 0.001718

[epoch: 673/1000, batch:   416/ 1052, ite: 176840] train loss: 0.003982, tar: 0.000048 
l0: 0.000011, l1: 0.000012, l2: 0.000026, l3: 0.000117, l4: 0.000262, l5: 0.000546, l6: 0.001320

[epoch: 673/1000, batch:   496/ 1052, ite: 176860] train loss: 0.003981, tar: 0.000048 
l0: 0.000041, l1: 0.000040, l2: 0.000175, l3: 0.000312, l4: 0.000598, l5: 0.001136, l6: 0.001827

[epoch: 673/1000, batch:   576/ 1052, ite: 176880] train loss: 0.003982, tar: 0.000048 
l0: 0.000013, l1: 0.000014, l2: 0.000021, l3: 0.000064, l4: 0.000115, l5: 0.000224, l6: 0.000601

[epoch: 673/1000, batch:   656/ 1052, ite: 176900] train loss: 0.003982, tar: 0.000048 
l0: 0.000038, l1: 0.000041, l2: 0.000096, l3: 0.000267, l4: 0.000622, l5: 0.000974, l6: 0.001305

[epoch: 673/1000, batch:   736/ 1052, ite: 176920] train loss: 0.003982, tar: 0.000048 
l0: 0.000010, l1: 0.000010, l2: 0.000047, l3: 0.000145, l4: 0.000548, l5: 0.000753, l6: 0.001299

[epoch: 673/1000, batch:   816/ 1052, ite: 176940] train loss: 0.003982, tar: 0.000048 
l0: 0.000020, l1: 0.000020, l2: 0.000046, l3: 0.000098, l4: 0.000423, l5: 0.000772, l6: 0.001675

[epoch: 673/1000, batch:   896/ 1052, ite: 176960] train loss: 0.003982, tar: 0.000048 
l0: 0.000016, l1: 0.000015, l2: 0.000036, l3: 0.000088, l4: 0.000415, l5: 0.000636, l6: 0.001394

[epoch: 673/1000, batch:   976/ 1052, ite: 176980] train loss: 0.003982, tar: 0.000048 
[Epoch 673/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000037, l1: 0.000036, l2: 0.000135, l3: 0.000360, l4: 0.000721, l5: 0.001829, l6: 0.003246

[epoch: 674/1000, batch:     4/ 1052, ite: 177000] train loss: 0.003981, tar: 0.000048 
l0: 0.000076, l1: 0.000075, l2: 0.000097, l3: 0.000241, l4: 0.000421, l5: 0.000446, l6: 0.001190

[epoch: 674/1000, batch:    84/ 1052, ite: 177020] train loss: 0.003981, tar: 0.000048 
l0: 0.000008, l1: 0.000008, l2: 0.000034, l3: 0.000135, l4: 0.000468, l5: 0.000699, l6: 0.002001

[epoch: 674/1000, batch:   164/ 1052, ite: 177040] train loss: 0.003981, tar: 0.000048 
l0: 0.000028, l1: 0.000030, l2: 0.000080, l3: 0.000224, l4: 0.000723, l5: 0.001188, l6: 0.002993

[epoch: 674/1000, batch:   244/ 1052, ite: 177060] train loss: 0.003980, tar: 0.000048 
l0: 0.000022, l1: 0.000022, l2: 0.000044, l3: 0.000158, l4: 0.000466, l5: 0.001153, l6: 0.001955

[epoch: 674/1000, batch:   324/ 1052, ite: 177080] train loss: 0.003982, tar: 0.000048 
l0: 0.000160, l1: 0.000158, l2: 0.000290, l3: 0.000460, l4: 0.001063, l5: 0.001687, l6: 0.002764

[epoch: 674/1000, batch:   404/ 1052, ite: 177100] train loss: 0.003982, tar: 0.000048 
l0: 0.000026, l1: 0.000026, l2: 0.000047, l3: 0.000124, l4: 0.000359, l5: 0.000957, l6: 0.001222

[epoch: 674/1000, batch:   484/ 1052, ite: 177120] train loss: 0.003983, tar: 0.000048 
l0: 0.000051, l1: 0.000047, l2: 0.000109, l3: 0.000216, l4: 0.000533, l5: 0.000934, l6: 0.001921

[epoch: 674/1000, batch:   564/ 1052, ite: 177140] train loss: 0.003981, tar: 0.000048 
l0: 0.000138, l1: 0.000136, l2: 0.000144, l3: 0.000212, l4: 0.000558, l5: 0.001711, l6: 0.002909

[epoch: 674/1000, batch:   644/ 1052, ite: 177160] train loss: 0.003982, tar: 0.000048 
l0: 0.000041, l1: 0.000040, l2: 0.000092, l3: 0.000236, l4: 0.000401, l5: 0.000987, l6: 0.002104

[epoch: 674/1000, batch:   724/ 1052, ite: 177180] train loss: 0.003981, tar: 0.000048 
l0: 0.000005, l1: 0.000006, l2: 0.000041, l3: 0.000164, l4: 0.000348, l5: 0.000871, l6: 0.001816

[epoch: 674/1000, batch:   804/ 1052, ite: 177200] train loss: 0.003981, tar: 0.000048 
l0: 0.000078, l1: 0.000079, l2: 0.000105, l3: 0.000151, l4: 0.000499, l5: 0.000638, l6: 0.001590

[epoch: 674/1000, batch:   884/ 1052, ite: 177220] train loss: 0.003980, tar: 0.000048 
l0: 0.000093, l1: 0.000101, l2: 0.000154, l3: 0.000280, l4: 0.000519, l5: 0.001603, l6: 0.004395

[epoch: 674/1000, batch:   964/ 1052, ite: 177240] train loss: 0.003979, tar: 0.000048 
l0: 0.000008, l1: 0.000008, l2: 0.000022, l3: 0.000069, l4: 0.000306, l5: 0.000690, l6: 0.001281

[epoch: 674/1000, batch:  1044/ 1052, ite: 177260] train loss: 0.003979, tar: 0.000048 
[Epoch 674/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000071, l1: 0.000071, l2: 0.000099, l3: 0.000207, l4: 0.000459, l5: 0.001447, l6: 0.002395

[epoch: 675/1000, batch:    72/ 1052, ite: 177280] train loss: 0.003979, tar: 0.000048 
l0: 0.000041, l1: 0.000042, l2: 0.000072, l3: 0.000128, l4: 0.000391, l5: 0.001003, l6: 0.000802

[epoch: 675/1000, batch:   152/ 1052, ite: 177300] train loss: 0.003979, tar: 0.000048 
l0: 0.000049, l1: 0.000053, l2: 0.000095, l3: 0.000217, l4: 0.000451, l5: 0.001589, l6: 0.002382

[epoch: 675/1000, batch:   232/ 1052, ite: 177320] train loss: 0.003979, tar: 0.000048 
l0: 0.000018, l1: 0.000018, l2: 0.000041, l3: 0.000138, l4: 0.000361, l5: 0.000547, l6: 0.001551

[epoch: 675/1000, batch:   312/ 1052, ite: 177340] train loss: 0.003980, tar: 0.000048 
l0: 0.000023, l1: 0.000025, l2: 0.000043, l3: 0.000130, l4: 0.000494, l5: 0.000783, l6: 0.002513

[epoch: 675/1000, batch:   392/ 1052, ite: 177360] train loss: 0.003980, tar: 0.000048 
l0: 0.000025, l1: 0.000024, l2: 0.000088, l3: 0.000247, l4: 0.000436, l5: 0.001281, l6: 0.001149

[epoch: 675/1000, batch:   472/ 1052, ite: 177380] train loss: 0.003980, tar: 0.000048 
l0: 0.000116, l1: 0.000116, l2: 0.000113, l3: 0.000216, l4: 0.000710, l5: 0.001275, l6: 0.001877

[epoch: 675/1000, batch:   552/ 1052, ite: 177400] train loss: 0.003981, tar: 0.000048 
l0: 0.000021, l1: 0.000023, l2: 0.000041, l3: 0.000129, l4: 0.000311, l5: 0.001108, l6: 0.001926

[epoch: 675/1000, batch:   632/ 1052, ite: 177420] train loss: 0.003981, tar: 0.000048 
l0: 0.000038, l1: 0.000040, l2: 0.000086, l3: 0.000219, l4: 0.000479, l5: 0.002060, l6: 0.002682

[epoch: 675/1000, batch:   712/ 1052, ite: 177440] train loss: 0.003980, tar: 0.000048 
l0: 0.000059, l1: 0.000058, l2: 0.000100, l3: 0.000209, l4: 0.000560, l5: 0.001147, l6: 0.001622

[epoch: 675/1000, batch:   792/ 1052, ite: 177460] train loss: 0.003981, tar: 0.000048 
l0: 0.000017, l1: 0.000016, l2: 0.000026, l3: 0.000089, l4: 0.000433, l5: 0.000759, l6: 0.001217

[epoch: 675/1000, batch:   872/ 1052, ite: 177480] train loss: 0.003980, tar: 0.000048 
l0: 0.000053, l1: 0.000054, l2: 0.000085, l3: 0.000151, l4: 0.000300, l5: 0.000973, l6: 0.001255

[epoch: 675/1000, batch:   952/ 1052, ite: 177500] train loss: 0.003980, tar: 0.000048 
l0: 0.000056, l1: 0.000055, l2: 0.000127, l3: 0.000208, l4: 0.000436, l5: 0.001066, l6: 0.002130

[epoch: 675/1000, batch:  1032/ 1052, ite: 177520] train loss: 0.003978, tar: 0.000048 
[Epoch 675/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000015, l1: 0.000016, l2: 0.000051, l3: 0.000158, l4: 0.000433, l5: 0.001148, l6: 0.001956

[epoch: 676/1000, batch:    60/ 1052, ite: 177540] train loss: 0.003978, tar: 0.000048 
l0: 0.000007, l1: 0.000008, l2: 0.000032, l3: 0.000118, l4: 0.000506, l5: 0.001103, l6: 0.001736

[epoch: 676/1000, batch:   140/ 1052, ite: 177560] train loss: 0.003978, tar: 0.000048 
l0: 0.000030, l1: 0.000029, l2: 0.000053, l3: 0.000120, l4: 0.000325, l5: 0.001414, l6: 0.002365

[epoch: 676/1000, batch:   220/ 1052, ite: 177580] train loss: 0.003977, tar: 0.000048 
l0: 0.000007, l1: 0.000008, l2: 0.000028, l3: 0.000146, l4: 0.000414, l5: 0.000936, l6: 0.001866

[epoch: 676/1000, batch:   300/ 1052, ite: 177600] train loss: 0.003977, tar: 0.000048 
l0: 0.000017, l1: 0.000016, l2: 0.000070, l3: 0.000210, l4: 0.000632, l5: 0.001122, l6: 0.002091

[epoch: 676/1000, batch:   380/ 1052, ite: 177620] train loss: 0.003978, tar: 0.000048 
l0: 0.000015, l1: 0.000016, l2: 0.000062, l3: 0.000105, l4: 0.000370, l5: 0.000673, l6: 0.001507

[epoch: 676/1000, batch:   460/ 1052, ite: 177640] train loss: 0.003979, tar: 0.000048 
l0: 0.000001, l1: 0.000001, l2: 0.000011, l3: 0.000049, l4: 0.000176, l5: 0.000519, l6: 0.000895

[epoch: 676/1000, batch:   540/ 1052, ite: 177660] train loss: 0.003978, tar: 0.000048 
l0: 0.000032, l1: 0.000033, l2: 0.000038, l3: 0.000079, l4: 0.000309, l5: 0.001141, l6: 0.001167

[epoch: 676/1000, batch:   620/ 1052, ite: 177680] train loss: 0.003977, tar: 0.000048 
l0: 0.000069, l1: 0.000066, l2: 0.000130, l3: 0.000277, l4: 0.000595, l5: 0.001515, l6: 0.002902

[epoch: 676/1000, batch:   700/ 1052, ite: 177700] train loss: 0.003977, tar: 0.000048 
l0: 0.000020, l1: 0.000019, l2: 0.000042, l3: 0.000168, l4: 0.000378, l5: 0.001046, l6: 0.001804

[epoch: 676/1000, batch:   780/ 1052, ite: 177720] train loss: 0.003976, tar: 0.000048 
l0: 0.000021, l1: 0.000021, l2: 0.000039, l3: 0.000111, l4: 0.000255, l5: 0.000689, l6: 0.001292

[epoch: 676/1000, batch:   860/ 1052, ite: 177740] train loss: 0.003978, tar: 0.000048 
l0: 0.000025, l1: 0.000027, l2: 0.000043, l3: 0.000100, l4: 0.000200, l5: 0.000719, l6: 0.000882

[epoch: 676/1000, batch:   940/ 1052, ite: 177760] train loss: 0.003977, tar: 0.000048 
l0: 0.000054, l1: 0.000054, l2: 0.000092, l3: 0.000200, l4: 0.000489, l5: 0.000910, l6: 0.001700

[epoch: 676/1000, batch:  1020/ 1052, ite: 177780] train loss: 0.003977, tar: 0.000048 
[Epoch 676/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000022, l1: 0.000022, l2: 0.000036, l3: 0.000128, l4: 0.000240, l5: 0.000667, l6: 0.000941

[epoch: 677/1000, batch:    48/ 1052, ite: 177800] train loss: 0.003977, tar: 0.000048 
l0: 0.000018, l1: 0.000020, l2: 0.000050, l3: 0.000115, l4: 0.000288, l5: 0.000619, l6: 0.001546

[epoch: 677/1000, batch:   128/ 1052, ite: 177820] train loss: 0.003977, tar: 0.000048 
l0: 0.000084, l1: 0.000090, l2: 0.000114, l3: 0.000270, l4: 0.001021, l5: 0.001819, l6: 0.002693

[epoch: 677/1000, batch:   208/ 1052, ite: 177840] train loss: 0.003977, tar: 0.000048 
l0: 0.000028, l1: 0.000029, l2: 0.000060, l3: 0.000183, l4: 0.000440, l5: 0.000994, l6: 0.001976

[epoch: 677/1000, batch:   288/ 1052, ite: 177860] train loss: 0.003976, tar: 0.000048 
l0: 0.000037, l1: 0.000037, l2: 0.000064, l3: 0.000143, l4: 0.000397, l5: 0.000701, l6: 0.001165

[epoch: 677/1000, batch:   368/ 1052, ite: 177880] train loss: 0.003975, tar: 0.000048 
l0: 0.000149, l1: 0.000150, l2: 0.000162, l3: 0.000290, l4: 0.000614, l5: 0.001772, l6: 0.002521

[epoch: 677/1000, batch:   448/ 1052, ite: 177900] train loss: 0.003975, tar: 0.000048 
l0: 0.000111, l1: 0.000110, l2: 0.000085, l3: 0.000110, l4: 0.000243, l5: 0.000501, l6: 0.000755

[epoch: 677/1000, batch:   528/ 1052, ite: 177920] train loss: 0.003976, tar: 0.000048 
l0: 0.000042, l1: 0.000041, l2: 0.000099, l3: 0.000188, l4: 0.000589, l5: 0.001461, l6: 0.002021

[epoch: 677/1000, batch:   608/ 1052, ite: 177940] train loss: 0.003977, tar: 0.000048 
l0: 0.000059, l1: 0.000056, l2: 0.000127, l3: 0.000228, l4: 0.000646, l5: 0.001166, l6: 0.002202

[epoch: 677/1000, batch:   688/ 1052, ite: 177960] train loss: 0.003976, tar: 0.000048 
l0: 0.000012, l1: 0.000013, l2: 0.000033, l3: 0.000214, l4: 0.000488, l5: 0.001220, l6: 0.002383

[epoch: 677/1000, batch:   768/ 1052, ite: 177980] train loss: 0.003977, tar: 0.000048 
l0: 0.000066, l1: 0.000071, l2: 0.000058, l3: 0.000143, l4: 0.000329, l5: 0.001029, l6: 0.001328

[epoch: 677/1000, batch:   848/ 1052, ite: 178000] train loss: 0.003976, tar: 0.000048 
l0: 0.000004, l1: 0.000005, l2: 0.000010, l3: 0.000102, l4: 0.000395, l5: 0.000705, l6: 0.000563

[epoch: 677/1000, batch:   928/ 1052, ite: 178020] train loss: 0.003977, tar: 0.000048 
l0: 0.000024, l1: 0.000024, l2: 0.000048, l3: 0.000160, l4: 0.000454, l5: 0.001228, l6: 0.002539

[epoch: 677/1000, batch:  1008/ 1052, ite: 178040] train loss: 0.003976, tar: 0.000048 
[Epoch 677/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000028, l1: 0.000027, l2: 0.000059, l3: 0.000101, l4: 0.000318, l5: 0.000613, l6: 0.001421

[epoch: 678/1000, batch:    36/ 1052, ite: 178060] train loss: 0.003976, tar: 0.000048 
l0: 0.000125, l1: 0.000125, l2: 0.000150, l3: 0.000261, l4: 0.000778, l5: 0.001529, l6: 0.002623

[epoch: 678/1000, batch:   116/ 1052, ite: 178080] train loss: 0.003976, tar: 0.000048 
l0: 0.000035, l1: 0.000037, l2: 0.000064, l3: 0.000219, l4: 0.000573, l5: 0.001275, l6: 0.002406

[epoch: 678/1000, batch:   196/ 1052, ite: 178100] train loss: 0.003976, tar: 0.000048 
l0: 0.000097, l1: 0.000095, l2: 0.000145, l3: 0.000290, l4: 0.000758, l5: 0.001730, l6: 0.002473

[epoch: 678/1000, batch:   276/ 1052, ite: 178120] train loss: 0.003977, tar: 0.000048 
l0: 0.000024, l1: 0.000022, l2: 0.000043, l3: 0.000096, l4: 0.000235, l5: 0.000561, l6: 0.000840

[epoch: 678/1000, batch:   356/ 1052, ite: 178140] train loss: 0.003975, tar: 0.000048 
l0: 0.000076, l1: 0.000075, l2: 0.000131, l3: 0.000316, l4: 0.000912, l5: 0.001734, l6: 0.002393

[epoch: 678/1000, batch:   436/ 1052, ite: 178160] train loss: 0.003975, tar: 0.000048 
l0: 0.000006, l1: 0.000007, l2: 0.000038, l3: 0.000172, l4: 0.000693, l5: 0.001142, l6: 0.001552

[epoch: 678/1000, batch:   516/ 1052, ite: 178180] train loss: 0.003976, tar: 0.000048 
l0: 0.000016, l1: 0.000018, l2: 0.000065, l3: 0.000215, l4: 0.000515, l5: 0.000774, l6: 0.001551

[epoch: 678/1000, batch:   596/ 1052, ite: 178200] train loss: 0.003976, tar: 0.000048 
l0: 0.000116, l1: 0.000115, l2: 0.000188, l3: 0.000280, l4: 0.000614, l5: 0.001418, l6: 0.002380

[epoch: 678/1000, batch:   676/ 1052, ite: 178220] train loss: 0.003975, tar: 0.000048 
l0: 0.000036, l1: 0.000036, l2: 0.000091, l3: 0.000198, l4: 0.000471, l5: 0.000673, l6: 0.001727

[epoch: 678/1000, batch:   756/ 1052, ite: 178240] train loss: 0.003974, tar: 0.000048 
l0: 0.000057, l1: 0.000057, l2: 0.000072, l3: 0.000181, l4: 0.000495, l5: 0.001539, l6: 0.001647

[epoch: 678/1000, batch:   836/ 1052, ite: 178260] train loss: 0.003974, tar: 0.000047 
l0: 0.000034, l1: 0.000035, l2: 0.000109, l3: 0.000199, l4: 0.000727, l5: 0.001623, l6: 0.002214

[epoch: 678/1000, batch:   916/ 1052, ite: 178280] train loss: 0.003975, tar: 0.000047 
l0: 0.000057, l1: 0.000055, l2: 0.000101, l3: 0.000188, l4: 0.000375, l5: 0.000666, l6: 0.001986

[epoch: 678/1000, batch:   996/ 1052, ite: 178300] train loss: 0.003975, tar: 0.000047 
[Epoch 678/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000038, l1: 0.000037, l2: 0.000097, l3: 0.000327, l4: 0.001050, l5: 0.002200, l6: 0.003141

[epoch: 679/1000, batch:    24/ 1052, ite: 178320] train loss: 0.003975, tar: 0.000047 
l0: 0.000064, l1: 0.000056, l2: 0.000088, l3: 0.000193, l4: 0.000335, l5: 0.000647, l6: 0.000807

[epoch: 679/1000, batch:   104/ 1052, ite: 178340] train loss: 0.003977, tar: 0.000047 
l0: 0.000044, l1: 0.000049, l2: 0.000080, l3: 0.000208, l4: 0.000596, l5: 0.001271, l6: 0.003160

[epoch: 679/1000, batch:   184/ 1052, ite: 178360] train loss: 0.003977, tar: 0.000047 
l0: 0.000027, l1: 0.000026, l2: 0.000088, l3: 0.000160, l4: 0.000357, l5: 0.000906, l6: 0.001829

[epoch: 679/1000, batch:   264/ 1052, ite: 178380] train loss: 0.003976, tar: 0.000047 
l0: 0.000011, l1: 0.000011, l2: 0.000037, l3: 0.000159, l4: 0.000410, l5: 0.000743, l6: 0.000878

[epoch: 679/1000, batch:   344/ 1052, ite: 178400] train loss: 0.003976, tar: 0.000047 
l0: 0.000005, l1: 0.000005, l2: 0.000019, l3: 0.000063, l4: 0.000173, l5: 0.000349, l6: 0.000653

[epoch: 679/1000, batch:   424/ 1052, ite: 178420] train loss: 0.003976, tar: 0.000047 
l0: 0.000041, l1: 0.000043, l2: 0.000078, l3: 0.000304, l4: 0.000573, l5: 0.001320, l6: 0.002993

[epoch: 679/1000, batch:   504/ 1052, ite: 178440] train loss: 0.003976, tar: 0.000047 
l0: 0.000100, l1: 0.000104, l2: 0.000176, l3: 0.000627, l4: 0.000979, l5: 0.001882, l6: 0.003019

[epoch: 679/1000, batch:   584/ 1052, ite: 178460] train loss: 0.003976, tar: 0.000047 
l0: 0.000022, l1: 0.000024, l2: 0.000066, l3: 0.000137, l4: 0.000453, l5: 0.000619, l6: 0.001156

[epoch: 679/1000, batch:   664/ 1052, ite: 178480] train loss: 0.003976, tar: 0.000047 
l0: 0.000028, l1: 0.000028, l2: 0.000060, l3: 0.000110, l4: 0.000420, l5: 0.000955, l6: 0.001926

[epoch: 679/1000, batch:   744/ 1052, ite: 178500] train loss: 0.003975, tar: 0.000047 
l0: 0.000009, l1: 0.000010, l2: 0.000030, l3: 0.000124, l4: 0.000272, l5: 0.000778, l6: 0.001154

[epoch: 679/1000, batch:   824/ 1052, ite: 178520] train loss: 0.003975, tar: 0.000047 
l0: 0.000025, l1: 0.000023, l2: 0.000067, l3: 0.000138, l4: 0.000330, l5: 0.001112, l6: 0.001743

[epoch: 679/1000, batch:   904/ 1052, ite: 178540] train loss: 0.003975, tar: 0.000047 
l0: 0.000008, l1: 0.000008, l2: 0.000075, l3: 0.000163, l4: 0.000531, l5: 0.001242, l6: 0.003041

[epoch: 679/1000, batch:   984/ 1052, ite: 178560] train loss: 0.003976, tar: 0.000047 
[Epoch 679/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000012, l1: 0.000014, l2: 0.000032, l3: 0.000125, l4: 0.000426, l5: 0.000801, l6: 0.001556

[epoch: 680/1000, batch:    12/ 1052, ite: 178580] train loss: 0.003976, tar: 0.000047 
l0: 0.000015, l1: 0.000015, l2: 0.000030, l3: 0.000125, l4: 0.000322, l5: 0.000777, l6: 0.001725

[epoch: 680/1000, batch:    92/ 1052, ite: 178600] train loss: 0.003975, tar: 0.000047 
l0: 0.000037, l1: 0.000036, l2: 0.000087, l3: 0.000284, l4: 0.000820, l5: 0.001868, l6: 0.002473

[epoch: 680/1000, batch:   172/ 1052, ite: 178620] train loss: 0.003974, tar: 0.000047 
l0: 0.000016, l1: 0.000017, l2: 0.000048, l3: 0.000159, l4: 0.000323, l5: 0.000976, l6: 0.002002

[epoch: 680/1000, batch:   252/ 1052, ite: 178640] train loss: 0.003974, tar: 0.000047 
l0: 0.000016, l1: 0.000017, l2: 0.000058, l3: 0.000226, l4: 0.000485, l5: 0.001214, l6: 0.001978

[epoch: 680/1000, batch:   332/ 1052, ite: 178660] train loss: 0.003974, tar: 0.000047 
l0: 0.000048, l1: 0.000048, l2: 0.000160, l3: 0.000246, l4: 0.000441, l5: 0.001581, l6: 0.003133

[epoch: 680/1000, batch:   412/ 1052, ite: 178680] train loss: 0.003974, tar: 0.000047 
l0: 0.000006, l1: 0.000006, l2: 0.000015, l3: 0.000047, l4: 0.000236, l5: 0.000495, l6: 0.000706

[epoch: 680/1000, batch:   492/ 1052, ite: 178700] train loss: 0.003973, tar: 0.000047 
l0: 0.000064, l1: 0.000071, l2: 0.000083, l3: 0.000223, l4: 0.000331, l5: 0.000428, l6: 0.002063

[epoch: 680/1000, batch:   572/ 1052, ite: 178720] train loss: 0.003973, tar: 0.000047 
l0: 0.000021, l1: 0.000021, l2: 0.000042, l3: 0.000155, l4: 0.000460, l5: 0.001211, l6: 0.002213

[epoch: 680/1000, batch:   652/ 1052, ite: 178740] train loss: 0.003973, tar: 0.000047 
l0: 0.000034, l1: 0.000033, l2: 0.000076, l3: 0.000300, l4: 0.000488, l5: 0.001224, l6: 0.002017

[epoch: 680/1000, batch:   732/ 1052, ite: 178760] train loss: 0.003973, tar: 0.000047 
l0: 0.000041, l1: 0.000043, l2: 0.000049, l3: 0.000143, l4: 0.000288, l5: 0.000974, l6: 0.001427

[epoch: 680/1000, batch:   812/ 1052, ite: 178780] train loss: 0.003974, tar: 0.000047 
l0: 0.000050, l1: 0.000051, l2: 0.000075, l3: 0.000272, l4: 0.000848, l5: 0.001400, l6: 0.002453

[epoch: 680/1000, batch:   892/ 1052, ite: 178800] train loss: 0.003974, tar: 0.000047 
l0: 0.000035, l1: 0.000035, l2: 0.000116, l3: 0.000265, l4: 0.000578, l5: 0.001504, l6: 0.001856

[epoch: 680/1000, batch:   972/ 1052, ite: 178820] train loss: 0.003974, tar: 0.000047 
l0: 0.000108, l1: 0.000106, l2: 0.000121, l3: 0.000209, l4: 0.000411, l5: 0.000925, l6: 0.001340

[epoch: 680/1000, batch:  1052/ 1052, ite: 178840] train loss: 0.003974, tar: 0.000047 
[Epoch 680/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000031, l1: 0.000031, l2: 0.000091, l3: 0.000226, l4: 0.000516, l5: 0.000844, l6: 0.001917

[epoch: 681/1000, batch:    80/ 1052, ite: 178860] train loss: 0.003955, tar: 0.000048 
l0: 0.000034, l1: 0.000033, l2: 0.000071, l3: 0.000172, l4: 0.000405, l5: 0.001013, l6: 0.001790

[epoch: 681/1000, batch:   160/ 1052, ite: 178880] train loss: 0.003763, tar: 0.000041 
l0: 0.000033, l1: 0.000031, l2: 0.000103, l3: 0.000221, l4: 0.000372, l5: 0.001353, l6: 0.000877

[epoch: 681/1000, batch:   240/ 1052, ite: 178900] train loss: 0.003687, tar: 0.000037 
l0: 0.000051, l1: 0.000050, l2: 0.000090, l3: 0.000275, l4: 0.000437, l5: 0.001819, l6: 0.002025

[epoch: 681/1000, batch:   320/ 1052, ite: 178920] train loss: 0.003704, tar: 0.000039 
l0: 0.000075, l1: 0.000069, l2: 0.000247, l3: 0.000473, l4: 0.000904, l5: 0.001214, l6: 0.001956

[epoch: 681/1000, batch:   400/ 1052, ite: 178940] train loss: 0.003633, tar: 0.000037 
l0: 0.000022, l1: 0.000022, l2: 0.000029, l3: 0.000116, l4: 0.000380, l5: 0.000835, l6: 0.001778

[epoch: 681/1000, batch:   480/ 1052, ite: 178960] train loss: 0.003694, tar: 0.000039 
l0: 0.000061, l1: 0.000062, l2: 0.000113, l3: 0.000354, l4: 0.000803, l5: 0.002351, l6: 0.003276

[epoch: 681/1000, batch:   560/ 1052, ite: 178980] train loss: 0.003714, tar: 0.000039 
l0: 0.000035, l1: 0.000037, l2: 0.000087, l3: 0.000154, l4: 0.000379, l5: 0.000717, l6: 0.000927

[epoch: 681/1000, batch:   640/ 1052, ite: 179000] train loss: 0.003705, tar: 0.000038 
l0: 0.000054, l1: 0.000054, l2: 0.000118, l3: 0.000257, l4: 0.000681, l5: 0.001173, l6: 0.001862

[epoch: 681/1000, batch:   720/ 1052, ite: 179020] train loss: 0.003774, tar: 0.000040 
l0: 0.000021, l1: 0.000021, l2: 0.000042, l3: 0.000067, l4: 0.000252, l5: 0.000662, l6: 0.001107

[epoch: 681/1000, batch:   800/ 1052, ite: 179040] train loss: 0.003784, tar: 0.000041 
l0: 0.000031, l1: 0.000031, l2: 0.000107, l3: 0.000188, l4: 0.000420, l5: 0.001087, l6: 0.002380

[epoch: 681/1000, batch:   880/ 1052, ite: 179060] train loss: 0.003801, tar: 0.000040 
l0: 0.000089, l1: 0.000105, l2: 0.000075, l3: 0.000181, l4: 0.000451, l5: 0.000891, l6: 0.002374

[epoch: 681/1000, batch:   960/ 1052, ite: 179080] train loss: 0.003866, tar: 0.000042 
l0: 0.000097, l1: 0.000104, l2: 0.000127, l3: 0.000237, l4: 0.000573, l5: 0.001215, l6: 0.001917

[epoch: 681/1000, batch:  1040/ 1052, ite: 179100] train loss: 0.003900, tar: 0.000042 
[Epoch 681/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000010, l1: 0.000011, l2: 0.000059, l3: 0.000198, l4: 0.000506, l5: 0.001143, l6: 0.001591

[epoch: 682/1000, batch:    68/ 1052, ite: 179120] train loss: 0.003871, tar: 0.000041 
l0: 0.000043, l1: 0.000048, l2: 0.000068, l3: 0.000310, l4: 0.000522, l5: 0.001131, l6: 0.002180

[epoch: 682/1000, batch:   148/ 1052, ite: 179140] train loss: 0.003876, tar: 0.000042 
l0: 0.000020, l1: 0.000020, l2: 0.000021, l3: 0.000076, l4: 0.000390, l5: 0.000629, l6: 0.000954

[epoch: 682/1000, batch:   228/ 1052, ite: 179160] train loss: 0.003857, tar: 0.000041 
l0: 0.000041, l1: 0.000043, l2: 0.000120, l3: 0.000221, l4: 0.000652, l5: 0.001310, l6: 0.002115

[epoch: 682/1000, batch:   308/ 1052, ite: 179180] train loss: 0.003849, tar: 0.000042 
l0: 0.000028, l1: 0.000030, l2: 0.000062, l3: 0.000213, l4: 0.000494, l5: 0.000998, l6: 0.001472

[epoch: 682/1000, batch:   388/ 1052, ite: 179200] train loss: 0.003863, tar: 0.000042 
l0: 0.000030, l1: 0.000032, l2: 0.000083, l3: 0.000186, l4: 0.000390, l5: 0.001177, l6: 0.001749

[epoch: 682/1000, batch:   468/ 1052, ite: 179220] train loss: 0.003885, tar: 0.000042 
l0: 0.000017, l1: 0.000019, l2: 0.000052, l3: 0.000128, l4: 0.000273, l5: 0.000595, l6: 0.001249

[epoch: 682/1000, batch:   548/ 1052, ite: 179240] train loss: 0.003893, tar: 0.000042 
l0: 0.000070, l1: 0.000070, l2: 0.000137, l3: 0.000281, l4: 0.000843, l5: 0.001160, l6: 0.002159

[epoch: 682/1000, batch:   628/ 1052, ite: 179260] train loss: 0.003944, tar: 0.000043 
l0: 0.000037, l1: 0.000040, l2: 0.000086, l3: 0.000196, l4: 0.000408, l5: 0.001070, l6: 0.002921

[epoch: 682/1000, batch:   708/ 1052, ite: 179280] train loss: 0.003936, tar: 0.000043 
l0: 0.000018, l1: 0.000017, l2: 0.000033, l3: 0.000127, l4: 0.000323, l5: 0.000883, l6: 0.001765

[epoch: 682/1000, batch:   788/ 1052, ite: 179300] train loss: 0.003921, tar: 0.000043 
l0: 0.000027, l1: 0.000028, l2: 0.000051, l3: 0.000214, l4: 0.000529, l5: 0.001337, l6: 0.003312

[epoch: 682/1000, batch:   868/ 1052, ite: 179320] train loss: 0.003931, tar: 0.000043 
l0: 0.000092, l1: 0.000091, l2: 0.000205, l3: 0.000376, l4: 0.001021, l5: 0.002177, l6: 0.005410

[epoch: 682/1000, batch:   948/ 1052, ite: 179340] train loss: 0.003947, tar: 0.000043 
l0: 0.000064, l1: 0.000064, l2: 0.000106, l3: 0.000243, l4: 0.000605, l5: 0.001258, l6: 0.002115

[epoch: 682/1000, batch:  1028/ 1052, ite: 179360] train loss: 0.003923, tar: 0.000043 
[Epoch 682/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000102, l1: 0.000103, l2: 0.000086, l3: 0.000171, l4: 0.000288, l5: 0.000896, l6: 0.001169

[epoch: 683/1000, batch:    56/ 1052, ite: 179380] train loss: 0.003916, tar: 0.000044 
l0: 0.000065, l1: 0.000071, l2: 0.000099, l3: 0.000261, l4: 0.000453, l5: 0.000744, l6: 0.001180

[epoch: 683/1000, batch:   136/ 1052, ite: 179400] train loss: 0.003928, tar: 0.000044 
l0: 0.000047, l1: 0.000046, l2: 0.000074, l3: 0.000180, l4: 0.000421, l5: 0.000957, l6: 0.001737

[epoch: 683/1000, batch:   216/ 1052, ite: 179420] train loss: 0.003930, tar: 0.000045 
l0: 0.000034, l1: 0.000033, l2: 0.000120, l3: 0.000284, l4: 0.000818, l5: 0.002065, l6: 0.002976

[epoch: 683/1000, batch:   296/ 1052, ite: 179440] train loss: 0.003944, tar: 0.000045 
l0: 0.000027, l1: 0.000024, l2: 0.000052, l3: 0.000086, l4: 0.000343, l5: 0.001053, l6: 0.001067

[epoch: 683/1000, batch:   376/ 1052, ite: 179460] train loss: 0.003929, tar: 0.000045 
l0: 0.000063, l1: 0.000061, l2: 0.000121, l3: 0.000196, l4: 0.000688, l5: 0.002188, l6: 0.003359

[epoch: 683/1000, batch:   456/ 1052, ite: 179480] train loss: 0.003930, tar: 0.000045 
l0: 0.000025, l1: 0.000026, l2: 0.000060, l3: 0.000169, l4: 0.000271, l5: 0.001097, l6: 0.001360

[epoch: 683/1000, batch:   536/ 1052, ite: 179500] train loss: 0.003920, tar: 0.000044 
l0: 0.000020, l1: 0.000022, l2: 0.000042, l3: 0.000153, l4: 0.000371, l5: 0.001166, l6: 0.001743

[epoch: 683/1000, batch:   616/ 1052, ite: 179520] train loss: 0.003927, tar: 0.000044 
l0: 0.000060, l1: 0.000065, l2: 0.000163, l3: 0.000366, l4: 0.000565, l5: 0.001209, l6: 0.002082

[epoch: 683/1000, batch:   696/ 1052, ite: 179540] train loss: 0.003945, tar: 0.000044 
l0: 0.000066, l1: 0.000065, l2: 0.000110, l3: 0.000219, l4: 0.000432, l5: 0.001071, l6: 0.001076

[epoch: 683/1000, batch:   776/ 1052, ite: 179560] train loss: 0.003950, tar: 0.000044 
l0: 0.000018, l1: 0.000018, l2: 0.000057, l3: 0.000125, l4: 0.000344, l5: 0.000916, l6: 0.001690

[epoch: 683/1000, batch:   856/ 1052, ite: 179580] train loss: 0.003951, tar: 0.000044 
l0: 0.000052, l1: 0.000050, l2: 0.000111, l3: 0.000180, l4: 0.000482, l5: 0.001226, l6: 0.003039

[epoch: 683/1000, batch:   936/ 1052, ite: 179600] train loss: 0.003950, tar: 0.000044 
l0: 0.000028, l1: 0.000030, l2: 0.000077, l3: 0.000314, l4: 0.000627, l5: 0.001468, l6: 0.002745

[epoch: 683/1000, batch:  1016/ 1052, ite: 179620] train loss: 0.003945, tar: 0.000044 
[Epoch 683/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000020, l1: 0.000019, l2: 0.000078, l3: 0.000427, l4: 0.001047, l5: 0.001481, l6: 0.002223

[epoch: 684/1000, batch:    44/ 1052, ite: 179640] train loss: 0.003944, tar: 0.000044 
l0: 0.000026, l1: 0.000024, l2: 0.000051, l3: 0.000158, l4: 0.000426, l5: 0.000682, l6: 0.001835

[epoch: 684/1000, batch:   124/ 1052, ite: 179660] train loss: 0.003940, tar: 0.000043 
l0: 0.000007, l1: 0.000006, l2: 0.000023, l3: 0.000097, l4: 0.000221, l5: 0.000829, l6: 0.001222

[epoch: 684/1000, batch:   204/ 1052, ite: 179680] train loss: 0.003933, tar: 0.000044 
l0: 0.000038, l1: 0.000039, l2: 0.000054, l3: 0.000114, l4: 0.000394, l5: 0.000761, l6: 0.001405

[epoch: 684/1000, batch:   284/ 1052, ite: 179700] train loss: 0.003930, tar: 0.000043 
l0: 0.000014, l1: 0.000015, l2: 0.000068, l3: 0.000168, l4: 0.000416, l5: 0.000889, l6: 0.001401

[epoch: 684/1000, batch:   364/ 1052, ite: 179720] train loss: 0.003919, tar: 0.000043 
l0: 0.000011, l1: 0.000011, l2: 0.000046, l3: 0.000191, l4: 0.000435, l5: 0.001027, l6: 0.001652

[epoch: 684/1000, batch:   444/ 1052, ite: 179740] train loss: 0.003912, tar: 0.000043 
l0: 0.000042, l1: 0.000039, l2: 0.000143, l3: 0.000321, l4: 0.000806, l5: 0.001202, l6: 0.002448

[epoch: 684/1000, batch:   524/ 1052, ite: 179760] train loss: 0.003917, tar: 0.000043 
l0: 0.000052, l1: 0.000052, l2: 0.000110, l3: 0.000270, l4: 0.000421, l5: 0.000793, l6: 0.001820

[epoch: 684/1000, batch:   604/ 1052, ite: 179780] train loss: 0.003924, tar: 0.000043 
l0: 0.000117, l1: 0.000119, l2: 0.000171, l3: 0.000416, l4: 0.001109, l5: 0.002477, l6: 0.004096

[epoch: 684/1000, batch:   684/ 1052, ite: 179800] train loss: 0.003930, tar: 0.000043 
l0: 0.000088, l1: 0.000091, l2: 0.000145, l3: 0.000327, l4: 0.000887, l5: 0.002533, l6: 0.004043

[epoch: 684/1000, batch:   764/ 1052, ite: 179820] train loss: 0.003935, tar: 0.000043 
l0: 0.000025, l1: 0.000025, l2: 0.000067, l3: 0.000146, l4: 0.000254, l5: 0.000858, l6: 0.001249

[epoch: 684/1000, batch:   844/ 1052, ite: 179840] train loss: 0.003931, tar: 0.000043 
l0: 0.000044, l1: 0.000043, l2: 0.000092, l3: 0.000166, l4: 0.000352, l5: 0.000922, l6: 0.001599

[epoch: 684/1000, batch:   924/ 1052, ite: 179860] train loss: 0.003934, tar: 0.000043 
l0: 0.000071, l1: 0.000073, l2: 0.000127, l3: 0.000342, l4: 0.000617, l5: 0.001333, l6: 0.002382

[epoch: 684/1000, batch:  1004/ 1052, ite: 179880] train loss: 0.003939, tar: 0.000043 
[Epoch 684/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000028, l1: 0.000029, l2: 0.000059, l3: 0.000215, l4: 0.000709, l5: 0.001125, l6: 0.002199

[epoch: 685/1000, batch:    32/ 1052, ite: 179900] train loss: 0.003935, tar: 0.000043 
l0: 0.000035, l1: 0.000032, l2: 0.000095, l3: 0.000210, l4: 0.000451, l5: 0.001271, l6: 0.001862

[epoch: 685/1000, batch:   112/ 1052, ite: 179920] train loss: 0.003932, tar: 0.000043 
l0: 0.000082, l1: 0.000084, l2: 0.000208, l3: 0.000332, l4: 0.000784, l5: 0.001607, l6: 0.004439

[epoch: 685/1000, batch:   192/ 1052, ite: 179940] train loss: 0.003940, tar: 0.000044 
l0: 0.000037, l1: 0.000041, l2: 0.000085, l3: 0.000160, l4: 0.000327, l5: 0.001058, l6: 0.001551

[epoch: 685/1000, batch:   272/ 1052, ite: 179960] train loss: 0.003939, tar: 0.000044 
l0: 0.000047, l1: 0.000047, l2: 0.000137, l3: 0.000266, l4: 0.000491, l5: 0.000977, l6: 0.001913

[epoch: 685/1000, batch:   352/ 1052, ite: 179980] train loss: 0.003944, tar: 0.000044 
l0: 0.000059, l1: 0.000059, l2: 0.000087, l3: 0.000325, l4: 0.000927, l5: 0.001385, l6: 0.002502

[epoch: 685/1000, batch:   432/ 1052, ite: 180000] train loss: 0.003952, tar: 0.000044 
l0: 0.000018, l1: 0.000018, l2: 0.000058, l3: 0.000145, l4: 0.000270, l5: 0.000863, l6: 0.001577

[epoch: 685/1000, batch:   512/ 1052, ite: 180020] train loss: 0.003947, tar: 0.000044 
l0: 0.000040, l1: 0.000041, l2: 0.000058, l3: 0.000119, l4: 0.000268, l5: 0.000864, l6: 0.001489

[epoch: 685/1000, batch:   592/ 1052, ite: 180040] train loss: 0.003942, tar: 0.000044 
l0: 0.000026, l1: 0.000025, l2: 0.000073, l3: 0.000229, l4: 0.000428, l5: 0.000664, l6: 0.002412

[epoch: 685/1000, batch:   672/ 1052, ite: 180060] train loss: 0.003940, tar: 0.000044 
l0: 0.000069, l1: 0.000072, l2: 0.000129, l3: 0.000226, l4: 0.000514, l5: 0.001514, l6: 0.003587

[epoch: 685/1000, batch:   752/ 1052, ite: 180080] train loss: 0.003952, tar: 0.000044 
l0: 0.000057, l1: 0.000057, l2: 0.000132, l3: 0.000355, l4: 0.000834, l5: 0.001932, l6: 0.003186

[epoch: 685/1000, batch:   832/ 1052, ite: 180100] train loss: 0.003953, tar: 0.000044 
l0: 0.000024, l1: 0.000025, l2: 0.000042, l3: 0.000171, l4: 0.000372, l5: 0.000462, l6: 0.001376

[epoch: 685/1000, batch:   912/ 1052, ite: 180120] train loss: 0.003944, tar: 0.000044 
l0: 0.000040, l1: 0.000038, l2: 0.000113, l3: 0.000341, l4: 0.000730, l5: 0.001355, l6: 0.002478

[epoch: 685/1000, batch:   992/ 1052, ite: 180140] train loss: 0.003946, tar: 0.000044 
[Epoch 685/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000036, l1: 0.000038, l2: 0.000071, l3: 0.000162, l4: 0.000474, l5: 0.001077, l6: 0.001449

[epoch: 686/1000, batch:    20/ 1052, ite: 180160] train loss: 0.003936, tar: 0.000044 
l0: 0.000022, l1: 0.000022, l2: 0.000062, l3: 0.000112, l4: 0.000419, l5: 0.000888, l6: 0.002742

[epoch: 686/1000, batch:   100/ 1052, ite: 180180] train loss: 0.003927, tar: 0.000043 
l0: 0.000031, l1: 0.000030, l2: 0.000050, l3: 0.000157, l4: 0.000604, l5: 0.000899, l6: 0.002026

[epoch: 686/1000, batch:   180/ 1052, ite: 180200] train loss: 0.003919, tar: 0.000043 
l0: 0.000027, l1: 0.000029, l2: 0.000115, l3: 0.000243, l4: 0.000610, l5: 0.001227, l6: 0.002446

[epoch: 686/1000, batch:   260/ 1052, ite: 180220] train loss: 0.003924, tar: 0.000043 
l0: 0.000107, l1: 0.000105, l2: 0.000157, l3: 0.000323, l4: 0.000747, l5: 0.001906, l6: 0.003185

[epoch: 686/1000, batch:   340/ 1052, ite: 180240] train loss: 0.003921, tar: 0.000043 
l0: 0.000007, l1: 0.000007, l2: 0.000038, l3: 0.000082, l4: 0.000268, l5: 0.000810, l6: 0.001271

[epoch: 686/1000, batch:   420/ 1052, ite: 180260] train loss: 0.003930, tar: 0.000043 
l0: 0.000084, l1: 0.000087, l2: 0.000158, l3: 0.000284, l4: 0.000535, l5: 0.000971, l6: 0.001890

[epoch: 686/1000, batch:   500/ 1052, ite: 180280] train loss: 0.003933, tar: 0.000043 
l0: 0.000031, l1: 0.000030, l2: 0.000059, l3: 0.000120, l4: 0.000398, l5: 0.000873, l6: 0.001049

[epoch: 686/1000, batch:   580/ 1052, ite: 180300] train loss: 0.003936, tar: 0.000043 
l0: 0.000066, l1: 0.000068, l2: 0.000108, l3: 0.000368, l4: 0.000644, l5: 0.001158, l6: 0.002059

[epoch: 686/1000, batch:   660/ 1052, ite: 180320] train loss: 0.003941, tar: 0.000044 
l0: 0.000018, l1: 0.000019, l2: 0.000086, l3: 0.000197, l4: 0.000367, l5: 0.000851, l6: 0.001662

[epoch: 686/1000, batch:   740/ 1052, ite: 180340] train loss: 0.003942, tar: 0.000044 
l0: 0.000019, l1: 0.000019, l2: 0.000070, l3: 0.000207, l4: 0.000654, l5: 0.001157, l6: 0.002037

[epoch: 686/1000, batch:   820/ 1052, ite: 180360] train loss: 0.003938, tar: 0.000044 
l0: 0.000006, l1: 0.000007, l2: 0.000035, l3: 0.000123, l4: 0.000370, l5: 0.000686, l6: 0.001060

[epoch: 686/1000, batch:   900/ 1052, ite: 180380] train loss: 0.003934, tar: 0.000043 
l0: 0.000033, l1: 0.000035, l2: 0.000031, l3: 0.000058, l4: 0.000271, l5: 0.000407, l6: 0.000598

[epoch: 686/1000, batch:   980/ 1052, ite: 180400] train loss: 0.003934, tar: 0.000043 
[Epoch 686/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000017, l1: 0.000017, l2: 0.000065, l3: 0.000207, l4: 0.000515, l5: 0.001085, l6: 0.001292

[epoch: 687/1000, batch:     8/ 1052, ite: 180420] train loss: 0.003935, tar: 0.000043 
l0: 0.000024, l1: 0.000025, l2: 0.000065, l3: 0.000133, l4: 0.000415, l5: 0.001189, l6: 0.002307

[epoch: 687/1000, batch:    88/ 1052, ite: 180440] train loss: 0.003933, tar: 0.000043 
l0: 0.000039, l1: 0.000037, l2: 0.000085, l3: 0.000161, l4: 0.000359, l5: 0.001185, l6: 0.002939

[epoch: 687/1000, batch:   168/ 1052, ite: 180460] train loss: 0.003931, tar: 0.000043 
l0: 0.000044, l1: 0.000046, l2: 0.000054, l3: 0.000095, l4: 0.000240, l5: 0.000583, l6: 0.001617

[epoch: 687/1000, batch:   248/ 1052, ite: 180480] train loss: 0.003931, tar: 0.000043 
l0: 0.000041, l1: 0.000038, l2: 0.000120, l3: 0.000212, l4: 0.000304, l5: 0.000651, l6: 0.001241

[epoch: 687/1000, batch:   328/ 1052, ite: 180500] train loss: 0.003929, tar: 0.000043 
l0: 0.000051, l1: 0.000053, l2: 0.000137, l3: 0.000198, l4: 0.000422, l5: 0.000953, l6: 0.002016

[epoch: 687/1000, batch:   408/ 1052, ite: 180520] train loss: 0.003926, tar: 0.000043 
l0: 0.000033, l1: 0.000033, l2: 0.000072, l3: 0.000210, l4: 0.000667, l5: 0.001525, l6: 0.001221

[epoch: 687/1000, batch:   488/ 1052, ite: 180540] train loss: 0.003932, tar: 0.000043 
l0: 0.000056, l1: 0.000059, l2: 0.000093, l3: 0.000213, l4: 0.000469, l5: 0.001318, l6: 0.001220

[epoch: 687/1000, batch:   568/ 1052, ite: 180560] train loss: 0.003941, tar: 0.000043 
l0: 0.000039, l1: 0.000042, l2: 0.000084, l3: 0.000138, l4: 0.000310, l5: 0.001044, l6: 0.001412

[epoch: 687/1000, batch:   648/ 1052, ite: 180580] train loss: 0.003938, tar: 0.000043 
l0: 0.000007, l1: 0.000007, l2: 0.000032, l3: 0.000350, l4: 0.000822, l5: 0.001156, l6: 0.002319

[epoch: 687/1000, batch:   728/ 1052, ite: 180600] train loss: 0.003936, tar: 0.000043 
l0: 0.000043, l1: 0.000048, l2: 0.000064, l3: 0.000146, l4: 0.000493, l5: 0.001197, l6: 0.002557

[epoch: 687/1000, batch:   808/ 1052, ite: 180620] train loss: 0.003934, tar: 0.000043 
l0: 0.000032, l1: 0.000031, l2: 0.000091, l3: 0.000185, l4: 0.000453, l5: 0.001344, l6: 0.001881

[epoch: 687/1000, batch:   888/ 1052, ite: 180640] train loss: 0.003937, tar: 0.000043 
l0: 0.000059, l1: 0.000064, l2: 0.000062, l3: 0.000114, l4: 0.000382, l5: 0.000740, l6: 0.001078

[epoch: 687/1000, batch:   968/ 1052, ite: 180660] train loss: 0.003940, tar: 0.000043 
l0: 0.000034, l1: 0.000036, l2: 0.000072, l3: 0.000159, l4: 0.000383, l5: 0.001144, l6: 0.001986

[epoch: 687/1000, batch:  1048/ 1052, ite: 180680] train loss: 0.003938, tar: 0.000043 
[Epoch 687/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000027, l1: 0.000028, l2: 0.000046, l3: 0.000101, l4: 0.000402, l5: 0.000676, l6: 0.001254

[epoch: 688/1000, batch:    76/ 1052, ite: 180700] train loss: 0.003936, tar: 0.000043 
l0: 0.000020, l1: 0.000019, l2: 0.000108, l3: 0.000181, l4: 0.000413, l5: 0.001128, l6: 0.002005

[epoch: 688/1000, batch:   156/ 1052, ite: 180720] train loss: 0.003944, tar: 0.000044 
l0: 0.000053, l1: 0.000056, l2: 0.000098, l3: 0.000217, l4: 0.000715, l5: 0.001780, l6: 0.003021

[epoch: 688/1000, batch:   236/ 1052, ite: 180740] train loss: 0.003947, tar: 0.000044 
l0: 0.000033, l1: 0.000035, l2: 0.000085, l3: 0.000343, l4: 0.000638, l5: 0.001439, l6: 0.002091

[epoch: 688/1000, batch:   316/ 1052, ite: 180760] train loss: 0.003946, tar: 0.000044 
l0: 0.000028, l1: 0.000026, l2: 0.000063, l3: 0.000131, l4: 0.000357, l5: 0.000590, l6: 0.001510

[epoch: 688/1000, batch:   396/ 1052, ite: 180780] train loss: 0.003945, tar: 0.000044 
l0: 0.000025, l1: 0.000024, l2: 0.000041, l3: 0.000138, l4: 0.000437, l5: 0.000988, l6: 0.001798

[epoch: 688/1000, batch:   476/ 1052, ite: 180800] train loss: 0.003944, tar: 0.000044 
l0: 0.000057, l1: 0.000057, l2: 0.000083, l3: 0.000143, l4: 0.000333, l5: 0.000785, l6: 0.002031

[epoch: 688/1000, batch:   556/ 1052, ite: 180820] train loss: 0.003939, tar: 0.000044 
l0: 0.000062, l1: 0.000061, l2: 0.000099, l3: 0.000241, l4: 0.000455, l5: 0.001071, l6: 0.002108

[epoch: 688/1000, batch:   636/ 1052, ite: 180840] train loss: 0.003940, tar: 0.000044 
l0: 0.000088, l1: 0.000094, l2: 0.000113, l3: 0.000219, l4: 0.000454, l5: 0.001356, l6: 0.003042

[epoch: 688/1000, batch:   716/ 1052, ite: 180860] train loss: 0.003941, tar: 0.000044 
l0: 0.000030, l1: 0.000030, l2: 0.000094, l3: 0.000323, l4: 0.000870, l5: 0.001270, l6: 0.002595

[epoch: 688/1000, batch:   796/ 1052, ite: 180880] train loss: 0.003942, tar: 0.000044 
l0: 0.000023, l1: 0.000025, l2: 0.000040, l3: 0.000160, l4: 0.000531, l5: 0.000914, l6: 0.001758

[epoch: 688/1000, batch:   876/ 1052, ite: 180900] train loss: 0.003943, tar: 0.000044 
l0: 0.000031, l1: 0.000032, l2: 0.000055, l3: 0.000170, l4: 0.000378, l5: 0.001058, l6: 0.001630

[epoch: 688/1000, batch:   956/ 1052, ite: 180920] train loss: 0.003938, tar: 0.000044 
l0: 0.000028, l1: 0.000030, l2: 0.000059, l3: 0.000157, l4: 0.000395, l5: 0.000608, l6: 0.001651

[epoch: 688/1000, batch:  1036/ 1052, ite: 180940] train loss: 0.003939, tar: 0.000044 
[Epoch 688/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000107, l1: 0.000110, l2: 0.000153, l3: 0.000285, l4: 0.000798, l5: 0.002037, l6: 0.004102

[epoch: 689/1000, batch:    64/ 1052, ite: 180960] train loss: 0.003943, tar: 0.000044 
l0: 0.000010, l1: 0.000009, l2: 0.000033, l3: 0.000095, l4: 0.000276, l5: 0.000915, l6: 0.001284

[epoch: 689/1000, batch:   144/ 1052, ite: 180980] train loss: 0.003942, tar: 0.000044 
l0: 0.000045, l1: 0.000047, l2: 0.000063, l3: 0.000199, l4: 0.000529, l5: 0.000629, l6: 0.001475

[epoch: 689/1000, batch:   224/ 1052, ite: 181000] train loss: 0.003943, tar: 0.000044 
l0: 0.000036, l1: 0.000039, l2: 0.000085, l3: 0.000196, l4: 0.000504, l5: 0.001124, l6: 0.001910

[epoch: 689/1000, batch:   304/ 1052, ite: 181020] train loss: 0.003940, tar: 0.000044 
l0: 0.000092, l1: 0.000094, l2: 0.000195, l3: 0.000344, l4: 0.000588, l5: 0.001322, l6: 0.003474

[epoch: 689/1000, batch:   384/ 1052, ite: 181040] train loss: 0.003942, tar: 0.000044 
l0: 0.000063, l1: 0.000066, l2: 0.000123, l3: 0.000304, l4: 0.000773, l5: 0.000924, l6: 0.002003

[epoch: 689/1000, batch:   464/ 1052, ite: 181060] train loss: 0.003946, tar: 0.000044 
l0: 0.000095, l1: 0.000093, l2: 0.000148, l3: 0.000270, l4: 0.000815, l5: 0.001345, l6: 0.002836

[epoch: 689/1000, batch:   544/ 1052, ite: 181080] train loss: 0.003950, tar: 0.000044 
l0: 0.000035, l1: 0.000040, l2: 0.000067, l3: 0.000163, l4: 0.000222, l5: 0.001102, l6: 0.001594

[epoch: 689/1000, batch:   624/ 1052, ite: 181100] train loss: 0.003945, tar: 0.000044 
l0: 0.000076, l1: 0.000078, l2: 0.000090, l3: 0.000174, l4: 0.000458, l5: 0.001258, l6: 0.003203

[epoch: 689/1000, batch:   704/ 1052, ite: 181120] train loss: 0.003944, tar: 0.000044 
l0: 0.000045, l1: 0.000046, l2: 0.000092, l3: 0.000125, l4: 0.000404, l5: 0.001046, l6: 0.002039

[epoch: 689/1000, batch:   784/ 1052, ite: 181140] train loss: 0.003946, tar: 0.000044 
l0: 0.000014, l1: 0.000016, l2: 0.000038, l3: 0.000095, l4: 0.000338, l5: 0.000525, l6: 0.001391

[epoch: 689/1000, batch:   864/ 1052, ite: 181160] train loss: 0.003944, tar: 0.000044 
l0: 0.000101, l1: 0.000100, l2: 0.000161, l3: 0.000326, l4: 0.000986, l5: 0.001862, l6: 0.003229

[epoch: 689/1000, batch:   944/ 1052, ite: 181180] train loss: 0.003944, tar: 0.000044 
l0: 0.000006, l1: 0.000007, l2: 0.000018, l3: 0.000081, l4: 0.000260, l5: 0.000835, l6: 0.001320

[epoch: 689/1000, batch:  1024/ 1052, ite: 181200] train loss: 0.003944, tar: 0.000044 
[Epoch 689/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000012, l1: 0.000013, l2: 0.000021, l3: 0.000072, l4: 0.000280, l5: 0.000729, l6: 0.001343

[epoch: 690/1000, batch:    52/ 1052, ite: 181220] train loss: 0.003944, tar: 0.000044 
l0: 0.000019, l1: 0.000018, l2: 0.000057, l3: 0.000224, l4: 0.000450, l5: 0.001044, l6: 0.001549

[epoch: 690/1000, batch:   132/ 1052, ite: 181240] train loss: 0.003945, tar: 0.000044 
l0: 0.000015, l1: 0.000016, l2: 0.000032, l3: 0.000077, l4: 0.000208, l5: 0.000912, l6: 0.001882

[epoch: 690/1000, batch:   212/ 1052, ite: 181260] train loss: 0.003942, tar: 0.000044 
l0: 0.000087, l1: 0.000088, l2: 0.000115, l3: 0.000220, l4: 0.000388, l5: 0.001279, l6: 0.001833

[epoch: 690/1000, batch:   292/ 1052, ite: 181280] train loss: 0.003944, tar: 0.000044 
l0: 0.000115, l1: 0.000114, l2: 0.000182, l3: 0.000348, l4: 0.000827, l5: 0.002012, l6: 0.003544

[epoch: 690/1000, batch:   372/ 1052, ite: 181300] train loss: 0.003945, tar: 0.000044 
l0: 0.000054, l1: 0.000061, l2: 0.000063, l3: 0.000157, l4: 0.000368, l5: 0.001384, l6: 0.001481

[epoch: 690/1000, batch:   452/ 1052, ite: 181320] train loss: 0.003945, tar: 0.000044 
l0: 0.000016, l1: 0.000018, l2: 0.000059, l3: 0.000180, l4: 0.000453, l5: 0.000721, l6: 0.001788

[epoch: 690/1000, batch:   532/ 1052, ite: 181340] train loss: 0.003942, tar: 0.000043 
l0: 0.000042, l1: 0.000039, l2: 0.000054, l3: 0.000147, l4: 0.000264, l5: 0.000866, l6: 0.000653

[epoch: 690/1000, batch:   612/ 1052, ite: 181360] train loss: 0.003940, tar: 0.000043 
l0: 0.000031, l1: 0.000031, l2: 0.000110, l3: 0.000212, l4: 0.000416, l5: 0.001452, l6: 0.002255

[epoch: 690/1000, batch:   692/ 1052, ite: 181380] train loss: 0.003939, tar: 0.000043 
l0: 0.000057, l1: 0.000055, l2: 0.000097, l3: 0.000203, l4: 0.000544, l5: 0.001081, l6: 0.002615

[epoch: 690/1000, batch:   772/ 1052, ite: 181400] train loss: 0.003942, tar: 0.000043 
l0: 0.000059, l1: 0.000058, l2: 0.000099, l3: 0.000233, l4: 0.000816, l5: 0.001667, l6: 0.003166

[epoch: 690/1000, batch:   852/ 1052, ite: 181420] train loss: 0.003945, tar: 0.000043 
l0: 0.000056, l1: 0.000056, l2: 0.000081, l3: 0.000189, l4: 0.000509, l5: 0.001167, l6: 0.001644

[epoch: 690/1000, batch:   932/ 1052, ite: 181440] train loss: 0.003947, tar: 0.000044 
l0: 0.000031, l1: 0.000031, l2: 0.000160, l3: 0.000646, l4: 0.001443, l5: 0.002589, l6: 0.003386

[epoch: 690/1000, batch:  1012/ 1052, ite: 181460] train loss: 0.003946, tar: 0.000044 
[Epoch 690/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000021, l1: 0.000023, l2: 0.000051, l3: 0.000201, l4: 0.000360, l5: 0.001153, l6: 0.001859

[epoch: 691/1000, batch:    40/ 1052, ite: 181480] train loss: 0.003948, tar: 0.000044 
l0: 0.000018, l1: 0.000018, l2: 0.000051, l3: 0.000155, l4: 0.000424, l5: 0.000812, l6: 0.001069

[epoch: 691/1000, batch:   120/ 1052, ite: 181500] train loss: 0.003948, tar: 0.000044 
l0: 0.000059, l1: 0.000057, l2: 0.000077, l3: 0.000125, l4: 0.000270, l5: 0.000772, l6: 0.002164

[epoch: 691/1000, batch:   200/ 1052, ite: 181520] train loss: 0.003947, tar: 0.000044 
l0: 0.000032, l1: 0.000034, l2: 0.000073, l3: 0.000174, l4: 0.000549, l5: 0.001213, l6: 0.001998

[epoch: 691/1000, batch:   280/ 1052, ite: 181540] train loss: 0.003948, tar: 0.000044 
l0: 0.000022, l1: 0.000020, l2: 0.000060, l3: 0.000162, l4: 0.000762, l5: 0.001140, l6: 0.002744

[epoch: 691/1000, batch:   360/ 1052, ite: 181560] train loss: 0.003953, tar: 0.000044 
l0: 0.000029, l1: 0.000031, l2: 0.000074, l3: 0.000207, l4: 0.000382, l5: 0.000754, l6: 0.001736

[epoch: 691/1000, batch:   440/ 1052, ite: 181580] train loss: 0.003953, tar: 0.000044 
l0: 0.000075, l1: 0.000077, l2: 0.000111, l3: 0.000225, l4: 0.000397, l5: 0.001398, l6: 0.002864

[epoch: 691/1000, batch:   520/ 1052, ite: 181600] train loss: 0.003954, tar: 0.000044 
l0: 0.000029, l1: 0.000026, l2: 0.000085, l3: 0.000168, l4: 0.000376, l5: 0.001322, l6: 0.002095

[epoch: 691/1000, batch:   600/ 1052, ite: 181620] train loss: 0.003953, tar: 0.000043 
l0: 0.000040, l1: 0.000038, l2: 0.000121, l3: 0.000325, l4: 0.000811, l5: 0.001083, l6: 0.002043

[epoch: 691/1000, batch:   680/ 1052, ite: 181640] train loss: 0.003950, tar: 0.000043 
l0: 0.000011, l1: 0.000011, l2: 0.000022, l3: 0.000095, l4: 0.000307, l5: 0.001326, l6: 0.002446

[epoch: 691/1000, batch:   760/ 1052, ite: 181660] train loss: 0.003946, tar: 0.000043 
l0: 0.000042, l1: 0.000045, l2: 0.000084, l3: 0.000147, l4: 0.000274, l5: 0.000746, l6: 0.001368

[epoch: 691/1000, batch:   840/ 1052, ite: 181680] train loss: 0.003945, tar: 0.000043 
l0: 0.000022, l1: 0.000023, l2: 0.000041, l3: 0.000064, l4: 0.000184, l5: 0.000628, l6: 0.001228

[epoch: 691/1000, batch:   920/ 1052, ite: 181700] train loss: 0.003945, tar: 0.000043 
l0: 0.000031, l1: 0.000032, l2: 0.000090, l3: 0.000260, l4: 0.000469, l5: 0.001211, l6: 0.001842

[epoch: 691/1000, batch:  1000/ 1052, ite: 181720] train loss: 0.003943, tar: 0.000043 
[Epoch 691/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000009, l1: 0.000010, l2: 0.000045, l3: 0.000160, l4: 0.000282, l5: 0.000688, l6: 0.001079

[epoch: 692/1000, batch:    28/ 1052, ite: 181740] train loss: 0.003939, tar: 0.000043 
l0: 0.000016, l1: 0.000016, l2: 0.000062, l3: 0.000124, l4: 0.000309, l5: 0.000730, l6: 0.001248

[epoch: 692/1000, batch:   108/ 1052, ite: 181760] train loss: 0.003935, tar: 0.000043 
l0: 0.000020, l1: 0.000018, l2: 0.000041, l3: 0.000082, l4: 0.000254, l5: 0.000837, l6: 0.001265

[epoch: 692/1000, batch:   188/ 1052, ite: 181780] train loss: 0.003934, tar: 0.000043 
l0: 0.000006, l1: 0.000005, l2: 0.000075, l3: 0.000164, l4: 0.000259, l5: 0.000518, l6: 0.002078

[epoch: 692/1000, batch:   268/ 1052, ite: 181800] train loss: 0.003938, tar: 0.000043 
l0: 0.000006, l1: 0.000005, l2: 0.000096, l3: 0.000329, l4: 0.000572, l5: 0.001497, l6: 0.002779

[epoch: 692/1000, batch:   348/ 1052, ite: 181820] train loss: 0.003941, tar: 0.000043 
l0: 0.000018, l1: 0.000020, l2: 0.000055, l3: 0.000143, l4: 0.000522, l5: 0.001061, l6: 0.002295

[epoch: 692/1000, batch:   428/ 1052, ite: 181840] train loss: 0.003942, tar: 0.000043 
l0: 0.000013, l1: 0.000014, l2: 0.000024, l3: 0.000125, l4: 0.000315, l5: 0.000553, l6: 0.001528

[epoch: 692/1000, batch:   508/ 1052, ite: 181860] train loss: 0.003940, tar: 0.000043 
l0: 0.000018, l1: 0.000018, l2: 0.000068, l3: 0.000197, l4: 0.000797, l5: 0.001560, l6: 0.002598

[epoch: 692/1000, batch:   588/ 1052, ite: 181880] train loss: 0.003944, tar: 0.000043 
l0: 0.000019, l1: 0.000020, l2: 0.000069, l3: 0.000142, l4: 0.000316, l5: 0.000636, l6: 0.001139

[epoch: 692/1000, batch:   668/ 1052, ite: 181900] train loss: 0.003945, tar: 0.000043 
l0: 0.000018, l1: 0.000018, l2: 0.000031, l3: 0.000096, l4: 0.000235, l5: 0.000616, l6: 0.000971

[epoch: 692/1000, batch:   748/ 1052, ite: 181920] train loss: 0.003945, tar: 0.000043 
l0: 0.000007, l1: 0.000008, l2: 0.000019, l3: 0.000082, l4: 0.000295, l5: 0.001398, l6: 0.002041

[epoch: 692/1000, batch:   828/ 1052, ite: 181940] train loss: 0.003945, tar: 0.000043 
l0: 0.000123, l1: 0.000129, l2: 0.000150, l3: 0.000261, l4: 0.000581, l5: 0.001473, l6: 0.001752

[epoch: 692/1000, batch:   908/ 1052, ite: 181960] train loss: 0.003943, tar: 0.000043 
l0: 0.000030, l1: 0.000030, l2: 0.000042, l3: 0.000210, l4: 0.000407, l5: 0.000770, l6: 0.001583

[epoch: 692/1000, batch:   988/ 1052, ite: 181980] train loss: 0.003942, tar: 0.000043 
[Epoch 692/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000014, l1: 0.000015, l2: 0.000030, l3: 0.000090, l4: 0.000264, l5: 0.000301, l6: 0.001149

[epoch: 693/1000, batch:    16/ 1052, ite: 182000] train loss: 0.003940, tar: 0.000043 
l0: 0.000014, l1: 0.000015, l2: 0.000036, l3: 0.000091, l4: 0.000417, l5: 0.000895, l6: 0.001583

[epoch: 693/1000, batch:    96/ 1052, ite: 182020] train loss: 0.003939, tar: 0.000043 
l0: 0.000013, l1: 0.000012, l2: 0.000030, l3: 0.000095, l4: 0.000393, l5: 0.000674, l6: 0.002055

[epoch: 693/1000, batch:   176/ 1052, ite: 182040] train loss: 0.003940, tar: 0.000043 
l0: 0.000024, l1: 0.000022, l2: 0.000035, l3: 0.000093, l4: 0.000494, l5: 0.000829, l6: 0.001593

[epoch: 693/1000, batch:   256/ 1052, ite: 182060] train loss: 0.003943, tar: 0.000043 
l0: 0.000025, l1: 0.000024, l2: 0.000078, l3: 0.000266, l4: 0.000709, l5: 0.001224, l6: 0.002839

[epoch: 693/1000, batch:   336/ 1052, ite: 182080] train loss: 0.003944, tar: 0.000043 
l0: 0.000033, l1: 0.000033, l2: 0.000049, l3: 0.000151, l4: 0.000447, l5: 0.001120, l6: 0.002210

[epoch: 693/1000, batch:   416/ 1052, ite: 182100] train loss: 0.003942, tar: 0.000043 
l0: 0.000033, l1: 0.000029, l2: 0.000092, l3: 0.000176, l4: 0.000474, l5: 0.001201, l6: 0.002039

[epoch: 693/1000, batch:   496/ 1052, ite: 182120] train loss: 0.003941, tar: 0.000043 
l0: 0.000016, l1: 0.000016, l2: 0.000052, l3: 0.000287, l4: 0.000921, l5: 0.001537, l6: 0.002925

[epoch: 693/1000, batch:   576/ 1052, ite: 182140] train loss: 0.003943, tar: 0.000043 
l0: 0.000022, l1: 0.000023, l2: 0.000059, l3: 0.000153, l4: 0.000451, l5: 0.000782, l6: 0.001738

[epoch: 693/1000, batch:   656/ 1052, ite: 182160] train loss: 0.003940, tar: 0.000043 
l0: 0.000042, l1: 0.000046, l2: 0.000089, l3: 0.000186, l4: 0.000341, l5: 0.001265, l6: 0.001243

[epoch: 693/1000, batch:   736/ 1052, ite: 182180] train loss: 0.003942, tar: 0.000043 
l0: 0.000058, l1: 0.000059, l2: 0.000060, l3: 0.000142, l4: 0.000490, l5: 0.001160, l6: 0.001514

[epoch: 693/1000, batch:   816/ 1052, ite: 182200] train loss: 0.003944, tar: 0.000043 
l0: 0.000020, l1: 0.000022, l2: 0.000025, l3: 0.000111, l4: 0.000247, l5: 0.000765, l6: 0.000882

[epoch: 693/1000, batch:   896/ 1052, ite: 182220] train loss: 0.003944, tar: 0.000043 
l0: 0.000041, l1: 0.000042, l2: 0.000146, l3: 0.000278, l4: 0.000748, l5: 0.001360, l6: 0.002135

[epoch: 693/1000, batch:   976/ 1052, ite: 182240] train loss: 0.003944, tar: 0.000043 
[Epoch 693/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000291, l1: 0.000282, l2: 0.000290, l3: 0.000337, l4: 0.000551, l5: 0.000938, l6: 0.001603

[epoch: 694/1000, batch:     4/ 1052, ite: 182260] train loss: 0.003943, tar: 0.000043 
l0: 0.000090, l1: 0.000092, l2: 0.000147, l3: 0.000333, l4: 0.000584, l5: 0.001299, l6: 0.001686

[epoch: 694/1000, batch:    84/ 1052, ite: 182280] train loss: 0.003946, tar: 0.000043 
l0: 0.000024, l1: 0.000022, l2: 0.000064, l3: 0.000112, l4: 0.000330, l5: 0.000752, l6: 0.000787

[epoch: 694/1000, batch:   164/ 1052, ite: 182300] train loss: 0.003945, tar: 0.000043 
l0: 0.000007, l1: 0.000006, l2: 0.000019, l3: 0.000128, l4: 0.000293, l5: 0.000508, l6: 0.000713

[epoch: 694/1000, batch:   244/ 1052, ite: 182320] train loss: 0.003944, tar: 0.000043 
l0: 0.000019, l1: 0.000022, l2: 0.000048, l3: 0.000215, l4: 0.000559, l5: 0.001137, l6: 0.001649

[epoch: 694/1000, batch:   324/ 1052, ite: 182340] train loss: 0.003944, tar: 0.000043 
l0: 0.000040, l1: 0.000040, l2: 0.000105, l3: 0.000229, l4: 0.000649, l5: 0.001466, l6: 0.001848

[epoch: 694/1000, batch:   404/ 1052, ite: 182360] train loss: 0.003945, tar: 0.000043 
l0: 0.000148, l1: 0.000142, l2: 0.000195, l3: 0.000280, l4: 0.000441, l5: 0.001910, l6: 0.002633

[epoch: 694/1000, batch:   484/ 1052, ite: 182380] train loss: 0.003947, tar: 0.000043 
l0: 0.000038, l1: 0.000038, l2: 0.000057, l3: 0.000159, l4: 0.000560, l5: 0.000865, l6: 0.001238

[epoch: 694/1000, batch:   564/ 1052, ite: 182400] train loss: 0.003946, tar: 0.000043 
l0: 0.000029, l1: 0.000034, l2: 0.000025, l3: 0.000112, l4: 0.000370, l5: 0.000832, l6: 0.001127

[epoch: 694/1000, batch:   644/ 1052, ite: 182420] train loss: 0.003945, tar: 0.000043 
l0: 0.000031, l1: 0.000033, l2: 0.000043, l3: 0.000120, l4: 0.000563, l5: 0.001011, l6: 0.002531

[epoch: 694/1000, batch:   724/ 1052, ite: 182440] train loss: 0.003947, tar: 0.000043 
l0: 0.000045, l1: 0.000044, l2: 0.000089, l3: 0.000211, l4: 0.000306, l5: 0.000893, l6: 0.001481

[epoch: 694/1000, batch:   804/ 1052, ite: 182460] train loss: 0.003946, tar: 0.000043 
l0: 0.000024, l1: 0.000026, l2: 0.000029, l3: 0.000114, l4: 0.000175, l5: 0.000834, l6: 0.000710

[epoch: 694/1000, batch:   884/ 1052, ite: 182480] train loss: 0.003943, tar: 0.000043 
l0: 0.000011, l1: 0.000013, l2: 0.000027, l3: 0.000112, l4: 0.000389, l5: 0.000857, l6: 0.001619

[epoch: 694/1000, batch:   964/ 1052, ite: 182500] train loss: 0.003943, tar: 0.000043 
l0: 0.000030, l1: 0.000029, l2: 0.000090, l3: 0.000216, l4: 0.000537, l5: 0.000993, l6: 0.001773

[epoch: 694/1000, batch:  1044/ 1052, ite: 182520] train loss: 0.003942, tar: 0.000043 
[Epoch 694/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000033, l1: 0.000032, l2: 0.000127, l3: 0.000253, l4: 0.000566, l5: 0.001005, l6: 0.001400

[epoch: 695/1000, batch:    72/ 1052, ite: 182540] train loss: 0.003940, tar: 0.000043 
l0: 0.000073, l1: 0.000074, l2: 0.000112, l3: 0.000296, l4: 0.000666, l5: 0.001281, l6: 0.002341

[epoch: 695/1000, batch:   152/ 1052, ite: 182560] train loss: 0.003939, tar: 0.000043 
l0: 0.000051, l1: 0.000050, l2: 0.000138, l3: 0.000181, l4: 0.000388, l5: 0.001018, l6: 0.001557

[epoch: 695/1000, batch:   232/ 1052, ite: 182580] train loss: 0.003937, tar: 0.000042 
l0: 0.000008, l1: 0.000008, l2: 0.000043, l3: 0.000133, l4: 0.000275, l5: 0.000800, l6: 0.001569

[epoch: 695/1000, batch:   312/ 1052, ite: 182600] train loss: 0.003936, tar: 0.000042 
l0: 0.000036, l1: 0.000038, l2: 0.000077, l3: 0.000130, l4: 0.000259, l5: 0.000847, l6: 0.001424

[epoch: 695/1000, batch:   392/ 1052, ite: 182620] train loss: 0.003937, tar: 0.000043 
l0: 0.000044, l1: 0.000046, l2: 0.000083, l3: 0.000240, l4: 0.000372, l5: 0.000824, l6: 0.001277

[epoch: 695/1000, batch:   472/ 1052, ite: 182640] train loss: 0.003940, tar: 0.000042 
l0: 0.000041, l1: 0.000041, l2: 0.000113, l3: 0.000325, l4: 0.000584, l5: 0.001221, l6: 0.001633

[epoch: 695/1000, batch:   552/ 1052, ite: 182660] train loss: 0.003940, tar: 0.000042 
l0: 0.000025, l1: 0.000023, l2: 0.000082, l3: 0.000130, l4: 0.000378, l5: 0.000836, l6: 0.001233

[epoch: 695/1000, batch:   632/ 1052, ite: 182680] train loss: 0.003942, tar: 0.000042 
l0: 0.000021, l1: 0.000021, l2: 0.000063, l3: 0.000163, l4: 0.000249, l5: 0.001343, l6: 0.001568

[epoch: 695/1000, batch:   712/ 1052, ite: 182700] train loss: 0.003942, tar: 0.000042 
l0: 0.000040, l1: 0.000041, l2: 0.000076, l3: 0.000176, l4: 0.000506, l5: 0.000913, l6: 0.002678

[epoch: 695/1000, batch:   792/ 1052, ite: 182720] train loss: 0.003940, tar: 0.000042 
l0: 0.000473, l1: 0.000448, l2: 0.000546, l3: 0.000764, l4: 0.001045, l5: 0.002548, l6: 0.003964

[epoch: 695/1000, batch:   872/ 1052, ite: 182740] train loss: 0.003941, tar: 0.000042 
l0: 0.000021, l1: 0.000021, l2: 0.000058, l3: 0.000131, l4: 0.000416, l5: 0.000573, l6: 0.002468

[epoch: 695/1000, batch:   952/ 1052, ite: 182760] train loss: 0.003941, tar: 0.000042 
l0: 0.000016, l1: 0.000017, l2: 0.000050, l3: 0.000224, l4: 0.000645, l5: 0.001524, l6: 0.001949

[epoch: 695/1000, batch:  1032/ 1052, ite: 182780] train loss: 0.003942, tar: 0.000042 
[Epoch 695/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000059, l1: 0.000062, l2: 0.000128, l3: 0.000315, l4: 0.000796, l5: 0.002187, l6: 0.003752

[epoch: 696/1000, batch:    60/ 1052, ite: 182800] train loss: 0.003943, tar: 0.000043 
l0: 0.000015, l1: 0.000012, l2: 0.000047, l3: 0.000117, l4: 0.000423, l5: 0.001092, l6: 0.002029

[epoch: 696/1000, batch:   140/ 1052, ite: 182820] train loss: 0.003942, tar: 0.000042 
l0: 0.000005, l1: 0.000005, l2: 0.000025, l3: 0.000107, l4: 0.000590, l5: 0.001322, l6: 0.002063

[epoch: 696/1000, batch:   220/ 1052, ite: 182840] train loss: 0.003942, tar: 0.000042 
l0: 0.000015, l1: 0.000014, l2: 0.000047, l3: 0.000113, l4: 0.000288, l5: 0.000944, l6: 0.000981

[epoch: 696/1000, batch:   300/ 1052, ite: 182860] train loss: 0.003942, tar: 0.000042 
l0: 0.000063, l1: 0.000062, l2: 0.000109, l3: 0.000190, l4: 0.000400, l5: 0.001828, l6: 0.002795

[epoch: 696/1000, batch:   380/ 1052, ite: 182880] train loss: 0.003943, tar: 0.000042 
l0: 0.000017, l1: 0.000018, l2: 0.000031, l3: 0.000081, l4: 0.000412, l5: 0.000831, l6: 0.001378

[epoch: 696/1000, batch:   460/ 1052, ite: 182900] train loss: 0.003942, tar: 0.000042 
l0: 0.000032, l1: 0.000035, l2: 0.000068, l3: 0.000230, l4: 0.000743, l5: 0.001283, l6: 0.001597

[epoch: 696/1000, batch:   540/ 1052, ite: 182920] train loss: 0.003943, tar: 0.000042 
l0: 0.000022, l1: 0.000019, l2: 0.000064, l3: 0.000084, l4: 0.000159, l5: 0.000644, l6: 0.001050

[epoch: 696/1000, batch:   620/ 1052, ite: 182940] train loss: 0.003942, tar: 0.000042 
l0: 0.000030, l1: 0.000038, l2: 0.000056, l3: 0.000158, l4: 0.000238, l5: 0.000722, l6: 0.001809

[epoch: 696/1000, batch:   700/ 1052, ite: 182960] train loss: 0.003941, tar: 0.000042 
l0: 0.000070, l1: 0.000067, l2: 0.000135, l3: 0.000324, l4: 0.000566, l5: 0.001250, l6: 0.002236

[epoch: 696/1000, batch:   780/ 1052, ite: 182980] train loss: 0.003941, tar: 0.000042 
l0: 0.000019, l1: 0.000018, l2: 0.000051, l3: 0.000133, l4: 0.000531, l5: 0.000733, l6: 0.001620

[epoch: 696/1000, batch:   860/ 1052, ite: 183000] train loss: 0.003941, tar: 0.000042 
l0: 0.000037, l1: 0.000035, l2: 0.000060, l3: 0.000144, l4: 0.000360, l5: 0.000835, l6: 0.002083

[epoch: 696/1000, batch:   940/ 1052, ite: 183020] train loss: 0.003941, tar: 0.000042 
l0: 0.000037, l1: 0.000036, l2: 0.000096, l3: 0.000200, l4: 0.000402, l5: 0.000805, l6: 0.002064

[epoch: 696/1000, batch:  1020/ 1052, ite: 183040] train loss: 0.003942, tar: 0.000042 
[Epoch 696/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000036, l1: 0.000035, l2: 0.000084, l3: 0.000153, l4: 0.000682, l5: 0.001751, l6: 0.002046

[epoch: 697/1000, batch:    48/ 1052, ite: 183060] train loss: 0.003941, tar: 0.000042 
l0: 0.000074, l1: 0.000074, l2: 0.000130, l3: 0.000216, l4: 0.000405, l5: 0.001157, l6: 0.002194

[epoch: 697/1000, batch:   128/ 1052, ite: 183080] train loss: 0.003940, tar: 0.000042 
l0: 0.000013, l1: 0.000012, l2: 0.000038, l3: 0.000134, l4: 0.000265, l5: 0.000798, l6: 0.001412

[epoch: 697/1000, batch:   208/ 1052, ite: 183100] train loss: 0.003940, tar: 0.000042 
l0: 0.000104, l1: 0.000097, l2: 0.000134, l3: 0.000195, l4: 0.000427, l5: 0.000669, l6: 0.001499

[epoch: 697/1000, batch:   288/ 1052, ite: 183120] train loss: 0.003942, tar: 0.000042 
l0: 0.000017, l1: 0.000018, l2: 0.000031, l3: 0.000103, l4: 0.000349, l5: 0.000974, l6: 0.001150

[epoch: 697/1000, batch:   368/ 1052, ite: 183140] train loss: 0.003942, tar: 0.000042 
l0: 0.000026, l1: 0.000026, l2: 0.000053, l3: 0.000162, l4: 0.000543, l5: 0.001025, l6: 0.001590

[epoch: 697/1000, batch:   448/ 1052, ite: 183160] train loss: 0.003940, tar: 0.000042 
l0: 0.000053, l1: 0.000057, l2: 0.000104, l3: 0.000171, l4: 0.000689, l5: 0.001099, l6: 0.002278

[epoch: 697/1000, batch:   528/ 1052, ite: 183180] train loss: 0.003940, tar: 0.000042 
l0: 0.000017, l1: 0.000016, l2: 0.000054, l3: 0.000119, l4: 0.000443, l5: 0.000875, l6: 0.001193

[epoch: 697/1000, batch:   608/ 1052, ite: 183200] train loss: 0.003941, tar: 0.000042 
l0: 0.000010, l1: 0.000008, l2: 0.000048, l3: 0.000091, l4: 0.000240, l5: 0.000529, l6: 0.001067

[epoch: 697/1000, batch:   688/ 1052, ite: 183220] train loss: 0.003938, tar: 0.000042 
l0: 0.000025, l1: 0.000025, l2: 0.000042, l3: 0.000123, l4: 0.000390, l5: 0.001094, l6: 0.001622

[epoch: 697/1000, batch:   768/ 1052, ite: 183240] train loss: 0.003938, tar: 0.000042 
l0: 0.000044, l1: 0.000048, l2: 0.000061, l3: 0.000098, l4: 0.000366, l5: 0.000803, l6: 0.001247

[epoch: 697/1000, batch:   848/ 1052, ite: 183260] train loss: 0.003940, tar: 0.000042 
l0: 0.000050, l1: 0.000052, l2: 0.000154, l3: 0.000433, l4: 0.000812, l5: 0.001629, l6: 0.003030

[epoch: 697/1000, batch:   928/ 1052, ite: 183280] train loss: 0.003942, tar: 0.000042 
l0: 0.000018, l1: 0.000019, l2: 0.000041, l3: 0.000138, l4: 0.000355, l5: 0.000433, l6: 0.002574

[epoch: 697/1000, batch:  1008/ 1052, ite: 183300] train loss: 0.003941, tar: 0.000042 
[Epoch 697/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000011, l1: 0.000011, l2: 0.000022, l3: 0.000087, l4: 0.000492, l5: 0.000763, l6: 0.001624

[epoch: 698/1000, batch:    36/ 1052, ite: 183320] train loss: 0.003942, tar: 0.000042 
l0: 0.000027, l1: 0.000032, l2: 0.000093, l3: 0.000417, l4: 0.001025, l5: 0.001535, l6: 0.002362

[epoch: 698/1000, batch:   116/ 1052, ite: 183340] train loss: 0.003943, tar: 0.000042 
l0: 0.000022, l1: 0.000021, l2: 0.000086, l3: 0.000144, l4: 0.000433, l5: 0.001038, l6: 0.001538

[epoch: 698/1000, batch:   196/ 1052, ite: 183360] train loss: 0.003942, tar: 0.000042 
l0: 0.000017, l1: 0.000020, l2: 0.000080, l3: 0.000262, l4: 0.000694, l5: 0.001631, l6: 0.001968

[epoch: 698/1000, batch:   276/ 1052, ite: 183380] train loss: 0.003940, tar: 0.000042 
l0: 0.000018, l1: 0.000017, l2: 0.000052, l3: 0.000190, l4: 0.000507, l5: 0.001458, l6: 0.002068

[epoch: 698/1000, batch:   356/ 1052, ite: 183400] train loss: 0.003944, tar: 0.000042 
l0: 0.000165, l1: 0.000171, l2: 0.000228, l3: 0.000347, l4: 0.000694, l5: 0.002563, l6: 0.002785

[epoch: 698/1000, batch:   436/ 1052, ite: 183420] train loss: 0.003945, tar: 0.000042 
l0: 0.000011, l1: 0.000012, l2: 0.000039, l3: 0.000154, l4: 0.000276, l5: 0.000936, l6: 0.001713

[epoch: 698/1000, batch:   516/ 1052, ite: 183440] train loss: 0.003946, tar: 0.000042 
l0: 0.000081, l1: 0.000084, l2: 0.000147, l3: 0.000271, l4: 0.000531, l5: 0.001472, l6: 0.001905

[epoch: 698/1000, batch:   596/ 1052, ite: 183460] train loss: 0.003946, tar: 0.000042 
l0: 0.000002, l1: 0.000002, l2: 0.000021, l3: 0.000088, l4: 0.000257, l5: 0.000944, l6: 0.001853

[epoch: 698/1000, batch:   676/ 1052, ite: 183480] train loss: 0.003946, tar: 0.000042 
l0: 0.000026, l1: 0.000029, l2: 0.000080, l3: 0.000286, l4: 0.000589, l5: 0.001179, l6: 0.002082

[epoch: 698/1000, batch:   756/ 1052, ite: 183500] train loss: 0.003947, tar: 0.000042 
l0: 0.000078, l1: 0.000083, l2: 0.000077, l3: 0.000125, l4: 0.000271, l5: 0.000976, l6: 0.002101

[epoch: 698/1000, batch:   836/ 1052, ite: 183520] train loss: 0.003948, tar: 0.000042 
l0: 0.000038, l1: 0.000037, l2: 0.000079, l3: 0.000268, l4: 0.000454, l5: 0.001072, l6: 0.001733

[epoch: 698/1000, batch:   916/ 1052, ite: 183540] train loss: 0.003948, tar: 0.000042 
l0: 0.000018, l1: 0.000019, l2: 0.000057, l3: 0.000143, l4: 0.000392, l5: 0.000877, l6: 0.001754

[epoch: 698/1000, batch:   996/ 1052, ite: 183560] train loss: 0.003946, tar: 0.000042 
[Epoch 698/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000019, l1: 0.000016, l2: 0.000051, l3: 0.000123, l4: 0.000370, l5: 0.000890, l6: 0.001256

[epoch: 699/1000, batch:    24/ 1052, ite: 183580] train loss: 0.003946, tar: 0.000042 
l0: 0.000062, l1: 0.000063, l2: 0.000149, l3: 0.000358, l4: 0.000778, l5: 0.001951, l6: 0.003006

[epoch: 699/1000, batch:   104/ 1052, ite: 183600] train loss: 0.003945, tar: 0.000042 
l0: 0.000007, l1: 0.000006, l2: 0.000036, l3: 0.000102, l4: 0.000358, l5: 0.000441, l6: 0.001343

[epoch: 699/1000, batch:   184/ 1052, ite: 183620] train loss: 0.003944, tar: 0.000042 
l0: 0.000020, l1: 0.000019, l2: 0.000083, l3: 0.000212, l4: 0.000557, l5: 0.001101, l6: 0.001890

[epoch: 699/1000, batch:   264/ 1052, ite: 183640] train loss: 0.003944, tar: 0.000042 
l0: 0.000077, l1: 0.000078, l2: 0.000142, l3: 0.000189, l4: 0.000520, l5: 0.001239, l6: 0.002875

[epoch: 699/1000, batch:   344/ 1052, ite: 183660] train loss: 0.003944, tar: 0.000042 
l0: 0.000033, l1: 0.000032, l2: 0.000081, l3: 0.000145, l4: 0.000388, l5: 0.000927, l6: 0.002145

[epoch: 699/1000, batch:   424/ 1052, ite: 183680] train loss: 0.003944, tar: 0.000042 
l0: 0.000012, l1: 0.000012, l2: 0.000040, l3: 0.000111, l4: 0.000294, l5: 0.000685, l6: 0.001151

[epoch: 699/1000, batch:   504/ 1052, ite: 183700] train loss: 0.003944, tar: 0.000042 
l0: 0.000020, l1: 0.000021, l2: 0.000041, l3: 0.000066, l4: 0.000243, l5: 0.000644, l6: 0.001562

[epoch: 699/1000, batch:   584/ 1052, ite: 183720] train loss: 0.003944, tar: 0.000042 
l0: 0.000009, l1: 0.000010, l2: 0.000034, l3: 0.000124, l4: 0.000329, l5: 0.000644, l6: 0.001595

[epoch: 699/1000, batch:   664/ 1052, ite: 183740] train loss: 0.003944, tar: 0.000042 
l0: 0.000053, l1: 0.000059, l2: 0.000089, l3: 0.000233, l4: 0.000606, l5: 0.001598, l6: 0.002887

[epoch: 699/1000, batch:   744/ 1052, ite: 183760] train loss: 0.003943, tar: 0.000042 
l0: 0.000060, l1: 0.000061, l2: 0.000083, l3: 0.000331, l4: 0.000469, l5: 0.001635, l6: 0.002440

[epoch: 699/1000, batch:   824/ 1052, ite: 183780] train loss: 0.003945, tar: 0.000042 
l0: 0.000078, l1: 0.000083, l2: 0.000158, l3: 0.000335, l4: 0.000618, l5: 0.001643, l6: 0.002844

[epoch: 699/1000, batch:   904/ 1052, ite: 183800] train loss: 0.003946, tar: 0.000042 
l0: 0.000064, l1: 0.000068, l2: 0.000110, l3: 0.000274, l4: 0.000911, l5: 0.001411, l6: 0.003043

[epoch: 699/1000, batch:   984/ 1052, ite: 183820] train loss: 0.003944, tar: 0.000042 
[Epoch 699/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000061, l1: 0.000062, l2: 0.000090, l3: 0.000176, l4: 0.000447, l5: 0.001146, l6: 0.001399

[epoch: 700/1000, batch:    12/ 1052, ite: 183840] train loss: 0.003946, tar: 0.000042 
l0: 0.000012, l1: 0.000011, l2: 0.000060, l3: 0.000187, l4: 0.000355, l5: 0.000919, l6: 0.001898

[epoch: 700/1000, batch:    92/ 1052, ite: 183860] train loss: 0.003945, tar: 0.000042 
l0: 0.000018, l1: 0.000019, l2: 0.000030, l3: 0.000059, l4: 0.000382, l5: 0.001036, l6: 0.001357

[epoch: 700/1000, batch:   172/ 1052, ite: 183880] train loss: 0.003944, tar: 0.000042 
l0: 0.000040, l1: 0.000042, l2: 0.000047, l3: 0.000096, l4: 0.000272, l5: 0.001156, l6: 0.001821

[epoch: 700/1000, batch:   252/ 1052, ite: 183900] train loss: 0.003944, tar: 0.000042 
l0: 0.000197, l1: 0.000200, l2: 0.000272, l3: 0.000303, l4: 0.000702, l5: 0.002124, l6: 0.002207

[epoch: 700/1000, batch:   332/ 1052, ite: 183920] train loss: 0.003943, tar: 0.000042 
l0: 0.000028, l1: 0.000028, l2: 0.000045, l3: 0.000081, l4: 0.000320, l5: 0.000638, l6: 0.001249

[epoch: 700/1000, batch:   412/ 1052, ite: 183940] train loss: 0.003942, tar: 0.000042 
l0: 0.000058, l1: 0.000064, l2: 0.000096, l3: 0.000296, l4: 0.000892, l5: 0.002145, l6: 0.003122

[epoch: 700/1000, batch:   492/ 1052, ite: 183960] train loss: 0.003940, tar: 0.000042 
l0: 0.000034, l1: 0.000033, l2: 0.000055, l3: 0.000122, l4: 0.000371, l5: 0.000972, l6: 0.001847

[epoch: 700/1000, batch:   572/ 1052, ite: 183980] train loss: 0.003939, tar: 0.000042 
l0: 0.000037, l1: 0.000037, l2: 0.000071, l3: 0.000184, l4: 0.000974, l5: 0.001015, l6: 0.003214

[epoch: 700/1000, batch:   652/ 1052, ite: 184000] train loss: 0.003938, tar: 0.000042 
l0: 0.000005, l1: 0.000004, l2: 0.000038, l3: 0.000116, l4: 0.000332, l5: 0.000664, l6: 0.001062

[epoch: 700/1000, batch:   732/ 1052, ite: 184020] train loss: 0.003939, tar: 0.000042 
l0: 0.000012, l1: 0.000012, l2: 0.000021, l3: 0.000077, l4: 0.000330, l5: 0.000576, l6: 0.000926

[epoch: 700/1000, batch:   812/ 1052, ite: 184040] train loss: 0.003939, tar: 0.000042 
l0: 0.000018, l1: 0.000020, l2: 0.000061, l3: 0.000153, l4: 0.000438, l5: 0.000991, l6: 0.001574

[epoch: 700/1000, batch:   892/ 1052, ite: 184060] train loss: 0.003939, tar: 0.000042 
l0: 0.000002, l1: 0.000002, l2: 0.000017, l3: 0.000056, l4: 0.000203, l5: 0.000998, l6: 0.001811

[epoch: 700/1000, batch:   972/ 1052, ite: 184080] train loss: 0.003941, tar: 0.000042 
l0: 0.000026, l1: 0.000027, l2: 0.000047, l3: 0.000149, l4: 0.000539, l5: 0.000896, l6: 0.001657

[epoch: 700/1000, batch:  1052/ 1052, ite: 184100] train loss: 0.003943, tar: 0.000042 
[Epoch 700/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000053, l1: 0.000053, l2: 0.000073, l3: 0.000229, l4: 0.000425, l5: 0.001029, l6: 0.001352

[epoch: 701/1000, batch:    80/ 1052, ite: 184120] train loss: 0.003942, tar: 0.000042 
l0: 0.000066, l1: 0.000070, l2: 0.000082, l3: 0.000254, l4: 0.000641, l5: 0.001272, l6: 0.001638

[epoch: 701/1000, batch:   160/ 1052, ite: 184140] train loss: 0.003944, tar: 0.000042 
l0: 0.000080, l1: 0.000079, l2: 0.000112, l3: 0.000272, l4: 0.000700, l5: 0.001199, l6: 0.002141

[epoch: 701/1000, batch:   240/ 1052, ite: 184160] train loss: 0.003948, tar: 0.000042 
l0: 0.000008, l1: 0.000009, l2: 0.000047, l3: 0.000120, l4: 0.000302, l5: 0.001006, l6: 0.001348

[epoch: 701/1000, batch:   320/ 1052, ite: 184180] train loss: 0.003945, tar: 0.000042 
l0: 0.000024, l1: 0.000026, l2: 0.000052, l3: 0.000176, l4: 0.000504, l5: 0.001223, l6: 0.002217

[epoch: 701/1000, batch:   400/ 1052, ite: 184200] train loss: 0.003945, tar: 0.000042 
l0: 0.000029, l1: 0.000029, l2: 0.000084, l3: 0.000153, l4: 0.000370, l5: 0.000873, l6: 0.001221

[epoch: 701/1000, batch:   480/ 1052, ite: 184220] train loss: 0.003945, tar: 0.000042 
l0: 0.000123, l1: 0.000127, l2: 0.000142, l3: 0.000250, l4: 0.000889, l5: 0.001356, l6: 0.003365

[epoch: 701/1000, batch:   560/ 1052, ite: 184240] train loss: 0.003945, tar: 0.000042 
l0: 0.000030, l1: 0.000032, l2: 0.000059, l3: 0.000116, l4: 0.000237, l5: 0.000992, l6: 0.001573

[epoch: 701/1000, batch:   640/ 1052, ite: 184260] train loss: 0.003946, tar: 0.000042 
l0: 0.000049, l1: 0.000047, l2: 0.000083, l3: 0.000209, l4: 0.000660, l5: 0.001351, l6: 0.001293

[epoch: 701/1000, batch:   720/ 1052, ite: 184280] train loss: 0.003943, tar: 0.000042 
l0: 0.000027, l1: 0.000030, l2: 0.000111, l3: 0.000308, l4: 0.000880, l5: 0.001268, l6: 0.003140

[epoch: 701/1000, batch:   800/ 1052, ite: 184300] train loss: 0.003945, tar: 0.000042 
l0: 0.000039, l1: 0.000039, l2: 0.000080, l3: 0.000201, l4: 0.000380, l5: 0.000767, l6: 0.001968

[epoch: 701/1000, batch:   880/ 1052, ite: 184320] train loss: 0.003944, tar: 0.000042 
l0: 0.000054, l1: 0.000055, l2: 0.000078, l3: 0.000211, l4: 0.000524, l5: 0.000989, l6: 0.001742

[epoch: 701/1000, batch:   960/ 1052, ite: 184340] train loss: 0.003943, tar: 0.000042 
l0: 0.000034, l1: 0.000034, l2: 0.000045, l3: 0.000093, l4: 0.000363, l5: 0.000742, l6: 0.001532

[epoch: 701/1000, batch:  1040/ 1052, ite: 184360] train loss: 0.003944, tar: 0.000042 
[Epoch 701/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000051, l1: 0.000054, l2: 0.000066, l3: 0.000129, l4: 0.000315, l5: 0.001050, l6: 0.001185

[epoch: 702/1000, batch:    68/ 1052, ite: 184380] train loss: 0.003942, tar: 0.000042 
l0: 0.000055, l1: 0.000057, l2: 0.000055, l3: 0.000140, l4: 0.000297, l5: 0.000901, l6: 0.002354

[epoch: 702/1000, batch:   148/ 1052, ite: 184400] train loss: 0.003943, tar: 0.000042 
l0: 0.000009, l1: 0.000010, l2: 0.000018, l3: 0.000049, l4: 0.000220, l5: 0.000778, l6: 0.001112

[epoch: 702/1000, batch:   228/ 1052, ite: 184420] train loss: 0.003940, tar: 0.000042 
l0: 0.000018, l1: 0.000019, l2: 0.000053, l3: 0.000219, l4: 0.000305, l5: 0.000931, l6: 0.001438

[epoch: 702/1000, batch:   308/ 1052, ite: 184440] train loss: 0.003940, tar: 0.000042 
l0: 0.000021, l1: 0.000022, l2: 0.000079, l3: 0.000240, l4: 0.000474, l5: 0.000780, l6: 0.001918

[epoch: 702/1000, batch:   388/ 1052, ite: 184460] train loss: 0.003942, tar: 0.000042 
l0: 0.000026, l1: 0.000027, l2: 0.000042, l3: 0.000072, l4: 0.000233, l5: 0.000734, l6: 0.001147

[epoch: 702/1000, batch:   468/ 1052, ite: 184480] train loss: 0.003942, tar: 0.000042 
l0: 0.000043, l1: 0.000042, l2: 0.000082, l3: 0.000220, l4: 0.000596, l5: 0.000979, l6: 0.001362

[epoch: 702/1000, batch:   548/ 1052, ite: 184500] train loss: 0.003940, tar: 0.000042 
l0: 0.000033, l1: 0.000035, l2: 0.000078, l3: 0.000146, l4: 0.000401, l5: 0.001004, l6: 0.002492

[epoch: 702/1000, batch:   628/ 1052, ite: 184520] train loss: 0.003940, tar: 0.000042 
l0: 0.000023, l1: 0.000023, l2: 0.000068, l3: 0.000152, l4: 0.000302, l5: 0.001173, l6: 0.002314

[epoch: 702/1000, batch:   708/ 1052, ite: 184540] train loss: 0.003940, tar: 0.000042 
l0: 0.000010, l1: 0.000011, l2: 0.000034, l3: 0.000109, l4: 0.000254, l5: 0.000779, l6: 0.001519

[epoch: 702/1000, batch:   788/ 1052, ite: 184560] train loss: 0.003939, tar: 0.000042 
l0: 0.000029, l1: 0.000027, l2: 0.000078, l3: 0.000137, l4: 0.000376, l5: 0.000706, l6: 0.001357

[epoch: 702/1000, batch:   868/ 1052, ite: 184580] train loss: 0.003941, tar: 0.000042 
l0: 0.000037, l1: 0.000035, l2: 0.000045, l3: 0.000058, l4: 0.000119, l5: 0.000498, l6: 0.000675

[epoch: 702/1000, batch:   948/ 1052, ite: 184600] train loss: 0.003942, tar: 0.000042 
l0: 0.000010, l1: 0.000011, l2: 0.000037, l3: 0.000130, l4: 0.000191, l5: 0.000841, l6: 0.001941

[epoch: 702/1000, batch:  1028/ 1052, ite: 184620] train loss: 0.003941, tar: 0.000042 
[Epoch 702/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000016, l1: 0.000016, l2: 0.000056, l3: 0.000220, l4: 0.000479, l5: 0.001142, l6: 0.002079

[epoch: 703/1000, batch:    56/ 1052, ite: 184640] train loss: 0.003940, tar: 0.000042 
l0: 0.000049, l1: 0.000047, l2: 0.000089, l3: 0.000202, l4: 0.000432, l5: 0.001361, l6: 0.001726

[epoch: 703/1000, batch:   136/ 1052, ite: 184660] train loss: 0.003940, tar: 0.000042 
l0: 0.000039, l1: 0.000038, l2: 0.000122, l3: 0.000242, l4: 0.000540, l5: 0.001468, l6: 0.003320

[epoch: 703/1000, batch:   216/ 1052, ite: 184680] train loss: 0.003937, tar: 0.000042 
l0: 0.000022, l1: 0.000022, l2: 0.000041, l3: 0.000087, l4: 0.000250, l5: 0.000784, l6: 0.001901

[epoch: 703/1000, batch:   296/ 1052, ite: 184700] train loss: 0.003937, tar: 0.000042 
l0: 0.000004, l1: 0.000004, l2: 0.000049, l3: 0.000127, l4: 0.000211, l5: 0.000572, l6: 0.001007

[epoch: 703/1000, batch:   376/ 1052, ite: 184720] train loss: 0.003935, tar: 0.000042 
l0: 0.000062, l1: 0.000056, l2: 0.000082, l3: 0.000198, l4: 0.000541, l5: 0.000949, l6: 0.001479

[epoch: 703/1000, batch:   456/ 1052, ite: 184740] train loss: 0.003937, tar: 0.000042 
l0: 0.000095, l1: 0.000097, l2: 0.000097, l3: 0.000140, l4: 0.000297, l5: 0.001257, l6: 0.001221

[epoch: 703/1000, batch:   536/ 1052, ite: 184760] train loss: 0.003937, tar: 0.000042 
l0: 0.000089, l1: 0.000097, l2: 0.000152, l3: 0.000264, l4: 0.000746, l5: 0.001736, l6: 0.002997

[epoch: 703/1000, batch:   616/ 1052, ite: 184780] train loss: 0.003938, tar: 0.000042 
l0: 0.000021, l1: 0.000021, l2: 0.000088, l3: 0.000240, l4: 0.000624, l5: 0.001434, l6: 0.002706

[epoch: 703/1000, batch:   696/ 1052, ite: 184800] train loss: 0.003938, tar: 0.000042 
l0: 0.000077, l1: 0.000082, l2: 0.000112, l3: 0.000166, l4: 0.000584, l5: 0.001391, l6: 0.002145

[epoch: 703/1000, batch:   776/ 1052, ite: 184820] train loss: 0.003937, tar: 0.000042 
l0: 0.000124, l1: 0.000130, l2: 0.000096, l3: 0.000229, l4: 0.000681, l5: 0.001428, l6: 0.002429

[epoch: 703/1000, batch:   856/ 1052, ite: 184840] train loss: 0.003938, tar: 0.000042 
l0: 0.000021, l1: 0.000022, l2: 0.000045, l3: 0.000158, l4: 0.000445, l5: 0.001234, l6: 0.002099

[epoch: 703/1000, batch:   936/ 1052, ite: 184860] train loss: 0.003939, tar: 0.000042 
l0: 0.000058, l1: 0.000061, l2: 0.000095, l3: 0.000164, l4: 0.000324, l5: 0.001084, l6: 0.002652

[epoch: 703/1000, batch:  1016/ 1052, ite: 184880] train loss: 0.003940, tar: 0.000042 
[Epoch 703/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000040, l1: 0.000040, l2: 0.000069, l3: 0.000173, l4: 0.000570, l5: 0.001154, l6: 0.002342

[epoch: 704/1000, batch:    44/ 1052, ite: 184900] train loss: 0.003939, tar: 0.000042 
l0: 0.000015, l1: 0.000016, l2: 0.000047, l3: 0.000161, l4: 0.000598, l5: 0.001847, l6: 0.003688

[epoch: 704/1000, batch:   124/ 1052, ite: 184920] train loss: 0.003941, tar: 0.000042 
l0: 0.000029, l1: 0.000030, l2: 0.000061, l3: 0.000252, l4: 0.000458, l5: 0.000650, l6: 0.001604

[epoch: 704/1000, batch:   204/ 1052, ite: 184940] train loss: 0.003940, tar: 0.000042 
l0: 0.000036, l1: 0.000036, l2: 0.000075, l3: 0.000149, l4: 0.000545, l5: 0.001077, l6: 0.001379

[epoch: 704/1000, batch:   284/ 1052, ite: 184960] train loss: 0.003940, tar: 0.000042 
l0: 0.000073, l1: 0.000080, l2: 0.000078, l3: 0.000176, l4: 0.000269, l5: 0.000676, l6: 0.001480

[epoch: 704/1000, batch:   364/ 1052, ite: 184980] train loss: 0.003940, tar: 0.000042 
l0: 0.000013, l1: 0.000014, l2: 0.000059, l3: 0.000158, l4: 0.000466, l5: 0.001096, l6: 0.001974

[epoch: 704/1000, batch:   444/ 1052, ite: 185000] train loss: 0.003940, tar: 0.000042 
l0: 0.000024, l1: 0.000024, l2: 0.000072, l3: 0.000244, l4: 0.000455, l5: 0.001219, l6: 0.002641

[epoch: 704/1000, batch:   524/ 1052, ite: 185020] train loss: 0.003940, tar: 0.000042 
l0: 0.000010, l1: 0.000011, l2: 0.000055, l3: 0.000135, l4: 0.000302, l5: 0.000826, l6: 0.001772

[epoch: 704/1000, batch:   604/ 1052, ite: 185040] train loss: 0.003939, tar: 0.000042 
l0: 0.000041, l1: 0.000043, l2: 0.000085, l3: 0.000142, l4: 0.000334, l5: 0.001458, l6: 0.001809

[epoch: 704/1000, batch:   684/ 1052, ite: 185060] train loss: 0.003939, tar: 0.000042 
l0: 0.000047, l1: 0.000051, l2: 0.000029, l3: 0.000146, l4: 0.000363, l5: 0.001081, l6: 0.001562

[epoch: 704/1000, batch:   764/ 1052, ite: 185080] train loss: 0.003941, tar: 0.000042 
l0: 0.000044, l1: 0.000049, l2: 0.000098, l3: 0.000272, l4: 0.000539, l5: 0.001642, l6: 0.001787

[epoch: 704/1000, batch:   844/ 1052, ite: 185100] train loss: 0.003940, tar: 0.000042 
l0: 0.000005, l1: 0.000004, l2: 0.000035, l3: 0.000145, l4: 0.000482, l5: 0.001519, l6: 0.002209

[epoch: 704/1000, batch:   924/ 1052, ite: 185120] train loss: 0.003940, tar: 0.000042 
l0: 0.000028, l1: 0.000027, l2: 0.000076, l3: 0.000204, l4: 0.000646, l5: 0.001441, l6: 0.002727

[epoch: 704/1000, batch:  1004/ 1052, ite: 185140] train loss: 0.003941, tar: 0.000042 
[Epoch 704/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000054, l1: 0.000058, l2: 0.000221, l3: 0.000502, l4: 0.000906, l5: 0.002299, l6: 0.004646

[epoch: 705/1000, batch:    32/ 1052, ite: 185160] train loss: 0.003942, tar: 0.000042 
l0: 0.000020, l1: 0.000020, l2: 0.000054, l3: 0.000178, l4: 0.000796, l5: 0.000752, l6: 0.001695

[epoch: 705/1000, batch:   112/ 1052, ite: 185180] train loss: 0.003942, tar: 0.000042 
l0: 0.000094, l1: 0.000095, l2: 0.000152, l3: 0.000204, l4: 0.000423, l5: 0.000838, l6: 0.001219

[epoch: 705/1000, batch:   192/ 1052, ite: 185200] train loss: 0.003943, tar: 0.000042 
l0: 0.000023, l1: 0.000021, l2: 0.000084, l3: 0.000149, l4: 0.000344, l5: 0.001038, l6: 0.001878

[epoch: 705/1000, batch:   272/ 1052, ite: 185220] train loss: 0.003943, tar: 0.000042 
l0: 0.000024, l1: 0.000020, l2: 0.000063, l3: 0.000192, l4: 0.000437, l5: 0.001023, l6: 0.002025

[epoch: 705/1000, batch:   352/ 1052, ite: 185240] train loss: 0.003944, tar: 0.000042 
l0: 0.000031, l1: 0.000033, l2: 0.000069, l3: 0.000115, l4: 0.000366, l5: 0.000956, l6: 0.001930

[epoch: 705/1000, batch:   432/ 1052, ite: 185260] train loss: 0.003943, tar: 0.000042 
l0: 0.000018, l1: 0.000021, l2: 0.000049, l3: 0.000110, l4: 0.000263, l5: 0.000901, l6: 0.003101

[epoch: 705/1000, batch:   512/ 1052, ite: 185280] train loss: 0.003942, tar: 0.000042 
l0: 0.000061, l1: 0.000060, l2: 0.000120, l3: 0.000393, l4: 0.000750, l5: 0.001648, l6: 0.003605

[epoch: 705/1000, batch:   592/ 1052, ite: 185300] train loss: 0.003942, tar: 0.000042 
l0: 0.000011, l1: 0.000010, l2: 0.000059, l3: 0.000146, l4: 0.000563, l5: 0.000963, l6: 0.001844

[epoch: 705/1000, batch:   672/ 1052, ite: 185320] train loss: 0.003942, tar: 0.000042 
l0: 0.000046, l1: 0.000043, l2: 0.000072, l3: 0.000105, l4: 0.000242, l5: 0.000918, l6: 0.001211

[epoch: 705/1000, batch:   752/ 1052, ite: 185340] train loss: 0.003941, tar: 0.000042 
l0: 0.000006, l1: 0.000007, l2: 0.000029, l3: 0.000089, l4: 0.000313, l5: 0.001069, l6: 0.001733

[epoch: 705/1000, batch:   832/ 1052, ite: 185360] train loss: 0.003940, tar: 0.000041 
l0: 0.000054, l1: 0.000052, l2: 0.000125, l3: 0.000343, l4: 0.000566, l5: 0.000704, l6: 0.001311

[epoch: 705/1000, batch:   912/ 1052, ite: 185380] train loss: 0.003940, tar: 0.000042 
l0: 0.000023, l1: 0.000023, l2: 0.000111, l3: 0.000167, l4: 0.000558, l5: 0.001060, l6: 0.002245

[epoch: 705/1000, batch:   992/ 1052, ite: 185400] train loss: 0.003940, tar: 0.000041 
[Epoch 705/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000032, l1: 0.000033, l2: 0.000059, l3: 0.000159, l4: 0.000249, l5: 0.000742, l6: 0.001852

[epoch: 706/1000, batch:    20/ 1052, ite: 185420] train loss: 0.003939, tar: 0.000041 
l0: 0.000014, l1: 0.000012, l2: 0.000082, l3: 0.000276, l4: 0.000489, l5: 0.000690, l6: 0.001243

[epoch: 706/1000, batch:   100/ 1052, ite: 185440] train loss: 0.003938, tar: 0.000041 
l0: 0.000007, l1: 0.000008, l2: 0.000049, l3: 0.000187, l4: 0.000460, l5: 0.001411, l6: 0.002190

[epoch: 706/1000, batch:   180/ 1052, ite: 185460] train loss: 0.003938, tar: 0.000041 
l0: 0.000016, l1: 0.000015, l2: 0.000069, l3: 0.000172, l4: 0.000248, l5: 0.000678, l6: 0.001182

[epoch: 706/1000, batch:   260/ 1052, ite: 185480] train loss: 0.003939, tar: 0.000041 
l0: 0.000026, l1: 0.000027, l2: 0.000060, l3: 0.000164, l4: 0.000412, l5: 0.001213, l6: 0.002014

[epoch: 706/1000, batch:   340/ 1052, ite: 185500] train loss: 0.003938, tar: 0.000041 
l0: 0.000029, l1: 0.000030, l2: 0.000032, l3: 0.000079, l4: 0.000412, l5: 0.000587, l6: 0.001063

[epoch: 706/1000, batch:   420/ 1052, ite: 185520] train loss: 0.003938, tar: 0.000041 
l0: 0.000020, l1: 0.000019, l2: 0.000114, l3: 0.000237, l4: 0.000551, l5: 0.001042, l6: 0.001842

[epoch: 706/1000, batch:   500/ 1052, ite: 185540] train loss: 0.003937, tar: 0.000041 
l0: 0.000058, l1: 0.000054, l2: 0.000134, l3: 0.000172, l4: 0.000294, l5: 0.000944, l6: 0.001594

[epoch: 706/1000, batch:   580/ 1052, ite: 185560] train loss: 0.003937, tar: 0.000041 
l0: 0.000042, l1: 0.000045, l2: 0.000111, l3: 0.000224, l4: 0.000878, l5: 0.001696, l6: 0.003334

[epoch: 706/1000, batch:   660/ 1052, ite: 185580] train loss: 0.003936, tar: 0.000041 
l0: 0.000058, l1: 0.000057, l2: 0.000129, l3: 0.000445, l4: 0.001134, l5: 0.002277, l6: 0.002805

[epoch: 706/1000, batch:   740/ 1052, ite: 185600] train loss: 0.003937, tar: 0.000041 
l0: 0.000060, l1: 0.000060, l2: 0.000150, l3: 0.000344, l4: 0.000818, l5: 0.001726, l6: 0.002959

[epoch: 706/1000, batch:   820/ 1052, ite: 185620] train loss: 0.003939, tar: 0.000041 
l0: 0.000023, l1: 0.000024, l2: 0.000039, l3: 0.000091, l4: 0.000289, l5: 0.000395, l6: 0.001967

[epoch: 706/1000, batch:   900/ 1052, ite: 185640] train loss: 0.003938, tar: 0.000041 
l0: 0.000078, l1: 0.000078, l2: 0.000101, l3: 0.000236, l4: 0.000442, l5: 0.001423, l6: 0.001725

[epoch: 706/1000, batch:   980/ 1052, ite: 185660] train loss: 0.003938, tar: 0.000041 
[Epoch 706/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000031, l1: 0.000032, l2: 0.000066, l3: 0.000115, l4: 0.000228, l5: 0.000703, l6: 0.001060

[epoch: 707/1000, batch:     8/ 1052, ite: 185680] train loss: 0.003938, tar: 0.000041 
l0: 0.000046, l1: 0.000045, l2: 0.000117, l3: 0.000255, l4: 0.000449, l5: 0.001210, l6: 0.002615

[epoch: 707/1000, batch:    88/ 1052, ite: 185700] train loss: 0.003939, tar: 0.000041 
l0: 0.000042, l1: 0.000041, l2: 0.000154, l3: 0.000327, l4: 0.000792, l5: 0.001852, l6: 0.002498

[epoch: 707/1000, batch:   168/ 1052, ite: 185720] train loss: 0.003940, tar: 0.000041 
l0: 0.000051, l1: 0.000050, l2: 0.000063, l3: 0.000167, l4: 0.000456, l5: 0.001065, l6: 0.001152

[epoch: 707/1000, batch:   248/ 1052, ite: 185740] train loss: 0.003941, tar: 0.000041 
l0: 0.000045, l1: 0.000044, l2: 0.000135, l3: 0.000276, l4: 0.000576, l5: 0.002164, l6: 0.004312

[epoch: 707/1000, batch:   328/ 1052, ite: 185760] train loss: 0.003940, tar: 0.000041 
l0: 0.000028, l1: 0.000031, l2: 0.000067, l3: 0.000200, l4: 0.000531, l5: 0.001722, l6: 0.002511

[epoch: 707/1000, batch:   408/ 1052, ite: 185780] train loss: 0.003941, tar: 0.000041 
l0: 0.000040, l1: 0.000038, l2: 0.000086, l3: 0.000135, l4: 0.000388, l5: 0.001059, l6: 0.002259

[epoch: 707/1000, batch:   488/ 1052, ite: 185800] train loss: 0.003941, tar: 0.000041 
l0: 0.000037, l1: 0.000038, l2: 0.000091, l3: 0.000459, l4: 0.001192, l5: 0.001498, l6: 0.003144

[epoch: 707/1000, batch:   568/ 1052, ite: 185820] train loss: 0.003941, tar: 0.000041 
l0: 0.000034, l1: 0.000034, l2: 0.000086, l3: 0.000224, l4: 0.000523, l5: 0.001205, l6: 0.000783

[epoch: 707/1000, batch:   648/ 1052, ite: 185840] train loss: 0.003941, tar: 0.000041 
l0: 0.000023, l1: 0.000022, l2: 0.000060, l3: 0.000127, l4: 0.000353, l5: 0.000885, l6: 0.001805

[epoch: 707/1000, batch:   728/ 1052, ite: 185860] train loss: 0.003941, tar: 0.000041 
l0: 0.000005, l1: 0.000006, l2: 0.000013, l3: 0.000101, l4: 0.000252, l5: 0.000624, l6: 0.001099

[epoch: 707/1000, batch:   808/ 1052, ite: 185880] train loss: 0.003939, tar: 0.000041 
l0: 0.000017, l1: 0.000017, l2: 0.000054, l3: 0.000107, l4: 0.000371, l5: 0.001330, l6: 0.002311

[epoch: 707/1000, batch:   888/ 1052, ite: 185900] train loss: 0.003940, tar: 0.000041 
l0: 0.000028, l1: 0.000030, l2: 0.000045, l3: 0.000149, l4: 0.000599, l5: 0.001414, l6: 0.002203

[epoch: 707/1000, batch:   968/ 1052, ite: 185920] train loss: 0.003939, tar: 0.000041 
l0: 0.000086, l1: 0.000080, l2: 0.000092, l3: 0.000205, l4: 0.000453, l5: 0.000999, l6: 0.001205

[epoch: 707/1000, batch:  1048/ 1052, ite: 185940] train loss: 0.003938, tar: 0.000041 
[Epoch 707/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000045, l1: 0.000046, l2: 0.000105, l3: 0.000122, l4: 0.000232, l5: 0.000989, l6: 0.001234

[epoch: 708/1000, batch:    76/ 1052, ite: 185960] train loss: 0.003938, tar: 0.000041 
l0: 0.000021, l1: 0.000019, l2: 0.000067, l3: 0.000149, l4: 0.000404, l5: 0.000852, l6: 0.001290

[epoch: 708/1000, batch:   156/ 1052, ite: 185980] train loss: 0.003939, tar: 0.000041 
l0: 0.000004, l1: 0.000004, l2: 0.000072, l3: 0.000189, l4: 0.000552, l5: 0.001471, l6: 0.002663

[epoch: 708/1000, batch:   236/ 1052, ite: 186000] train loss: 0.003938, tar: 0.000041 
l0: 0.000031, l1: 0.000031, l2: 0.000061, l3: 0.000117, l4: 0.000396, l5: 0.001008, l6: 0.001390

[epoch: 708/1000, batch:   316/ 1052, ite: 186020] train loss: 0.003940, tar: 0.000041 
l0: 0.000020, l1: 0.000021, l2: 0.000066, l3: 0.000187, l4: 0.000483, l5: 0.000785, l6: 0.001828

[epoch: 708/1000, batch:   396/ 1052, ite: 186040] train loss: 0.003940, tar: 0.000041 
l0: 0.000025, l1: 0.000023, l2: 0.000066, l3: 0.000126, l4: 0.000431, l5: 0.000907, l6: 0.002117

[epoch: 708/1000, batch:   476/ 1052, ite: 186060] train loss: 0.003940, tar: 0.000041 
l0: 0.000034, l1: 0.000034, l2: 0.000057, l3: 0.000118, l4: 0.000386, l5: 0.000791, l6: 0.001630

[epoch: 708/1000, batch:   556/ 1052, ite: 186080] train loss: 0.003939, tar: 0.000041 
l0: 0.000008, l1: 0.000010, l2: 0.000027, l3: 0.000107, l4: 0.000302, l5: 0.000636, l6: 0.000815

[epoch: 708/1000, batch:   636/ 1052, ite: 186100] train loss: 0.003940, tar: 0.000041 
l0: 0.000014, l1: 0.000015, l2: 0.000043, l3: 0.000086, l4: 0.000270, l5: 0.000680, l6: 0.001836

[epoch: 708/1000, batch:   716/ 1052, ite: 186120] train loss: 0.003941, tar: 0.000041 
l0: 0.000042, l1: 0.000042, l2: 0.000090, l3: 0.000221, l4: 0.000440, l5: 0.001297, l6: 0.001897

[epoch: 708/1000, batch:   796/ 1052, ite: 186140] train loss: 0.003940, tar: 0.000041 
l0: 0.000039, l1: 0.000039, l2: 0.000077, l3: 0.000158, l4: 0.000439, l5: 0.000795, l6: 0.003282

[epoch: 708/1000, batch:   876/ 1052, ite: 186160] train loss: 0.003940, tar: 0.000041 
l0: 0.000024, l1: 0.000024, l2: 0.000078, l3: 0.000302, l4: 0.000895, l5: 0.001804, l6: 0.003033

[epoch: 708/1000, batch:   956/ 1052, ite: 186180] train loss: 0.003940, tar: 0.000041 
l0: 0.000005, l1: 0.000005, l2: 0.000029, l3: 0.000107, l4: 0.000506, l5: 0.000880, l6: 0.001390

[epoch: 708/1000, batch:  1036/ 1052, ite: 186200] train loss: 0.003939, tar: 0.000041 
[Epoch 708/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000031, l1: 0.000032, l2: 0.000081, l3: 0.000221, l4: 0.000443, l5: 0.000881, l6: 0.001412

[epoch: 709/1000, batch:    64/ 1052, ite: 186220] train loss: 0.003940, tar: 0.000041 
l0: 0.000036, l1: 0.000040, l2: 0.000090, l3: 0.000263, l4: 0.000561, l5: 0.001475, l6: 0.001460

[epoch: 709/1000, batch:   144/ 1052, ite: 186240] train loss: 0.003939, tar: 0.000041 
l0: 0.000017, l1: 0.000018, l2: 0.000085, l3: 0.000208, l4: 0.000468, l5: 0.000943, l6: 0.001839

[epoch: 709/1000, batch:   224/ 1052, ite: 186260] train loss: 0.003939, tar: 0.000041 
l0: 0.000144, l1: 0.000151, l2: 0.000174, l3: 0.000220, l4: 0.000475, l5: 0.000873, l6: 0.001873

[epoch: 709/1000, batch:   304/ 1052, ite: 186280] train loss: 0.003938, tar: 0.000041 
l0: 0.000037, l1: 0.000038, l2: 0.000072, l3: 0.000172, l4: 0.000466, l5: 0.000676, l6: 0.001470

[epoch: 709/1000, batch:   384/ 1052, ite: 186300] train loss: 0.003937, tar: 0.000041 
l0: 0.000076, l1: 0.000073, l2: 0.000142, l3: 0.000306, l4: 0.000685, l5: 0.001247, l6: 0.002119

[epoch: 709/1000, batch:   464/ 1052, ite: 186320] train loss: 0.003937, tar: 0.000041 
l0: 0.000025, l1: 0.000024, l2: 0.000071, l3: 0.000257, l4: 0.000679, l5: 0.001338, l6: 0.003549

[epoch: 709/1000, batch:   544/ 1052, ite: 186340] train loss: 0.003937, tar: 0.000041 
l0: 0.000023, l1: 0.000024, l2: 0.000027, l3: 0.000146, l4: 0.000488, l5: 0.001139, l6: 0.001860

[epoch: 709/1000, batch:   624/ 1052, ite: 186360] train loss: 0.003936, tar: 0.000041 
l0: 0.000057, l1: 0.000058, l2: 0.000081, l3: 0.000234, l4: 0.000585, l5: 0.001051, l6: 0.001865

[epoch: 709/1000, batch:   704/ 1052, ite: 186380] train loss: 0.003936, tar: 0.000041 
l0: 0.000024, l1: 0.000024, l2: 0.000057, l3: 0.000147, l4: 0.000372, l5: 0.000748, l6: 0.001525

[epoch: 709/1000, batch:   784/ 1052, ite: 186400] train loss: 0.003935, tar: 0.000041 
l0: 0.000085, l1: 0.000087, l2: 0.000148, l3: 0.000167, l4: 0.000397, l5: 0.001113, l6: 0.001398

[epoch: 709/1000, batch:   864/ 1052, ite: 186420] train loss: 0.003936, tar: 0.000041 
l0: 0.000211, l1: 0.000203, l2: 0.000304, l3: 0.000715, l4: 0.001356, l5: 0.002187, l6: 0.002983

[epoch: 709/1000, batch:   944/ 1052, ite: 186440] train loss: 0.003939, tar: 0.000041 
l0: 0.000012, l1: 0.000012, l2: 0.000073, l3: 0.000224, l4: 0.000493, l5: 0.001302, l6: 0.001814

[epoch: 709/1000, batch:  1024/ 1052, ite: 186460] train loss: 0.003940, tar: 0.000041 
[Epoch 709/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000051, l1: 0.000053, l2: 0.000125, l3: 0.000512, l4: 0.000926, l5: 0.001222, l6: 0.002373

[epoch: 710/1000, batch:    52/ 1052, ite: 186480] train loss: 0.003939, tar: 0.000041 
l0: 0.000120, l1: 0.000125, l2: 0.000157, l3: 0.000315, l4: 0.000682, l5: 0.002142, l6: 0.004442

[epoch: 710/1000, batch:   132/ 1052, ite: 186500] train loss: 0.003940, tar: 0.000041 
l0: 0.000056, l1: 0.000059, l2: 0.000084, l3: 0.000179, l4: 0.000493, l5: 0.001285, l6: 0.001780

[epoch: 710/1000, batch:   212/ 1052, ite: 186520] train loss: 0.003939, tar: 0.000041 
l0: 0.000008, l1: 0.000008, l2: 0.000036, l3: 0.000052, l4: 0.000199, l5: 0.000935, l6: 0.001382

[epoch: 710/1000, batch:   292/ 1052, ite: 186540] train loss: 0.003939, tar: 0.000041 
l0: 0.000046, l1: 0.000046, l2: 0.000074, l3: 0.000167, l4: 0.000322, l5: 0.000991, l6: 0.001428

[epoch: 710/1000, batch:   372/ 1052, ite: 186560] train loss: 0.003940, tar: 0.000041 
l0: 0.000067, l1: 0.000067, l2: 0.000106, l3: 0.000378, l4: 0.000781, l5: 0.001212, l6: 0.003063

[epoch: 710/1000, batch:   452/ 1052, ite: 186580] train loss: 0.003940, tar: 0.000041 
l0: 0.000039, l1: 0.000039, l2: 0.000124, l3: 0.000307, l4: 0.000571, l5: 0.000989, l6: 0.002559

[epoch: 710/1000, batch:   532/ 1052, ite: 186600] train loss: 0.003941, tar: 0.000041 
l0: 0.000021, l1: 0.000022, l2: 0.000065, l3: 0.000268, l4: 0.000562, l5: 0.000937, l6: 0.002077

[epoch: 710/1000, batch:   612/ 1052, ite: 186620] train loss: 0.003941, tar: 0.000041 
l0: 0.000014, l1: 0.000013, l2: 0.000018, l3: 0.000052, l4: 0.000352, l5: 0.000864, l6: 0.000656

[epoch: 710/1000, batch:   692/ 1052, ite: 186640] train loss: 0.003941, tar: 0.000041 
l0: 0.000036, l1: 0.000037, l2: 0.000063, l3: 0.000181, l4: 0.000374, l5: 0.001525, l6: 0.002078

[epoch: 710/1000, batch:   772/ 1052, ite: 186660] train loss: 0.003940, tar: 0.000041 
l0: 0.000033, l1: 0.000038, l2: 0.000080, l3: 0.000208, l4: 0.000728, l5: 0.001108, l6: 0.002052

[epoch: 710/1000, batch:   852/ 1052, ite: 186680] train loss: 0.003941, tar: 0.000041 
l0: 0.000020, l1: 0.000021, l2: 0.000046, l3: 0.000110, l4: 0.000344, l5: 0.000907, l6: 0.001391

[epoch: 710/1000, batch:   932/ 1052, ite: 186700] train loss: 0.003941, tar: 0.000041 
l0: 0.000041, l1: 0.000043, l2: 0.000071, l3: 0.000129, l4: 0.000346, l5: 0.001783, l6: 0.002107

[epoch: 710/1000, batch:  1012/ 1052, ite: 186720] train loss: 0.003940, tar: 0.000041 
[Epoch 710/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000010, l1: 0.000010, l2: 0.000025, l3: 0.000085, l4: 0.000198, l5: 0.000751, l6: 0.001113

[epoch: 711/1000, batch:    40/ 1052, ite: 186740] train loss: 0.003939, tar: 0.000041 
l0: 0.000066, l1: 0.000065, l2: 0.000166, l3: 0.000312, l4: 0.000789, l5: 0.001975, l6: 0.003590

[epoch: 711/1000, batch:   120/ 1052, ite: 186760] train loss: 0.003939, tar: 0.000041 
l0: 0.000019, l1: 0.000021, l2: 0.000076, l3: 0.000120, l4: 0.000259, l5: 0.000810, l6: 0.002779

[epoch: 711/1000, batch:   200/ 1052, ite: 186780] train loss: 0.003937, tar: 0.000041 
l0: 0.000033, l1: 0.000032, l2: 0.000147, l3: 0.000298, l4: 0.000698, l5: 0.002336, l6: 0.003001

[epoch: 711/1000, batch:   280/ 1052, ite: 186800] train loss: 0.003938, tar: 0.000041 
l0: 0.000012, l1: 0.000012, l2: 0.000023, l3: 0.000079, l4: 0.000393, l5: 0.000993, l6: 0.001705

[epoch: 711/1000, batch:   360/ 1052, ite: 186820] train loss: 0.003937, tar: 0.000041 
l0: 0.000059, l1: 0.000055, l2: 0.000162, l3: 0.000326, l4: 0.000666, l5: 0.001170, l6: 0.002164

[epoch: 711/1000, batch:   440/ 1052, ite: 186840] train loss: 0.003937, tar: 0.000041 
l0: 0.000009, l1: 0.000009, l2: 0.000067, l3: 0.000169, l4: 0.000283, l5: 0.000989, l6: 0.001494

[epoch: 711/1000, batch:   520/ 1052, ite: 186860] train loss: 0.003937, tar: 0.000041 
l0: 0.000060, l1: 0.000059, l2: 0.000200, l3: 0.000351, l4: 0.000767, l5: 0.002172, l6: 0.002639

[epoch: 711/1000, batch:   600/ 1052, ite: 186880] train loss: 0.003937, tar: 0.000041 
l0: 0.000012, l1: 0.000013, l2: 0.000033, l3: 0.000078, l4: 0.000257, l5: 0.000694, l6: 0.001733

[epoch: 711/1000, batch:   680/ 1052, ite: 186900] train loss: 0.003936, tar: 0.000041 
l0: 0.000011, l1: 0.000011, l2: 0.000023, l3: 0.000081, l4: 0.000158, l5: 0.000775, l6: 0.001540

[epoch: 711/1000, batch:   760/ 1052, ite: 186920] train loss: 0.003936, tar: 0.000041 
l0: 0.000038, l1: 0.000037, l2: 0.000106, l3: 0.000417, l4: 0.000657, l5: 0.001423, l6: 0.001980

[epoch: 711/1000, batch:   840/ 1052, ite: 186940] train loss: 0.003936, tar: 0.000041 
l0: 0.000043, l1: 0.000044, l2: 0.000108, l3: 0.000331, l4: 0.000699, l5: 0.001392, l6: 0.001883

[epoch: 711/1000, batch:   920/ 1052, ite: 186960] train loss: 0.003936, tar: 0.000041 
l0: 0.000154, l1: 0.000158, l2: 0.000144, l3: 0.000195, l4: 0.000451, l5: 0.001217, l6: 0.002740

[epoch: 711/1000, batch:  1000/ 1052, ite: 186980] train loss: 0.003938, tar: 0.000041 
[Epoch 711/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000058, l1: 0.000060, l2: 0.000108, l3: 0.000224, l4: 0.000679, l5: 0.002144, l6: 0.002944

[epoch: 712/1000, batch:    28/ 1052, ite: 187000] train loss: 0.003938, tar: 0.000041 
l0: 0.000058, l1: 0.000058, l2: 0.000107, l3: 0.000214, l4: 0.000718, l5: 0.001475, l6: 0.002402

[epoch: 712/1000, batch:   108/ 1052, ite: 187020] train loss: 0.003937, tar: 0.000041 
l0: 0.000028, l1: 0.000027, l2: 0.000041, l3: 0.000134, l4: 0.000423, l5: 0.001099, l6: 0.002317

[epoch: 712/1000, batch:   188/ 1052, ite: 187040] train loss: 0.003937, tar: 0.000041 
l0: 0.000024, l1: 0.000025, l2: 0.000060, l3: 0.000115, l4: 0.000410, l5: 0.000614, l6: 0.001272

[epoch: 712/1000, batch:   268/ 1052, ite: 187060] train loss: 0.003937, tar: 0.000041 
l0: 0.000024, l1: 0.000021, l2: 0.000075, l3: 0.000405, l4: 0.000499, l5: 0.001235, l6: 0.002532

[epoch: 712/1000, batch:   348/ 1052, ite: 187080] train loss: 0.003937, tar: 0.000041 
l0: 0.000010, l1: 0.000011, l2: 0.000054, l3: 0.000104, l4: 0.000378, l5: 0.000715, l6: 0.001246

[epoch: 712/1000, batch:   428/ 1052, ite: 187100] train loss: 0.003937, tar: 0.000041 
l0: 0.000056, l1: 0.000062, l2: 0.000107, l3: 0.000193, l4: 0.000451, l5: 0.001051, l6: 0.002266

[epoch: 712/1000, batch:   508/ 1052, ite: 187120] train loss: 0.003936, tar: 0.000041 
l0: 0.000026, l1: 0.000027, l2: 0.000083, l3: 0.000303, l4: 0.000511, l5: 0.000982, l6: 0.001826

[epoch: 712/1000, batch:   588/ 1052, ite: 187140] train loss: 0.003936, tar: 0.000041 
l0: 0.000016, l1: 0.000017, l2: 0.000057, l3: 0.000113, l4: 0.000342, l5: 0.001357, l6: 0.001981

[epoch: 712/1000, batch:   668/ 1052, ite: 187160] train loss: 0.003937, tar: 0.000041 
l0: 0.000028, l1: 0.000028, l2: 0.000102, l3: 0.000232, l4: 0.000513, l5: 0.001479, l6: 0.001986

[epoch: 712/1000, batch:   748/ 1052, ite: 187180] train loss: 0.003936, tar: 0.000041 
l0: 0.000060, l1: 0.000058, l2: 0.000103, l3: 0.000252, l4: 0.000484, l5: 0.001215, l6: 0.002415

[epoch: 712/1000, batch:   828/ 1052, ite: 187200] train loss: 0.003936, tar: 0.000041 
l0: 0.000070, l1: 0.000077, l2: 0.000216, l3: 0.000421, l4: 0.000671, l5: 0.002039, l6: 0.003624

[epoch: 712/1000, batch:   908/ 1052, ite: 187220] train loss: 0.003936, tar: 0.000041 
l0: 0.000052, l1: 0.000056, l2: 0.000078, l3: 0.000167, l4: 0.000430, l5: 0.000855, l6: 0.002445

[epoch: 712/1000, batch:   988/ 1052, ite: 187240] train loss: 0.003935, tar: 0.000041 
[Epoch 712/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000006, l1: 0.000006, l2: 0.000030, l3: 0.000178, l4: 0.000376, l5: 0.001005, l6: 0.001463

[epoch: 713/1000, batch:    16/ 1052, ite: 187260] train loss: 0.003935, tar: 0.000041 
l0: 0.000016, l1: 0.000015, l2: 0.000030, l3: 0.000133, l4: 0.000398, l5: 0.000891, l6: 0.001237

[epoch: 713/1000, batch:    96/ 1052, ite: 187280] train loss: 0.003938, tar: 0.000041 
l0: 0.000060, l1: 0.000058, l2: 0.000100, l3: 0.000143, l4: 0.000441, l5: 0.000915, l6: 0.001512

[epoch: 713/1000, batch:   176/ 1052, ite: 187300] train loss: 0.003938, tar: 0.000041 
l0: 0.000073, l1: 0.000075, l2: 0.000105, l3: 0.000145, l4: 0.000405, l5: 0.001152, l6: 0.002025

[epoch: 713/1000, batch:   256/ 1052, ite: 187320] train loss: 0.003938, tar: 0.000041 
l0: 0.000006, l1: 0.000006, l2: 0.000032, l3: 0.000121, l4: 0.000282, l5: 0.001190, l6: 0.002868

[epoch: 713/1000, batch:   336/ 1052, ite: 187340] train loss: 0.003938, tar: 0.000041 
l0: 0.000021, l1: 0.000024, l2: 0.000076, l3: 0.000182, l4: 0.000453, l5: 0.001177, l6: 0.001994

[epoch: 713/1000, batch:   416/ 1052, ite: 187360] train loss: 0.003939, tar: 0.000041 
l0: 0.000012, l1: 0.000011, l2: 0.000029, l3: 0.000108, l4: 0.000401, l5: 0.000979, l6: 0.001490

[epoch: 713/1000, batch:   496/ 1052, ite: 187380] train loss: 0.003940, tar: 0.000041 
l0: 0.000032, l1: 0.000032, l2: 0.000082, l3: 0.000266, l4: 0.000535, l5: 0.001587, l6: 0.002461

[epoch: 713/1000, batch:   576/ 1052, ite: 187400] train loss: 0.003939, tar: 0.000041 
l0: 0.000003, l1: 0.000002, l2: 0.000017, l3: 0.000099, l4: 0.000247, l5: 0.000774, l6: 0.001011

[epoch: 713/1000, batch:   656/ 1052, ite: 187420] train loss: 0.003939, tar: 0.000041 
l0: 0.000035, l1: 0.000036, l2: 0.000064, l3: 0.000248, l4: 0.000514, l5: 0.001552, l6: 0.002753

[epoch: 713/1000, batch:   736/ 1052, ite: 187440] train loss: 0.003940, tar: 0.000041 
l0: 0.000026, l1: 0.000024, l2: 0.000045, l3: 0.000092, l4: 0.000250, l5: 0.000647, l6: 0.001425

[epoch: 713/1000, batch:   816/ 1052, ite: 187460] train loss: 0.003940, tar: 0.000041 
l0: 0.000007, l1: 0.000007, l2: 0.000038, l3: 0.000124, l4: 0.000391, l5: 0.000596, l6: 0.001087

[epoch: 713/1000, batch:   896/ 1052, ite: 187480] train loss: 0.003939, tar: 0.000041 
l0: 0.000064, l1: 0.000069, l2: 0.000159, l3: 0.000342, l4: 0.000668, l5: 0.001412, l6: 0.002340

[epoch: 713/1000, batch:   976/ 1052, ite: 187500] train loss: 0.003938, tar: 0.000041 
[Epoch 713/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000063, l1: 0.000067, l2: 0.000083, l3: 0.000212, l4: 0.000630, l5: 0.001687, l6: 0.002414

[epoch: 714/1000, batch:     4/ 1052, ite: 187520] train loss: 0.003937, tar: 0.000041 
l0: 0.000006, l1: 0.000006, l2: 0.000026, l3: 0.000107, l4: 0.000280, l5: 0.000905, l6: 0.001226

[epoch: 714/1000, batch:    84/ 1052, ite: 187540] train loss: 0.003936, tar: 0.000041 
l0: 0.000008, l1: 0.000008, l2: 0.000044, l3: 0.000133, l4: 0.000407, l5: 0.000732, l6: 0.001247

[epoch: 714/1000, batch:   164/ 1052, ite: 187560] train loss: 0.003935, tar: 0.000041 
l0: 0.000192, l1: 0.000170, l2: 0.000207, l3: 0.000159, l4: 0.000405, l5: 0.000728, l6: 0.001429

[epoch: 714/1000, batch:   244/ 1052, ite: 187580] train loss: 0.003935, tar: 0.000041 
l0: 0.000019, l1: 0.000019, l2: 0.000048, l3: 0.000114, l4: 0.000365, l5: 0.000828, l6: 0.001237

[epoch: 714/1000, batch:   324/ 1052, ite: 187600] train loss: 0.003936, tar: 0.000041 
l0: 0.000052, l1: 0.000054, l2: 0.000109, l3: 0.000421, l4: 0.000769, l5: 0.001354, l6: 0.002316

[epoch: 714/1000, batch:   404/ 1052, ite: 187620] train loss: 0.003935, tar: 0.000041 
l0: 0.000217, l1: 0.000222, l2: 0.000257, l3: 0.000318, l4: 0.000497, l5: 0.000986, l6: 0.001899

[epoch: 714/1000, batch:   484/ 1052, ite: 187640] train loss: 0.003935, tar: 0.000041 
l0: 0.000063, l1: 0.000059, l2: 0.000138, l3: 0.000229, l4: 0.000726, l5: 0.001081, l6: 0.002395

[epoch: 714/1000, batch:   564/ 1052, ite: 187660] train loss: 0.003936, tar: 0.000041 
l0: 0.000029, l1: 0.000029, l2: 0.000043, l3: 0.000096, l4: 0.000493, l5: 0.000869, l6: 0.002156

[epoch: 714/1000, batch:   644/ 1052, ite: 187680] train loss: 0.003936, tar: 0.000041 
l0: 0.000029, l1: 0.000028, l2: 0.000139, l3: 0.000240, l4: 0.000641, l5: 0.001193, l6: 0.001754

[epoch: 714/1000, batch:   724/ 1052, ite: 187700] train loss: 0.003936, tar: 0.000041 
l0: 0.000014, l1: 0.000015, l2: 0.000034, l3: 0.000068, l4: 0.000253, l5: 0.001049, l6: 0.000905

[epoch: 714/1000, batch:   804/ 1052, ite: 187720] train loss: 0.003935, tar: 0.000041 
l0: 0.000017, l1: 0.000019, l2: 0.000039, l3: 0.000108, l4: 0.000325, l5: 0.001044, l6: 0.001412

[epoch: 714/1000, batch:   884/ 1052, ite: 187740] train loss: 0.003935, tar: 0.000041 
l0: 0.000007, l1: 0.000007, l2: 0.000061, l3: 0.000259, l4: 0.000498, l5: 0.001179, l6: 0.002024

[epoch: 714/1000, batch:   964/ 1052, ite: 187760] train loss: 0.003936, tar: 0.000041 
l0: 0.000014, l1: 0.000016, l2: 0.000033, l3: 0.000161, l4: 0.000491, l5: 0.000940, l6: 0.001743

[epoch: 714/1000, batch:  1044/ 1052, ite: 187780] train loss: 0.003936, tar: 0.000041 
[Epoch 714/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000023, l1: 0.000027, l2: 0.000031, l3: 0.000087, l4: 0.000407, l5: 0.000855, l6: 0.001482

[epoch: 715/1000, batch:    72/ 1052, ite: 187800] train loss: 0.003936, tar: 0.000041 
l0: 0.000029, l1: 0.000028, l2: 0.000059, l3: 0.000083, l4: 0.000399, l5: 0.000999, l6: 0.001247

[epoch: 715/1000, batch:   152/ 1052, ite: 187820] train loss: 0.003936, tar: 0.000041 
l0: 0.000031, l1: 0.000034, l2: 0.000047, l3: 0.000070, l4: 0.000301, l5: 0.001240, l6: 0.001996

[epoch: 715/1000, batch:   232/ 1052, ite: 187840] train loss: 0.003935, tar: 0.000041 
l0: 0.000025, l1: 0.000023, l2: 0.000060, l3: 0.000173, l4: 0.000408, l5: 0.000833, l6: 0.001264

[epoch: 715/1000, batch:   312/ 1052, ite: 187860] train loss: 0.003935, tar: 0.000041 
l0: 0.000008, l1: 0.000009, l2: 0.000030, l3: 0.000100, l4: 0.000171, l5: 0.000585, l6: 0.001029

[epoch: 715/1000, batch:   392/ 1052, ite: 187880] train loss: 0.003935, tar: 0.000041 
l0: 0.000071, l1: 0.000064, l2: 0.000163, l3: 0.000348, l4: 0.000737, l5: 0.002328, l6: 0.004443

[epoch: 715/1000, batch:   472/ 1052, ite: 187900] train loss: 0.003934, tar: 0.000041 
l0: 0.000061, l1: 0.000059, l2: 0.000123, l3: 0.000266, l4: 0.000535, l5: 0.001123, l6: 0.002179

[epoch: 715/1000, batch:   552/ 1052, ite: 187920] train loss: 0.003935, tar: 0.000041 
l0: 0.000004, l1: 0.000004, l2: 0.000074, l3: 0.000237, l4: 0.000482, l5: 0.000837, l6: 0.001354

[epoch: 715/1000, batch:   632/ 1052, ite: 187940] train loss: 0.003935, tar: 0.000041 
l0: 0.000048, l1: 0.000047, l2: 0.000054, l3: 0.000115, l4: 0.000315, l5: 0.000869, l6: 0.001808

[epoch: 715/1000, batch:   712/ 1052, ite: 187960] train loss: 0.003935, tar: 0.000041 
l0: 0.000031, l1: 0.000031, l2: 0.000124, l3: 0.000437, l4: 0.000808, l5: 0.001952, l6: 0.002908

[epoch: 715/1000, batch:   792/ 1052, ite: 187980] train loss: 0.003935, tar: 0.000041 
l0: 0.000048, l1: 0.000052, l2: 0.000073, l3: 0.000220, l4: 0.000668, l5: 0.001292, l6: 0.002316

[epoch: 715/1000, batch:   872/ 1052, ite: 188000] train loss: 0.003935, tar: 0.000041 
l0: 0.000047, l1: 0.000049, l2: 0.000099, l3: 0.000238, l4: 0.000512, l5: 0.001755, l6: 0.003729

[epoch: 715/1000, batch:   952/ 1052, ite: 188020] train loss: 0.003935, tar: 0.000041 
l0: 0.000025, l1: 0.000026, l2: 0.000034, l3: 0.000134, l4: 0.000653, l5: 0.000974, l6: 0.002177

[epoch: 715/1000, batch:  1032/ 1052, ite: 188040] train loss: 0.003936, tar: 0.000041 
[Epoch 715/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000059, l1: 0.000052, l2: 0.000105, l3: 0.000249, l4: 0.000453, l5: 0.001064, l6: 0.001214

[epoch: 716/1000, batch:    60/ 1052, ite: 188060] train loss: 0.003936, tar: 0.000041 
l0: 0.000022, l1: 0.000022, l2: 0.000087, l3: 0.000263, l4: 0.000865, l5: 0.001125, l6: 0.002498

[epoch: 716/1000, batch:   140/ 1052, ite: 188080] train loss: 0.003935, tar: 0.000041 
l0: 0.000007, l1: 0.000007, l2: 0.000028, l3: 0.000114, l4: 0.000305, l5: 0.000826, l6: 0.001190

[epoch: 716/1000, batch:   220/ 1052, ite: 188100] train loss: 0.003936, tar: 0.000041 
l0: 0.000099, l1: 0.000097, l2: 0.000156, l3: 0.000304, l4: 0.000952, l5: 0.001794, l6: 0.003733

[epoch: 716/1000, batch:   300/ 1052, ite: 188120] train loss: 0.003936, tar: 0.000041 
l0: 0.000047, l1: 0.000048, l2: 0.000050, l3: 0.000193, l4: 0.000495, l5: 0.001127, l6: 0.001683

[epoch: 716/1000, batch:   380/ 1052, ite: 188140] train loss: 0.003935, tar: 0.000041 
l0: 0.000152, l1: 0.000155, l2: 0.000240, l3: 0.000534, l4: 0.001028, l5: 0.002078, l6: 0.004053

[epoch: 716/1000, batch:   460/ 1052, ite: 188160] train loss: 0.003936, tar: 0.000041 
l0: 0.000008, l1: 0.000008, l2: 0.000075, l3: 0.000220, l4: 0.000687, l5: 0.001535, l6: 0.003089

[epoch: 716/1000, batch:   540/ 1052, ite: 188180] train loss: 0.003936, tar: 0.000041 
l0: 0.000059, l1: 0.000058, l2: 0.000096, l3: 0.000212, l4: 0.000389, l5: 0.001956, l6: 0.002681

[epoch: 716/1000, batch:   620/ 1052, ite: 188200] train loss: 0.003936, tar: 0.000041 
l0: 0.000007, l1: 0.000007, l2: 0.000017, l3: 0.000061, l4: 0.000235, l5: 0.000586, l6: 0.000928

[epoch: 716/1000, batch:   700/ 1052, ite: 188220] train loss: 0.003935, tar: 0.000040 
l0: 0.000118, l1: 0.000125, l2: 0.000191, l3: 0.000296, l4: 0.000622, l5: 0.001242, l6: 0.002730

[epoch: 716/1000, batch:   780/ 1052, ite: 188240] train loss: 0.003935, tar: 0.000040 
l0: 0.000018, l1: 0.000022, l2: 0.000076, l3: 0.000238, l4: 0.000443, l5: 0.001109, l6: 0.002105

[epoch: 716/1000, batch:   860/ 1052, ite: 188260] train loss: 0.003934, tar: 0.000040 
l0: 0.000023, l1: 0.000024, l2: 0.000038, l3: 0.000130, l4: 0.000575, l5: 0.000933, l6: 0.001892

[epoch: 716/1000, batch:   940/ 1052, ite: 188280] train loss: 0.003935, tar: 0.000040 
l0: 0.000004, l1: 0.000003, l2: 0.000032, l3: 0.000128, l4: 0.000327, l5: 0.000879, l6: 0.001697

[epoch: 716/1000, batch:  1020/ 1052, ite: 188300] train loss: 0.003935, tar: 0.000040 
[Epoch 716/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000003, l1: 0.000003, l2: 0.000025, l3: 0.000151, l4: 0.000657, l5: 0.001043, l6: 0.002275

[epoch: 717/1000, batch:    48/ 1052, ite: 188320] train loss: 0.003935, tar: 0.000040 
l0: 0.000021, l1: 0.000023, l2: 0.000063, l3: 0.000162, l4: 0.000343, l5: 0.001046, l6: 0.002029

[epoch: 717/1000, batch:   128/ 1052, ite: 188340] train loss: 0.003935, tar: 0.000040 
l0: 0.000017, l1: 0.000019, l2: 0.000054, l3: 0.000153, l4: 0.000263, l5: 0.001085, l6: 0.001616

[epoch: 717/1000, batch:   208/ 1052, ite: 188360] train loss: 0.003935, tar: 0.000040 
l0: 0.000026, l1: 0.000027, l2: 0.000053, l3: 0.000123, l4: 0.000446, l5: 0.000938, l6: 0.002382

[epoch: 717/1000, batch:   288/ 1052, ite: 188380] train loss: 0.003936, tar: 0.000040 
l0: 0.000045, l1: 0.000048, l2: 0.000066, l3: 0.000188, l4: 0.000592, l5: 0.001906, l6: 0.002590

[epoch: 717/1000, batch:   368/ 1052, ite: 188400] train loss: 0.003935, tar: 0.000040 
l0: 0.000030, l1: 0.000030, l2: 0.000053, l3: 0.000126, l4: 0.000336, l5: 0.000746, l6: 0.003035

[epoch: 717/1000, batch:   448/ 1052, ite: 188420] train loss: 0.003935, tar: 0.000040 
l0: 0.000076, l1: 0.000077, l2: 0.000151, l3: 0.000459, l4: 0.000979, l5: 0.001947, l6: 0.003270

[epoch: 717/1000, batch:   528/ 1052, ite: 188440] train loss: 0.003935, tar: 0.000040 
l0: 0.000081, l1: 0.000081, l2: 0.000139, l3: 0.000272, l4: 0.000711, l5: 0.001843, l6: 0.003095

[epoch: 717/1000, batch:   608/ 1052, ite: 188460] train loss: 0.003935, tar: 0.000040 
l0: 0.000012, l1: 0.000012, l2: 0.000033, l3: 0.000111, l4: 0.000357, l5: 0.000632, l6: 0.001694

[epoch: 717/1000, batch:   688/ 1052, ite: 188480] train loss: 0.003934, tar: 0.000040 
l0: 0.000022, l1: 0.000021, l2: 0.000086, l3: 0.000221, l4: 0.000480, l5: 0.000855, l6: 0.002081

[epoch: 717/1000, batch:   768/ 1052, ite: 188500] train loss: 0.003933, tar: 0.000040 
l0: 0.000012, l1: 0.000011, l2: 0.000038, l3: 0.000165, l4: 0.000336, l5: 0.000857, l6: 0.001430

[epoch: 717/1000, batch:   848/ 1052, ite: 188520] train loss: 0.003934, tar: 0.000040 
l0: 0.000077, l1: 0.000075, l2: 0.000085, l3: 0.000142, l4: 0.000371, l5: 0.000720, l6: 0.002231

[epoch: 717/1000, batch:   928/ 1052, ite: 188540] train loss: 0.003934, tar: 0.000040 
l0: 0.000057, l1: 0.000060, l2: 0.000157, l3: 0.000286, l4: 0.000562, l5: 0.002060, l6: 0.003938

[epoch: 717/1000, batch:  1008/ 1052, ite: 188560] train loss: 0.003936, tar: 0.000040 
[Epoch 717/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000071, l1: 0.000072, l2: 0.000184, l3: 0.000371, l4: 0.001049, l5: 0.001730, l6: 0.002574

[epoch: 718/1000, batch:    36/ 1052, ite: 188580] train loss: 0.003936, tar: 0.000040 
l0: 0.000105, l1: 0.000129, l2: 0.000089, l3: 0.000205, l4: 0.000267, l5: 0.000784, l6: 0.001493

[epoch: 718/1000, batch:   116/ 1052, ite: 188600] train loss: 0.003935, tar: 0.000040 
l0: 0.000062, l1: 0.000059, l2: 0.000122, l3: 0.000279, l4: 0.000632, l5: 0.001062, l6: 0.001723

[epoch: 718/1000, batch:   196/ 1052, ite: 188620] train loss: 0.003935, tar: 0.000040 
l0: 0.000028, l1: 0.000030, l2: 0.000039, l3: 0.000146, l4: 0.000335, l5: 0.001042, l6: 0.001703

[epoch: 718/1000, batch:   276/ 1052, ite: 188640] train loss: 0.003936, tar: 0.000040 
l0: 0.000019, l1: 0.000021, l2: 0.000038, l3: 0.000124, l4: 0.000243, l5: 0.000832, l6: 0.001322

[epoch: 718/1000, batch:   356/ 1052, ite: 188660] train loss: 0.003936, tar: 0.000040 
l0: 0.000092, l1: 0.000096, l2: 0.000100, l3: 0.000222, l4: 0.000612, l5: 0.001743, l6: 0.002673

[epoch: 718/1000, batch:   436/ 1052, ite: 188680] train loss: 0.003937, tar: 0.000040 
l0: 0.000036, l1: 0.000041, l2: 0.000084, l3: 0.000184, l4: 0.000523, l5: 0.001469, l6: 0.002001

[epoch: 718/1000, batch:   516/ 1052, ite: 188700] train loss: 0.003937, tar: 0.000040 
l0: 0.000022, l1: 0.000021, l2: 0.000064, l3: 0.000226, l4: 0.000715, l5: 0.000943, l6: 0.002729

[epoch: 718/1000, batch:   596/ 1052, ite: 188720] train loss: 0.003938, tar: 0.000040 
l0: 0.000023, l1: 0.000024, l2: 0.000051, l3: 0.000145, l4: 0.000413, l5: 0.000921, l6: 0.001685

[epoch: 718/1000, batch:   676/ 1052, ite: 188740] train loss: 0.003938, tar: 0.000040 
l0: 0.000022, l1: 0.000022, l2: 0.000054, l3: 0.000129, l4: 0.000418, l5: 0.001238, l6: 0.001790

[epoch: 718/1000, batch:   756/ 1052, ite: 188760] train loss: 0.003937, tar: 0.000040 
l0: 0.000048, l1: 0.000049, l2: 0.000094, l3: 0.000119, l4: 0.000404, l5: 0.001285, l6: 0.001251

[epoch: 718/1000, batch:   836/ 1052, ite: 188780] train loss: 0.003938, tar: 0.000040 
l0: 0.000064, l1: 0.000070, l2: 0.000060, l3: 0.000108, l4: 0.000239, l5: 0.000549, l6: 0.000964

[epoch: 718/1000, batch:   916/ 1052, ite: 188800] train loss: 0.003937, tar: 0.000040 
l0: 0.000035, l1: 0.000034, l2: 0.000046, l3: 0.000131, l4: 0.000392, l5: 0.001047, l6: 0.002184

[epoch: 718/1000, batch:   996/ 1052, ite: 188820] train loss: 0.003937, tar: 0.000040 
[Epoch 718/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000013, l1: 0.000013, l2: 0.000055, l3: 0.000172, l4: 0.000516, l5: 0.001377, l6: 0.001808

[epoch: 719/1000, batch:    24/ 1052, ite: 188840] train loss: 0.003936, tar: 0.000040 
l0: 0.000043, l1: 0.000046, l2: 0.000080, l3: 0.000189, l4: 0.000453, l5: 0.001030, l6: 0.001859

[epoch: 719/1000, batch:   104/ 1052, ite: 188860] train loss: 0.003937, tar: 0.000040 
l0: 0.000027, l1: 0.000029, l2: 0.000069, l3: 0.000146, l4: 0.000481, l5: 0.001207, l6: 0.003071

[epoch: 719/1000, batch:   184/ 1052, ite: 188880] train loss: 0.003937, tar: 0.000040 
l0: 0.000017, l1: 0.000016, l2: 0.000053, l3: 0.000073, l4: 0.000380, l5: 0.000683, l6: 0.001410

[epoch: 719/1000, batch:   264/ 1052, ite: 188900] train loss: 0.003936, tar: 0.000040 
l0: 0.000067, l1: 0.000068, l2: 0.000120, l3: 0.000250, l4: 0.000409, l5: 0.001211, l6: 0.002716

[epoch: 719/1000, batch:   344/ 1052, ite: 188920] train loss: 0.003938, tar: 0.000040 
l0: 0.000074, l1: 0.000076, l2: 0.000220, l3: 0.000345, l4: 0.000746, l5: 0.001472, l6: 0.001942

[epoch: 719/1000, batch:   424/ 1052, ite: 188940] train loss: 0.003937, tar: 0.000041 
l0: 0.000018, l1: 0.000017, l2: 0.000041, l3: 0.000133, l4: 0.000329, l5: 0.000778, l6: 0.001793

[epoch: 719/1000, batch:   504/ 1052, ite: 188960] train loss: 0.003938, tar: 0.000041 
l0: 0.000069, l1: 0.000072, l2: 0.000119, l3: 0.000161, l4: 0.000335, l5: 0.000654, l6: 0.001366

[epoch: 719/1000, batch:   584/ 1052, ite: 188980] train loss: 0.003937, tar: 0.000041 
l0: 0.000014, l1: 0.000013, l2: 0.000029, l3: 0.000095, l4: 0.000174, l5: 0.000688, l6: 0.001014

[epoch: 719/1000, batch:   664/ 1052, ite: 189000] train loss: 0.003938, tar: 0.000041 
l0: 0.000039, l1: 0.000039, l2: 0.000200, l3: 0.000392, l4: 0.001089, l5: 0.002848, l6: 0.004031

[epoch: 719/1000, batch:   744/ 1052, ite: 189020] train loss: 0.003938, tar: 0.000041 
l0: 0.000022, l1: 0.000021, l2: 0.000051, l3: 0.000134, l4: 0.000420, l5: 0.000658, l6: 0.001320

[epoch: 719/1000, batch:   824/ 1052, ite: 189040] train loss: 0.003938, tar: 0.000041 
l0: 0.000050, l1: 0.000053, l2: 0.000085, l3: 0.000131, l4: 0.000300, l5: 0.001147, l6: 0.003084

[epoch: 719/1000, batch:   904/ 1052, ite: 189060] train loss: 0.003938, tar: 0.000041 
l0: 0.000046, l1: 0.000047, l2: 0.000065, l3: 0.000135, l4: 0.000304, l5: 0.000852, l6: 0.001557

[epoch: 719/1000, batch:   984/ 1052, ite: 189080] train loss: 0.003937, tar: 0.000040 
[Epoch 719/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000010, l1: 0.000011, l2: 0.000024, l3: 0.000076, l4: 0.000333, l5: 0.000535, l6: 0.001221

[epoch: 720/1000, batch:    12/ 1052, ite: 189100] train loss: 0.003935, tar: 0.000040 
l0: 0.000020, l1: 0.000021, l2: 0.000083, l3: 0.000242, l4: 0.000589, l5: 0.000877, l6: 0.002550

[epoch: 720/1000, batch:    92/ 1052, ite: 189120] train loss: 0.003936, tar: 0.000040 
l0: 0.000024, l1: 0.000024, l2: 0.000068, l3: 0.000228, l4: 0.000373, l5: 0.000852, l6: 0.002468

[epoch: 720/1000, batch:   172/ 1052, ite: 189140] train loss: 0.003936, tar: 0.000040 
l0: 0.000031, l1: 0.000028, l2: 0.000067, l3: 0.000241, l4: 0.000464, l5: 0.000873, l6: 0.001933

[epoch: 720/1000, batch:   252/ 1052, ite: 189160] train loss: 0.003936, tar: 0.000040 
l0: 0.000007, l1: 0.000008, l2: 0.000037, l3: 0.000138, l4: 0.000584, l5: 0.001331, l6: 0.001796

[epoch: 720/1000, batch:   332/ 1052, ite: 189180] train loss: 0.003935, tar: 0.000040 
l0: 0.000040, l1: 0.000041, l2: 0.000056, l3: 0.000145, l4: 0.000386, l5: 0.000810, l6: 0.001509

[epoch: 720/1000, batch:   412/ 1052, ite: 189200] train loss: 0.003935, tar: 0.000040 
l0: 0.000011, l1: 0.000011, l2: 0.000036, l3: 0.000118, l4: 0.000364, l5: 0.000757, l6: 0.001148

[epoch: 720/1000, batch:   492/ 1052, ite: 189220] train loss: 0.003934, tar: 0.000040 
l0: 0.000003, l1: 0.000003, l2: 0.000012, l3: 0.000051, l4: 0.000198, l5: 0.000646, l6: 0.001235

[epoch: 720/1000, batch:   572/ 1052, ite: 189240] train loss: 0.003934, tar: 0.000040 
l0: 0.000001, l1: 0.000001, l2: 0.000014, l3: 0.000154, l4: 0.000260, l5: 0.000801, l6: 0.001668

[epoch: 720/1000, batch:   652/ 1052, ite: 189260] train loss: 0.003934, tar: 0.000040 
l0: 0.000030, l1: 0.000028, l2: 0.000064, l3: 0.000138, l4: 0.000322, l5: 0.000752, l6: 0.001429

[epoch: 720/1000, batch:   732/ 1052, ite: 189280] train loss: 0.003933, tar: 0.000040 
l0: 0.000035, l1: 0.000039, l2: 0.000072, l3: 0.000255, l4: 0.000568, l5: 0.001140, l6: 0.001930

[epoch: 720/1000, batch:   812/ 1052, ite: 189300] train loss: 0.003933, tar: 0.000040 
l0: 0.000021, l1: 0.000024, l2: 0.000107, l3: 0.000200, l4: 0.000592, l5: 0.000657, l6: 0.002173

[epoch: 720/1000, batch:   892/ 1052, ite: 189320] train loss: 0.003934, tar: 0.000040 
l0: 0.000084, l1: 0.000083, l2: 0.000039, l3: 0.000128, l4: 0.000384, l5: 0.001202, l6: 0.001866

[epoch: 720/1000, batch:   972/ 1052, ite: 189340] train loss: 0.003934, tar: 0.000040 
l0: 0.000017, l1: 0.000016, l2: 0.000102, l3: 0.000203, l4: 0.000503, l5: 0.001085, l6: 0.001511

[epoch: 720/1000, batch:  1052/ 1052, ite: 189360] train loss: 0.003934, tar: 0.000040 
[Epoch 720/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000004, l1: 0.000005, l2: 0.000017, l3: 0.000063, l4: 0.000272, l5: 0.000435, l6: 0.001181

[epoch: 721/1000, batch:    80/ 1052, ite: 189380] train loss: 0.003769, tar: 0.000040 
l0: 0.000033, l1: 0.000034, l2: 0.000078, l3: 0.000264, l4: 0.000777, l5: 0.001352, l6: 0.003079

[epoch: 721/1000, batch:   160/ 1052, ite: 189400] train loss: 0.003893, tar: 0.000039 
l0: 0.000022, l1: 0.000024, l2: 0.000060, l3: 0.000155, l4: 0.000348, l5: 0.000687, l6: 0.001318

[epoch: 721/1000, batch:   240/ 1052, ite: 189420] train loss: 0.003849, tar: 0.000035 
l0: 0.000011, l1: 0.000009, l2: 0.000034, l3: 0.000137, l4: 0.000450, l5: 0.000990, l6: 0.001408

[epoch: 721/1000, batch:   320/ 1052, ite: 189440] train loss: 0.003845, tar: 0.000034 
l0: 0.000086, l1: 0.000087, l2: 0.000164, l3: 0.000344, l4: 0.000919, l5: 0.001733, l6: 0.003539

[epoch: 721/1000, batch:   400/ 1052, ite: 189460] train loss: 0.003948, tar: 0.000034 
l0: 0.000055, l1: 0.000054, l2: 0.000128, l3: 0.000262, l4: 0.000502, l5: 0.001447, l6: 0.002524

[epoch: 721/1000, batch:   480/ 1052, ite: 189480] train loss: 0.003956, tar: 0.000035 
l0: 0.000020, l1: 0.000019, l2: 0.000036, l3: 0.000065, l4: 0.000214, l5: 0.000604, l6: 0.001190

[epoch: 721/1000, batch:   560/ 1052, ite: 189500] train loss: 0.004000, tar: 0.000036 
l0: 0.000002, l1: 0.000003, l2: 0.000013, l3: 0.000082, l4: 0.000313, l5: 0.000541, l6: 0.000867

[epoch: 721/1000, batch:   640/ 1052, ite: 189520] train loss: 0.003952, tar: 0.000038 
l0: 0.000018, l1: 0.000019, l2: 0.000053, l3: 0.000172, l4: 0.000440, l5: 0.000771, l6: 0.001700

[epoch: 721/1000, batch:   720/ 1052, ite: 189540] train loss: 0.003923, tar: 0.000038 
l0: 0.000028, l1: 0.000029, l2: 0.000054, l3: 0.000155, l4: 0.000513, l5: 0.001065, l6: 0.002059

[epoch: 721/1000, batch:   800/ 1052, ite: 189560] train loss: 0.003947, tar: 0.000038 
l0: 0.000015, l1: 0.000016, l2: 0.000020, l3: 0.000098, l4: 0.000618, l5: 0.001014, l6: 0.002386

[epoch: 721/1000, batch:   880/ 1052, ite: 189580] train loss: 0.003902, tar: 0.000037 
l0: 0.000045, l1: 0.000047, l2: 0.000120, l3: 0.000160, l4: 0.000472, l5: 0.001523, l6: 0.002003

[epoch: 721/1000, batch:   960/ 1052, ite: 189600] train loss: 0.003943, tar: 0.000038 
l0: 0.000199, l1: 0.000195, l2: 0.000243, l3: 0.000314, l4: 0.000564, l5: 0.000810, l6: 0.002510

[epoch: 721/1000, batch:  1040/ 1052, ite: 189620] train loss: 0.003916, tar: 0.000037 
[Epoch 721/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000060, l1: 0.000062, l2: 0.000096, l3: 0.000149, l4: 0.000467, l5: 0.001376, l6: 0.002206

[epoch: 722/1000, batch:    68/ 1052, ite: 189640] train loss: 0.003917, tar: 0.000037 
l0: 0.000063, l1: 0.000058, l2: 0.000144, l3: 0.000425, l4: 0.000695, l5: 0.002149, l6: 0.002725

[epoch: 722/1000, batch:   148/ 1052, ite: 189660] train loss: 0.003917, tar: 0.000037 
l0: 0.000061, l1: 0.000060, l2: 0.000112, l3: 0.000202, l4: 0.000632, l5: 0.000932, l6: 0.001677

[epoch: 722/1000, batch:   228/ 1052, ite: 189680] train loss: 0.003897, tar: 0.000037 
l0: 0.000025, l1: 0.000026, l2: 0.000047, l3: 0.000126, l4: 0.000380, l5: 0.001411, l6: 0.002575

[epoch: 722/1000, batch:   308/ 1052, ite: 189700] train loss: 0.003889, tar: 0.000036 
l0: 0.000012, l1: 0.000011, l2: 0.000079, l3: 0.000164, l4: 0.000360, l5: 0.000848, l6: 0.002595

[epoch: 722/1000, batch:   388/ 1052, ite: 189720] train loss: 0.003893, tar: 0.000037 
l0: 0.000021, l1: 0.000024, l2: 0.000053, l3: 0.000144, l4: 0.000316, l5: 0.000720, l6: 0.002563

[epoch: 722/1000, batch:   468/ 1052, ite: 189740] train loss: 0.003906, tar: 0.000037 
l0: 0.000016, l1: 0.000016, l2: 0.000074, l3: 0.000216, l4: 0.000444, l5: 0.001058, l6: 0.001292

[epoch: 722/1000, batch:   548/ 1052, ite: 189760] train loss: 0.003938, tar: 0.000037 
l0: 0.000010, l1: 0.000010, l2: 0.000050, l3: 0.000094, l4: 0.000310, l5: 0.000703, l6: 0.001348

[epoch: 722/1000, batch:   628/ 1052, ite: 189780] train loss: 0.003933, tar: 0.000037 
l0: 0.000012, l1: 0.000011, l2: 0.000039, l3: 0.000107, l4: 0.000494, l5: 0.000738, l6: 0.001547

[epoch: 722/1000, batch:   708/ 1052, ite: 189800] train loss: 0.003922, tar: 0.000037 
l0: 0.000044, l1: 0.000047, l2: 0.000037, l3: 0.000111, l4: 0.000331, l5: 0.001154, l6: 0.001811

[epoch: 722/1000, batch:   788/ 1052, ite: 189820] train loss: 0.003926, tar: 0.000037 
l0: 0.000051, l1: 0.000052, l2: 0.000084, l3: 0.000176, l4: 0.000312, l5: 0.000611, l6: 0.001309

[epoch: 722/1000, batch:   868/ 1052, ite: 189840] train loss: 0.003934, tar: 0.000037 
l0: 0.000006, l1: 0.000005, l2: 0.000035, l3: 0.000111, l4: 0.000249, l5: 0.000771, l6: 0.001528

[epoch: 722/1000, batch:   948/ 1052, ite: 189860] train loss: 0.003915, tar: 0.000036 
l0: 0.000120, l1: 0.000114, l2: 0.000142, l3: 0.000185, l4: 0.000473, l5: 0.001260, l6: 0.002081

[epoch: 722/1000, batch:  1028/ 1052, ite: 189880] train loss: 0.003923, tar: 0.000037 
[Epoch 722/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000042, l1: 0.000055, l2: 0.000061, l3: 0.000136, l4: 0.000366, l5: 0.000784, l6: 0.001207

[epoch: 723/1000, batch:    56/ 1052, ite: 189900] train loss: 0.003931, tar: 0.000036 
l0: 0.000023, l1: 0.000025, l2: 0.000022, l3: 0.000075, l4: 0.000420, l5: 0.000912, l6: 0.000991

[epoch: 723/1000, batch:   136/ 1052, ite: 189920] train loss: 0.003936, tar: 0.000036 
l0: 0.000018, l1: 0.000016, l2: 0.000049, l3: 0.000070, l4: 0.000283, l5: 0.001031, l6: 0.001005

[epoch: 723/1000, batch:   216/ 1052, ite: 189940] train loss: 0.003931, tar: 0.000036 
l0: 0.000034, l1: 0.000036, l2: 0.000110, l3: 0.000282, l4: 0.000487, l5: 0.000734, l6: 0.001694

[epoch: 723/1000, batch:   296/ 1052, ite: 189960] train loss: 0.003912, tar: 0.000036 
l0: 0.000324, l1: 0.000309, l2: 0.000390, l3: 0.000449, l4: 0.000557, l5: 0.001370, l6: 0.002360

[epoch: 723/1000, batch:   376/ 1052, ite: 189980] train loss: 0.003922, tar: 0.000036 
l0: 0.000039, l1: 0.000041, l2: 0.000082, l3: 0.000198, l4: 0.000646, l5: 0.001557, l6: 0.002504

[epoch: 723/1000, batch:   456/ 1052, ite: 190000] train loss: 0.003911, tar: 0.000036 
l0: 0.000016, l1: 0.000015, l2: 0.000107, l3: 0.000225, l4: 0.000435, l5: 0.000617, l6: 0.001968

[epoch: 723/1000, batch:   536/ 1052, ite: 190020] train loss: 0.003921, tar: 0.000036 
l0: 0.000041, l1: 0.000045, l2: 0.000073, l3: 0.000240, l4: 0.000254, l5: 0.000839, l6: 0.001512

[epoch: 723/1000, batch:   616/ 1052, ite: 190040] train loss: 0.003906, tar: 0.000036 
l0: 0.000007, l1: 0.000007, l2: 0.000028, l3: 0.000064, l4: 0.000222, l5: 0.000647, l6: 0.001081

[epoch: 723/1000, batch:   696/ 1052, ite: 190060] train loss: 0.003915, tar: 0.000036 
l0: 0.000030, l1: 0.000032, l2: 0.000057, l3: 0.000191, l4: 0.000241, l5: 0.000644, l6: 0.001736

[epoch: 723/1000, batch:   776/ 1052, ite: 190080] train loss: 0.003921, tar: 0.000036 
l0: 0.000009, l1: 0.000009, l2: 0.000014, l3: 0.000077, l4: 0.000266, l5: 0.000729, l6: 0.002127

[epoch: 723/1000, batch:   856/ 1052, ite: 190100] train loss: 0.003924, tar: 0.000036 
l0: 0.000002, l1: 0.000002, l2: 0.000020, l3: 0.000141, l4: 0.000362, l5: 0.000719, l6: 0.001952

[epoch: 723/1000, batch:   936/ 1052, ite: 190120] train loss: 0.003916, tar: 0.000036 
l0: 0.000038, l1: 0.000038, l2: 0.000095, l3: 0.000280, l4: 0.000600, l5: 0.000910, l6: 0.002790

[epoch: 723/1000, batch:  1016/ 1052, ite: 190140] train loss: 0.003916, tar: 0.000036 
[Epoch 723/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000014, l1: 0.000015, l2: 0.000088, l3: 0.000219, l4: 0.000469, l5: 0.001264, l6: 0.002410

[epoch: 724/1000, batch:    44/ 1052, ite: 190160] train loss: 0.003918, tar: 0.000036 
l0: 0.000023, l1: 0.000023, l2: 0.000049, l3: 0.000138, l4: 0.000281, l5: 0.001345, l6: 0.001471

[epoch: 724/1000, batch:   124/ 1052, ite: 190180] train loss: 0.003920, tar: 0.000036 
l0: 0.000044, l1: 0.000046, l2: 0.000082, l3: 0.000301, l4: 0.000679, l5: 0.001193, l6: 0.002213

[epoch: 724/1000, batch:   204/ 1052, ite: 190200] train loss: 0.003905, tar: 0.000036 
l0: 0.000028, l1: 0.000027, l2: 0.000096, l3: 0.000221, l4: 0.000438, l5: 0.000856, l6: 0.001695

[epoch: 724/1000, batch:   284/ 1052, ite: 190220] train loss: 0.003902, tar: 0.000036 
l0: 0.000022, l1: 0.000024, l2: 0.000067, l3: 0.000231, l4: 0.000536, l5: 0.001144, l6: 0.002321

[epoch: 724/1000, batch:   364/ 1052, ite: 190240] train loss: 0.003902, tar: 0.000036 
l0: 0.000117, l1: 0.000117, l2: 0.000179, l3: 0.000423, l4: 0.000949, l5: 0.001794, l6: 0.004019

[epoch: 724/1000, batch:   444/ 1052, ite: 190260] train loss: 0.003911, tar: 0.000036 
l0: 0.000057, l1: 0.000055, l2: 0.000071, l3: 0.000170, l4: 0.000420, l5: 0.000986, l6: 0.002577

[epoch: 724/1000, batch:   524/ 1052, ite: 190280] train loss: 0.003915, tar: 0.000036 
l0: 0.000025, l1: 0.000026, l2: 0.000046, l3: 0.000106, l4: 0.000398, l5: 0.000922, l6: 0.001746

[epoch: 724/1000, batch:   604/ 1052, ite: 190300] train loss: 0.003903, tar: 0.000036 
l0: 0.000053, l1: 0.000053, l2: 0.000132, l3: 0.000324, l4: 0.000517, l5: 0.001276, l6: 0.001871

[epoch: 724/1000, batch:   684/ 1052, ite: 190320] train loss: 0.003905, tar: 0.000036 
l0: 0.000050, l1: 0.000051, l2: 0.000072, l3: 0.000218, l4: 0.000704, l5: 0.000806, l6: 0.002124

[epoch: 724/1000, batch:   764/ 1052, ite: 190340] train loss: 0.003901, tar: 0.000036 
l0: 0.000031, l1: 0.000032, l2: 0.000048, l3: 0.000124, l4: 0.000414, l5: 0.000608, l6: 0.001139

[epoch: 724/1000, batch:   844/ 1052, ite: 190360] train loss: 0.003903, tar: 0.000036 
l0: 0.000032, l1: 0.000033, l2: 0.000057, l3: 0.000153, l4: 0.000239, l5: 0.000980, l6: 0.001674

[epoch: 724/1000, batch:   924/ 1052, ite: 190380] train loss: 0.003906, tar: 0.000036 
l0: 0.000026, l1: 0.000025, l2: 0.000062, l3: 0.000312, l4: 0.000780, l5: 0.001085, l6: 0.002069

[epoch: 724/1000, batch:  1004/ 1052, ite: 190400] train loss: 0.003916, tar: 0.000036 
[Epoch 724/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000011, l1: 0.000011, l2: 0.000080, l3: 0.000246, l4: 0.000673, l5: 0.001570, l6: 0.002944

[epoch: 725/1000, batch:    32/ 1052, ite: 190420] train loss: 0.003918, tar: 0.000036 
l0: 0.000016, l1: 0.000016, l2: 0.000042, l3: 0.000094, l4: 0.000280, l5: 0.000867, l6: 0.001440

[epoch: 725/1000, batch:   112/ 1052, ite: 190440] train loss: 0.003917, tar: 0.000036 
l0: 0.000029, l1: 0.000031, l2: 0.000075, l3: 0.000234, l4: 0.000553, l5: 0.001123, l6: 0.001433

[epoch: 725/1000, batch:   192/ 1052, ite: 190460] train loss: 0.003916, tar: 0.000036 
l0: 0.000016, l1: 0.000016, l2: 0.000053, l3: 0.000127, l4: 0.000253, l5: 0.001107, l6: 0.001375

[epoch: 725/1000, batch:   272/ 1052, ite: 190480] train loss: 0.003911, tar: 0.000036 
l0: 0.000004, l1: 0.000004, l2: 0.000044, l3: 0.000233, l4: 0.000825, l5: 0.001629, l6: 0.002501

[epoch: 725/1000, batch:   352/ 1052, ite: 190500] train loss: 0.003911, tar: 0.000036 
l0: 0.000006, l1: 0.000005, l2: 0.000073, l3: 0.000191, l4: 0.000642, l5: 0.001185, l6: 0.001804

[epoch: 725/1000, batch:   432/ 1052, ite: 190520] train loss: 0.003913, tar: 0.000036 
l0: 0.000146, l1: 0.000144, l2: 0.000341, l3: 0.000491, l4: 0.000676, l5: 0.002502, l6: 0.003934

[epoch: 725/1000, batch:   512/ 1052, ite: 190540] train loss: 0.003914, tar: 0.000036 
l0: 0.000023, l1: 0.000022, l2: 0.000040, l3: 0.000095, l4: 0.000307, l5: 0.000316, l6: 0.000978

[epoch: 725/1000, batch:   592/ 1052, ite: 190560] train loss: 0.003904, tar: 0.000036 
l0: 0.000003, l1: 0.000004, l2: 0.000042, l3: 0.000167, l4: 0.000351, l5: 0.000732, l6: 0.001331

[epoch: 725/1000, batch:   672/ 1052, ite: 190580] train loss: 0.003903, tar: 0.000035 
l0: 0.000076, l1: 0.000075, l2: 0.000174, l3: 0.000372, l4: 0.000844, l5: 0.001585, l6: 0.002989

[epoch: 725/1000, batch:   752/ 1052, ite: 190600] train loss: 0.003902, tar: 0.000036 
l0: 0.000012, l1: 0.000012, l2: 0.000030, l3: 0.000110, l4: 0.000218, l5: 0.000930, l6: 0.001264

[epoch: 725/1000, batch:   832/ 1052, ite: 190620] train loss: 0.003910, tar: 0.000036 
l0: 0.000010, l1: 0.000010, l2: 0.000023, l3: 0.000103, l4: 0.000248, l5: 0.000797, l6: 0.000896

[epoch: 725/1000, batch:   912/ 1052, ite: 190640] train loss: 0.003914, tar: 0.000036 
l0: 0.000061, l1: 0.000060, l2: 0.000115, l3: 0.000247, l4: 0.000453, l5: 0.000886, l6: 0.001244

[epoch: 725/1000, batch:   992/ 1052, ite: 190660] train loss: 0.003914, tar: 0.000036 
[Epoch 725/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000019, l1: 0.000025, l2: 0.000064, l3: 0.000206, l4: 0.000438, l5: 0.000916, l6: 0.002286

[epoch: 726/1000, batch:    20/ 1052, ite: 190680] train loss: 0.003910, tar: 0.000036 
l0: 0.000032, l1: 0.000032, l2: 0.000066, l3: 0.000139, l4: 0.000164, l5: 0.000546, l6: 0.000907

[epoch: 726/1000, batch:   100/ 1052, ite: 190700] train loss: 0.003903, tar: 0.000036 
l0: 0.000008, l1: 0.000009, l2: 0.000056, l3: 0.000190, l4: 0.000805, l5: 0.001334, l6: 0.001979

[epoch: 726/1000, batch:   180/ 1052, ite: 190720] train loss: 0.003906, tar: 0.000035 
l0: 0.000055, l1: 0.000054, l2: 0.000074, l3: 0.000213, l4: 0.000398, l5: 0.001078, l6: 0.001456

[epoch: 726/1000, batch:   260/ 1052, ite: 190740] train loss: 0.003910, tar: 0.000036 
l0: 0.000010, l1: 0.000011, l2: 0.000040, l3: 0.000096, l4: 0.000380, l5: 0.001225, l6: 0.001863

[epoch: 726/1000, batch:   340/ 1052, ite: 190760] train loss: 0.003904, tar: 0.000036 
l0: 0.000044, l1: 0.000046, l2: 0.000057, l3: 0.000130, l4: 0.000342, l5: 0.000940, l6: 0.002577

[epoch: 726/1000, batch:   420/ 1052, ite: 190780] train loss: 0.003907, tar: 0.000036 
l0: 0.000014, l1: 0.000016, l2: 0.000045, l3: 0.000141, l4: 0.000344, l5: 0.000406, l6: 0.001429

[epoch: 726/1000, batch:   500/ 1052, ite: 190800] train loss: 0.003902, tar: 0.000036 
l0: 0.000011, l1: 0.000013, l2: 0.000046, l3: 0.000122, l4: 0.000192, l5: 0.000976, l6: 0.001977

[epoch: 726/1000, batch:   580/ 1052, ite: 190820] train loss: 0.003906, tar: 0.000036 
l0: 0.000058, l1: 0.000062, l2: 0.000093, l3: 0.000163, l4: 0.000471, l5: 0.001098, l6: 0.002222

[epoch: 726/1000, batch:   660/ 1052, ite: 190840] train loss: 0.003907, tar: 0.000036 
l0: 0.000024, l1: 0.000027, l2: 0.000088, l3: 0.000335, l4: 0.000501, l5: 0.001115, l6: 0.002380

[epoch: 726/1000, batch:   740/ 1052, ite: 190860] train loss: 0.003914, tar: 0.000036 
l0: 0.000041, l1: 0.000039, l2: 0.000106, l3: 0.000385, l4: 0.000821, l5: 0.001663, l6: 0.004310

[epoch: 726/1000, batch:   820/ 1052, ite: 190880] train loss: 0.003910, tar: 0.000036 
l0: 0.000015, l1: 0.000017, l2: 0.000045, l3: 0.000099, l4: 0.000310, l5: 0.000736, l6: 0.001899

[epoch: 726/1000, batch:   900/ 1052, ite: 190900] train loss: 0.003910, tar: 0.000036 
l0: 0.000044, l1: 0.000044, l2: 0.000113, l3: 0.000218, l4: 0.000453, l5: 0.001287, l6: 0.002200

[epoch: 726/1000, batch:   980/ 1052, ite: 190920] train loss: 0.003908, tar: 0.000036 
[Epoch 726/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000030, l1: 0.000030, l2: 0.000049, l3: 0.000080, l4: 0.000465, l5: 0.000889, l6: 0.002024

[epoch: 727/1000, batch:     8/ 1052, ite: 190940] train loss: 0.003913, tar: 0.000035 
l0: 0.000003, l1: 0.000004, l2: 0.000036, l3: 0.000223, l4: 0.000690, l5: 0.001527, l6: 0.002412

[epoch: 727/1000, batch:    88/ 1052, ite: 190960] train loss: 0.003916, tar: 0.000036 
l0: 0.000071, l1: 0.000066, l2: 0.000136, l3: 0.000368, l4: 0.000708, l5: 0.001862, l6: 0.002562

[epoch: 727/1000, batch:   168/ 1052, ite: 190980] train loss: 0.003918, tar: 0.000036 
l0: 0.000012, l1: 0.000013, l2: 0.000013, l3: 0.000095, l4: 0.000253, l5: 0.000742, l6: 0.001134

[epoch: 727/1000, batch:   248/ 1052, ite: 191000] train loss: 0.003914, tar: 0.000036 
l0: 0.000029, l1: 0.000029, l2: 0.000069, l3: 0.000172, l4: 0.000476, l5: 0.000778, l6: 0.001725

[epoch: 727/1000, batch:   328/ 1052, ite: 191020] train loss: 0.003912, tar: 0.000036 
l0: 0.000057, l1: 0.000059, l2: 0.000067, l3: 0.000244, l4: 0.000429, l5: 0.001145, l6: 0.001571

[epoch: 727/1000, batch:   408/ 1052, ite: 191040] train loss: 0.003913, tar: 0.000036 
l0: 0.000027, l1: 0.000026, l2: 0.000046, l3: 0.000139, l4: 0.000543, l5: 0.000928, l6: 0.001954

[epoch: 727/1000, batch:   488/ 1052, ite: 191060] train loss: 0.003907, tar: 0.000036 
l0: 0.000058, l1: 0.000058, l2: 0.000098, l3: 0.000242, l4: 0.000822, l5: 0.001469, l6: 0.002973

[epoch: 727/1000, batch:   568/ 1052, ite: 191080] train loss: 0.003905, tar: 0.000036 
l0: 0.000050, l1: 0.000052, l2: 0.000040, l3: 0.000103, l4: 0.000361, l5: 0.000904, l6: 0.001478

[epoch: 727/1000, batch:   648/ 1052, ite: 191100] train loss: 0.003907, tar: 0.000036 
l0: 0.000029, l1: 0.000029, l2: 0.000047, l3: 0.000200, l4: 0.000403, l5: 0.000827, l6: 0.002155

[epoch: 727/1000, batch:   728/ 1052, ite: 191120] train loss: 0.003899, tar: 0.000036 
l0: 0.000028, l1: 0.000029, l2: 0.000063, l3: 0.000184, l4: 0.000397, l5: 0.001122, l6: 0.001870

[epoch: 727/1000, batch:   808/ 1052, ite: 191140] train loss: 0.003901, tar: 0.000036 
l0: 0.000021, l1: 0.000021, l2: 0.000064, l3: 0.000147, l4: 0.000290, l5: 0.000813, l6: 0.001569

[epoch: 727/1000, batch:   888/ 1052, ite: 191160] train loss: 0.003902, tar: 0.000035 
l0: 0.000028, l1: 0.000029, l2: 0.000052, l3: 0.000109, l4: 0.000311, l5: 0.000627, l6: 0.001192

[epoch: 727/1000, batch:   968/ 1052, ite: 191180] train loss: 0.003905, tar: 0.000036 
l0: 0.000012, l1: 0.000012, l2: 0.000065, l3: 0.000323, l4: 0.001070, l5: 0.001315, l6: 0.002578

[epoch: 727/1000, batch:  1048/ 1052, ite: 191200] train loss: 0.003906, tar: 0.000036 
[Epoch 727/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000041, l1: 0.000042, l2: 0.000068, l3: 0.000156, l4: 0.000475, l5: 0.001301, l6: 0.002315

[epoch: 728/1000, batch:    76/ 1052, ite: 191220] train loss: 0.003903, tar: 0.000036 
l0: 0.000057, l1: 0.000062, l2: 0.000073, l3: 0.000191, l4: 0.000909, l5: 0.002038, l6: 0.002549

[epoch: 728/1000, batch:   156/ 1052, ite: 191240] train loss: 0.003908, tar: 0.000036 
l0: 0.000011, l1: 0.000011, l2: 0.000059, l3: 0.000165, l4: 0.000423, l5: 0.001068, l6: 0.002022

[epoch: 728/1000, batch:   236/ 1052, ite: 191260] train loss: 0.003909, tar: 0.000035 
l0: 0.000028, l1: 0.000029, l2: 0.000095, l3: 0.000395, l4: 0.000684, l5: 0.001155, l6: 0.002033

[epoch: 728/1000, batch:   316/ 1052, ite: 191280] train loss: 0.003909, tar: 0.000035 
l0: 0.000029, l1: 0.000029, l2: 0.000071, l3: 0.000283, l4: 0.000507, l5: 0.001248, l6: 0.001709

[epoch: 728/1000, batch:   396/ 1052, ite: 191300] train loss: 0.003911, tar: 0.000035 
l0: 0.000004, l1: 0.000004, l2: 0.000026, l3: 0.000114, l4: 0.000326, l5: 0.000652, l6: 0.001346

[epoch: 728/1000, batch:   476/ 1052, ite: 191320] train loss: 0.003907, tar: 0.000035 
l0: 0.000160, l1: 0.000163, l2: 0.000123, l3: 0.000276, l4: 0.000427, l5: 0.001433, l6: 0.002644

[epoch: 728/1000, batch:   556/ 1052, ite: 191340] train loss: 0.003906, tar: 0.000035 
l0: 0.000014, l1: 0.000014, l2: 0.000035, l3: 0.000082, l4: 0.000243, l5: 0.000760, l6: 0.001530

[epoch: 728/1000, batch:   636/ 1052, ite: 191360] train loss: 0.003904, tar: 0.000035 
l0: 0.000025, l1: 0.000026, l2: 0.000037, l3: 0.000090, l4: 0.000327, l5: 0.000710, l6: 0.000775

[epoch: 728/1000, batch:   716/ 1052, ite: 191380] train loss: 0.003907, tar: 0.000035 
l0: 0.000042, l1: 0.000041, l2: 0.000077, l3: 0.000156, l4: 0.000368, l5: 0.000812, l6: 0.001821

[epoch: 728/1000, batch:   796/ 1052, ite: 191400] train loss: 0.003904, tar: 0.000035 
l0: 0.000067, l1: 0.000067, l2: 0.000128, l3: 0.000261, l4: 0.000565, l5: 0.001914, l6: 0.002500

[epoch: 728/1000, batch:   876/ 1052, ite: 191420] train loss: 0.003901, tar: 0.000035 
l0: 0.000112, l1: 0.000113, l2: 0.000213, l3: 0.000566, l4: 0.000995, l5: 0.003458, l6: 0.006160

[epoch: 728/1000, batch:   956/ 1052, ite: 191440] train loss: 0.003910, tar: 0.000036 
l0: 0.000028, l1: 0.000029, l2: 0.000059, l3: 0.000237, l4: 0.000531, l5: 0.001242, l6: 0.002311

[epoch: 728/1000, batch:  1036/ 1052, ite: 191460] train loss: 0.003908, tar: 0.000036 
[Epoch 728/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000003, l1: 0.000003, l2: 0.000005, l3: 0.000047, l4: 0.000183, l5: 0.000542, l6: 0.000922

[epoch: 729/1000, batch:    64/ 1052, ite: 191480] train loss: 0.003910, tar: 0.000036 
l0: 0.000010, l1: 0.000010, l2: 0.000025, l3: 0.000043, l4: 0.000208, l5: 0.000717, l6: 0.000968

[epoch: 729/1000, batch:   144/ 1052, ite: 191500] train loss: 0.003913, tar: 0.000036 
l0: 0.000046, l1: 0.000046, l2: 0.000083, l3: 0.000220, l4: 0.000560, l5: 0.001055, l6: 0.002390

[epoch: 729/1000, batch:   224/ 1052, ite: 191520] train loss: 0.003913, tar: 0.000036 
l0: 0.000038, l1: 0.000037, l2: 0.000100, l3: 0.000151, l4: 0.000482, l5: 0.001026, l6: 0.001731

[epoch: 729/1000, batch:   304/ 1052, ite: 191540] train loss: 0.003908, tar: 0.000036 
l0: 0.000032, l1: 0.000034, l2: 0.000096, l3: 0.000298, l4: 0.000710, l5: 0.001527, l6: 0.003311

[epoch: 729/1000, batch:   384/ 1052, ite: 191560] train loss: 0.003906, tar: 0.000036 
l0: 0.000005, l1: 0.000005, l2: 0.000012, l3: 0.000100, l4: 0.000180, l5: 0.000854, l6: 0.000926

[epoch: 729/1000, batch:   464/ 1052, ite: 191580] train loss: 0.003907, tar: 0.000036 
l0: 0.000008, l1: 0.000008, l2: 0.000030, l3: 0.000136, l4: 0.000442, l5: 0.000859, l6: 0.001028

[epoch: 729/1000, batch:   544/ 1052, ite: 191600] train loss: 0.003910, tar: 0.000036 
l0: 0.000063, l1: 0.000062, l2: 0.000083, l3: 0.000168, l4: 0.000412, l5: 0.000940, l6: 0.002853

[epoch: 729/1000, batch:   624/ 1052, ite: 191620] train loss: 0.003912, tar: 0.000036 
l0: 0.000011, l1: 0.000011, l2: 0.000046, l3: 0.000126, l4: 0.000338, l5: 0.000710, l6: 0.001259

[epoch: 729/1000, batch:   704/ 1052, ite: 191640] train loss: 0.003913, tar: 0.000036 
l0: 0.000021, l1: 0.000023, l2: 0.000063, l3: 0.000271, l4: 0.000709, l5: 0.000961, l6: 0.002855

[epoch: 729/1000, batch:   784/ 1052, ite: 191660] train loss: 0.003912, tar: 0.000036 
l0: 0.000035, l1: 0.000036, l2: 0.000040, l3: 0.000147, l4: 0.000413, l5: 0.000911, l6: 0.001164

[epoch: 729/1000, batch:   864/ 1052, ite: 191680] train loss: 0.003910, tar: 0.000036 
l0: 0.000017, l1: 0.000017, l2: 0.000034, l3: 0.000098, l4: 0.000342, l5: 0.000593, l6: 0.001484

[epoch: 729/1000, batch:   944/ 1052, ite: 191700] train loss: 0.003907, tar: 0.000036 
l0: 0.000010, l1: 0.000010, l2: 0.000024, l3: 0.000066, l4: 0.000272, l5: 0.000975, l6: 0.001293

[epoch: 729/1000, batch:  1024/ 1052, ite: 191720] train loss: 0.003905, tar: 0.000036 
[Epoch 729/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000020, l1: 0.000020, l2: 0.000060, l3: 0.000133, l4: 0.000351, l5: 0.001676, l6: 0.002174

[epoch: 730/1000, batch:    52/ 1052, ite: 191740] train loss: 0.003906, tar: 0.000036 
l0: 0.000041, l1: 0.000040, l2: 0.000095, l3: 0.000180, l4: 0.000565, l5: 0.001128, l6: 0.001394

[epoch: 730/1000, batch:   132/ 1052, ite: 191760] train loss: 0.003905, tar: 0.000036 
l0: 0.000004, l1: 0.000005, l2: 0.000031, l3: 0.000143, l4: 0.000483, l5: 0.001485, l6: 0.001793

[epoch: 730/1000, batch:   212/ 1052, ite: 191780] train loss: 0.003909, tar: 0.000036 
l0: 0.000067, l1: 0.000066, l2: 0.000063, l3: 0.000133, l4: 0.000180, l5: 0.000314, l6: 0.000617

[epoch: 730/1000, batch:   292/ 1052, ite: 191800] train loss: 0.003906, tar: 0.000036 
l0: 0.000020, l1: 0.000022, l2: 0.000063, l3: 0.000172, l4: 0.000458, l5: 0.001548, l6: 0.003346

[epoch: 730/1000, batch:   372/ 1052, ite: 191820] train loss: 0.003904, tar: 0.000036 
l0: 0.000012, l1: 0.000012, l2: 0.000028, l3: 0.000083, l4: 0.000414, l5: 0.001029, l6: 0.001911

[epoch: 730/1000, batch:   452/ 1052, ite: 191840] train loss: 0.003905, tar: 0.000036 
l0: 0.000013, l1: 0.000013, l2: 0.000028, l3: 0.000092, l4: 0.000259, l5: 0.000843, l6: 0.001472

[epoch: 730/1000, batch:   532/ 1052, ite: 191860] train loss: 0.003906, tar: 0.000036 
l0: 0.000007, l1: 0.000008, l2: 0.000041, l3: 0.000131, l4: 0.000338, l5: 0.001192, l6: 0.001862

[epoch: 730/1000, batch:   612/ 1052, ite: 191880] train loss: 0.003906, tar: 0.000036 
l0: 0.000045, l1: 0.000048, l2: 0.000045, l3: 0.000088, l4: 0.000329, l5: 0.000847, l6: 0.001451

[epoch: 730/1000, batch:   692/ 1052, ite: 191900] train loss: 0.003907, tar: 0.000036 
l0: 0.000027, l1: 0.000025, l2: 0.000072, l3: 0.000193, l4: 0.000451, l5: 0.000801, l6: 0.001081

[epoch: 730/1000, batch:   772/ 1052, ite: 191920] train loss: 0.003908, tar: 0.000036 
l0: 0.000042, l1: 0.000040, l2: 0.000099, l3: 0.000459, l4: 0.000705, l5: 0.001467, l6: 0.002129

[epoch: 730/1000, batch:   852/ 1052, ite: 191940] train loss: 0.003912, tar: 0.000036 
l0: 0.000085, l1: 0.000086, l2: 0.000118, l3: 0.000250, l4: 0.000486, l5: 0.001450, l6: 0.002904

[epoch: 730/1000, batch:   932/ 1052, ite: 191960] train loss: 0.003913, tar: 0.000036 
l0: 0.000020, l1: 0.000020, l2: 0.000048, l3: 0.000197, l4: 0.000443, l5: 0.000982, l6: 0.001571

[epoch: 730/1000, batch:  1012/ 1052, ite: 191980] train loss: 0.003909, tar: 0.000036 
[Epoch 730/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000037, l1: 0.000038, l2: 0.000127, l3: 0.000338, l4: 0.000718, l5: 0.001098, l6: 0.001708

[epoch: 731/1000, batch:    40/ 1052, ite: 192000] train loss: 0.003907, tar: 0.000036 
l0: 0.000042, l1: 0.000045, l2: 0.000130, l3: 0.000172, l4: 0.000472, l5: 0.000832, l6: 0.002435

[epoch: 731/1000, batch:   120/ 1052, ite: 192020] train loss: 0.003906, tar: 0.000036 
l0: 0.000003, l1: 0.000002, l2: 0.000021, l3: 0.000053, l4: 0.000189, l5: 0.000449, l6: 0.001017

[epoch: 731/1000, batch:   200/ 1052, ite: 192040] train loss: 0.003908, tar: 0.000036 
l0: 0.000036, l1: 0.000037, l2: 0.000106, l3: 0.000442, l4: 0.001157, l5: 0.002564, l6: 0.003389

[epoch: 731/1000, batch:   280/ 1052, ite: 192060] train loss: 0.003908, tar: 0.000036 
l0: 0.000091, l1: 0.000096, l2: 0.000217, l3: 0.000397, l4: 0.000952, l5: 0.002091, l6: 0.002861

[epoch: 731/1000, batch:   360/ 1052, ite: 192080] train loss: 0.003910, tar: 0.000036 
l0: 0.000010, l1: 0.000009, l2: 0.000042, l3: 0.000133, l4: 0.000492, l5: 0.001065, l6: 0.001319

[epoch: 731/1000, batch:   440/ 1052, ite: 192100] train loss: 0.003912, tar: 0.000036 
l0: 0.000038, l1: 0.000038, l2: 0.000058, l3: 0.000122, l4: 0.000355, l5: 0.000585, l6: 0.001378

[epoch: 731/1000, batch:   520/ 1052, ite: 192120] train loss: 0.003909, tar: 0.000036 
l0: 0.000030, l1: 0.000032, l2: 0.000057, l3: 0.000144, l4: 0.000296, l5: 0.001165, l6: 0.002431

[epoch: 731/1000, batch:   600/ 1052, ite: 192140] train loss: 0.003910, tar: 0.000035 
l0: 0.000067, l1: 0.000072, l2: 0.000097, l3: 0.000207, l4: 0.000510, l5: 0.001125, l6: 0.001537

[epoch: 731/1000, batch:   680/ 1052, ite: 192160] train loss: 0.003907, tar: 0.000036 
l0: 0.000020, l1: 0.000020, l2: 0.000062, l3: 0.000131, l4: 0.000355, l5: 0.000608, l6: 0.000814

[epoch: 731/1000, batch:   760/ 1052, ite: 192180] train loss: 0.003907, tar: 0.000036 
l0: 0.000012, l1: 0.000012, l2: 0.000047, l3: 0.000112, l4: 0.000374, l5: 0.000813, l6: 0.000988

[epoch: 731/1000, batch:   840/ 1052, ite: 192200] train loss: 0.003910, tar: 0.000035 
l0: 0.000052, l1: 0.000054, l2: 0.000091, l3: 0.000199, l4: 0.000623, l5: 0.001196, l6: 0.001502

[epoch: 731/1000, batch:   920/ 1052, ite: 192220] train loss: 0.003909, tar: 0.000035 
l0: 0.000066, l1: 0.000067, l2: 0.000167, l3: 0.000365, l4: 0.000815, l5: 0.001648, l6: 0.003635

[epoch: 731/1000, batch:  1000/ 1052, ite: 192240] train loss: 0.003909, tar: 0.000035 
[Epoch 731/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000013, l1: 0.000014, l2: 0.000080, l3: 0.000210, l4: 0.000570, l5: 0.001489, l6: 0.002322

[epoch: 732/1000, batch:    28/ 1052, ite: 192260] train loss: 0.003907, tar: 0.000035 
l0: 0.000019, l1: 0.000021, l2: 0.000048, l3: 0.000162, l4: 0.000505, l5: 0.000928, l6: 0.001790

[epoch: 732/1000, batch:   108/ 1052, ite: 192280] train loss: 0.003905, tar: 0.000035 
l0: 0.000013, l1: 0.000014, l2: 0.000015, l3: 0.000114, l4: 0.000195, l5: 0.000587, l6: 0.000952

[epoch: 732/1000, batch:   188/ 1052, ite: 192300] train loss: 0.003897, tar: 0.000035 
l0: 0.000029, l1: 0.000031, l2: 0.000057, l3: 0.000137, l4: 0.000289, l5: 0.000835, l6: 0.001102

[epoch: 732/1000, batch:   268/ 1052, ite: 192320] train loss: 0.003897, tar: 0.000035 
l0: 0.000002, l1: 0.000002, l2: 0.000043, l3: 0.000128, l4: 0.000406, l5: 0.000950, l6: 0.001204

[epoch: 732/1000, batch:   348/ 1052, ite: 192340] train loss: 0.003896, tar: 0.000035 
l0: 0.000027, l1: 0.000024, l2: 0.000069, l3: 0.000314, l4: 0.000469, l5: 0.001013, l6: 0.001596

[epoch: 732/1000, batch:   428/ 1052, ite: 192360] train loss: 0.003898, tar: 0.000035 
l0: 0.000058, l1: 0.000060, l2: 0.000137, l3: 0.000441, l4: 0.000896, l5: 0.001927, l6: 0.004162

[epoch: 732/1000, batch:   508/ 1052, ite: 192380] train loss: 0.003897, tar: 0.000035 
l0: 0.000010, l1: 0.000011, l2: 0.000023, l3: 0.000082, l4: 0.000363, l5: 0.000626, l6: 0.001800

[epoch: 732/1000, batch:   588/ 1052, ite: 192400] train loss: 0.003900, tar: 0.000035 
l0: 0.000039, l1: 0.000039, l2: 0.000076, l3: 0.000124, l4: 0.000240, l5: 0.000882, l6: 0.001295

[epoch: 732/1000, batch:   668/ 1052, ite: 192420] train loss: 0.003900, tar: 0.000035 
l0: 0.000043, l1: 0.000043, l2: 0.000078, l3: 0.000210, l4: 0.000424, l5: 0.001183, l6: 0.002051

[epoch: 732/1000, batch:   748/ 1052, ite: 192440] train loss: 0.003900, tar: 0.000035 
l0: 0.000033, l1: 0.000033, l2: 0.000061, l3: 0.000135, l4: 0.000357, l5: 0.000909, l6: 0.001680

[epoch: 732/1000, batch:   828/ 1052, ite: 192460] train loss: 0.003903, tar: 0.000035 
l0: 0.000035, l1: 0.000030, l2: 0.000040, l3: 0.000061, l4: 0.000139, l5: 0.000294, l6: 0.000518

[epoch: 732/1000, batch:   908/ 1052, ite: 192480] train loss: 0.003903, tar: 0.000035 
l0: 0.000005, l1: 0.000007, l2: 0.000025, l3: 0.000084, l4: 0.000458, l5: 0.001036, l6: 0.001858

[epoch: 732/1000, batch:   988/ 1052, ite: 192500] train loss: 0.003906, tar: 0.000035 
[Epoch 732/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000038, l1: 0.000036, l2: 0.000058, l3: 0.000155, l4: 0.000405, l5: 0.001140, l6: 0.001687

[epoch: 733/1000, batch:    16/ 1052, ite: 192520] train loss: 0.003905, tar: 0.000035 
l0: 0.000030, l1: 0.000031, l2: 0.000074, l3: 0.000203, l4: 0.000414, l5: 0.001203, l6: 0.001908

[epoch: 733/1000, batch:    96/ 1052, ite: 192540] train loss: 0.003903, tar: 0.000035 
l0: 0.000024, l1: 0.000022, l2: 0.000043, l3: 0.000104, l4: 0.000292, l5: 0.000621, l6: 0.001346

[epoch: 733/1000, batch:   176/ 1052, ite: 192560] train loss: 0.003903, tar: 0.000035 
l0: 0.000017, l1: 0.000018, l2: 0.000067, l3: 0.000162, l4: 0.000574, l5: 0.000516, l6: 0.001284

[epoch: 733/1000, batch:   256/ 1052, ite: 192580] train loss: 0.003904, tar: 0.000035 
l0: 0.000031, l1: 0.000032, l2: 0.000101, l3: 0.000335, l4: 0.000547, l5: 0.001339, l6: 0.002578

[epoch: 733/1000, batch:   336/ 1052, ite: 192600] train loss: 0.003904, tar: 0.000035 
l0: 0.000011, l1: 0.000012, l2: 0.000020, l3: 0.000072, l4: 0.000243, l5: 0.000963, l6: 0.001116

[epoch: 733/1000, batch:   416/ 1052, ite: 192620] train loss: 0.003903, tar: 0.000035 
l0: 0.000038, l1: 0.000039, l2: 0.000052, l3: 0.000117, l4: 0.000421, l5: 0.000925, l6: 0.001873

[epoch: 733/1000, batch:   496/ 1052, ite: 192640] train loss: 0.003900, tar: 0.000035 
l0: 0.000033, l1: 0.000037, l2: 0.000049, l3: 0.000181, l4: 0.000590, l5: 0.001132, l6: 0.002755

[epoch: 733/1000, batch:   576/ 1052, ite: 192660] train loss: 0.003896, tar: 0.000035 
l0: 0.000016, l1: 0.000018, l2: 0.000094, l3: 0.000342, l4: 0.000710, l5: 0.001546, l6: 0.002691

[epoch: 733/1000, batch:   656/ 1052, ite: 192680] train loss: 0.003897, tar: 0.000035 
l0: 0.000034, l1: 0.000039, l2: 0.000055, l3: 0.000134, l4: 0.000371, l5: 0.000836, l6: 0.001758

[epoch: 733/1000, batch:   736/ 1052, ite: 192700] train loss: 0.003895, tar: 0.000035 
l0: 0.000029, l1: 0.000027, l2: 0.000073, l3: 0.000179, l4: 0.000367, l5: 0.000778, l6: 0.001616

[epoch: 733/1000, batch:   816/ 1052, ite: 192720] train loss: 0.003896, tar: 0.000035 
l0: 0.000068, l1: 0.000063, l2: 0.000189, l3: 0.000259, l4: 0.000481, l5: 0.000988, l6: 0.002227

[epoch: 733/1000, batch:   896/ 1052, ite: 192740] train loss: 0.003899, tar: 0.000035 
l0: 0.000058, l1: 0.000061, l2: 0.000135, l3: 0.000435, l4: 0.000805, l5: 0.002501, l6: 0.005556

[epoch: 733/1000, batch:   976/ 1052, ite: 192760] train loss: 0.003900, tar: 0.000035 
[Epoch 733/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000003, l1: 0.000003, l2: 0.000035, l3: 0.000108, l4: 0.000309, l5: 0.000475, l6: 0.001762

[epoch: 734/1000, batch:     4/ 1052, ite: 192780] train loss: 0.003904, tar: 0.000035 
l0: 0.000026, l1: 0.000026, l2: 0.000119, l3: 0.000304, l4: 0.000653, l5: 0.001265, l6: 0.003495

[epoch: 734/1000, batch:    84/ 1052, ite: 192800] train loss: 0.003904, tar: 0.000035 
l0: 0.000024, l1: 0.000024, l2: 0.000053, l3: 0.000133, l4: 0.000229, l5: 0.000422, l6: 0.000501

[epoch: 734/1000, batch:   164/ 1052, ite: 192820] train loss: 0.003901, tar: 0.000035 
l0: 0.000027, l1: 0.000029, l2: 0.000085, l3: 0.000172, l4: 0.000476, l5: 0.000720, l6: 0.001853

[epoch: 734/1000, batch:   244/ 1052, ite: 192840] train loss: 0.003901, tar: 0.000035 
l0: 0.000044, l1: 0.000042, l2: 0.000073, l3: 0.000147, l4: 0.000427, l5: 0.001153, l6: 0.001722

[epoch: 734/1000, batch:   324/ 1052, ite: 192860] train loss: 0.003899, tar: 0.000035 
l0: 0.000054, l1: 0.000053, l2: 0.000112, l3: 0.000274, l4: 0.000554, l5: 0.001288, l6: 0.003271

[epoch: 734/1000, batch:   404/ 1052, ite: 192880] train loss: 0.003899, tar: 0.000035 
l0: 0.000096, l1: 0.000096, l2: 0.000128, l3: 0.000363, l4: 0.000761, l5: 0.001449, l6: 0.002225

[epoch: 734/1000, batch:   484/ 1052, ite: 192900] train loss: 0.003899, tar: 0.000035 
l0: 0.000075, l1: 0.000074, l2: 0.000081, l3: 0.000189, l4: 0.000448, l5: 0.001325, l6: 0.002004

[epoch: 734/1000, batch:   564/ 1052, ite: 192920] train loss: 0.003898, tar: 0.000035 
l0: 0.000020, l1: 0.000021, l2: 0.000054, l3: 0.000151, l4: 0.000464, l5: 0.000890, l6: 0.001485

[epoch: 734/1000, batch:   644/ 1052, ite: 192940] train loss: 0.003897, tar: 0.000035 
l0: 0.000038, l1: 0.000038, l2: 0.000075, l3: 0.000186, l4: 0.000479, l5: 0.001225, l6: 0.001894

[epoch: 734/1000, batch:   724/ 1052, ite: 192960] train loss: 0.003896, tar: 0.000035 
l0: 0.000051, l1: 0.000052, l2: 0.000082, l3: 0.000193, l4: 0.000492, l5: 0.000937, l6: 0.002071

[epoch: 734/1000, batch:   804/ 1052, ite: 192980] train loss: 0.003898, tar: 0.000035 
l0: 0.000016, l1: 0.000015, l2: 0.000017, l3: 0.000070, l4: 0.000116, l5: 0.000353, l6: 0.000414

[epoch: 734/1000, batch:   884/ 1052, ite: 193000] train loss: 0.003901, tar: 0.000035 
l0: 0.000044, l1: 0.000044, l2: 0.000084, l3: 0.000192, l4: 0.000661, l5: 0.001606, l6: 0.002773

[epoch: 734/1000, batch:   964/ 1052, ite: 193020] train loss: 0.003901, tar: 0.000035 
l0: 0.000061, l1: 0.000062, l2: 0.000182, l3: 0.000423, l4: 0.000987, l5: 0.002130, l6: 0.003010

[epoch: 734/1000, batch:  1044/ 1052, ite: 193040] train loss: 0.003902, tar: 0.000035 
[Epoch 734/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000038, l1: 0.000037, l2: 0.000075, l3: 0.000171, l4: 0.000483, l5: 0.001200, l6: 0.002663

[epoch: 735/1000, batch:    72/ 1052, ite: 193060] train loss: 0.003903, tar: 0.000035 
l0: 0.000027, l1: 0.000027, l2: 0.000036, l3: 0.000110, l4: 0.000419, l5: 0.000887, l6: 0.001129

[epoch: 735/1000, batch:   152/ 1052, ite: 193080] train loss: 0.003906, tar: 0.000036 
l0: 0.000035, l1: 0.000036, l2: 0.000072, l3: 0.000206, l4: 0.000506, l5: 0.001096, l6: 0.001247

[epoch: 735/1000, batch:   232/ 1052, ite: 193100] train loss: 0.003906, tar: 0.000036 
l0: 0.000073, l1: 0.000073, l2: 0.000108, l3: 0.000267, l4: 0.000487, l5: 0.001283, l6: 0.003729

[epoch: 735/1000, batch:   312/ 1052, ite: 193120] train loss: 0.003905, tar: 0.000036 
l0: 0.000009, l1: 0.000011, l2: 0.000042, l3: 0.000167, l4: 0.000358, l5: 0.000816, l6: 0.001258

[epoch: 735/1000, batch:   392/ 1052, ite: 193140] train loss: 0.003906, tar: 0.000036 
l0: 0.000001, l1: 0.000001, l2: 0.000028, l3: 0.000059, l4: 0.000356, l5: 0.000533, l6: 0.000590

[epoch: 735/1000, batch:   472/ 1052, ite: 193160] train loss: 0.003906, tar: 0.000036 
l0: 0.000026, l1: 0.000024, l2: 0.000070, l3: 0.000261, l4: 0.000630, l5: 0.001094, l6: 0.002029

[epoch: 735/1000, batch:   552/ 1052, ite: 193180] train loss: 0.003905, tar: 0.000036 
l0: 0.000026, l1: 0.000024, l2: 0.000077, l3: 0.000292, l4: 0.000580, l5: 0.001222, l6: 0.002126

[epoch: 735/1000, batch:   632/ 1052, ite: 193200] train loss: 0.003904, tar: 0.000036 
l0: 0.000052, l1: 0.000051, l2: 0.000074, l3: 0.000147, l4: 0.000343, l5: 0.000618, l6: 0.002065

[epoch: 735/1000, batch:   712/ 1052, ite: 193220] train loss: 0.003903, tar: 0.000035 
l0: 0.000039, l1: 0.000036, l2: 0.000111, l3: 0.000231, l4: 0.000666, l5: 0.001227, l6: 0.001143

[epoch: 735/1000, batch:   792/ 1052, ite: 193240] train loss: 0.003900, tar: 0.000035 
l0: 0.000013, l1: 0.000014, l2: 0.000056, l3: 0.000160, l4: 0.000508, l5: 0.000928, l6: 0.001364

[epoch: 735/1000, batch:   872/ 1052, ite: 193260] train loss: 0.003899, tar: 0.000035 
l0: 0.000024, l1: 0.000023, l2: 0.000046, l3: 0.000138, l4: 0.000432, l5: 0.000869, l6: 0.001001

[epoch: 735/1000, batch:   952/ 1052, ite: 193280] train loss: 0.003898, tar: 0.000035 
l0: 0.000042, l1: 0.000040, l2: 0.000075, l3: 0.000262, l4: 0.000757, l5: 0.003018, l6: 0.003814

[epoch: 735/1000, batch:  1032/ 1052, ite: 193300] train loss: 0.003899, tar: 0.000036 
[Epoch 735/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000035, l1: 0.000035, l2: 0.000055, l3: 0.000155, l4: 0.000345, l5: 0.001062, l6: 0.001786

[epoch: 736/1000, batch:    60/ 1052, ite: 193320] train loss: 0.003899, tar: 0.000036 
l0: 0.000010, l1: 0.000009, l2: 0.000041, l3: 0.000221, l4: 0.000604, l5: 0.000827, l6: 0.002258

[epoch: 736/1000, batch:   140/ 1052, ite: 193340] train loss: 0.003898, tar: 0.000035 
l0: 0.000013, l1: 0.000013, l2: 0.000023, l3: 0.000069, l4: 0.000386, l5: 0.000740, l6: 0.001681

[epoch: 736/1000, batch:   220/ 1052, ite: 193360] train loss: 0.003896, tar: 0.000035 
l0: 0.000020, l1: 0.000021, l2: 0.000082, l3: 0.000192, l4: 0.000475, l5: 0.000934, l6: 0.001690

[epoch: 736/1000, batch:   300/ 1052, ite: 193380] train loss: 0.003896, tar: 0.000035 
l0: 0.000024, l1: 0.000022, l2: 0.000047, l3: 0.000102, l4: 0.000232, l5: 0.000828, l6: 0.000854

[epoch: 736/1000, batch:   380/ 1052, ite: 193400] train loss: 0.003897, tar: 0.000035 
l0: 0.000011, l1: 0.000011, l2: 0.000040, l3: 0.000142, l4: 0.000257, l5: 0.000765, l6: 0.001193

[epoch: 736/1000, batch:   460/ 1052, ite: 193420] train loss: 0.003899, tar: 0.000035 
l0: 0.000022, l1: 0.000022, l2: 0.000077, l3: 0.000227, l4: 0.000463, l5: 0.001085, l6: 0.001438

[epoch: 736/1000, batch:   540/ 1052, ite: 193440] train loss: 0.003899, tar: 0.000035 
l0: 0.000060, l1: 0.000060, l2: 0.000096, l3: 0.000247, l4: 0.000447, l5: 0.001313, l6: 0.002580

[epoch: 736/1000, batch:   620/ 1052, ite: 193460] train loss: 0.003899, tar: 0.000035 
l0: 0.000020, l1: 0.000022, l2: 0.000120, l3: 0.000336, l4: 0.000763, l5: 0.001324, l6: 0.002383

[epoch: 736/1000, batch:   700/ 1052, ite: 193480] train loss: 0.003898, tar: 0.000035 
l0: 0.000004, l1: 0.000005, l2: 0.000018, l3: 0.000105, l4: 0.000504, l5: 0.001021, l6: 0.001595

[epoch: 736/1000, batch:   780/ 1052, ite: 193500] train loss: 0.003898, tar: 0.000035 
l0: 0.000022, l1: 0.000024, l2: 0.000105, l3: 0.000360, l4: 0.000804, l5: 0.001325, l6: 0.002000

[epoch: 736/1000, batch:   860/ 1052, ite: 193520] train loss: 0.003901, tar: 0.000035 
l0: 0.000046, l1: 0.000052, l2: 0.000052, l3: 0.000136, l4: 0.000378, l5: 0.001173, l6: 0.001111

[epoch: 736/1000, batch:   940/ 1052, ite: 193540] train loss: 0.003900, tar: 0.000035 
l0: 0.000026, l1: 0.000028, l2: 0.000184, l3: 0.000420, l4: 0.000867, l5: 0.002371, l6: 0.004199

[epoch: 736/1000, batch:  1020/ 1052, ite: 193560] train loss: 0.003899, tar: 0.000035 
[Epoch 736/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000010, l1: 0.000011, l2: 0.000044, l3: 0.000110, l4: 0.000298, l5: 0.000732, l6: 0.001180

[epoch: 737/1000, batch:    48/ 1052, ite: 193580] train loss: 0.003898, tar: 0.000035 
l0: 0.000023, l1: 0.000022, l2: 0.000046, l3: 0.000122, l4: 0.000408, l5: 0.000781, l6: 0.001539

[epoch: 737/1000, batch:   128/ 1052, ite: 193600] train loss: 0.003900, tar: 0.000035 
l0: 0.000023, l1: 0.000022, l2: 0.000063, l3: 0.000166, l4: 0.000408, l5: 0.000829, l6: 0.001425

[epoch: 737/1000, batch:   208/ 1052, ite: 193620] train loss: 0.003899, tar: 0.000035 
l0: 0.000008, l1: 0.000008, l2: 0.000049, l3: 0.000194, l4: 0.000480, l5: 0.000949, l6: 0.002223

[epoch: 737/1000, batch:   288/ 1052, ite: 193640] train loss: 0.003900, tar: 0.000035 
l0: 0.000021, l1: 0.000023, l2: 0.000037, l3: 0.000150, l4: 0.000519, l5: 0.001361, l6: 0.002442

[epoch: 737/1000, batch:   368/ 1052, ite: 193660] train loss: 0.003900, tar: 0.000035 
l0: 0.000064, l1: 0.000067, l2: 0.000121, l3: 0.000208, l4: 0.000457, l5: 0.000886, l6: 0.003145

[epoch: 737/1000, batch:   448/ 1052, ite: 193680] train loss: 0.003898, tar: 0.000035 
l0: 0.000040, l1: 0.000041, l2: 0.000069, l3: 0.000219, l4: 0.000457, l5: 0.001420, l6: 0.001551

[epoch: 737/1000, batch:   528/ 1052, ite: 193700] train loss: 0.003898, tar: 0.000035 
l0: 0.000001, l1: 0.000001, l2: 0.000005, l3: 0.000089, l4: 0.000327, l5: 0.000628, l6: 0.000897

[epoch: 737/1000, batch:   608/ 1052, ite: 193720] train loss: 0.003896, tar: 0.000035 
l0: 0.000019, l1: 0.000020, l2: 0.000022, l3: 0.000080, l4: 0.000254, l5: 0.000660, l6: 0.000914

[epoch: 737/1000, batch:   688/ 1052, ite: 193740] train loss: 0.003896, tar: 0.000035 
l0: 0.000032, l1: 0.000037, l2: 0.000024, l3: 0.000087, l4: 0.000222, l5: 0.000666, l6: 0.001378

[epoch: 737/1000, batch:   768/ 1052, ite: 193760] train loss: 0.003896, tar: 0.000035 
l0: 0.000005, l1: 0.000005, l2: 0.000015, l3: 0.000095, l4: 0.000247, l5: 0.000910, l6: 0.000723

[epoch: 737/1000, batch:   848/ 1052, ite: 193780] train loss: 0.003896, tar: 0.000035 
l0: 0.000002, l1: 0.000002, l2: 0.000012, l3: 0.000058, l4: 0.000335, l5: 0.000881, l6: 0.001165

[epoch: 737/1000, batch:   928/ 1052, ite: 193800] train loss: 0.003897, tar: 0.000035 
l0: 0.000046, l1: 0.000047, l2: 0.000101, l3: 0.000248, l4: 0.000533, l5: 0.000940, l6: 0.002532

[epoch: 737/1000, batch:  1008/ 1052, ite: 193820] train loss: 0.003897, tar: 0.000035 
[Epoch 737/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000014, l1: 0.000013, l2: 0.000044, l3: 0.000132, l4: 0.000715, l5: 0.001170, l6: 0.002885

[epoch: 738/1000, batch:    36/ 1052, ite: 193840] train loss: 0.003897, tar: 0.000035 
l0: 0.000067, l1: 0.000067, l2: 0.000107, l3: 0.000294, l4: 0.000595, l5: 0.001358, l6: 0.003262

[epoch: 738/1000, batch:   116/ 1052, ite: 193860] train loss: 0.003899, tar: 0.000035 
l0: 0.000010, l1: 0.000011, l2: 0.000047, l3: 0.000186, l4: 0.000357, l5: 0.001077, l6: 0.001407

[epoch: 738/1000, batch:   196/ 1052, ite: 193880] train loss: 0.003899, tar: 0.000035 
l0: 0.000023, l1: 0.000023, l2: 0.000036, l3: 0.000129, l4: 0.000354, l5: 0.000620, l6: 0.001456

[epoch: 738/1000, batch:   276/ 1052, ite: 193900] train loss: 0.003900, tar: 0.000035 
l0: 0.000023, l1: 0.000021, l2: 0.000057, l3: 0.000117, l4: 0.000322, l5: 0.001415, l6: 0.001379

[epoch: 738/1000, batch:   356/ 1052, ite: 193920] train loss: 0.003899, tar: 0.000035 
l0: 0.000064, l1: 0.000062, l2: 0.000121, l3: 0.000195, l4: 0.000403, l5: 0.000680, l6: 0.001014

[epoch: 738/1000, batch:   436/ 1052, ite: 193940] train loss: 0.003898, tar: 0.000035 
l0: 0.000038, l1: 0.000035, l2: 0.000094, l3: 0.000133, l4: 0.000284, l5: 0.000606, l6: 0.001410

[epoch: 738/1000, batch:   516/ 1052, ite: 193960] train loss: 0.003898, tar: 0.000035 
l0: 0.000017, l1: 0.000015, l2: 0.000077, l3: 0.000307, l4: 0.000630, l5: 0.001353, l6: 0.002788

[epoch: 738/1000, batch:   596/ 1052, ite: 193980] train loss: 0.003898, tar: 0.000035 
l0: 0.000091, l1: 0.000094, l2: 0.000137, l3: 0.000197, l4: 0.000472, l5: 0.001123, l6: 0.001614

[epoch: 738/1000, batch:   676/ 1052, ite: 194000] train loss: 0.003899, tar: 0.000035 
l0: 0.000041, l1: 0.000043, l2: 0.000153, l3: 0.000451, l4: 0.001078, l5: 0.002000, l6: 0.003218

[epoch: 738/1000, batch:   756/ 1052, ite: 194020] train loss: 0.003899, tar: 0.000035 
l0: 0.000032, l1: 0.000029, l2: 0.000116, l3: 0.000266, l4: 0.000509, l5: 0.001356, l6: 0.002628

[epoch: 738/1000, batch:   836/ 1052, ite: 194040] train loss: 0.003901, tar: 0.000035 
l0: 0.000032, l1: 0.000031, l2: 0.000134, l3: 0.000300, l4: 0.000670, l5: 0.001425, l6: 0.002150

[epoch: 738/1000, batch:   916/ 1052, ite: 194060] train loss: 0.003901, tar: 0.000035 
l0: 0.000018, l1: 0.000021, l2: 0.000021, l3: 0.000102, l4: 0.000357, l5: 0.000864, l6: 0.001503

[epoch: 738/1000, batch:   996/ 1052, ite: 194080] train loss: 0.003899, tar: 0.000035 
[Epoch 738/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000008, l1: 0.000008, l2: 0.000017, l3: 0.000055, l4: 0.000256, l5: 0.000966, l6: 0.001474

[epoch: 739/1000, batch:    24/ 1052, ite: 194100] train loss: 0.003897, tar: 0.000035 
l0: 0.000030, l1: 0.000030, l2: 0.000097, l3: 0.000193, l4: 0.000462, l5: 0.000781, l6: 0.001650

[epoch: 739/1000, batch:   104/ 1052, ite: 194120] train loss: 0.003896, tar: 0.000035 
l0: 0.000019, l1: 0.000017, l2: 0.000074, l3: 0.000209, l4: 0.000431, l5: 0.001043, l6: 0.002475

[epoch: 739/1000, batch:   184/ 1052, ite: 194140] train loss: 0.003895, tar: 0.000035 
l0: 0.000023, l1: 0.000024, l2: 0.000037, l3: 0.000099, l4: 0.000308, l5: 0.000695, l6: 0.002242

[epoch: 739/1000, batch:   264/ 1052, ite: 194160] train loss: 0.003895, tar: 0.000035 
l0: 0.000051, l1: 0.000055, l2: 0.000119, l3: 0.000286, l4: 0.000905, l5: 0.001996, l6: 0.002683

[epoch: 739/1000, batch:   344/ 1052, ite: 194180] train loss: 0.003898, tar: 0.000035 
l0: 0.000046, l1: 0.000050, l2: 0.000154, l3: 0.000332, l4: 0.000660, l5: 0.001769, l6: 0.002567

[epoch: 739/1000, batch:   424/ 1052, ite: 194200] train loss: 0.003899, tar: 0.000035 
l0: 0.000004, l1: 0.000004, l2: 0.000020, l3: 0.000095, l4: 0.000259, l5: 0.000846, l6: 0.001012

[epoch: 739/1000, batch:   504/ 1052, ite: 194220] train loss: 0.003897, tar: 0.000035 
l0: 0.000024, l1: 0.000026, l2: 0.000072, l3: 0.000174, l4: 0.000574, l5: 0.001605, l6: 0.003162

[epoch: 739/1000, batch:   584/ 1052, ite: 194240] train loss: 0.003898, tar: 0.000035 
l0: 0.000004, l1: 0.000005, l2: 0.000009, l3: 0.000082, l4: 0.000226, l5: 0.000256, l6: 0.000890

[epoch: 739/1000, batch:   664/ 1052, ite: 194260] train loss: 0.003896, tar: 0.000035 
l0: 0.000003, l1: 0.000003, l2: 0.000028, l3: 0.000095, l4: 0.000244, l5: 0.000750, l6: 0.001412

[epoch: 739/1000, batch:   744/ 1052, ite: 194280] train loss: 0.003895, tar: 0.000035 
l0: 0.000031, l1: 0.000031, l2: 0.000066, l3: 0.000217, l4: 0.000614, l5: 0.001293, l6: 0.001451

[epoch: 739/1000, batch:   824/ 1052, ite: 194300] train loss: 0.003896, tar: 0.000035 
l0: 0.000037, l1: 0.000035, l2: 0.000095, l3: 0.000237, l4: 0.000691, l5: 0.001415, l6: 0.002080

[epoch: 739/1000, batch:   904/ 1052, ite: 194320] train loss: 0.003898, tar: 0.000035 
l0: 0.000015, l1: 0.000015, l2: 0.000085, l3: 0.000193, l4: 0.000347, l5: 0.000835, l6: 0.001831

[epoch: 739/1000, batch:   984/ 1052, ite: 194340] train loss: 0.003897, tar: 0.000035 
[Epoch 739/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000029, l1: 0.000030, l2: 0.000073, l3: 0.000281, l4: 0.000518, l5: 0.001109, l6: 0.003319

[epoch: 740/1000, batch:    12/ 1052, ite: 194360] train loss: 0.003899, tar: 0.000035 
l0: 0.000007, l1: 0.000007, l2: 0.000024, l3: 0.000086, l4: 0.000235, l5: 0.000586, l6: 0.001414

[epoch: 740/1000, batch:    92/ 1052, ite: 194380] train loss: 0.003901, tar: 0.000035 
l0: 0.000019, l1: 0.000019, l2: 0.000045, l3: 0.000176, l4: 0.000432, l5: 0.001256, l6: 0.002125

[epoch: 740/1000, batch:   172/ 1052, ite: 194400] train loss: 0.003901, tar: 0.000035 
l0: 0.000164, l1: 0.000160, l2: 0.000188, l3: 0.000269, l4: 0.000533, l5: 0.001202, l6: 0.002910

[epoch: 740/1000, batch:   252/ 1052, ite: 194420] train loss: 0.003900, tar: 0.000035 
l0: 0.000072, l1: 0.000073, l2: 0.000100, l3: 0.000176, l4: 0.000667, l5: 0.001658, l6: 0.002590

[epoch: 740/1000, batch:   332/ 1052, ite: 194440] train loss: 0.003900, tar: 0.000035 
l0: 0.000009, l1: 0.000010, l2: 0.000028, l3: 0.000133, l4: 0.000221, l5: 0.000666, l6: 0.001439

[epoch: 740/1000, batch:   412/ 1052, ite: 194460] train loss: 0.003899, tar: 0.000035 
l0: 0.000054, l1: 0.000051, l2: 0.000097, l3: 0.000189, l4: 0.000319, l5: 0.001223, l6: 0.001070

[epoch: 740/1000, batch:   492/ 1052, ite: 194480] train loss: 0.003900, tar: 0.000035 
l0: 0.000011, l1: 0.000011, l2: 0.000038, l3: 0.000156, l4: 0.000448, l5: 0.001194, l6: 0.002626

[epoch: 740/1000, batch:   572/ 1052, ite: 194500] train loss: 0.003900, tar: 0.000035 
l0: 0.000003, l1: 0.000003, l2: 0.000040, l3: 0.000113, l4: 0.000340, l5: 0.000641, l6: 0.001097

[epoch: 740/1000, batch:   652/ 1052, ite: 194520] train loss: 0.003899, tar: 0.000035 
l0: 0.000014, l1: 0.000015, l2: 0.000035, l3: 0.000154, l4: 0.000670, l5: 0.001261, l6: 0.001932

[epoch: 740/1000, batch:   732/ 1052, ite: 194540] train loss: 0.003899, tar: 0.000035 
l0: 0.000058, l1: 0.000056, l2: 0.000118, l3: 0.000312, l4: 0.000829, l5: 0.002009, l6: 0.004033

[epoch: 740/1000, batch:   812/ 1052, ite: 194560] train loss: 0.003901, tar: 0.000035 
l0: 0.000025, l1: 0.000026, l2: 0.000069, l3: 0.000275, l4: 0.000683, l5: 0.001228, l6: 0.002284

[epoch: 740/1000, batch:   892/ 1052, ite: 194580] train loss: 0.003902, tar: 0.000035 
l0: 0.000018, l1: 0.000018, l2: 0.000029, l3: 0.000139, l4: 0.000303, l5: 0.000827, l6: 0.001836

[epoch: 740/1000, batch:   972/ 1052, ite: 194600] train loss: 0.003902, tar: 0.000035 
l0: 0.000018, l1: 0.000018, l2: 0.000040, l3: 0.000128, l4: 0.000280, l5: 0.001108, l6: 0.001495

[epoch: 740/1000, batch:  1052/ 1052, ite: 194620] train loss: 0.003901, tar: 0.000035 
[Epoch 740/1000] Test loss: 0.018, Test target loss: 0.004
l0: 0.000031, l1: 0.000033, l2: 0.000083, l3: 0.000422, l4: 0.001116, l5: 0.001615, l6: 0.002681

[epoch: 741/1000, batch:    80/ 1052, ite: 194640] train loss: 0.003900, tar: 0.000035 
l0: 0.000046, l1: 0.000047, l2: 0.000071, l3: 0.000309, l4: 0.000578, l5: 0.001381, l6: 0.001902

[epoch: 741/1000, batch:   160/ 1052, ite: 194660] train loss: 0.003900, tar: 0.000035 
l0: 0.000394, l1: 0.000389, l2: 0.000394, l3: 0.000449, l4: 0.000549, l5: 0.001240, l6: 0.002376

[epoch: 741/1000, batch:   240/ 1052, ite: 194680] train loss: 0.003903, tar: 0.000035 
l0: 0.000039, l1: 0.000040, l2: 0.000107, l3: 0.000207, l4: 0.000494, l5: 0.000875, l6: 0.001651

[epoch: 741/1000, batch:   320/ 1052, ite: 194700] train loss: 0.003904, tar: 0.000035 
l0: 0.000160, l1: 0.000171, l2: 0.000199, l3: 0.000334, l4: 0.000497, l5: 0.000907, l6: 0.001810

[epoch: 741/1000, batch:   400/ 1052, ite: 194720] train loss: 0.003908, tar: 0.000036 
l0: 0.000063, l1: 0.000073, l2: 0.000090, l3: 0.000195, l4: 0.000350, l5: 0.000772, l6: 0.002156

[epoch: 741/1000, batch:   480/ 1052, ite: 194740] train loss: 0.003908, tar: 0.000036 
l0: 0.000073, l1: 0.000082, l2: 0.000089, l3: 0.000127, l4: 0.000222, l5: 0.001084, l6: 0.001772

[epoch: 741/1000, batch:   560/ 1052, ite: 194760] train loss: 0.003910, tar: 0.000037 
l0: 0.000093, l1: 0.000104, l2: 0.000155, l3: 0.000411, l4: 0.000644, l5: 0.001392, l6: 0.002703

[epoch: 741/1000, batch:   640/ 1052, ite: 194780] train loss: 0.003911, tar: 0.000037 
l0: 0.000043, l1: 0.000043, l2: 0.000068, l3: 0.000135, l4: 0.000302, l5: 0.001164, l6: 0.001963

[epoch: 741/1000, batch:   720/ 1052, ite: 194800] train loss: 0.003910, tar: 0.000037 
l0: 0.000018, l1: 0.000017, l2: 0.000059, l3: 0.000157, l4: 0.000499, l5: 0.001424, l6: 0.001673

[epoch: 741/1000, batch:   800/ 1052, ite: 194820] train loss: 0.003912, tar: 0.000037 
l0: 0.000009, l1: 0.000010, l2: 0.000012, l3: 0.000081, l4: 0.000212, l5: 0.000721, l6: 0.000808

[epoch: 741/1000, batch:   880/ 1052, ite: 194840] train loss: 0.003911, tar: 0.000037 
l0: 0.000065, l1: 0.000060, l2: 0.000117, l3: 0.000335, l4: 0.000774, l5: 0.001623, l6: 0.002674

[epoch: 741/1000, batch:   960/ 1052, ite: 194860] train loss: 0.003911, tar: 0.000037 
l0: 0.000017, l1: 0.000021, l2: 0.000032, l3: 0.000078, l4: 0.000205, l5: 0.000427, l6: 0.001095

[epoch: 741/1000, batch:  1040/ 1052, ite: 194880] train loss: 0.003911, tar: 0.000037 
[Epoch 741/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000062, l1: 0.000065, l2: 0.000177, l3: 0.000332, l4: 0.000732, l5: 0.002390, l6: 0.003716

[epoch: 742/1000, batch:    68/ 1052, ite: 194900] train loss: 0.003912, tar: 0.000037 
l0: 0.000069, l1: 0.000071, l2: 0.000097, l3: 0.000231, l4: 0.000414, l5: 0.001025, l6: 0.002055

[epoch: 742/1000, batch:   148/ 1052, ite: 194920] train loss: 0.003912, tar: 0.000037 
l0: 0.000052, l1: 0.000046, l2: 0.000152, l3: 0.000306, l4: 0.000934, l5: 0.001496, l6: 0.001985

[epoch: 742/1000, batch:   228/ 1052, ite: 194940] train loss: 0.003912, tar: 0.000037 
l0: 0.000037, l1: 0.000036, l2: 0.000058, l3: 0.000091, l4: 0.000341, l5: 0.000640, l6: 0.001107

[epoch: 742/1000, batch:   308/ 1052, ite: 194960] train loss: 0.003913, tar: 0.000037 
l0: 0.000030, l1: 0.000031, l2: 0.000058, l3: 0.000114, l4: 0.000363, l5: 0.001040, l6: 0.001322

[epoch: 742/1000, batch:   388/ 1052, ite: 194980] train loss: 0.003913, tar: 0.000037 
l0: 0.000018, l1: 0.000017, l2: 0.000073, l3: 0.000163, l4: 0.000379, l5: 0.000908, l6: 0.001267

[epoch: 742/1000, batch:   468/ 1052, ite: 195000] train loss: 0.003912, tar: 0.000037 
l0: 0.000070, l1: 0.000076, l2: 0.000099, l3: 0.000162, l4: 0.000414, l5: 0.001099, l6: 0.001441

[epoch: 742/1000, batch:   548/ 1052, ite: 195020] train loss: 0.003911, tar: 0.000037 
l0: 0.000006, l1: 0.000005, l2: 0.000018, l3: 0.000076, l4: 0.000298, l5: 0.000629, l6: 0.001249

[epoch: 742/1000, batch:   628/ 1052, ite: 195040] train loss: 0.003913, tar: 0.000037 
l0: 0.000096, l1: 0.000098, l2: 0.000127, l3: 0.000284, l4: 0.000666, l5: 0.000966, l6: 0.002704

[epoch: 742/1000, batch:   708/ 1052, ite: 195060] train loss: 0.003914, tar: 0.000037 
l0: 0.000065, l1: 0.000066, l2: 0.000160, l3: 0.000407, l4: 0.001106, l5: 0.002043, l6: 0.004361

[epoch: 742/1000, batch:   788/ 1052, ite: 195080] train loss: 0.003917, tar: 0.000037 
l0: 0.000012, l1: 0.000012, l2: 0.000030, l3: 0.000100, l4: 0.000397, l5: 0.000694, l6: 0.000900

[epoch: 742/1000, batch:   868/ 1052, ite: 195100] train loss: 0.003915, tar: 0.000037 
l0: 0.000013, l1: 0.000012, l2: 0.000052, l3: 0.000114, l4: 0.000278, l5: 0.000316, l6: 0.001050

[epoch: 742/1000, batch:   948/ 1052, ite: 195120] train loss: 0.003912, tar: 0.000037 
l0: 0.000028, l1: 0.000029, l2: 0.000051, l3: 0.000136, l4: 0.000460, l5: 0.001140, l6: 0.001382

[epoch: 742/1000, batch:  1028/ 1052, ite: 195140] train loss: 0.003911, tar: 0.000037 
[Epoch 742/1000] Test loss: 0.020, Test target loss: 0.003
l0: 0.000016, l1: 0.000013, l2: 0.000031, l3: 0.000082, l4: 0.000402, l5: 0.001035, l6: 0.001056

[epoch: 743/1000, batch:    56/ 1052, ite: 195160] train loss: 0.003912, tar: 0.000037 
l0: 0.000006, l1: 0.000005, l2: 0.000030, l3: 0.000091, l4: 0.000573, l5: 0.000735, l6: 0.001224

[epoch: 743/1000, batch:   136/ 1052, ite: 195180] train loss: 0.003910, tar: 0.000037 
l0: 0.000043, l1: 0.000047, l2: 0.000057, l3: 0.000120, l4: 0.000318, l5: 0.000792, l6: 0.001723

[epoch: 743/1000, batch:   216/ 1052, ite: 195200] train loss: 0.003911, tar: 0.000037 
l0: 0.000013, l1: 0.000013, l2: 0.000046, l3: 0.000101, l4: 0.000315, l5: 0.000787, l6: 0.001011

[epoch: 743/1000, batch:   296/ 1052, ite: 195220] train loss: 0.003910, tar: 0.000037 
l0: 0.000005, l1: 0.000004, l2: 0.000026, l3: 0.000092, l4: 0.000285, l5: 0.000732, l6: 0.001577

[epoch: 743/1000, batch:   376/ 1052, ite: 195240] train loss: 0.003911, tar: 0.000037 
l0: 0.000009, l1: 0.000009, l2: 0.000027, l3: 0.000096, l4: 0.000365, l5: 0.000871, l6: 0.001342

[epoch: 743/1000, batch:   456/ 1052, ite: 195260] train loss: 0.003911, tar: 0.000037 
l0: 0.000003, l1: 0.000003, l2: 0.000012, l3: 0.000110, l4: 0.000358, l5: 0.000656, l6: 0.001335

[epoch: 743/1000, batch:   536/ 1052, ite: 195280] train loss: 0.003911, tar: 0.000037 
l0: 0.000044, l1: 0.000046, l2: 0.000067, l3: 0.000132, l4: 0.000404, l5: 0.000784, l6: 0.001407

[epoch: 743/1000, batch:   616/ 1052, ite: 195300] train loss: 0.003908, tar: 0.000037 
l0: 0.000130, l1: 0.000127, l2: 0.000202, l3: 0.000300, l4: 0.000506, l5: 0.001465, l6: 0.003096

[epoch: 743/1000, batch:   696/ 1052, ite: 195320] train loss: 0.003909, tar: 0.000037 
l0: 0.000059, l1: 0.000057, l2: 0.000144, l3: 0.000314, l4: 0.000495, l5: 0.000989, l6: 0.002053

[epoch: 743/1000, batch:   776/ 1052, ite: 195340] train loss: 0.003909, tar: 0.000037 
l0: 0.000036, l1: 0.000037, l2: 0.000150, l3: 0.000414, l4: 0.000774, l5: 0.001214, l6: 0.002401

[epoch: 743/1000, batch:   856/ 1052, ite: 195360] train loss: 0.003909, tar: 0.000037 
l0: 0.000016, l1: 0.000017, l2: 0.000030, l3: 0.000118, l4: 0.000468, l5: 0.000920, l6: 0.001924

[epoch: 743/1000, batch:   936/ 1052, ite: 195380] train loss: 0.003910, tar: 0.000037 
l0: 0.000009, l1: 0.000009, l2: 0.000025, l3: 0.000161, l4: 0.000291, l5: 0.000887, l6: 0.000809

[epoch: 743/1000, batch:  1016/ 1052, ite: 195400] train loss: 0.003911, tar: 0.000037 
[Epoch 743/1000] Test loss: 0.020, Test target loss: 0.003
l0: 0.000035, l1: 0.000037, l2: 0.000067, l3: 0.000167, l4: 0.000457, l5: 0.001533, l6: 0.002169

[epoch: 744/1000, batch:    44/ 1052, ite: 195420] train loss: 0.003911, tar: 0.000037 
l0: 0.000049, l1: 0.000045, l2: 0.000141, l3: 0.000276, l4: 0.000418, l5: 0.001123, l6: 0.002194

[epoch: 744/1000, batch:   124/ 1052, ite: 195440] train loss: 0.003911, tar: 0.000037 
l0: 0.000022, l1: 0.000020, l2: 0.000064, l3: 0.000159, l4: 0.000417, l5: 0.001134, l6: 0.002553

[epoch: 744/1000, batch:   204/ 1052, ite: 195460] train loss: 0.003910, tar: 0.000037 
l0: 0.000037, l1: 0.000039, l2: 0.000062, l3: 0.000170, l4: 0.000347, l5: 0.000998, l6: 0.001262

[epoch: 744/1000, batch:   284/ 1052, ite: 195480] train loss: 0.003911, tar: 0.000037 
l0: 0.000007, l1: 0.000006, l2: 0.000070, l3: 0.000135, l4: 0.000274, l5: 0.000752, l6: 0.001426

[epoch: 744/1000, batch:   364/ 1052, ite: 195500] train loss: 0.003909, tar: 0.000037 
l0: 0.000016, l1: 0.000015, l2: 0.000043, l3: 0.000117, l4: 0.000532, l5: 0.000850, l6: 0.001353

[epoch: 744/1000, batch:   444/ 1052, ite: 195520] train loss: 0.003910, tar: 0.000037 
l0: 0.000051, l1: 0.000052, l2: 0.000072, l3: 0.000129, l4: 0.000383, l5: 0.000944, l6: 0.002562

[epoch: 744/1000, batch:   524/ 1052, ite: 195540] train loss: 0.003911, tar: 0.000037 
l0: 0.000025, l1: 0.000026, l2: 0.000045, l3: 0.000175, l4: 0.000555, l5: 0.001464, l6: 0.001582

[epoch: 744/1000, batch:   604/ 1052, ite: 195560] train loss: 0.003910, tar: 0.000037 
l0: 0.000035, l1: 0.000036, l2: 0.000147, l3: 0.000481, l4: 0.000916, l5: 0.001751, l6: 0.003584

[epoch: 744/1000, batch:   684/ 1052, ite: 195580] train loss: 0.003910, tar: 0.000037 
l0: 0.000007, l1: 0.000007, l2: 0.000036, l3: 0.000104, l4: 0.000182, l5: 0.000514, l6: 0.000873

[epoch: 744/1000, batch:   764/ 1052, ite: 195600] train loss: 0.003911, tar: 0.000037 
l0: 0.000009, l1: 0.000007, l2: 0.000057, l3: 0.000173, l4: 0.000405, l5: 0.000883, l6: 0.001624

[epoch: 744/1000, batch:   844/ 1052, ite: 195620] train loss: 0.003910, tar: 0.000037 
l0: 0.000020, l1: 0.000021, l2: 0.000074, l3: 0.000166, l4: 0.000438, l5: 0.000727, l6: 0.001781

[epoch: 744/1000, batch:   924/ 1052, ite: 195640] train loss: 0.003910, tar: 0.000037 
l0: 0.000010, l1: 0.000011, l2: 0.000038, l3: 0.000109, l4: 0.000317, l5: 0.000768, l6: 0.001561

[epoch: 744/1000, batch:  1004/ 1052, ite: 195660] train loss: 0.003909, tar: 0.000037 
[Epoch 744/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000022, l1: 0.000021, l2: 0.000063, l3: 0.000144, l4: 0.000198, l5: 0.001201, l6: 0.002052

[epoch: 745/1000, batch:    32/ 1052, ite: 195680] train loss: 0.003909, tar: 0.000037 
l0: 0.000026, l1: 0.000025, l2: 0.000066, l3: 0.000168, l4: 0.000427, l5: 0.000926, l6: 0.002048

[epoch: 745/1000, batch:   112/ 1052, ite: 195700] train loss: 0.003908, tar: 0.000037 
l0: 0.000046, l1: 0.000045, l2: 0.000148, l3: 0.000270, l4: 0.000584, l5: 0.001852, l6: 0.002788

[epoch: 745/1000, batch:   192/ 1052, ite: 195720] train loss: 0.003908, tar: 0.000037 
l0: 0.000014, l1: 0.000015, l2: 0.000015, l3: 0.000048, l4: 0.000203, l5: 0.000703, l6: 0.001372

[epoch: 745/1000, batch:   272/ 1052, ite: 195740] train loss: 0.003908, tar: 0.000037 
l0: 0.000024, l1: 0.000021, l2: 0.000077, l3: 0.000236, l4: 0.000600, l5: 0.002340, l6: 0.003009

[epoch: 745/1000, batch:   352/ 1052, ite: 195760] train loss: 0.003909, tar: 0.000037 
l0: 0.000043, l1: 0.000048, l2: 0.000079, l3: 0.000236, l4: 0.000307, l5: 0.001106, l6: 0.002205

[epoch: 745/1000, batch:   432/ 1052, ite: 195780] train loss: 0.003909, tar: 0.000037 
l0: 0.000010, l1: 0.000011, l2: 0.000032, l3: 0.000090, l4: 0.000327, l5: 0.000761, l6: 0.001733

[epoch: 745/1000, batch:   512/ 1052, ite: 195800] train loss: 0.003908, tar: 0.000037 
l0: 0.000031, l1: 0.000031, l2: 0.000035, l3: 0.000131, l4: 0.000330, l5: 0.001244, l6: 0.001518

[epoch: 745/1000, batch:   592/ 1052, ite: 195820] train loss: 0.003908, tar: 0.000037 
l0: 0.000009, l1: 0.000009, l2: 0.000065, l3: 0.000211, l4: 0.000441, l5: 0.000991, l6: 0.001681

[epoch: 745/1000, batch:   672/ 1052, ite: 195840] train loss: 0.003907, tar: 0.000037 
l0: 0.000037, l1: 0.000040, l2: 0.000033, l3: 0.000096, l4: 0.000302, l5: 0.000584, l6: 0.001456

[epoch: 745/1000, batch:   752/ 1052, ite: 195860] train loss: 0.003907, tar: 0.000037 
l0: 0.000056, l1: 0.000051, l2: 0.000174, l3: 0.000465, l4: 0.000938, l5: 0.001707, l6: 0.002204

[epoch: 745/1000, batch:   832/ 1052, ite: 195880] train loss: 0.003908, tar: 0.000037 
l0: 0.000025, l1: 0.000024, l2: 0.000032, l3: 0.000082, l4: 0.000471, l5: 0.001141, l6: 0.001549

[epoch: 745/1000, batch:   912/ 1052, ite: 195900] train loss: 0.003907, tar: 0.000037 
l0: 0.000047, l1: 0.000050, l2: 0.000163, l3: 0.000454, l4: 0.000815, l5: 0.001329, l6: 0.004108

[epoch: 745/1000, batch:   992/ 1052, ite: 195920] train loss: 0.003907, tar: 0.000037 
[Epoch 745/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000022, l1: 0.000024, l2: 0.000061, l3: 0.000133, l4: 0.000548, l5: 0.002054, l6: 0.003092

[epoch: 746/1000, batch:    20/ 1052, ite: 195940] train loss: 0.003906, tar: 0.000037 
l0: 0.000049, l1: 0.000045, l2: 0.000103, l3: 0.000244, l4: 0.000570, l5: 0.000887, l6: 0.001695

[epoch: 746/1000, batch:   100/ 1052, ite: 195960] train loss: 0.003906, tar: 0.000037 
l0: 0.000006, l1: 0.000005, l2: 0.000027, l3: 0.000131, l4: 0.000353, l5: 0.001088, l6: 0.002201

[epoch: 746/1000, batch:   180/ 1052, ite: 195980] train loss: 0.003907, tar: 0.000037 
l0: 0.000016, l1: 0.000015, l2: 0.000051, l3: 0.000070, l4: 0.000192, l5: 0.000519, l6: 0.000956

[epoch: 746/1000, batch:   260/ 1052, ite: 196000] train loss: 0.003906, tar: 0.000037 
l0: 0.000046, l1: 0.000043, l2: 0.000150, l3: 0.000269, l4: 0.000533, l5: 0.000853, l6: 0.003164

[epoch: 746/1000, batch:   340/ 1052, ite: 196020] train loss: 0.003905, tar: 0.000037 
l0: 0.000011, l1: 0.000013, l2: 0.000032, l3: 0.000128, l4: 0.000237, l5: 0.001064, l6: 0.002223

[epoch: 746/1000, batch:   420/ 1052, ite: 196040] train loss: 0.003906, tar: 0.000037 
l0: 0.000038, l1: 0.000041, l2: 0.000088, l3: 0.000176, l4: 0.000368, l5: 0.000400, l6: 0.001702

[epoch: 746/1000, batch:   500/ 1052, ite: 196060] train loss: 0.003906, tar: 0.000037 
l0: 0.000018, l1: 0.000018, l2: 0.000052, l3: 0.000157, l4: 0.000333, l5: 0.000845, l6: 0.001793

[epoch: 746/1000, batch:   580/ 1052, ite: 196080] train loss: 0.003905, tar: 0.000037 
l0: 0.000111, l1: 0.000112, l2: 0.000182, l3: 0.000268, l4: 0.000536, l5: 0.000990, l6: 0.003577

[epoch: 746/1000, batch:   660/ 1052, ite: 196100] train loss: 0.003905, tar: 0.000037 
l0: 0.000021, l1: 0.000020, l2: 0.000058, l3: 0.000167, l4: 0.000417, l5: 0.000618, l6: 0.001327

[epoch: 746/1000, batch:   740/ 1052, ite: 196120] train loss: 0.003904, tar: 0.000037 
l0: 0.000009, l1: 0.000008, l2: 0.000042, l3: 0.000134, l4: 0.000359, l5: 0.001154, l6: 0.001800

[epoch: 746/1000, batch:   820/ 1052, ite: 196140] train loss: 0.003903, tar: 0.000037 
l0: 0.000033, l1: 0.000035, l2: 0.000091, l3: 0.000268, l4: 0.000512, l5: 0.001127, l6: 0.002417

[epoch: 746/1000, batch:   900/ 1052, ite: 196160] train loss: 0.003901, tar: 0.000036 
l0: 0.000025, l1: 0.000026, l2: 0.000079, l3: 0.000229, l4: 0.000463, l5: 0.001221, l6: 0.002769

[epoch: 746/1000, batch:   980/ 1052, ite: 196180] train loss: 0.003900, tar: 0.000036 
[Epoch 746/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000036, l1: 0.000032, l2: 0.000117, l3: 0.000278, l4: 0.000488, l5: 0.001987, l6: 0.002436

[epoch: 747/1000, batch:     8/ 1052, ite: 196200] train loss: 0.003901, tar: 0.000036 
l0: 0.000014, l1: 0.000015, l2: 0.000044, l3: 0.000119, l4: 0.000450, l5: 0.000760, l6: 0.001663

[epoch: 747/1000, batch:    88/ 1052, ite: 196220] train loss: 0.003901, tar: 0.000036 
l0: 0.000072, l1: 0.000074, l2: 0.000118, l3: 0.000281, l4: 0.001116, l5: 0.001726, l6: 0.002896

[epoch: 747/1000, batch:   168/ 1052, ite: 196240] train loss: 0.003902, tar: 0.000036 
l0: 0.000008, l1: 0.000008, l2: 0.000010, l3: 0.000048, l4: 0.000133, l5: 0.000126, l6: 0.000658

[epoch: 747/1000, batch:   248/ 1052, ite: 196260] train loss: 0.003903, tar: 0.000036 
l0: 0.000004, l1: 0.000005, l2: 0.000035, l3: 0.000151, l4: 0.000461, l5: 0.000982, l6: 0.001453

[epoch: 747/1000, batch:   328/ 1052, ite: 196280] train loss: 0.003902, tar: 0.000036 
l0: 0.000026, l1: 0.000028, l2: 0.000056, l3: 0.000112, l4: 0.000249, l5: 0.000605, l6: 0.002093

[epoch: 747/1000, batch:   408/ 1052, ite: 196300] train loss: 0.003901, tar: 0.000036 
l0: 0.000001, l1: 0.000001, l2: 0.000013, l3: 0.000133, l4: 0.000329, l5: 0.000779, l6: 0.001349

[epoch: 747/1000, batch:   488/ 1052, ite: 196320] train loss: 0.003900, tar: 0.000036 
l0: 0.000027, l1: 0.000027, l2: 0.000067, l3: 0.000146, l4: 0.000455, l5: 0.001345, l6: 0.002177

[epoch: 747/1000, batch:   568/ 1052, ite: 196340] train loss: 0.003900, tar: 0.000036 
l0: 0.000019, l1: 0.000020, l2: 0.000079, l3: 0.000223, l4: 0.000541, l5: 0.001170, l6: 0.002107

[epoch: 747/1000, batch:   648/ 1052, ite: 196360] train loss: 0.003901, tar: 0.000036 
l0: 0.000015, l1: 0.000015, l2: 0.000023, l3: 0.000054, l4: 0.000175, l5: 0.000557, l6: 0.001386

[epoch: 747/1000, batch:   728/ 1052, ite: 196380] train loss: 0.003902, tar: 0.000036 
l0: 0.000026, l1: 0.000025, l2: 0.000046, l3: 0.000143, l4: 0.000526, l5: 0.001367, l6: 0.001658

[epoch: 747/1000, batch:   808/ 1052, ite: 196400] train loss: 0.003900, tar: 0.000036 
l0: 0.000031, l1: 0.000033, l2: 0.000071, l3: 0.000214, l4: 0.000451, l5: 0.000791, l6: 0.002214

[epoch: 747/1000, batch:   888/ 1052, ite: 196420] train loss: 0.003900, tar: 0.000036 
l0: 0.000010, l1: 0.000011, l2: 0.000025, l3: 0.000088, l4: 0.000284, l5: 0.000404, l6: 0.001055

[epoch: 747/1000, batch:   968/ 1052, ite: 196440] train loss: 0.003900, tar: 0.000036 
l0: 0.000018, l1: 0.000017, l2: 0.000056, l3: 0.000160, l4: 0.000394, l5: 0.001065, l6: 0.002345

[epoch: 747/1000, batch:  1048/ 1052, ite: 196460] train loss: 0.003900, tar: 0.000036 
[Epoch 747/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000037, l1: 0.000039, l2: 0.000131, l3: 0.000315, l4: 0.000804, l5: 0.001409, l6: 0.002840

[epoch: 748/1000, batch:    76/ 1052, ite: 196480] train loss: 0.003900, tar: 0.000036 
l0: 0.000034, l1: 0.000031, l2: 0.000066, l3: 0.000112, l4: 0.000383, l5: 0.001092, l6: 0.001625

[epoch: 748/1000, batch:   156/ 1052, ite: 196500] train loss: 0.003899, tar: 0.000036 
l0: 0.000004, l1: 0.000005, l2: 0.000018, l3: 0.000086, l4: 0.000288, l5: 0.000393, l6: 0.001274

[epoch: 748/1000, batch:   236/ 1052, ite: 196520] train loss: 0.003899, tar: 0.000036 
l0: 0.000011, l1: 0.000012, l2: 0.000035, l3: 0.000114, l4: 0.000392, l5: 0.001071, l6: 0.001630

[epoch: 748/1000, batch:   316/ 1052, ite: 196540] train loss: 0.003899, tar: 0.000036 
l0: 0.000041, l1: 0.000048, l2: 0.000093, l3: 0.000262, l4: 0.000552, l5: 0.000900, l6: 0.001657

[epoch: 748/1000, batch:   396/ 1052, ite: 196560] train loss: 0.003900, tar: 0.000036 
l0: 0.000026, l1: 0.000024, l2: 0.000104, l3: 0.000325, l4: 0.000584, l5: 0.001179, l6: 0.001667

[epoch: 748/1000, batch:   476/ 1052, ite: 196580] train loss: 0.003900, tar: 0.000036 
l0: 0.000010, l1: 0.000009, l2: 0.000059, l3: 0.000177, l4: 0.000546, l5: 0.001295, l6: 0.002442

[epoch: 748/1000, batch:   556/ 1052, ite: 196600] train loss: 0.003899, tar: 0.000036 
l0: 0.000020, l1: 0.000018, l2: 0.000048, l3: 0.000105, l4: 0.000319, l5: 0.000944, l6: 0.001412

[epoch: 748/1000, batch:   636/ 1052, ite: 196620] train loss: 0.003900, tar: 0.000036 
l0: 0.000035, l1: 0.000036, l2: 0.000087, l3: 0.000405, l4: 0.000872, l5: 0.001643, l6: 0.003486

[epoch: 748/1000, batch:   716/ 1052, ite: 196640] train loss: 0.003900, tar: 0.000036 
l0: 0.000006, l1: 0.000008, l2: 0.000016, l3: 0.000147, l4: 0.000270, l5: 0.000572, l6: 0.001235

[epoch: 748/1000, batch:   796/ 1052, ite: 196660] train loss: 0.003898, tar: 0.000036 
l0: 0.000005, l1: 0.000006, l2: 0.000033, l3: 0.000138, l4: 0.000343, l5: 0.000632, l6: 0.001563

[epoch: 748/1000, batch:   876/ 1052, ite: 196680] train loss: 0.003898, tar: 0.000036 
l0: 0.000024, l1: 0.000023, l2: 0.000084, l3: 0.000215, l4: 0.000331, l5: 0.000957, l6: 0.002685

[epoch: 748/1000, batch:   956/ 1052, ite: 196700] train loss: 0.003899, tar: 0.000036 
l0: 0.000008, l1: 0.000008, l2: 0.000023, l3: 0.000079, l4: 0.000410, l5: 0.000767, l6: 0.001648

[epoch: 748/1000, batch:  1036/ 1052, ite: 196720] train loss: 0.003899, tar: 0.000036 
[Epoch 748/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000006, l1: 0.000005, l2: 0.000062, l3: 0.000205, l4: 0.000674, l5: 0.001222, l6: 0.002411

[epoch: 749/1000, batch:    64/ 1052, ite: 196740] train loss: 0.003899, tar: 0.000036 
l0: 0.000019, l1: 0.000021, l2: 0.000154, l3: 0.000322, l4: 0.000649, l5: 0.001172, l6: 0.002425

[epoch: 749/1000, batch:   144/ 1052, ite: 196760] train loss: 0.003899, tar: 0.000036 
l0: 0.000021, l1: 0.000023, l2: 0.000043, l3: 0.000166, l4: 0.000449, l5: 0.000795, l6: 0.001512

[epoch: 749/1000, batch:   224/ 1052, ite: 196780] train loss: 0.003898, tar: 0.000036 
l0: 0.000027, l1: 0.000026, l2: 0.000036, l3: 0.000206, l4: 0.000296, l5: 0.000855, l6: 0.001175

[epoch: 749/1000, batch:   304/ 1052, ite: 196800] train loss: 0.003897, tar: 0.000036 
l0: 0.000021, l1: 0.000023, l2: 0.000066, l3: 0.000217, l4: 0.000764, l5: 0.001755, l6: 0.002984

[epoch: 749/1000, batch:   384/ 1052, ite: 196820] train loss: 0.003896, tar: 0.000036 
l0: 0.000021, l1: 0.000022, l2: 0.000040, l3: 0.000076, l4: 0.000445, l5: 0.000706, l6: 0.001391

[epoch: 749/1000, batch:   464/ 1052, ite: 196840] train loss: 0.003895, tar: 0.000036 
l0: 0.000030, l1: 0.000032, l2: 0.000055, l3: 0.000173, l4: 0.000401, l5: 0.001226, l6: 0.000898

[epoch: 749/1000, batch:   544/ 1052, ite: 196860] train loss: 0.003896, tar: 0.000036 
l0: 0.000004, l1: 0.000004, l2: 0.000036, l3: 0.000109, l4: 0.000254, l5: 0.000755, l6: 0.001315

[epoch: 749/1000, batch:   624/ 1052, ite: 196880] train loss: 0.003896, tar: 0.000036 
l0: 0.000055, l1: 0.000057, l2: 0.000070, l3: 0.000281, l4: 0.000510, l5: 0.001418, l6: 0.003351

[epoch: 749/1000, batch:   704/ 1052, ite: 196900] train loss: 0.003898, tar: 0.000036 
l0: 0.000011, l1: 0.000011, l2: 0.000034, l3: 0.000221, l4: 0.000447, l5: 0.001231, l6: 0.001286

[epoch: 749/1000, batch:   784/ 1052, ite: 196920] train loss: 0.003900, tar: 0.000036 
l0: 0.000017, l1: 0.000018, l2: 0.000026, l3: 0.000110, l4: 0.000337, l5: 0.001248, l6: 0.001888

[epoch: 749/1000, batch:   864/ 1052, ite: 196940] train loss: 0.003900, tar: 0.000036 
l0: 0.000020, l1: 0.000020, l2: 0.000047, l3: 0.000127, l4: 0.000195, l5: 0.000538, l6: 0.001484

[epoch: 749/1000, batch:   944/ 1052, ite: 196960] train loss: 0.003898, tar: 0.000036 
l0: 0.000015, l1: 0.000014, l2: 0.000037, l3: 0.000103, l4: 0.000849, l5: 0.001986, l6: 0.002398

[epoch: 749/1000, batch:  1024/ 1052, ite: 196980] train loss: 0.003899, tar: 0.000036 
[Epoch 749/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000047, l1: 0.000044, l2: 0.000121, l3: 0.000232, l4: 0.000838, l5: 0.001272, l6: 0.002620

[epoch: 750/1000, batch:    52/ 1052, ite: 197000] train loss: 0.003899, tar: 0.000036 
l0: 0.000078, l1: 0.000077, l2: 0.000128, l3: 0.000177, l4: 0.000328, l5: 0.000531, l6: 0.001045

[epoch: 750/1000, batch:   132/ 1052, ite: 197020] train loss: 0.003900, tar: 0.000036 
l0: 0.000012, l1: 0.000013, l2: 0.000018, l3: 0.000037, l4: 0.000104, l5: 0.000580, l6: 0.001215

[epoch: 750/1000, batch:   212/ 1052, ite: 197040] train loss: 0.003899, tar: 0.000036 
l0: 0.000023, l1: 0.000025, l2: 0.000075, l3: 0.000221, l4: 0.000711, l5: 0.001782, l6: 0.003133

[epoch: 750/1000, batch:   292/ 1052, ite: 197060] train loss: 0.003899, tar: 0.000036 
l0: 0.000010, l1: 0.000010, l2: 0.000028, l3: 0.000190, l4: 0.000376, l5: 0.001069, l6: 0.002445

[epoch: 750/1000, batch:   372/ 1052, ite: 197080] train loss: 0.003898, tar: 0.000036 
l0: 0.000037, l1: 0.000038, l2: 0.000117, l3: 0.000343, l4: 0.001377, l5: 0.002664, l6: 0.002409

[epoch: 750/1000, batch:   452/ 1052, ite: 197100] train loss: 0.003898, tar: 0.000036 
l0: 0.000072, l1: 0.000079, l2: 0.000102, l3: 0.000320, l4: 0.000548, l5: 0.001006, l6: 0.002724

[epoch: 750/1000, batch:   532/ 1052, ite: 197120] train loss: 0.003898, tar: 0.000036 
l0: 0.000047, l1: 0.000047, l2: 0.000111, l3: 0.000424, l4: 0.000807, l5: 0.001598, l6: 0.003813

[epoch: 750/1000, batch:   612/ 1052, ite: 197140] train loss: 0.003898, tar: 0.000036 
l0: 0.000028, l1: 0.000030, l2: 0.000056, l3: 0.000157, l4: 0.000403, l5: 0.000963, l6: 0.001795

[epoch: 750/1000, batch:   692/ 1052, ite: 197160] train loss: 0.003898, tar: 0.000036 
l0: 0.000031, l1: 0.000030, l2: 0.000133, l3: 0.000371, l4: 0.000653, l5: 0.001480, l6: 0.003098

[epoch: 750/1000, batch:   772/ 1052, ite: 197180] train loss: 0.003898, tar: 0.000036 
l0: 0.000011, l1: 0.000011, l2: 0.000035, l3: 0.000110, l4: 0.000437, l5: 0.000799, l6: 0.001927

[epoch: 750/1000, batch:   852/ 1052, ite: 197200] train loss: 0.003898, tar: 0.000036 
l0: 0.000016, l1: 0.000017, l2: 0.000036, l3: 0.000141, l4: 0.000421, l5: 0.001202, l6: 0.002508

[epoch: 750/1000, batch:   932/ 1052, ite: 197220] train loss: 0.003899, tar: 0.000036 
l0: 0.000048, l1: 0.000049, l2: 0.000110, l3: 0.000257, l4: 0.000720, l5: 0.001394, l6: 0.001878

[epoch: 750/1000, batch:  1012/ 1052, ite: 197240] train loss: 0.003899, tar: 0.000036 
[Epoch 750/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000023, l1: 0.000022, l2: 0.000049, l3: 0.000169, l4: 0.000464, l5: 0.000921, l6: 0.001590

[epoch: 751/1000, batch:    40/ 1052, ite: 197260] train loss: 0.003899, tar: 0.000036 
l0: 0.000023, l1: 0.000024, l2: 0.000068, l3: 0.000181, l4: 0.000556, l5: 0.001766, l6: 0.002403

[epoch: 751/1000, batch:   120/ 1052, ite: 197280] train loss: 0.003900, tar: 0.000036 
l0: 0.000021, l1: 0.000022, l2: 0.000049, l3: 0.000201, l4: 0.000414, l5: 0.001164, l6: 0.002962

[epoch: 751/1000, batch:   200/ 1052, ite: 197300] train loss: 0.003901, tar: 0.000036 
l0: 0.000037, l1: 0.000036, l2: 0.000064, l3: 0.000135, l4: 0.000368, l5: 0.001232, l6: 0.002718

[epoch: 751/1000, batch:   280/ 1052, ite: 197320] train loss: 0.003901, tar: 0.000036 
l0: 0.000048, l1: 0.000043, l2: 0.000087, l3: 0.000189, l4: 0.000371, l5: 0.000754, l6: 0.001154

[epoch: 751/1000, batch:   360/ 1052, ite: 197340] train loss: 0.003901, tar: 0.000036 
l0: 0.000021, l1: 0.000021, l2: 0.000060, l3: 0.000156, l4: 0.000392, l5: 0.000772, l6: 0.001380

[epoch: 751/1000, batch:   440/ 1052, ite: 197360] train loss: 0.003901, tar: 0.000036 
l0: 0.000143, l1: 0.000143, l2: 0.000192, l3: 0.000409, l4: 0.000727, l5: 0.001643, l6: 0.004405

[epoch: 751/1000, batch:   520/ 1052, ite: 197380] train loss: 0.003901, tar: 0.000036 
l0: 0.000074, l1: 0.000072, l2: 0.000123, l3: 0.000226, l4: 0.000523, l5: 0.001061, l6: 0.003660

[epoch: 751/1000, batch:   600/ 1052, ite: 197400] train loss: 0.003902, tar: 0.000036 
l0: 0.000049, l1: 0.000054, l2: 0.000180, l3: 0.000409, l4: 0.000791, l5: 0.002095, l6: 0.005038

[epoch: 751/1000, batch:   680/ 1052, ite: 197420] train loss: 0.003903, tar: 0.000036 
l0: 0.000057, l1: 0.000055, l2: 0.000104, l3: 0.000134, l4: 0.000503, l5: 0.001155, l6: 0.001543

[epoch: 751/1000, batch:   760/ 1052, ite: 197440] train loss: 0.003902, tar: 0.000036 
l0: 0.000025, l1: 0.000026, l2: 0.000070, l3: 0.000190, l4: 0.000529, l5: 0.001188, l6: 0.002703

[epoch: 751/1000, batch:   840/ 1052, ite: 197460] train loss: 0.003901, tar: 0.000036 
l0: 0.000016, l1: 0.000019, l2: 0.000077, l3: 0.000253, l4: 0.000479, l5: 0.001557, l6: 0.002610

[epoch: 751/1000, batch:   920/ 1052, ite: 197480] train loss: 0.003900, tar: 0.000036 
l0: 0.000007, l1: 0.000008, l2: 0.000054, l3: 0.000258, l4: 0.000823, l5: 0.002247, l6: 0.003180

[epoch: 751/1000, batch:  1000/ 1052, ite: 197500] train loss: 0.003900, tar: 0.000036 
[Epoch 751/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000021, l1: 0.000019, l2: 0.000074, l3: 0.000269, l4: 0.000557, l5: 0.001257, l6: 0.002538

[epoch: 752/1000, batch:    28/ 1052, ite: 197520] train loss: 0.003900, tar: 0.000036 
l0: 0.000022, l1: 0.000023, l2: 0.000037, l3: 0.000077, l4: 0.000342, l5: 0.000881, l6: 0.001751

[epoch: 752/1000, batch:   108/ 1052, ite: 197540] train loss: 0.003899, tar: 0.000036 
l0: 0.000001, l1: 0.000001, l2: 0.000025, l3: 0.000073, l4: 0.000353, l5: 0.000675, l6: 0.000731

[epoch: 752/1000, batch:   188/ 1052, ite: 197560] train loss: 0.003900, tar: 0.000035 
l0: 0.000102, l1: 0.000105, l2: 0.000180, l3: 0.000273, l4: 0.000598, l5: 0.001446, l6: 0.002871

[epoch: 752/1000, batch:   268/ 1052, ite: 197580] train loss: 0.003899, tar: 0.000035 
l0: 0.000006, l1: 0.000006, l2: 0.000047, l3: 0.000203, l4: 0.000362, l5: 0.000664, l6: 0.000916

[epoch: 752/1000, batch:   348/ 1052, ite: 197600] train loss: 0.003900, tar: 0.000035 
l0: 0.000039, l1: 0.000037, l2: 0.000067, l3: 0.000210, l4: 0.000609, l5: 0.001115, l6: 0.002279

[epoch: 752/1000, batch:   428/ 1052, ite: 197620] train loss: 0.003901, tar: 0.000035 
l0: 0.000061, l1: 0.000062, l2: 0.000093, l3: 0.000201, l4: 0.000445, l5: 0.001328, l6: 0.002627

[epoch: 752/1000, batch:   508/ 1052, ite: 197640] train loss: 0.003901, tar: 0.000035 
l0: 0.000035, l1: 0.000039, l2: 0.000071, l3: 0.000238, l4: 0.000420, l5: 0.000909, l6: 0.001361

[epoch: 752/1000, batch:   588/ 1052, ite: 197660] train loss: 0.003901, tar: 0.000035 
l0: 0.000025, l1: 0.000025, l2: 0.000069, l3: 0.000242, l4: 0.000429, l5: 0.001281, l6: 0.001647

[epoch: 752/1000, batch:   668/ 1052, ite: 197680] train loss: 0.003900, tar: 0.000035 
l0: 0.000019, l1: 0.000019, l2: 0.000113, l3: 0.000230, l4: 0.000466, l5: 0.000951, l6: 0.002332

[epoch: 752/1000, batch:   748/ 1052, ite: 197700] train loss: 0.003900, tar: 0.000035 
l0: 0.000029, l1: 0.000030, l2: 0.000077, l3: 0.000341, l4: 0.000753, l5: 0.001516, l6: 0.002721

[epoch: 752/1000, batch:   828/ 1052, ite: 197720] train loss: 0.003899, tar: 0.000035 
l0: 0.000042, l1: 0.000041, l2: 0.000091, l3: 0.000235, l4: 0.000669, l5: 0.001437, l6: 0.002362

[epoch: 752/1000, batch:   908/ 1052, ite: 197740] train loss: 0.003898, tar: 0.000035 
l0: 0.000011, l1: 0.000012, l2: 0.000058, l3: 0.000203, l4: 0.000547, l5: 0.001322, l6: 0.002301

[epoch: 752/1000, batch:   988/ 1052, ite: 197760] train loss: 0.003898, tar: 0.000035 
[Epoch 752/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000349, l1: 0.000316, l2: 0.000344, l3: 0.000434, l4: 0.000488, l5: 0.000709, l6: 0.001893

[epoch: 753/1000, batch:    16/ 1052, ite: 197780] train loss: 0.003900, tar: 0.000035 
l0: 0.000028, l1: 0.000027, l2: 0.000072, l3: 0.000232, l4: 0.000427, l5: 0.001335, l6: 0.002864

[epoch: 753/1000, batch:    96/ 1052, ite: 197800] train loss: 0.003900, tar: 0.000035 
l0: 0.000026, l1: 0.000028, l2: 0.000073, l3: 0.000145, l4: 0.000290, l5: 0.000873, l6: 0.001606

[epoch: 753/1000, batch:   176/ 1052, ite: 197820] train loss: 0.003899, tar: 0.000035 
l0: 0.000011, l1: 0.000010, l2: 0.000087, l3: 0.000186, l4: 0.000381, l5: 0.000946, l6: 0.001837

[epoch: 753/1000, batch:   256/ 1052, ite: 197840] train loss: 0.003900, tar: 0.000035 
l0: 0.000011, l1: 0.000011, l2: 0.000031, l3: 0.000103, l4: 0.000356, l5: 0.001287, l6: 0.002371

[epoch: 753/1000, batch:   336/ 1052, ite: 197860] train loss: 0.003900, tar: 0.000035 
l0: 0.000054, l1: 0.000057, l2: 0.000070, l3: 0.000302, l4: 0.000912, l5: 0.001210, l6: 0.003370

[epoch: 753/1000, batch:   416/ 1052, ite: 197880] train loss: 0.003899, tar: 0.000035 
l0: 0.000148, l1: 0.000150, l2: 0.000220, l3: 0.000172, l4: 0.000443, l5: 0.000782, l6: 0.002621

[epoch: 753/1000, batch:   496/ 1052, ite: 197900] train loss: 0.003900, tar: 0.000035 
l0: 0.000056, l1: 0.000059, l2: 0.000244, l3: 0.000444, l4: 0.000885, l5: 0.003646, l6: 0.005046

[epoch: 753/1000, batch:   576/ 1052, ite: 197920] train loss: 0.003901, tar: 0.000035 
l0: 0.000025, l1: 0.000025, l2: 0.000051, l3: 0.000178, l4: 0.000328, l5: 0.000813, l6: 0.001541

[epoch: 753/1000, batch:   656/ 1052, ite: 197940] train loss: 0.003900, tar: 0.000035 
l0: 0.000005, l1: 0.000007, l2: 0.000024, l3: 0.000070, l4: 0.000187, l5: 0.000673, l6: 0.000738

[epoch: 753/1000, batch:   736/ 1052, ite: 197960] train loss: 0.003899, tar: 0.000035 
l0: 0.000006, l1: 0.000007, l2: 0.000052, l3: 0.000165, l4: 0.000471, l5: 0.001121, l6: 0.001634

[epoch: 753/1000, batch:   816/ 1052, ite: 197980] train loss: 0.003900, tar: 0.000035 
l0: 0.000079, l1: 0.000079, l2: 0.000194, l3: 0.000366, l4: 0.000685, l5: 0.002358, l6: 0.003489

[epoch: 753/1000, batch:   896/ 1052, ite: 198000] train loss: 0.003899, tar: 0.000035 
l0: 0.000012, l1: 0.000012, l2: 0.000028, l3: 0.000138, l4: 0.000367, l5: 0.001080, l6: 0.002471

[epoch: 753/1000, batch:   976/ 1052, ite: 198020] train loss: 0.003899, tar: 0.000035 
[Epoch 753/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000019, l1: 0.000020, l2: 0.000068, l3: 0.000184, l4: 0.000503, l5: 0.000860, l6: 0.002359

[epoch: 754/1000, batch:     4/ 1052, ite: 198040] train loss: 0.003899, tar: 0.000035 
l0: 0.000039, l1: 0.000039, l2: 0.000076, l3: 0.000199, l4: 0.000398, l5: 0.000704, l6: 0.001550

[epoch: 754/1000, batch:    84/ 1052, ite: 198060] train loss: 0.003900, tar: 0.000035 
l0: 0.000014, l1: 0.000014, l2: 0.000064, l3: 0.000117, l4: 0.000335, l5: 0.000787, l6: 0.001315

[epoch: 754/1000, batch:   164/ 1052, ite: 198080] train loss: 0.003901, tar: 0.000035 
l0: 0.000007, l1: 0.000006, l2: 0.000058, l3: 0.000214, l4: 0.000278, l5: 0.000855, l6: 0.001683

[epoch: 754/1000, batch:   244/ 1052, ite: 198100] train loss: 0.003901, tar: 0.000035 
l0: 0.000119, l1: 0.000120, l2: 0.000281, l3: 0.000571, l4: 0.000992, l5: 0.002399, l6: 0.004564

[epoch: 754/1000, batch:   324/ 1052, ite: 198120] train loss: 0.003902, tar: 0.000035 
l0: 0.000040, l1: 0.000042, l2: 0.000110, l3: 0.000266, l4: 0.000680, l5: 0.002283, l6: 0.003289

[epoch: 754/1000, batch:   404/ 1052, ite: 198140] train loss: 0.003903, tar: 0.000035 
l0: 0.000026, l1: 0.000026, l2: 0.000057, l3: 0.000189, l4: 0.000369, l5: 0.000615, l6: 0.001496

[epoch: 754/1000, batch:   484/ 1052, ite: 198160] train loss: 0.003902, tar: 0.000035 
l0: 0.000038, l1: 0.000037, l2: 0.000080, l3: 0.000178, l4: 0.000611, l5: 0.000960, l6: 0.002161

[epoch: 754/1000, batch:   564/ 1052, ite: 198180] train loss: 0.003902, tar: 0.000035 
l0: 0.000051, l1: 0.000060, l2: 0.000066, l3: 0.000191, l4: 0.000447, l5: 0.001206, l6: 0.001950

[epoch: 754/1000, batch:   644/ 1052, ite: 198200] train loss: 0.003903, tar: 0.000036 
l0: 0.000043, l1: 0.000047, l2: 0.000067, l3: 0.000132, l4: 0.000321, l5: 0.000739, l6: 0.000922

[epoch: 754/1000, batch:   724/ 1052, ite: 198220] train loss: 0.003906, tar: 0.000036 
l0: 0.000042, l1: 0.000041, l2: 0.000104, l3: 0.000180, l4: 0.000416, l5: 0.000907, l6: 0.001526

[epoch: 754/1000, batch:   804/ 1052, ite: 198240] train loss: 0.003905, tar: 0.000036 
l0: 0.000053, l1: 0.000059, l2: 0.000060, l3: 0.000196, l4: 0.000384, l5: 0.000444, l6: 0.001183

[epoch: 754/1000, batch:   884/ 1052, ite: 198260] train loss: 0.003903, tar: 0.000036 
l0: 0.000033, l1: 0.000031, l2: 0.000062, l3: 0.000219, l4: 0.000675, l5: 0.001034, l6: 0.002129

[epoch: 754/1000, batch:   964/ 1052, ite: 198280] train loss: 0.003903, tar: 0.000036 
l0: 0.000018, l1: 0.000018, l2: 0.000067, l3: 0.000176, l4: 0.000296, l5: 0.001205, l6: 0.002241

[epoch: 754/1000, batch:  1044/ 1052, ite: 198300] train loss: 0.003903, tar: 0.000036 
[Epoch 754/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000026, l1: 0.000026, l2: 0.000066, l3: 0.000226, l4: 0.000489, l5: 0.001017, l6: 0.001502

[epoch: 755/1000, batch:    72/ 1052, ite: 198320] train loss: 0.003902, tar: 0.000036 
l0: 0.000074, l1: 0.000078, l2: 0.000104, l3: 0.000215, l4: 0.000482, l5: 0.000782, l6: 0.002421

[epoch: 755/1000, batch:   152/ 1052, ite: 198340] train loss: 0.003903, tar: 0.000036 
l0: 0.000051, l1: 0.000054, l2: 0.000119, l3: 0.000191, l4: 0.000610, l5: 0.001777, l6: 0.002720

[epoch: 755/1000, batch:   232/ 1052, ite: 198360] train loss: 0.003903, tar: 0.000036 
l0: 0.000034, l1: 0.000032, l2: 0.000080, l3: 0.000199, l4: 0.000440, l5: 0.000936, l6: 0.002833

[epoch: 755/1000, batch:   312/ 1052, ite: 198380] train loss: 0.003904, tar: 0.000036 
l0: 0.000051, l1: 0.000058, l2: 0.000087, l3: 0.000071, l4: 0.000168, l5: 0.000719, l6: 0.001190

[epoch: 755/1000, batch:   392/ 1052, ite: 198400] train loss: 0.003903, tar: 0.000036 
l0: 0.000016, l1: 0.000014, l2: 0.000049, l3: 0.000161, l4: 0.000459, l5: 0.001028, l6: 0.001643

[epoch: 755/1000, batch:   472/ 1052, ite: 198420] train loss: 0.003904, tar: 0.000036 
l0: 0.000114, l1: 0.000109, l2: 0.000242, l3: 0.000461, l4: 0.000787, l5: 0.001676, l6: 0.003009

[epoch: 755/1000, batch:   552/ 1052, ite: 198440] train loss: 0.003905, tar: 0.000036 
l0: 0.000046, l1: 0.000052, l2: 0.000086, l3: 0.000222, l4: 0.000307, l5: 0.001159, l6: 0.002494

[epoch: 755/1000, batch:   632/ 1052, ite: 198460] train loss: 0.003907, tar: 0.000036 
l0: 0.000044, l1: 0.000043, l2: 0.000078, l3: 0.000174, l4: 0.000832, l5: 0.001264, l6: 0.002182

[epoch: 755/1000, batch:   712/ 1052, ite: 198480] train loss: 0.003907, tar: 0.000036 
l0: 0.000057, l1: 0.000056, l2: 0.000125, l3: 0.000215, l4: 0.000462, l5: 0.001010, l6: 0.001399

[epoch: 755/1000, batch:   792/ 1052, ite: 198500] train loss: 0.003906, tar: 0.000036 
l0: 0.000015, l1: 0.000016, l2: 0.000018, l3: 0.000057, l4: 0.000245, l5: 0.000816, l6: 0.001281

[epoch: 755/1000, batch:   872/ 1052, ite: 198520] train loss: 0.003906, tar: 0.000036 
l0: 0.000120, l1: 0.000100, l2: 0.000127, l3: 0.000350, l4: 0.000680, l5: 0.001807, l6: 0.003279

[epoch: 755/1000, batch:   952/ 1052, ite: 198540] train loss: 0.003906, tar: 0.000036 
l0: 0.000021, l1: 0.000021, l2: 0.000033, l3: 0.000147, l4: 0.000460, l5: 0.001103, l6: 0.001017

[epoch: 755/1000, batch:  1032/ 1052, ite: 198560] train loss: 0.003905, tar: 0.000036 
[Epoch 755/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000029, l1: 0.000029, l2: 0.000051, l3: 0.000167, l4: 0.000460, l5: 0.000898, l6: 0.001079

[epoch: 756/1000, batch:    60/ 1052, ite: 198580] train loss: 0.003904, tar: 0.000036 
l0: 0.000010, l1: 0.000010, l2: 0.000066, l3: 0.000135, l4: 0.000436, l5: 0.000616, l6: 0.001162

[epoch: 756/1000, batch:   140/ 1052, ite: 198600] train loss: 0.003904, tar: 0.000036 
l0: 0.000017, l1: 0.000016, l2: 0.000079, l3: 0.000217, l4: 0.000666, l5: 0.001290, l6: 0.003224

[epoch: 756/1000, batch:   220/ 1052, ite: 198620] train loss: 0.003905, tar: 0.000036 
l0: 0.000006, l1: 0.000007, l2: 0.000019, l3: 0.000088, l4: 0.000264, l5: 0.000822, l6: 0.001351

[epoch: 756/1000, batch:   300/ 1052, ite: 198640] train loss: 0.003906, tar: 0.000036 
l0: 0.000020, l1: 0.000021, l2: 0.000029, l3: 0.000051, l4: 0.000193, l5: 0.000475, l6: 0.000828

[epoch: 756/1000, batch:   380/ 1052, ite: 198660] train loss: 0.003906, tar: 0.000036 
l0: 0.000018, l1: 0.000020, l2: 0.000030, l3: 0.000112, l4: 0.000395, l5: 0.001073, l6: 0.001780

[epoch: 756/1000, batch:   460/ 1052, ite: 198680] train loss: 0.003906, tar: 0.000036 
l0: 0.000032, l1: 0.000029, l2: 0.000063, l3: 0.000180, l4: 0.000427, l5: 0.001084, l6: 0.002248

[epoch: 756/1000, batch:   540/ 1052, ite: 198700] train loss: 0.003905, tar: 0.000036 
l0: 0.000020, l1: 0.000019, l2: 0.000048, l3: 0.000195, l4: 0.000313, l5: 0.001412, l6: 0.001958

[epoch: 756/1000, batch:   620/ 1052, ite: 198720] train loss: 0.003904, tar: 0.000036 
l0: 0.000038, l1: 0.000039, l2: 0.000138, l3: 0.000250, l4: 0.000921, l5: 0.002212, l6: 0.002469

[epoch: 756/1000, batch:   700/ 1052, ite: 198740] train loss: 0.003906, tar: 0.000036 
l0: 0.000007, l1: 0.000007, l2: 0.000018, l3: 0.000075, l4: 0.000237, l5: 0.000702, l6: 0.001090

[epoch: 756/1000, batch:   780/ 1052, ite: 198760] train loss: 0.003903, tar: 0.000036 
l0: 0.000018, l1: 0.000019, l2: 0.000027, l3: 0.000088, l4: 0.000323, l5: 0.000999, l6: 0.001578

[epoch: 756/1000, batch:   860/ 1052, ite: 198780] train loss: 0.003903, tar: 0.000036 
l0: 0.000023, l1: 0.000021, l2: 0.000036, l3: 0.000226, l4: 0.000722, l5: 0.001443, l6: 0.002250

[epoch: 756/1000, batch:   940/ 1052, ite: 198800] train loss: 0.003902, tar: 0.000036 
l0: 0.000019, l1: 0.000018, l2: 0.000044, l3: 0.000239, l4: 0.000416, l5: 0.000916, l6: 0.001315

[epoch: 756/1000, batch:  1020/ 1052, ite: 198820] train loss: 0.003903, tar: 0.000036 
[Epoch 756/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000038, l1: 0.000041, l2: 0.000053, l3: 0.000145, l4: 0.000496, l5: 0.001130, l6: 0.001523

[epoch: 757/1000, batch:    48/ 1052, ite: 198840] train loss: 0.003903, tar: 0.000036 
l0: 0.000020, l1: 0.000019, l2: 0.000068, l3: 0.000277, l4: 0.000435, l5: 0.001262, l6: 0.002948

[epoch: 757/1000, batch:   128/ 1052, ite: 198860] train loss: 0.003903, tar: 0.000036 
l0: 0.000064, l1: 0.000062, l2: 0.000162, l3: 0.000314, l4: 0.000493, l5: 0.001012, l6: 0.001320

[epoch: 757/1000, batch:   208/ 1052, ite: 198880] train loss: 0.003902, tar: 0.000036 
l0: 0.000019, l1: 0.000021, l2: 0.000032, l3: 0.000109, l4: 0.000339, l5: 0.000889, l6: 0.001879

[epoch: 757/1000, batch:   288/ 1052, ite: 198900] train loss: 0.003902, tar: 0.000036 
l0: 0.000023, l1: 0.000027, l2: 0.000045, l3: 0.000222, l4: 0.000424, l5: 0.001002, l6: 0.002930

[epoch: 757/1000, batch:   368/ 1052, ite: 198920] train loss: 0.003902, tar: 0.000036 
l0: 0.000038, l1: 0.000036, l2: 0.000102, l3: 0.000203, l4: 0.000371, l5: 0.001062, l6: 0.001665

[epoch: 757/1000, batch:   448/ 1052, ite: 198940] train loss: 0.003901, tar: 0.000036 
l0: 0.000032, l1: 0.000031, l2: 0.000070, l3: 0.000216, l4: 0.000355, l5: 0.000757, l6: 0.001679

[epoch: 757/1000, batch:   528/ 1052, ite: 198960] train loss: 0.003900, tar: 0.000036 
l0: 0.000082, l1: 0.000080, l2: 0.000155, l3: 0.000378, l4: 0.001135, l5: 0.002331, l6: 0.003637

[epoch: 757/1000, batch:   608/ 1052, ite: 198980] train loss: 0.003901, tar: 0.000036 
l0: 0.000025, l1: 0.000026, l2: 0.000061, l3: 0.000171, l4: 0.000745, l5: 0.001030, l6: 0.002265

[epoch: 757/1000, batch:   688/ 1052, ite: 199000] train loss: 0.003901, tar: 0.000036 
l0: 0.000034, l1: 0.000032, l2: 0.000122, l3: 0.000315, l4: 0.000542, l5: 0.001132, l6: 0.001685

[epoch: 757/1000, batch:   768/ 1052, ite: 199020] train loss: 0.003901, tar: 0.000036 
l0: 0.000028, l1: 0.000030, l2: 0.000057, l3: 0.000149, l4: 0.000319, l5: 0.001178, l6: 0.001891

[epoch: 757/1000, batch:   848/ 1052, ite: 199040] train loss: 0.003900, tar: 0.000036 
l0: 0.000035, l1: 0.000035, l2: 0.000108, l3: 0.000166, l4: 0.000548, l5: 0.001917, l6: 0.002495

[epoch: 757/1000, batch:   928/ 1052, ite: 199060] train loss: 0.003902, tar: 0.000036 
l0: 0.000011, l1: 0.000012, l2: 0.000037, l3: 0.000123, l4: 0.000339, l5: 0.000985, l6: 0.001165

[epoch: 757/1000, batch:  1008/ 1052, ite: 199080] train loss: 0.003902, tar: 0.000036 
[Epoch 757/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000054, l1: 0.000057, l2: 0.000127, l3: 0.000362, l4: 0.000732, l5: 0.002038, l6: 0.004032

[epoch: 758/1000, batch:    36/ 1052, ite: 199100] train loss: 0.003902, tar: 0.000036 
l0: 0.000034, l1: 0.000034, l2: 0.000079, l3: 0.000131, l4: 0.000361, l5: 0.000516, l6: 0.002136

[epoch: 758/1000, batch:   116/ 1052, ite: 199120] train loss: 0.003903, tar: 0.000036 
l0: 0.000029, l1: 0.000034, l2: 0.000061, l3: 0.000176, l4: 0.000426, l5: 0.001020, l6: 0.001690

[epoch: 758/1000, batch:   196/ 1052, ite: 199140] train loss: 0.003903, tar: 0.000036 
l0: 0.000014, l1: 0.000016, l2: 0.000044, l3: 0.000130, l4: 0.000383, l5: 0.000890, l6: 0.002195

[epoch: 758/1000, batch:   276/ 1052, ite: 199160] train loss: 0.003904, tar: 0.000036 
l0: 0.000057, l1: 0.000060, l2: 0.000124, l3: 0.000299, l4: 0.000629, l5: 0.001365, l6: 0.002476

[epoch: 758/1000, batch:   356/ 1052, ite: 199180] train loss: 0.003904, tar: 0.000036 
l0: 0.000055, l1: 0.000049, l2: 0.000118, l3: 0.000322, l4: 0.000623, l5: 0.001148, l6: 0.002710

[epoch: 758/1000, batch:   436/ 1052, ite: 199200] train loss: 0.003903, tar: 0.000036 
l0: 0.000004, l1: 0.000004, l2: 0.000022, l3: 0.000055, l4: 0.000103, l5: 0.000355, l6: 0.000546

[epoch: 758/1000, batch:   516/ 1052, ite: 199220] train loss: 0.003903, tar: 0.000036 
l0: 0.000006, l1: 0.000006, l2: 0.000036, l3: 0.000089, l4: 0.000180, l5: 0.000503, l6: 0.000867

[epoch: 758/1000, batch:   596/ 1052, ite: 199240] train loss: 0.003902, tar: 0.000036 
l0: 0.000012, l1: 0.000011, l2: 0.000050, l3: 0.000146, l4: 0.000250, l5: 0.000491, l6: 0.000860

[epoch: 758/1000, batch:   676/ 1052, ite: 199260] train loss: 0.003902, tar: 0.000036 
l0: 0.000037, l1: 0.000040, l2: 0.000079, l3: 0.000222, l4: 0.000764, l5: 0.001803, l6: 0.002780

[epoch: 758/1000, batch:   756/ 1052, ite: 199280] train loss: 0.003902, tar: 0.000036 
l0: 0.000062, l1: 0.000059, l2: 0.000118, l3: 0.000342, l4: 0.000901, l5: 0.001600, l6: 0.002668

[epoch: 758/1000, batch:   836/ 1052, ite: 199300] train loss: 0.003901, tar: 0.000036 
l0: 0.000050, l1: 0.000054, l2: 0.000101, l3: 0.000386, l4: 0.000813, l5: 0.001589, l6: 0.003375

[epoch: 758/1000, batch:   916/ 1052, ite: 199320] train loss: 0.003902, tar: 0.000036 
l0: 0.000029, l1: 0.000028, l2: 0.000059, l3: 0.000148, l4: 0.000348, l5: 0.001226, l6: 0.002943

[epoch: 758/1000, batch:   996/ 1052, ite: 199340] train loss: 0.003903, tar: 0.000036 
[Epoch 758/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000052, l1: 0.000058, l2: 0.000079, l3: 0.000254, l4: 0.000512, l5: 0.000798, l6: 0.001141

[epoch: 759/1000, batch:    24/ 1052, ite: 199360] train loss: 0.003902, tar: 0.000036 
l0: 0.000017, l1: 0.000020, l2: 0.000080, l3: 0.000281, l4: 0.000720, l5: 0.001693, l6: 0.003506

[epoch: 759/1000, batch:   104/ 1052, ite: 199380] train loss: 0.003901, tar: 0.000036 
l0: 0.000018, l1: 0.000018, l2: 0.000027, l3: 0.000128, l4: 0.000388, l5: 0.000944, l6: 0.001207

[epoch: 759/1000, batch:   184/ 1052, ite: 199400] train loss: 0.003901, tar: 0.000036 
l0: 0.000021, l1: 0.000022, l2: 0.000066, l3: 0.000163, l4: 0.000484, l5: 0.001111, l6: 0.001139

[epoch: 759/1000, batch:   264/ 1052, ite: 199420] train loss: 0.003902, tar: 0.000036 
l0: 0.000008, l1: 0.000009, l2: 0.000049, l3: 0.000117, l4: 0.000451, l5: 0.000702, l6: 0.001139

[epoch: 759/1000, batch:   344/ 1052, ite: 199440] train loss: 0.003901, tar: 0.000036 
l0: 0.000017, l1: 0.000017, l2: 0.000077, l3: 0.000248, l4: 0.000621, l5: 0.001892, l6: 0.003420

[epoch: 759/1000, batch:   424/ 1052, ite: 199460] train loss: 0.003902, tar: 0.000036 
l0: 0.000009, l1: 0.000010, l2: 0.000050, l3: 0.000096, l4: 0.000246, l5: 0.000987, l6: 0.001320

[epoch: 759/1000, batch:   504/ 1052, ite: 199480] train loss: 0.003901, tar: 0.000036 
l0: 0.000072, l1: 0.000075, l2: 0.000089, l3: 0.000210, l4: 0.000481, l5: 0.001592, l6: 0.002604

[epoch: 759/1000, batch:   584/ 1052, ite: 199500] train loss: 0.003901, tar: 0.000036 
l0: 0.000021, l1: 0.000024, l2: 0.000037, l3: 0.000122, l4: 0.000555, l5: 0.000670, l6: 0.001022

[epoch: 759/1000, batch:   664/ 1052, ite: 199520] train loss: 0.003900, tar: 0.000036 
l0: 0.000009, l1: 0.000011, l2: 0.000078, l3: 0.000327, l4: 0.000720, l5: 0.002112, l6: 0.003195

[epoch: 759/1000, batch:   744/ 1052, ite: 199540] train loss: 0.003901, tar: 0.000036 
l0: 0.000064, l1: 0.000065, l2: 0.000131, l3: 0.000275, l4: 0.000632, l5: 0.001219, l6: 0.002678

[epoch: 759/1000, batch:   824/ 1052, ite: 199560] train loss: 0.003900, tar: 0.000036 
l0: 0.000018, l1: 0.000018, l2: 0.000045, l3: 0.000147, l4: 0.000355, l5: 0.000921, l6: 0.001574

[epoch: 759/1000, batch:   904/ 1052, ite: 199580] train loss: 0.003899, tar: 0.000036 
l0: 0.000025, l1: 0.000026, l2: 0.000036, l3: 0.000146, l4: 0.000543, l5: 0.000849, l6: 0.001569

[epoch: 759/1000, batch:   984/ 1052, ite: 199600] train loss: 0.003900, tar: 0.000036 
[Epoch 759/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000041, l1: 0.000043, l2: 0.000079, l3: 0.000208, l4: 0.000540, l5: 0.001420, l6: 0.001991

[epoch: 760/1000, batch:    12/ 1052, ite: 199620] train loss: 0.003901, tar: 0.000036 
l0: 0.000052, l1: 0.000054, l2: 0.000081, l3: 0.000297, l4: 0.000615, l5: 0.001279, l6: 0.002085

[epoch: 760/1000, batch:    92/ 1052, ite: 199640] train loss: 0.003901, tar: 0.000036 
l0: 0.000064, l1: 0.000062, l2: 0.000119, l3: 0.000276, l4: 0.000636, l5: 0.001609, l6: 0.001800

[epoch: 760/1000, batch:   172/ 1052, ite: 199660] train loss: 0.003901, tar: 0.000036 
l0: 0.000024, l1: 0.000025, l2: 0.000037, l3: 0.000228, l4: 0.000580, l5: 0.001085, l6: 0.002004

[epoch: 760/1000, batch:   252/ 1052, ite: 199680] train loss: 0.003900, tar: 0.000036 
l0: 0.000010, l1: 0.000009, l2: 0.000022, l3: 0.000068, l4: 0.000243, l5: 0.000665, l6: 0.001079

[epoch: 760/1000, batch:   332/ 1052, ite: 199700] train loss: 0.003899, tar: 0.000036 
l0: 0.000026, l1: 0.000025, l2: 0.000053, l3: 0.000251, l4: 0.000357, l5: 0.001034, l6: 0.002263

[epoch: 760/1000, batch:   412/ 1052, ite: 199720] train loss: 0.003900, tar: 0.000036 
l0: 0.000023, l1: 0.000023, l2: 0.000098, l3: 0.000313, l4: 0.000788, l5: 0.001351, l6: 0.003613

[epoch: 760/1000, batch:   492/ 1052, ite: 199740] train loss: 0.003900, tar: 0.000036 
l0: 0.000039, l1: 0.000040, l2: 0.000086, l3: 0.000167, l4: 0.000496, l5: 0.000793, l6: 0.001520

[epoch: 760/1000, batch:   572/ 1052, ite: 199760] train loss: 0.003899, tar: 0.000036 
l0: 0.000027, l1: 0.000031, l2: 0.000061, l3: 0.000164, l4: 0.000412, l5: 0.001585, l6: 0.003249

[epoch: 760/1000, batch:   652/ 1052, ite: 199780] train loss: 0.003900, tar: 0.000036 
l0: 0.000006, l1: 0.000006, l2: 0.000023, l3: 0.000100, l4: 0.000271, l5: 0.000645, l6: 0.000810

[epoch: 760/1000, batch:   732/ 1052, ite: 199800] train loss: 0.003899, tar: 0.000036 
l0: 0.000044, l1: 0.000044, l2: 0.000106, l3: 0.000202, l4: 0.000403, l5: 0.001379, l6: 0.002611

[epoch: 760/1000, batch:   812/ 1052, ite: 199820] train loss: 0.003899, tar: 0.000036 
l0: 0.000037, l1: 0.000036, l2: 0.000065, l3: 0.000192, l4: 0.000300, l5: 0.001026, l6: 0.001367

[epoch: 760/1000, batch:   892/ 1052, ite: 199840] train loss: 0.003898, tar: 0.000036 
l0: 0.000029, l1: 0.000031, l2: 0.000053, l3: 0.000173, l4: 0.000535, l5: 0.001285, l6: 0.001847

[epoch: 760/1000, batch:   972/ 1052, ite: 199860] train loss: 0.003898, tar: 0.000036 
l0: 0.000035, l1: 0.000037, l2: 0.000077, l3: 0.000184, l4: 0.000645, l5: 0.001327, l6: 0.002624

[epoch: 760/1000, batch:  1052/ 1052, ite: 199880] train loss: 0.003898, tar: 0.000036 
[Epoch 760/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000003, l1: 0.000003, l2: 0.000050, l3: 0.000168, l4: 0.000309, l5: 0.000928, l6: 0.001327

[epoch: 761/1000, batch:    80/ 1052, ite: 199900] train loss: 0.003831, tar: 0.000023 
l0: 0.000017, l1: 0.000016, l2: 0.000070, l3: 0.000198, l4: 0.000515, l5: 0.001345, l6: 0.001721

[epoch: 761/1000, batch:   160/ 1052, ite: 199920] train loss: 0.003709, tar: 0.000023 
l0: 0.000012, l1: 0.000011, l2: 0.000028, l3: 0.000131, l4: 0.000220, l5: 0.000892, l6: 0.001412

[epoch: 761/1000, batch:   240/ 1052, ite: 199940] train loss: 0.003732, tar: 0.000023 
l0: 0.000008, l1: 0.000007, l2: 0.000030, l3: 0.000088, l4: 0.000298, l5: 0.001113, l6: 0.002106

[epoch: 761/1000, batch:   320/ 1052, ite: 199960] train loss: 0.003718, tar: 0.000024 
l0: 0.000020, l1: 0.000017, l2: 0.000061, l3: 0.000200, l4: 0.000628, l5: 0.000910, l6: 0.002530

[epoch: 761/1000, batch:   400/ 1052, ite: 199980] train loss: 0.003715, tar: 0.000025 
l0: 0.000023, l1: 0.000022, l2: 0.000096, l3: 0.000239, l4: 0.000705, l5: 0.001488, l6: 0.002607

[epoch: 761/1000, batch:   480/ 1052, ite: 200000] train loss: 0.003745, tar: 0.000027 
l0: 0.000003, l1: 0.000004, l2: 0.000038, l3: 0.000056, l4: 0.000161, l5: 0.000656, l6: 0.001255

[epoch: 761/1000, batch:   560/ 1052, ite: 200020] train loss: 0.003791, tar: 0.000027 
l0: 0.000019, l1: 0.000017, l2: 0.000046, l3: 0.000120, l4: 0.000421, l5: 0.000928, l6: 0.001679

[epoch: 761/1000, batch:   640/ 1052, ite: 200040] train loss: 0.003823, tar: 0.000028 
l0: 0.000016, l1: 0.000016, l2: 0.000044, l3: 0.000142, l4: 0.000381, l5: 0.001244, l6: 0.001840

[epoch: 761/1000, batch:   720/ 1052, ite: 200060] train loss: 0.003873, tar: 0.000028 
l0: 0.000030, l1: 0.000033, l2: 0.000057, l3: 0.000166, l4: 0.000494, l5: 0.001105, l6: 0.001499

[epoch: 761/1000, batch:   800/ 1052, ite: 200080] train loss: 0.003810, tar: 0.000028 
l0: 0.000011, l1: 0.000011, l2: 0.000024, l3: 0.000154, l4: 0.000407, l5: 0.000803, l6: 0.001113

[epoch: 761/1000, batch:   880/ 1052, ite: 200100] train loss: 0.003852, tar: 0.000028 
l0: 0.000068, l1: 0.000064, l2: 0.000132, l3: 0.000231, l4: 0.000461, l5: 0.001177, l6: 0.001576

[epoch: 761/1000, batch:   960/ 1052, ite: 200120] train loss: 0.003854, tar: 0.000029 
l0: 0.000010, l1: 0.000009, l2: 0.000088, l3: 0.000229, l4: 0.000481, l5: 0.001324, l6: 0.002329

[epoch: 761/1000, batch:  1040/ 1052, ite: 200140] train loss: 0.003869, tar: 0.000029 
[Epoch 761/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000011, l1: 0.000011, l2: 0.000050, l3: 0.000126, l4: 0.000336, l5: 0.000910, l6: 0.002204

[epoch: 762/1000, batch:    68/ 1052, ite: 200160] train loss: 0.003875, tar: 0.000029 
l0: 0.000060, l1: 0.000063, l2: 0.000081, l3: 0.000181, l4: 0.000459, l5: 0.001130, l6: 0.001763

[epoch: 762/1000, batch:   148/ 1052, ite: 200180] train loss: 0.003861, tar: 0.000028 
l0: 0.000025, l1: 0.000028, l2: 0.000039, l3: 0.000179, l4: 0.000533, l5: 0.001180, l6: 0.001734

[epoch: 762/1000, batch:   228/ 1052, ite: 200200] train loss: 0.003867, tar: 0.000028 
l0: 0.000005, l1: 0.000005, l2: 0.000034, l3: 0.000151, l4: 0.000379, l5: 0.000683, l6: 0.001235

[epoch: 762/1000, batch:   308/ 1052, ite: 200220] train loss: 0.003850, tar: 0.000028 
l0: 0.000012, l1: 0.000013, l2: 0.000037, l3: 0.000153, l4: 0.000431, l5: 0.000768, l6: 0.001733

[epoch: 762/1000, batch:   388/ 1052, ite: 200240] train loss: 0.003844, tar: 0.000028 
l0: 0.000021, l1: 0.000020, l2: 0.000045, l3: 0.000145, l4: 0.000439, l5: 0.001201, l6: 0.001700

[epoch: 762/1000, batch:   468/ 1052, ite: 200260] train loss: 0.003889, tar: 0.000029 
l0: 0.000004, l1: 0.000004, l2: 0.000029, l3: 0.000181, l4: 0.000519, l5: 0.000802, l6: 0.001851

[epoch: 762/1000, batch:   548/ 1052, ite: 200280] train loss: 0.003892, tar: 0.000029 
l0: 0.000006, l1: 0.000006, l2: 0.000034, l3: 0.000125, l4: 0.000434, l5: 0.001181, l6: 0.001770

[epoch: 762/1000, batch:   628/ 1052, ite: 200300] train loss: 0.003864, tar: 0.000029 
l0: 0.000045, l1: 0.000045, l2: 0.000084, l3: 0.000166, l4: 0.000198, l5: 0.000746, l6: 0.001155

[epoch: 762/1000, batch:   708/ 1052, ite: 200320] train loss: 0.003847, tar: 0.000029 
l0: 0.000030, l1: 0.000031, l2: 0.000029, l3: 0.000062, l4: 0.000342, l5: 0.000996, l6: 0.001241

[epoch: 762/1000, batch:   788/ 1052, ite: 200340] train loss: 0.003845, tar: 0.000030 
l0: 0.000081, l1: 0.000079, l2: 0.000151, l3: 0.000311, l4: 0.000682, l5: 0.002635, l6: 0.005536

[epoch: 762/1000, batch:   868/ 1052, ite: 200360] train loss: 0.003862, tar: 0.000030 
l0: 0.000014, l1: 0.000014, l2: 0.000041, l3: 0.000098, l4: 0.000381, l5: 0.001016, l6: 0.001371

[epoch: 762/1000, batch:   948/ 1052, ite: 200380] train loss: 0.003887, tar: 0.000030 
l0: 0.000023, l1: 0.000022, l2: 0.000079, l3: 0.000214, l4: 0.000518, l5: 0.001243, l6: 0.002885

[epoch: 762/1000, batch:  1028/ 1052, ite: 200400] train loss: 0.003886, tar: 0.000030 
[Epoch 762/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000011, l1: 0.000010, l2: 0.000050, l3: 0.000089, l4: 0.000360, l5: 0.000657, l6: 0.001148

[epoch: 763/1000, batch:    56/ 1052, ite: 200420] train loss: 0.003867, tar: 0.000029 
l0: 0.000017, l1: 0.000018, l2: 0.000040, l3: 0.000189, l4: 0.000636, l5: 0.001458, l6: 0.002572

[epoch: 763/1000, batch:   136/ 1052, ite: 200440] train loss: 0.003850, tar: 0.000029 
l0: 0.000022, l1: 0.000023, l2: 0.000076, l3: 0.000303, l4: 0.000787, l5: 0.001592, l6: 0.002727

[epoch: 763/1000, batch:   216/ 1052, ite: 200460] train loss: 0.003851, tar: 0.000029 
l0: 0.000082, l1: 0.000088, l2: 0.000133, l3: 0.000361, l4: 0.001129, l5: 0.001010, l6: 0.002754

[epoch: 763/1000, batch:   296/ 1052, ite: 200480] train loss: 0.003842, tar: 0.000029 
l0: 0.000037, l1: 0.000041, l2: 0.000080, l3: 0.000255, l4: 0.000790, l5: 0.001335, l6: 0.003310

[epoch: 763/1000, batch:   376/ 1052, ite: 200500] train loss: 0.003845, tar: 0.000029 
l0: 0.000039, l1: 0.000038, l2: 0.000121, l3: 0.000334, l4: 0.000808, l5: 0.001688, l6: 0.002057

[epoch: 763/1000, batch:   456/ 1052, ite: 200520] train loss: 0.003845, tar: 0.000029 
l0: 0.000022, l1: 0.000023, l2: 0.000025, l3: 0.000116, l4: 0.000409, l5: 0.000911, l6: 0.001703

[epoch: 763/1000, batch:   536/ 1052, ite: 200540] train loss: 0.003854, tar: 0.000029 
l0: 0.000080, l1: 0.000076, l2: 0.000096, l3: 0.000198, l4: 0.000456, l5: 0.000928, l6: 0.002145

[epoch: 763/1000, batch:   616/ 1052, ite: 200560] train loss: 0.003865, tar: 0.000029 
l0: 0.000009, l1: 0.000010, l2: 0.000022, l3: 0.000112, l4: 0.000475, l5: 0.000738, l6: 0.002345

[epoch: 763/1000, batch:   696/ 1052, ite: 200580] train loss: 0.003868, tar: 0.000029 
l0: 0.000023, l1: 0.000022, l2: 0.000037, l3: 0.000164, l4: 0.000381, l5: 0.000926, l6: 0.002409

[epoch: 763/1000, batch:   776/ 1052, ite: 200600] train loss: 0.003867, tar: 0.000030 
l0: 0.000017, l1: 0.000016, l2: 0.000069, l3: 0.000110, l4: 0.000467, l5: 0.001032, l6: 0.000836

[epoch: 763/1000, batch:   856/ 1052, ite: 200620] train loss: 0.003861, tar: 0.000030 
l0: 0.000021, l1: 0.000021, l2: 0.000062, l3: 0.000323, l4: 0.000903, l5: 0.001662, l6: 0.002404

[epoch: 763/1000, batch:   936/ 1052, ite: 200640] train loss: 0.003875, tar: 0.000030 
l0: 0.000057, l1: 0.000058, l2: 0.000144, l3: 0.000362, l4: 0.000953, l5: 0.002654, l6: 0.003817

[epoch: 763/1000, batch:  1016/ 1052, ite: 200660] train loss: 0.003877, tar: 0.000030 
[Epoch 763/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000006, l1: 0.000006, l2: 0.000015, l3: 0.000064, l4: 0.000230, l5: 0.000794, l6: 0.001305

[epoch: 764/1000, batch:    44/ 1052, ite: 200680] train loss: 0.003867, tar: 0.000030 
l0: 0.000044, l1: 0.000042, l2: 0.000176, l3: 0.000413, l4: 0.000824, l5: 0.002139, l6: 0.003500

[epoch: 764/1000, batch:   124/ 1052, ite: 200700] train loss: 0.003874, tar: 0.000030 
l0: 0.000018, l1: 0.000018, l2: 0.000070, l3: 0.000182, l4: 0.000425, l5: 0.001344, l6: 0.002418

[epoch: 764/1000, batch:   204/ 1052, ite: 200720] train loss: 0.003877, tar: 0.000030 
l0: 0.000122, l1: 0.000118, l2: 0.000142, l3: 0.000216, l4: 0.000432, l5: 0.000730, l6: 0.001323

[epoch: 764/1000, batch:   284/ 1052, ite: 200740] train loss: 0.003866, tar: 0.000030 
l0: 0.000013, l1: 0.000015, l2: 0.000030, l3: 0.000117, l4: 0.000288, l5: 0.000818, l6: 0.001365

[epoch: 764/1000, batch:   364/ 1052, ite: 200760] train loss: 0.003867, tar: 0.000029 
l0: 0.000019, l1: 0.000022, l2: 0.000029, l3: 0.000178, l4: 0.000723, l5: 0.001203, l6: 0.001943

[epoch: 764/1000, batch:   444/ 1052, ite: 200780] train loss: 0.003877, tar: 0.000029 
l0: 0.000016, l1: 0.000019, l2: 0.000124, l3: 0.000334, l4: 0.000765, l5: 0.001472, l6: 0.003850

[epoch: 764/1000, batch:   524/ 1052, ite: 200800] train loss: 0.003885, tar: 0.000029 
l0: 0.000018, l1: 0.000018, l2: 0.000061, l3: 0.000183, l4: 0.000621, l5: 0.001531, l6: 0.002963

[epoch: 764/1000, batch:   604/ 1052, ite: 200820] train loss: 0.003886, tar: 0.000029 
l0: 0.000040, l1: 0.000044, l2: 0.000088, l3: 0.000261, l4: 0.000662, l5: 0.001622, l6: 0.003548

[epoch: 764/1000, batch:   684/ 1052, ite: 200840] train loss: 0.003884, tar: 0.000029 
l0: 0.000008, l1: 0.000009, l2: 0.000049, l3: 0.000196, l4: 0.000564, l5: 0.000971, l6: 0.001850

[epoch: 764/1000, batch:   764/ 1052, ite: 200860] train loss: 0.003871, tar: 0.000029 
l0: 0.000025, l1: 0.000022, l2: 0.000060, l3: 0.000183, l4: 0.000285, l5: 0.000809, l6: 0.001540

[epoch: 764/1000, batch:   844/ 1052, ite: 200880] train loss: 0.003861, tar: 0.000029 
l0: 0.000005, l1: 0.000007, l2: 0.000040, l3: 0.000233, l4: 0.000532, l5: 0.001175, l6: 0.001350

[epoch: 764/1000, batch:   924/ 1052, ite: 200900] train loss: 0.003880, tar: 0.000029 
l0: 0.000003, l1: 0.000005, l2: 0.000033, l3: 0.000063, l4: 0.000144, l5: 0.000525, l6: 0.001248

[epoch: 764/1000, batch:  1004/ 1052, ite: 200920] train loss: 0.003873, tar: 0.000029 
[Epoch 764/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000022, l1: 0.000024, l2: 0.000042, l3: 0.000245, l4: 0.000450, l5: 0.000660, l6: 0.001496

[epoch: 765/1000, batch:    32/ 1052, ite: 200940] train loss: 0.003866, tar: 0.000029 
l0: 0.000024, l1: 0.000025, l2: 0.000080, l3: 0.000192, l4: 0.000625, l5: 0.001000, l6: 0.002771

[epoch: 765/1000, batch:   112/ 1052, ite: 200960] train loss: 0.003860, tar: 0.000029 
l0: 0.000013, l1: 0.000015, l2: 0.000077, l3: 0.000176, l4: 0.000531, l5: 0.001188, l6: 0.002872

[epoch: 765/1000, batch:   192/ 1052, ite: 200980] train loss: 0.003859, tar: 0.000029 
l0: 0.000031, l1: 0.000032, l2: 0.000132, l3: 0.000435, l4: 0.000635, l5: 0.001871, l6: 0.003960

[epoch: 765/1000, batch:   272/ 1052, ite: 201000] train loss: 0.003860, tar: 0.000029 
l0: 0.000028, l1: 0.000026, l2: 0.000065, l3: 0.000128, l4: 0.000350, l5: 0.000643, l6: 0.001448

[epoch: 765/1000, batch:   352/ 1052, ite: 201020] train loss: 0.003858, tar: 0.000029 
l0: 0.000025, l1: 0.000027, l2: 0.000080, l3: 0.000217, l4: 0.000430, l5: 0.000675, l6: 0.002716

[epoch: 765/1000, batch:   432/ 1052, ite: 201040] train loss: 0.003860, tar: 0.000029 
l0: 0.000016, l1: 0.000017, l2: 0.000045, l3: 0.000147, l4: 0.000490, l5: 0.001282, l6: 0.001402

[epoch: 765/1000, batch:   512/ 1052, ite: 201060] train loss: 0.003864, tar: 0.000029 
l0: 0.000004, l1: 0.000004, l2: 0.000023, l3: 0.000038, l4: 0.000430, l5: 0.000729, l6: 0.001528

[epoch: 765/1000, batch:   592/ 1052, ite: 201080] train loss: 0.003866, tar: 0.000029 
l0: 0.000044, l1: 0.000043, l2: 0.000104, l3: 0.000353, l4: 0.000618, l5: 0.001423, l6: 0.003263

[epoch: 765/1000, batch:   672/ 1052, ite: 201100] train loss: 0.003871, tar: 0.000029 
l0: 0.000028, l1: 0.000030, l2: 0.000085, l3: 0.000170, l4: 0.000542, l5: 0.000830, l6: 0.001683

[epoch: 765/1000, batch:   752/ 1052, ite: 201120] train loss: 0.003868, tar: 0.000029 
l0: 0.000032, l1: 0.000033, l2: 0.000036, l3: 0.000071, l4: 0.000289, l5: 0.000710, l6: 0.001244

[epoch: 765/1000, batch:   832/ 1052, ite: 201140] train loss: 0.003865, tar: 0.000029 
l0: 0.000015, l1: 0.000019, l2: 0.000049, l3: 0.000087, l4: 0.000323, l5: 0.000639, l6: 0.002281

[epoch: 765/1000, batch:   912/ 1052, ite: 201160] train loss: 0.003866, tar: 0.000029 
l0: 0.000002, l1: 0.000003, l2: 0.000035, l3: 0.000087, l4: 0.000249, l5: 0.000457, l6: 0.001229

[epoch: 765/1000, batch:   992/ 1052, ite: 201180] train loss: 0.003864, tar: 0.000029 
[Epoch 765/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000031, l1: 0.000033, l2: 0.000068, l3: 0.000096, l4: 0.000464, l5: 0.000888, l6: 0.001652

[epoch: 766/1000, batch:    20/ 1052, ite: 201200] train loss: 0.003867, tar: 0.000029 
l0: 0.000040, l1: 0.000042, l2: 0.000066, l3: 0.000173, l4: 0.000441, l5: 0.001333, l6: 0.003661

[epoch: 766/1000, batch:   100/ 1052, ite: 201220] train loss: 0.003868, tar: 0.000029 
l0: 0.000017, l1: 0.000017, l2: 0.000029, l3: 0.000217, l4: 0.000562, l5: 0.000939, l6: 0.001270

[epoch: 766/1000, batch:   180/ 1052, ite: 201240] train loss: 0.003879, tar: 0.000029 
l0: 0.000040, l1: 0.000037, l2: 0.000091, l3: 0.000139, l4: 0.000444, l5: 0.000842, l6: 0.002191

[epoch: 766/1000, batch:   260/ 1052, ite: 201260] train loss: 0.003875, tar: 0.000029 
l0: 0.000019, l1: 0.000018, l2: 0.000041, l3: 0.000152, l4: 0.000283, l5: 0.000648, l6: 0.001411

[epoch: 766/1000, batch:   340/ 1052, ite: 201280] train loss: 0.003875, tar: 0.000029 
l0: 0.000070, l1: 0.000070, l2: 0.000143, l3: 0.000475, l4: 0.001099, l5: 0.002327, l6: 0.003412

[epoch: 766/1000, batch:   420/ 1052, ite: 201300] train loss: 0.003872, tar: 0.000029 
l0: 0.000038, l1: 0.000039, l2: 0.000118, l3: 0.000240, l4: 0.000574, l5: 0.000938, l6: 0.001967

[epoch: 766/1000, batch:   500/ 1052, ite: 201320] train loss: 0.003865, tar: 0.000029 
l0: 0.000057, l1: 0.000055, l2: 0.000076, l3: 0.000186, l4: 0.000524, l5: 0.001025, l6: 0.001566

[epoch: 766/1000, batch:   580/ 1052, ite: 201340] train loss: 0.003863, tar: 0.000029 
l0: 0.000024, l1: 0.000024, l2: 0.000066, l3: 0.000239, l4: 0.000522, l5: 0.001919, l6: 0.003234

[epoch: 766/1000, batch:   660/ 1052, ite: 201360] train loss: 0.003867, tar: 0.000029 
l0: 0.000045, l1: 0.000048, l2: 0.000112, l3: 0.000251, l4: 0.000521, l5: 0.001010, l6: 0.002202

[epoch: 766/1000, batch:   740/ 1052, ite: 201380] train loss: 0.003869, tar: 0.000029 
l0: 0.000063, l1: 0.000065, l2: 0.000079, l3: 0.000163, l4: 0.000596, l5: 0.001542, l6: 0.002813

[epoch: 766/1000, batch:   820/ 1052, ite: 201400] train loss: 0.003865, tar: 0.000030 
l0: 0.000055, l1: 0.000054, l2: 0.000100, l3: 0.000164, l4: 0.000583, l5: 0.000957, l6: 0.002142

[epoch: 766/1000, batch:   900/ 1052, ite: 201420] train loss: 0.003860, tar: 0.000029 
l0: 0.000021, l1: 0.000026, l2: 0.000045, l3: 0.000162, l4: 0.000538, l5: 0.001133, l6: 0.002281

[epoch: 766/1000, batch:   980/ 1052, ite: 201440] train loss: 0.003864, tar: 0.000030 
[Epoch 766/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000030, l1: 0.000031, l2: 0.000052, l3: 0.000174, l4: 0.000424, l5: 0.001182, l6: 0.001534

[epoch: 767/1000, batch:     8/ 1052, ite: 201460] train loss: 0.003864, tar: 0.000029 
l0: 0.000015, l1: 0.000014, l2: 0.000107, l3: 0.000253, l4: 0.000502, l5: 0.001076, l6: 0.001334

[epoch: 767/1000, batch:    88/ 1052, ite: 201480] train loss: 0.003873, tar: 0.000029 
l0: 0.000004, l1: 0.000004, l2: 0.000052, l3: 0.000138, l4: 0.000464, l5: 0.000922, l6: 0.001065

[epoch: 767/1000, batch:   168/ 1052, ite: 201500] train loss: 0.003873, tar: 0.000029 
l0: 0.000008, l1: 0.000009, l2: 0.000025, l3: 0.000068, l4: 0.000495, l5: 0.000888, l6: 0.001352

[epoch: 767/1000, batch:   248/ 1052, ite: 201520] train loss: 0.003866, tar: 0.000029 
l0: 0.000027, l1: 0.000027, l2: 0.000165, l3: 0.000306, l4: 0.000862, l5: 0.001968, l6: 0.003393

[epoch: 767/1000, batch:   328/ 1052, ite: 201540] train loss: 0.003863, tar: 0.000029 
l0: 0.000028, l1: 0.000032, l2: 0.000034, l3: 0.000121, l4: 0.000281, l5: 0.001009, l6: 0.002680

[epoch: 767/1000, batch:   408/ 1052, ite: 201560] train loss: 0.003873, tar: 0.000029 
l0: 0.000001, l1: 0.000001, l2: 0.000015, l3: 0.000108, l4: 0.000251, l5: 0.000950, l6: 0.001483

[epoch: 767/1000, batch:   488/ 1052, ite: 201580] train loss: 0.003876, tar: 0.000029 
l0: 0.000001, l1: 0.000001, l2: 0.000014, l3: 0.000054, l4: 0.000294, l5: 0.000797, l6: 0.001433

[epoch: 767/1000, batch:   568/ 1052, ite: 201600] train loss: 0.003878, tar: 0.000029 
l0: 0.000023, l1: 0.000022, l2: 0.000046, l3: 0.000095, l4: 0.000264, l5: 0.000985, l6: 0.000904

[epoch: 767/1000, batch:   648/ 1052, ite: 201620] train loss: 0.003874, tar: 0.000029 
l0: 0.000051, l1: 0.000050, l2: 0.000087, l3: 0.000195, l4: 0.000525, l5: 0.001105, l6: 0.001379

[epoch: 767/1000, batch:   728/ 1052, ite: 201640] train loss: 0.003878, tar: 0.000029 
l0: 0.000042, l1: 0.000041, l2: 0.000135, l3: 0.000194, l4: 0.000403, l5: 0.000840, l6: 0.002090

[epoch: 767/1000, batch:   808/ 1052, ite: 201660] train loss: 0.003875, tar: 0.000029 
l0: 0.000008, l1: 0.000008, l2: 0.000029, l3: 0.000060, l4: 0.000321, l5: 0.000618, l6: 0.001504

[epoch: 767/1000, batch:   888/ 1052, ite: 201680] train loss: 0.003873, tar: 0.000030 
l0: 0.000005, l1: 0.000006, l2: 0.000014, l3: 0.000055, l4: 0.000095, l5: 0.000502, l6: 0.001302

[epoch: 767/1000, batch:   968/ 1052, ite: 201700] train loss: 0.003870, tar: 0.000030 
l0: 0.000003, l1: 0.000004, l2: 0.000027, l3: 0.000130, l4: 0.000326, l5: 0.000717, l6: 0.001233

[epoch: 767/1000, batch:  1048/ 1052, ite: 201720] train loss: 0.003867, tar: 0.000030 
[Epoch 767/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000129, l1: 0.000132, l2: 0.000154, l3: 0.000187, l4: 0.000412, l5: 0.000850, l6: 0.001550

[epoch: 768/1000, batch:    76/ 1052, ite: 201740] train loss: 0.003860, tar: 0.000030 
l0: 0.000091, l1: 0.000092, l2: 0.000127, l3: 0.000182, l4: 0.000572, l5: 0.001142, l6: 0.001728

[epoch: 768/1000, batch:   156/ 1052, ite: 201760] train loss: 0.003857, tar: 0.000030 
l0: 0.000003, l1: 0.000003, l2: 0.000033, l3: 0.000136, l4: 0.000312, l5: 0.000919, l6: 0.001513

[epoch: 768/1000, batch:   236/ 1052, ite: 201780] train loss: 0.003861, tar: 0.000030 
l0: 0.000008, l1: 0.000009, l2: 0.000020, l3: 0.000076, l4: 0.000246, l5: 0.000805, l6: 0.001111

[epoch: 768/1000, batch:   316/ 1052, ite: 201800] train loss: 0.003855, tar: 0.000029 
l0: 0.000004, l1: 0.000004, l2: 0.000029, l3: 0.000095, l4: 0.000385, l5: 0.000731, l6: 0.000953

[epoch: 768/1000, batch:   396/ 1052, ite: 201820] train loss: 0.003858, tar: 0.000029 
l0: 0.000023, l1: 0.000024, l2: 0.000053, l3: 0.000119, l4: 0.000407, l5: 0.000910, l6: 0.001290

[epoch: 768/1000, batch:   476/ 1052, ite: 201840] train loss: 0.003857, tar: 0.000030 
l0: 0.000016, l1: 0.000016, l2: 0.000036, l3: 0.000094, l4: 0.000351, l5: 0.000903, l6: 0.001250

[epoch: 768/1000, batch:   556/ 1052, ite: 201860] train loss: 0.003862, tar: 0.000030 
l0: 0.000057, l1: 0.000058, l2: 0.000138, l3: 0.000254, l4: 0.000642, l5: 0.001458, l6: 0.002772

[epoch: 768/1000, batch:   636/ 1052, ite: 201880] train loss: 0.003866, tar: 0.000030 
l0: 0.000051, l1: 0.000051, l2: 0.000089, l3: 0.000201, l4: 0.000428, l5: 0.001358, l6: 0.002920

[epoch: 768/1000, batch:   716/ 1052, ite: 201900] train loss: 0.003865, tar: 0.000030 
l0: 0.000029, l1: 0.000032, l2: 0.000077, l3: 0.000194, l4: 0.000412, l5: 0.001068, l6: 0.001715

[epoch: 768/1000, batch:   796/ 1052, ite: 201920] train loss: 0.003867, tar: 0.000030 
l0: 0.000050, l1: 0.000055, l2: 0.000093, l3: 0.000296, l4: 0.001020, l5: 0.001759, l6: 0.003855

[epoch: 768/1000, batch:   876/ 1052, ite: 201940] train loss: 0.003871, tar: 0.000030 
l0: 0.000041, l1: 0.000040, l2: 0.000082, l3: 0.000189, l4: 0.000445, l5: 0.001103, l6: 0.000918

[epoch: 768/1000, batch:   956/ 1052, ite: 201960] train loss: 0.003872, tar: 0.000030 
l0: 0.000010, l1: 0.000011, l2: 0.000021, l3: 0.000093, l4: 0.000305, l5: 0.000763, l6: 0.001435

[epoch: 768/1000, batch:  1036/ 1052, ite: 201980] train loss: 0.003870, tar: 0.000030 
[Epoch 768/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000014, l1: 0.000013, l2: 0.000080, l3: 0.000176, l4: 0.000415, l5: 0.001255, l6: 0.002259

[epoch: 769/1000, batch:    64/ 1052, ite: 202000] train loss: 0.003872, tar: 0.000030 
l0: 0.000005, l1: 0.000005, l2: 0.000021, l3: 0.000099, l4: 0.000422, l5: 0.000940, l6: 0.001584

[epoch: 769/1000, batch:   144/ 1052, ite: 202020] train loss: 0.003873, tar: 0.000030 
l0: 0.000069, l1: 0.000066, l2: 0.000123, l3: 0.000208, l4: 0.000296, l5: 0.001190, l6: 0.001470

[epoch: 769/1000, batch:   224/ 1052, ite: 202040] train loss: 0.003877, tar: 0.000030 
l0: 0.000031, l1: 0.000031, l2: 0.000068, l3: 0.000200, l4: 0.000424, l5: 0.000829, l6: 0.001134

[epoch: 769/1000, batch:   304/ 1052, ite: 202060] train loss: 0.003875, tar: 0.000030 
l0: 0.000028, l1: 0.000029, l2: 0.000060, l3: 0.000183, l4: 0.000624, l5: 0.001430, l6: 0.002630

[epoch: 769/1000, batch:   384/ 1052, ite: 202080] train loss: 0.003876, tar: 0.000030 
l0: 0.000027, l1: 0.000025, l2: 0.000065, l3: 0.000191, l4: 0.000441, l5: 0.001008, l6: 0.001867

[epoch: 769/1000, batch:   464/ 1052, ite: 202100] train loss: 0.003875, tar: 0.000030 
l0: 0.000030, l1: 0.000032, l2: 0.000096, l3: 0.000245, l4: 0.000656, l5: 0.001413, l6: 0.002076

[epoch: 769/1000, batch:   544/ 1052, ite: 202120] train loss: 0.003869, tar: 0.000030 
l0: 0.000037, l1: 0.000036, l2: 0.000063, l3: 0.000156, l4: 0.000362, l5: 0.000832, l6: 0.001339

[epoch: 769/1000, batch:   624/ 1052, ite: 202140] train loss: 0.003869, tar: 0.000030 
l0: 0.000076, l1: 0.000074, l2: 0.000118, l3: 0.000283, l4: 0.001095, l5: 0.002218, l6: 0.003362

[epoch: 769/1000, batch:   704/ 1052, ite: 202160] train loss: 0.003866, tar: 0.000030 
l0: 0.000018, l1: 0.000018, l2: 0.000036, l3: 0.000120, l4: 0.000434, l5: 0.000709, l6: 0.001626

[epoch: 769/1000, batch:   784/ 1052, ite: 202180] train loss: 0.003865, tar: 0.000030 
l0: 0.000018, l1: 0.000018, l2: 0.000053, l3: 0.000151, l4: 0.000224, l5: 0.000631, l6: 0.000773

[epoch: 769/1000, batch:   864/ 1052, ite: 202200] train loss: 0.003869, tar: 0.000030 
l0: 0.000017, l1: 0.000016, l2: 0.000058, l3: 0.000151, l4: 0.000528, l5: 0.001038, l6: 0.001051

[epoch: 769/1000, batch:   944/ 1052, ite: 202220] train loss: 0.003871, tar: 0.000030 
l0: 0.000050, l1: 0.000048, l2: 0.000146, l3: 0.000283, l4: 0.000491, l5: 0.001072, l6: 0.002341

[epoch: 769/1000, batch:  1024/ 1052, ite: 202240] train loss: 0.003872, tar: 0.000030 
[Epoch 769/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000005, l1: 0.000004, l2: 0.000028, l3: 0.000096, l4: 0.000293, l5: 0.000624, l6: 0.002155

[epoch: 770/1000, batch:    52/ 1052, ite: 202260] train loss: 0.003871, tar: 0.000030 
l0: 0.000022, l1: 0.000024, l2: 0.000033, l3: 0.000112, l4: 0.000251, l5: 0.000735, l6: 0.001424

[epoch: 770/1000, batch:   132/ 1052, ite: 202280] train loss: 0.003872, tar: 0.000030 
l0: 0.000049, l1: 0.000048, l2: 0.000107, l3: 0.000132, l4: 0.000279, l5: 0.001009, l6: 0.001614

[epoch: 770/1000, batch:   212/ 1052, ite: 202300] train loss: 0.003870, tar: 0.000030 
l0: 0.000021, l1: 0.000020, l2: 0.000074, l3: 0.000146, l4: 0.000470, l5: 0.001000, l6: 0.001970

[epoch: 770/1000, batch:   292/ 1052, ite: 202320] train loss: 0.003870, tar: 0.000031 
l0: 0.000006, l1: 0.000005, l2: 0.000035, l3: 0.000128, l4: 0.000260, l5: 0.000822, l6: 0.000844

[epoch: 770/1000, batch:   372/ 1052, ite: 202340] train loss: 0.003869, tar: 0.000031 
l0: 0.000000, l1: 0.000001, l2: 0.000001, l3: 0.000035, l4: 0.000139, l5: 0.000353, l6: 0.000321

[epoch: 770/1000, batch:   452/ 1052, ite: 202360] train loss: 0.003871, tar: 0.000031 
l0: 0.000056, l1: 0.000058, l2: 0.000113, l3: 0.000198, l4: 0.000383, l5: 0.000621, l6: 0.001324

[epoch: 770/1000, batch:   532/ 1052, ite: 202380] train loss: 0.003867, tar: 0.000030 
l0: 0.000044, l1: 0.000046, l2: 0.000102, l3: 0.000461, l4: 0.001210, l5: 0.001786, l6: 0.004267

[epoch: 770/1000, batch:   612/ 1052, ite: 202400] train loss: 0.003870, tar: 0.000031 
l0: 0.000012, l1: 0.000012, l2: 0.000034, l3: 0.000118, l4: 0.000418, l5: 0.001051, l6: 0.001144

[epoch: 770/1000, batch:   692/ 1052, ite: 202420] train loss: 0.003869, tar: 0.000030 
l0: 0.000026, l1: 0.000024, l2: 0.000052, l3: 0.000158, l4: 0.000344, l5: 0.000914, l6: 0.001665

[epoch: 770/1000, batch:   772/ 1052, ite: 202440] train loss: 0.003869, tar: 0.000031 
l0: 0.000014, l1: 0.000017, l2: 0.000042, l3: 0.000137, l4: 0.000368, l5: 0.001410, l6: 0.002276

[epoch: 770/1000, batch:   852/ 1052, ite: 202460] train loss: 0.003870, tar: 0.000031 
l0: 0.000034, l1: 0.000035, l2: 0.000069, l3: 0.000207, l4: 0.000356, l5: 0.001302, l6: 0.003615

[epoch: 770/1000, batch:   932/ 1052, ite: 202480] train loss: 0.003868, tar: 0.000031 
l0: 0.000022, l1: 0.000023, l2: 0.000104, l3: 0.000241, l4: 0.000650, l5: 0.001036, l6: 0.002558

[epoch: 770/1000, batch:  1012/ 1052, ite: 202500] train loss: 0.003870, tar: 0.000031 
[Epoch 770/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000031, l1: 0.000031, l2: 0.000083, l3: 0.000430, l4: 0.001328, l5: 0.002448, l6: 0.004322

[epoch: 771/1000, batch:    40/ 1052, ite: 202520] train loss: 0.003872, tar: 0.000030 
l0: 0.000220, l1: 0.000164, l2: 0.000178, l3: 0.000289, l4: 0.000622, l5: 0.001836, l6: 0.003026

[epoch: 771/1000, batch:   120/ 1052, ite: 202540] train loss: 0.003872, tar: 0.000031 
l0: 0.000005, l1: 0.000005, l2: 0.000030, l3: 0.000083, l4: 0.000198, l5: 0.000268, l6: 0.000741

[epoch: 771/1000, batch:   200/ 1052, ite: 202560] train loss: 0.003870, tar: 0.000031 
l0: 0.000021, l1: 0.000021, l2: 0.000149, l3: 0.000404, l4: 0.000751, l5: 0.001375, l6: 0.001707

[epoch: 771/1000, batch:   280/ 1052, ite: 202580] train loss: 0.003873, tar: 0.000031 
l0: 0.000034, l1: 0.000036, l2: 0.000060, l3: 0.000192, l4: 0.000527, l5: 0.001191, l6: 0.002323

[epoch: 771/1000, batch:   360/ 1052, ite: 202600] train loss: 0.003873, tar: 0.000031 
l0: 0.000027, l1: 0.000027, l2: 0.000071, l3: 0.000282, l4: 0.000484, l5: 0.001448, l6: 0.002496

[epoch: 771/1000, batch:   440/ 1052, ite: 202620] train loss: 0.003875, tar: 0.000031 
l0: 0.000008, l1: 0.000010, l2: 0.000027, l3: 0.000185, l4: 0.000480, l5: 0.000759, l6: 0.001734

[epoch: 771/1000, batch:   520/ 1052, ite: 202640] train loss: 0.003876, tar: 0.000031 
l0: 0.000005, l1: 0.000005, l2: 0.000032, l3: 0.000132, l4: 0.000616, l5: 0.001089, l6: 0.001656

[epoch: 771/1000, batch:   600/ 1052, ite: 202660] train loss: 0.003872, tar: 0.000031 
l0: 0.000045, l1: 0.000048, l2: 0.000117, l3: 0.000301, l4: 0.000797, l5: 0.002736, l6: 0.003467

[epoch: 771/1000, batch:   680/ 1052, ite: 202680] train loss: 0.003870, tar: 0.000031 
l0: 0.000019, l1: 0.000021, l2: 0.000033, l3: 0.000092, l4: 0.000393, l5: 0.000895, l6: 0.001768

[epoch: 771/1000, batch:   760/ 1052, ite: 202700] train loss: 0.003870, tar: 0.000031 
l0: 0.000018, l1: 0.000017, l2: 0.000040, l3: 0.000153, l4: 0.000528, l5: 0.001168, l6: 0.002702

[epoch: 771/1000, batch:   840/ 1052, ite: 202720] train loss: 0.003871, tar: 0.000031 
l0: 0.000005, l1: 0.000005, l2: 0.000043, l3: 0.000138, l4: 0.000332, l5: 0.000803, l6: 0.001826

[epoch: 771/1000, batch:   920/ 1052, ite: 202740] train loss: 0.003873, tar: 0.000031 
l0: 0.000036, l1: 0.000031, l2: 0.000074, l3: 0.000166, l4: 0.000391, l5: 0.000907, l6: 0.001346

[epoch: 771/1000, batch:  1000/ 1052, ite: 202760] train loss: 0.003870, tar: 0.000030 
[Epoch 771/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000041, l1: 0.000042, l2: 0.000113, l3: 0.000247, l4: 0.000683, l5: 0.002036, l6: 0.002257

[epoch: 772/1000, batch:    28/ 1052, ite: 202780] train loss: 0.003874, tar: 0.000031 
l0: 0.000012, l1: 0.000013, l2: 0.000028, l3: 0.000047, l4: 0.000231, l5: 0.000699, l6: 0.000838

[epoch: 772/1000, batch:   108/ 1052, ite: 202800] train loss: 0.003877, tar: 0.000031 
l0: 0.000084, l1: 0.000082, l2: 0.000100, l3: 0.000224, l4: 0.000575, l5: 0.001262, l6: 0.001408

[epoch: 772/1000, batch:   188/ 1052, ite: 202820] train loss: 0.003879, tar: 0.000031 
l0: 0.000033, l1: 0.000034, l2: 0.000080, l3: 0.000163, l4: 0.000343, l5: 0.001104, l6: 0.002555

[epoch: 772/1000, batch:   268/ 1052, ite: 202840] train loss: 0.003880, tar: 0.000031 
l0: 0.000074, l1: 0.000074, l2: 0.000077, l3: 0.000173, l4: 0.000374, l5: 0.001071, l6: 0.002617

[epoch: 772/1000, batch:   348/ 1052, ite: 202860] train loss: 0.003881, tar: 0.000031 
l0: 0.000030, l1: 0.000031, l2: 0.000076, l3: 0.000163, l4: 0.000529, l5: 0.001153, l6: 0.001624

[epoch: 772/1000, batch:   428/ 1052, ite: 202880] train loss: 0.003879, tar: 0.000031 
l0: 0.000051, l1: 0.000054, l2: 0.000076, l3: 0.000172, l4: 0.000592, l5: 0.001017, l6: 0.001978

[epoch: 772/1000, batch:   508/ 1052, ite: 202900] train loss: 0.003877, tar: 0.000031 
l0: 0.000015, l1: 0.000018, l2: 0.000040, l3: 0.000114, l4: 0.000524, l5: 0.000645, l6: 0.001955

[epoch: 772/1000, batch:   588/ 1052, ite: 202920] train loss: 0.003878, tar: 0.000031 
l0: 0.000009, l1: 0.000008, l2: 0.000033, l3: 0.000122, l4: 0.000341, l5: 0.000908, l6: 0.001373

[epoch: 772/1000, batch:   668/ 1052, ite: 202940] train loss: 0.003876, tar: 0.000031 
l0: 0.000007, l1: 0.000007, l2: 0.000047, l3: 0.000110, l4: 0.000311, l5: 0.000974, l6: 0.000977

[epoch: 772/1000, batch:   748/ 1052, ite: 202960] train loss: 0.003875, tar: 0.000031 
l0: 0.000016, l1: 0.000015, l2: 0.000039, l3: 0.000162, l4: 0.000182, l5: 0.000450, l6: 0.001647

[epoch: 772/1000, batch:   828/ 1052, ite: 202980] train loss: 0.003872, tar: 0.000031 
l0: 0.000016, l1: 0.000017, l2: 0.000029, l3: 0.000099, l4: 0.000344, l5: 0.000882, l6: 0.002171

[epoch: 772/1000, batch:   908/ 1052, ite: 203000] train loss: 0.003874, tar: 0.000031 
l0: 0.000005, l1: 0.000005, l2: 0.000025, l3: 0.000130, l4: 0.000496, l5: 0.000978, l6: 0.001715

[epoch: 772/1000, batch:   988/ 1052, ite: 203020] train loss: 0.003873, tar: 0.000031 
[Epoch 772/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000049, l1: 0.000054, l2: 0.000098, l3: 0.000217, l4: 0.000606, l5: 0.001255, l6: 0.002159

[epoch: 773/1000, batch:    16/ 1052, ite: 203040] train loss: 0.003875, tar: 0.000031 
l0: 0.000021, l1: 0.000022, l2: 0.000113, l3: 0.000285, l4: 0.000520, l5: 0.001749, l6: 0.002314

[epoch: 773/1000, batch:    96/ 1052, ite: 203060] train loss: 0.003871, tar: 0.000031 
l0: 0.000049, l1: 0.000052, l2: 0.000071, l3: 0.000123, l4: 0.000298, l5: 0.001217, l6: 0.003142

[epoch: 773/1000, batch:   176/ 1052, ite: 203080] train loss: 0.003873, tar: 0.000031 
l0: 0.000014, l1: 0.000015, l2: 0.000051, l3: 0.000105, l4: 0.000299, l5: 0.001078, l6: 0.001445

[epoch: 773/1000, batch:   256/ 1052, ite: 203100] train loss: 0.003874, tar: 0.000031 
l0: 0.000005, l1: 0.000005, l2: 0.000020, l3: 0.000095, l4: 0.000303, l5: 0.000844, l6: 0.000999

[epoch: 773/1000, batch:   336/ 1052, ite: 203120] train loss: 0.003872, tar: 0.000031 
l0: 0.000069, l1: 0.000068, l2: 0.000153, l3: 0.000355, l4: 0.000995, l5: 0.001636, l6: 0.001977

[epoch: 773/1000, batch:   416/ 1052, ite: 203140] train loss: 0.003873, tar: 0.000031 
l0: 0.000015, l1: 0.000017, l2: 0.000027, l3: 0.000073, l4: 0.000259, l5: 0.000642, l6: 0.001610

[epoch: 773/1000, batch:   496/ 1052, ite: 203160] train loss: 0.003874, tar: 0.000031 
l0: 0.000049, l1: 0.000053, l2: 0.000062, l3: 0.000137, l4: 0.000497, l5: 0.000969, l6: 0.001654

[epoch: 773/1000, batch:   576/ 1052, ite: 203180] train loss: 0.003873, tar: 0.000031 
l0: 0.000012, l1: 0.000013, l2: 0.000040, l3: 0.000144, l4: 0.000324, l5: 0.001409, l6: 0.002077

[epoch: 773/1000, batch:   656/ 1052, ite: 203200] train loss: 0.003874, tar: 0.000031 
l0: 0.000023, l1: 0.000026, l2: 0.000060, l3: 0.000149, l4: 0.000340, l5: 0.000639, l6: 0.001801

[epoch: 773/1000, batch:   736/ 1052, ite: 203220] train loss: 0.003876, tar: 0.000031 
l0: 0.000009, l1: 0.000010, l2: 0.000037, l3: 0.000135, l4: 0.000657, l5: 0.001001, l6: 0.001397

[epoch: 773/1000, batch:   816/ 1052, ite: 203240] train loss: 0.003875, tar: 0.000031 
l0: 0.000030, l1: 0.000033, l2: 0.000116, l3: 0.000346, l4: 0.000668, l5: 0.001013, l6: 0.004093

[epoch: 773/1000, batch:   896/ 1052, ite: 203260] train loss: 0.003873, tar: 0.000031 
l0: 0.000015, l1: 0.000015, l2: 0.000035, l3: 0.000162, l4: 0.000387, l5: 0.000961, l6: 0.001345

[epoch: 773/1000, batch:   976/ 1052, ite: 203280] train loss: 0.003870, tar: 0.000031 
[Epoch 773/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000013, l1: 0.000012, l2: 0.000048, l3: 0.000114, l4: 0.000304, l5: 0.000877, l6: 0.001321

[epoch: 774/1000, batch:     4/ 1052, ite: 203300] train loss: 0.003872, tar: 0.000031 
l0: 0.000023, l1: 0.000024, l2: 0.000044, l3: 0.000089, l4: 0.000253, l5: 0.000784, l6: 0.001963

[epoch: 774/1000, batch:    84/ 1052, ite: 203320] train loss: 0.003872, tar: 0.000031 
l0: 0.000008, l1: 0.000009, l2: 0.000042, l3: 0.000101, l4: 0.000311, l5: 0.000769, l6: 0.001776

[epoch: 774/1000, batch:   164/ 1052, ite: 203340] train loss: 0.003872, tar: 0.000031 
l0: 0.000034, l1: 0.000037, l2: 0.000079, l3: 0.000106, l4: 0.000374, l5: 0.000912, l6: 0.000869

[epoch: 774/1000, batch:   244/ 1052, ite: 203360] train loss: 0.003871, tar: 0.000031 
l0: 0.000013, l1: 0.000011, l2: 0.000027, l3: 0.000085, l4: 0.000188, l5: 0.000695, l6: 0.001002

[epoch: 774/1000, batch:   324/ 1052, ite: 203380] train loss: 0.003871, tar: 0.000031 
l0: 0.000044, l1: 0.000041, l2: 0.000064, l3: 0.000142, l4: 0.000343, l5: 0.000911, l6: 0.001684

[epoch: 774/1000, batch:   404/ 1052, ite: 203400] train loss: 0.003872, tar: 0.000031 
l0: 0.000012, l1: 0.000013, l2: 0.000057, l3: 0.000243, l4: 0.000682, l5: 0.001279, l6: 0.002496

[epoch: 774/1000, batch:   484/ 1052, ite: 203420] train loss: 0.003870, tar: 0.000030 
l0: 0.000020, l1: 0.000022, l2: 0.000072, l3: 0.000247, l4: 0.000673, l5: 0.001439, l6: 0.003034

[epoch: 774/1000, batch:   564/ 1052, ite: 203440] train loss: 0.003871, tar: 0.000030 
l0: 0.000019, l1: 0.000020, l2: 0.000065, l3: 0.000172, l4: 0.000752, l5: 0.001315, l6: 0.002676

[epoch: 774/1000, batch:   644/ 1052, ite: 203460] train loss: 0.003871, tar: 0.000030 
l0: 0.000025, l1: 0.000023, l2: 0.000076, l3: 0.000185, l4: 0.000491, l5: 0.001201, l6: 0.001900

[epoch: 774/1000, batch:   724/ 1052, ite: 203480] train loss: 0.003871, tar: 0.000030 
l0: 0.000009, l1: 0.000009, l2: 0.000040, l3: 0.000124, l4: 0.000397, l5: 0.000737, l6: 0.001765

[epoch: 774/1000, batch:   804/ 1052, ite: 203500] train loss: 0.003872, tar: 0.000030 
l0: 0.000013, l1: 0.000012, l2: 0.000029, l3: 0.000138, l4: 0.000322, l5: 0.000596, l6: 0.001029

[epoch: 774/1000, batch:   884/ 1052, ite: 203520] train loss: 0.003874, tar: 0.000030 
l0: 0.000023, l1: 0.000023, l2: 0.000097, l3: 0.000214, l4: 0.000685, l5: 0.001457, l6: 0.002209

[epoch: 774/1000, batch:   964/ 1052, ite: 203540] train loss: 0.003871, tar: 0.000030 
l0: 0.000007, l1: 0.000008, l2: 0.000049, l3: 0.000151, l4: 0.000285, l5: 0.000836, l6: 0.000908

[epoch: 774/1000, batch:  1044/ 1052, ite: 203560] train loss: 0.003874, tar: 0.000031 
[Epoch 774/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000016, l1: 0.000017, l2: 0.000027, l3: 0.000114, l4: 0.000215, l5: 0.001011, l6: 0.001227

[epoch: 775/1000, batch:    72/ 1052, ite: 203580] train loss: 0.003873, tar: 0.000030 
l0: 0.000029, l1: 0.000032, l2: 0.000036, l3: 0.000216, l4: 0.000798, l5: 0.001263, l6: 0.002224

[epoch: 775/1000, batch:   152/ 1052, ite: 203600] train loss: 0.003873, tar: 0.000030 
l0: 0.000027, l1: 0.000026, l2: 0.000052, l3: 0.000134, l4: 0.000330, l5: 0.000788, l6: 0.001833

[epoch: 775/1000, batch:   232/ 1052, ite: 203620] train loss: 0.003876, tar: 0.000031 
l0: 0.000018, l1: 0.000019, l2: 0.000055, l3: 0.000109, l4: 0.000422, l5: 0.000778, l6: 0.001904

[epoch: 775/1000, batch:   312/ 1052, ite: 203640] train loss: 0.003877, tar: 0.000030 
l0: 0.000005, l1: 0.000007, l2: 0.000018, l3: 0.000104, l4: 0.000358, l5: 0.001023, l6: 0.001532

[epoch: 775/1000, batch:   392/ 1052, ite: 203660] train loss: 0.003877, tar: 0.000030 
l0: 0.000009, l1: 0.000007, l2: 0.000017, l3: 0.000065, l4: 0.000276, l5: 0.000557, l6: 0.000818

[epoch: 775/1000, batch:   472/ 1052, ite: 203680] train loss: 0.003875, tar: 0.000031 
l0: 0.000014, l1: 0.000015, l2: 0.000034, l3: 0.000128, l4: 0.000556, l5: 0.001296, l6: 0.001606

[epoch: 775/1000, batch:   552/ 1052, ite: 203700] train loss: 0.003875, tar: 0.000031 
l0: 0.000083, l1: 0.000089, l2: 0.000094, l3: 0.000145, l4: 0.000542, l5: 0.001136, l6: 0.003083

[epoch: 775/1000, batch:   632/ 1052, ite: 203720] train loss: 0.003875, tar: 0.000031 
l0: 0.000028, l1: 0.000029, l2: 0.000081, l3: 0.000267, l4: 0.000729, l5: 0.001707, l6: 0.002800

[epoch: 775/1000, batch:   712/ 1052, ite: 203740] train loss: 0.003876, tar: 0.000031 
l0: 0.000012, l1: 0.000013, l2: 0.000017, l3: 0.000139, l4: 0.000237, l5: 0.001070, l6: 0.001335

[epoch: 775/1000, batch:   792/ 1052, ite: 203760] train loss: 0.003877, tar: 0.000031 
l0: 0.000007, l1: 0.000010, l2: 0.000032, l3: 0.000123, l4: 0.000288, l5: 0.000384, l6: 0.001293

[epoch: 775/1000, batch:   872/ 1052, ite: 203780] train loss: 0.003878, tar: 0.000031 
l0: 0.000066, l1: 0.000068, l2: 0.000103, l3: 0.000163, l4: 0.000502, l5: 0.001094, l6: 0.003136

[epoch: 775/1000, batch:   952/ 1052, ite: 203800] train loss: 0.003880, tar: 0.000031 
l0: 0.000024, l1: 0.000023, l2: 0.000069, l3: 0.000177, l4: 0.000249, l5: 0.000718, l6: 0.001203

[epoch: 775/1000, batch:  1032/ 1052, ite: 203820] train loss: 0.003881, tar: 0.000031 
[Epoch 775/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000023, l1: 0.000024, l2: 0.000084, l3: 0.000206, l4: 0.000547, l5: 0.001201, l6: 0.002022

[epoch: 776/1000, batch:    60/ 1052, ite: 203840] train loss: 0.003880, tar: 0.000031 
l0: 0.000032, l1: 0.000035, l2: 0.000101, l3: 0.000358, l4: 0.000577, l5: 0.001247, l6: 0.003611

[epoch: 776/1000, batch:   140/ 1052, ite: 203860] train loss: 0.003880, tar: 0.000031 
l0: 0.000023, l1: 0.000022, l2: 0.000078, l3: 0.000197, l4: 0.000420, l5: 0.000914, l6: 0.001285

[epoch: 776/1000, batch:   220/ 1052, ite: 203880] train loss: 0.003884, tar: 0.000031 
l0: 0.000132, l1: 0.000130, l2: 0.000143, l3: 0.000255, l4: 0.000456, l5: 0.000832, l6: 0.001196

[epoch: 776/1000, batch:   300/ 1052, ite: 203900] train loss: 0.003884, tar: 0.000031 
l0: 0.000017, l1: 0.000015, l2: 0.000073, l3: 0.000192, l4: 0.000567, l5: 0.001352, l6: 0.002974

[epoch: 776/1000, batch:   380/ 1052, ite: 203920] train loss: 0.003885, tar: 0.000031 
l0: 0.000038, l1: 0.000044, l2: 0.000080, l3: 0.000225, l4: 0.000553, l5: 0.001342, l6: 0.002378

[epoch: 776/1000, batch:   460/ 1052, ite: 203940] train loss: 0.003883, tar: 0.000031 
l0: 0.000021, l1: 0.000022, l2: 0.000083, l3: 0.000265, l4: 0.000474, l5: 0.001101, l6: 0.002781

[epoch: 776/1000, batch:   540/ 1052, ite: 203960] train loss: 0.003883, tar: 0.000031 
l0: 0.000031, l1: 0.000033, l2: 0.000035, l3: 0.000080, l4: 0.000234, l5: 0.000478, l6: 0.001734

[epoch: 776/1000, batch:   620/ 1052, ite: 203980] train loss: 0.003881, tar: 0.000031 
l0: 0.000016, l1: 0.000014, l2: 0.000039, l3: 0.000126, l4: 0.000238, l5: 0.000867, l6: 0.001503

[epoch: 776/1000, batch:   700/ 1052, ite: 204000] train loss: 0.003880, tar: 0.000031 
l0: 0.000010, l1: 0.000011, l2: 0.000016, l3: 0.000050, l4: 0.000202, l5: 0.000702, l6: 0.001286

[epoch: 776/1000, batch:   780/ 1052, ite: 204020] train loss: 0.003879, tar: 0.000031 
l0: 0.000013, l1: 0.000013, l2: 0.000044, l3: 0.000108, l4: 0.000254, l5: 0.000582, l6: 0.001268

[epoch: 776/1000, batch:   860/ 1052, ite: 204040] train loss: 0.003876, tar: 0.000031 
l0: 0.000018, l1: 0.000019, l2: 0.000052, l3: 0.000165, l4: 0.000542, l5: 0.001036, l6: 0.003245

[epoch: 776/1000, batch:   940/ 1052, ite: 204060] train loss: 0.003877, tar: 0.000031 
l0: 0.000026, l1: 0.000027, l2: 0.000064, l3: 0.000154, l4: 0.000502, l5: 0.000606, l6: 0.002012

[epoch: 776/1000, batch:  1020/ 1052, ite: 204080] train loss: 0.003880, tar: 0.000031 
[Epoch 776/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000013, l1: 0.000011, l2: 0.000072, l3: 0.000198, l4: 0.000551, l5: 0.001052, l6: 0.002203

[epoch: 777/1000, batch:    48/ 1052, ite: 204100] train loss: 0.003880, tar: 0.000031 
l0: 0.000035, l1: 0.000041, l2: 0.000040, l3: 0.000171, l4: 0.000519, l5: 0.001081, l6: 0.001497

[epoch: 777/1000, batch:   128/ 1052, ite: 204120] train loss: 0.003881, tar: 0.000031 
l0: 0.000077, l1: 0.000077, l2: 0.000166, l3: 0.000326, l4: 0.000740, l5: 0.001103, l6: 0.003243

[epoch: 777/1000, batch:   208/ 1052, ite: 204140] train loss: 0.003881, tar: 0.000031 
l0: 0.000025, l1: 0.000114, l2: 0.000046, l3: 0.000140, l4: 0.000352, l5: 0.000532, l6: 0.001216

[epoch: 777/1000, batch:   288/ 1052, ite: 204160] train loss: 0.003879, tar: 0.000031 
l0: 0.000012, l1: 0.000010, l2: 0.000038, l3: 0.000279, l4: 0.000351, l5: 0.000657, l6: 0.001243

[epoch: 777/1000, batch:   368/ 1052, ite: 204180] train loss: 0.003879, tar: 0.000031 
l0: 0.000049, l1: 0.000043, l2: 0.000094, l3: 0.000227, l4: 0.000498, l5: 0.000894, l6: 0.001527

[epoch: 777/1000, batch:   448/ 1052, ite: 204200] train loss: 0.003880, tar: 0.000031 
l0: 0.000016, l1: 0.000015, l2: 0.000061, l3: 0.000141, l4: 0.000240, l5: 0.000924, l6: 0.001274

[epoch: 777/1000, batch:   528/ 1052, ite: 204220] train loss: 0.003880, tar: 0.000031 
l0: 0.000011, l1: 0.000013, l2: 0.000033, l3: 0.000157, l4: 0.000499, l5: 0.001277, l6: 0.002847

[epoch: 777/1000, batch:   608/ 1052, ite: 204240] train loss: 0.003884, tar: 0.000031 
l0: 0.000017, l1: 0.000017, l2: 0.000057, l3: 0.000125, l4: 0.000333, l5: 0.000809, l6: 0.002153

[epoch: 777/1000, batch:   688/ 1052, ite: 204260] train loss: 0.003883, tar: 0.000031 
l0: 0.000042, l1: 0.000044, l2: 0.000070, l3: 0.000177, l4: 0.000268, l5: 0.001094, l6: 0.002103

[epoch: 777/1000, batch:   768/ 1052, ite: 204280] train loss: 0.003881, tar: 0.000031 
l0: 0.000004, l1: 0.000005, l2: 0.000026, l3: 0.000082, l4: 0.000332, l5: 0.000817, l6: 0.001345

[epoch: 777/1000, batch:   848/ 1052, ite: 204300] train loss: 0.003881, tar: 0.000031 
l0: 0.000016, l1: 0.000017, l2: 0.000035, l3: 0.000173, l4: 0.000326, l5: 0.001184, l6: 0.002585

[epoch: 777/1000, batch:   928/ 1052, ite: 204320] train loss: 0.003883, tar: 0.000031 
l0: 0.000025, l1: 0.000026, l2: 0.000067, l3: 0.000180, l4: 0.001069, l5: 0.001006, l6: 0.002341

[epoch: 777/1000, batch:  1008/ 1052, ite: 204340] train loss: 0.003881, tar: 0.000031 
[Epoch 777/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000061, l1: 0.000064, l2: 0.000109, l3: 0.000190, l4: 0.000590, l5: 0.000966, l6: 0.002913

[epoch: 778/1000, batch:    36/ 1052, ite: 204360] train loss: 0.003879, tar: 0.000031 
l0: 0.000007, l1: 0.000008, l2: 0.000026, l3: 0.000116, l4: 0.000322, l5: 0.000882, l6: 0.001983

[epoch: 778/1000, batch:   116/ 1052, ite: 204380] train loss: 0.003879, tar: 0.000031 
l0: 0.000045, l1: 0.000047, l2: 0.000084, l3: 0.000178, l4: 0.000437, l5: 0.000606, l6: 0.001785

[epoch: 778/1000, batch:   196/ 1052, ite: 204400] train loss: 0.003878, tar: 0.000031 
l0: 0.000137, l1: 0.000133, l2: 0.000241, l3: 0.000489, l4: 0.000541, l5: 0.001194, l6: 0.003949

[epoch: 778/1000, batch:   276/ 1052, ite: 204420] train loss: 0.003879, tar: 0.000031 
l0: 0.000019, l1: 0.000022, l2: 0.000104, l3: 0.000254, l4: 0.000431, l5: 0.001056, l6: 0.002114

[epoch: 778/1000, batch:   356/ 1052, ite: 204440] train loss: 0.003879, tar: 0.000031 
l0: 0.000042, l1: 0.000042, l2: 0.000086, l3: 0.000226, l4: 0.000630, l5: 0.001115, l6: 0.001799

[epoch: 778/1000, batch:   436/ 1052, ite: 204460] train loss: 0.003879, tar: 0.000031 
l0: 0.000013, l1: 0.000011, l2: 0.000054, l3: 0.000160, l4: 0.000369, l5: 0.000989, l6: 0.001521

[epoch: 778/1000, batch:   516/ 1052, ite: 204480] train loss: 0.003878, tar: 0.000031 
l0: 0.000012, l1: 0.000012, l2: 0.000079, l3: 0.000156, l4: 0.000440, l5: 0.000967, l6: 0.001633

[epoch: 778/1000, batch:   596/ 1052, ite: 204500] train loss: 0.003878, tar: 0.000031 
l0: 0.000073, l1: 0.000073, l2: 0.000088, l3: 0.000179, l4: 0.000356, l5: 0.001088, l6: 0.002610

[epoch: 778/1000, batch:   676/ 1052, ite: 204520] train loss: 0.003877, tar: 0.000031 
l0: 0.000031, l1: 0.000029, l2: 0.000071, l3: 0.000205, l4: 0.000515, l5: 0.001306, l6: 0.002813

[epoch: 778/1000, batch:   756/ 1052, ite: 204540] train loss: 0.003878, tar: 0.000031 
l0: 0.000025, l1: 0.000030, l2: 0.000060, l3: 0.000179, l4: 0.000749, l5: 0.002090, l6: 0.003028

[epoch: 778/1000, batch:   836/ 1052, ite: 204560] train loss: 0.003878, tar: 0.000031 
l0: 0.000013, l1: 0.000013, l2: 0.000039, l3: 0.000107, l4: 0.000383, l5: 0.000854, l6: 0.001579

[epoch: 778/1000, batch:   916/ 1052, ite: 204580] train loss: 0.003879, tar: 0.000031 
l0: 0.000074, l1: 0.000067, l2: 0.000228, l3: 0.000659, l4: 0.001127, l5: 0.002337, l6: 0.003609

[epoch: 778/1000, batch:   996/ 1052, ite: 204600] train loss: 0.003881, tar: 0.000031 
[Epoch 778/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000046, l1: 0.000045, l2: 0.000132, l3: 0.000285, l4: 0.000551, l5: 0.001076, l6: 0.001441

[epoch: 779/1000, batch:    24/ 1052, ite: 204620] train loss: 0.003879, tar: 0.000031 
l0: 0.000033, l1: 0.000030, l2: 0.000106, l3: 0.000292, l4: 0.000682, l5: 0.001456, l6: 0.002625

[epoch: 779/1000, batch:   104/ 1052, ite: 204640] train loss: 0.003879, tar: 0.000031 
l0: 0.000039, l1: 0.000044, l2: 0.000138, l3: 0.000326, l4: 0.000694, l5: 0.001828, l6: 0.004759

[epoch: 779/1000, batch:   184/ 1052, ite: 204660] train loss: 0.003879, tar: 0.000031 
l0: 0.000035, l1: 0.000035, l2: 0.000059, l3: 0.000164, l4: 0.000441, l5: 0.001680, l6: 0.002598

[epoch: 779/1000, batch:   264/ 1052, ite: 204680] train loss: 0.003878, tar: 0.000031 
l0: 0.000014, l1: 0.000014, l2: 0.000054, l3: 0.000183, l4: 0.000604, l5: 0.001313, l6: 0.002559

[epoch: 779/1000, batch:   344/ 1052, ite: 204700] train loss: 0.003876, tar: 0.000031 
l0: 0.000038, l1: 0.000040, l2: 0.000076, l3: 0.000192, l4: 0.000345, l5: 0.001243, l6: 0.001848

[epoch: 779/1000, batch:   424/ 1052, ite: 204720] train loss: 0.003878, tar: 0.000031 
l0: 0.000031, l1: 0.000033, l2: 0.000062, l3: 0.000159, l4: 0.000410, l5: 0.001647, l6: 0.003283

[epoch: 779/1000, batch:   504/ 1052, ite: 204740] train loss: 0.003880, tar: 0.000031 
l0: 0.000014, l1: 0.000016, l2: 0.000058, l3: 0.000213, l4: 0.000594, l5: 0.000844, l6: 0.002062

[epoch: 779/1000, batch:   584/ 1052, ite: 204760] train loss: 0.003880, tar: 0.000031 
l0: 0.000078, l1: 0.000077, l2: 0.000139, l3: 0.000254, l4: 0.000646, l5: 0.000936, l6: 0.002693

[epoch: 779/1000, batch:   664/ 1052, ite: 204780] train loss: 0.003879, tar: 0.000031 
l0: 0.000045, l1: 0.000044, l2: 0.000063, l3: 0.000108, l4: 0.000298, l5: 0.000674, l6: 0.000960

[epoch: 779/1000, batch:   744/ 1052, ite: 204800] train loss: 0.003880, tar: 0.000031 
l0: 0.000066, l1: 0.000064, l2: 0.000117, l3: 0.000178, l4: 0.000298, l5: 0.001234, l6: 0.001840

[epoch: 779/1000, batch:   824/ 1052, ite: 204820] train loss: 0.003882, tar: 0.000031 
l0: 0.000056, l1: 0.000054, l2: 0.000102, l3: 0.000216, l4: 0.000507, l5: 0.000651, l6: 0.001213

[epoch: 779/1000, batch:   904/ 1052, ite: 204840] train loss: 0.003881, tar: 0.000031 
l0: 0.000031, l1: 0.000030, l2: 0.000069, l3: 0.000177, l4: 0.000349, l5: 0.000903, l6: 0.001026

[epoch: 779/1000, batch:   984/ 1052, ite: 204860] train loss: 0.003879, tar: 0.000031 
[Epoch 779/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000016, l1: 0.000019, l2: 0.000042, l3: 0.000083, l4: 0.000267, l5: 0.000457, l6: 0.000999

[epoch: 780/1000, batch:    12/ 1052, ite: 204880] train loss: 0.003878, tar: 0.000031 
l0: 0.000022, l1: 0.000023, l2: 0.000057, l3: 0.000131, l4: 0.000366, l5: 0.001003, l6: 0.001527

[epoch: 780/1000, batch:    92/ 1052, ite: 204900] train loss: 0.003877, tar: 0.000031 
l0: 0.000021, l1: 0.000022, l2: 0.000068, l3: 0.000150, l4: 0.000456, l5: 0.001821, l6: 0.002310

[epoch: 780/1000, batch:   172/ 1052, ite: 204920] train loss: 0.003876, tar: 0.000031 
l0: 0.000024, l1: 0.000026, l2: 0.000057, l3: 0.000164, l4: 0.000418, l5: 0.000754, l6: 0.001334

[epoch: 780/1000, batch:   252/ 1052, ite: 204940] train loss: 0.003876, tar: 0.000031 
l0: 0.000024, l1: 0.000022, l2: 0.000081, l3: 0.000267, l4: 0.000451, l5: 0.001343, l6: 0.001975

[epoch: 780/1000, batch:   332/ 1052, ite: 204960] train loss: 0.003876, tar: 0.000031 
l0: 0.000047, l1: 0.000050, l2: 0.000105, l3: 0.000180, l4: 0.000531, l5: 0.001003, l6: 0.001203

[epoch: 780/1000, batch:   412/ 1052, ite: 204980] train loss: 0.003875, tar: 0.000031 
l0: 0.000007, l1: 0.000007, l2: 0.000040, l3: 0.000147, l4: 0.000398, l5: 0.000487, l6: 0.002194

[epoch: 780/1000, batch:   492/ 1052, ite: 205000] train loss: 0.003874, tar: 0.000031 
l0: 0.000009, l1: 0.000010, l2: 0.000027, l3: 0.000120, l4: 0.000440, l5: 0.000563, l6: 0.001771

[epoch: 780/1000, batch:   572/ 1052, ite: 205020] train loss: 0.003876, tar: 0.000031 
l0: 0.000148, l1: 0.000158, l2: 0.000153, l3: 0.000299, l4: 0.000635, l5: 0.001584, l6: 0.002882

[epoch: 780/1000, batch:   652/ 1052, ite: 205040] train loss: 0.003876, tar: 0.000031 
l0: 0.000002, l1: 0.000002, l2: 0.000014, l3: 0.000142, l4: 0.000287, l5: 0.001194, l6: 0.002125

[epoch: 780/1000, batch:   732/ 1052, ite: 205060] train loss: 0.003876, tar: 0.000031 
l0: 0.000041, l1: 0.000044, l2: 0.000134, l3: 0.000272, l4: 0.000708, l5: 0.001690, l6: 0.004000

[epoch: 780/1000, batch:   812/ 1052, ite: 205080] train loss: 0.003875, tar: 0.000031 
l0: 0.000025, l1: 0.000025, l2: 0.000114, l3: 0.000328, l4: 0.000977, l5: 0.001439, l6: 0.002548

[epoch: 780/1000, batch:   892/ 1052, ite: 205100] train loss: 0.003874, tar: 0.000031 
l0: 0.000015, l1: 0.000017, l2: 0.000062, l3: 0.000161, l4: 0.000397, l5: 0.000800, l6: 0.001453

[epoch: 780/1000, batch:   972/ 1052, ite: 205120] train loss: 0.003875, tar: 0.000031 
l0: 0.000023, l1: 0.000022, l2: 0.000048, l3: 0.000179, l4: 0.000217, l5: 0.000826, l6: 0.001624

[epoch: 780/1000, batch:  1052/ 1052, ite: 205140] train loss: 0.003876, tar: 0.000031 
[Epoch 780/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000017, l1: 0.000016, l2: 0.000088, l3: 0.000178, l4: 0.000516, l5: 0.000951, l6: 0.001588

[epoch: 781/1000, batch:    80/ 1052, ite: 205160] train loss: 0.003875, tar: 0.000031 
l0: 0.000018, l1: 0.000019, l2: 0.000037, l3: 0.000108, l4: 0.000297, l5: 0.000374, l6: 0.000937

[epoch: 781/1000, batch:   160/ 1052, ite: 205180] train loss: 0.003875, tar: 0.000031 
l0: 0.000040, l1: 0.000041, l2: 0.000086, l3: 0.000187, l4: 0.000562, l5: 0.001378, l6: 0.002241

[epoch: 781/1000, batch:   240/ 1052, ite: 205200] train loss: 0.003876, tar: 0.000031 
l0: 0.000011, l1: 0.000012, l2: 0.000047, l3: 0.000206, l4: 0.000336, l5: 0.001077, l6: 0.001328

[epoch: 781/1000, batch:   320/ 1052, ite: 205220] train loss: 0.003876, tar: 0.000031 
l0: 0.000015, l1: 0.000015, l2: 0.000107, l3: 0.000326, l4: 0.000960, l5: 0.001635, l6: 0.002800

[epoch: 781/1000, batch:   400/ 1052, ite: 205240] train loss: 0.003877, tar: 0.000031 
l0: 0.000010, l1: 0.000010, l2: 0.000023, l3: 0.000169, l4: 0.000482, l5: 0.000968, l6: 0.001930

[epoch: 781/1000, batch:   480/ 1052, ite: 205260] train loss: 0.003875, tar: 0.000031 
l0: 0.000014, l1: 0.000014, l2: 0.000063, l3: 0.000178, l4: 0.000315, l5: 0.001359, l6: 0.001632

[epoch: 781/1000, batch:   560/ 1052, ite: 205280] train loss: 0.003876, tar: 0.000031 
l0: 0.000013, l1: 0.000014, l2: 0.000048, l3: 0.000231, l4: 0.000502, l5: 0.001297, l6: 0.001874

[epoch: 781/1000, batch:   640/ 1052, ite: 205300] train loss: 0.003875, tar: 0.000031 
l0: 0.000002, l1: 0.000002, l2: 0.000019, l3: 0.000109, l4: 0.000314, l5: 0.000566, l6: 0.001385

[epoch: 781/1000, batch:   720/ 1052, ite: 205320] train loss: 0.003875, tar: 0.000031 
l0: 0.000122, l1: 0.000120, l2: 0.000170, l3: 0.000301, l4: 0.000339, l5: 0.001260, l6: 0.002319

[epoch: 781/1000, batch:   800/ 1052, ite: 205340] train loss: 0.003876, tar: 0.000031 
l0: 0.000008, l1: 0.000010, l2: 0.000036, l3: 0.000119, l4: 0.000379, l5: 0.000627, l6: 0.001484

[epoch: 781/1000, batch:   880/ 1052, ite: 205360] train loss: 0.003875, tar: 0.000031 
l0: 0.000007, l1: 0.000009, l2: 0.000046, l3: 0.000183, l4: 0.000518, l5: 0.000884, l6: 0.002047

[epoch: 781/1000, batch:   960/ 1052, ite: 205380] train loss: 0.003874, tar: 0.000031 
l0: 0.000023, l1: 0.000026, l2: 0.000066, l3: 0.000186, l4: 0.000393, l5: 0.001293, l6: 0.002128

[epoch: 781/1000, batch:  1040/ 1052, ite: 205400] train loss: 0.003875, tar: 0.000031 
[Epoch 781/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000024, l1: 0.000026, l2: 0.000055, l3: 0.000150, l4: 0.000325, l5: 0.001098, l6: 0.001165

[epoch: 782/1000, batch:    68/ 1052, ite: 205420] train loss: 0.003875, tar: 0.000031 
l0: 0.000009, l1: 0.000008, l2: 0.000087, l3: 0.000409, l4: 0.000603, l5: 0.000886, l6: 0.001773

[epoch: 782/1000, batch:   148/ 1052, ite: 205440] train loss: 0.003876, tar: 0.000031 
l0: 0.000024, l1: 0.000025, l2: 0.000068, l3: 0.000346, l4: 0.000636, l5: 0.001385, l6: 0.002167

[epoch: 782/1000, batch:   228/ 1052, ite: 205460] train loss: 0.003877, tar: 0.000031 
l0: 0.000028, l1: 0.000027, l2: 0.000073, l3: 0.000219, l4: 0.000611, l5: 0.001233, l6: 0.002978

[epoch: 782/1000, batch:   308/ 1052, ite: 205480] train loss: 0.003877, tar: 0.000031 
l0: 0.000066, l1: 0.000065, l2: 0.000115, l3: 0.000232, l4: 0.000507, l5: 0.001250, l6: 0.002779

[epoch: 782/1000, batch:   388/ 1052, ite: 205500] train loss: 0.003875, tar: 0.000031 
l0: 0.000077, l1: 0.000077, l2: 0.000166, l3: 0.000376, l4: 0.000786, l5: 0.001377, l6: 0.002130

[epoch: 782/1000, batch:   468/ 1052, ite: 205520] train loss: 0.003875, tar: 0.000031 
l0: 0.000040, l1: 0.000041, l2: 0.000091, l3: 0.000223, l4: 0.000664, l5: 0.001485, l6: 0.002511

[epoch: 782/1000, batch:   548/ 1052, ite: 205540] train loss: 0.003876, tar: 0.000031 
l0: 0.000016, l1: 0.000017, l2: 0.000068, l3: 0.000197, l4: 0.000564, l5: 0.001897, l6: 0.003361

[epoch: 782/1000, batch:   628/ 1052, ite: 205560] train loss: 0.003875, tar: 0.000031 
l0: 0.000045, l1: 0.000046, l2: 0.000130, l3: 0.000317, l4: 0.000603, l5: 0.000798, l6: 0.001886

[epoch: 782/1000, batch:   708/ 1052, ite: 205580] train loss: 0.003875, tar: 0.000031 
l0: 0.000003, l1: 0.000003, l2: 0.000037, l3: 0.000159, l4: 0.000323, l5: 0.000828, l6: 0.001471

[epoch: 782/1000, batch:   788/ 1052, ite: 205600] train loss: 0.003875, tar: 0.000031 
l0: 0.000044, l1: 0.000045, l2: 0.000091, l3: 0.000204, l4: 0.000482, l5: 0.000991, l6: 0.001215

[epoch: 782/1000, batch:   868/ 1052, ite: 205620] train loss: 0.003876, tar: 0.000031 
l0: 0.000020, l1: 0.000020, l2: 0.000137, l3: 0.000423, l4: 0.000896, l5: 0.001478, l6: 0.002525

[epoch: 782/1000, batch:   948/ 1052, ite: 205640] train loss: 0.003876, tar: 0.000031 
l0: 0.000016, l1: 0.000018, l2: 0.000062, l3: 0.000182, l4: 0.000432, l5: 0.000727, l6: 0.001023

[epoch: 782/1000, batch:  1028/ 1052, ite: 205660] train loss: 0.003875, tar: 0.000031 
[Epoch 782/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000062, l1: 0.000071, l2: 0.000091, l3: 0.000217, l4: 0.000464, l5: 0.001102, l6: 0.002788

[epoch: 783/1000, batch:    56/ 1052, ite: 205680] train loss: 0.003876, tar: 0.000031 
l0: 0.000020, l1: 0.000022, l2: 0.000096, l3: 0.000325, l4: 0.000681, l5: 0.000635, l6: 0.002204

[epoch: 783/1000, batch:   136/ 1052, ite: 205700] train loss: 0.003876, tar: 0.000031 
l0: 0.000009, l1: 0.000009, l2: 0.000084, l3: 0.000277, l4: 0.000686, l5: 0.001353, l6: 0.002143

[epoch: 783/1000, batch:   216/ 1052, ite: 205720] train loss: 0.003875, tar: 0.000031 
l0: 0.000029, l1: 0.000031, l2: 0.000041, l3: 0.000134, l4: 0.000423, l5: 0.001063, l6: 0.001650

[epoch: 783/1000, batch:   296/ 1052, ite: 205740] train loss: 0.003874, tar: 0.000031 
l0: 0.000059, l1: 0.000061, l2: 0.000079, l3: 0.000128, l4: 0.000331, l5: 0.000978, l6: 0.002129

[epoch: 783/1000, batch:   376/ 1052, ite: 205760] train loss: 0.003872, tar: 0.000030 
l0: 0.000009, l1: 0.000009, l2: 0.000048, l3: 0.000270, l4: 0.000900, l5: 0.001418, l6: 0.002735

[epoch: 783/1000, batch:   456/ 1052, ite: 205780] train loss: 0.003873, tar: 0.000030 
l0: 0.000049, l1: 0.000051, l2: 0.000103, l3: 0.000157, l4: 0.000776, l5: 0.001173, l6: 0.001914

[epoch: 783/1000, batch:   536/ 1052, ite: 205800] train loss: 0.003872, tar: 0.000030 
l0: 0.000003, l1: 0.000003, l2: 0.000006, l3: 0.000072, l4: 0.000283, l5: 0.000638, l6: 0.001635

[epoch: 783/1000, batch:   616/ 1052, ite: 205820] train loss: 0.003872, tar: 0.000030 
l0: 0.000035, l1: 0.000035, l2: 0.000087, l3: 0.000230, l4: 0.000736, l5: 0.002408, l6: 0.003730

[epoch: 783/1000, batch:   696/ 1052, ite: 205840] train loss: 0.003873, tar: 0.000030 
l0: 0.000031, l1: 0.000032, l2: 0.000042, l3: 0.000098, l4: 0.000477, l5: 0.001324, l6: 0.001668

[epoch: 783/1000, batch:   776/ 1052, ite: 205860] train loss: 0.003872, tar: 0.000030 
l0: 0.000042, l1: 0.000047, l2: 0.000060, l3: 0.000187, l4: 0.000328, l5: 0.001127, l6: 0.001610

[epoch: 783/1000, batch:   856/ 1052, ite: 205880] train loss: 0.003871, tar: 0.000030 
l0: 0.000031, l1: 0.000033, l2: 0.000042, l3: 0.000084, l4: 0.000176, l5: 0.000499, l6: 0.001103

[epoch: 783/1000, batch:   936/ 1052, ite: 205900] train loss: 0.003873, tar: 0.000030 
l0: 0.000034, l1: 0.000033, l2: 0.000041, l3: 0.000070, l4: 0.000350, l5: 0.000882, l6: 0.001030

[epoch: 783/1000, batch:  1016/ 1052, ite: 205920] train loss: 0.003871, tar: 0.000030 
[Epoch 783/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000006, l1: 0.000006, l2: 0.000055, l3: 0.000131, l4: 0.000453, l5: 0.001872, l6: 0.002189

[epoch: 784/1000, batch:    44/ 1052, ite: 205940] train loss: 0.003873, tar: 0.000031 
l0: 0.000030, l1: 0.000029, l2: 0.000055, l3: 0.000133, l4: 0.000398, l5: 0.001075, l6: 0.001999

[epoch: 784/1000, batch:   124/ 1052, ite: 205960] train loss: 0.003874, tar: 0.000031 
l0: 0.000116, l1: 0.000123, l2: 0.000193, l3: 0.000348, l4: 0.000818, l5: 0.001896, l6: 0.003146

[epoch: 784/1000, batch:   204/ 1052, ite: 205980] train loss: 0.003873, tar: 0.000031 
l0: 0.000020, l1: 0.000021, l2: 0.000064, l3: 0.000196, l4: 0.000553, l5: 0.000694, l6: 0.002001

[epoch: 784/1000, batch:   284/ 1052, ite: 206000] train loss: 0.003873, tar: 0.000031 
l0: 0.000048, l1: 0.000048, l2: 0.000103, l3: 0.000215, l4: 0.000777, l5: 0.001519, l6: 0.003483

[epoch: 784/1000, batch:   364/ 1052, ite: 206020] train loss: 0.003872, tar: 0.000031 
l0: 0.000020, l1: 0.000018, l2: 0.000043, l3: 0.000182, l4: 0.000577, l5: 0.000680, l6: 0.002027

[epoch: 784/1000, batch:   444/ 1052, ite: 206040] train loss: 0.003871, tar: 0.000031 
l0: 0.000041, l1: 0.000046, l2: 0.000088, l3: 0.000240, l4: 0.000558, l5: 0.001321, l6: 0.001748

[epoch: 784/1000, batch:   524/ 1052, ite: 206060] train loss: 0.003869, tar: 0.000031 
l0: 0.000028, l1: 0.000026, l2: 0.000096, l3: 0.000352, l4: 0.000740, l5: 0.001603, l6: 0.002821

[epoch: 784/1000, batch:   604/ 1052, ite: 206080] train loss: 0.003870, tar: 0.000031 
l0: 0.000026, l1: 0.000027, l2: 0.000108, l3: 0.000252, l4: 0.000573, l5: 0.001338, l6: 0.004217

[epoch: 784/1000, batch:   684/ 1052, ite: 206100] train loss: 0.003869, tar: 0.000030 
l0: 0.000016, l1: 0.000013, l2: 0.000052, l3: 0.000240, l4: 0.000584, l5: 0.001004, l6: 0.002060

[epoch: 784/1000, batch:   764/ 1052, ite: 206120] train loss: 0.003871, tar: 0.000030 
l0: 0.000040, l1: 0.000043, l2: 0.000052, l3: 0.000125, l4: 0.000442, l5: 0.000828, l6: 0.001912

[epoch: 784/1000, batch:   844/ 1052, ite: 206140] train loss: 0.003871, tar: 0.000031 
l0: 0.000019, l1: 0.000019, l2: 0.000098, l3: 0.000279, l4: 0.000673, l5: 0.001572, l6: 0.002727

[epoch: 784/1000, batch:   924/ 1052, ite: 206160] train loss: 0.003872, tar: 0.000030 
l0: 0.000005, l1: 0.000005, l2: 0.000032, l3: 0.000127, l4: 0.000405, l5: 0.001244, l6: 0.001964

[epoch: 784/1000, batch:  1004/ 1052, ite: 206180] train loss: 0.003871, tar: 0.000031 
[Epoch 784/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000028, l1: 0.000027, l2: 0.000093, l3: 0.000359, l4: 0.000496, l5: 0.000850, l6: 0.001937

[epoch: 785/1000, batch:    32/ 1052, ite: 206200] train loss: 0.003873, tar: 0.000031 
l0: 0.000021, l1: 0.000021, l2: 0.000053, l3: 0.000182, l4: 0.000453, l5: 0.001276, l6: 0.001561

[epoch: 785/1000, batch:   112/ 1052, ite: 206220] train loss: 0.003874, tar: 0.000031 
l0: 0.000047, l1: 0.000047, l2: 0.000087, l3: 0.000189, l4: 0.000723, l5: 0.001451, l6: 0.003079

[epoch: 785/1000, batch:   192/ 1052, ite: 206240] train loss: 0.003874, tar: 0.000031 
l0: 0.000012, l1: 0.000011, l2: 0.000019, l3: 0.000114, l4: 0.000322, l5: 0.000357, l6: 0.001009

[epoch: 785/1000, batch:   272/ 1052, ite: 206260] train loss: 0.003873, tar: 0.000031 
l0: 0.000015, l1: 0.000014, l2: 0.000026, l3: 0.000085, l4: 0.000285, l5: 0.000798, l6: 0.001484

[epoch: 785/1000, batch:   352/ 1052, ite: 206280] train loss: 0.003874, tar: 0.000031 
l0: 0.000022, l1: 0.000025, l2: 0.000054, l3: 0.000111, l4: 0.000315, l5: 0.000920, l6: 0.001655

[epoch: 785/1000, batch:   432/ 1052, ite: 206300] train loss: 0.003871, tar: 0.000031 
l0: 0.000008, l1: 0.000008, l2: 0.000033, l3: 0.000068, l4: 0.000408, l5: 0.000849, l6: 0.000869

[epoch: 785/1000, batch:   512/ 1052, ite: 206320] train loss: 0.003870, tar: 0.000031 
l0: 0.000017, l1: 0.000019, l2: 0.000070, l3: 0.000090, l4: 0.000226, l5: 0.000581, l6: 0.002068

[epoch: 785/1000, batch:   592/ 1052, ite: 206340] train loss: 0.003871, tar: 0.000031 
l0: 0.000071, l1: 0.000079, l2: 0.000124, l3: 0.000281, l4: 0.000680, l5: 0.001257, l6: 0.001504

[epoch: 785/1000, batch:   672/ 1052, ite: 206360] train loss: 0.003870, tar: 0.000031 
l0: 0.000047, l1: 0.000048, l2: 0.000107, l3: 0.000275, l4: 0.000655, l5: 0.001674, l6: 0.003968

[epoch: 785/1000, batch:   752/ 1052, ite: 206380] train loss: 0.003871, tar: 0.000031 
l0: 0.000033, l1: 0.000034, l2: 0.000043, l3: 0.000153, l4: 0.000385, l5: 0.000996, l6: 0.002430

[epoch: 785/1000, batch:   832/ 1052, ite: 206400] train loss: 0.003871, tar: 0.000031 
l0: 0.000046, l1: 0.000050, l2: 0.000119, l3: 0.000284, l4: 0.000365, l5: 0.001353, l6: 0.002456

[epoch: 785/1000, batch:   912/ 1052, ite: 206420] train loss: 0.003872, tar: 0.000031 
l0: 0.000037, l1: 0.000038, l2: 0.000064, l3: 0.000206, l4: 0.000600, l5: 0.000863, l6: 0.001429

[epoch: 785/1000, batch:   992/ 1052, ite: 206440] train loss: 0.003872, tar: 0.000031 
[Epoch 785/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000075, l1: 0.000071, l2: 0.000082, l3: 0.000119, l4: 0.000304, l5: 0.000896, l6: 0.001284

[epoch: 786/1000, batch:    20/ 1052, ite: 206460] train loss: 0.003872, tar: 0.000031 
l0: 0.000031, l1: 0.000032, l2: 0.000050, l3: 0.000120, l4: 0.000285, l5: 0.001135, l6: 0.001821

[epoch: 786/1000, batch:   100/ 1052, ite: 206480] train loss: 0.003872, tar: 0.000031 
l0: 0.000171, l1: 0.000170, l2: 0.000236, l3: 0.000404, l4: 0.000520, l5: 0.000676, l6: 0.001798

[epoch: 786/1000, batch:   180/ 1052, ite: 206500] train loss: 0.003871, tar: 0.000031 
l0: 0.000041, l1: 0.000045, l2: 0.000077, l3: 0.000133, l4: 0.000387, l5: 0.001171, l6: 0.002492

[epoch: 786/1000, batch:   260/ 1052, ite: 206520] train loss: 0.003871, tar: 0.000031 
l0: 0.000026, l1: 0.000028, l2: 0.000085, l3: 0.000185, l4: 0.000329, l5: 0.000744, l6: 0.002058

[epoch: 786/1000, batch:   340/ 1052, ite: 206540] train loss: 0.003871, tar: 0.000031 
l0: 0.000178, l1: 0.000179, l2: 0.000193, l3: 0.000268, l4: 0.000661, l5: 0.001110, l6: 0.001973

[epoch: 786/1000, batch:   420/ 1052, ite: 206560] train loss: 0.003874, tar: 0.000031 
l0: 0.000016, l1: 0.000016, l2: 0.000081, l3: 0.000312, l4: 0.000976, l5: 0.001741, l6: 0.002589

[epoch: 786/1000, batch:   500/ 1052, ite: 206580] train loss: 0.003875, tar: 0.000031 
l0: 0.000011, l1: 0.000010, l2: 0.000036, l3: 0.000129, l4: 0.000311, l5: 0.001016, l6: 0.001740

[epoch: 786/1000, batch:   580/ 1052, ite: 206600] train loss: 0.003873, tar: 0.000031 
l0: 0.000013, l1: 0.000014, l2: 0.000068, l3: 0.000209, l4: 0.000471, l5: 0.001140, l6: 0.002950

[epoch: 786/1000, batch:   660/ 1052, ite: 206620] train loss: 0.003875, tar: 0.000031 
l0: 0.000049, l1: 0.000046, l2: 0.000090, l3: 0.000292, l4: 0.000823, l5: 0.000980, l6: 0.002613

[epoch: 786/1000, batch:   740/ 1052, ite: 206640] train loss: 0.003874, tar: 0.000031 
l0: 0.000027, l1: 0.000028, l2: 0.000058, l3: 0.000274, l4: 0.000621, l5: 0.001160, l6: 0.002491

[epoch: 786/1000, batch:   820/ 1052, ite: 206660] train loss: 0.003872, tar: 0.000031 
l0: 0.000105, l1: 0.000113, l2: 0.000123, l3: 0.000201, l4: 0.000530, l5: 0.000988, l6: 0.002214

[epoch: 786/1000, batch:   900/ 1052, ite: 206680] train loss: 0.003871, tar: 0.000031 
l0: 0.000110, l1: 0.000069, l2: 0.000093, l3: 0.000169, l4: 0.000387, l5: 0.001045, l6: 0.001869

[epoch: 786/1000, batch:   980/ 1052, ite: 206700] train loss: 0.003872, tar: 0.000031 
[Epoch 786/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000031, l1: 0.000032, l2: 0.000076, l3: 0.000267, l4: 0.000773, l5: 0.001041, l6: 0.002791

[epoch: 787/1000, batch:     8/ 1052, ite: 206720] train loss: 0.003872, tar: 0.000031 
l0: 0.000037, l1: 0.000036, l2: 0.000045, l3: 0.000142, l4: 0.000430, l5: 0.000961, l6: 0.001857

[epoch: 787/1000, batch:    88/ 1052, ite: 206740] train loss: 0.003872, tar: 0.000031 
l0: 0.000004, l1: 0.000005, l2: 0.000031, l3: 0.000178, l4: 0.000392, l5: 0.001026, l6: 0.001840

[epoch: 787/1000, batch:   168/ 1052, ite: 206760] train loss: 0.003872, tar: 0.000031 
l0: 0.000021, l1: 0.000025, l2: 0.000113, l3: 0.000309, l4: 0.000622, l5: 0.001814, l6: 0.003291

[epoch: 787/1000, batch:   248/ 1052, ite: 206780] train loss: 0.003873, tar: 0.000030 
l0: 0.000038, l1: 0.000041, l2: 0.000088, l3: 0.000230, l4: 0.000551, l5: 0.000902, l6: 0.002896

[epoch: 787/1000, batch:   328/ 1052, ite: 206800] train loss: 0.003873, tar: 0.000031 
l0: 0.000014, l1: 0.000014, l2: 0.000028, l3: 0.000171, l4: 0.000409, l5: 0.001186, l6: 0.002242

[epoch: 787/1000, batch:   408/ 1052, ite: 206820] train loss: 0.003872, tar: 0.000030 
l0: 0.000030, l1: 0.000032, l2: 0.000116, l3: 0.000272, l4: 0.000353, l5: 0.001223, l6: 0.002366

[epoch: 787/1000, batch:   488/ 1052, ite: 206840] train loss: 0.003872, tar: 0.000031 
l0: 0.000020, l1: 0.000021, l2: 0.000098, l3: 0.000254, l4: 0.000501, l5: 0.001151, l6: 0.002645

[epoch: 787/1000, batch:   568/ 1052, ite: 206860] train loss: 0.003872, tar: 0.000030 
l0: 0.000016, l1: 0.000016, l2: 0.000075, l3: 0.000207, l4: 0.000579, l5: 0.000890, l6: 0.001454

[epoch: 787/1000, batch:   648/ 1052, ite: 206880] train loss: 0.003871, tar: 0.000030 
l0: 0.000005, l1: 0.000005, l2: 0.000022, l3: 0.000140, l4: 0.000469, l5: 0.000953, l6: 0.001669

[epoch: 787/1000, batch:   728/ 1052, ite: 206900] train loss: 0.003871, tar: 0.000030 
l0: 0.000010, l1: 0.000008, l2: 0.000041, l3: 0.000120, l4: 0.000316, l5: 0.000928, l6: 0.001159

[epoch: 787/1000, batch:   808/ 1052, ite: 206920] train loss: 0.003871, tar: 0.000030 
l0: 0.000009, l1: 0.000010, l2: 0.000027, l3: 0.000188, l4: 0.000378, l5: 0.000884, l6: 0.001759

[epoch: 787/1000, batch:   888/ 1052, ite: 206940] train loss: 0.003871, tar: 0.000030 
l0: 0.000012, l1: 0.000012, l2: 0.000016, l3: 0.000102, l4: 0.000211, l5: 0.000814, l6: 0.001129

[epoch: 787/1000, batch:   968/ 1052, ite: 206960] train loss: 0.003872, tar: 0.000031 
l0: 0.000014, l1: 0.000014, l2: 0.000060, l3: 0.000212, l4: 0.000361, l5: 0.001199, l6: 0.002819

[epoch: 787/1000, batch:  1048/ 1052, ite: 206980] train loss: 0.003871, tar: 0.000031 
[Epoch 787/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000010, l1: 0.000008, l2: 0.000049, l3: 0.000285, l4: 0.000598, l5: 0.001740, l6: 0.002756

[epoch: 788/1000, batch:    76/ 1052, ite: 207000] train loss: 0.003873, tar: 0.000030 
l0: 0.000019, l1: 0.000021, l2: 0.000075, l3: 0.000196, l4: 0.000308, l5: 0.000743, l6: 0.000758

[epoch: 788/1000, batch:   156/ 1052, ite: 207020] train loss: 0.003873, tar: 0.000030 
l0: 0.000069, l1: 0.000066, l2: 0.000080, l3: 0.000126, l4: 0.000399, l5: 0.001033, l6: 0.001579

[epoch: 788/1000, batch:   236/ 1052, ite: 207040] train loss: 0.003874, tar: 0.000031 
l0: 0.000008, l1: 0.000009, l2: 0.000031, l3: 0.000129, l4: 0.000305, l5: 0.000989, l6: 0.001610

[epoch: 788/1000, batch:   316/ 1052, ite: 207060] train loss: 0.003874, tar: 0.000031 
l0: 0.000015, l1: 0.000015, l2: 0.000054, l3: 0.000124, l4: 0.000404, l5: 0.000848, l6: 0.001541

[epoch: 788/1000, batch:   396/ 1052, ite: 207080] train loss: 0.003874, tar: 0.000030 
l0: 0.000094, l1: 0.000096, l2: 0.000164, l3: 0.000233, l4: 0.000521, l5: 0.001634, l6: 0.003195

[epoch: 788/1000, batch:   476/ 1052, ite: 207100] train loss: 0.003873, tar: 0.000030 
l0: 0.000004, l1: 0.000005, l2: 0.000037, l3: 0.000120, l4: 0.000265, l5: 0.000924, l6: 0.001856

[epoch: 788/1000, batch:   556/ 1052, ite: 207120] train loss: 0.003873, tar: 0.000030 
l0: 0.000042, l1: 0.000043, l2: 0.000079, l3: 0.000217, l4: 0.000610, l5: 0.001200, l6: 0.003155

[epoch: 788/1000, batch:   636/ 1052, ite: 207140] train loss: 0.003873, tar: 0.000031 
l0: 0.000027, l1: 0.000028, l2: 0.000078, l3: 0.000229, l4: 0.000521, l5: 0.001176, l6: 0.003611

[epoch: 788/1000, batch:   716/ 1052, ite: 207160] train loss: 0.003874, tar: 0.000031 
l0: 0.000003, l1: 0.000003, l2: 0.000023, l3: 0.000100, l4: 0.000620, l5: 0.001951, l6: 0.002537

[epoch: 788/1000, batch:   796/ 1052, ite: 207180] train loss: 0.003873, tar: 0.000031 
l0: 0.000020, l1: 0.000021, l2: 0.000023, l3: 0.000088, l4: 0.000325, l5: 0.000901, l6: 0.001593

[epoch: 788/1000, batch:   876/ 1052, ite: 207200] train loss: 0.003875, tar: 0.000031 
l0: 0.000023, l1: 0.000023, l2: 0.000034, l3: 0.000112, l4: 0.000240, l5: 0.000715, l6: 0.001300

[epoch: 788/1000, batch:   956/ 1052, ite: 207220] train loss: 0.003875, tar: 0.000031 
l0: 0.000714, l1: 0.001257, l2: 0.002033, l3: 0.000504, l4: 0.000567, l5: 0.000974, l6: 0.000828

[epoch: 788/1000, batch:  1036/ 1052, ite: 207240] train loss: 0.003876, tar: 0.000031 
[Epoch 788/1000] Test loss: 0.020, Test target loss: 0.003
l0: 0.000047, l1: 0.000050, l2: 0.000091, l3: 0.000214, l4: 0.000504, l5: 0.001370, l6: 0.002198

[epoch: 789/1000, batch:    64/ 1052, ite: 207260] train loss: 0.003877, tar: 0.000031 
l0: 0.000025, l1: 0.000027, l2: 0.000071, l3: 0.000191, l4: 0.000437, l5: 0.001060, l6: 0.001631

[epoch: 789/1000, batch:   144/ 1052, ite: 207280] train loss: 0.003878, tar: 0.000031 
l0: 0.000069, l1: 0.000076, l2: 0.000124, l3: 0.000263, l4: 0.000883, l5: 0.001397, l6: 0.001667

[epoch: 789/1000, batch:   224/ 1052, ite: 207300] train loss: 0.003879, tar: 0.000032 
l0: 0.000042, l1: 0.000039, l2: 0.000100, l3: 0.000228, l4: 0.000575, l5: 0.000932, l6: 0.001934

[epoch: 789/1000, batch:   304/ 1052, ite: 207320] train loss: 0.003880, tar: 0.000032 
l0: 0.000030, l1: 0.000031, l2: 0.000032, l3: 0.000116, l4: 0.000328, l5: 0.001152, l6: 0.001957

[epoch: 789/1000, batch:   384/ 1052, ite: 207340] train loss: 0.003879, tar: 0.000032 
l0: 0.000066, l1: 0.000065, l2: 0.000119, l3: 0.000232, l4: 0.000667, l5: 0.001921, l6: 0.002336

[epoch: 789/1000, batch:   464/ 1052, ite: 207360] train loss: 0.003880, tar: 0.000032 
l0: 0.000023, l1: 0.000023, l2: 0.000067, l3: 0.000151, l4: 0.000337, l5: 0.001216, l6: 0.002457

[epoch: 789/1000, batch:   544/ 1052, ite: 207380] train loss: 0.003881, tar: 0.000032 
l0: 0.000014, l1: 0.000016, l2: 0.000043, l3: 0.000179, l4: 0.000312, l5: 0.000745, l6: 0.001632

[epoch: 789/1000, batch:   624/ 1052, ite: 207400] train loss: 0.003882, tar: 0.000032 
l0: 0.000011, l1: 0.000010, l2: 0.000027, l3: 0.000112, l4: 0.000338, l5: 0.001120, l6: 0.001376

[epoch: 789/1000, batch:   704/ 1052, ite: 207420] train loss: 0.003882, tar: 0.000032 
l0: 0.000021, l1: 0.000017, l2: 0.000043, l3: 0.000121, l4: 0.000374, l5: 0.000609, l6: 0.001294

[epoch: 789/1000, batch:   784/ 1052, ite: 207440] train loss: 0.003880, tar: 0.000032 
l0: 0.000011, l1: 0.000011, l2: 0.000047, l3: 0.000113, l4: 0.000184, l5: 0.000565, l6: 0.001216

[epoch: 789/1000, batch:   864/ 1052, ite: 207460] train loss: 0.003878, tar: 0.000032 
l0: 0.000008, l1: 0.000008, l2: 0.000043, l3: 0.000185, l4: 0.000528, l5: 0.001155, l6: 0.002213

[epoch: 789/1000, batch:   944/ 1052, ite: 207480] train loss: 0.003878, tar: 0.000032 
l0: 0.000011, l1: 0.000013, l2: 0.000025, l3: 0.000058, l4: 0.000288, l5: 0.000482, l6: 0.001212

[epoch: 789/1000, batch:  1024/ 1052, ite: 207500] train loss: 0.003877, tar: 0.000032 
[Epoch 789/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000037, l1: 0.000040, l2: 0.000069, l3: 0.000235, l4: 0.000453, l5: 0.001190, l6: 0.002488

[epoch: 790/1000, batch:    52/ 1052, ite: 207520] train loss: 0.003879, tar: 0.000032 
l0: 0.000030, l1: 0.000032, l2: 0.000077, l3: 0.000243, l4: 0.000817, l5: 0.001534, l6: 0.001886

[epoch: 790/1000, batch:   132/ 1052, ite: 207540] train loss: 0.003878, tar: 0.000032 
l0: 0.000056, l1: 0.000058, l2: 0.000104, l3: 0.000408, l4: 0.000769, l5: 0.001335, l6: 0.003009

[epoch: 790/1000, batch:   212/ 1052, ite: 207560] train loss: 0.003880, tar: 0.000032 
l0: 0.000030, l1: 0.000030, l2: 0.000066, l3: 0.000111, l4: 0.000368, l5: 0.000770, l6: 0.001632

[epoch: 790/1000, batch:   292/ 1052, ite: 207580] train loss: 0.003880, tar: 0.000032 
l0: 0.000006, l1: 0.000005, l2: 0.000031, l3: 0.000147, l4: 0.000423, l5: 0.001121, l6: 0.001992

[epoch: 790/1000, batch:   372/ 1052, ite: 207600] train loss: 0.003880, tar: 0.000032 
l0: 0.000021, l1: 0.000023, l2: 0.000045, l3: 0.000101, l4: 0.000422, l5: 0.001194, l6: 0.002114

[epoch: 790/1000, batch:   452/ 1052, ite: 207620] train loss: 0.003880, tar: 0.000032 
l0: 0.000025, l1: 0.000025, l2: 0.000044, l3: 0.000127, l4: 0.000358, l5: 0.000993, l6: 0.001435

[epoch: 790/1000, batch:   532/ 1052, ite: 207640] train loss: 0.003882, tar: 0.000032 
l0: 0.000011, l1: 0.000011, l2: 0.000020, l3: 0.000086, l4: 0.000319, l5: 0.001102, l6: 0.001957

[epoch: 790/1000, batch:   612/ 1052, ite: 207660] train loss: 0.003882, tar: 0.000032 
l0: 0.000040, l1: 0.000041, l2: 0.000048, l3: 0.000147, l4: 0.000411, l5: 0.000682, l6: 0.001612

[epoch: 790/1000, batch:   692/ 1052, ite: 207680] train loss: 0.003880, tar: 0.000032 
l0: 0.000048, l1: 0.000045, l2: 0.000092, l3: 0.000150, l4: 0.000328, l5: 0.000790, l6: 0.000859

[epoch: 790/1000, batch:   772/ 1052, ite: 207700] train loss: 0.003879, tar: 0.000032 
l0: 0.000013, l1: 0.000014, l2: 0.000038, l3: 0.000135, l4: 0.000301, l5: 0.000561, l6: 0.001531

[epoch: 790/1000, batch:   852/ 1052, ite: 207720] train loss: 0.003879, tar: 0.000032 
l0: 0.000013, l1: 0.000015, l2: 0.000025, l3: 0.000121, l4: 0.000392, l5: 0.000873, l6: 0.001084

[epoch: 790/1000, batch:   932/ 1052, ite: 207740] train loss: 0.003879, tar: 0.000032 
l0: 0.000039, l1: 0.000039, l2: 0.000039, l3: 0.000124, l4: 0.000324, l5: 0.000991, l6: 0.001402

[epoch: 790/1000, batch:  1012/ 1052, ite: 207760] train loss: 0.003878, tar: 0.000032 
[Epoch 790/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000030, l1: 0.000030, l2: 0.000068, l3: 0.000145, l4: 0.000280, l5: 0.000699, l6: 0.002005

[epoch: 791/1000, batch:    40/ 1052, ite: 207780] train loss: 0.003878, tar: 0.000032 
l0: 0.000021, l1: 0.000020, l2: 0.000055, l3: 0.000140, l4: 0.000544, l5: 0.000851, l6: 0.001939

[epoch: 791/1000, batch:   120/ 1052, ite: 207800] train loss: 0.003879, tar: 0.000032 
l0: 0.000013, l1: 0.000013, l2: 0.000117, l3: 0.000259, l4: 0.000649, l5: 0.001429, l6: 0.002010

[epoch: 791/1000, batch:   200/ 1052, ite: 207820] train loss: 0.003878, tar: 0.000032 
l0: 0.000015, l1: 0.000014, l2: 0.000048, l3: 0.000110, l4: 0.000269, l5: 0.000681, l6: 0.000752

[epoch: 791/1000, batch:   280/ 1052, ite: 207840] train loss: 0.003879, tar: 0.000032 
l0: 0.000118, l1: 0.000114, l2: 0.000124, l3: 0.000152, l4: 0.000232, l5: 0.000792, l6: 0.001246

[epoch: 791/1000, batch:   360/ 1052, ite: 207860] train loss: 0.003877, tar: 0.000032 
l0: 0.000057, l1: 0.000058, l2: 0.000123, l3: 0.000430, l4: 0.000691, l5: 0.001334, l6: 0.003020

[epoch: 791/1000, batch:   440/ 1052, ite: 207880] train loss: 0.003878, tar: 0.000032 
l0: 0.000006, l1: 0.000008, l2: 0.000011, l3: 0.000056, l4: 0.000182, l5: 0.000481, l6: 0.000790

[epoch: 791/1000, batch:   520/ 1052, ite: 207900] train loss: 0.003878, tar: 0.000032 
l0: 0.000045, l1: 0.000049, l2: 0.000075, l3: 0.000143, l4: 0.000419, l5: 0.000750, l6: 0.002057

[epoch: 791/1000, batch:   600/ 1052, ite: 207920] train loss: 0.003877, tar: 0.000032 
l0: 0.000035, l1: 0.000037, l2: 0.000050, l3: 0.000301, l4: 0.000790, l5: 0.001544, l6: 0.002875

[epoch: 791/1000, batch:   680/ 1052, ite: 207940] train loss: 0.003879, tar: 0.000032 
l0: 0.000053, l1: 0.000053, l2: 0.000145, l3: 0.000290, l4: 0.000768, l5: 0.001755, l6: 0.002465

[epoch: 791/1000, batch:   760/ 1052, ite: 207960] train loss: 0.003879, tar: 0.000032 
l0: 0.000134, l1: 0.000133, l2: 0.000117, l3: 0.000317, l4: 0.000658, l5: 0.000998, l6: 0.001725

[epoch: 791/1000, batch:   840/ 1052, ite: 207980] train loss: 0.003879, tar: 0.000032 
l0: 0.000036, l1: 0.000035, l2: 0.000072, l3: 0.000150, l4: 0.000306, l5: 0.000767, l6: 0.001681

[epoch: 791/1000, batch:   920/ 1052, ite: 208000] train loss: 0.003880, tar: 0.000032 
l0: 0.000153, l1: 0.000153, l2: 0.000219, l3: 0.000326, l4: 0.000287, l5: 0.000620, l6: 0.001363

[epoch: 791/1000, batch:  1000/ 1052, ite: 208020] train loss: 0.003880, tar: 0.000032 
[Epoch 791/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000026, l1: 0.000025, l2: 0.000061, l3: 0.000143, l4: 0.000369, l5: 0.000903, l6: 0.001307

[epoch: 792/1000, batch:    28/ 1052, ite: 208040] train loss: 0.003880, tar: 0.000032 
l0: 0.000050, l1: 0.000061, l2: 0.000086, l3: 0.000115, l4: 0.000308, l5: 0.000746, l6: 0.001536

[epoch: 792/1000, batch:   108/ 1052, ite: 208060] train loss: 0.003880, tar: 0.000032 
l0: 0.000043, l1: 0.000044, l2: 0.000086, l3: 0.000189, l4: 0.000645, l5: 0.001442, l6: 0.002290

[epoch: 792/1000, batch:   188/ 1052, ite: 208080] train loss: 0.003881, tar: 0.000032 
l0: 0.000016, l1: 0.000017, l2: 0.000053, l3: 0.000129, l4: 0.000407, l5: 0.000769, l6: 0.001556

[epoch: 792/1000, batch:   268/ 1052, ite: 208100] train loss: 0.003880, tar: 0.000032 
l0: 0.000042, l1: 0.000046, l2: 0.000109, l3: 0.000280, l4: 0.000697, l5: 0.001299, l6: 0.003348

[epoch: 792/1000, batch:   348/ 1052, ite: 208120] train loss: 0.003880, tar: 0.000032 
l0: 0.000100, l1: 0.000106, l2: 0.000123, l3: 0.000246, l4: 0.000302, l5: 0.000701, l6: 0.001602

[epoch: 792/1000, batch:   428/ 1052, ite: 208140] train loss: 0.003880, tar: 0.000032 
l0: 0.000042, l1: 0.000047, l2: 0.000055, l3: 0.000138, l4: 0.000302, l5: 0.000905, l6: 0.001292

[epoch: 792/1000, batch:   508/ 1052, ite: 208160] train loss: 0.003880, tar: 0.000032 
l0: 0.000064, l1: 0.000063, l2: 0.000095, l3: 0.000184, l4: 0.000446, l5: 0.001323, l6: 0.003043

[epoch: 792/1000, batch:   588/ 1052, ite: 208180] train loss: 0.003880, tar: 0.000032 
l0: 0.000094, l1: 0.000090, l2: 0.000137, l3: 0.000216, l4: 0.000364, l5: 0.000722, l6: 0.001206

[epoch: 792/1000, batch:   668/ 1052, ite: 208200] train loss: 0.003880, tar: 0.000032 
l0: 0.000043, l1: 0.000041, l2: 0.000080, l3: 0.000215, l4: 0.000375, l5: 0.001126, l6: 0.001555

[epoch: 792/1000, batch:   748/ 1052, ite: 208220] train loss: 0.003880, tar: 0.000032 
l0: 0.000006, l1: 0.000005, l2: 0.000032, l3: 0.000092, l4: 0.000155, l5: 0.000585, l6: 0.001109

[epoch: 792/1000, batch:   828/ 1052, ite: 208240] train loss: 0.003881, tar: 0.000032 
l0: 0.000055, l1: 0.000059, l2: 0.000118, l3: 0.000231, l4: 0.000589, l5: 0.001394, l6: 0.001952

[epoch: 792/1000, batch:   908/ 1052, ite: 208260] train loss: 0.003881, tar: 0.000032 
l0: 0.000005, l1: 0.000005, l2: 0.000025, l3: 0.000106, l4: 0.000387, l5: 0.001014, l6: 0.001168

[epoch: 792/1000, batch:   988/ 1052, ite: 208280] train loss: 0.003881, tar: 0.000032 
[Epoch 792/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000197, l1: 0.000210, l2: 0.000256, l3: 0.000437, l4: 0.000935, l5: 0.001467, l6: 0.002693

[epoch: 793/1000, batch:    16/ 1052, ite: 208300] train loss: 0.003883, tar: 0.000032 
l0: 0.000015, l1: 0.000017, l2: 0.000032, l3: 0.000086, l4: 0.000359, l5: 0.001114, l6: 0.001538

[epoch: 793/1000, batch:    96/ 1052, ite: 208320] train loss: 0.003882, tar: 0.000032 
l0: 0.000076, l1: 0.000078, l2: 0.000092, l3: 0.000142, l4: 0.000478, l5: 0.001371, l6: 0.002546

[epoch: 793/1000, batch:   176/ 1052, ite: 208340] train loss: 0.003882, tar: 0.000032 
l0: 0.000023, l1: 0.000023, l2: 0.000084, l3: 0.000245, l4: 0.000522, l5: 0.001076, l6: 0.001517

[epoch: 793/1000, batch:   256/ 1052, ite: 208360] train loss: 0.003881, tar: 0.000032 
l0: 0.000009, l1: 0.000009, l2: 0.000032, l3: 0.000117, l4: 0.000289, l5: 0.000546, l6: 0.001333

[epoch: 793/1000, batch:   336/ 1052, ite: 208380] train loss: 0.003882, tar: 0.000032 
l0: 0.000068, l1: 0.000068, l2: 0.000194, l3: 0.000415, l4: 0.000798, l5: 0.002224, l6: 0.004434

[epoch: 793/1000, batch:   416/ 1052, ite: 208400] train loss: 0.003883, tar: 0.000032 
l0: 0.000025, l1: 0.000023, l2: 0.000112, l3: 0.000283, l4: 0.000593, l5: 0.001488, l6: 0.004115

[epoch: 793/1000, batch:   496/ 1052, ite: 208420] train loss: 0.003884, tar: 0.000032 
l0: 0.000026, l1: 0.000027, l2: 0.000070, l3: 0.000195, l4: 0.000484, l5: 0.001485, l6: 0.002426

[epoch: 793/1000, batch:   576/ 1052, ite: 208440] train loss: 0.003884, tar: 0.000032 
l0: 0.000013, l1: 0.000012, l2: 0.000018, l3: 0.000054, l4: 0.000317, l5: 0.000690, l6: 0.001493

[epoch: 793/1000, batch:   656/ 1052, ite: 208460] train loss: 0.003884, tar: 0.000032 
l0: 0.000033, l1: 0.000033, l2: 0.000113, l3: 0.000339, l4: 0.000718, l5: 0.001248, l6: 0.002765

[epoch: 793/1000, batch:   736/ 1052, ite: 208480] train loss: 0.003885, tar: 0.000032 
l0: 0.000008, l1: 0.000010, l2: 0.000032, l3: 0.000122, l4: 0.000366, l5: 0.000938, l6: 0.001628

[epoch: 793/1000, batch:   816/ 1052, ite: 208500] train loss: 0.003884, tar: 0.000032 
l0: 0.000012, l1: 0.000012, l2: 0.000063, l3: 0.000139, l4: 0.000402, l5: 0.001014, l6: 0.001516

[epoch: 793/1000, batch:   896/ 1052, ite: 208520] train loss: 0.003884, tar: 0.000032 
l0: 0.000006, l1: 0.000007, l2: 0.000018, l3: 0.000082, l4: 0.000311, l5: 0.000765, l6: 0.000976

[epoch: 793/1000, batch:   976/ 1052, ite: 208540] train loss: 0.003885, tar: 0.000032 
[Epoch 793/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000042, l1: 0.000043, l2: 0.000053, l3: 0.000291, l4: 0.000472, l5: 0.001338, l6: 0.002287

[epoch: 794/1000, batch:     4/ 1052, ite: 208560] train loss: 0.003885, tar: 0.000032 
l0: 0.000018, l1: 0.000016, l2: 0.000039, l3: 0.000118, l4: 0.000357, l5: 0.000762, l6: 0.002404

[epoch: 794/1000, batch:    84/ 1052, ite: 208580] train loss: 0.003885, tar: 0.000032 
l0: 0.000033, l1: 0.000032, l2: 0.000092, l3: 0.000205, l4: 0.000547, l5: 0.001214, l6: 0.003187

[epoch: 794/1000, batch:   164/ 1052, ite: 208600] train loss: 0.003885, tar: 0.000032 
l0: 0.000036, l1: 0.000030, l2: 0.000082, l3: 0.000294, l4: 0.000781, l5: 0.001717, l6: 0.002825

[epoch: 794/1000, batch:   244/ 1052, ite: 208620] train loss: 0.003884, tar: 0.000032 
l0: 0.001332, l1: 0.001346, l2: 0.000623, l3: 0.000682, l4: 0.000509, l5: 0.000855, l6: 0.001571

[epoch: 794/1000, batch:   324/ 1052, ite: 208640] train loss: 0.003885, tar: 0.000033 
l0: 0.000062, l1: 0.000066, l2: 0.000079, l3: 0.000215, l4: 0.000370, l5: 0.000843, l6: 0.001720

[epoch: 794/1000, batch:   404/ 1052, ite: 208660] train loss: 0.003888, tar: 0.000033 
l0: 0.000120, l1: 0.000133, l2: 0.000119, l3: 0.000215, l4: 0.000452, l5: 0.001249, l6: 0.003290

[epoch: 794/1000, batch:   484/ 1052, ite: 208680] train loss: 0.003890, tar: 0.000034 
l0: 0.000119, l1: 0.000089, l2: 0.000118, l3: 0.000338, l4: 0.000691, l5: 0.001646, l6: 0.003470

[epoch: 794/1000, batch:   564/ 1052, ite: 208700] train loss: 0.003891, tar: 0.000034 
l0: 0.000060, l1: 0.000061, l2: 0.000090, l3: 0.000246, l4: 0.000431, l5: 0.001216, l6: 0.001495

[epoch: 794/1000, batch:   644/ 1052, ite: 208720] train loss: 0.003891, tar: 0.000034 
l0: 0.000039, l1: 0.000036, l2: 0.000073, l3: 0.000229, l4: 0.000439, l5: 0.001053, l6: 0.001950

[epoch: 794/1000, batch:   724/ 1052, ite: 208740] train loss: 0.003893, tar: 0.000034 
l0: 0.000052, l1: 0.000042, l2: 0.000108, l3: 0.000341, l4: 0.000748, l5: 0.001150, l6: 0.002600

[epoch: 794/1000, batch:   804/ 1052, ite: 208760] train loss: 0.003895, tar: 0.000034 
l0: 0.000020, l1: 0.000016, l2: 0.000060, l3: 0.000138, l4: 0.000292, l5: 0.000619, l6: 0.002140

[epoch: 794/1000, batch:   884/ 1052, ite: 208780] train loss: 0.003895, tar: 0.000034 
l0: 0.000070, l1: 0.000081, l2: 0.000103, l3: 0.000188, l4: 0.000420, l5: 0.001137, l6: 0.002193

[epoch: 794/1000, batch:   964/ 1052, ite: 208800] train loss: 0.003895, tar: 0.000034 
l0: 0.000005, l1: 0.000004, l2: 0.000055, l3: 0.000122, l4: 0.000379, l5: 0.000582, l6: 0.001209

[epoch: 794/1000, batch:  1044/ 1052, ite: 208820] train loss: 0.003895, tar: 0.000034 
[Epoch 794/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000041, l1: 0.000042, l2: 0.000061, l3: 0.000139, l4: 0.000371, l5: 0.000943, l6: 0.001877

[epoch: 795/1000, batch:    72/ 1052, ite: 208840] train loss: 0.003895, tar: 0.000034 
l0: 0.000048, l1: 0.000055, l2: 0.000094, l3: 0.000193, l4: 0.000473, l5: 0.000806, l6: 0.001763

[epoch: 795/1000, batch:   152/ 1052, ite: 208860] train loss: 0.003894, tar: 0.000034 
l0: 0.000007, l1: 0.000007, l2: 0.000031, l3: 0.000072, l4: 0.000200, l5: 0.000880, l6: 0.001434

[epoch: 795/1000, batch:   232/ 1052, ite: 208880] train loss: 0.003894, tar: 0.000034 
l0: 0.000138, l1: 0.000162, l2: 0.000187, l3: 0.000242, l4: 0.000773, l5: 0.001008, l6: 0.001245

[epoch: 795/1000, batch:   312/ 1052, ite: 208900] train loss: 0.003895, tar: 0.000034 
l0: 0.000010, l1: 0.000008, l2: 0.000015, l3: 0.000094, l4: 0.000316, l5: 0.000510, l6: 0.001257

[epoch: 795/1000, batch:   392/ 1052, ite: 208920] train loss: 0.003895, tar: 0.000034 
l0: 0.000029, l1: 0.000030, l2: 0.000085, l3: 0.000269, l4: 0.000501, l5: 0.000973, l6: 0.002153

[epoch: 795/1000, batch:   472/ 1052, ite: 208940] train loss: 0.003894, tar: 0.000034 
l0: 0.000049, l1: 0.000052, l2: 0.000068, l3: 0.000227, l4: 0.000613, l5: 0.001293, l6: 0.002299

[epoch: 795/1000, batch:   552/ 1052, ite: 208960] train loss: 0.003895, tar: 0.000034 
l0: 0.000012, l1: 0.000010, l2: 0.000030, l3: 0.000124, l4: 0.000279, l5: 0.000576, l6: 0.001149

[epoch: 795/1000, batch:   632/ 1052, ite: 208980] train loss: 0.003895, tar: 0.000034 
l0: 0.000013, l1: 0.000015, l2: 0.000029, l3: 0.000082, l4: 0.000138, l5: 0.000547, l6: 0.001020

[epoch: 795/1000, batch:   712/ 1052, ite: 209000] train loss: 0.003896, tar: 0.000034 
l0: 0.000064, l1: 0.000061, l2: 0.000138, l3: 0.000415, l4: 0.000970, l5: 0.002474, l6: 0.004435

[epoch: 795/1000, batch:   792/ 1052, ite: 209020] train loss: 0.003896, tar: 0.000034 
l0: 0.000056, l1: 0.000080, l2: 0.000111, l3: 0.000115, l4: 0.000297, l5: 0.000565, l6: 0.000911

[epoch: 795/1000, batch:   872/ 1052, ite: 209040] train loss: 0.003894, tar: 0.000034 
l0: 0.000042, l1: 0.000042, l2: 0.000053, l3: 0.000101, l4: 0.000383, l5: 0.001161, l6: 0.002178

[epoch: 795/1000, batch:   952/ 1052, ite: 209060] train loss: 0.003894, tar: 0.000034 
l0: 0.000027, l1: 0.000024, l2: 0.000077, l3: 0.000231, l4: 0.000731, l5: 0.001657, l6: 0.002834

[epoch: 795/1000, batch:  1032/ 1052, ite: 209080] train loss: 0.003894, tar: 0.000034 
[Epoch 795/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000021, l1: 0.000016, l2: 0.000062, l3: 0.000129, l4: 0.000363, l5: 0.000666, l6: 0.001143

[epoch: 796/1000, batch:    60/ 1052, ite: 209100] train loss: 0.003894, tar: 0.000034 
l0: 0.000010, l1: 0.000007, l2: 0.000050, l3: 0.000158, l4: 0.000266, l5: 0.000459, l6: 0.000688

[epoch: 796/1000, batch:   140/ 1052, ite: 209120] train loss: 0.003894, tar: 0.000034 
l0: 0.000013, l1: 0.000012, l2: 0.000032, l3: 0.000093, l4: 0.000301, l5: 0.000586, l6: 0.001385

[epoch: 796/1000, batch:   220/ 1052, ite: 209140] train loss: 0.003893, tar: 0.000034 
l0: 0.000037, l1: 0.000038, l2: 0.000041, l3: 0.000079, l4: 0.000332, l5: 0.000432, l6: 0.001775

[epoch: 796/1000, batch:   300/ 1052, ite: 209160] train loss: 0.003893, tar: 0.000034 
l0: 0.000007, l1: 0.000008, l2: 0.000021, l3: 0.000091, l4: 0.000298, l5: 0.000528, l6: 0.001854

[epoch: 796/1000, batch:   380/ 1052, ite: 209180] train loss: 0.003893, tar: 0.000034 
l0: 0.000011, l1: 0.000010, l2: 0.000070, l3: 0.000172, l4: 0.000396, l5: 0.001018, l6: 0.001352

[epoch: 796/1000, batch:   460/ 1052, ite: 209200] train loss: 0.003892, tar: 0.000034 
l0: 0.000031, l1: 0.000032, l2: 0.000063, l3: 0.000126, l4: 0.000450, l5: 0.000335, l6: 0.001359

[epoch: 796/1000, batch:   540/ 1052, ite: 209220] train loss: 0.003891, tar: 0.000034 
l0: 0.000009, l1: 0.000008, l2: 0.000063, l3: 0.000171, l4: 0.000290, l5: 0.000699, l6: 0.001725

[epoch: 796/1000, batch:   620/ 1052, ite: 209240] train loss: 0.003892, tar: 0.000034 
l0: 0.000026, l1: 0.000026, l2: 0.000043, l3: 0.000182, l4: 0.000485, l5: 0.001350, l6: 0.002541

[epoch: 796/1000, batch:   700/ 1052, ite: 209260] train loss: 0.003891, tar: 0.000034 
l0: 0.000022, l1: 0.000022, l2: 0.000046, l3: 0.000184, l4: 0.000392, l5: 0.000723, l6: 0.001273

[epoch: 796/1000, batch:   780/ 1052, ite: 209280] train loss: 0.003892, tar: 0.000034 
l0: 0.000024, l1: 0.000024, l2: 0.000072, l3: 0.000280, l4: 0.000684, l5: 0.001780, l6: 0.002556

[epoch: 796/1000, batch:   860/ 1052, ite: 209300] train loss: 0.003892, tar: 0.000034 
l0: 0.000040, l1: 0.000047, l2: 0.000091, l3: 0.000227, l4: 0.000848, l5: 0.002014, l6: 0.001850

[epoch: 796/1000, batch:   940/ 1052, ite: 209320] train loss: 0.003893, tar: 0.000034 
l0: 0.000014, l1: 0.000015, l2: 0.000025, l3: 0.000125, l4: 0.000663, l5: 0.000939, l6: 0.001746

[epoch: 796/1000, batch:  1020/ 1052, ite: 209340] train loss: 0.003893, tar: 0.000034 
[Epoch 796/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000022, l1: 0.000025, l2: 0.000035, l3: 0.000081, l4: 0.000304, l5: 0.000906, l6: 0.000646

[epoch: 797/1000, batch:    48/ 1052, ite: 209360] train loss: 0.003894, tar: 0.000034 
l0: 0.000001, l1: 0.000002, l2: 0.000005, l3: 0.000091, l4: 0.000364, l5: 0.000405, l6: 0.000860

[epoch: 797/1000, batch:   128/ 1052, ite: 209380] train loss: 0.003894, tar: 0.000034 
l0: 0.000019, l1: 0.000020, l2: 0.000031, l3: 0.000079, l4: 0.000410, l5: 0.001155, l6: 0.001791

[epoch: 797/1000, batch:   208/ 1052, ite: 209400] train loss: 0.003893, tar: 0.000034 
l0: 0.000010, l1: 0.000009, l2: 0.000066, l3: 0.000193, l4: 0.000354, l5: 0.001153, l6: 0.001920

[epoch: 797/1000, batch:   288/ 1052, ite: 209420] train loss: 0.003892, tar: 0.000034 
l0: 0.000023, l1: 0.000025, l2: 0.000050, l3: 0.000110, l4: 0.000356, l5: 0.001468, l6: 0.002186

[epoch: 797/1000, batch:   368/ 1052, ite: 209440] train loss: 0.003893, tar: 0.000034 
l0: 0.000016, l1: 0.000016, l2: 0.000079, l3: 0.000150, l4: 0.000441, l5: 0.000876, l6: 0.001597

[epoch: 797/1000, batch:   448/ 1052, ite: 209460] train loss: 0.003893, tar: 0.000034 
l0: 0.000014, l1: 0.000015, l2: 0.000041, l3: 0.000099, l4: 0.000309, l5: 0.000988, l6: 0.001508

[epoch: 797/1000, batch:   528/ 1052, ite: 209480] train loss: 0.003894, tar: 0.000034 
l0: 0.000059, l1: 0.000059, l2: 0.000089, l3: 0.000171, l4: 0.000293, l5: 0.001223, l6: 0.001855

[epoch: 797/1000, batch:   608/ 1052, ite: 209500] train loss: 0.003894, tar: 0.000034 
l0: 0.000019, l1: 0.000020, l2: 0.000040, l3: 0.000102, l4: 0.000161, l5: 0.000554, l6: 0.001658

[epoch: 797/1000, batch:   688/ 1052, ite: 209520] train loss: 0.003894, tar: 0.000034 
l0: 0.000008, l1: 0.000006, l2: 0.000032, l3: 0.000120, l4: 0.000289, l5: 0.000909, l6: 0.001665

[epoch: 797/1000, batch:   768/ 1052, ite: 209540] train loss: 0.003894, tar: 0.000034 
l0: 0.000007, l1: 0.000007, l2: 0.000028, l3: 0.000128, l4: 0.000581, l5: 0.001009, l6: 0.002458

[epoch: 797/1000, batch:   848/ 1052, ite: 209560] train loss: 0.003894, tar: 0.000034 
l0: 0.000036, l1: 0.000038, l2: 0.000055, l3: 0.000117, l4: 0.000456, l5: 0.000720, l6: 0.002376

[epoch: 797/1000, batch:   928/ 1052, ite: 209580] train loss: 0.003895, tar: 0.000034 
l0: 0.000010, l1: 0.000010, l2: 0.000063, l3: 0.000263, l4: 0.000522, l5: 0.000928, l6: 0.001426

[epoch: 797/1000, batch:  1008/ 1052, ite: 209600] train loss: 0.003894, tar: 0.000034 
[Epoch 797/1000] Test loss: 0.020, Test target loss: 0.003
l0: 0.000027, l1: 0.000029, l2: 0.000044, l3: 0.000167, l4: 0.000367, l5: 0.000887, l6: 0.000794

[epoch: 798/1000, batch:    36/ 1052, ite: 209620] train loss: 0.003894, tar: 0.000034 
l0: 0.000002, l1: 0.000002, l2: 0.000019, l3: 0.000169, l4: 0.000405, l5: 0.001429, l6: 0.001188

[epoch: 798/1000, batch:   116/ 1052, ite: 209640] train loss: 0.003894, tar: 0.000034 
l0: 0.000004, l1: 0.000004, l2: 0.000025, l3: 0.000175, l4: 0.000316, l5: 0.000679, l6: 0.001326

[epoch: 798/1000, batch:   196/ 1052, ite: 209660] train loss: 0.003893, tar: 0.000034 
l0: 0.000039, l1: 0.000035, l2: 0.000148, l3: 0.000405, l4: 0.000752, l5: 0.002393, l6: 0.004519

[epoch: 798/1000, batch:   276/ 1052, ite: 209680] train loss: 0.003894, tar: 0.000034 
l0: 0.000099, l1: 0.000084, l2: 0.000069, l3: 0.000232, l4: 0.000416, l5: 0.000941, l6: 0.002633

[epoch: 798/1000, batch:   356/ 1052, ite: 209700] train loss: 0.003893, tar: 0.000034 
l0: 0.000027, l1: 0.000027, l2: 0.000079, l3: 0.000329, l4: 0.000662, l5: 0.001689, l6: 0.002918

[epoch: 798/1000, batch:   436/ 1052, ite: 209720] train loss: 0.003895, tar: 0.000034 
l0: 0.000029, l1: 0.000027, l2: 0.000090, l3: 0.000176, l4: 0.000344, l5: 0.001106, l6: 0.002571

[epoch: 798/1000, batch:   516/ 1052, ite: 209740] train loss: 0.003895, tar: 0.000034 
l0: 0.000014, l1: 0.000014, l2: 0.000051, l3: 0.000157, l4: 0.000262, l5: 0.000950, l6: 0.002019

[epoch: 798/1000, batch:   596/ 1052, ite: 209760] train loss: 0.003896, tar: 0.000034 
l0: 0.000055, l1: 0.000057, l2: 0.000056, l3: 0.000215, l4: 0.000523, l5: 0.001221, l6: 0.001212

[epoch: 798/1000, batch:   676/ 1052, ite: 209780] train loss: 0.003896, tar: 0.000034 
l0: 0.000005, l1: 0.000005, l2: 0.000036, l3: 0.000280, l4: 0.000919, l5: 0.001753, l6: 0.002286

[epoch: 798/1000, batch:   756/ 1052, ite: 209800] train loss: 0.003896, tar: 0.000034 
l0: 0.000049, l1: 0.000055, l2: 0.000082, l3: 0.000171, l4: 0.000470, l5: 0.001049, l6: 0.001513

[epoch: 798/1000, batch:   836/ 1052, ite: 209820] train loss: 0.003896, tar: 0.000034 
l0: 0.000069, l1: 0.000071, l2: 0.000092, l3: 0.000169, l4: 0.000419, l5: 0.001327, l6: 0.001794

[epoch: 798/1000, batch:   916/ 1052, ite: 209840] train loss: 0.003895, tar: 0.000034 
l0: 0.000016, l1: 0.000016, l2: 0.000032, l3: 0.000055, l4: 0.000268, l5: 0.000462, l6: 0.001271

[epoch: 798/1000, batch:   996/ 1052, ite: 209860] train loss: 0.003894, tar: 0.000034 
[Epoch 798/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000002, l1: 0.000002, l2: 0.000018, l3: 0.000071, l4: 0.000369, l5: 0.000717, l6: 0.001111

[epoch: 799/1000, batch:    24/ 1052, ite: 209880] train loss: 0.003893, tar: 0.000034 
l0: 0.000039, l1: 0.000039, l2: 0.000124, l3: 0.000300, l4: 0.000791, l5: 0.002171, l6: 0.004563

[epoch: 799/1000, batch:   104/ 1052, ite: 209900] train loss: 0.003892, tar: 0.000034 
l0: 0.000037, l1: 0.000037, l2: 0.000074, l3: 0.000261, l4: 0.000768, l5: 0.001313, l6: 0.002517

[epoch: 799/1000, batch:   184/ 1052, ite: 209920] train loss: 0.003893, tar: 0.000034 
l0: 0.000002, l1: 0.000002, l2: 0.000021, l3: 0.000098, l4: 0.000327, l5: 0.000648, l6: 0.001139

[epoch: 799/1000, batch:   264/ 1052, ite: 209940] train loss: 0.003894, tar: 0.000034 
l0: 0.000012, l1: 0.000012, l2: 0.000044, l3: 0.000107, l4: 0.000301, l5: 0.001064, l6: 0.001476

[epoch: 799/1000, batch:   344/ 1052, ite: 209960] train loss: 0.003893, tar: 0.000034 
l0: 0.000016, l1: 0.000017, l2: 0.000034, l3: 0.000110, l4: 0.000256, l5: 0.001206, l6: 0.002498

[epoch: 799/1000, batch:   424/ 1052, ite: 209980] train loss: 0.003893, tar: 0.000034 
l0: 0.000003, l1: 0.000003, l2: 0.000010, l3: 0.000047, l4: 0.000303, l5: 0.000706, l6: 0.001493

[epoch: 799/1000, batch:   504/ 1052, ite: 210000] train loss: 0.003893, tar: 0.000034 
l0: 0.000050, l1: 0.000048, l2: 0.000090, l3: 0.000177, l4: 0.000506, l5: 0.001081, l6: 0.003260

[epoch: 799/1000, batch:   584/ 1052, ite: 210020] train loss: 0.003892, tar: 0.000034 
l0: 0.000002, l1: 0.000002, l2: 0.000020, l3: 0.000098, l4: 0.000286, l5: 0.000745, l6: 0.001165

[epoch: 799/1000, batch:   664/ 1052, ite: 210040] train loss: 0.003891, tar: 0.000034 
l0: 0.000033, l1: 0.000035, l2: 0.000060, l3: 0.000198, l4: 0.000630, l5: 0.000734, l6: 0.001866

[epoch: 799/1000, batch:   744/ 1052, ite: 210060] train loss: 0.003892, tar: 0.000034 
l0: 0.000053, l1: 0.000054, l2: 0.000179, l3: 0.000271, l4: 0.000523, l5: 0.001877, l6: 0.004698

[epoch: 799/1000, batch:   824/ 1052, ite: 210080] train loss: 0.003891, tar: 0.000034 
l0: 0.000005, l1: 0.000005, l2: 0.000028, l3: 0.000150, l4: 0.000647, l5: 0.001266, l6: 0.001482

[epoch: 799/1000, batch:   904/ 1052, ite: 210100] train loss: 0.003891, tar: 0.000034 
l0: 0.000015, l1: 0.000016, l2: 0.000067, l3: 0.000303, l4: 0.000705, l5: 0.001436, l6: 0.001475

[epoch: 799/1000, batch:   984/ 1052, ite: 210120] train loss: 0.003891, tar: 0.000034 
[Epoch 799/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000001, l1: 0.000001, l2: 0.000002, l3: 0.000029, l4: 0.000055, l5: 0.000327, l6: 0.000421

[epoch: 800/1000, batch:    12/ 1052, ite: 210140] train loss: 0.003890, tar: 0.000034 
l0: 0.000019, l1: 0.000020, l2: 0.000096, l3: 0.000234, l4: 0.000559, l5: 0.000860, l6: 0.001829

[epoch: 800/1000, batch:    92/ 1052, ite: 210160] train loss: 0.003891, tar: 0.000033 
l0: 0.000019, l1: 0.000019, l2: 0.000040, l3: 0.000112, l4: 0.000306, l5: 0.000830, l6: 0.001337

[epoch: 800/1000, batch:   172/ 1052, ite: 210180] train loss: 0.003891, tar: 0.000033 
l0: 0.000014, l1: 0.000015, l2: 0.000013, l3: 0.000057, l4: 0.000125, l5: 0.000556, l6: 0.000947

[epoch: 800/1000, batch:   252/ 1052, ite: 210200] train loss: 0.003890, tar: 0.000033 
l0: 0.000010, l1: 0.000009, l2: 0.000053, l3: 0.000222, l4: 0.000298, l5: 0.000884, l6: 0.001363

[epoch: 800/1000, batch:   332/ 1052, ite: 210220] train loss: 0.003890, tar: 0.000033 
l0: 0.000036, l1: 0.000039, l2: 0.000047, l3: 0.000176, l4: 0.000580, l5: 0.001204, l6: 0.002352

[epoch: 800/1000, batch:   412/ 1052, ite: 210240] train loss: 0.003890, tar: 0.000033 
l0: 0.000038, l1: 0.000040, l2: 0.000070, l3: 0.000180, l4: 0.000753, l5: 0.001806, l6: 0.002103

[epoch: 800/1000, batch:   492/ 1052, ite: 210260] train loss: 0.003891, tar: 0.000033 
l0: 0.000009, l1: 0.000011, l2: 0.000014, l3: 0.000059, l4: 0.000312, l5: 0.000491, l6: 0.000583

[epoch: 800/1000, batch:   572/ 1052, ite: 210280] train loss: 0.003890, tar: 0.000033 
l0: 0.000005, l1: 0.000005, l2: 0.000029, l3: 0.000136, l4: 0.000252, l5: 0.000715, l6: 0.000966

[epoch: 800/1000, batch:   652/ 1052, ite: 210300] train loss: 0.003890, tar: 0.000033 
l0: 0.000019, l1: 0.000018, l2: 0.000045, l3: 0.000125, l4: 0.000729, l5: 0.002113, l6: 0.003120

[epoch: 800/1000, batch:   732/ 1052, ite: 210320] train loss: 0.003890, tar: 0.000033 
l0: 0.000019, l1: 0.000020, l2: 0.000120, l3: 0.000450, l4: 0.000833, l5: 0.002604, l6: 0.004393

[epoch: 800/1000, batch:   812/ 1052, ite: 210340] train loss: 0.003892, tar: 0.000033 
l0: 0.000005, l1: 0.000005, l2: 0.000064, l3: 0.000280, l4: 0.000641, l5: 0.001325, l6: 0.001953

[epoch: 800/1000, batch:   892/ 1052, ite: 210360] train loss: 0.003891, tar: 0.000033 
l0: 0.000002, l1: 0.000002, l2: 0.000013, l3: 0.000063, l4: 0.000207, l5: 0.000495, l6: 0.000752

[epoch: 800/1000, batch:   972/ 1052, ite: 210380] train loss: 0.003890, tar: 0.000033 
l0: 0.000025, l1: 0.000024, l2: 0.000077, l3: 0.000244, l4: 0.000625, l5: 0.001448, l6: 0.002250

[epoch: 800/1000, batch:  1052/ 1052, ite: 210400] train loss: 0.003890, tar: 0.000033 
[Epoch 800/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000001, l1: 0.000002, l2: 0.000021, l3: 0.000110, l4: 0.000307, l5: 0.000775, l6: 0.001922

[epoch: 801/1000, batch:    80/ 1052, ite: 210420] train loss: 0.004083, tar: 0.000014 
l0: 0.000007, l1: 0.000006, l2: 0.000037, l3: 0.000116, l4: 0.000427, l5: 0.000912, l6: 0.001884

[epoch: 801/1000, batch:   160/ 1052, ite: 210440] train loss: 0.003903, tar: 0.000020 
l0: 0.000031, l1: 0.000029, l2: 0.000042, l3: 0.000130, l4: 0.000382, l5: 0.000929, l6: 0.001173

[epoch: 801/1000, batch:   240/ 1052, ite: 210460] train loss: 0.004035, tar: 0.000021 
l0: 0.000031, l1: 0.000031, l2: 0.000097, l3: 0.000209, l4: 0.000453, l5: 0.000962, l6: 0.001881

[epoch: 801/1000, batch:   320/ 1052, ite: 210480] train loss: 0.003981, tar: 0.000022 
l0: 0.000010, l1: 0.000011, l2: 0.000047, l3: 0.000156, l4: 0.000385, l5: 0.002020, l6: 0.002567

[epoch: 801/1000, batch:   400/ 1052, ite: 210500] train loss: 0.003967, tar: 0.000023 
l0: 0.000019, l1: 0.000023, l2: 0.000089, l3: 0.000252, l4: 0.000571, l5: 0.001280, l6: 0.002267

[epoch: 801/1000, batch:   480/ 1052, ite: 210520] train loss: 0.003866, tar: 0.000023 
l0: 0.000032, l1: 0.000034, l2: 0.000074, l3: 0.000277, l4: 0.000680, l5: 0.001252, l6: 0.001889

[epoch: 801/1000, batch:   560/ 1052, ite: 210540] train loss: 0.003846, tar: 0.000022 
l0: 0.000059, l1: 0.000058, l2: 0.000094, l3: 0.000180, l4: 0.000374, l5: 0.001226, l6: 0.002895

[epoch: 801/1000, batch:   640/ 1052, ite: 210560] train loss: 0.003870, tar: 0.000023 
l0: 0.000007, l1: 0.000007, l2: 0.000049, l3: 0.000163, l4: 0.000450, l5: 0.000697, l6: 0.001166

[epoch: 801/1000, batch:   720/ 1052, ite: 210580] train loss: 0.003821, tar: 0.000023 
l0: 0.000023, l1: 0.000026, l2: 0.000065, l3: 0.000233, l4: 0.000564, l5: 0.001130, l6: 0.001813

[epoch: 801/1000, batch:   800/ 1052, ite: 210600] train loss: 0.003794, tar: 0.000023 
l0: 0.000002, l1: 0.000002, l2: 0.000045, l3: 0.000076, l4: 0.000198, l5: 0.000695, l6: 0.001432

[epoch: 801/1000, batch:   880/ 1052, ite: 210620] train loss: 0.003805, tar: 0.000022 
l0: 0.000035, l1: 0.000033, l2: 0.000044, l3: 0.000086, l4: 0.000303, l5: 0.000525, l6: 0.001306

[epoch: 801/1000, batch:   960/ 1052, ite: 210640] train loss: 0.003836, tar: 0.000023 
l0: 0.000017, l1: 0.000020, l2: 0.000154, l3: 0.000418, l4: 0.001112, l5: 0.001986, l6: 0.002419

[epoch: 801/1000, batch:  1040/ 1052, ite: 210660] train loss: 0.003861, tar: 0.000022 
[Epoch 801/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000003, l1: 0.000003, l2: 0.000017, l3: 0.000060, l4: 0.000230, l5: 0.000682, l6: 0.001089

[epoch: 802/1000, batch:    68/ 1052, ite: 210680] train loss: 0.003874, tar: 0.000022 
l0: 0.000014, l1: 0.000014, l2: 0.000052, l3: 0.000123, l4: 0.000408, l5: 0.000789, l6: 0.002383

[epoch: 802/1000, batch:   148/ 1052, ite: 210700] train loss: 0.003855, tar: 0.000022 
l0: 0.000020, l1: 0.000021, l2: 0.000087, l3: 0.000241, l4: 0.000548, l5: 0.001133, l6: 0.002132

[epoch: 802/1000, batch:   228/ 1052, ite: 210720] train loss: 0.003843, tar: 0.000022 
l0: 0.000002, l1: 0.000002, l2: 0.000038, l3: 0.000158, l4: 0.000241, l5: 0.000399, l6: 0.001216

[epoch: 802/1000, batch:   308/ 1052, ite: 210740] train loss: 0.003814, tar: 0.000022 
l0: 0.000011, l1: 0.000010, l2: 0.000086, l3: 0.000516, l4: 0.001072, l5: 0.001639, l6: 0.003109

[epoch: 802/1000, batch:   388/ 1052, ite: 210760] train loss: 0.003831, tar: 0.000021 
l0: 0.000039, l1: 0.000043, l2: 0.000060, l3: 0.000160, l4: 0.000401, l5: 0.000808, l6: 0.001471

[epoch: 802/1000, batch:   468/ 1052, ite: 210780] train loss: 0.003827, tar: 0.000022 
l0: 0.000025, l1: 0.000023, l2: 0.000154, l3: 0.000473, l4: 0.000957, l5: 0.001979, l6: 0.003207

[epoch: 802/1000, batch:   548/ 1052, ite: 210800] train loss: 0.003860, tar: 0.000022 
l0: 0.000016, l1: 0.000017, l2: 0.000056, l3: 0.000131, l4: 0.000309, l5: 0.001002, l6: 0.001772

[epoch: 802/1000, batch:   628/ 1052, ite: 210820] train loss: 0.003878, tar: 0.000022 
l0: 0.000000, l1: 0.000000, l2: 0.000010, l3: 0.000077, l4: 0.000204, l5: 0.000522, l6: 0.000941

[epoch: 802/1000, batch:   708/ 1052, ite: 210840] train loss: 0.003882, tar: 0.000023 
l0: 0.000035, l1: 0.000034, l2: 0.000064, l3: 0.000214, l4: 0.000317, l5: 0.001044, l6: 0.001037

[epoch: 802/1000, batch:   788/ 1052, ite: 210860] train loss: 0.003889, tar: 0.000023 
l0: 0.000016, l1: 0.000016, l2: 0.000039, l3: 0.000166, l4: 0.000603, l5: 0.000871, l6: 0.002311

[epoch: 802/1000, batch:   868/ 1052, ite: 210880] train loss: 0.003887, tar: 0.000023 
l0: 0.000023, l1: 0.000021, l2: 0.000056, l3: 0.000168, l4: 0.000454, l5: 0.001238, l6: 0.001791

[epoch: 802/1000, batch:   948/ 1052, ite: 210900] train loss: 0.003869, tar: 0.000023 
l0: 0.000006, l1: 0.000007, l2: 0.000018, l3: 0.000116, l4: 0.000315, l5: 0.000839, l6: 0.000785

[epoch: 802/1000, batch:  1028/ 1052, ite: 210920] train loss: 0.003843, tar: 0.000023 
[Epoch 802/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000037, l1: 0.000040, l2: 0.000104, l3: 0.000214, l4: 0.000499, l5: 0.000949, l6: 0.002033

[epoch: 803/1000, batch:    56/ 1052, ite: 210940] train loss: 0.003837, tar: 0.000023 
l0: 0.000024, l1: 0.000025, l2: 0.000066, l3: 0.000191, l4: 0.000513, l5: 0.001180, l6: 0.001807

[epoch: 803/1000, batch:   136/ 1052, ite: 210960] train loss: 0.003843, tar: 0.000023 
l0: 0.000033, l1: 0.000034, l2: 0.000061, l3: 0.000137, l4: 0.000523, l5: 0.000921, l6: 0.001624

[epoch: 803/1000, batch:   216/ 1052, ite: 210980] train loss: 0.003850, tar: 0.000024 
l0: 0.000011, l1: 0.000011, l2: 0.000028, l3: 0.000081, l4: 0.000401, l5: 0.000617, l6: 0.001007

[epoch: 803/1000, batch:   296/ 1052, ite: 211000] train loss: 0.003834, tar: 0.000024 
l0: 0.000026, l1: 0.000026, l2: 0.000088, l3: 0.000350, l4: 0.000720, l5: 0.001683, l6: 0.001980

[epoch: 803/1000, batch:   376/ 1052, ite: 211020] train loss: 0.003837, tar: 0.000024 
l0: 0.000013, l1: 0.000013, l2: 0.000073, l3: 0.000215, l4: 0.000631, l5: 0.001035, l6: 0.001769

[epoch: 803/1000, batch:   456/ 1052, ite: 211040] train loss: 0.003844, tar: 0.000024 
l0: 0.000028, l1: 0.000026, l2: 0.000079, l3: 0.000186, l4: 0.000315, l5: 0.000962, l6: 0.001440

[epoch: 803/1000, batch:   536/ 1052, ite: 211060] train loss: 0.003837, tar: 0.000024 
l0: 0.000033, l1: 0.000033, l2: 0.000066, l3: 0.000135, l4: 0.000302, l5: 0.001312, l6: 0.003129

[epoch: 803/1000, batch:   616/ 1052, ite: 211080] train loss: 0.003837, tar: 0.000024 
l0: 0.000032, l1: 0.000034, l2: 0.000030, l3: 0.000078, l4: 0.000268, l5: 0.000490, l6: 0.001168

[epoch: 803/1000, batch:   696/ 1052, ite: 211100] train loss: 0.003830, tar: 0.000024 
l0: 0.000025, l1: 0.000026, l2: 0.000107, l3: 0.000218, l4: 0.000438, l5: 0.000977, l6: 0.002437

[epoch: 803/1000, batch:   776/ 1052, ite: 211120] train loss: 0.003826, tar: 0.000024 
l0: 0.000002, l1: 0.000003, l2: 0.000018, l3: 0.000024, l4: 0.000127, l5: 0.000422, l6: 0.000433

[epoch: 803/1000, batch:   856/ 1052, ite: 211140] train loss: 0.003820, tar: 0.000024 
l0: 0.000043, l1: 0.000040, l2: 0.000084, l3: 0.000187, l4: 0.000418, l5: 0.001833, l6: 0.003734

[epoch: 803/1000, batch:   936/ 1052, ite: 211160] train loss: 0.003826, tar: 0.000024 
l0: 0.000009, l1: 0.000009, l2: 0.000048, l3: 0.000183, l4: 0.000363, l5: 0.000855, l6: 0.001260

[epoch: 803/1000, batch:  1016/ 1052, ite: 211180] train loss: 0.003822, tar: 0.000024 
[Epoch 803/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000022, l1: 0.000020, l2: 0.000032, l3: 0.000114, l4: 0.000146, l5: 0.000737, l6: 0.001488

[epoch: 804/1000, batch:    44/ 1052, ite: 211200] train loss: 0.003821, tar: 0.000024 
l0: 0.000020, l1: 0.000022, l2: 0.000056, l3: 0.000206, l4: 0.000455, l5: 0.001312, l6: 0.002240

[epoch: 804/1000, batch:   124/ 1052, ite: 211220] train loss: 0.003823, tar: 0.000024 
l0: 0.000045, l1: 0.000053, l2: 0.000164, l3: 0.000281, l4: 0.000525, l5: 0.001259, l6: 0.003104

[epoch: 804/1000, batch:   204/ 1052, ite: 211240] train loss: 0.003814, tar: 0.000024 
l0: 0.000040, l1: 0.000041, l2: 0.000078, l3: 0.000174, l4: 0.000411, l5: 0.000803, l6: 0.001644

[epoch: 804/1000, batch:   284/ 1052, ite: 211260] train loss: 0.003808, tar: 0.000024 
l0: 0.000015, l1: 0.000015, l2: 0.000052, l3: 0.000158, l4: 0.000416, l5: 0.000918, l6: 0.001646

[epoch: 804/1000, batch:   364/ 1052, ite: 211280] train loss: 0.003809, tar: 0.000024 
l0: 0.000072, l1: 0.000078, l2: 0.000149, l3: 0.000382, l4: 0.000874, l5: 0.001981, l6: 0.004742

[epoch: 804/1000, batch:   444/ 1052, ite: 211300] train loss: 0.003822, tar: 0.000024 
l0: 0.000029, l1: 0.000032, l2: 0.000054, l3: 0.000207, l4: 0.000442, l5: 0.000740, l6: 0.001803

[epoch: 804/1000, batch:   524/ 1052, ite: 211320] train loss: 0.003820, tar: 0.000025 
l0: 0.000008, l1: 0.000008, l2: 0.000095, l3: 0.000291, l4: 0.000711, l5: 0.001185, l6: 0.001890

[epoch: 804/1000, batch:   604/ 1052, ite: 211340] train loss: 0.003824, tar: 0.000025 
l0: 0.000009, l1: 0.000010, l2: 0.000042, l3: 0.000172, l4: 0.000500, l5: 0.001584, l6: 0.003201

[epoch: 804/1000, batch:   684/ 1052, ite: 211360] train loss: 0.003825, tar: 0.000025 
l0: 0.000028, l1: 0.000029, l2: 0.000058, l3: 0.000121, l4: 0.000336, l5: 0.000978, l6: 0.001647

[epoch: 804/1000, batch:   764/ 1052, ite: 211380] train loss: 0.003822, tar: 0.000025 
l0: 0.000046, l1: 0.000043, l2: 0.000094, l3: 0.000308, l4: 0.000717, l5: 0.001682, l6: 0.002681

[epoch: 804/1000, batch:   844/ 1052, ite: 211400] train loss: 0.003826, tar: 0.000025 
l0: 0.000010, l1: 0.000009, l2: 0.000042, l3: 0.000090, l4: 0.000305, l5: 0.000669, l6: 0.001458

[epoch: 804/1000, batch:   924/ 1052, ite: 211420] train loss: 0.003824, tar: 0.000025 
l0: 0.000044, l1: 0.000045, l2: 0.000089, l3: 0.000180, l4: 0.000440, l5: 0.001456, l6: 0.001558

[epoch: 804/1000, batch:  1004/ 1052, ite: 211440] train loss: 0.003824, tar: 0.000025 
[Epoch 804/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000022, l1: 0.000025, l2: 0.000036, l3: 0.000115, l4: 0.000290, l5: 0.000843, l6: 0.002742

[epoch: 805/1000, batch:    32/ 1052, ite: 211460] train loss: 0.003824, tar: 0.000025 
l0: 0.000010, l1: 0.000009, l2: 0.000066, l3: 0.000235, l4: 0.000362, l5: 0.000910, l6: 0.001260

[epoch: 805/1000, batch:   112/ 1052, ite: 211480] train loss: 0.003814, tar: 0.000025 
l0: 0.000020, l1: 0.000021, l2: 0.000091, l3: 0.000206, l4: 0.000454, l5: 0.000895, l6: 0.001515

[epoch: 805/1000, batch:   192/ 1052, ite: 211500] train loss: 0.003808, tar: 0.000025 
l0: 0.000024, l1: 0.000028, l2: 0.000046, l3: 0.000391, l4: 0.000906, l5: 0.001639, l6: 0.004395

[epoch: 805/1000, batch:   272/ 1052, ite: 211520] train loss: 0.003805, tar: 0.000025 
l0: 0.000025, l1: 0.000022, l2: 0.000080, l3: 0.000136, l4: 0.000306, l5: 0.001080, l6: 0.002644

[epoch: 805/1000, batch:   352/ 1052, ite: 211540] train loss: 0.003809, tar: 0.000025 
l0: 0.000012, l1: 0.000014, l2: 0.000015, l3: 0.000109, l4: 0.000321, l5: 0.000380, l6: 0.001234

[epoch: 805/1000, batch:   432/ 1052, ite: 211560] train loss: 0.003816, tar: 0.000025 
l0: 0.000048, l1: 0.000050, l2: 0.000040, l3: 0.000090, l4: 0.000306, l5: 0.000826, l6: 0.001188

[epoch: 805/1000, batch:   512/ 1052, ite: 211580] train loss: 0.003830, tar: 0.000026 
l0: 0.000022, l1: 0.000022, l2: 0.000093, l3: 0.000227, l4: 0.000516, l5: 0.001736, l6: 0.002398

[epoch: 805/1000, batch:   592/ 1052, ite: 211600] train loss: 0.003836, tar: 0.000026 
l0: 0.000006, l1: 0.000005, l2: 0.000029, l3: 0.000073, l4: 0.000323, l5: 0.000836, l6: 0.001557

[epoch: 805/1000, batch:   672/ 1052, ite: 211620] train loss: 0.003828, tar: 0.000026 
l0: 0.000025, l1: 0.000025, l2: 0.000079, l3: 0.000213, l4: 0.000481, l5: 0.001358, l6: 0.002094

[epoch: 805/1000, batch:   752/ 1052, ite: 211640] train loss: 0.003825, tar: 0.000026 
l0: 0.000024, l1: 0.000023, l2: 0.000067, l3: 0.000148, l4: 0.000327, l5: 0.000837, l6: 0.001447

[epoch: 805/1000, batch:   832/ 1052, ite: 211660] train loss: 0.003827, tar: 0.000025 
l0: 0.000010, l1: 0.000009, l2: 0.000053, l3: 0.000229, l4: 0.000434, l5: 0.000896, l6: 0.001518

[epoch: 805/1000, batch:   912/ 1052, ite: 211680] train loss: 0.003825, tar: 0.000025 
l0: 0.000038, l1: 0.000037, l2: 0.000100, l3: 0.000210, l4: 0.000581, l5: 0.001190, l6: 0.002344

[epoch: 805/1000, batch:   992/ 1052, ite: 211700] train loss: 0.003822, tar: 0.000025 
[Epoch 805/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000013, l1: 0.000014, l2: 0.000054, l3: 0.000179, l4: 0.000350, l5: 0.001091, l6: 0.001460

[epoch: 806/1000, batch:    20/ 1052, ite: 211720] train loss: 0.003830, tar: 0.000025 
l0: 0.000016, l1: 0.000018, l2: 0.000051, l3: 0.000140, l4: 0.000501, l5: 0.001163, l6: 0.001405

[epoch: 806/1000, batch:   100/ 1052, ite: 211740] train loss: 0.003829, tar: 0.000026 
l0: 0.000141, l1: 0.000148, l2: 0.000181, l3: 0.000239, l4: 0.000697, l5: 0.000955, l6: 0.002207

[epoch: 806/1000, batch:   180/ 1052, ite: 211760] train loss: 0.003827, tar: 0.000026 
l0: 0.000004, l1: 0.000004, l2: 0.000042, l3: 0.000153, l4: 0.000466, l5: 0.001355, l6: 0.002032

[epoch: 806/1000, batch:   260/ 1052, ite: 211780] train loss: 0.003823, tar: 0.000025 
l0: 0.000009, l1: 0.000008, l2: 0.000025, l3: 0.000089, l4: 0.000382, l5: 0.000654, l6: 0.001219

[epoch: 806/1000, batch:   340/ 1052, ite: 211800] train loss: 0.003825, tar: 0.000026 
l0: 0.000018, l1: 0.000019, l2: 0.000036, l3: 0.000131, l4: 0.000584, l5: 0.001084, l6: 0.002397

[epoch: 806/1000, batch:   420/ 1052, ite: 211820] train loss: 0.003827, tar: 0.000026 
l0: 0.000064, l1: 0.000064, l2: 0.000096, l3: 0.000210, l4: 0.000601, l5: 0.001594, l6: 0.003029

[epoch: 806/1000, batch:   500/ 1052, ite: 211840] train loss: 0.003836, tar: 0.000026 
l0: 0.000010, l1: 0.000011, l2: 0.000020, l3: 0.000078, l4: 0.000308, l5: 0.001090, l6: 0.000871

[epoch: 806/1000, batch:   580/ 1052, ite: 211860] train loss: 0.003835, tar: 0.000026 
l0: 0.000058, l1: 0.000062, l2: 0.000095, l3: 0.000160, l4: 0.000252, l5: 0.001419, l6: 0.003294

[epoch: 806/1000, batch:   660/ 1052, ite: 211880] train loss: 0.003834, tar: 0.000026 
l0: 0.000021, l1: 0.000022, l2: 0.000039, l3: 0.000163, l4: 0.000326, l5: 0.000795, l6: 0.001515

[epoch: 806/1000, batch:   740/ 1052, ite: 211900] train loss: 0.003832, tar: 0.000026 
l0: 0.000010, l1: 0.000010, l2: 0.000058, l3: 0.000116, l4: 0.000315, l5: 0.000483, l6: 0.001553

[epoch: 806/1000, batch:   820/ 1052, ite: 211920] train loss: 0.003827, tar: 0.000026 
l0: 0.000029, l1: 0.000029, l2: 0.000037, l3: 0.000080, l4: 0.000278, l5: 0.000893, l6: 0.001298

[epoch: 806/1000, batch:   900/ 1052, ite: 211940] train loss: 0.003830, tar: 0.000026 
l0: 0.000013, l1: 0.000012, l2: 0.000036, l3: 0.000306, l4: 0.000571, l5: 0.000999, l6: 0.003597

[epoch: 806/1000, batch:   980/ 1052, ite: 211960] train loss: 0.003826, tar: 0.000026 
[Epoch 806/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000006, l1: 0.000006, l2: 0.000024, l3: 0.000107, l4: 0.000439, l5: 0.000878, l6: 0.001106

[epoch: 807/1000, batch:     8/ 1052, ite: 211980] train loss: 0.003829, tar: 0.000026 
l0: 0.000015, l1: 0.000015, l2: 0.000023, l3: 0.000061, l4: 0.000283, l5: 0.000579, l6: 0.001035

[epoch: 807/1000, batch:    88/ 1052, ite: 212000] train loss: 0.003825, tar: 0.000026 
l0: 0.000009, l1: 0.000012, l2: 0.000024, l3: 0.000150, l4: 0.000461, l5: 0.000755, l6: 0.001455

[epoch: 807/1000, batch:   168/ 1052, ite: 212020] train loss: 0.003827, tar: 0.000026 
l0: 0.000017, l1: 0.000019, l2: 0.000057, l3: 0.000174, l4: 0.000377, l5: 0.001051, l6: 0.002167

[epoch: 807/1000, batch:   248/ 1052, ite: 212040] train loss: 0.003822, tar: 0.000026 
l0: 0.000013, l1: 0.000013, l2: 0.000045, l3: 0.000195, l4: 0.000465, l5: 0.000650, l6: 0.001163

[epoch: 807/1000, batch:   328/ 1052, ite: 212060] train loss: 0.003819, tar: 0.000026 
l0: 0.000023, l1: 0.000021, l2: 0.000030, l3: 0.000055, l4: 0.000207, l5: 0.000771, l6: 0.001045

[epoch: 807/1000, batch:   408/ 1052, ite: 212080] train loss: 0.003825, tar: 0.000026 
l0: 0.000017, l1: 0.000018, l2: 0.000044, l3: 0.000104, l4: 0.000268, l5: 0.001048, l6: 0.001433

[epoch: 807/1000, batch:   488/ 1052, ite: 212100] train loss: 0.003817, tar: 0.000026 
l0: 0.000077, l1: 0.000076, l2: 0.000112, l3: 0.000281, l4: 0.000764, l5: 0.001593, l6: 0.001730

[epoch: 807/1000, batch:   568/ 1052, ite: 212120] train loss: 0.003817, tar: 0.000026 
l0: 0.000013, l1: 0.000014, l2: 0.000025, l3: 0.000103, l4: 0.000382, l5: 0.001460, l6: 0.001551

[epoch: 807/1000, batch:   648/ 1052, ite: 212140] train loss: 0.003817, tar: 0.000026 
l0: 0.000024, l1: 0.000028, l2: 0.000076, l3: 0.000240, l4: 0.000499, l5: 0.001284, l6: 0.002872

[epoch: 807/1000, batch:   728/ 1052, ite: 212160] train loss: 0.003822, tar: 0.000026 
l0: 0.000011, l1: 0.000012, l2: 0.000023, l3: 0.000094, l4: 0.000201, l5: 0.000662, l6: 0.000733

[epoch: 807/1000, batch:   808/ 1052, ite: 212180] train loss: 0.003827, tar: 0.000026 
l0: 0.000042, l1: 0.000044, l2: 0.000064, l3: 0.000119, l4: 0.000612, l5: 0.001546, l6: 0.002520

[epoch: 807/1000, batch:   888/ 1052, ite: 212200] train loss: 0.003826, tar: 0.000026 
l0: 0.000014, l1: 0.000014, l2: 0.000056, l3: 0.000204, l4: 0.000444, l5: 0.000806, l6: 0.001373

[epoch: 807/1000, batch:   968/ 1052, ite: 212220] train loss: 0.003832, tar: 0.000026 
l0: 0.000012, l1: 0.000013, l2: 0.000029, l3: 0.000128, l4: 0.000367, l5: 0.000651, l6: 0.001600

[epoch: 807/1000, batch:  1048/ 1052, ite: 212240] train loss: 0.003831, tar: 0.000026 
[Epoch 807/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000031, l1: 0.000031, l2: 0.000050, l3: 0.000168, l4: 0.000354, l5: 0.001119, l6: 0.002275

[epoch: 808/1000, batch:    76/ 1052, ite: 212260] train loss: 0.003829, tar: 0.000026 
l0: 0.000012, l1: 0.000011, l2: 0.000063, l3: 0.000119, l4: 0.000350, l5: 0.000445, l6: 0.001345

[epoch: 808/1000, batch:   156/ 1052, ite: 212280] train loss: 0.003830, tar: 0.000026 
l0: 0.000017, l1: 0.000017, l2: 0.000026, l3: 0.000134, l4: 0.000420, l5: 0.001013, l6: 0.001339

[epoch: 808/1000, batch:   236/ 1052, ite: 212300] train loss: 0.003825, tar: 0.000026 
l0: 0.000033, l1: 0.000033, l2: 0.000031, l3: 0.000113, l4: 0.000498, l5: 0.000965, l6: 0.001409

[epoch: 808/1000, batch:   316/ 1052, ite: 212320] train loss: 0.003824, tar: 0.000026 
l0: 0.000029, l1: 0.000030, l2: 0.000057, l3: 0.000112, l4: 0.000337, l5: 0.000928, l6: 0.001107

[epoch: 808/1000, batch:   396/ 1052, ite: 212340] train loss: 0.003820, tar: 0.000026 
l0: 0.000009, l1: 0.000010, l2: 0.000022, l3: 0.000105, l4: 0.000427, l5: 0.001735, l6: 0.002920

[epoch: 808/1000, batch:   476/ 1052, ite: 212360] train loss: 0.003821, tar: 0.000026 
l0: 0.000012, l1: 0.000013, l2: 0.000028, l3: 0.000115, l4: 0.000388, l5: 0.000614, l6: 0.001148

[epoch: 808/1000, batch:   556/ 1052, ite: 212380] train loss: 0.003824, tar: 0.000026 
l0: 0.000010, l1: 0.000014, l2: 0.000046, l3: 0.000221, l4: 0.000660, l5: 0.001656, l6: 0.002204

[epoch: 808/1000, batch:   636/ 1052, ite: 212400] train loss: 0.003828, tar: 0.000026 
l0: 0.000007, l1: 0.000008, l2: 0.000028, l3: 0.000083, l4: 0.000306, l5: 0.000635, l6: 0.001412

[epoch: 808/1000, batch:   716/ 1052, ite: 212420] train loss: 0.003828, tar: 0.000026 
l0: 0.000046, l1: 0.000047, l2: 0.000063, l3: 0.000204, l4: 0.000368, l5: 0.001245, l6: 0.001751

[epoch: 808/1000, batch:   796/ 1052, ite: 212440] train loss: 0.003830, tar: 0.000026 
l0: 0.000018, l1: 0.000018, l2: 0.000074, l3: 0.000285, l4: 0.000939, l5: 0.001315, l6: 0.003315

[epoch: 808/1000, batch:   876/ 1052, ite: 212460] train loss: 0.003832, tar: 0.000026 
l0: 0.000018, l1: 0.000018, l2: 0.000073, l3: 0.000200, l4: 0.000340, l5: 0.001198, l6: 0.001949

[epoch: 808/1000, batch:   956/ 1052, ite: 212480] train loss: 0.003831, tar: 0.000026 
l0: 0.000027, l1: 0.000029, l2: 0.000088, l3: 0.000376, l4: 0.000781, l5: 0.001605, l6: 0.001748

[epoch: 808/1000, batch:  1036/ 1052, ite: 212500] train loss: 0.003835, tar: 0.000026 
[Epoch 808/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000018, l1: 0.000018, l2: 0.000061, l3: 0.000153, l4: 0.000441, l5: 0.001084, l6: 0.003618

[epoch: 809/1000, batch:    64/ 1052, ite: 212520] train loss: 0.003831, tar: 0.000025 
l0: 0.000038, l1: 0.000038, l2: 0.000081, l3: 0.000148, l4: 0.000345, l5: 0.001325, l6: 0.001737

[epoch: 809/1000, batch:   144/ 1052, ite: 212540] train loss: 0.003826, tar: 0.000025 
l0: 0.000006, l1: 0.000006, l2: 0.000053, l3: 0.000124, l4: 0.000397, l5: 0.000970, l6: 0.001920

[epoch: 809/1000, batch:   224/ 1052, ite: 212560] train loss: 0.003834, tar: 0.000025 
l0: 0.000019, l1: 0.000018, l2: 0.000121, l3: 0.000323, l4: 0.000761, l5: 0.001286, l6: 0.002188

[epoch: 809/1000, batch:   304/ 1052, ite: 212580] train loss: 0.003835, tar: 0.000025 
l0: 0.000020, l1: 0.000021, l2: 0.000023, l3: 0.000117, l4: 0.000228, l5: 0.000814, l6: 0.001546

[epoch: 809/1000, batch:   384/ 1052, ite: 212600] train loss: 0.003837, tar: 0.000025 
l0: 0.000011, l1: 0.000013, l2: 0.000049, l3: 0.000113, l4: 0.000283, l5: 0.001076, l6: 0.001410

[epoch: 809/1000, batch:   464/ 1052, ite: 212620] train loss: 0.003834, tar: 0.000025 
l0: 0.000054, l1: 0.000059, l2: 0.000219, l3: 0.000506, l4: 0.001097, l5: 0.002664, l6: 0.005279

[epoch: 809/1000, batch:   544/ 1052, ite: 212640] train loss: 0.003838, tar: 0.000025 
l0: 0.000020, l1: 0.000019, l2: 0.000048, l3: 0.000177, l4: 0.000490, l5: 0.001329, l6: 0.002808

[epoch: 809/1000, batch:   624/ 1052, ite: 212660] train loss: 0.003838, tar: 0.000025 
l0: 0.000029, l1: 0.000030, l2: 0.000059, l3: 0.000153, l4: 0.000414, l5: 0.001355, l6: 0.001958

[epoch: 809/1000, batch:   704/ 1052, ite: 212680] train loss: 0.003835, tar: 0.000025 
l0: 0.000010, l1: 0.000011, l2: 0.000014, l3: 0.000093, l4: 0.000130, l5: 0.000663, l6: 0.000846

[epoch: 809/1000, batch:   784/ 1052, ite: 212700] train loss: 0.003832, tar: 0.000025 
l0: 0.000011, l1: 0.000012, l2: 0.000025, l3: 0.000078, l4: 0.000239, l5: 0.000786, l6: 0.000843

[epoch: 809/1000, batch:   864/ 1052, ite: 212720] train loss: 0.003833, tar: 0.000025 
l0: 0.000025, l1: 0.000027, l2: 0.000064, l3: 0.000168, l4: 0.000535, l5: 0.001291, l6: 0.001694

[epoch: 809/1000, batch:   944/ 1052, ite: 212740] train loss: 0.003833, tar: 0.000025 
l0: 0.000024, l1: 0.000025, l2: 0.000050, l3: 0.000165, l4: 0.000494, l5: 0.000859, l6: 0.001408

[epoch: 809/1000, batch:  1024/ 1052, ite: 212760] train loss: 0.003830, tar: 0.000025 
[Epoch 809/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000072, l1: 0.000075, l2: 0.000108, l3: 0.000292, l4: 0.000688, l5: 0.001492, l6: 0.003155

[epoch: 810/1000, batch:    52/ 1052, ite: 212780] train loss: 0.003831, tar: 0.000025 
l0: 0.000027, l1: 0.000027, l2: 0.000073, l3: 0.000178, l4: 0.000502, l5: 0.001208, l6: 0.001950

[epoch: 810/1000, batch:   132/ 1052, ite: 212800] train loss: 0.003833, tar: 0.000025 
l0: 0.000022, l1: 0.000021, l2: 0.000041, l3: 0.000113, l4: 0.000390, l5: 0.000598, l6: 0.000821

[epoch: 810/1000, batch:   212/ 1052, ite: 212820] train loss: 0.003840, tar: 0.000025 
l0: 0.000019, l1: 0.000018, l2: 0.000042, l3: 0.000063, l4: 0.000190, l5: 0.000604, l6: 0.001735

[epoch: 810/1000, batch:   292/ 1052, ite: 212840] train loss: 0.003840, tar: 0.000026 
l0: 0.000061, l1: 0.000063, l2: 0.000072, l3: 0.000176, l4: 0.000359, l5: 0.001121, l6: 0.001483

[epoch: 810/1000, batch:   372/ 1052, ite: 212860] train loss: 0.003838, tar: 0.000026 
l0: 0.000008, l1: 0.000010, l2: 0.000014, l3: 0.000121, l4: 0.000727, l5: 0.001532, l6: 0.002603

[epoch: 810/1000, batch:   452/ 1052, ite: 212880] train loss: 0.003834, tar: 0.000026 
l0: 0.000042, l1: 0.000044, l2: 0.000083, l3: 0.000125, l4: 0.000404, l5: 0.001314, l6: 0.001455

[epoch: 810/1000, batch:   532/ 1052, ite: 212900] train loss: 0.003831, tar: 0.000025 
l0: 0.000024, l1: 0.000025, l2: 0.000038, l3: 0.000118, l4: 0.000389, l5: 0.001041, l6: 0.001913

[epoch: 810/1000, batch:   612/ 1052, ite: 212920] train loss: 0.003832, tar: 0.000026 
l0: 0.000026, l1: 0.000027, l2: 0.000073, l3: 0.000190, l4: 0.000381, l5: 0.000870, l6: 0.002198

[epoch: 810/1000, batch:   692/ 1052, ite: 212940] train loss: 0.003826, tar: 0.000025 
l0: 0.000047, l1: 0.000047, l2: 0.000066, l3: 0.000160, l4: 0.000477, l5: 0.000526, l6: 0.001645

[epoch: 810/1000, batch:   772/ 1052, ite: 212960] train loss: 0.003830, tar: 0.000026 
l0: 0.000017, l1: 0.000018, l2: 0.000045, l3: 0.000136, l4: 0.000400, l5: 0.000985, l6: 0.001901

[epoch: 810/1000, batch:   852/ 1052, ite: 212980] train loss: 0.003829, tar: 0.000026 
l0: 0.000095, l1: 0.000096, l2: 0.000170, l3: 0.000231, l4: 0.000749, l5: 0.001505, l6: 0.003296

[epoch: 810/1000, batch:   932/ 1052, ite: 213000] train loss: 0.003829, tar: 0.000026 
l0: 0.000079, l1: 0.000078, l2: 0.000105, l3: 0.000257, l4: 0.000590, l5: 0.001179, l6: 0.001560

[epoch: 810/1000, batch:  1012/ 1052, ite: 213020] train loss: 0.003832, tar: 0.000026 
[Epoch 810/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000035, l1: 0.000035, l2: 0.000097, l3: 0.000204, l4: 0.000444, l5: 0.000772, l6: 0.002877

[epoch: 811/1000, batch:    40/ 1052, ite: 213040] train loss: 0.003832, tar: 0.000026 
l0: 0.000004, l1: 0.000004, l2: 0.000033, l3: 0.000104, l4: 0.000357, l5: 0.000906, l6: 0.002973

[epoch: 811/1000, batch:   120/ 1052, ite: 213060] train loss: 0.003830, tar: 0.000026 
l0: 0.000024, l1: 0.000022, l2: 0.000092, l3: 0.000216, l4: 0.000424, l5: 0.001202, l6: 0.002343

[epoch: 811/1000, batch:   200/ 1052, ite: 213080] train loss: 0.003831, tar: 0.000026 
l0: 0.000020, l1: 0.000021, l2: 0.000044, l3: 0.000158, l4: 0.000328, l5: 0.001106, l6: 0.002272

[epoch: 811/1000, batch:   280/ 1052, ite: 213100] train loss: 0.003832, tar: 0.000026 
l0: 0.000060, l1: 0.000057, l2: 0.000153, l3: 0.000275, l4: 0.000947, l5: 0.001638, l6: 0.003365

[epoch: 811/1000, batch:   360/ 1052, ite: 213120] train loss: 0.003832, tar: 0.000026 
l0: 0.000020, l1: 0.000021, l2: 0.000068, l3: 0.000275, l4: 0.000630, l5: 0.001542, l6: 0.003166

[epoch: 811/1000, batch:   440/ 1052, ite: 213140] train loss: 0.003832, tar: 0.000026 
l0: 0.000029, l1: 0.000032, l2: 0.000080, l3: 0.000263, l4: 0.000791, l5: 0.001251, l6: 0.003527

[epoch: 811/1000, batch:   520/ 1052, ite: 213160] train loss: 0.003834, tar: 0.000026 
l0: 0.000022, l1: 0.000023, l2: 0.000078, l3: 0.000198, l4: 0.000530, l5: 0.000999, l6: 0.003390

[epoch: 811/1000, batch:   600/ 1052, ite: 213180] train loss: 0.003834, tar: 0.000026 
l0: 0.000021, l1: 0.000021, l2: 0.000059, l3: 0.000141, l4: 0.000343, l5: 0.001186, l6: 0.001270

[epoch: 811/1000, batch:   680/ 1052, ite: 213200] train loss: 0.003835, tar: 0.000026 
l0: 0.000114, l1: 0.000121, l2: 0.000166, l3: 0.000196, l4: 0.000483, l5: 0.000753, l6: 0.001886

[epoch: 811/1000, batch:   760/ 1052, ite: 213220] train loss: 0.003834, tar: 0.000026 
l0: 0.000080, l1: 0.000080, l2: 0.000101, l3: 0.000129, l4: 0.000489, l5: 0.000697, l6: 0.001489

[epoch: 811/1000, batch:   840/ 1052, ite: 213240] train loss: 0.003835, tar: 0.000026 
l0: 0.000049, l1: 0.000049, l2: 0.000086, l3: 0.000274, l4: 0.000482, l5: 0.000876, l6: 0.002881

[epoch: 811/1000, batch:   920/ 1052, ite: 213260] train loss: 0.003835, tar: 0.000026 
l0: 0.000028, l1: 0.000028, l2: 0.000101, l3: 0.000270, l4: 0.000737, l5: 0.001246, l6: 0.002112

[epoch: 811/1000, batch:  1000/ 1052, ite: 213280] train loss: 0.003832, tar: 0.000026 
[Epoch 811/1000] Test loss: 0.020, Test target loss: 0.003
l0: 0.000022, l1: 0.000021, l2: 0.000052, l3: 0.000190, l4: 0.000474, l5: 0.001875, l6: 0.003241

[epoch: 812/1000, batch:    28/ 1052, ite: 213300] train loss: 0.003837, tar: 0.000026 
l0: 0.000003, l1: 0.000004, l2: 0.000025, l3: 0.000053, l4: 0.000159, l5: 0.000633, l6: 0.000903

[epoch: 812/1000, batch:   108/ 1052, ite: 213320] train loss: 0.003837, tar: 0.000026 
l0: 0.000015, l1: 0.000015, l2: 0.000018, l3: 0.000080, l4: 0.000345, l5: 0.000824, l6: 0.000980

[epoch: 812/1000, batch:   188/ 1052, ite: 213340] train loss: 0.003838, tar: 0.000026 
l0: 0.000008, l1: 0.000008, l2: 0.000045, l3: 0.000146, l4: 0.000369, l5: 0.001171, l6: 0.002084

[epoch: 812/1000, batch:   268/ 1052, ite: 213360] train loss: 0.003837, tar: 0.000026 
l0: 0.000014, l1: 0.000012, l2: 0.000032, l3: 0.000134, l4: 0.000308, l5: 0.000573, l6: 0.001561

[epoch: 812/1000, batch:   348/ 1052, ite: 213380] train loss: 0.003835, tar: 0.000026 
l0: 0.000041, l1: 0.000037, l2: 0.000080, l3: 0.000186, l4: 0.000608, l5: 0.001391, l6: 0.002286

[epoch: 812/1000, batch:   428/ 1052, ite: 213400] train loss: 0.003836, tar: 0.000026 
l0: 0.000003, l1: 0.000003, l2: 0.000018, l3: 0.000113, l4: 0.000568, l5: 0.000747, l6: 0.001689

[epoch: 812/1000, batch:   508/ 1052, ite: 213420] train loss: 0.003836, tar: 0.000026 
l0: 0.000010, l1: 0.000010, l2: 0.000031, l3: 0.000066, l4: 0.000253, l5: 0.000400, l6: 0.000857

[epoch: 812/1000, batch:   588/ 1052, ite: 213440] train loss: 0.003836, tar: 0.000026 
l0: 0.000012, l1: 0.000013, l2: 0.000018, l3: 0.000062, l4: 0.000366, l5: 0.000868, l6: 0.000871

[epoch: 812/1000, batch:   668/ 1052, ite: 213460] train loss: 0.003835, tar: 0.000026 
l0: 0.000038, l1: 0.000041, l2: 0.000040, l3: 0.000079, l4: 0.000305, l5: 0.000969, l6: 0.001220

[epoch: 812/1000, batch:   748/ 1052, ite: 213480] train loss: 0.003834, tar: 0.000026 
l0: 0.000054, l1: 0.000053, l2: 0.000069, l3: 0.000233, l4: 0.000455, l5: 0.000988, l6: 0.002171

[epoch: 812/1000, batch:   828/ 1052, ite: 213500] train loss: 0.003836, tar: 0.000026 
l0: 0.000016, l1: 0.000018, l2: 0.000032, l3: 0.000160, l4: 0.000439, l5: 0.001014, l6: 0.001537

[epoch: 812/1000, batch:   908/ 1052, ite: 213520] train loss: 0.003837, tar: 0.000027 
l0: 0.000058, l1: 0.000060, l2: 0.000105, l3: 0.000164, l4: 0.000519, l5: 0.001709, l6: 0.002817

[epoch: 812/1000, batch:   988/ 1052, ite: 213540] train loss: 0.003839, tar: 0.000027 
[Epoch 812/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000034, l1: 0.000037, l2: 0.000086, l3: 0.000341, l4: 0.001040, l5: 0.002050, l6: 0.002570

[epoch: 813/1000, batch:    16/ 1052, ite: 213560] train loss: 0.003840, tar: 0.000027 
l0: 0.000007, l1: 0.000007, l2: 0.000042, l3: 0.000135, l4: 0.000325, l5: 0.000720, l6: 0.001477

[epoch: 813/1000, batch:    96/ 1052, ite: 213580] train loss: 0.003840, tar: 0.000027 
l0: 0.000096, l1: 0.000099, l2: 0.000119, l3: 0.000239, l4: 0.000454, l5: 0.001215, l6: 0.003424

[epoch: 813/1000, batch:   176/ 1052, ite: 213600] train loss: 0.003840, tar: 0.000027 
l0: 0.000047, l1: 0.000050, l2: 0.000129, l3: 0.000310, l4: 0.000521, l5: 0.001648, l6: 0.001888

[epoch: 813/1000, batch:   256/ 1052, ite: 213620] train loss: 0.003840, tar: 0.000027 
l0: 0.000020, l1: 0.000019, l2: 0.000022, l3: 0.000071, l4: 0.000228, l5: 0.000617, l6: 0.001543

[epoch: 813/1000, batch:   336/ 1052, ite: 213640] train loss: 0.003839, tar: 0.000027 
l0: 0.000001, l1: 0.000001, l2: 0.000014, l3: 0.000099, l4: 0.000438, l5: 0.001165, l6: 0.001414

[epoch: 813/1000, batch:   416/ 1052, ite: 213660] train loss: 0.003837, tar: 0.000026 
l0: 0.000014, l1: 0.000014, l2: 0.000039, l3: 0.000147, l4: 0.000292, l5: 0.000896, l6: 0.001612

[epoch: 813/1000, batch:   496/ 1052, ite: 213680] train loss: 0.003838, tar: 0.000026 
l0: 0.000014, l1: 0.000015, l2: 0.000059, l3: 0.000210, l4: 0.000535, l5: 0.001626, l6: 0.001527

[epoch: 813/1000, batch:   576/ 1052, ite: 213700] train loss: 0.003838, tar: 0.000026 
l0: 0.000008, l1: 0.000010, l2: 0.000046, l3: 0.000246, l4: 0.000637, l5: 0.001400, l6: 0.002209

[epoch: 813/1000, batch:   656/ 1052, ite: 213720] train loss: 0.003837, tar: 0.000026 
l0: 0.000015, l1: 0.000018, l2: 0.000034, l3: 0.000095, l4: 0.000228, l5: 0.000705, l6: 0.001744

[epoch: 813/1000, batch:   736/ 1052, ite: 213740] train loss: 0.003838, tar: 0.000026 
l0: 0.000005, l1: 0.000007, l2: 0.000015, l3: 0.000103, l4: 0.000268, l5: 0.000671, l6: 0.000590

[epoch: 813/1000, batch:   816/ 1052, ite: 213760] train loss: 0.003836, tar: 0.000026 
l0: 0.000018, l1: 0.000020, l2: 0.000038, l3: 0.000122, l4: 0.000396, l5: 0.000834, l6: 0.001321

[epoch: 813/1000, batch:   896/ 1052, ite: 213780] train loss: 0.003833, tar: 0.000026 
l0: 0.000017, l1: 0.000019, l2: 0.000063, l3: 0.000157, l4: 0.000394, l5: 0.000869, l6: 0.001433

[epoch: 813/1000, batch:   976/ 1052, ite: 213800] train loss: 0.003836, tar: 0.000026 
[Epoch 813/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000009, l1: 0.000010, l2: 0.000041, l3: 0.000178, l4: 0.000463, l5: 0.000835, l6: 0.001762

[epoch: 814/1000, batch:     4/ 1052, ite: 213820] train loss: 0.003835, tar: 0.000026 
l0: 0.000004, l1: 0.000005, l2: 0.000024, l3: 0.000127, l4: 0.000352, l5: 0.000992, l6: 0.001472

[epoch: 814/1000, batch:    84/ 1052, ite: 213840] train loss: 0.003832, tar: 0.000026 
l0: 0.000035, l1: 0.000034, l2: 0.000055, l3: 0.000143, l4: 0.000279, l5: 0.000884, l6: 0.002327

[epoch: 814/1000, batch:   164/ 1052, ite: 213860] train loss: 0.003832, tar: 0.000026 
l0: 0.000039, l1: 0.000037, l2: 0.000071, l3: 0.000111, l4: 0.000214, l5: 0.000886, l6: 0.001106

[epoch: 814/1000, batch:   244/ 1052, ite: 213880] train loss: 0.003833, tar: 0.000026 
l0: 0.000055, l1: 0.000052, l2: 0.000067, l3: 0.000168, l4: 0.000517, l5: 0.001118, l6: 0.001435

[epoch: 814/1000, batch:   324/ 1052, ite: 213900] train loss: 0.003833, tar: 0.000026 
l0: 0.000045, l1: 0.000045, l2: 0.000120, l3: 0.000182, l4: 0.000404, l5: 0.001276, l6: 0.001984

[epoch: 814/1000, batch:   404/ 1052, ite: 213920] train loss: 0.003833, tar: 0.000026 
l0: 0.000017, l1: 0.000018, l2: 0.000089, l3: 0.000166, l4: 0.000412, l5: 0.000566, l6: 0.001940

[epoch: 814/1000, batch:   484/ 1052, ite: 213940] train loss: 0.003831, tar: 0.000026 
l0: 0.000012, l1: 0.000014, l2: 0.000050, l3: 0.000129, l4: 0.000391, l5: 0.001047, l6: 0.002129

[epoch: 814/1000, batch:   564/ 1052, ite: 213960] train loss: 0.003832, tar: 0.000026 
l0: 0.000017, l1: 0.000016, l2: 0.000052, l3: 0.000212, l4: 0.000414, l5: 0.000921, l6: 0.002167

[epoch: 814/1000, batch:   644/ 1052, ite: 213980] train loss: 0.003833, tar: 0.000026 
l0: 0.000001, l1: 0.000002, l2: 0.000014, l3: 0.000061, l4: 0.000168, l5: 0.000526, l6: 0.001288

[epoch: 814/1000, batch:   724/ 1052, ite: 214000] train loss: 0.003832, tar: 0.000026 
l0: 0.000031, l1: 0.000036, l2: 0.000043, l3: 0.000160, l4: 0.000458, l5: 0.000997, l6: 0.002007

[epoch: 814/1000, batch:   804/ 1052, ite: 214020] train loss: 0.003831, tar: 0.000026 
l0: 0.000060, l1: 0.000059, l2: 0.000111, l3: 0.000199, l4: 0.000489, l5: 0.002108, l6: 0.003704

[epoch: 814/1000, batch:   884/ 1052, ite: 214040] train loss: 0.003832, tar: 0.000026 
l0: 0.000011, l1: 0.000012, l2: 0.000033, l3: 0.000076, l4: 0.000333, l5: 0.000774, l6: 0.001263

[epoch: 814/1000, batch:   964/ 1052, ite: 214060] train loss: 0.003832, tar: 0.000026 
l0: 0.000020, l1: 0.000020, l2: 0.000085, l3: 0.000305, l4: 0.000618, l5: 0.000937, l6: 0.001502

[epoch: 814/1000, batch:  1044/ 1052, ite: 214080] train loss: 0.003834, tar: 0.000026 
[Epoch 814/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000004, l1: 0.000004, l2: 0.000041, l3: 0.000190, l4: 0.000537, l5: 0.001545, l6: 0.001957

[epoch: 815/1000, batch:    72/ 1052, ite: 214100] train loss: 0.003833, tar: 0.000026 
l0: 0.000029, l1: 0.000028, l2: 0.000039, l3: 0.000108, l4: 0.000345, l5: 0.000675, l6: 0.001263

[epoch: 815/1000, batch:   152/ 1052, ite: 214120] train loss: 0.003832, tar: 0.000026 
l0: 0.000010, l1: 0.000012, l2: 0.000066, l3: 0.000216, l4: 0.000606, l5: 0.001577, l6: 0.001947

[epoch: 815/1000, batch:   232/ 1052, ite: 214140] train loss: 0.003833, tar: 0.000026 
l0: 0.000017, l1: 0.000017, l2: 0.000040, l3: 0.000088, l4: 0.000321, l5: 0.000653, l6: 0.001323

[epoch: 815/1000, batch:   312/ 1052, ite: 214160] train loss: 0.003833, tar: 0.000026 
l0: 0.000049, l1: 0.000048, l2: 0.000132, l3: 0.000354, l4: 0.000732, l5: 0.001665, l6: 0.003092

[epoch: 815/1000, batch:   392/ 1052, ite: 214180] train loss: 0.003835, tar: 0.000026 
l0: 0.000023, l1: 0.000022, l2: 0.000043, l3: 0.000168, l4: 0.000426, l5: 0.000951, l6: 0.002174

[epoch: 815/1000, batch:   472/ 1052, ite: 214200] train loss: 0.003835, tar: 0.000026 
l0: 0.000017, l1: 0.000016, l2: 0.000067, l3: 0.000188, l4: 0.000453, l5: 0.001187, l6: 0.002837

[epoch: 815/1000, batch:   552/ 1052, ite: 214220] train loss: 0.003835, tar: 0.000026 
l0: 0.000013, l1: 0.000013, l2: 0.000041, l3: 0.000178, l4: 0.000468, l5: 0.000948, l6: 0.001653

[epoch: 815/1000, batch:   632/ 1052, ite: 214240] train loss: 0.003837, tar: 0.000026 
l0: 0.000015, l1: 0.000017, l2: 0.000084, l3: 0.000326, l4: 0.000752, l5: 0.001308, l6: 0.001922

[epoch: 815/1000, batch:   712/ 1052, ite: 214260] train loss: 0.003836, tar: 0.000026 
l0: 0.000034, l1: 0.000034, l2: 0.000160, l3: 0.000367, l4: 0.000634, l5: 0.002197, l6: 0.004436

[epoch: 815/1000, batch:   792/ 1052, ite: 214280] train loss: 0.003838, tar: 0.000026 
l0: 0.000052, l1: 0.000050, l2: 0.000060, l3: 0.000144, l4: 0.000423, l5: 0.001150, l6: 0.001950

[epoch: 815/1000, batch:   872/ 1052, ite: 214300] train loss: 0.003839, tar: 0.000026 
l0: 0.000018, l1: 0.000018, l2: 0.000052, l3: 0.000170, l4: 0.000353, l5: 0.000730, l6: 0.002034

[epoch: 815/1000, batch:   952/ 1052, ite: 214320] train loss: 0.003839, tar: 0.000026 
l0: 0.000033, l1: 0.000038, l2: 0.000034, l3: 0.000057, l4: 0.000195, l5: 0.000321, l6: 0.000793

[epoch: 815/1000, batch:  1032/ 1052, ite: 214340] train loss: 0.003838, tar: 0.000026 
[Epoch 815/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000046, l1: 0.000049, l2: 0.000115, l3: 0.000292, l4: 0.000810, l5: 0.001251, l6: 0.002879

[epoch: 816/1000, batch:    60/ 1052, ite: 214360] train loss: 0.003836, tar: 0.000026 
l0: 0.000007, l1: 0.000007, l2: 0.000053, l3: 0.000156, l4: 0.000455, l5: 0.000893, l6: 0.002167

[epoch: 816/1000, batch:   140/ 1052, ite: 214380] train loss: 0.003834, tar: 0.000026 
l0: 0.000008, l1: 0.000009, l2: 0.000032, l3: 0.000112, l4: 0.000270, l5: 0.000722, l6: 0.002070

[epoch: 816/1000, batch:   220/ 1052, ite: 214400] train loss: 0.003835, tar: 0.000026 
l0: 0.000019, l1: 0.000019, l2: 0.000053, l3: 0.000115, l4: 0.000532, l5: 0.001436, l6: 0.002669

[epoch: 816/1000, batch:   300/ 1052, ite: 214420] train loss: 0.003835, tar: 0.000026 
l0: 0.000049, l1: 0.000049, l2: 0.000085, l3: 0.000259, l4: 0.000595, l5: 0.001342, l6: 0.001877

[epoch: 816/1000, batch:   380/ 1052, ite: 214440] train loss: 0.003834, tar: 0.000026 
l0: 0.000004, l1: 0.000003, l2: 0.000048, l3: 0.000132, l4: 0.000452, l5: 0.001054, l6: 0.001280

[epoch: 816/1000, batch:   460/ 1052, ite: 214460] train loss: 0.003835, tar: 0.000026 
l0: 0.000025, l1: 0.000025, l2: 0.000061, l3: 0.000158, l4: 0.000317, l5: 0.000919, l6: 0.001050

[epoch: 816/1000, batch:   540/ 1052, ite: 214480] train loss: 0.003835, tar: 0.000026 
l0: 0.000000, l1: 0.000001, l2: 0.000026, l3: 0.000179, l4: 0.000287, l5: 0.000858, l6: 0.001008

[epoch: 816/1000, batch:   620/ 1052, ite: 214500] train loss: 0.003834, tar: 0.000026 
l0: 0.000021, l1: 0.000023, l2: 0.000029, l3: 0.000163, l4: 0.000377, l5: 0.000833, l6: 0.002269

[epoch: 816/1000, batch:   700/ 1052, ite: 214520] train loss: 0.003836, tar: 0.000026 
l0: 0.000008, l1: 0.000009, l2: 0.000033, l3: 0.000113, l4: 0.000299, l5: 0.000675, l6: 0.001385

[epoch: 816/1000, batch:   780/ 1052, ite: 214540] train loss: 0.003834, tar: 0.000026 
l0: 0.000047, l1: 0.000050, l2: 0.000037, l3: 0.000112, l4: 0.000417, l5: 0.000654, l6: 0.001453

[epoch: 816/1000, batch:   860/ 1052, ite: 214560] train loss: 0.003835, tar: 0.000026 
l0: 0.000007, l1: 0.000008, l2: 0.000037, l3: 0.000118, l4: 0.000349, l5: 0.000896, l6: 0.001253

[epoch: 816/1000, batch:   940/ 1052, ite: 214580] train loss: 0.003838, tar: 0.000026 
l0: 0.000027, l1: 0.000029, l2: 0.000100, l3: 0.000207, l4: 0.000369, l5: 0.001428, l6: 0.002932

[epoch: 816/1000, batch:  1020/ 1052, ite: 214600] train loss: 0.003840, tar: 0.000026 
[Epoch 816/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000035, l1: 0.000032, l2: 0.000050, l3: 0.000198, l4: 0.000464, l5: 0.000539, l6: 0.001114

[epoch: 817/1000, batch:    48/ 1052, ite: 214620] train loss: 0.003838, tar: 0.000026 
l0: 0.000019, l1: 0.000020, l2: 0.000031, l3: 0.000153, l4: 0.000413, l5: 0.000797, l6: 0.001410

[epoch: 817/1000, batch:   128/ 1052, ite: 214640] train loss: 0.003838, tar: 0.000026 
l0: 0.000009, l1: 0.000008, l2: 0.000020, l3: 0.000106, l4: 0.000213, l5: 0.000398, l6: 0.000789

[epoch: 817/1000, batch:   208/ 1052, ite: 214660] train loss: 0.003836, tar: 0.000026 
l0: 0.000031, l1: 0.000032, l2: 0.000056, l3: 0.000149, l4: 0.000436, l5: 0.001154, l6: 0.002005

[epoch: 817/1000, batch:   288/ 1052, ite: 214680] train loss: 0.003837, tar: 0.000026 
l0: 0.000019, l1: 0.000019, l2: 0.000061, l3: 0.000197, l4: 0.000594, l5: 0.001384, l6: 0.002197

[epoch: 817/1000, batch:   368/ 1052, ite: 214700] train loss: 0.003838, tar: 0.000026 
l0: 0.000025, l1: 0.000026, l2: 0.000089, l3: 0.000230, l4: 0.000550, l5: 0.001899, l6: 0.003282

[epoch: 817/1000, batch:   448/ 1052, ite: 214720] train loss: 0.003840, tar: 0.000027 
l0: 0.000008, l1: 0.000008, l2: 0.000036, l3: 0.000137, l4: 0.000320, l5: 0.000780, l6: 0.000969

[epoch: 817/1000, batch:   528/ 1052, ite: 214740] train loss: 0.003838, tar: 0.000026 
l0: 0.000015, l1: 0.000015, l2: 0.000045, l3: 0.000115, l4: 0.000433, l5: 0.001028, l6: 0.001457

[epoch: 817/1000, batch:   608/ 1052, ite: 214760] train loss: 0.003840, tar: 0.000026 
l0: 0.000047, l1: 0.000046, l2: 0.000070, l3: 0.000118, l4: 0.000502, l5: 0.001241, l6: 0.001293

[epoch: 817/1000, batch:   688/ 1052, ite: 214780] train loss: 0.003841, tar: 0.000026 
l0: 0.000015, l1: 0.000014, l2: 0.000035, l3: 0.000186, l4: 0.000538, l5: 0.000814, l6: 0.002227

[epoch: 817/1000, batch:   768/ 1052, ite: 214800] train loss: 0.003840, tar: 0.000027 
l0: 0.000033, l1: 0.000033, l2: 0.000071, l3: 0.000197, l4: 0.000566, l5: 0.001223, l6: 0.003041

[epoch: 817/1000, batch:   848/ 1052, ite: 214820] train loss: 0.003840, tar: 0.000027 
l0: 0.000021, l1: 0.000021, l2: 0.000090, l3: 0.000211, l4: 0.000579, l5: 0.001166, l6: 0.002544

[epoch: 817/1000, batch:   928/ 1052, ite: 214840] train loss: 0.003839, tar: 0.000026 
l0: 0.000068, l1: 0.000064, l2: 0.000135, l3: 0.000273, l4: 0.000661, l5: 0.002364, l6: 0.003872

[epoch: 817/1000, batch:  1008/ 1052, ite: 214860] train loss: 0.003841, tar: 0.000027 
[Epoch 817/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000017, l1: 0.000019, l2: 0.000071, l3: 0.000104, l4: 0.000356, l5: 0.001295, l6: 0.002329

[epoch: 818/1000, batch:    36/ 1052, ite: 214880] train loss: 0.003841, tar: 0.000026 
l0: 0.000025, l1: 0.000025, l2: 0.000051, l3: 0.000186, l4: 0.000354, l5: 0.000951, l6: 0.001660

[epoch: 818/1000, batch:   116/ 1052, ite: 214900] train loss: 0.003840, tar: 0.000026 
l0: 0.000044, l1: 0.000046, l2: 0.000041, l3: 0.000133, l4: 0.000405, l5: 0.001039, l6: 0.001999

[epoch: 818/1000, batch:   196/ 1052, ite: 214920] train loss: 0.003838, tar: 0.000026 
l0: 0.000003, l1: 0.000003, l2: 0.000025, l3: 0.000139, l4: 0.000483, l5: 0.001417, l6: 0.002987

[epoch: 818/1000, batch:   276/ 1052, ite: 214940] train loss: 0.003839, tar: 0.000027 
l0: 0.000008, l1: 0.000009, l2: 0.000042, l3: 0.000126, l4: 0.000354, l5: 0.000737, l6: 0.001176

[epoch: 818/1000, batch:   356/ 1052, ite: 214960] train loss: 0.003838, tar: 0.000027 
l0: 0.000040, l1: 0.000040, l2: 0.000065, l3: 0.000259, l4: 0.000454, l5: 0.001760, l6: 0.001750

[epoch: 818/1000, batch:   436/ 1052, ite: 214980] train loss: 0.003837, tar: 0.000027 
l0: 0.000026, l1: 0.000026, l2: 0.000109, l3: 0.000218, l4: 0.000498, l5: 0.000580, l6: 0.002502

[epoch: 818/1000, batch:   516/ 1052, ite: 215000] train loss: 0.003838, tar: 0.000026 
l0: 0.000022, l1: 0.000020, l2: 0.000104, l3: 0.000264, l4: 0.000494, l5: 0.001295, l6: 0.002312

[epoch: 818/1000, batch:   596/ 1052, ite: 215020] train loss: 0.003835, tar: 0.000026 
l0: 0.000079, l1: 0.000085, l2: 0.000165, l3: 0.000293, l4: 0.000661, l5: 0.002707, l6: 0.004469

[epoch: 818/1000, batch:   676/ 1052, ite: 215040] train loss: 0.003838, tar: 0.000026 
l0: 0.000014, l1: 0.000014, l2: 0.000040, l3: 0.000119, l4: 0.000318, l5: 0.000737, l6: 0.001857

[epoch: 818/1000, batch:   756/ 1052, ite: 215060] train loss: 0.003840, tar: 0.000027 
l0: 0.000015, l1: 0.000016, l2: 0.000034, l3: 0.000076, l4: 0.000269, l5: 0.000538, l6: 0.000696

[epoch: 818/1000, batch:   836/ 1052, ite: 215080] train loss: 0.003839, tar: 0.000027 
l0: 0.000076, l1: 0.000072, l2: 0.000171, l3: 0.000373, l4: 0.000842, l5: 0.001899, l6: 0.004051

[epoch: 818/1000, batch:   916/ 1052, ite: 215100] train loss: 0.003840, tar: 0.000027 
l0: 0.000051, l1: 0.000053, l2: 0.000123, l3: 0.000339, l4: 0.001011, l5: 0.004321, l6: 0.005981

[epoch: 818/1000, batch:   996/ 1052, ite: 215120] train loss: 0.003840, tar: 0.000027 
[Epoch 818/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000017, l1: 0.000016, l2: 0.000053, l3: 0.000159, l4: 0.000514, l5: 0.000945, l6: 0.002016

[epoch: 819/1000, batch:    24/ 1052, ite: 215140] train loss: 0.003841, tar: 0.000027 
l0: 0.000017, l1: 0.000015, l2: 0.000074, l3: 0.000128, l4: 0.000506, l5: 0.001231, l6: 0.001370

[epoch: 819/1000, batch:   104/ 1052, ite: 215160] train loss: 0.003841, tar: 0.000027 
l0: 0.000002, l1: 0.000002, l2: 0.000024, l3: 0.000087, l4: 0.000227, l5: 0.000577, l6: 0.000974

[epoch: 819/1000, batch:   184/ 1052, ite: 215180] train loss: 0.003840, tar: 0.000027 
l0: 0.000022, l1: 0.000024, l2: 0.000024, l3: 0.000090, l4: 0.000282, l5: 0.001270, l6: 0.001412

[epoch: 819/1000, batch:   264/ 1052, ite: 215200] train loss: 0.003841, tar: 0.000027 
l0: 0.000029, l1: 0.000029, l2: 0.000056, l3: 0.000232, l4: 0.000689, l5: 0.001450, l6: 0.002401

[epoch: 819/1000, batch:   344/ 1052, ite: 215220] train loss: 0.003844, tar: 0.000027 
l0: 0.000030, l1: 0.000027, l2: 0.000052, l3: 0.000138, l4: 0.000357, l5: 0.000902, l6: 0.001761

[epoch: 819/1000, batch:   424/ 1052, ite: 215240] train loss: 0.003845, tar: 0.000027 
l0: 0.000024, l1: 0.000024, l2: 0.000053, l3: 0.000120, l4: 0.000214, l5: 0.000534, l6: 0.001705

[epoch: 819/1000, batch:   504/ 1052, ite: 215260] train loss: 0.003845, tar: 0.000027 
l0: 0.000003, l1: 0.000004, l2: 0.000027, l3: 0.000063, l4: 0.000287, l5: 0.000707, l6: 0.001600

[epoch: 819/1000, batch:   584/ 1052, ite: 215280] train loss: 0.003846, tar: 0.000027 
l0: 0.000026, l1: 0.000028, l2: 0.000070, l3: 0.000384, l4: 0.000707, l5: 0.001624, l6: 0.003389

[epoch: 819/1000, batch:   664/ 1052, ite: 215300] train loss: 0.003846, tar: 0.000027 
l0: 0.000044, l1: 0.000044, l2: 0.000080, l3: 0.000224, l4: 0.000562, l5: 0.001655, l6: 0.002859

[epoch: 819/1000, batch:   744/ 1052, ite: 215320] train loss: 0.003844, tar: 0.000027 
l0: 0.000014, l1: 0.000014, l2: 0.000039, l3: 0.000084, l4: 0.000253, l5: 0.000519, l6: 0.001562

[epoch: 819/1000, batch:   824/ 1052, ite: 215340] train loss: 0.003843, tar: 0.000027 
l0: 0.000027, l1: 0.000025, l2: 0.000066, l3: 0.000211, l4: 0.000577, l5: 0.001395, l6: 0.002134

[epoch: 819/1000, batch:   904/ 1052, ite: 215360] train loss: 0.003841, tar: 0.000027 
l0: 0.000014, l1: 0.000015, l2: 0.000025, l3: 0.000081, l4: 0.000212, l5: 0.000395, l6: 0.001335

[epoch: 819/1000, batch:   984/ 1052, ite: 215380] train loss: 0.003840, tar: 0.000027 
[Epoch 819/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000013, l1: 0.000015, l2: 0.000029, l3: 0.000116, l4: 0.000370, l5: 0.001011, l6: 0.000861

[epoch: 820/1000, batch:    12/ 1052, ite: 215400] train loss: 0.003841, tar: 0.000027 
l0: 0.000010, l1: 0.000012, l2: 0.000017, l3: 0.000113, l4: 0.000303, l5: 0.001021, l6: 0.001895

[epoch: 820/1000, batch:    92/ 1052, ite: 215420] train loss: 0.003841, tar: 0.000027 
l0: 0.000063, l1: 0.000066, l2: 0.000118, l3: 0.000260, l4: 0.000654, l5: 0.001326, l6: 0.002112

[epoch: 820/1000, batch:   172/ 1052, ite: 215440] train loss: 0.003841, tar: 0.000027 
l0: 0.000002, l1: 0.000003, l2: 0.000029, l3: 0.000147, l4: 0.000526, l5: 0.001255, l6: 0.002048

[epoch: 820/1000, batch:   252/ 1052, ite: 215460] train loss: 0.003840, tar: 0.000027 
l0: 0.000005, l1: 0.000005, l2: 0.000018, l3: 0.000077, l4: 0.000214, l5: 0.000698, l6: 0.001050

[epoch: 820/1000, batch:   332/ 1052, ite: 215480] train loss: 0.003842, tar: 0.000027 
l0: 0.000002, l1: 0.000002, l2: 0.000020, l3: 0.000099, l4: 0.000565, l5: 0.001190, l6: 0.001426

[epoch: 820/1000, batch:   412/ 1052, ite: 215500] train loss: 0.003841, tar: 0.000027 
l0: 0.000093, l1: 0.000091, l2: 0.000118, l3: 0.000142, l4: 0.000464, l5: 0.001303, l6: 0.002508

[epoch: 820/1000, batch:   492/ 1052, ite: 215520] train loss: 0.003842, tar: 0.000027 
l0: 0.000001, l1: 0.000001, l2: 0.000004, l3: 0.000061, l4: 0.000372, l5: 0.000710, l6: 0.001342

[epoch: 820/1000, batch:   572/ 1052, ite: 215540] train loss: 0.003845, tar: 0.000027 
l0: 0.000016, l1: 0.000017, l2: 0.000025, l3: 0.000088, l4: 0.000353, l5: 0.000860, l6: 0.001853

[epoch: 820/1000, batch:   652/ 1052, ite: 215560] train loss: 0.003845, tar: 0.000027 
l0: 0.000005, l1: 0.000008, l2: 0.000016, l3: 0.000096, l4: 0.000382, l5: 0.000662, l6: 0.000898

[epoch: 820/1000, batch:   732/ 1052, ite: 215580] train loss: 0.003844, tar: 0.000027 
l0: 0.000016, l1: 0.000016, l2: 0.000037, l3: 0.000097, l4: 0.000399, l5: 0.001089, l6: 0.001549

[epoch: 820/1000, batch:   812/ 1052, ite: 215600] train loss: 0.003843, tar: 0.000027 
l0: 0.000044, l1: 0.000045, l2: 0.000109, l3: 0.000368, l4: 0.000783, l5: 0.001297, l6: 0.003080

[epoch: 820/1000, batch:   892/ 1052, ite: 215620] train loss: 0.003844, tar: 0.000027 
l0: 0.000001, l1: 0.000001, l2: 0.000027, l3: 0.000111, l4: 0.000622, l5: 0.001545, l6: 0.001972

[epoch: 820/1000, batch:   972/ 1052, ite: 215640] train loss: 0.003843, tar: 0.000027 
l0: 0.000027, l1: 0.000028, l2: 0.000089, l3: 0.000244, l4: 0.000499, l5: 0.001169, l6: 0.002213

[epoch: 820/1000, batch:  1052/ 1052, ite: 215660] train loss: 0.003842, tar: 0.000027 
[Epoch 820/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000007, l1: 0.000007, l2: 0.000063, l3: 0.000217, l4: 0.000656, l5: 0.001015, l6: 0.002156

[epoch: 821/1000, batch:    80/ 1052, ite: 215680] train loss: 0.003841, tar: 0.000027 
l0: 0.000177, l1: 0.000188, l2: 0.000191, l3: 0.000286, l4: 0.000283, l5: 0.000959, l6: 0.001487

[epoch: 821/1000, batch:   160/ 1052, ite: 215700] train loss: 0.003841, tar: 0.000027 
l0: 0.000027, l1: 0.000031, l2: 0.000060, l3: 0.000148, l4: 0.000476, l5: 0.000544, l6: 0.001367

[epoch: 821/1000, batch:   240/ 1052, ite: 215720] train loss: 0.003840, tar: 0.000027 
l0: 0.000028, l1: 0.000028, l2: 0.000067, l3: 0.000232, l4: 0.000440, l5: 0.000957, l6: 0.002681

[epoch: 821/1000, batch:   320/ 1052, ite: 215740] train loss: 0.003838, tar: 0.000027 
l0: 0.000085, l1: 0.000092, l2: 0.000215, l3: 0.000438, l4: 0.000755, l5: 0.002302, l6: 0.004671

[epoch: 821/1000, batch:   400/ 1052, ite: 215760] train loss: 0.003839, tar: 0.000027 
l0: 0.000022, l1: 0.000022, l2: 0.000091, l3: 0.000233, l4: 0.000430, l5: 0.000806, l6: 0.002250

[epoch: 821/1000, batch:   480/ 1052, ite: 215780] train loss: 0.003839, tar: 0.000027 
l0: 0.000008, l1: 0.000008, l2: 0.000025, l3: 0.000048, l4: 0.000469, l5: 0.000617, l6: 0.001355

[epoch: 821/1000, batch:   560/ 1052, ite: 215800] train loss: 0.003837, tar: 0.000027 
l0: 0.000005, l1: 0.000005, l2: 0.000030, l3: 0.000101, l4: 0.000363, l5: 0.000791, l6: 0.001757

[epoch: 821/1000, batch:   640/ 1052, ite: 215820] train loss: 0.003838, tar: 0.000027 
l0: 0.000049, l1: 0.000051, l2: 0.000099, l3: 0.000204, l4: 0.000442, l5: 0.001126, l6: 0.002575

[epoch: 821/1000, batch:   720/ 1052, ite: 215840] train loss: 0.003838, tar: 0.000027 
l0: 0.000008, l1: 0.000008, l2: 0.000097, l3: 0.000223, l4: 0.000611, l5: 0.001126, l6: 0.002222

[epoch: 821/1000, batch:   800/ 1052, ite: 215860] train loss: 0.003838, tar: 0.000027 
l0: 0.000029, l1: 0.000031, l2: 0.000056, l3: 0.000124, l4: 0.000373, l5: 0.000960, l6: 0.002686

[epoch: 821/1000, batch:   880/ 1052, ite: 215880] train loss: 0.003840, tar: 0.000027 
l0: 0.000028, l1: 0.000028, l2: 0.000062, l3: 0.000236, l4: 0.000724, l5: 0.002361, l6: 0.004023

[epoch: 821/1000, batch:   960/ 1052, ite: 215900] train loss: 0.003840, tar: 0.000027 
l0: 0.000022, l1: 0.000023, l2: 0.000061, l3: 0.000295, l4: 0.000589, l5: 0.000780, l6: 0.002259

[epoch: 821/1000, batch:  1040/ 1052, ite: 215920] train loss: 0.003842, tar: 0.000027 
[Epoch 821/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000013, l1: 0.000012, l2: 0.000050, l3: 0.000122, l4: 0.000442, l5: 0.001070, l6: 0.001082

[epoch: 822/1000, batch:    68/ 1052, ite: 215940] train loss: 0.003842, tar: 0.000027 
l0: 0.000022, l1: 0.000026, l2: 0.000086, l3: 0.000272, l4: 0.000841, l5: 0.001439, l6: 0.003600

[epoch: 822/1000, batch:   148/ 1052, ite: 215960] train loss: 0.003843, tar: 0.000027 
l0: 0.000006, l1: 0.000006, l2: 0.000047, l3: 0.000146, l4: 0.000550, l5: 0.000655, l6: 0.001909

[epoch: 822/1000, batch:   228/ 1052, ite: 215980] train loss: 0.003843, tar: 0.000027 
l0: 0.000025, l1: 0.000026, l2: 0.000078, l3: 0.000172, l4: 0.000403, l5: 0.001023, l6: 0.002368

[epoch: 822/1000, batch:   308/ 1052, ite: 216000] train loss: 0.003843, tar: 0.000027 
l0: 0.000019, l1: 0.000019, l2: 0.000045, l3: 0.000127, l4: 0.000369, l5: 0.000604, l6: 0.001998

[epoch: 822/1000, batch:   388/ 1052, ite: 216020] train loss: 0.003840, tar: 0.000027 
l0: 0.000008, l1: 0.000011, l2: 0.000024, l3: 0.000080, l4: 0.000323, l5: 0.000743, l6: 0.001225

[epoch: 822/1000, batch:   468/ 1052, ite: 216040] train loss: 0.003839, tar: 0.000027 
l0: 0.000018, l1: 0.000020, l2: 0.000047, l3: 0.000159, l4: 0.000415, l5: 0.000960, l6: 0.001225

[epoch: 822/1000, batch:   548/ 1052, ite: 216060] train loss: 0.003839, tar: 0.000027 
l0: 0.000019, l1: 0.000021, l2: 0.000046, l3: 0.000196, l4: 0.000321, l5: 0.000655, l6: 0.001197

[epoch: 822/1000, batch:   628/ 1052, ite: 216080] train loss: 0.003837, tar: 0.000027 
l0: 0.000025, l1: 0.000025, l2: 0.000079, l3: 0.000161, l4: 0.000367, l5: 0.001342, l6: 0.001245

[epoch: 822/1000, batch:   708/ 1052, ite: 216100] train loss: 0.003838, tar: 0.000027 
l0: 0.000030, l1: 0.000032, l2: 0.000072, l3: 0.000332, l4: 0.000770, l5: 0.001791, l6: 0.002497

[epoch: 822/1000, batch:   788/ 1052, ite: 216120] train loss: 0.003841, tar: 0.000027 
l0: 0.000012, l1: 0.000011, l2: 0.000112, l3: 0.000379, l4: 0.000847, l5: 0.001221, l6: 0.002196

[epoch: 822/1000, batch:   868/ 1052, ite: 216140] train loss: 0.003841, tar: 0.000027 
l0: 0.000110, l1: 0.000106, l2: 0.000193, l3: 0.000436, l4: 0.000781, l5: 0.001251, l6: 0.002120

[epoch: 822/1000, batch:   948/ 1052, ite: 216160] train loss: 0.003841, tar: 0.000027 
l0: 0.000018, l1: 0.000020, l2: 0.000032, l3: 0.000094, l4: 0.000376, l5: 0.000957, l6: 0.001486

[epoch: 822/1000, batch:  1028/ 1052, ite: 216180] train loss: 0.003841, tar: 0.000027 
[Epoch 822/1000] Test loss: 0.026, Test target loss: 0.005
l0: 0.000020, l1: 0.000019, l2: 0.000102, l3: 0.000255, l4: 0.000530, l5: 0.000991, l6: 0.001770

[epoch: 823/1000, batch:    56/ 1052, ite: 216200] train loss: 0.003841, tar: 0.000027 
l0: 0.000008, l1: 0.000008, l2: 0.000053, l3: 0.000235, l4: 0.000384, l5: 0.001007, l6: 0.001749

[epoch: 823/1000, batch:   136/ 1052, ite: 216220] train loss: 0.003840, tar: 0.000027 
l0: 0.000012, l1: 0.000012, l2: 0.000022, l3: 0.000089, l4: 0.000370, l5: 0.000587, l6: 0.001212

[epoch: 823/1000, batch:   216/ 1052, ite: 216240] train loss: 0.003841, tar: 0.000027 
l0: 0.000012, l1: 0.000014, l2: 0.000027, l3: 0.000115, l4: 0.000301, l5: 0.000461, l6: 0.001225

[epoch: 823/1000, batch:   296/ 1052, ite: 216260] train loss: 0.003840, tar: 0.000027 
l0: 0.000003, l1: 0.000003, l2: 0.000011, l3: 0.000081, l4: 0.000395, l5: 0.000445, l6: 0.000927

[epoch: 823/1000, batch:   376/ 1052, ite: 216280] train loss: 0.003838, tar: 0.000027 
l0: 0.000008, l1: 0.000008, l2: 0.000035, l3: 0.000155, l4: 0.000317, l5: 0.000929, l6: 0.001441

[epoch: 823/1000, batch:   456/ 1052, ite: 216300] train loss: 0.003838, tar: 0.000027 
l0: 0.000018, l1: 0.000017, l2: 0.000044, l3: 0.000142, l4: 0.000264, l5: 0.000927, l6: 0.001390

[epoch: 823/1000, batch:   536/ 1052, ite: 216320] train loss: 0.003838, tar: 0.000027 
l0: 0.000034, l1: 0.000032, l2: 0.000067, l3: 0.000143, l4: 0.000350, l5: 0.000839, l6: 0.001529

[epoch: 823/1000, batch:   616/ 1052, ite: 216340] train loss: 0.003838, tar: 0.000027 
l0: 0.000008, l1: 0.000008, l2: 0.000034, l3: 0.000093, l4: 0.000451, l5: 0.000659, l6: 0.001197

[epoch: 823/1000, batch:   696/ 1052, ite: 216360] train loss: 0.003840, tar: 0.000027 
l0: 0.000015, l1: 0.000015, l2: 0.000029, l3: 0.000103, l4: 0.000319, l5: 0.001007, l6: 0.001416

[epoch: 823/1000, batch:   776/ 1052, ite: 216380] train loss: 0.003840, tar: 0.000027 
l0: 0.000073, l1: 0.000076, l2: 0.000051, l3: 0.000113, l4: 0.000394, l5: 0.000982, l6: 0.001139

[epoch: 823/1000, batch:   856/ 1052, ite: 216400] train loss: 0.003838, tar: 0.000027 
l0: 0.000007, l1: 0.000006, l2: 0.000032, l3: 0.000124, l4: 0.000389, l5: 0.000994, l6: 0.001073

[epoch: 823/1000, batch:   936/ 1052, ite: 216420] train loss: 0.003839, tar: 0.000027 
l0: 0.000006, l1: 0.000006, l2: 0.000031, l3: 0.000094, l4: 0.000295, l5: 0.000584, l6: 0.001407

[epoch: 823/1000, batch:  1016/ 1052, ite: 216440] train loss: 0.003839, tar: 0.000027 
[Epoch 823/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000055, l1: 0.000057, l2: 0.000126, l3: 0.000219, l4: 0.000596, l5: 0.001475, l6: 0.002753

[epoch: 824/1000, batch:    44/ 1052, ite: 216460] train loss: 0.003840, tar: 0.000027 
l0: 0.000010, l1: 0.000010, l2: 0.000040, l3: 0.000187, l4: 0.000495, l5: 0.001161, l6: 0.001301

[epoch: 824/1000, batch:   124/ 1052, ite: 216480] train loss: 0.003839, tar: 0.000027 
l0: 0.000008, l1: 0.000010, l2: 0.000060, l3: 0.000166, l4: 0.000748, l5: 0.001321, l6: 0.002054

[epoch: 824/1000, batch:   204/ 1052, ite: 216500] train loss: 0.003838, tar: 0.000027 
l0: 0.000013, l1: 0.000014, l2: 0.000052, l3: 0.000176, l4: 0.000393, l5: 0.001035, l6: 0.002628

[epoch: 824/1000, batch:   284/ 1052, ite: 216520] train loss: 0.003839, tar: 0.000027 
l0: 0.000032, l1: 0.000034, l2: 0.000032, l3: 0.000072, l4: 0.000276, l5: 0.000682, l6: 0.001355

[epoch: 824/1000, batch:   364/ 1052, ite: 216540] train loss: 0.003838, tar: 0.000027 
l0: 0.000010, l1: 0.000009, l2: 0.000090, l3: 0.000221, l4: 0.000333, l5: 0.000777, l6: 0.001360

[epoch: 824/1000, batch:   444/ 1052, ite: 216560] train loss: 0.003836, tar: 0.000027 
l0: 0.000036, l1: 0.000038, l2: 0.000046, l3: 0.000126, l4: 0.000297, l5: 0.000669, l6: 0.001183

[epoch: 824/1000, batch:   524/ 1052, ite: 216580] train loss: 0.003836, tar: 0.000027 
l0: 0.000014, l1: 0.000017, l2: 0.000029, l3: 0.000105, l4: 0.000284, l5: 0.000305, l6: 0.000982

[epoch: 824/1000, batch:   604/ 1052, ite: 216600] train loss: 0.003836, tar: 0.000027 
l0: 0.000014, l1: 0.000013, l2: 0.000045, l3: 0.000136, l4: 0.000459, l5: 0.001348, l6: 0.002988

[epoch: 824/1000, batch:   684/ 1052, ite: 216620] train loss: 0.003835, tar: 0.000027 
l0: 0.000102, l1: 0.000103, l2: 0.000176, l3: 0.000231, l4: 0.000633, l5: 0.001212, l6: 0.002632

[epoch: 824/1000, batch:   764/ 1052, ite: 216640] train loss: 0.003836, tar: 0.000027 
l0: 0.000007, l1: 0.000007, l2: 0.000031, l3: 0.000208, l4: 0.000600, l5: 0.001195, l6: 0.001920

[epoch: 824/1000, batch:   844/ 1052, ite: 216660] train loss: 0.003836, tar: 0.000027 
l0: 0.000026, l1: 0.000031, l2: 0.000038, l3: 0.000110, l4: 0.000745, l5: 0.001181, l6: 0.002311

[epoch: 824/1000, batch:   924/ 1052, ite: 216680] train loss: 0.003835, tar: 0.000027 
l0: 0.000054, l1: 0.000058, l2: 0.000092, l3: 0.000257, l4: 0.000617, l5: 0.001770, l6: 0.002390

[epoch: 824/1000, batch:  1004/ 1052, ite: 216700] train loss: 0.003836, tar: 0.000027 
[Epoch 824/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000008, l1: 0.000009, l2: 0.000035, l3: 0.000085, l4: 0.000199, l5: 0.000593, l6: 0.000817

[epoch: 825/1000, batch:    32/ 1052, ite: 216720] train loss: 0.003838, tar: 0.000027 
l0: 0.000056, l1: 0.000053, l2: 0.000091, l3: 0.000193, l4: 0.000670, l5: 0.001269, l6: 0.002488

[epoch: 825/1000, batch:   112/ 1052, ite: 216740] train loss: 0.003838, tar: 0.000027 
l0: 0.000000, l1: 0.000000, l2: 0.000008, l3: 0.000070, l4: 0.000306, l5: 0.000495, l6: 0.001044

[epoch: 825/1000, batch:   192/ 1052, ite: 216760] train loss: 0.003837, tar: 0.000027 
l0: 0.000029, l1: 0.000029, l2: 0.000068, l3: 0.000208, l4: 0.000419, l5: 0.000723, l6: 0.002568

[epoch: 825/1000, batch:   272/ 1052, ite: 216780] train loss: 0.003836, tar: 0.000027 
l0: 0.000033, l1: 0.000038, l2: 0.000080, l3: 0.000289, l4: 0.000903, l5: 0.002499, l6: 0.003308

[epoch: 825/1000, batch:   352/ 1052, ite: 216800] train loss: 0.003839, tar: 0.000027 
l0: 0.000022, l1: 0.000021, l2: 0.000067, l3: 0.000254, l4: 0.000507, l5: 0.001084, l6: 0.001494

[epoch: 825/1000, batch:   432/ 1052, ite: 216820] train loss: 0.003838, tar: 0.000027 
l0: 0.000013, l1: 0.000014, l2: 0.000036, l3: 0.000071, l4: 0.000202, l5: 0.001206, l6: 0.001382

[epoch: 825/1000, batch:   512/ 1052, ite: 216840] train loss: 0.003836, tar: 0.000027 
l0: 0.000006, l1: 0.000007, l2: 0.000021, l3: 0.000067, l4: 0.000248, l5: 0.000505, l6: 0.000951

[epoch: 825/1000, batch:   592/ 1052, ite: 216860] train loss: 0.003837, tar: 0.000027 
l0: 0.000027, l1: 0.000026, l2: 0.000085, l3: 0.000232, l4: 0.000646, l5: 0.001324, l6: 0.002074

[epoch: 825/1000, batch:   672/ 1052, ite: 216880] train loss: 0.003839, tar: 0.000027 
l0: 0.000007, l1: 0.000008, l2: 0.000019, l3: 0.000107, l4: 0.000461, l5: 0.000921, l6: 0.001024

[epoch: 825/1000, batch:   752/ 1052, ite: 216900] train loss: 0.003839, tar: 0.000027 
l0: 0.000008, l1: 0.000010, l2: 0.000023, l3: 0.000169, l4: 0.000430, l5: 0.001188, l6: 0.001765

[epoch: 825/1000, batch:   832/ 1052, ite: 216920] train loss: 0.003838, tar: 0.000027 
l0: 0.000046, l1: 0.000044, l2: 0.000076, l3: 0.000189, l4: 0.000441, l5: 0.001801, l6: 0.003830

[epoch: 825/1000, batch:   912/ 1052, ite: 216940] train loss: 0.003839, tar: 0.000027 
l0: 0.000024, l1: 0.000025, l2: 0.000064, l3: 0.000156, l4: 0.000415, l5: 0.001252, l6: 0.002203

[epoch: 825/1000, batch:   992/ 1052, ite: 216960] train loss: 0.003839, tar: 0.000027 
[Epoch 825/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000003, l1: 0.000004, l2: 0.000029, l3: 0.000098, l4: 0.000535, l5: 0.001110, l6: 0.001756

[epoch: 826/1000, batch:    20/ 1052, ite: 216980] train loss: 0.003839, tar: 0.000027 
l0: 0.000115, l1: 0.000121, l2: 0.000174, l3: 0.000212, l4: 0.000391, l5: 0.001179, l6: 0.002685

[epoch: 826/1000, batch:   100/ 1052, ite: 217000] train loss: 0.003839, tar: 0.000027 
l0: 0.000012, l1: 0.000013, l2: 0.000047, l3: 0.000074, l4: 0.000424, l5: 0.000966, l6: 0.001899

[epoch: 826/1000, batch:   180/ 1052, ite: 217020] train loss: 0.003839, tar: 0.000027 
l0: 0.000011, l1: 0.000012, l2: 0.000036, l3: 0.000188, l4: 0.000610, l5: 0.001209, l6: 0.003015

[epoch: 826/1000, batch:   260/ 1052, ite: 217040] train loss: 0.003839, tar: 0.000027 
l0: 0.000011, l1: 0.000011, l2: 0.000038, l3: 0.000116, l4: 0.000468, l5: 0.000866, l6: 0.002032

[epoch: 826/1000, batch:   340/ 1052, ite: 217060] train loss: 0.003839, tar: 0.000027 
l0: 0.000033, l1: 0.000030, l2: 0.000057, l3: 0.000136, l4: 0.000632, l5: 0.001123, l6: 0.001817

[epoch: 826/1000, batch:   420/ 1052, ite: 217080] train loss: 0.003839, tar: 0.000027 
l0: 0.000135, l1: 0.000130, l2: 0.000185, l3: 0.000296, l4: 0.000433, l5: 0.001111, l6: 0.002175

[epoch: 826/1000, batch:   500/ 1052, ite: 217100] train loss: 0.003838, tar: 0.000027 
l0: 0.000007, l1: 0.000008, l2: 0.000038, l3: 0.000172, l4: 0.000311, l5: 0.001256, l6: 0.002007

[epoch: 826/1000, batch:   580/ 1052, ite: 217120] train loss: 0.003837, tar: 0.000027 
l0: 0.000014, l1: 0.000014, l2: 0.000034, l3: 0.000111, l4: 0.000423, l5: 0.001150, l6: 0.002053

[epoch: 826/1000, batch:   660/ 1052, ite: 217140] train loss: 0.003837, tar: 0.000027 
l0: 0.000034, l1: 0.000036, l2: 0.000041, l3: 0.000173, l4: 0.000320, l5: 0.001392, l6: 0.002659

[epoch: 826/1000, batch:   740/ 1052, ite: 217160] train loss: 0.003836, tar: 0.000027 
l0: 0.000022, l1: 0.000023, l2: 0.000061, l3: 0.000187, l4: 0.000330, l5: 0.000925, l6: 0.002458

[epoch: 826/1000, batch:   820/ 1052, ite: 217180] train loss: 0.003838, tar: 0.000027 
l0: 0.000003, l1: 0.000003, l2: 0.000027, l3: 0.000095, l4: 0.000362, l5: 0.000843, l6: 0.001336

[epoch: 826/1000, batch:   900/ 1052, ite: 217200] train loss: 0.003837, tar: 0.000027 
l0: 0.000041, l1: 0.000045, l2: 0.000038, l3: 0.000164, l4: 0.000715, l5: 0.000971, l6: 0.002587

[epoch: 826/1000, batch:   980/ 1052, ite: 217220] train loss: 0.003837, tar: 0.000027 
[Epoch 826/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000024, l1: 0.000023, l2: 0.000054, l3: 0.000149, l4: 0.000451, l5: 0.001135, l6: 0.001942

[epoch: 827/1000, batch:     8/ 1052, ite: 217240] train loss: 0.003838, tar: 0.000027 
l0: 0.000029, l1: 0.000028, l2: 0.000056, l3: 0.000214, l4: 0.000634, l5: 0.001426, l6: 0.002573

[epoch: 827/1000, batch:    88/ 1052, ite: 217260] train loss: 0.003837, tar: 0.000027 
l0: 0.000045, l1: 0.000048, l2: 0.000062, l3: 0.000160, l4: 0.000235, l5: 0.001034, l6: 0.001750

[epoch: 827/1000, batch:   168/ 1052, ite: 217280] train loss: 0.003836, tar: 0.000027 
l0: 0.000027, l1: 0.000028, l2: 0.000095, l3: 0.000159, l4: 0.000476, l5: 0.000757, l6: 0.001481

[epoch: 827/1000, batch:   248/ 1052, ite: 217300] train loss: 0.003836, tar: 0.000027 
l0: 0.000038, l1: 0.000033, l2: 0.000078, l3: 0.000117, l4: 0.000307, l5: 0.001203, l6: 0.001921

[epoch: 827/1000, batch:   328/ 1052, ite: 217320] train loss: 0.003835, tar: 0.000027 
l0: 0.000010, l1: 0.000012, l2: 0.000041, l3: 0.000123, l4: 0.000393, l5: 0.000954, l6: 0.001514

[epoch: 827/1000, batch:   408/ 1052, ite: 217340] train loss: 0.003835, tar: 0.000027 
l0: 0.000029, l1: 0.000027, l2: 0.000042, l3: 0.000094, l4: 0.000404, l5: 0.000881, l6: 0.002599

[epoch: 827/1000, batch:   488/ 1052, ite: 217360] train loss: 0.003834, tar: 0.000027 
l0: 0.000002, l1: 0.000003, l2: 0.000018, l3: 0.000090, l4: 0.000356, l5: 0.001191, l6: 0.001527

[epoch: 827/1000, batch:   568/ 1052, ite: 217380] train loss: 0.003835, tar: 0.000027 
l0: 0.000001, l1: 0.000001, l2: 0.000046, l3: 0.000341, l4: 0.000706, l5: 0.001237, l6: 0.002380

[epoch: 827/1000, batch:   648/ 1052, ite: 217400] train loss: 0.003836, tar: 0.000027 
l0: 0.000174, l1: 0.000181, l2: 0.000188, l3: 0.000403, l4: 0.001137, l5: 0.003922, l6: 0.005623

[epoch: 827/1000, batch:   728/ 1052, ite: 217420] train loss: 0.003837, tar: 0.000027 
l0: 0.000004, l1: 0.000006, l2: 0.000025, l3: 0.000194, l4: 0.000697, l5: 0.001451, l6: 0.001535

[epoch: 827/1000, batch:   808/ 1052, ite: 217440] train loss: 0.003838, tar: 0.000027 
l0: 0.000004, l1: 0.000005, l2: 0.000007, l3: 0.000046, l4: 0.000334, l5: 0.000619, l6: 0.001165

[epoch: 827/1000, batch:   888/ 1052, ite: 217460] train loss: 0.003838, tar: 0.000027 
l0: 0.000022, l1: 0.000025, l2: 0.000045, l3: 0.000093, l4: 0.000184, l5: 0.000781, l6: 0.001491

[epoch: 827/1000, batch:   968/ 1052, ite: 217480] train loss: 0.003838, tar: 0.000027 
l0: 0.000028, l1: 0.000029, l2: 0.000048, l3: 0.000128, l4: 0.000400, l5: 0.000788, l6: 0.001280

[epoch: 827/1000, batch:  1048/ 1052, ite: 217500] train loss: 0.003838, tar: 0.000027 
[Epoch 827/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000018, l1: 0.000020, l2: 0.000022, l3: 0.000095, l4: 0.000213, l5: 0.000403, l6: 0.000828

[epoch: 828/1000, batch:    76/ 1052, ite: 217520] train loss: 0.003840, tar: 0.000027 
l0: 0.000023, l1: 0.000021, l2: 0.000070, l3: 0.000168, l4: 0.000773, l5: 0.001681, l6: 0.002324

[epoch: 828/1000, batch:   156/ 1052, ite: 217540] train loss: 0.003839, tar: 0.000027 
l0: 0.000002, l1: 0.000002, l2: 0.000006, l3: 0.000039, l4: 0.000258, l5: 0.000243, l6: 0.000991

[epoch: 828/1000, batch:   236/ 1052, ite: 217560] train loss: 0.003839, tar: 0.000027 
l0: 0.000070, l1: 0.000081, l2: 0.000114, l3: 0.000343, l4: 0.000866, l5: 0.002208, l6: 0.005122

[epoch: 828/1000, batch:   316/ 1052, ite: 217580] train loss: 0.003839, tar: 0.000027 
l0: 0.000050, l1: 0.000054, l2: 0.000068, l3: 0.000165, l4: 0.000353, l5: 0.001139, l6: 0.002844

[epoch: 828/1000, batch:   396/ 1052, ite: 217600] train loss: 0.003838, tar: 0.000027 
l0: 0.000010, l1: 0.000010, l2: 0.000031, l3: 0.000095, l4: 0.000200, l5: 0.000791, l6: 0.000911

[epoch: 828/1000, batch:   476/ 1052, ite: 217620] train loss: 0.003838, tar: 0.000027 
l0: 0.000001, l1: 0.000001, l2: 0.000020, l3: 0.000035, l4: 0.000289, l5: 0.000463, l6: 0.001472

[epoch: 828/1000, batch:   556/ 1052, ite: 217640] train loss: 0.003839, tar: 0.000027 
l0: 0.000023, l1: 0.000025, l2: 0.000084, l3: 0.000200, l4: 0.000362, l5: 0.001153, l6: 0.002234

[epoch: 828/1000, batch:   636/ 1052, ite: 217660] train loss: 0.003839, tar: 0.000027 
l0: 0.000004, l1: 0.000004, l2: 0.000030, l3: 0.000109, l4: 0.000245, l5: 0.000927, l6: 0.002055

[epoch: 828/1000, batch:   716/ 1052, ite: 217680] train loss: 0.003840, tar: 0.000027 
l0: 0.000027, l1: 0.000030, l2: 0.000055, l3: 0.000185, l4: 0.000365, l5: 0.001079, l6: 0.002815

[epoch: 828/1000, batch:   796/ 1052, ite: 217700] train loss: 0.003840, tar: 0.000027 
l0: 0.000005, l1: 0.000006, l2: 0.000038, l3: 0.000134, l4: 0.000270, l5: 0.000801, l6: 0.002072

[epoch: 828/1000, batch:   876/ 1052, ite: 217720] train loss: 0.003839, tar: 0.000027 
l0: 0.000013, l1: 0.000013, l2: 0.000050, l3: 0.000179, l4: 0.000427, l5: 0.000910, l6: 0.001047

[epoch: 828/1000, batch:   956/ 1052, ite: 217740] train loss: 0.003839, tar: 0.000027 
l0: 0.000030, l1: 0.000030, l2: 0.000092, l3: 0.000306, l4: 0.000659, l5: 0.001215, l6: 0.002861

[epoch: 828/1000, batch:  1036/ 1052, ite: 217760] train loss: 0.003839, tar: 0.000027 
[Epoch 828/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000025, l1: 0.000023, l2: 0.000113, l3: 0.000210, l4: 0.000367, l5: 0.001331, l6: 0.002738

[epoch: 829/1000, batch:    64/ 1052, ite: 217780] train loss: 0.003841, tar: 0.000027 
l0: 0.000041, l1: 0.000040, l2: 0.000101, l3: 0.000257, l4: 0.000473, l5: 0.001687, l6: 0.002505

[epoch: 829/1000, batch:   144/ 1052, ite: 217800] train loss: 0.003840, tar: 0.000027 
l0: 0.000021, l1: 0.000022, l2: 0.000041, l3: 0.000278, l4: 0.000955, l5: 0.001689, l6: 0.001778

[epoch: 829/1000, batch:   224/ 1052, ite: 217820] train loss: 0.003841, tar: 0.000027 
l0: 0.000074, l1: 0.000077, l2: 0.000080, l3: 0.000157, l4: 0.000337, l5: 0.000989, l6: 0.001731

[epoch: 829/1000, batch:   304/ 1052, ite: 217840] train loss: 0.003841, tar: 0.000027 
l0: 0.000023, l1: 0.000026, l2: 0.000092, l3: 0.000309, l4: 0.000564, l5: 0.001116, l6: 0.002171

[epoch: 829/1000, batch:   384/ 1052, ite: 217860] train loss: 0.003841, tar: 0.000027 
l0: 0.000006, l1: 0.000005, l2: 0.000021, l3: 0.000094, l4: 0.000226, l5: 0.000464, l6: 0.001308

[epoch: 829/1000, batch:   464/ 1052, ite: 217880] train loss: 0.003842, tar: 0.000027 
l0: 0.000030, l1: 0.000029, l2: 0.000084, l3: 0.000214, l4: 0.000426, l5: 0.000867, l6: 0.002295

[epoch: 829/1000, batch:   544/ 1052, ite: 217900] train loss: 0.003841, tar: 0.000027 
l0: 0.000023, l1: 0.000022, l2: 0.000068, l3: 0.000214, l4: 0.000422, l5: 0.002064, l6: 0.003125

[epoch: 829/1000, batch:   624/ 1052, ite: 217920] train loss: 0.003841, tar: 0.000027 
l0: 0.000005, l1: 0.000005, l2: 0.000040, l3: 0.000238, l4: 0.000552, l5: 0.001077, l6: 0.001481

[epoch: 829/1000, batch:   704/ 1052, ite: 217940] train loss: 0.003842, tar: 0.000027 
l0: 0.000108, l1: 0.000098, l2: 0.000164, l3: 0.000320, l4: 0.000590, l5: 0.001497, l6: 0.004474

[epoch: 829/1000, batch:   784/ 1052, ite: 217960] train loss: 0.003842, tar: 0.000027 
l0: 0.000011, l1: 0.000008, l2: 0.000031, l3: 0.000085, l4: 0.000209, l5: 0.000513, l6: 0.000849

[epoch: 829/1000, batch:   864/ 1052, ite: 217980] train loss: 0.003841, tar: 0.000027 
l0: 0.000040, l1: 0.000043, l2: 0.000066, l3: 0.000152, l4: 0.000422, l5: 0.000591, l6: 0.001885

[epoch: 829/1000, batch:   944/ 1052, ite: 218000] train loss: 0.003841, tar: 0.000027 
l0: 0.000026, l1: 0.000031, l2: 0.000044, l3: 0.000109, l4: 0.000387, l5: 0.000721, l6: 0.002027

[epoch: 829/1000, batch:  1024/ 1052, ite: 218020] train loss: 0.003841, tar: 0.000027 
[Epoch 829/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000008, l1: 0.000009, l2: 0.000046, l3: 0.000343, l4: 0.000884, l5: 0.001905, l6: 0.002648

[epoch: 830/1000, batch:    52/ 1052, ite: 218040] train loss: 0.003840, tar: 0.000027 
l0: 0.000152, l1: 0.000151, l2: 0.000220, l3: 0.000282, l4: 0.000669, l5: 0.001474, l6: 0.002997

[epoch: 830/1000, batch:   132/ 1052, ite: 218060] train loss: 0.003840, tar: 0.000027 
l0: 0.000010, l1: 0.000009, l2: 0.000039, l3: 0.000080, l4: 0.000357, l5: 0.000731, l6: 0.001525

[epoch: 830/1000, batch:   212/ 1052, ite: 218080] train loss: 0.003840, tar: 0.000027 
l0: 0.000025, l1: 0.000024, l2: 0.000041, l3: 0.000148, l4: 0.000443, l5: 0.000858, l6: 0.001688

[epoch: 830/1000, batch:   292/ 1052, ite: 218100] train loss: 0.003840, tar: 0.000027 
l0: 0.000022, l1: 0.000023, l2: 0.000056, l3: 0.000097, l4: 0.000357, l5: 0.000482, l6: 0.001363

[epoch: 830/1000, batch:   372/ 1052, ite: 218120] train loss: 0.003839, tar: 0.000027 
l0: 0.000008, l1: 0.000008, l2: 0.000021, l3: 0.000124, l4: 0.000294, l5: 0.000698, l6: 0.001234

[epoch: 830/1000, batch:   452/ 1052, ite: 218140] train loss: 0.003839, tar: 0.000027 
l0: 0.000038, l1: 0.000036, l2: 0.000086, l3: 0.000165, l4: 0.000347, l5: 0.000879, l6: 0.001867

[epoch: 830/1000, batch:   532/ 1052, ite: 218160] train loss: 0.003839, tar: 0.000027 
l0: 0.000028, l1: 0.000028, l2: 0.000193, l3: 0.000435, l4: 0.000912, l5: 0.001710, l6: 0.001780

[epoch: 830/1000, batch:   612/ 1052, ite: 218180] train loss: 0.003838, tar: 0.000027 
l0: 0.000002, l1: 0.000002, l2: 0.000019, l3: 0.000056, l4: 0.000348, l5: 0.000618, l6: 0.001264

[epoch: 830/1000, batch:   692/ 1052, ite: 218200] train loss: 0.003838, tar: 0.000027 
l0: 0.000042, l1: 0.000042, l2: 0.000104, l3: 0.000409, l4: 0.000982, l5: 0.002012, l6: 0.002874

[epoch: 830/1000, batch:   772/ 1052, ite: 218220] train loss: 0.003837, tar: 0.000027 
l0: 0.000010, l1: 0.000009, l2: 0.000049, l3: 0.000154, l4: 0.000358, l5: 0.000732, l6: 0.001662

[epoch: 830/1000, batch:   852/ 1052, ite: 218240] train loss: 0.003838, tar: 0.000027 
l0: 0.000008, l1: 0.000008, l2: 0.000047, l3: 0.000152, l4: 0.000170, l5: 0.000894, l6: 0.001998

[epoch: 830/1000, batch:   932/ 1052, ite: 218260] train loss: 0.003838, tar: 0.000027 
l0: 0.000006, l1: 0.000007, l2: 0.000029, l3: 0.000145, l4: 0.000375, l5: 0.000943, l6: 0.001316

[epoch: 830/1000, batch:  1012/ 1052, ite: 218280] train loss: 0.003839, tar: 0.000027 
[Epoch 830/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000015, l1: 0.000014, l2: 0.000063, l3: 0.000159, l4: 0.000425, l5: 0.001384, l6: 0.001398

[epoch: 831/1000, batch:    40/ 1052, ite: 218300] train loss: 0.003841, tar: 0.000027 
l0: 0.000055, l1: 0.000053, l2: 0.000142, l3: 0.000312, l4: 0.000820, l5: 0.001435, l6: 0.002919

[epoch: 831/1000, batch:   120/ 1052, ite: 218320] train loss: 0.003841, tar: 0.000027 
l0: 0.000004, l1: 0.000004, l2: 0.000025, l3: 0.000101, l4: 0.000253, l5: 0.001157, l6: 0.001705

[epoch: 831/1000, batch:   200/ 1052, ite: 218340] train loss: 0.003840, tar: 0.000027 
l0: 0.000027, l1: 0.000023, l2: 0.000078, l3: 0.000163, l4: 0.000422, l5: 0.001040, l6: 0.001775

[epoch: 831/1000, batch:   280/ 1052, ite: 218360] train loss: 0.003840, tar: 0.000027 
l0: 0.000003, l1: 0.000003, l2: 0.000034, l3: 0.000158, l4: 0.000329, l5: 0.000926, l6: 0.001413

[epoch: 831/1000, batch:   360/ 1052, ite: 218380] train loss: 0.003840, tar: 0.000027 
l0: 0.000007, l1: 0.000006, l2: 0.000036, l3: 0.000113, l4: 0.000296, l5: 0.000912, l6: 0.000848

[epoch: 831/1000, batch:   440/ 1052, ite: 218400] train loss: 0.003840, tar: 0.000027 
l0: 0.000044, l1: 0.000047, l2: 0.000057, l3: 0.000109, l4: 0.000399, l5: 0.000882, l6: 0.001562

[epoch: 831/1000, batch:   520/ 1052, ite: 218420] train loss: 0.003841, tar: 0.000027 
l0: 0.000025, l1: 0.000026, l2: 0.000088, l3: 0.000203, l4: 0.000488, l5: 0.001224, l6: 0.001596

[epoch: 831/1000, batch:   600/ 1052, ite: 218440] train loss: 0.003841, tar: 0.000027 
l0: 0.000026, l1: 0.000028, l2: 0.000050, l3: 0.000133, l4: 0.000314, l5: 0.001059, l6: 0.002089

[epoch: 831/1000, batch:   680/ 1052, ite: 218460] train loss: 0.003841, tar: 0.000027 
l0: 0.000020, l1: 0.000020, l2: 0.000068, l3: 0.000166, l4: 0.000260, l5: 0.000667, l6: 0.002043

[epoch: 831/1000, batch:   760/ 1052, ite: 218480] train loss: 0.003841, tar: 0.000027 
l0: 0.000012, l1: 0.000013, l2: 0.000046, l3: 0.000130, l4: 0.000443, l5: 0.000788, l6: 0.001133

[epoch: 831/1000, batch:   840/ 1052, ite: 218500] train loss: 0.003841, tar: 0.000027 
l0: 0.000023, l1: 0.000024, l2: 0.000053, l3: 0.000104, l4: 0.000273, l5: 0.000829, l6: 0.001773

[epoch: 831/1000, batch:   920/ 1052, ite: 218520] train loss: 0.003841, tar: 0.000027 
l0: 0.000016, l1: 0.000016, l2: 0.000037, l3: 0.000132, l4: 0.000295, l5: 0.000876, l6: 0.001439

[epoch: 831/1000, batch:  1000/ 1052, ite: 218540] train loss: 0.003841, tar: 0.000027 
[Epoch 831/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000032, l1: 0.000033, l2: 0.000073, l3: 0.000148, l4: 0.000471, l5: 0.000523, l6: 0.001453

[epoch: 832/1000, batch:    28/ 1052, ite: 218560] train loss: 0.003841, tar: 0.000027 
l0: 0.000060, l1: 0.000052, l2: 0.000127, l3: 0.000367, l4: 0.000561, l5: 0.001026, l6: 0.002627

[epoch: 832/1000, batch:   108/ 1052, ite: 218580] train loss: 0.003842, tar: 0.000027 
l0: 0.000005, l1: 0.000006, l2: 0.000037, l3: 0.000183, l4: 0.000566, l5: 0.000970, l6: 0.001936

[epoch: 832/1000, batch:   188/ 1052, ite: 218600] train loss: 0.003842, tar: 0.000027 
l0: 0.000011, l1: 0.000009, l2: 0.000058, l3: 0.000131, l4: 0.000373, l5: 0.000936, l6: 0.001387

[epoch: 832/1000, batch:   268/ 1052, ite: 218620] train loss: 0.003842, tar: 0.000027 
l0: 0.000016, l1: 0.000015, l2: 0.000036, l3: 0.000155, l4: 0.000392, l5: 0.001009, l6: 0.001417

[epoch: 832/1000, batch:   348/ 1052, ite: 218640] train loss: 0.003842, tar: 0.000027 
l0: 0.000007, l1: 0.000007, l2: 0.000022, l3: 0.000139, l4: 0.000343, l5: 0.000795, l6: 0.001216

[epoch: 832/1000, batch:   428/ 1052, ite: 218660] train loss: 0.003842, tar: 0.000027 
l0: 0.000008, l1: 0.000007, l2: 0.000018, l3: 0.000054, l4: 0.000449, l5: 0.000792, l6: 0.001663

[epoch: 832/1000, batch:   508/ 1052, ite: 218680] train loss: 0.003841, tar: 0.000027 
l0: 0.000031, l1: 0.000035, l2: 0.000031, l3: 0.000105, l4: 0.000315, l5: 0.000742, l6: 0.000776

[epoch: 832/1000, batch:   588/ 1052, ite: 218700] train loss: 0.003841, tar: 0.000027 
l0: 0.000025, l1: 0.000026, l2: 0.000039, l3: 0.000054, l4: 0.000102, l5: 0.000469, l6: 0.000891

[epoch: 832/1000, batch:   668/ 1052, ite: 218720] train loss: 0.003841, tar: 0.000027 
l0: 0.000006, l1: 0.000006, l2: 0.000017, l3: 0.000158, l4: 0.000486, l5: 0.000873, l6: 0.001331

[epoch: 832/1000, batch:   748/ 1052, ite: 218740] train loss: 0.003839, tar: 0.000027 
l0: 0.000047, l1: 0.000046, l2: 0.000095, l3: 0.000273, l4: 0.000610, l5: 0.002782, l6: 0.004465

[epoch: 832/1000, batch:   828/ 1052, ite: 218760] train loss: 0.003841, tar: 0.000027 
l0: 0.000008, l1: 0.000009, l2: 0.000019, l3: 0.000118, l4: 0.000371, l5: 0.001146, l6: 0.001515

[epoch: 832/1000, batch:   908/ 1052, ite: 218780] train loss: 0.003841, tar: 0.000027 
l0: 0.000026, l1: 0.000027, l2: 0.000075, l3: 0.000275, l4: 0.000599, l5: 0.000929, l6: 0.003217

[epoch: 832/1000, batch:   988/ 1052, ite: 218800] train loss: 0.003842, tar: 0.000027 
[Epoch 832/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000001, l1: 0.000001, l2: 0.000021, l3: 0.000122, l4: 0.000502, l5: 0.000612, l6: 0.001143

[epoch: 833/1000, batch:    16/ 1052, ite: 218820] train loss: 0.003842, tar: 0.000027 
l0: 0.000036, l1: 0.000035, l2: 0.000075, l3: 0.000249, l4: 0.000815, l5: 0.002051, l6: 0.002212

[epoch: 833/1000, batch:    96/ 1052, ite: 218840] train loss: 0.003843, tar: 0.000027 
l0: 0.000013, l1: 0.000016, l2: 0.000023, l3: 0.000063, l4: 0.000342, l5: 0.000879, l6: 0.001652

[epoch: 833/1000, batch:   176/ 1052, ite: 218860] train loss: 0.003843, tar: 0.000027 
l0: 0.000004, l1: 0.000004, l2: 0.000061, l3: 0.000167, l4: 0.000432, l5: 0.001213, l6: 0.001641

[epoch: 833/1000, batch:   256/ 1052, ite: 218880] train loss: 0.003843, tar: 0.000027 
l0: 0.000024, l1: 0.000021, l2: 0.000057, l3: 0.000199, l4: 0.000594, l5: 0.001454, l6: 0.002300

[epoch: 833/1000, batch:   336/ 1052, ite: 218900] train loss: 0.003846, tar: 0.000027 
l0: 0.000046, l1: 0.000048, l2: 0.000087, l3: 0.000210, l4: 0.000439, l5: 0.001238, l6: 0.002817

[epoch: 833/1000, batch:   416/ 1052, ite: 218920] train loss: 0.003846, tar: 0.000027 
l0: 0.000009, l1: 0.000009, l2: 0.000029, l3: 0.000107, l4: 0.000534, l5: 0.001302, l6: 0.001362

[epoch: 833/1000, batch:   496/ 1052, ite: 218940] train loss: 0.003846, tar: 0.000027 
l0: 0.000023, l1: 0.000028, l2: 0.000023, l3: 0.000070, l4: 0.000235, l5: 0.000630, l6: 0.000964

[epoch: 833/1000, batch:   576/ 1052, ite: 218960] train loss: 0.003845, tar: 0.000027 
l0: 0.000010, l1: 0.000010, l2: 0.000067, l3: 0.000141, l4: 0.000287, l5: 0.000684, l6: 0.002072

[epoch: 833/1000, batch:   656/ 1052, ite: 218980] train loss: 0.003845, tar: 0.000027 
l0: 0.000016, l1: 0.000015, l2: 0.000058, l3: 0.000246, l4: 0.000455, l5: 0.001715, l6: 0.003829

[epoch: 833/1000, batch:   736/ 1052, ite: 219000] train loss: 0.003845, tar: 0.000027 
l0: 0.000050, l1: 0.000047, l2: 0.000112, l3: 0.000184, l4: 0.000335, l5: 0.001838, l6: 0.003543

[epoch: 833/1000, batch:   816/ 1052, ite: 219020] train loss: 0.003845, tar: 0.000027 
l0: 0.000003, l1: 0.000003, l2: 0.000008, l3: 0.000050, l4: 0.000291, l5: 0.000443, l6: 0.001185

[epoch: 833/1000, batch:   896/ 1052, ite: 219040] train loss: 0.003844, tar: 0.000027 
l0: 0.000026, l1: 0.000025, l2: 0.000037, l3: 0.000125, l4: 0.000386, l5: 0.001129, l6: 0.000997

[epoch: 833/1000, batch:   976/ 1052, ite: 219060] train loss: 0.003845, tar: 0.000027 
[Epoch 833/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000010, l1: 0.000010, l2: 0.000041, l3: 0.000138, l4: 0.000431, l5: 0.000804, l6: 0.001561

[epoch: 834/1000, batch:     4/ 1052, ite: 219080] train loss: 0.003844, tar: 0.000027 
l0: 0.000018, l1: 0.000017, l2: 0.000049, l3: 0.000213, l4: 0.000626, l5: 0.001322, l6: 0.002802

[epoch: 834/1000, batch:    84/ 1052, ite: 219100] train loss: 0.003844, tar: 0.000027 
l0: 0.000014, l1: 0.000013, l2: 0.000048, l3: 0.000196, l4: 0.000342, l5: 0.001022, l6: 0.001740

[epoch: 834/1000, batch:   164/ 1052, ite: 219120] train loss: 0.003844, tar: 0.000027 
l0: 0.000027, l1: 0.000026, l2: 0.000061, l3: 0.000175, l4: 0.000650, l5: 0.001486, l6: 0.002641

[epoch: 834/1000, batch:   244/ 1052, ite: 219140] train loss: 0.003844, tar: 0.000027 
l0: 0.000032, l1: 0.000030, l2: 0.000084, l3: 0.000234, l4: 0.000439, l5: 0.001128, l6: 0.001895

[epoch: 834/1000, batch:   324/ 1052, ite: 219160] train loss: 0.003845, tar: 0.000027 
l0: 0.000065, l1: 0.000070, l2: 0.000145, l3: 0.000394, l4: 0.000861, l5: 0.003252, l6: 0.006273

[epoch: 834/1000, batch:   404/ 1052, ite: 219180] train loss: 0.003847, tar: 0.000027 
l0: 0.000006, l1: 0.000005, l2: 0.000037, l3: 0.000140, l4: 0.000390, l5: 0.001267, l6: 0.001874

[epoch: 834/1000, batch:   484/ 1052, ite: 219200] train loss: 0.003846, tar: 0.000027 
l0: 0.000042, l1: 0.000042, l2: 0.000140, l3: 0.000385, l4: 0.000851, l5: 0.001428, l6: 0.005249

[epoch: 834/1000, batch:   564/ 1052, ite: 219220] train loss: 0.003846, tar: 0.000027 
l0: 0.000021, l1: 0.000022, l2: 0.000068, l3: 0.000131, l4: 0.000473, l5: 0.001610, l6: 0.002998

[epoch: 834/1000, batch:   644/ 1052, ite: 219240] train loss: 0.003845, tar: 0.000027 
l0: 0.000016, l1: 0.000017, l2: 0.000050, l3: 0.000181, l4: 0.000561, l5: 0.001453, l6: 0.002425

[epoch: 834/1000, batch:   724/ 1052, ite: 219260] train loss: 0.003846, tar: 0.000027 
l0: 0.000001, l1: 0.000001, l2: 0.000009, l3: 0.000023, l4: 0.000208, l5: 0.000628, l6: 0.000589

[epoch: 834/1000, batch:   804/ 1052, ite: 219280] train loss: 0.003845, tar: 0.000027 
l0: 0.000014, l1: 0.000016, l2: 0.000021, l3: 0.000075, l4: 0.000718, l5: 0.000963, l6: 0.001916

[epoch: 834/1000, batch:   884/ 1052, ite: 219300] train loss: 0.003845, tar: 0.000027 
l0: 0.000005, l1: 0.000005, l2: 0.000039, l3: 0.000120, l4: 0.000407, l5: 0.001134, l6: 0.002063

[epoch: 834/1000, batch:   964/ 1052, ite: 219320] train loss: 0.003845, tar: 0.000027 
l0: 0.000047, l1: 0.000046, l2: 0.000126, l3: 0.000251, l4: 0.001026, l5: 0.002680, l6: 0.004358

[epoch: 834/1000, batch:  1044/ 1052, ite: 219340] train loss: 0.003845, tar: 0.000027 
[Epoch 834/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000022, l1: 0.000021, l2: 0.000063, l3: 0.000133, l4: 0.000266, l5: 0.000878, l6: 0.001428

[epoch: 835/1000, batch:    72/ 1052, ite: 219360] train loss: 0.003845, tar: 0.000027 
l0: 0.000049, l1: 0.000049, l2: 0.000094, l3: 0.000204, l4: 0.000607, l5: 0.001257, l6: 0.001570

[epoch: 835/1000, batch:   152/ 1052, ite: 219380] train loss: 0.003845, tar: 0.000027 
l0: 0.000051, l1: 0.000052, l2: 0.000061, l3: 0.000124, l4: 0.000468, l5: 0.001114, l6: 0.002236

[epoch: 835/1000, batch:   232/ 1052, ite: 219400] train loss: 0.003845, tar: 0.000027 
l0: 0.000037, l1: 0.000040, l2: 0.000082, l3: 0.000236, l4: 0.000480, l5: 0.001063, l6: 0.003876

[epoch: 835/1000, batch:   312/ 1052, ite: 219420] train loss: 0.003845, tar: 0.000027 
l0: 0.000004, l1: 0.000004, l2: 0.000032, l3: 0.000094, l4: 0.000289, l5: 0.000942, l6: 0.001189

[epoch: 835/1000, batch:   392/ 1052, ite: 219440] train loss: 0.003844, tar: 0.000027 
l0: 0.000030, l1: 0.000033, l2: 0.000068, l3: 0.000227, l4: 0.000371, l5: 0.001099, l6: 0.001736

[epoch: 835/1000, batch:   472/ 1052, ite: 219460] train loss: 0.003845, tar: 0.000027 
l0: 0.000001, l1: 0.000002, l2: 0.000009, l3: 0.000058, l4: 0.000276, l5: 0.000894, l6: 0.001772

[epoch: 835/1000, batch:   552/ 1052, ite: 219480] train loss: 0.003845, tar: 0.000027 
l0: 0.000033, l1: 0.000027, l2: 0.000065, l3: 0.000118, l4: 0.000507, l5: 0.001468, l6: 0.001879

[epoch: 835/1000, batch:   632/ 1052, ite: 219500] train loss: 0.003845, tar: 0.000027 
l0: 0.000005, l1: 0.000005, l2: 0.000038, l3: 0.000246, l4: 0.000301, l5: 0.000724, l6: 0.001455

[epoch: 835/1000, batch:   712/ 1052, ite: 219520] train loss: 0.003845, tar: 0.000027 
l0: 0.000025, l1: 0.000025, l2: 0.000058, l3: 0.000137, l4: 0.000439, l5: 0.000724, l6: 0.002025

[epoch: 835/1000, batch:   792/ 1052, ite: 219540] train loss: 0.003845, tar: 0.000027 
l0: 0.000008, l1: 0.000009, l2: 0.000029, l3: 0.000074, l4: 0.000354, l5: 0.000992, l6: 0.001773

[epoch: 835/1000, batch:   872/ 1052, ite: 219560] train loss: 0.003844, tar: 0.000027 
l0: 0.000009, l1: 0.000009, l2: 0.000034, l3: 0.000101, l4: 0.000514, l5: 0.001318, l6: 0.001817

[epoch: 835/1000, batch:   952/ 1052, ite: 219580] train loss: 0.003844, tar: 0.000027 
l0: 0.000017, l1: 0.000017, l2: 0.000026, l3: 0.000119, l4: 0.000342, l5: 0.000892, l6: 0.001108

[epoch: 835/1000, batch:  1032/ 1052, ite: 219600] train loss: 0.003845, tar: 0.000027 
[Epoch 835/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000016, l1: 0.000015, l2: 0.000046, l3: 0.000106, l4: 0.000313, l5: 0.000854, l6: 0.001633

[epoch: 836/1000, batch:    60/ 1052, ite: 219620] train loss: 0.003846, tar: 0.000027 
l0: 0.000013, l1: 0.000013, l2: 0.000039, l3: 0.000134, l4: 0.000441, l5: 0.001061, l6: 0.000957

[epoch: 836/1000, batch:   140/ 1052, ite: 219640] train loss: 0.003845, tar: 0.000027 
l0: 0.000007, l1: 0.000007, l2: 0.000026, l3: 0.000108, l4: 0.000258, l5: 0.000946, l6: 0.001386

[epoch: 836/1000, batch:   220/ 1052, ite: 219660] train loss: 0.003845, tar: 0.000027 
l0: 0.000011, l1: 0.000011, l2: 0.000055, l3: 0.000126, l4: 0.000367, l5: 0.000817, l6: 0.001779

[epoch: 836/1000, batch:   300/ 1052, ite: 219680] train loss: 0.003844, tar: 0.000027 
l0: 0.000007, l1: 0.000009, l2: 0.000044, l3: 0.000180, l4: 0.000349, l5: 0.001010, l6: 0.002145

[epoch: 836/1000, batch:   380/ 1052, ite: 219700] train loss: 0.003844, tar: 0.000027 
l0: 0.000005, l1: 0.000006, l2: 0.000014, l3: 0.000065, l4: 0.000386, l5: 0.000409, l6: 0.001623

[epoch: 836/1000, batch:   460/ 1052, ite: 219720] train loss: 0.003844, tar: 0.000027 
l0: 0.000007, l1: 0.000007, l2: 0.000026, l3: 0.000092, l4: 0.000305, l5: 0.000877, l6: 0.001269

[epoch: 836/1000, batch:   540/ 1052, ite: 219740] train loss: 0.003843, tar: 0.000027 
l0: 0.000041, l1: 0.000043, l2: 0.000051, l3: 0.000110, l4: 0.000461, l5: 0.001201, l6: 0.002631

[epoch: 836/1000, batch:   620/ 1052, ite: 219760] train loss: 0.003844, tar: 0.000027 
l0: 0.000010, l1: 0.000011, l2: 0.000058, l3: 0.000106, l4: 0.000202, l5: 0.001031, l6: 0.002004

[epoch: 836/1000, batch:   700/ 1052, ite: 219780] train loss: 0.003844, tar: 0.000027 
l0: 0.000010, l1: 0.000011, l2: 0.000051, l3: 0.000098, l4: 0.000256, l5: 0.000682, l6: 0.001313

[epoch: 836/1000, batch:   780/ 1052, ite: 219800] train loss: 0.003844, tar: 0.000027 
l0: 0.000151, l1: 0.000158, l2: 0.000219, l3: 0.000327, l4: 0.000552, l5: 0.001129, l6: 0.001676

[epoch: 836/1000, batch:   860/ 1052, ite: 219820] train loss: 0.003843, tar: 0.000027 
l0: 0.000005, l1: 0.000005, l2: 0.000024, l3: 0.000098, l4: 0.000375, l5: 0.000836, l6: 0.001373

[epoch: 836/1000, batch:   940/ 1052, ite: 219840] train loss: 0.003845, tar: 0.000027 
l0: 0.000014, l1: 0.000015, l2: 0.000090, l3: 0.000241, l4: 0.000626, l5: 0.000889, l6: 0.001732

[epoch: 836/1000, batch:  1020/ 1052, ite: 219860] train loss: 0.003844, tar: 0.000027 
[Epoch 836/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000018, l1: 0.000020, l2: 0.000042, l3: 0.000134, l4: 0.000346, l5: 0.000857, l6: 0.001947

[epoch: 837/1000, batch:    48/ 1052, ite: 219880] train loss: 0.003844, tar: 0.000027 
l0: 0.000003, l1: 0.000002, l2: 0.000034, l3: 0.000126, l4: 0.000433, l5: 0.000909, l6: 0.001938

[epoch: 837/1000, batch:   128/ 1052, ite: 219900] train loss: 0.003844, tar: 0.000027 
l0: 0.000002, l1: 0.000002, l2: 0.000008, l3: 0.000094, l4: 0.000375, l5: 0.000796, l6: 0.000919

[epoch: 837/1000, batch:   208/ 1052, ite: 219920] train loss: 0.003843, tar: 0.000027 
l0: 0.000017, l1: 0.000015, l2: 0.000059, l3: 0.000163, l4: 0.000709, l5: 0.001010, l6: 0.001348

[epoch: 837/1000, batch:   288/ 1052, ite: 219940] train loss: 0.003842, tar: 0.000027 
l0: 0.000048, l1: 0.000049, l2: 0.000069, l3: 0.000150, l4: 0.000492, l5: 0.001087, l6: 0.002627

[epoch: 837/1000, batch:   368/ 1052, ite: 219960] train loss: 0.003842, tar: 0.000027 
l0: 0.000104, l1: 0.000104, l2: 0.000154, l3: 0.000343, l4: 0.000863, l5: 0.001751, l6: 0.003515

[epoch: 837/1000, batch:   448/ 1052, ite: 219980] train loss: 0.003843, tar: 0.000027 
l0: 0.000035, l1: 0.000034, l2: 0.000112, l3: 0.000223, l4: 0.000752, l5: 0.001187, l6: 0.002932

[epoch: 837/1000, batch:   528/ 1052, ite: 220000] train loss: 0.003843, tar: 0.000027 
l0: 0.000002, l1: 0.000002, l2: 0.000045, l3: 0.000486, l4: 0.000903, l5: 0.002350, l6: 0.003560

[epoch: 837/1000, batch:   608/ 1052, ite: 220020] train loss: 0.003845, tar: 0.000027 
l0: 0.000009, l1: 0.000011, l2: 0.000015, l3: 0.000093, l4: 0.000367, l5: 0.000699, l6: 0.001009

[epoch: 837/1000, batch:   688/ 1052, ite: 220040] train loss: 0.003844, tar: 0.000027 
l0: 0.000043, l1: 0.000042, l2: 0.000078, l3: 0.000235, l4: 0.000540, l5: 0.000836, l6: 0.002067

[epoch: 837/1000, batch:   768/ 1052, ite: 220060] train loss: 0.003844, tar: 0.000027 
l0: 0.000011, l1: 0.000012, l2: 0.000025, l3: 0.000084, l4: 0.000234, l5: 0.000950, l6: 0.000854

[epoch: 837/1000, batch:   848/ 1052, ite: 220080] train loss: 0.003843, tar: 0.000027 
l0: 0.000013, l1: 0.000012, l2: 0.000057, l3: 0.000157, l4: 0.000600, l5: 0.001203, l6: 0.003412

[epoch: 837/1000, batch:   928/ 1052, ite: 220100] train loss: 0.003844, tar: 0.000027 
l0: 0.000039, l1: 0.000043, l2: 0.000040, l3: 0.000127, l4: 0.000547, l5: 0.001373, l6: 0.001908

[epoch: 837/1000, batch:  1008/ 1052, ite: 220120] train loss: 0.003845, tar: 0.000027 
[Epoch 837/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000022, l1: 0.000021, l2: 0.000076, l3: 0.000203, l4: 0.000452, l5: 0.000695, l6: 0.001529

[epoch: 838/1000, batch:    36/ 1052, ite: 220140] train loss: 0.003846, tar: 0.000027 
l0: 0.000051, l1: 0.000049, l2: 0.000121, l3: 0.000299, l4: 0.000593, l5: 0.001361, l6: 0.003503

[epoch: 838/1000, batch:   116/ 1052, ite: 220160] train loss: 0.003846, tar: 0.000027 
l0: 0.000033, l1: 0.000035, l2: 0.000058, l3: 0.000130, l4: 0.000328, l5: 0.000895, l6: 0.002806

[epoch: 838/1000, batch:   196/ 1052, ite: 220180] train loss: 0.003846, tar: 0.000027 
l0: 0.000020, l1: 0.000021, l2: 0.000056, l3: 0.000162, l4: 0.000314, l5: 0.001077, l6: 0.001314

[epoch: 838/1000, batch:   276/ 1052, ite: 220200] train loss: 0.003845, tar: 0.000027 
l0: 0.000058, l1: 0.000060, l2: 0.000095, l3: 0.000186, l4: 0.000509, l5: 0.001297, l6: 0.003060

[epoch: 838/1000, batch:   356/ 1052, ite: 220220] train loss: 0.003846, tar: 0.000027 
l0: 0.000015, l1: 0.000016, l2: 0.000059, l3: 0.000150, l4: 0.000571, l5: 0.001437, l6: 0.001714

[epoch: 838/1000, batch:   436/ 1052, ite: 220240] train loss: 0.003848, tar: 0.000027 
l0: 0.000020, l1: 0.000020, l2: 0.000055, l3: 0.000135, l4: 0.000266, l5: 0.000977, l6: 0.001545

[epoch: 838/1000, batch:   516/ 1052, ite: 220260] train loss: 0.003847, tar: 0.000027 
l0: 0.000018, l1: 0.000019, l2: 0.000053, l3: 0.000256, l4: 0.000627, l5: 0.001233, l6: 0.002796

[epoch: 838/1000, batch:   596/ 1052, ite: 220280] train loss: 0.003846, tar: 0.000027 
l0: 0.000002, l1: 0.000003, l2: 0.000019, l3: 0.000114, l4: 0.000217, l5: 0.000550, l6: 0.000835

[epoch: 838/1000, batch:   676/ 1052, ite: 220300] train loss: 0.003846, tar: 0.000027 
l0: 0.000073, l1: 0.000071, l2: 0.000110, l3: 0.000156, l4: 0.000234, l5: 0.000422, l6: 0.001305

[epoch: 838/1000, batch:   756/ 1052, ite: 220320] train loss: 0.003846, tar: 0.000027 
l0: 0.000020, l1: 0.000019, l2: 0.000069, l3: 0.000181, l4: 0.000312, l5: 0.001244, l6: 0.001522

[epoch: 838/1000, batch:   836/ 1052, ite: 220340] train loss: 0.003846, tar: 0.000027 
l0: 0.000001, l1: 0.000002, l2: 0.000008, l3: 0.000032, l4: 0.000076, l5: 0.000377, l6: 0.000786

[epoch: 838/1000, batch:   916/ 1052, ite: 220360] train loss: 0.003845, tar: 0.000027 
l0: 0.000054, l1: 0.000052, l2: 0.000090, l3: 0.000150, l4: 0.000224, l5: 0.001024, l6: 0.001949

[epoch: 838/1000, batch:   996/ 1052, ite: 220380] train loss: 0.003845, tar: 0.000027 
[Epoch 838/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000048, l1: 0.000048, l2: 0.000099, l3: 0.000268, l4: 0.000492, l5: 0.001011, l6: 0.002034

[epoch: 839/1000, batch:    24/ 1052, ite: 220400] train loss: 0.003845, tar: 0.000027 
l0: 0.000017, l1: 0.000020, l2: 0.000024, l3: 0.000050, l4: 0.000252, l5: 0.000667, l6: 0.001100

[epoch: 839/1000, batch:   104/ 1052, ite: 220420] train loss: 0.003845, tar: 0.000027 
l0: 0.000016, l1: 0.000014, l2: 0.000046, l3: 0.000146, l4: 0.000249, l5: 0.001137, l6: 0.001327

[epoch: 839/1000, batch:   184/ 1052, ite: 220440] train loss: 0.003846, tar: 0.000027 
l0: 0.000022, l1: 0.000021, l2: 0.000038, l3: 0.000138, l4: 0.000472, l5: 0.000946, l6: 0.002339

[epoch: 839/1000, batch:   264/ 1052, ite: 220460] train loss: 0.003846, tar: 0.000027 
l0: 0.000008, l1: 0.000008, l2: 0.000039, l3: 0.000130, l4: 0.000467, l5: 0.000668, l6: 0.002057

[epoch: 839/1000, batch:   344/ 1052, ite: 220480] train loss: 0.003846, tar: 0.000027 
l0: 0.000015, l1: 0.000016, l2: 0.000065, l3: 0.000120, l4: 0.000504, l5: 0.001391, l6: 0.002778

[epoch: 839/1000, batch:   424/ 1052, ite: 220500] train loss: 0.003846, tar: 0.000027 
l0: 0.000004, l1: 0.000003, l2: 0.000017, l3: 0.000105, l4: 0.000299, l5: 0.000519, l6: 0.001622

[epoch: 839/1000, batch:   504/ 1052, ite: 220520] train loss: 0.003845, tar: 0.000027 
l0: 0.000028, l1: 0.000029, l2: 0.000078, l3: 0.000231, l4: 0.000356, l5: 0.000880, l6: 0.001409

[epoch: 839/1000, batch:   584/ 1052, ite: 220540] train loss: 0.003845, tar: 0.000027 
l0: 0.000017, l1: 0.000016, l2: 0.000048, l3: 0.000149, l4: 0.000320, l5: 0.000851, l6: 0.001902

[epoch: 839/1000, batch:   664/ 1052, ite: 220560] train loss: 0.003846, tar: 0.000027 
l0: 0.000017, l1: 0.000017, l2: 0.000050, l3: 0.000199, l4: 0.000542, l5: 0.001727, l6: 0.003209

[epoch: 839/1000, batch:   744/ 1052, ite: 220580] train loss: 0.003846, tar: 0.000027 
l0: 0.000017, l1: 0.000016, l2: 0.000047, l3: 0.000156, l4: 0.000570, l5: 0.001205, l6: 0.001752

[epoch: 839/1000, batch:   824/ 1052, ite: 220600] train loss: 0.003845, tar: 0.000027 
l0: 0.000095, l1: 0.000088, l2: 0.000158, l3: 0.000247, l4: 0.000445, l5: 0.001055, l6: 0.001518

[epoch: 839/1000, batch:   904/ 1052, ite: 220620] train loss: 0.003845, tar: 0.000027 
l0: 0.000023, l1: 0.000020, l2: 0.000063, l3: 0.000203, l4: 0.000522, l5: 0.000859, l6: 0.002024

[epoch: 839/1000, batch:   984/ 1052, ite: 220640] train loss: 0.003845, tar: 0.000027 
[Epoch 839/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000007, l1: 0.000008, l2: 0.000061, l3: 0.000128, l4: 0.000490, l5: 0.001088, l6: 0.002558

[epoch: 840/1000, batch:    12/ 1052, ite: 220660] train loss: 0.003845, tar: 0.000027 
l0: 0.000005, l1: 0.000004, l2: 0.000029, l3: 0.000063, l4: 0.000546, l5: 0.001094, l6: 0.001600

[epoch: 840/1000, batch:    92/ 1052, ite: 220680] train loss: 0.003845, tar: 0.000027 
l0: 0.000012, l1: 0.000011, l2: 0.000092, l3: 0.000212, l4: 0.000338, l5: 0.001496, l6: 0.002149

[epoch: 840/1000, batch:   172/ 1052, ite: 220700] train loss: 0.003844, tar: 0.000027 
l0: 0.000018, l1: 0.000017, l2: 0.000036, l3: 0.000201, l4: 0.000503, l5: 0.001637, l6: 0.001937

[epoch: 840/1000, batch:   252/ 1052, ite: 220720] train loss: 0.003846, tar: 0.000027 
l0: 0.000029, l1: 0.000030, l2: 0.000050, l3: 0.000129, l4: 0.000437, l5: 0.001254, l6: 0.002526

[epoch: 840/1000, batch:   332/ 1052, ite: 220740] train loss: 0.003846, tar: 0.000027 
l0: 0.000012, l1: 0.000012, l2: 0.000029, l3: 0.000106, l4: 0.000342, l5: 0.001127, l6: 0.001952

[epoch: 840/1000, batch:   412/ 1052, ite: 220760] train loss: 0.003846, tar: 0.000027 
l0: 0.000003, l1: 0.000002, l2: 0.000042, l3: 0.000126, l4: 0.000454, l5: 0.001082, l6: 0.001932

[epoch: 840/1000, batch:   492/ 1052, ite: 220780] train loss: 0.003846, tar: 0.000027 
l0: 0.000005, l1: 0.000005, l2: 0.000015, l3: 0.000046, l4: 0.000195, l5: 0.000564, l6: 0.000602

[epoch: 840/1000, batch:   572/ 1052, ite: 220800] train loss: 0.003845, tar: 0.000027 
l0: 0.000029, l1: 0.000029, l2: 0.000095, l3: 0.000319, l4: 0.000653, l5: 0.001152, l6: 0.002709

[epoch: 840/1000, batch:   652/ 1052, ite: 220820] train loss: 0.003846, tar: 0.000027 
l0: 0.000020, l1: 0.000022, l2: 0.000035, l3: 0.000173, l4: 0.000594, l5: 0.001209, l6: 0.001688

[epoch: 840/1000, batch:   732/ 1052, ite: 220840] train loss: 0.003845, tar: 0.000027 
l0: 0.000019, l1: 0.000017, l2: 0.000083, l3: 0.000235, l4: 0.000482, l5: 0.000699, l6: 0.001783

[epoch: 840/1000, batch:   812/ 1052, ite: 220860] train loss: 0.003845, tar: 0.000027 
l0: 0.000023, l1: 0.000022, l2: 0.000073, l3: 0.000167, l4: 0.000391, l5: 0.000994, l6: 0.001413

[epoch: 840/1000, batch:   892/ 1052, ite: 220880] train loss: 0.003845, tar: 0.000027 
l0: 0.000016, l1: 0.000019, l2: 0.000087, l3: 0.000221, l4: 0.000449, l5: 0.001132, l6: 0.003364

[epoch: 840/1000, batch:   972/ 1052, ite: 220900] train loss: 0.003845, tar: 0.000027 
l0: 0.000010, l1: 0.000010, l2: 0.000031, l3: 0.000088, l4: 0.000338, l5: 0.000868, l6: 0.000974

[epoch: 840/1000, batch:  1052/ 1052, ite: 220920] train loss: 0.003845, tar: 0.000027 
[Epoch 840/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000036, l1: 0.000036, l2: 0.000091, l3: 0.000167, l4: 0.000643, l5: 0.001028, l6: 0.001662

[epoch: 841/1000, batch:    80/ 1052, ite: 220940] train loss: 0.004339, tar: 0.000034 
l0: 0.000024, l1: 0.000026, l2: 0.000068, l3: 0.000233, l4: 0.000678, l5: 0.001045, l6: 0.001693

[epoch: 841/1000, batch:   160/ 1052, ite: 220960] train loss: 0.004110, tar: 0.000038 
l0: 0.000021, l1: 0.000020, l2: 0.000045, l3: 0.000143, l4: 0.000286, l5: 0.000699, l6: 0.000888

[epoch: 841/1000, batch:   240/ 1052, ite: 220980] train loss: 0.003825, tar: 0.000032 
l0: 0.000025, l1: 0.000024, l2: 0.000026, l3: 0.000053, l4: 0.000199, l5: 0.000520, l6: 0.001269

[epoch: 841/1000, batch:   320/ 1052, ite: 221000] train loss: 0.003691, tar: 0.000028 
l0: 0.000002, l1: 0.000002, l2: 0.000008, l3: 0.000051, l4: 0.000170, l5: 0.001250, l6: 0.001682

[epoch: 841/1000, batch:   400/ 1052, ite: 221020] train loss: 0.003689, tar: 0.000027 
l0: 0.000024, l1: 0.000026, l2: 0.000086, l3: 0.000223, l4: 0.000450, l5: 0.000959, l6: 0.001303

[epoch: 841/1000, batch:   480/ 1052, ite: 221040] train loss: 0.003579, tar: 0.000027 
l0: 0.000005, l1: 0.000006, l2: 0.000020, l3: 0.000067, l4: 0.000241, l5: 0.001069, l6: 0.001459

[epoch: 841/1000, batch:   560/ 1052, ite: 221060] train loss: 0.003689, tar: 0.000025 
l0: 0.000033, l1: 0.000032, l2: 0.000064, l3: 0.000282, l4: 0.000762, l5: 0.001611, l6: 0.002252

[epoch: 841/1000, batch:   640/ 1052, ite: 221080] train loss: 0.003699, tar: 0.000026 
l0: 0.000012, l1: 0.000013, l2: 0.000037, l3: 0.000083, l4: 0.000318, l5: 0.000968, l6: 0.001659

[epoch: 841/1000, batch:   720/ 1052, ite: 221100] train loss: 0.003721, tar: 0.000025 
l0: 0.000003, l1: 0.000003, l2: 0.000042, l3: 0.000101, l4: 0.000330, l5: 0.000871, l6: 0.001758

[epoch: 841/1000, batch:   800/ 1052, ite: 221120] train loss: 0.003753, tar: 0.000025 
l0: 0.000015, l1: 0.000014, l2: 0.000040, l3: 0.000231, l4: 0.000365, l5: 0.001083, l6: 0.000915

[epoch: 841/1000, batch:   880/ 1052, ite: 221140] train loss: 0.003795, tar: 0.000024 
l0: 0.000140, l1: 0.000141, l2: 0.000261, l3: 0.000465, l4: 0.001010, l5: 0.001666, l6: 0.003678

[epoch: 841/1000, batch:   960/ 1052, ite: 221160] train loss: 0.003840, tar: 0.000025 
l0: 0.000012, l1: 0.000011, l2: 0.000078, l3: 0.000328, l4: 0.000920, l5: 0.001864, l6: 0.002872

[epoch: 841/1000, batch:  1040/ 1052, ite: 221180] train loss: 0.003845, tar: 0.000025 
[Epoch 841/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000032, l1: 0.000035, l2: 0.000067, l3: 0.000128, l4: 0.000392, l5: 0.001495, l6: 0.002680

[epoch: 842/1000, batch:    68/ 1052, ite: 221200] train loss: 0.003831, tar: 0.000024 
l0: 0.000038, l1: 0.000037, l2: 0.000095, l3: 0.000459, l4: 0.000719, l5: 0.001673, l6: 0.002766

[epoch: 842/1000, batch:   148/ 1052, ite: 221220] train loss: 0.003831, tar: 0.000024 
l0: 0.000007, l1: 0.000008, l2: 0.000046, l3: 0.000111, l4: 0.000378, l5: 0.000611, l6: 0.001047

[epoch: 842/1000, batch:   228/ 1052, ite: 221240] train loss: 0.003841, tar: 0.000024 
l0: 0.000003, l1: 0.000004, l2: 0.000016, l3: 0.000096, l4: 0.000191, l5: 0.001014, l6: 0.001046

[epoch: 842/1000, batch:   308/ 1052, ite: 221260] train loss: 0.003857, tar: 0.000024 
l0: 0.000086, l1: 0.000089, l2: 0.000104, l3: 0.000144, l4: 0.000424, l5: 0.001488, l6: 0.001498

[epoch: 842/1000, batch:   388/ 1052, ite: 221280] train loss: 0.003852, tar: 0.000024 
l0: 0.000034, l1: 0.000034, l2: 0.000122, l3: 0.000213, l4: 0.000626, l5: 0.001052, l6: 0.002211

[epoch: 842/1000, batch:   468/ 1052, ite: 221300] train loss: 0.003870, tar: 0.000025 
l0: 0.000012, l1: 0.000011, l2: 0.000051, l3: 0.000080, l4: 0.000277, l5: 0.000864, l6: 0.001426

[epoch: 842/1000, batch:   548/ 1052, ite: 221320] train loss: 0.003908, tar: 0.000025 
l0: 0.000004, l1: 0.000004, l2: 0.000040, l3: 0.000128, l4: 0.000538, l5: 0.000716, l6: 0.001718

[epoch: 842/1000, batch:   628/ 1052, ite: 221340] train loss: 0.003891, tar: 0.000024 
l0: 0.000009, l1: 0.000010, l2: 0.000039, l3: 0.000170, l4: 0.000578, l5: 0.000782, l6: 0.001490

[epoch: 842/1000, batch:   708/ 1052, ite: 221360] train loss: 0.003888, tar: 0.000024 
l0: 0.000029, l1: 0.000030, l2: 0.000052, l3: 0.000154, l4: 0.000483, l5: 0.001132, l6: 0.002184

[epoch: 842/1000, batch:   788/ 1052, ite: 221380] train loss: 0.003868, tar: 0.000024 
l0: 0.000019, l1: 0.000018, l2: 0.000042, l3: 0.000144, l4: 0.000437, l5: 0.001251, l6: 0.001622

[epoch: 842/1000, batch:   868/ 1052, ite: 221400] train loss: 0.003857, tar: 0.000024 
l0: 0.000091, l1: 0.000091, l2: 0.000096, l3: 0.000178, l4: 0.000332, l5: 0.000604, l6: 0.001352

[epoch: 842/1000, batch:   948/ 1052, ite: 221420] train loss: 0.003845, tar: 0.000025 
l0: 0.000000, l1: 0.000000, l2: 0.000014, l3: 0.000097, l4: 0.000214, l5: 0.001000, l6: 0.001640

[epoch: 842/1000, batch:  1028/ 1052, ite: 221440] train loss: 0.003834, tar: 0.000024 
[Epoch 842/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000102, l1: 0.000101, l2: 0.000184, l3: 0.000264, l4: 0.000354, l5: 0.000700, l6: 0.000575

[epoch: 843/1000, batch:    56/ 1052, ite: 221460] train loss: 0.003828, tar: 0.000025 
l0: 0.000003, l1: 0.000004, l2: 0.000020, l3: 0.000081, l4: 0.000304, l5: 0.000505, l6: 0.001208

[epoch: 843/1000, batch:   136/ 1052, ite: 221480] train loss: 0.003824, tar: 0.000025 
l0: 0.000021, l1: 0.000024, l2: 0.000120, l3: 0.000360, l4: 0.000806, l5: 0.002436, l6: 0.004614

[epoch: 843/1000, batch:   216/ 1052, ite: 221500] train loss: 0.003824, tar: 0.000024 
l0: 0.000017, l1: 0.000017, l2: 0.000059, l3: 0.000141, l4: 0.000438, l5: 0.000834, l6: 0.001517

[epoch: 843/1000, batch:   296/ 1052, ite: 221520] train loss: 0.003828, tar: 0.000024 
l0: 0.000022, l1: 0.000023, l2: 0.000028, l3: 0.000046, l4: 0.000226, l5: 0.000658, l6: 0.001389

[epoch: 843/1000, batch:   376/ 1052, ite: 221540] train loss: 0.003823, tar: 0.000025 
l0: 0.000021, l1: 0.000017, l2: 0.000053, l3: 0.000103, l4: 0.000318, l5: 0.000750, l6: 0.000641

[epoch: 843/1000, batch:   456/ 1052, ite: 221560] train loss: 0.003825, tar: 0.000025 
l0: 0.000053, l1: 0.000055, l2: 0.000059, l3: 0.000198, l4: 0.000527, l5: 0.001030, l6: 0.002107

[epoch: 843/1000, batch:   536/ 1052, ite: 221580] train loss: 0.003831, tar: 0.000025 
l0: 0.000023, l1: 0.000024, l2: 0.000050, l3: 0.000098, l4: 0.000487, l5: 0.000729, l6: 0.001600

[epoch: 843/1000, batch:   616/ 1052, ite: 221600] train loss: 0.003828, tar: 0.000026 
l0: 0.000004, l1: 0.000005, l2: 0.000037, l3: 0.000155, l4: 0.000241, l5: 0.001115, l6: 0.001593

[epoch: 843/1000, batch:   696/ 1052, ite: 221620] train loss: 0.003839, tar: 0.000026 
l0: 0.000034, l1: 0.000035, l2: 0.000074, l3: 0.000188, l4: 0.000454, l5: 0.001773, l6: 0.002696

[epoch: 843/1000, batch:   776/ 1052, ite: 221640] train loss: 0.003844, tar: 0.000026 
l0: 0.000042, l1: 0.000042, l2: 0.000090, l3: 0.000228, l4: 0.000375, l5: 0.001116, l6: 0.001209

[epoch: 843/1000, batch:   856/ 1052, ite: 221660] train loss: 0.003835, tar: 0.000026 
l0: 0.000082, l1: 0.000086, l2: 0.000092, l3: 0.000289, l4: 0.000635, l5: 0.001291, l6: 0.003638

[epoch: 843/1000, batch:   936/ 1052, ite: 221680] train loss: 0.003840, tar: 0.000026 
l0: 0.000003, l1: 0.000003, l2: 0.000037, l3: 0.000130, l4: 0.000338, l5: 0.000516, l6: 0.001734

[epoch: 843/1000, batch:  1016/ 1052, ite: 221700] train loss: 0.003848, tar: 0.000026 
[Epoch 843/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000010, l1: 0.000009, l2: 0.000020, l3: 0.000129, l4: 0.000275, l5: 0.000789, l6: 0.001138

[epoch: 844/1000, batch:    44/ 1052, ite: 221720] train loss: 0.003828, tar: 0.000025 
l0: 0.000047, l1: 0.000048, l2: 0.000060, l3: 0.000145, l4: 0.000403, l5: 0.001213, l6: 0.001933

[epoch: 844/1000, batch:   124/ 1052, ite: 221740] train loss: 0.003822, tar: 0.000025 
l0: 0.000098, l1: 0.000105, l2: 0.000153, l3: 0.000314, l4: 0.000757, l5: 0.001278, l6: 0.003036

[epoch: 844/1000, batch:   204/ 1052, ite: 221760] train loss: 0.003826, tar: 0.000025 
l0: 0.000019, l1: 0.000016, l2: 0.000053, l3: 0.000117, l4: 0.000305, l5: 0.000941, l6: 0.002384

[epoch: 844/1000, batch:   284/ 1052, ite: 221780] train loss: 0.003835, tar: 0.000025 
l0: 0.000021, l1: 0.000023, l2: 0.000054, l3: 0.000175, l4: 0.000565, l5: 0.000990, l6: 0.002674

[epoch: 844/1000, batch:   364/ 1052, ite: 221800] train loss: 0.003837, tar: 0.000025 
l0: 0.000013, l1: 0.000012, l2: 0.000034, l3: 0.000184, l4: 0.000458, l5: 0.001111, l6: 0.002470

[epoch: 844/1000, batch:   444/ 1052, ite: 221820] train loss: 0.003849, tar: 0.000025 
l0: 0.000019, l1: 0.000019, l2: 0.000097, l3: 0.000289, l4: 0.000679, l5: 0.001552, l6: 0.001998

[epoch: 844/1000, batch:   524/ 1052, ite: 221840] train loss: 0.003846, tar: 0.000025 
l0: 0.000009, l1: 0.000010, l2: 0.000051, l3: 0.000219, l4: 0.000606, l5: 0.001135, l6: 0.003035

[epoch: 844/1000, batch:   604/ 1052, ite: 221860] train loss: 0.003839, tar: 0.000025 
l0: 0.000008, l1: 0.000008, l2: 0.000025, l3: 0.000287, l4: 0.000513, l5: 0.001597, l6: 0.002050

[epoch: 844/1000, batch:   684/ 1052, ite: 221880] train loss: 0.003853, tar: 0.000024 
l0: 0.000046, l1: 0.000042, l2: 0.000126, l3: 0.000358, l4: 0.000532, l5: 0.000861, l6: 0.002386

[epoch: 844/1000, batch:   764/ 1052, ite: 221900] train loss: 0.003852, tar: 0.000024 
l0: 0.000079, l1: 0.000077, l2: 0.000134, l3: 0.000314, l4: 0.000580, l5: 0.001535, l6: 0.003376

[epoch: 844/1000, batch:   844/ 1052, ite: 221920] train loss: 0.003844, tar: 0.000024 
l0: 0.000040, l1: 0.000041, l2: 0.000103, l3: 0.000416, l4: 0.001003, l5: 0.002327, l6: 0.003743

[epoch: 844/1000, batch:   924/ 1052, ite: 221940] train loss: 0.003847, tar: 0.000025 
l0: 0.000026, l1: 0.000028, l2: 0.000024, l3: 0.000135, l4: 0.000409, l5: 0.000903, l6: 0.001333

[epoch: 844/1000, batch:  1004/ 1052, ite: 221960] train loss: 0.003851, tar: 0.000025 
[Epoch 844/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000161, l1: 0.000163, l2: 0.000254, l3: 0.000595, l4: 0.001986, l5: 0.004273, l6: 0.006025

[epoch: 845/1000, batch:    32/ 1052, ite: 221980] train loss: 0.003846, tar: 0.000025 
l0: 0.000003, l1: 0.000004, l2: 0.000047, l3: 0.000155, l4: 0.000388, l5: 0.001256, l6: 0.002135

[epoch: 845/1000, batch:   112/ 1052, ite: 222000] train loss: 0.003846, tar: 0.000025 
l0: 0.000104, l1: 0.000100, l2: 0.000103, l3: 0.000234, l4: 0.000465, l5: 0.001612, l6: 0.002603

[epoch: 845/1000, batch:   192/ 1052, ite: 222020] train loss: 0.003858, tar: 0.000025 
l0: 0.000086, l1: 0.000087, l2: 0.000111, l3: 0.000140, l4: 0.000333, l5: 0.000950, l6: 0.001418

[epoch: 845/1000, batch:   272/ 1052, ite: 222040] train loss: 0.003848, tar: 0.000025 
l0: 0.000054, l1: 0.000060, l2: 0.000091, l3: 0.000237, l4: 0.000704, l5: 0.001279, l6: 0.003284

[epoch: 845/1000, batch:   352/ 1052, ite: 222060] train loss: 0.003839, tar: 0.000025 
l0: 0.000015, l1: 0.000016, l2: 0.000031, l3: 0.000108, l4: 0.000290, l5: 0.000639, l6: 0.001113

[epoch: 845/1000, batch:   432/ 1052, ite: 222080] train loss: 0.003839, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000026, l3: 0.000116, l4: 0.000466, l5: 0.000812, l6: 0.001947

[epoch: 845/1000, batch:   512/ 1052, ite: 222100] train loss: 0.003842, tar: 0.000025 
l0: 0.000020, l1: 0.000022, l2: 0.000065, l3: 0.000268, l4: 0.000636, l5: 0.001299, l6: 0.002107

[epoch: 845/1000, batch:   592/ 1052, ite: 222120] train loss: 0.003841, tar: 0.000025 
l0: 0.000011, l1: 0.000012, l2: 0.000059, l3: 0.000231, l4: 0.000483, l5: 0.001150, l6: 0.001805

[epoch: 845/1000, batch:   672/ 1052, ite: 222140] train loss: 0.003848, tar: 0.000025 
l0: 0.000041, l1: 0.000038, l2: 0.000111, l3: 0.000307, l4: 0.000507, l5: 0.000990, l6: 0.001606

[epoch: 845/1000, batch:   752/ 1052, ite: 222160] train loss: 0.003843, tar: 0.000025 
l0: 0.000008, l1: 0.000009, l2: 0.000019, l3: 0.000068, l4: 0.000208, l5: 0.000543, l6: 0.001322

[epoch: 845/1000, batch:   832/ 1052, ite: 222180] train loss: 0.003836, tar: 0.000025 
l0: 0.000003, l1: 0.000003, l2: 0.000048, l3: 0.000179, l4: 0.000393, l5: 0.001131, l6: 0.002217

[epoch: 845/1000, batch:   912/ 1052, ite: 222200] train loss: 0.003834, tar: 0.000025 
l0: 0.000051, l1: 0.000053, l2: 0.000082, l3: 0.000228, l4: 0.000551, l5: 0.001662, l6: 0.003552

[epoch: 845/1000, batch:   992/ 1052, ite: 222220] train loss: 0.003843, tar: 0.000025 
[Epoch 845/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000003, l1: 0.000004, l2: 0.000018, l3: 0.000096, l4: 0.000438, l5: 0.000594, l6: 0.001060

[epoch: 846/1000, batch:    20/ 1052, ite: 222240] train loss: 0.003854, tar: 0.000025 
l0: 0.000067, l1: 0.000066, l2: 0.000190, l3: 0.000414, l4: 0.000803, l5: 0.002256, l6: 0.002908

[epoch: 846/1000, batch:   100/ 1052, ite: 222260] train loss: 0.003854, tar: 0.000025 
l0: 0.000007, l1: 0.000007, l2: 0.000073, l3: 0.000269, l4: 0.000493, l5: 0.000983, l6: 0.001834

[epoch: 846/1000, batch:   180/ 1052, ite: 222280] train loss: 0.003857, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000013, l3: 0.000068, l4: 0.000308, l5: 0.001003, l6: 0.001424

[epoch: 846/1000, batch:   260/ 1052, ite: 222300] train loss: 0.003860, tar: 0.000025 
l0: 0.000011, l1: 0.000011, l2: 0.000087, l3: 0.000226, l4: 0.000403, l5: 0.000931, l6: 0.001390

[epoch: 846/1000, batch:   340/ 1052, ite: 222320] train loss: 0.003859, tar: 0.000025 
l0: 0.000012, l1: 0.000012, l2: 0.000043, l3: 0.000206, l4: 0.000549, l5: 0.001003, l6: 0.001769

[epoch: 846/1000, batch:   420/ 1052, ite: 222340] train loss: 0.003851, tar: 0.000025 
l0: 0.000037, l1: 0.000038, l2: 0.000058, l3: 0.000133, l4: 0.000416, l5: 0.001144, l6: 0.003380

[epoch: 846/1000, batch:   500/ 1052, ite: 222360] train loss: 0.003851, tar: 0.000025 
l0: 0.000048, l1: 0.000048, l2: 0.000089, l3: 0.000253, l4: 0.000449, l5: 0.001126, l6: 0.001967

[epoch: 846/1000, batch:   580/ 1052, ite: 222380] train loss: 0.003849, tar: 0.000025 
l0: 0.000023, l1: 0.000023, l2: 0.000042, l3: 0.000130, l4: 0.000306, l5: 0.001376, l6: 0.002472

[epoch: 846/1000, batch:   660/ 1052, ite: 222400] train loss: 0.003846, tar: 0.000025 
l0: 0.000022, l1: 0.000022, l2: 0.000038, l3: 0.000119, l4: 0.000410, l5: 0.000994, l6: 0.001405

[epoch: 846/1000, batch:   740/ 1052, ite: 222420] train loss: 0.003845, tar: 0.000025 
l0: 0.000012, l1: 0.000013, l2: 0.000020, l3: 0.000113, l4: 0.000410, l5: 0.000680, l6: 0.001128

[epoch: 846/1000, batch:   820/ 1052, ite: 222440] train loss: 0.003846, tar: 0.000025 
l0: 0.000038, l1: 0.000041, l2: 0.000105, l3: 0.000516, l4: 0.000934, l5: 0.001624, l6: 0.003917

[epoch: 846/1000, batch:   900/ 1052, ite: 222460] train loss: 0.003852, tar: 0.000025 
l0: 0.000025, l1: 0.000027, l2: 0.000037, l3: 0.000133, l4: 0.000398, l5: 0.000512, l6: 0.001141

[epoch: 846/1000, batch:   980/ 1052, ite: 222480] train loss: 0.003855, tar: 0.000025 
[Epoch 846/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000006, l1: 0.000007, l2: 0.000028, l3: 0.000095, l4: 0.000199, l5: 0.000748, l6: 0.001000

[epoch: 847/1000, batch:     8/ 1052, ite: 222500] train loss: 0.003852, tar: 0.000025 
l0: 0.000068, l1: 0.000070, l2: 0.000073, l3: 0.000166, l4: 0.000460, l5: 0.000858, l6: 0.001281

[epoch: 847/1000, batch:    88/ 1052, ite: 222520] train loss: 0.003847, tar: 0.000025 
l0: 0.000005, l1: 0.000004, l2: 0.000039, l3: 0.000158, l4: 0.000394, l5: 0.000813, l6: 0.001178

[epoch: 847/1000, batch:   168/ 1052, ite: 222540] train loss: 0.003846, tar: 0.000025 
l0: 0.000004, l1: 0.000003, l2: 0.000032, l3: 0.000242, l4: 0.000702, l5: 0.001211, l6: 0.002105

[epoch: 847/1000, batch:   248/ 1052, ite: 222560] train loss: 0.003841, tar: 0.000025 
l0: 0.000015, l1: 0.000016, l2: 0.000052, l3: 0.000115, l4: 0.000490, l5: 0.001354, l6: 0.002570

[epoch: 847/1000, batch:   328/ 1052, ite: 222580] train loss: 0.003842, tar: 0.000025 
l0: 0.000013, l1: 0.000014, l2: 0.000027, l3: 0.000097, l4: 0.000388, l5: 0.000808, l6: 0.001239

[epoch: 847/1000, batch:   408/ 1052, ite: 222600] train loss: 0.003848, tar: 0.000025 
l0: 0.000068, l1: 0.000070, l2: 0.000142, l3: 0.000257, l4: 0.000618, l5: 0.001597, l6: 0.004495

[epoch: 847/1000, batch:   488/ 1052, ite: 222620] train loss: 0.003856, tar: 0.000025 
l0: 0.000046, l1: 0.000044, l2: 0.000064, l3: 0.000209, l4: 0.000503, l5: 0.001390, l6: 0.002699

[epoch: 847/1000, batch:   568/ 1052, ite: 222640] train loss: 0.003855, tar: 0.000025 
l0: 0.000023, l1: 0.000023, l2: 0.000061, l3: 0.000272, l4: 0.000627, l5: 0.001109, l6: 0.002331

[epoch: 847/1000, batch:   648/ 1052, ite: 222660] train loss: 0.003863, tar: 0.000025 
l0: 0.000015, l1: 0.000015, l2: 0.000029, l3: 0.000098, l4: 0.000186, l5: 0.000728, l6: 0.000960

[epoch: 847/1000, batch:   728/ 1052, ite: 222680] train loss: 0.003858, tar: 0.000025 
l0: 0.000016, l1: 0.000016, l2: 0.000064, l3: 0.000206, l4: 0.000460, l5: 0.001531, l6: 0.002183

[epoch: 847/1000, batch:   808/ 1052, ite: 222700] train loss: 0.003853, tar: 0.000025 
l0: 0.000015, l1: 0.000014, l2: 0.000027, l3: 0.000047, l4: 0.000252, l5: 0.000571, l6: 0.000794

[epoch: 847/1000, batch:   888/ 1052, ite: 222720] train loss: 0.003848, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000023, l3: 0.000150, l4: 0.000426, l5: 0.001004, l6: 0.001976

[epoch: 847/1000, batch:   968/ 1052, ite: 222740] train loss: 0.003848, tar: 0.000025 
l0: 0.000063, l1: 0.000061, l2: 0.000142, l3: 0.000248, l4: 0.000522, l5: 0.001003, l6: 0.002082

[epoch: 847/1000, batch:  1048/ 1052, ite: 222760] train loss: 0.003853, tar: 0.000025 
[Epoch 847/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000015, l1: 0.000017, l2: 0.000031, l3: 0.000129, l4: 0.000401, l5: 0.000947, l6: 0.002397

[epoch: 848/1000, batch:    76/ 1052, ite: 222780] train loss: 0.003852, tar: 0.000025 
l0: 0.000014, l1: 0.000013, l2: 0.000100, l3: 0.000260, l4: 0.000451, l5: 0.001015, l6: 0.002719

[epoch: 848/1000, batch:   156/ 1052, ite: 222800] train loss: 0.003853, tar: 0.000025 
l0: 0.000205, l1: 0.000205, l2: 0.000243, l3: 0.000294, l4: 0.000373, l5: 0.000772, l6: 0.002470

[epoch: 848/1000, batch:   236/ 1052, ite: 222820] train loss: 0.003854, tar: 0.000025 
l0: 0.000026, l1: 0.000026, l2: 0.000054, l3: 0.000095, l4: 0.000132, l5: 0.000566, l6: 0.001629

[epoch: 848/1000, batch:   316/ 1052, ite: 222840] train loss: 0.003853, tar: 0.000025 
l0: 0.000029, l1: 0.000027, l2: 0.000054, l3: 0.000175, l4: 0.000578, l5: 0.001113, l6: 0.002116

[epoch: 848/1000, batch:   396/ 1052, ite: 222860] train loss: 0.003854, tar: 0.000025 
l0: 0.000029, l1: 0.000028, l2: 0.000082, l3: 0.000191, l4: 0.000759, l5: 0.001287, l6: 0.002448

[epoch: 848/1000, batch:   476/ 1052, ite: 222880] train loss: 0.003858, tar: 0.000025 
l0: 0.000026, l1: 0.000027, l2: 0.000072, l3: 0.000357, l4: 0.000564, l5: 0.000999, l6: 0.001746

[epoch: 848/1000, batch:   556/ 1052, ite: 222900] train loss: 0.003854, tar: 0.000025 
l0: 0.000046, l1: 0.000045, l2: 0.000098, l3: 0.000230, l4: 0.000507, l5: 0.001268, l6: 0.001842

[epoch: 848/1000, batch:   636/ 1052, ite: 222920] train loss: 0.003856, tar: 0.000025 
l0: 0.000006, l1: 0.000007, l2: 0.000032, l3: 0.000125, l4: 0.000421, l5: 0.001034, l6: 0.001346

[epoch: 848/1000, batch:   716/ 1052, ite: 222940] train loss: 0.003854, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000043, l3: 0.000133, l4: 0.000389, l5: 0.001140, l6: 0.002287

[epoch: 848/1000, batch:   796/ 1052, ite: 222960] train loss: 0.003849, tar: 0.000025 
l0: 0.000026, l1: 0.000024, l2: 0.000080, l3: 0.000243, l4: 0.000550, l5: 0.001000, l6: 0.001693

[epoch: 848/1000, batch:   876/ 1052, ite: 222980] train loss: 0.003848, tar: 0.000025 
l0: 0.000032, l1: 0.000034, l2: 0.000096, l3: 0.000301, l4: 0.000648, l5: 0.001558, l6: 0.003878

[epoch: 848/1000, batch:   956/ 1052, ite: 223000] train loss: 0.003848, tar: 0.000025 
l0: 0.000103, l1: 0.000096, l2: 0.000149, l3: 0.000204, l4: 0.000356, l5: 0.001021, l6: 0.001887

[epoch: 848/1000, batch:  1036/ 1052, ite: 223020] train loss: 0.003847, tar: 0.000025 
[Epoch 848/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000034, l1: 0.000035, l2: 0.000085, l3: 0.000221, l4: 0.000406, l5: 0.001006, l6: 0.002686

[epoch: 849/1000, batch:    64/ 1052, ite: 223040] train loss: 0.003851, tar: 0.000025 
l0: 0.000010, l1: 0.000010, l2: 0.000047, l3: 0.000199, l4: 0.000500, l5: 0.001476, l6: 0.002262

[epoch: 849/1000, batch:   144/ 1052, ite: 223060] train loss: 0.003850, tar: 0.000025 
l0: 0.000022, l1: 0.000019, l2: 0.000041, l3: 0.000114, l4: 0.000369, l5: 0.000637, l6: 0.001321

[epoch: 849/1000, batch:   224/ 1052, ite: 223080] train loss: 0.003851, tar: 0.000025 
l0: 0.000010, l1: 0.000009, l2: 0.000033, l3: 0.000165, l4: 0.000275, l5: 0.000610, l6: 0.002013

[epoch: 849/1000, batch:   304/ 1052, ite: 223100] train loss: 0.003851, tar: 0.000025 
l0: 0.000023, l1: 0.000025, l2: 0.000053, l3: 0.000122, l4: 0.000369, l5: 0.000817, l6: 0.001184

[epoch: 849/1000, batch:   384/ 1052, ite: 223120] train loss: 0.003846, tar: 0.000025 
l0: 0.000016, l1: 0.000016, l2: 0.000043, l3: 0.000134, l4: 0.000553, l5: 0.001766, l6: 0.002671

[epoch: 849/1000, batch:   464/ 1052, ite: 223140] train loss: 0.003846, tar: 0.000025 
l0: 0.000017, l1: 0.000018, l2: 0.000044, l3: 0.000088, l4: 0.000214, l5: 0.000859, l6: 0.002134

[epoch: 849/1000, batch:   544/ 1052, ite: 223160] train loss: 0.003847, tar: 0.000025 
l0: 0.000004, l1: 0.000006, l2: 0.000022, l3: 0.000146, l4: 0.000439, l5: 0.001595, l6: 0.002137

[epoch: 849/1000, batch:   624/ 1052, ite: 223180] train loss: 0.003847, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000020, l3: 0.000072, l4: 0.000351, l5: 0.000839, l6: 0.000972

[epoch: 849/1000, batch:   704/ 1052, ite: 223200] train loss: 0.003849, tar: 0.000025 
l0: 0.000008, l1: 0.000008, l2: 0.000044, l3: 0.000140, l4: 0.000291, l5: 0.000724, l6: 0.002239

[epoch: 849/1000, batch:   784/ 1052, ite: 223220] train loss: 0.003851, tar: 0.000025 
l0: 0.000029, l1: 0.000031, l2: 0.000117, l3: 0.000286, l4: 0.000766, l5: 0.001613, l6: 0.002634

[epoch: 849/1000, batch:   864/ 1052, ite: 223240] train loss: 0.003850, tar: 0.000025 
l0: 0.000003, l1: 0.000004, l2: 0.000011, l3: 0.000054, l4: 0.000153, l5: 0.000411, l6: 0.000907

[epoch: 849/1000, batch:   944/ 1052, ite: 223260] train loss: 0.003845, tar: 0.000025 
l0: 0.000002, l1: 0.000003, l2: 0.000010, l3: 0.000073, l4: 0.000246, l5: 0.000695, l6: 0.001285

[epoch: 849/1000, batch:  1024/ 1052, ite: 223280] train loss: 0.003842, tar: 0.000025 
[Epoch 849/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000030, l1: 0.000031, l2: 0.000059, l3: 0.000193, l4: 0.000394, l5: 0.001015, l6: 0.003406

[epoch: 850/1000, batch:    52/ 1052, ite: 223300] train loss: 0.003844, tar: 0.000025 
l0: 0.000014, l1: 0.000013, l2: 0.000036, l3: 0.000120, l4: 0.000233, l5: 0.000806, l6: 0.000878

[epoch: 850/1000, batch:   132/ 1052, ite: 223320] train loss: 0.003843, tar: 0.000025 
l0: 0.000063, l1: 0.000062, l2: 0.000096, l3: 0.000225, l4: 0.000478, l5: 0.001584, l6: 0.001954

[epoch: 850/1000, batch:   212/ 1052, ite: 223340] train loss: 0.003842, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000010, l3: 0.000038, l4: 0.000332, l5: 0.000783, l6: 0.001394

[epoch: 850/1000, batch:   292/ 1052, ite: 223360] train loss: 0.003843, tar: 0.000025 
l0: 0.000012, l1: 0.000012, l2: 0.000037, l3: 0.000128, l4: 0.000395, l5: 0.001531, l6: 0.002023

[epoch: 850/1000, batch:   372/ 1052, ite: 223380] train loss: 0.003843, tar: 0.000025 
l0: 0.000019, l1: 0.000018, l2: 0.000051, l3: 0.000154, l4: 0.000302, l5: 0.000887, l6: 0.001821

[epoch: 850/1000, batch:   452/ 1052, ite: 223400] train loss: 0.003840, tar: 0.000025 
l0: 0.000145, l1: 0.000131, l2: 0.000152, l3: 0.000186, l4: 0.000467, l5: 0.001329, l6: 0.001953

[epoch: 850/1000, batch:   532/ 1052, ite: 223420] train loss: 0.003838, tar: 0.000025 
l0: 0.000099, l1: 0.000099, l2: 0.000210, l3: 0.000499, l4: 0.000947, l5: 0.003099, l6: 0.007460

[epoch: 850/1000, batch:   612/ 1052, ite: 223440] train loss: 0.003843, tar: 0.000025 
l0: 0.000007, l1: 0.000007, l2: 0.000045, l3: 0.000338, l4: 0.000924, l5: 0.001470, l6: 0.002768

[epoch: 850/1000, batch:   692/ 1052, ite: 223460] train loss: 0.003842, tar: 0.000025 
l0: 0.000050, l1: 0.000056, l2: 0.000100, l3: 0.000219, l4: 0.000520, l5: 0.000971, l6: 0.001813

[epoch: 850/1000, batch:   772/ 1052, ite: 223480] train loss: 0.003841, tar: 0.000025 
l0: 0.000016, l1: 0.000017, l2: 0.000036, l3: 0.000147, l4: 0.000580, l5: 0.001346, l6: 0.002085

[epoch: 850/1000, batch:   852/ 1052, ite: 223500] train loss: 0.003841, tar: 0.000025 
l0: 0.000057, l1: 0.000064, l2: 0.000087, l3: 0.000170, l4: 0.000413, l5: 0.000954, l6: 0.001438

[epoch: 850/1000, batch:   932/ 1052, ite: 223520] train loss: 0.003843, tar: 0.000025 
l0: 0.000014, l1: 0.000015, l2: 0.000036, l3: 0.000105, l4: 0.000403, l5: 0.000937, l6: 0.001460

[epoch: 850/1000, batch:  1012/ 1052, ite: 223540] train loss: 0.003840, tar: 0.000025 
[Epoch 850/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000129, l1: 0.000127, l2: 0.000223, l3: 0.000473, l4: 0.000748, l5: 0.001711, l6: 0.005482

[epoch: 851/1000, batch:    40/ 1052, ite: 223560] train loss: 0.003837, tar: 0.000025 
l0: 0.000028, l1: 0.000025, l2: 0.000059, l3: 0.000107, l4: 0.000376, l5: 0.000711, l6: 0.000975

[epoch: 851/1000, batch:   120/ 1052, ite: 223580] train loss: 0.003838, tar: 0.000025 
l0: 0.000032, l1: 0.000033, l2: 0.000127, l3: 0.000462, l4: 0.000980, l5: 0.001563, l6: 0.002181

[epoch: 851/1000, batch:   200/ 1052, ite: 223600] train loss: 0.003839, tar: 0.000025 
l0: 0.000003, l1: 0.000003, l2: 0.000025, l3: 0.000111, l4: 0.000453, l5: 0.000963, l6: 0.000947

[epoch: 851/1000, batch:   280/ 1052, ite: 223620] train loss: 0.003838, tar: 0.000025 
l0: 0.000143, l1: 0.000149, l2: 0.000175, l3: 0.000273, l4: 0.000545, l5: 0.001250, l6: 0.003077

[epoch: 851/1000, batch:   360/ 1052, ite: 223640] train loss: 0.003838, tar: 0.000025 
l0: 0.000022, l1: 0.000027, l2: 0.000061, l3: 0.000198, l4: 0.000399, l5: 0.000857, l6: 0.001753

[epoch: 851/1000, batch:   440/ 1052, ite: 223660] train loss: 0.003837, tar: 0.000025 
l0: 0.000013, l1: 0.000012, l2: 0.000033, l3: 0.000080, l4: 0.000324, l5: 0.000815, l6: 0.001304

[epoch: 851/1000, batch:   520/ 1052, ite: 223680] train loss: 0.003837, tar: 0.000025 
l0: 0.000024, l1: 0.000023, l2: 0.000046, l3: 0.000130, l4: 0.000358, l5: 0.000719, l6: 0.001471

[epoch: 851/1000, batch:   600/ 1052, ite: 223700] train loss: 0.003837, tar: 0.000025 
l0: 0.000025, l1: 0.000026, l2: 0.000052, l3: 0.000182, l4: 0.000413, l5: 0.001089, l6: 0.002649

[epoch: 851/1000, batch:   680/ 1052, ite: 223720] train loss: 0.003843, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000008, l3: 0.000062, l4: 0.000261, l5: 0.000565, l6: 0.001152

[epoch: 851/1000, batch:   760/ 1052, ite: 223740] train loss: 0.003843, tar: 0.000025 
l0: 0.000028, l1: 0.000031, l2: 0.000037, l3: 0.000108, l4: 0.000544, l5: 0.000759, l6: 0.001447

[epoch: 851/1000, batch:   840/ 1052, ite: 223760] train loss: 0.003843, tar: 0.000025 
l0: 0.000035, l1: 0.000032, l2: 0.000069, l3: 0.000172, l4: 0.000522, l5: 0.001062, l6: 0.002301

[epoch: 851/1000, batch:   920/ 1052, ite: 223780] train loss: 0.003844, tar: 0.000025 
l0: 0.000008, l1: 0.000008, l2: 0.000026, l3: 0.000090, l4: 0.000313, l5: 0.000651, l6: 0.001343

[epoch: 851/1000, batch:  1000/ 1052, ite: 223800] train loss: 0.003841, tar: 0.000025 
[Epoch 851/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000023, l1: 0.000023, l2: 0.000068, l3: 0.000165, l4: 0.000423, l5: 0.001144, l6: 0.002454

[epoch: 852/1000, batch:    28/ 1052, ite: 223820] train loss: 0.003839, tar: 0.000025 
l0: 0.000013, l1: 0.000014, l2: 0.000030, l3: 0.000135, l4: 0.000325, l5: 0.000993, l6: 0.000933

[epoch: 852/1000, batch:   108/ 1052, ite: 223840] train loss: 0.003837, tar: 0.000025 
l0: 0.000055, l1: 0.000058, l2: 0.000120, l3: 0.000348, l4: 0.000815, l5: 0.001652, l6: 0.003512

[epoch: 852/1000, batch:   188/ 1052, ite: 223860] train loss: 0.003838, tar: 0.000025 
l0: 0.000036, l1: 0.000036, l2: 0.000066, l3: 0.000104, l4: 0.000410, l5: 0.001170, l6: 0.001938

[epoch: 852/1000, batch:   268/ 1052, ite: 223880] train loss: 0.003838, tar: 0.000025 
l0: 0.000026, l1: 0.000023, l2: 0.000081, l3: 0.000235, l4: 0.000675, l5: 0.000881, l6: 0.002149

[epoch: 852/1000, batch:   348/ 1052, ite: 223900] train loss: 0.003838, tar: 0.000025 
l0: 0.000026, l1: 0.000026, l2: 0.000090, l3: 0.000235, l4: 0.000727, l5: 0.001313, l6: 0.002236

[epoch: 852/1000, batch:   428/ 1052, ite: 223920] train loss: 0.003839, tar: 0.000025 
l0: 0.000015, l1: 0.000014, l2: 0.000054, l3: 0.000168, l4: 0.000401, l5: 0.001270, l6: 0.001550

[epoch: 852/1000, batch:   508/ 1052, ite: 223940] train loss: 0.003837, tar: 0.000025 
l0: 0.000023, l1: 0.000027, l2: 0.000051, l3: 0.000206, l4: 0.000664, l5: 0.001936, l6: 0.003114

[epoch: 852/1000, batch:   588/ 1052, ite: 223960] train loss: 0.003837, tar: 0.000025 
l0: 0.000016, l1: 0.000017, l2: 0.000012, l3: 0.000026, l4: 0.000150, l5: 0.000342, l6: 0.001084

[epoch: 852/1000, batch:   668/ 1052, ite: 223980] train loss: 0.003838, tar: 0.000025 
l0: 0.000027, l1: 0.000029, l2: 0.000061, l3: 0.000159, l4: 0.000578, l5: 0.001382, l6: 0.002430

[epoch: 852/1000, batch:   748/ 1052, ite: 224000] train loss: 0.003839, tar: 0.000025 
l0: 0.000029, l1: 0.000029, l2: 0.000062, l3: 0.000217, l4: 0.000819, l5: 0.001755, l6: 0.002232

[epoch: 852/1000, batch:   828/ 1052, ite: 224020] train loss: 0.003836, tar: 0.000025 
l0: 0.000032, l1: 0.000035, l2: 0.000062, l3: 0.000156, l4: 0.000431, l5: 0.001466, l6: 0.001757

[epoch: 852/1000, batch:   908/ 1052, ite: 224040] train loss: 0.003837, tar: 0.000025 
l0: 0.000035, l1: 0.000040, l2: 0.000048, l3: 0.000151, l4: 0.000453, l5: 0.001170, l6: 0.001654

[epoch: 852/1000, batch:   988/ 1052, ite: 224060] train loss: 0.003838, tar: 0.000025 
[Epoch 852/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000010, l1: 0.000010, l2: 0.000096, l3: 0.000309, l4: 0.001251, l5: 0.002339, l6: 0.004107

[epoch: 853/1000, batch:    16/ 1052, ite: 224080] train loss: 0.003842, tar: 0.000025 
l0: 0.000017, l1: 0.000018, l2: 0.000052, l3: 0.000217, l4: 0.000703, l5: 0.001424, l6: 0.002629

[epoch: 853/1000, batch:    96/ 1052, ite: 224100] train loss: 0.003840, tar: 0.000025 
l0: 0.000031, l1: 0.000033, l2: 0.000067, l3: 0.000137, l4: 0.000393, l5: 0.000961, l6: 0.002564

[epoch: 853/1000, batch:   176/ 1052, ite: 224120] train loss: 0.003839, tar: 0.000025 
l0: 0.000018, l1: 0.000018, l2: 0.000039, l3: 0.000113, l4: 0.000288, l5: 0.000740, l6: 0.001404

[epoch: 853/1000, batch:   256/ 1052, ite: 224140] train loss: 0.003843, tar: 0.000025 
l0: 0.000015, l1: 0.000016, l2: 0.000025, l3: 0.000077, l4: 0.000388, l5: 0.000938, l6: 0.001416

[epoch: 853/1000, batch:   336/ 1052, ite: 224160] train loss: 0.003843, tar: 0.000025 
l0: 0.000040, l1: 0.000041, l2: 0.000082, l3: 0.000183, l4: 0.000417, l5: 0.001301, l6: 0.002703

[epoch: 853/1000, batch:   416/ 1052, ite: 224180] train loss: 0.003848, tar: 0.000025 
l0: 0.000021, l1: 0.000020, l2: 0.000101, l3: 0.000329, l4: 0.000656, l5: 0.000872, l6: 0.002182

[epoch: 853/1000, batch:   496/ 1052, ite: 224200] train loss: 0.003846, tar: 0.000025 
l0: 0.000016, l1: 0.000017, l2: 0.000026, l3: 0.000116, l4: 0.000359, l5: 0.000966, l6: 0.001048

[epoch: 853/1000, batch:   576/ 1052, ite: 224220] train loss: 0.003845, tar: 0.000025 
l0: 0.000006, l1: 0.000006, l2: 0.000053, l3: 0.000087, l4: 0.000242, l5: 0.001024, l6: 0.001380

[epoch: 853/1000, batch:   656/ 1052, ite: 224240] train loss: 0.003846, tar: 0.000025 
l0: 0.000012, l1: 0.000013, l2: 0.000047, l3: 0.000105, l4: 0.000334, l5: 0.000765, l6: 0.001459

[epoch: 853/1000, batch:   736/ 1052, ite: 224260] train loss: 0.003845, tar: 0.000025 
l0: 0.000043, l1: 0.000047, l2: 0.000056, l3: 0.000174, l4: 0.000418, l5: 0.001381, l6: 0.002089

[epoch: 853/1000, batch:   816/ 1052, ite: 224280] train loss: 0.003844, tar: 0.000025 
l0: 0.000008, l1: 0.000007, l2: 0.000041, l3: 0.000199, l4: 0.000312, l5: 0.000924, l6: 0.002043

[epoch: 853/1000, batch:   896/ 1052, ite: 224300] train loss: 0.003843, tar: 0.000025 
l0: 0.000022, l1: 0.000022, l2: 0.000081, l3: 0.000374, l4: 0.000827, l5: 0.001708, l6: 0.003045

[epoch: 853/1000, batch:   976/ 1052, ite: 224320] train loss: 0.003843, tar: 0.000025 
[Epoch 853/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000037, l1: 0.000033, l2: 0.000076, l3: 0.000224, l4: 0.000334, l5: 0.000776, l6: 0.001427

[epoch: 854/1000, batch:     4/ 1052, ite: 224340] train loss: 0.003840, tar: 0.000025 
l0: 0.000014, l1: 0.000013, l2: 0.000032, l3: 0.000134, l4: 0.000388, l5: 0.000878, l6: 0.001043

[epoch: 854/1000, batch:    84/ 1052, ite: 224360] train loss: 0.003838, tar: 0.000025 
l0: 0.000000, l1: 0.000001, l2: 0.000007, l3: 0.000024, l4: 0.000432, l5: 0.000721, l6: 0.000971

[epoch: 854/1000, batch:   164/ 1052, ite: 224380] train loss: 0.003836, tar: 0.000025 
l0: 0.000031, l1: 0.000033, l2: 0.000074, l3: 0.000178, l4: 0.000518, l5: 0.000970, l6: 0.001338

[epoch: 854/1000, batch:   244/ 1052, ite: 224400] train loss: 0.003835, tar: 0.000025 
l0: 0.000002, l1: 0.000002, l2: 0.000010, l3: 0.000076, l4: 0.000312, l5: 0.000855, l6: 0.001433

[epoch: 854/1000, batch:   324/ 1052, ite: 224420] train loss: 0.003838, tar: 0.000025 
l0: 0.000010, l1: 0.000009, l2: 0.000069, l3: 0.000110, l4: 0.000400, l5: 0.000848, l6: 0.001083

[epoch: 854/1000, batch:   404/ 1052, ite: 224440] train loss: 0.003840, tar: 0.000025 
l0: 0.000021, l1: 0.000024, l2: 0.000046, l3: 0.000178, l4: 0.000446, l5: 0.001320, l6: 0.002295

[epoch: 854/1000, batch:   484/ 1052, ite: 224460] train loss: 0.003838, tar: 0.000025 
l0: 0.000040, l1: 0.000042, l2: 0.000145, l3: 0.000348, l4: 0.000983, l5: 0.002694, l6: 0.003781

[epoch: 854/1000, batch:   564/ 1052, ite: 224480] train loss: 0.003843, tar: 0.000025 
l0: 0.000044, l1: 0.000047, l2: 0.000118, l3: 0.000281, l4: 0.000637, l5: 0.001638, l6: 0.004305

[epoch: 854/1000, batch:   644/ 1052, ite: 224500] train loss: 0.003840, tar: 0.000025 
l0: 0.000041, l1: 0.000040, l2: 0.000054, l3: 0.000265, l4: 0.000611, l5: 0.002175, l6: 0.003139

[epoch: 854/1000, batch:   724/ 1052, ite: 224520] train loss: 0.003843, tar: 0.000025 
l0: 0.000011, l1: 0.000011, l2: 0.000121, l3: 0.000248, l4: 0.000496, l5: 0.000840, l6: 0.001343

[epoch: 854/1000, batch:   804/ 1052, ite: 224540] train loss: 0.003844, tar: 0.000025 
l0: 0.000009, l1: 0.000008, l2: 0.000022, l3: 0.000071, l4: 0.000246, l5: 0.000684, l6: 0.001776

[epoch: 854/1000, batch:   884/ 1052, ite: 224560] train loss: 0.003843, tar: 0.000025 
l0: 0.000009, l1: 0.000011, l2: 0.000018, l3: 0.000126, l4: 0.000493, l5: 0.000969, l6: 0.001717

[epoch: 854/1000, batch:   964/ 1052, ite: 224580] train loss: 0.003842, tar: 0.000025 
l0: 0.000118, l1: 0.000105, l2: 0.000179, l3: 0.000415, l4: 0.000917, l5: 0.002081, l6: 0.004214

[epoch: 854/1000, batch:  1044/ 1052, ite: 224600] train loss: 0.003842, tar: 0.000025 
[Epoch 854/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000021, l1: 0.000019, l2: 0.000021, l3: 0.000060, l4: 0.000278, l5: 0.000568, l6: 0.001088

[epoch: 855/1000, batch:    72/ 1052, ite: 224620] train loss: 0.003844, tar: 0.000025 
l0: 0.000018, l1: 0.000019, l2: 0.000044, l3: 0.000140, l4: 0.000413, l5: 0.000935, l6: 0.002086

[epoch: 855/1000, batch:   152/ 1052, ite: 224640] train loss: 0.003845, tar: 0.000025 
l0: 0.000029, l1: 0.000029, l2: 0.000044, l3: 0.000148, l4: 0.000603, l5: 0.000845, l6: 0.002641

[epoch: 855/1000, batch:   232/ 1052, ite: 224660] train loss: 0.003845, tar: 0.000025 
l0: 0.000021, l1: 0.000020, l2: 0.000063, l3: 0.000137, l4: 0.000388, l5: 0.000875, l6: 0.001357

[epoch: 855/1000, batch:   312/ 1052, ite: 224680] train loss: 0.003845, tar: 0.000025 
l0: 0.000003, l1: 0.000004, l2: 0.000014, l3: 0.000119, l4: 0.000309, l5: 0.000764, l6: 0.001616

[epoch: 855/1000, batch:   392/ 1052, ite: 224700] train loss: 0.003846, tar: 0.000025 
l0: 0.000002, l1: 0.000002, l2: 0.000010, l3: 0.000066, l4: 0.000374, l5: 0.000676, l6: 0.001521

[epoch: 855/1000, batch:   472/ 1052, ite: 224720] train loss: 0.003845, tar: 0.000025 
l0: 0.000015, l1: 0.000015, l2: 0.000048, l3: 0.000124, l4: 0.000324, l5: 0.000606, l6: 0.001556

[epoch: 855/1000, batch:   552/ 1052, ite: 224740] train loss: 0.003845, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000011, l3: 0.000063, l4: 0.000196, l5: 0.000746, l6: 0.001160

[epoch: 855/1000, batch:   632/ 1052, ite: 224760] train loss: 0.003844, tar: 0.000025 
l0: 0.000004, l1: 0.000004, l2: 0.000012, l3: 0.000086, l4: 0.000233, l5: 0.001046, l6: 0.001988

[epoch: 855/1000, batch:   712/ 1052, ite: 224780] train loss: 0.003843, tar: 0.000025 
l0: 0.000015, l1: 0.000015, l2: 0.000045, l3: 0.000143, l4: 0.000393, l5: 0.000740, l6: 0.001344

[epoch: 855/1000, batch:   792/ 1052, ite: 224800] train loss: 0.003841, tar: 0.000025 
l0: 0.000008, l1: 0.000008, l2: 0.000076, l3: 0.000139, l4: 0.000512, l5: 0.001147, l6: 0.001995

[epoch: 855/1000, batch:   872/ 1052, ite: 224820] train loss: 0.003841, tar: 0.000025 
l0: 0.000011, l1: 0.000011, l2: 0.000026, l3: 0.000165, l4: 0.000708, l5: 0.001324, l6: 0.002852

[epoch: 855/1000, batch:   952/ 1052, ite: 224840] train loss: 0.003839, tar: 0.000025 
l0: 0.000008, l1: 0.000009, l2: 0.000072, l3: 0.000172, l4: 0.000538, l5: 0.001651, l6: 0.002065

[epoch: 855/1000, batch:  1032/ 1052, ite: 224860] train loss: 0.003840, tar: 0.000025 
[Epoch 855/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000016, l1: 0.000018, l2: 0.000054, l3: 0.000321, l4: 0.000532, l5: 0.001885, l6: 0.003832

[epoch: 856/1000, batch:    60/ 1052, ite: 224880] train loss: 0.003840, tar: 0.000025 
l0: 0.000024, l1: 0.000024, l2: 0.000051, l3: 0.000284, l4: 0.000464, l5: 0.001226, l6: 0.002323

[epoch: 856/1000, batch:   140/ 1052, ite: 224900] train loss: 0.003840, tar: 0.000025 
l0: 0.000048, l1: 0.000048, l2: 0.000142, l3: 0.000313, l4: 0.000690, l5: 0.001540, l6: 0.002398

[epoch: 856/1000, batch:   220/ 1052, ite: 224920] train loss: 0.003839, tar: 0.000025 
l0: 0.000013, l1: 0.000013, l2: 0.000031, l3: 0.000129, l4: 0.000405, l5: 0.001257, l6: 0.002338

[epoch: 856/1000, batch:   300/ 1052, ite: 224940] train loss: 0.003838, tar: 0.000025 
l0: 0.000036, l1: 0.000038, l2: 0.000077, l3: 0.000235, l4: 0.000534, l5: 0.000844, l6: 0.003161

[epoch: 856/1000, batch:   380/ 1052, ite: 224960] train loss: 0.003838, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000026, l3: 0.000163, l4: 0.000324, l5: 0.000806, l6: 0.001291

[epoch: 856/1000, batch:   460/ 1052, ite: 224980] train loss: 0.003841, tar: 0.000025 
l0: 0.000034, l1: 0.000035, l2: 0.000100, l3: 0.000277, l4: 0.000574, l5: 0.001111, l6: 0.001736

[epoch: 856/1000, batch:   540/ 1052, ite: 225000] train loss: 0.003841, tar: 0.000025 
l0: 0.000016, l1: 0.000018, l2: 0.000034, l3: 0.000089, l4: 0.000194, l5: 0.000862, l6: 0.001418

[epoch: 856/1000, batch:   620/ 1052, ite: 225020] train loss: 0.003842, tar: 0.000025 
l0: 0.000012, l1: 0.000014, l2: 0.000033, l3: 0.000126, l4: 0.000211, l5: 0.001017, l6: 0.002083

[epoch: 856/1000, batch:   700/ 1052, ite: 225040] train loss: 0.003843, tar: 0.000025 
l0: 0.000008, l1: 0.000008, l2: 0.000028, l3: 0.000121, l4: 0.000567, l5: 0.001310, l6: 0.001979

[epoch: 856/1000, batch:   780/ 1052, ite: 225060] train loss: 0.003840, tar: 0.000025 
l0: 0.000003, l1: 0.000004, l2: 0.000005, l3: 0.000038, l4: 0.000183, l5: 0.000501, l6: 0.000945

[epoch: 856/1000, batch:   860/ 1052, ite: 225080] train loss: 0.003841, tar: 0.000025 
l0: 0.000011, l1: 0.000012, l2: 0.000096, l3: 0.000416, l4: 0.000890, l5: 0.001214, l6: 0.001995

[epoch: 856/1000, batch:   940/ 1052, ite: 225100] train loss: 0.003842, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000114, l3: 0.000184, l4: 0.000354, l5: 0.000949, l6: 0.001348

[epoch: 856/1000, batch:  1020/ 1052, ite: 225120] train loss: 0.003841, tar: 0.000025 
[Epoch 856/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000017, l1: 0.000016, l2: 0.000026, l3: 0.000132, l4: 0.000731, l5: 0.001299, l6: 0.002273

[epoch: 857/1000, batch:    48/ 1052, ite: 225140] train loss: 0.003845, tar: 0.000025 
l0: 0.000037, l1: 0.000035, l2: 0.000072, l3: 0.000308, l4: 0.000680, l5: 0.001257, l6: 0.002032

[epoch: 857/1000, batch:   128/ 1052, ite: 225160] train loss: 0.003846, tar: 0.000025 
l0: 0.000016, l1: 0.000016, l2: 0.000047, l3: 0.000288, l4: 0.001060, l5: 0.001818, l6: 0.003365

[epoch: 857/1000, batch:   208/ 1052, ite: 225180] train loss: 0.003846, tar: 0.000025 
l0: 0.000032, l1: 0.000034, l2: 0.000080, l3: 0.000214, l4: 0.000462, l5: 0.001343, l6: 0.002052

[epoch: 857/1000, batch:   288/ 1052, ite: 225200] train loss: 0.003847, tar: 0.000025 
l0: 0.000041, l1: 0.000040, l2: 0.000081, l3: 0.000222, l4: 0.000326, l5: 0.000790, l6: 0.001942

[epoch: 857/1000, batch:   368/ 1052, ite: 225220] train loss: 0.003847, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000047, l3: 0.000140, l4: 0.000358, l5: 0.001222, l6: 0.002015

[epoch: 857/1000, batch:   448/ 1052, ite: 225240] train loss: 0.003846, tar: 0.000025 
l0: 0.000009, l1: 0.000010, l2: 0.000055, l3: 0.000310, l4: 0.001001, l5: 0.001332, l6: 0.002179

[epoch: 857/1000, batch:   528/ 1052, ite: 225260] train loss: 0.003845, tar: 0.000025 
l0: 0.000008, l1: 0.000008, l2: 0.000036, l3: 0.000121, l4: 0.000272, l5: 0.001307, l6: 0.002673

[epoch: 857/1000, batch:   608/ 1052, ite: 225280] train loss: 0.003843, tar: 0.000025 
l0: 0.000032, l1: 0.000031, l2: 0.000050, l3: 0.000161, l4: 0.000474, l5: 0.000756, l6: 0.001869

[epoch: 857/1000, batch:   688/ 1052, ite: 225300] train loss: 0.003842, tar: 0.000025 
l0: 0.000003, l1: 0.000002, l2: 0.000028, l3: 0.000116, l4: 0.000299, l5: 0.000637, l6: 0.001167

[epoch: 857/1000, batch:   768/ 1052, ite: 225320] train loss: 0.003843, tar: 0.000025 
l0: 0.000090, l1: 0.000084, l2: 0.000086, l3: 0.000221, l4: 0.000421, l5: 0.000662, l6: 0.001303

[epoch: 857/1000, batch:   848/ 1052, ite: 225340] train loss: 0.003844, tar: 0.000025 
l0: 0.000085, l1: 0.000099, l2: 0.000159, l3: 0.000385, l4: 0.000994, l5: 0.001976, l6: 0.003124

[epoch: 857/1000, batch:   928/ 1052, ite: 225360] train loss: 0.003844, tar: 0.000025 
l0: 0.000010, l1: 0.000010, l2: 0.000039, l3: 0.000168, l4: 0.000482, l5: 0.000642, l6: 0.001129

[epoch: 857/1000, batch:  1008/ 1052, ite: 225380] train loss: 0.003843, tar: 0.000025 
[Epoch 857/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000103, l1: 0.000102, l2: 0.000170, l3: 0.000253, l4: 0.000379, l5: 0.000970, l6: 0.002645

[epoch: 858/1000, batch:    36/ 1052, ite: 225400] train loss: 0.003842, tar: 0.000025 
l0: 0.000024, l1: 0.000023, l2: 0.000104, l3: 0.000389, l4: 0.000876, l5: 0.002696, l6: 0.003735

[epoch: 858/1000, batch:   116/ 1052, ite: 225420] train loss: 0.003841, tar: 0.000025 
l0: 0.000044, l1: 0.000043, l2: 0.000093, l3: 0.000247, l4: 0.000653, l5: 0.001701, l6: 0.001950

[epoch: 858/1000, batch:   196/ 1052, ite: 225440] train loss: 0.003841, tar: 0.000025 
l0: 0.000082, l1: 0.000082, l2: 0.000139, l3: 0.000211, l4: 0.000506, l5: 0.000959, l6: 0.002021

[epoch: 858/1000, batch:   276/ 1052, ite: 225460] train loss: 0.003842, tar: 0.000025 
l0: 0.000004, l1: 0.000004, l2: 0.000042, l3: 0.000134, l4: 0.000473, l5: 0.000673, l6: 0.001165

[epoch: 858/1000, batch:   356/ 1052, ite: 225480] train loss: 0.003841, tar: 0.000025 
l0: 0.000050, l1: 0.000052, l2: 0.000072, l3: 0.000262, l4: 0.000422, l5: 0.001345, l6: 0.003647

[epoch: 858/1000, batch:   436/ 1052, ite: 225500] train loss: 0.003840, tar: 0.000025 
l0: 0.000041, l1: 0.000040, l2: 0.000121, l3: 0.000497, l4: 0.001172, l5: 0.002050, l6: 0.003786

[epoch: 858/1000, batch:   516/ 1052, ite: 225520] train loss: 0.003842, tar: 0.000025 
l0: 0.000016, l1: 0.000019, l2: 0.000038, l3: 0.000133, l4: 0.000366, l5: 0.000899, l6: 0.001338

[epoch: 858/1000, batch:   596/ 1052, ite: 225540] train loss: 0.003843, tar: 0.000025 
l0: 0.000006, l1: 0.000007, l2: 0.000046, l3: 0.000124, l4: 0.000459, l5: 0.000987, l6: 0.002064

[epoch: 858/1000, batch:   676/ 1052, ite: 225560] train loss: 0.003843, tar: 0.000025 
l0: 0.000016, l1: 0.000017, l2: 0.000077, l3: 0.000292, l4: 0.000767, l5: 0.001283, l6: 0.002189

[epoch: 858/1000, batch:   756/ 1052, ite: 225580] train loss: 0.003842, tar: 0.000025 
l0: 0.000004, l1: 0.000003, l2: 0.000038, l3: 0.000154, l4: 0.000570, l5: 0.000764, l6: 0.002241

[epoch: 858/1000, batch:   836/ 1052, ite: 225600] train loss: 0.003841, tar: 0.000025 
l0: 0.000059, l1: 0.000059, l2: 0.000099, l3: 0.000192, l4: 0.000523, l5: 0.000964, l6: 0.002963

[epoch: 858/1000, batch:   916/ 1052, ite: 225620] train loss: 0.003838, tar: 0.000025 
l0: 0.000029, l1: 0.000029, l2: 0.000061, l3: 0.000170, l4: 0.000429, l5: 0.001151, l6: 0.001635

[epoch: 858/1000, batch:   996/ 1052, ite: 225640] train loss: 0.003839, tar: 0.000025 
[Epoch 858/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000028, l1: 0.000027, l2: 0.000045, l3: 0.000142, l4: 0.000279, l5: 0.000941, l6: 0.001977

[epoch: 859/1000, batch:    24/ 1052, ite: 225660] train loss: 0.003839, tar: 0.000025 
l0: 0.000035, l1: 0.000034, l2: 0.000111, l3: 0.000308, l4: 0.000508, l5: 0.000971, l6: 0.002462

[epoch: 859/1000, batch:   104/ 1052, ite: 225680] train loss: 0.003840, tar: 0.000025 
l0: 0.000010, l1: 0.000009, l2: 0.000029, l3: 0.000227, l4: 0.000370, l5: 0.000735, l6: 0.001284

[epoch: 859/1000, batch:   184/ 1052, ite: 225700] train loss: 0.003842, tar: 0.000025 
l0: 0.000031, l1: 0.000033, l2: 0.000051, l3: 0.000094, l4: 0.000350, l5: 0.000963, l6: 0.001389

[epoch: 859/1000, batch:   264/ 1052, ite: 225720] train loss: 0.003842, tar: 0.000025 
l0: 0.000022, l1: 0.000024, l2: 0.000038, l3: 0.000116, l4: 0.000369, l5: 0.001002, l6: 0.001903

[epoch: 859/1000, batch:   344/ 1052, ite: 225740] train loss: 0.003840, tar: 0.000025 
l0: 0.000027, l1: 0.000027, l2: 0.000059, l3: 0.000170, l4: 0.000700, l5: 0.001609, l6: 0.002444

[epoch: 859/1000, batch:   424/ 1052, ite: 225760] train loss: 0.003842, tar: 0.000025 
l0: 0.000019, l1: 0.000022, l2: 0.000039, l3: 0.000139, l4: 0.000541, l5: 0.000921, l6: 0.001997

[epoch: 859/1000, batch:   504/ 1052, ite: 225780] train loss: 0.003843, tar: 0.000025 
l0: 0.000056, l1: 0.000056, l2: 0.000131, l3: 0.000341, l4: 0.000903, l5: 0.001525, l6: 0.002922

[epoch: 859/1000, batch:   584/ 1052, ite: 225800] train loss: 0.003842, tar: 0.000025 
l0: 0.000019, l1: 0.000020, l2: 0.000036, l3: 0.000085, l4: 0.000347, l5: 0.000681, l6: 0.001965

[epoch: 859/1000, batch:   664/ 1052, ite: 225820] train loss: 0.003841, tar: 0.000025 
l0: 0.000003, l1: 0.000003, l2: 0.000016, l3: 0.000065, l4: 0.000423, l5: 0.000760, l6: 0.001651

[epoch: 859/1000, batch:   744/ 1052, ite: 225840] train loss: 0.003842, tar: 0.000025 
l0: 0.000023, l1: 0.000022, l2: 0.000033, l3: 0.000136, l4: 0.000439, l5: 0.000873, l6: 0.001173

[epoch: 859/1000, batch:   824/ 1052, ite: 225860] train loss: 0.003841, tar: 0.000025 
l0: 0.000010, l1: 0.000010, l2: 0.000025, l3: 0.000067, l4: 0.000403, l5: 0.001145, l6: 0.001832

[epoch: 859/1000, batch:   904/ 1052, ite: 225880] train loss: 0.003842, tar: 0.000025 
l0: 0.000068, l1: 0.000066, l2: 0.000196, l3: 0.000265, l4: 0.000356, l5: 0.000919, l6: 0.002250

[epoch: 859/1000, batch:   984/ 1052, ite: 225900] train loss: 0.003843, tar: 0.000025 
[Epoch 859/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000038, l1: 0.000039, l2: 0.000076, l3: 0.000274, l4: 0.000583, l5: 0.001557, l6: 0.002697

[epoch: 860/1000, batch:    12/ 1052, ite: 225920] train loss: 0.003841, tar: 0.000025 
l0: 0.000012, l1: 0.000012, l2: 0.000039, l3: 0.000134, l4: 0.000685, l5: 0.001007, l6: 0.001828

[epoch: 860/1000, batch:    92/ 1052, ite: 225940] train loss: 0.003840, tar: 0.000025 
l0: 0.000002, l1: 0.000003, l2: 0.000015, l3: 0.000082, l4: 0.000319, l5: 0.000862, l6: 0.001601

[epoch: 860/1000, batch:   172/ 1052, ite: 225960] train loss: 0.003840, tar: 0.000025 
l0: 0.000019, l1: 0.000018, l2: 0.000067, l3: 0.000220, l4: 0.000579, l5: 0.001645, l6: 0.002662

[epoch: 860/1000, batch:   252/ 1052, ite: 225980] train loss: 0.003839, tar: 0.000025 
l0: 0.000019, l1: 0.000022, l2: 0.000042, l3: 0.000234, l4: 0.000671, l5: 0.001125, l6: 0.002115

[epoch: 860/1000, batch:   332/ 1052, ite: 226000] train loss: 0.003840, tar: 0.000025 
l0: 0.000002, l1: 0.000003, l2: 0.000005, l3: 0.000065, l4: 0.000294, l5: 0.000362, l6: 0.000951

[epoch: 860/1000, batch:   412/ 1052, ite: 226020] train loss: 0.003838, tar: 0.000025 
l0: 0.000043, l1: 0.000040, l2: 0.000082, l3: 0.000245, l4: 0.000349, l5: 0.001160, l6: 0.001612

[epoch: 860/1000, batch:   492/ 1052, ite: 226040] train loss: 0.003838, tar: 0.000025 
l0: 0.000011, l1: 0.000011, l2: 0.000026, l3: 0.000202, l4: 0.000364, l5: 0.000886, l6: 0.002055

[epoch: 860/1000, batch:   572/ 1052, ite: 226060] train loss: 0.003837, tar: 0.000025 
l0: 0.000036, l1: 0.000036, l2: 0.000091, l3: 0.000265, l4: 0.000442, l5: 0.001095, l6: 0.002896

[epoch: 860/1000, batch:   652/ 1052, ite: 226080] train loss: 0.003837, tar: 0.000025 
l0: 0.000001, l1: 0.000002, l2: 0.000010, l3: 0.000084, l4: 0.000300, l5: 0.000672, l6: 0.000913

[epoch: 860/1000, batch:   732/ 1052, ite: 226100] train loss: 0.003838, tar: 0.000025 
l0: 0.000027, l1: 0.000027, l2: 0.000069, l3: 0.000289, l4: 0.000576, l5: 0.001614, l6: 0.002158

[epoch: 860/1000, batch:   812/ 1052, ite: 226120] train loss: 0.003839, tar: 0.000025 
l0: 0.000251, l1: 0.000238, l2: 0.000313, l3: 0.000482, l4: 0.000819, l5: 0.001703, l6: 0.002729

[epoch: 860/1000, batch:   892/ 1052, ite: 226140] train loss: 0.003840, tar: 0.000025 
l0: 0.000031, l1: 0.000033, l2: 0.000046, l3: 0.000193, l4: 0.000492, l5: 0.000989, l6: 0.001724

[epoch: 860/1000, batch:   972/ 1052, ite: 226160] train loss: 0.003841, tar: 0.000025 
l0: 0.000016, l1: 0.000018, l2: 0.000063, l3: 0.000176, l4: 0.000672, l5: 0.001620, l6: 0.001511

[epoch: 860/1000, batch:  1052/ 1052, ite: 226180] train loss: 0.003841, tar: 0.000025 
[Epoch 860/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000016, l1: 0.000017, l2: 0.000039, l3: 0.000174, l4: 0.000746, l5: 0.001806, l6: 0.003164

[epoch: 861/1000, batch:    80/ 1052, ite: 226200] train loss: 0.003842, tar: 0.000025 
l0: 0.000025, l1: 0.000026, l2: 0.000032, l3: 0.000068, l4: 0.000274, l5: 0.000697, l6: 0.001193

[epoch: 861/1000, batch:   160/ 1052, ite: 226220] train loss: 0.003840, tar: 0.000025 
l0: 0.000019, l1: 0.000018, l2: 0.000041, l3: 0.000171, l4: 0.000557, l5: 0.000996, l6: 0.001991

[epoch: 861/1000, batch:   240/ 1052, ite: 226240] train loss: 0.003840, tar: 0.000025 
l0: 0.000041, l1: 0.000040, l2: 0.000082, l3: 0.000222, l4: 0.000519, l5: 0.001166, l6: 0.001976

[epoch: 861/1000, batch:   320/ 1052, ite: 226260] train loss: 0.003838, tar: 0.000025 
l0: 0.000054, l1: 0.000051, l2: 0.000133, l3: 0.000414, l4: 0.000728, l5: 0.001153, l6: 0.001981

[epoch: 861/1000, batch:   400/ 1052, ite: 226280] train loss: 0.003841, tar: 0.000025 
l0: 0.000188, l1: 0.000181, l2: 0.000180, l3: 0.000272, l4: 0.000861, l5: 0.001182, l6: 0.002054

[epoch: 861/1000, batch:   480/ 1052, ite: 226300] train loss: 0.003841, tar: 0.000025 
l0: 0.000002, l1: 0.000002, l2: 0.000022, l3: 0.000092, l4: 0.000246, l5: 0.000836, l6: 0.001052

[epoch: 861/1000, batch:   560/ 1052, ite: 226320] train loss: 0.003842, tar: 0.000025 
l0: 0.000017, l1: 0.000018, l2: 0.000035, l3: 0.000193, l4: 0.000344, l5: 0.001184, l6: 0.001866

[epoch: 861/1000, batch:   640/ 1052, ite: 226340] train loss: 0.003841, tar: 0.000025 
l0: 0.000024, l1: 0.000023, l2: 0.000054, l3: 0.000167, l4: 0.000531, l5: 0.001198, l6: 0.003229

[epoch: 861/1000, batch:   720/ 1052, ite: 226360] train loss: 0.003842, tar: 0.000025 
l0: 0.000004, l1: 0.000003, l2: 0.000018, l3: 0.000114, l4: 0.000414, l5: 0.000695, l6: 0.001367

[epoch: 861/1000, batch:   800/ 1052, ite: 226380] train loss: 0.003841, tar: 0.000025 
l0: 0.000003, l1: 0.000003, l2: 0.000017, l3: 0.000135, l4: 0.000464, l5: 0.001032, l6: 0.001273

[epoch: 861/1000, batch:   880/ 1052, ite: 226400] train loss: 0.003841, tar: 0.000025 
l0: 0.000023, l1: 0.000022, l2: 0.000065, l3: 0.000196, l4: 0.000553, l5: 0.001137, l6: 0.002018

[epoch: 861/1000, batch:   960/ 1052, ite: 226420] train loss: 0.003843, tar: 0.000025 
l0: 0.000007, l1: 0.000006, l2: 0.000022, l3: 0.000098, l4: 0.000267, l5: 0.001430, l6: 0.002540

[epoch: 861/1000, batch:  1040/ 1052, ite: 226440] train loss: 0.003842, tar: 0.000025 
[Epoch 861/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000005, l1: 0.000005, l2: 0.000021, l3: 0.000130, l4: 0.000385, l5: 0.000985, l6: 0.001826

[epoch: 862/1000, batch:    68/ 1052, ite: 226460] train loss: 0.003841, tar: 0.000025 
l0: 0.000022, l1: 0.000019, l2: 0.000134, l3: 0.000362, l4: 0.000849, l5: 0.001659, l6: 0.001925

[epoch: 862/1000, batch:   148/ 1052, ite: 226480] train loss: 0.003839, tar: 0.000025 
l0: 0.000002, l1: 0.000002, l2: 0.000023, l3: 0.000116, l4: 0.000484, l5: 0.000559, l6: 0.001327

[epoch: 862/1000, batch:   228/ 1052, ite: 226500] train loss: 0.003840, tar: 0.000025 
l0: 0.000086, l1: 0.000084, l2: 0.000100, l3: 0.000225, l4: 0.000420, l5: 0.001176, l6: 0.001825

[epoch: 862/1000, batch:   308/ 1052, ite: 226520] train loss: 0.003840, tar: 0.000025 
l0: 0.000011, l1: 0.000012, l2: 0.000036, l3: 0.000110, l4: 0.000304, l5: 0.000801, l6: 0.001993

[epoch: 862/1000, batch:   388/ 1052, ite: 226540] train loss: 0.003839, tar: 0.000025 
l0: 0.000038, l1: 0.000039, l2: 0.000149, l3: 0.000358, l4: 0.000791, l5: 0.001458, l6: 0.003276

[epoch: 862/1000, batch:   468/ 1052, ite: 226560] train loss: 0.003841, tar: 0.000025 
l0: 0.000026, l1: 0.000027, l2: 0.000051, l3: 0.000189, l4: 0.000485, l5: 0.001232, l6: 0.001419

[epoch: 862/1000, batch:   548/ 1052, ite: 226580] train loss: 0.003841, tar: 0.000025 
l0: 0.000021, l1: 0.000024, l2: 0.000054, l3: 0.000140, l4: 0.000559, l5: 0.000663, l6: 0.001227

[epoch: 862/1000, batch:   628/ 1052, ite: 226600] train loss: 0.003840, tar: 0.000025 
l0: 0.000058, l1: 0.000057, l2: 0.000159, l3: 0.000443, l4: 0.001068, l5: 0.001638, l6: 0.002632

[epoch: 862/1000, batch:   708/ 1052, ite: 226620] train loss: 0.003838, tar: 0.000025 
l0: 0.000029, l1: 0.000026, l2: 0.000083, l3: 0.000194, l4: 0.000415, l5: 0.001010, l6: 0.001327

[epoch: 862/1000, batch:   788/ 1052, ite: 226640] train loss: 0.003840, tar: 0.000025 
l0: 0.000108, l1: 0.000112, l2: 0.000084, l3: 0.000146, l4: 0.000254, l5: 0.000931, l6: 0.000947

[epoch: 862/1000, batch:   868/ 1052, ite: 226660] train loss: 0.003840, tar: 0.000025 
l0: 0.000022, l1: 0.000023, l2: 0.000053, l3: 0.000117, l4: 0.000308, l5: 0.000902, l6: 0.002315

[epoch: 862/1000, batch:   948/ 1052, ite: 226680] train loss: 0.003839, tar: 0.000025 
l0: 0.000020, l1: 0.000020, l2: 0.000070, l3: 0.000194, l4: 0.000468, l5: 0.000859, l6: 0.002575

[epoch: 862/1000, batch:  1028/ 1052, ite: 226700] train loss: 0.003839, tar: 0.000025 
[Epoch 862/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000021, l1: 0.000023, l2: 0.000031, l3: 0.000137, l4: 0.000336, l5: 0.001008, l6: 0.001476

[epoch: 863/1000, batch:    56/ 1052, ite: 226720] train loss: 0.003839, tar: 0.000025 
l0: 0.000015, l1: 0.000016, l2: 0.000052, l3: 0.000102, l4: 0.000199, l5: 0.000990, l6: 0.000642

[epoch: 863/1000, batch:   136/ 1052, ite: 226740] train loss: 0.003838, tar: 0.000025 
l0: 0.000034, l1: 0.000035, l2: 0.000082, l3: 0.000262, l4: 0.000550, l5: 0.001164, l6: 0.001939

[epoch: 863/1000, batch:   216/ 1052, ite: 226760] train loss: 0.003839, tar: 0.000025 
l0: 0.000011, l1: 0.000011, l2: 0.000074, l3: 0.000502, l4: 0.001329, l5: 0.002371, l6: 0.003405

[epoch: 863/1000, batch:   296/ 1052, ite: 226780] train loss: 0.003840, tar: 0.000025 
l0: 0.000017, l1: 0.000017, l2: 0.000115, l3: 0.000360, l4: 0.000809, l5: 0.001619, l6: 0.002536

[epoch: 863/1000, batch:   376/ 1052, ite: 226800] train loss: 0.003842, tar: 0.000025 
l0: 0.000007, l1: 0.000006, l2: 0.000033, l3: 0.000126, l4: 0.000321, l5: 0.000694, l6: 0.001327

[epoch: 863/1000, batch:   456/ 1052, ite: 226820] train loss: 0.003841, tar: 0.000025 
l0: 0.000036, l1: 0.000038, l2: 0.000054, l3: 0.000153, l4: 0.001045, l5: 0.001349, l6: 0.002762

[epoch: 863/1000, batch:   536/ 1052, ite: 226840] train loss: 0.003840, tar: 0.000025 
l0: 0.000039, l1: 0.000041, l2: 0.000086, l3: 0.000309, l4: 0.000569, l5: 0.001561, l6: 0.002710

[epoch: 863/1000, batch:   616/ 1052, ite: 226860] train loss: 0.003840, tar: 0.000025 
l0: 0.000033, l1: 0.000035, l2: 0.000042, l3: 0.000118, l4: 0.000291, l5: 0.000658, l6: 0.001441

[epoch: 863/1000, batch:   696/ 1052, ite: 226880] train loss: 0.003840, tar: 0.000025 
l0: 0.000018, l1: 0.000019, l2: 0.000105, l3: 0.000231, l4: 0.000543, l5: 0.001155, l6: 0.002718

[epoch: 863/1000, batch:   776/ 1052, ite: 226900] train loss: 0.003840, tar: 0.000025 
l0: 0.000009, l1: 0.000009, l2: 0.000035, l3: 0.000087, l4: 0.000361, l5: 0.000866, l6: 0.002579

[epoch: 863/1000, batch:   856/ 1052, ite: 226920] train loss: 0.003840, tar: 0.000025 
l0: 0.000024, l1: 0.000022, l2: 0.000092, l3: 0.000256, l4: 0.000672, l5: 0.001841, l6: 0.003020

[epoch: 863/1000, batch:   936/ 1052, ite: 226940] train loss: 0.003840, tar: 0.000025 
l0: 0.000006, l1: 0.000006, l2: 0.000049, l3: 0.000247, l4: 0.000604, l5: 0.001172, l6: 0.002158

[epoch: 863/1000, batch:  1016/ 1052, ite: 226960] train loss: 0.003840, tar: 0.000025 
[Epoch 863/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000015, l1: 0.000015, l2: 0.000075, l3: 0.000300, l4: 0.000576, l5: 0.001240, l6: 0.002646

[epoch: 864/1000, batch:    44/ 1052, ite: 226980] train loss: 0.003838, tar: 0.000025 
l0: 0.000006, l1: 0.000006, l2: 0.000048, l3: 0.000061, l4: 0.000253, l5: 0.000814, l6: 0.001889

[epoch: 864/1000, batch:   124/ 1052, ite: 227000] train loss: 0.003838, tar: 0.000025 
l0: 0.000004, l1: 0.000004, l2: 0.000026, l3: 0.000128, l4: 0.000329, l5: 0.001116, l6: 0.001603

[epoch: 864/1000, batch:   204/ 1052, ite: 227020] train loss: 0.003838, tar: 0.000025 
l0: 0.000013, l1: 0.000013, l2: 0.000054, l3: 0.000193, l4: 0.000460, l5: 0.001094, l6: 0.001695

[epoch: 864/1000, batch:   284/ 1052, ite: 227040] train loss: 0.003836, tar: 0.000025 
l0: 0.000003, l1: 0.000002, l2: 0.000027, l3: 0.000094, l4: 0.000221, l5: 0.000677, l6: 0.000974

[epoch: 864/1000, batch:   364/ 1052, ite: 227060] train loss: 0.003835, tar: 0.000025 
l0: 0.000026, l1: 0.000027, l2: 0.000093, l3: 0.000237, l4: 0.000461, l5: 0.001160, l6: 0.003037

[epoch: 864/1000, batch:   444/ 1052, ite: 227080] train loss: 0.003838, tar: 0.000025 
l0: 0.000006, l1: 0.000005, l2: 0.000056, l3: 0.000279, l4: 0.000549, l5: 0.000990, l6: 0.003031

[epoch: 864/1000, batch:   524/ 1052, ite: 227100] train loss: 0.003839, tar: 0.000025 
l0: 0.000025, l1: 0.000025, l2: 0.000023, l3: 0.000099, l4: 0.000328, l5: 0.001013, l6: 0.001907

[epoch: 864/1000, batch:   604/ 1052, ite: 227120] train loss: 0.003840, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000049, l3: 0.000203, l4: 0.000568, l5: 0.001489, l6: 0.002872

[epoch: 864/1000, batch:   684/ 1052, ite: 227140] train loss: 0.003840, tar: 0.000025 
l0: 0.000003, l1: 0.000003, l2: 0.000042, l3: 0.000112, l4: 0.000325, l5: 0.000755, l6: 0.000892

[epoch: 864/1000, batch:   764/ 1052, ite: 227160] train loss: 0.003841, tar: 0.000025 
l0: 0.000017, l1: 0.000016, l2: 0.000035, l3: 0.000120, l4: 0.000367, l5: 0.001032, l6: 0.001535

[epoch: 864/1000, batch:   844/ 1052, ite: 227180] train loss: 0.003840, tar: 0.000025 
l0: 0.000008, l1: 0.000007, l2: 0.000045, l3: 0.000130, l4: 0.000199, l5: 0.000901, l6: 0.001460

[epoch: 864/1000, batch:   924/ 1052, ite: 227200] train loss: 0.003839, tar: 0.000025 
l0: 0.000045, l1: 0.000048, l2: 0.000150, l3: 0.000458, l4: 0.001105, l5: 0.002479, l6: 0.005022

[epoch: 864/1000, batch:  1004/ 1052, ite: 227220] train loss: 0.003839, tar: 0.000025 
[Epoch 864/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000010, l1: 0.000011, l2: 0.000047, l3: 0.000178, l4: 0.000658, l5: 0.001555, l6: 0.002973

[epoch: 865/1000, batch:    32/ 1052, ite: 227240] train loss: 0.003839, tar: 0.000025 
l0: 0.000006, l1: 0.000005, l2: 0.000045, l3: 0.000121, l4: 0.000210, l5: 0.000523, l6: 0.000990

[epoch: 865/1000, batch:   112/ 1052, ite: 227260] train loss: 0.003838, tar: 0.000025 
l0: 0.000020, l1: 0.000018, l2: 0.000072, l3: 0.000174, l4: 0.000766, l5: 0.001293, l6: 0.002122

[epoch: 865/1000, batch:   192/ 1052, ite: 227280] train loss: 0.003838, tar: 0.000025 
l0: 0.000022, l1: 0.000022, l2: 0.000055, l3: 0.000138, l4: 0.000561, l5: 0.001250, l6: 0.001913

[epoch: 865/1000, batch:   272/ 1052, ite: 227300] train loss: 0.003838, tar: 0.000025 
l0: 0.000039, l1: 0.000038, l2: 0.000049, l3: 0.000091, l4: 0.000380, l5: 0.000985, l6: 0.001731

[epoch: 865/1000, batch:   352/ 1052, ite: 227320] train loss: 0.003837, tar: 0.000025 
l0: 0.000036, l1: 0.000040, l2: 0.000049, l3: 0.000167, l4: 0.000354, l5: 0.001136, l6: 0.001793

[epoch: 865/1000, batch:   432/ 1052, ite: 227340] train loss: 0.003836, tar: 0.000025 
l0: 0.000008, l1: 0.000007, l2: 0.000023, l3: 0.000075, l4: 0.000272, l5: 0.000645, l6: 0.001145

[epoch: 865/1000, batch:   512/ 1052, ite: 227360] train loss: 0.003835, tar: 0.000025 
l0: 0.000010, l1: 0.000010, l2: 0.000088, l3: 0.000203, l4: 0.000460, l5: 0.001101, l6: 0.001566

[epoch: 865/1000, batch:   592/ 1052, ite: 227380] train loss: 0.003835, tar: 0.000025 
l0: 0.000006, l1: 0.000006, l2: 0.000016, l3: 0.000053, l4: 0.000218, l5: 0.000308, l6: 0.000854

[epoch: 865/1000, batch:   672/ 1052, ite: 227400] train loss: 0.003835, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000018, l3: 0.000053, l4: 0.000165, l5: 0.001040, l6: 0.002028

[epoch: 865/1000, batch:   752/ 1052, ite: 227420] train loss: 0.003835, tar: 0.000025 
l0: 0.000030, l1: 0.000029, l2: 0.000064, l3: 0.000198, l4: 0.000666, l5: 0.001164, l6: 0.002508

[epoch: 865/1000, batch:   832/ 1052, ite: 227440] train loss: 0.003834, tar: 0.000025 
l0: 0.000009, l1: 0.000009, l2: 0.000036, l3: 0.000122, l4: 0.000182, l5: 0.000826, l6: 0.001967

[epoch: 865/1000, batch:   912/ 1052, ite: 227460] train loss: 0.003836, tar: 0.000025 
l0: 0.000002, l1: 0.000002, l2: 0.000023, l3: 0.000111, l4: 0.000333, l5: 0.000985, l6: 0.003116

[epoch: 865/1000, batch:   992/ 1052, ite: 227480] train loss: 0.003836, tar: 0.000025 
[Epoch 865/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000009, l1: 0.000009, l2: 0.000037, l3: 0.000117, l4: 0.000494, l5: 0.000705, l6: 0.001071

[epoch: 866/1000, batch:    20/ 1052, ite: 227500] train loss: 0.003836, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000025, l3: 0.000100, l4: 0.000237, l5: 0.000441, l6: 0.001372

[epoch: 866/1000, batch:   100/ 1052, ite: 227520] train loss: 0.003836, tar: 0.000025 
l0: 0.000007, l1: 0.000008, l2: 0.000026, l3: 0.000228, l4: 0.000462, l5: 0.001262, l6: 0.002102

[epoch: 866/1000, batch:   180/ 1052, ite: 227540] train loss: 0.003837, tar: 0.000025 
l0: 0.000031, l1: 0.000033, l2: 0.000033, l3: 0.000096, l4: 0.000369, l5: 0.000977, l6: 0.001706

[epoch: 866/1000, batch:   260/ 1052, ite: 227560] train loss: 0.003837, tar: 0.000025 
l0: 0.000015, l1: 0.000016, l2: 0.000015, l3: 0.000078, l4: 0.000137, l5: 0.000581, l6: 0.001004

[epoch: 866/1000, batch:   340/ 1052, ite: 227580] train loss: 0.003836, tar: 0.000025 
l0: 0.000024, l1: 0.000025, l2: 0.000043, l3: 0.000156, l4: 0.000371, l5: 0.001088, l6: 0.002614

[epoch: 866/1000, batch:   420/ 1052, ite: 227600] train loss: 0.003838, tar: 0.000025 
l0: 0.000042, l1: 0.000046, l2: 0.000160, l3: 0.000345, l4: 0.000922, l5: 0.002228, l6: 0.003856

[epoch: 866/1000, batch:   500/ 1052, ite: 227620] train loss: 0.003838, tar: 0.000025 
l0: 0.000012, l1: 0.000011, l2: 0.000055, l3: 0.000217, l4: 0.000582, l5: 0.001257, l6: 0.002509

[epoch: 866/1000, batch:   580/ 1052, ite: 227640] train loss: 0.003839, tar: 0.000025 
l0: 0.000009, l1: 0.000009, l2: 0.000026, l3: 0.000073, l4: 0.000311, l5: 0.000705, l6: 0.001494

[epoch: 866/1000, batch:   660/ 1052, ite: 227660] train loss: 0.003838, tar: 0.000025 
l0: 0.000028, l1: 0.000029, l2: 0.000052, l3: 0.000140, l4: 0.000419, l5: 0.000871, l6: 0.002094

[epoch: 866/1000, batch:   740/ 1052, ite: 227680] train loss: 0.003839, tar: 0.000025 
l0: 0.000002, l1: 0.000003, l2: 0.000009, l3: 0.000035, l4: 0.000142, l5: 0.000508, l6: 0.000584

[epoch: 866/1000, batch:   820/ 1052, ite: 227700] train loss: 0.003837, tar: 0.000025 
l0: 0.000012, l1: 0.000011, l2: 0.000104, l3: 0.000231, l4: 0.001046, l5: 0.001368, l6: 0.002433

[epoch: 866/1000, batch:   900/ 1052, ite: 227720] train loss: 0.003836, tar: 0.000025 
l0: 0.000031, l1: 0.000031, l2: 0.000069, l3: 0.000308, l4: 0.000508, l5: 0.000880, l6: 0.001942

[epoch: 866/1000, batch:   980/ 1052, ite: 227740] train loss: 0.003836, tar: 0.000025 
[Epoch 866/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000120, l1: 0.000131, l2: 0.000134, l3: 0.000311, l4: 0.000576, l5: 0.001227, l6: 0.001710

[epoch: 867/1000, batch:     8/ 1052, ite: 227760] train loss: 0.003836, tar: 0.000025 
l0: 0.000014, l1: 0.000016, l2: 0.000024, l3: 0.000126, l4: 0.000437, l5: 0.001158, l6: 0.002139

[epoch: 867/1000, batch:    88/ 1052, ite: 227780] train loss: 0.003837, tar: 0.000025 
l0: 0.000025, l1: 0.000027, l2: 0.000060, l3: 0.000091, l4: 0.000266, l5: 0.000677, l6: 0.001200

[epoch: 867/1000, batch:   168/ 1052, ite: 227800] train loss: 0.003835, tar: 0.000025 
l0: 0.000033, l1: 0.000032, l2: 0.000129, l3: 0.000269, l4: 0.000652, l5: 0.001225, l6: 0.001844

[epoch: 867/1000, batch:   248/ 1052, ite: 227820] train loss: 0.003838, tar: 0.000025 
l0: 0.000019, l1: 0.000021, l2: 0.000062, l3: 0.000192, l4: 0.000396, l5: 0.001497, l6: 0.002304

[epoch: 867/1000, batch:   328/ 1052, ite: 227840] train loss: 0.003837, tar: 0.000025 
l0: 0.000017, l1: 0.000017, l2: 0.000048, l3: 0.000195, l4: 0.000453, l5: 0.001129, l6: 0.002755

[epoch: 867/1000, batch:   408/ 1052, ite: 227860] train loss: 0.003837, tar: 0.000025 
l0: 0.000062, l1: 0.000066, l2: 0.000075, l3: 0.000201, l4: 0.000467, l5: 0.000940, l6: 0.001779

[epoch: 867/1000, batch:   488/ 1052, ite: 227880] train loss: 0.003837, tar: 0.000025 
l0: 0.000049, l1: 0.000050, l2: 0.000135, l3: 0.000294, l4: 0.000940, l5: 0.002043, l6: 0.004118

[epoch: 867/1000, batch:   568/ 1052, ite: 227900] train loss: 0.003838, tar: 0.000025 
l0: 0.000018, l1: 0.000020, l2: 0.000093, l3: 0.000153, l4: 0.000345, l5: 0.001222, l6: 0.002235

[epoch: 867/1000, batch:   648/ 1052, ite: 227920] train loss: 0.003838, tar: 0.000025 
l0: 0.000011, l1: 0.000011, l2: 0.000066, l3: 0.000401, l4: 0.000834, l5: 0.002373, l6: 0.003276

[epoch: 867/1000, batch:   728/ 1052, ite: 227940] train loss: 0.003839, tar: 0.000025 
l0: 0.000012, l1: 0.000010, l2: 0.000024, l3: 0.000135, l4: 0.000397, l5: 0.000883, l6: 0.001447

[epoch: 867/1000, batch:   808/ 1052, ite: 227960] train loss: 0.003839, tar: 0.000025 
l0: 0.000011, l1: 0.000011, l2: 0.000056, l3: 0.000127, l4: 0.000247, l5: 0.000843, l6: 0.000902

[epoch: 867/1000, batch:   888/ 1052, ite: 227980] train loss: 0.003840, tar: 0.000025 
l0: 0.000010, l1: 0.000010, l2: 0.000042, l3: 0.000171, l4: 0.000263, l5: 0.000951, l6: 0.002288

[epoch: 867/1000, batch:   968/ 1052, ite: 228000] train loss: 0.003837, tar: 0.000025 
l0: 0.000090, l1: 0.000096, l2: 0.000216, l3: 0.000370, l4: 0.000704, l5: 0.002228, l6: 0.004267

[epoch: 867/1000, batch:  1048/ 1052, ite: 228020] train loss: 0.003838, tar: 0.000025 
[Epoch 867/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000019, l1: 0.000018, l2: 0.000046, l3: 0.000138, l4: 0.000379, l5: 0.001274, l6: 0.001850

[epoch: 868/1000, batch:    76/ 1052, ite: 228040] train loss: 0.003838, tar: 0.000025 
l0: 0.000224, l1: 0.000293, l2: 0.000121, l3: 0.000285, l4: 0.000284, l5: 0.000820, l6: 0.001749

[epoch: 868/1000, batch:   156/ 1052, ite: 228060] train loss: 0.003837, tar: 0.000025 
l0: 0.000379, l1: 0.000405, l2: 0.000484, l3: 0.000509, l4: 0.000723, l5: 0.001746, l6: 0.002233

[epoch: 868/1000, batch:   236/ 1052, ite: 228080] train loss: 0.003845, tar: 0.000027 
l0: 0.000312, l1: 0.000306, l2: 0.000276, l3: 0.000389, l4: 0.000647, l5: 0.000986, l6: 0.001680

[epoch: 868/1000, batch:   316/ 1052, ite: 228100] train loss: 0.003864, tar: 0.000029 
l0: 0.000230, l1: 0.000274, l2: 0.000277, l3: 0.000273, l4: 0.000454, l5: 0.001504, l6: 0.002136

[epoch: 868/1000, batch:   396/ 1052, ite: 228120] train loss: 0.003869, tar: 0.000030 
l0: 0.000188, l1: 0.000173, l2: 0.000286, l3: 0.000275, l4: 0.000655, l5: 0.001266, l6: 0.002000

[epoch: 868/1000, batch:   476/ 1052, ite: 228140] train loss: 0.003871, tar: 0.000031 
l0: 0.000274, l1: 0.000286, l2: 0.000293, l3: 0.000283, l4: 0.000468, l5: 0.001073, l6: 0.002379

[epoch: 868/1000, batch:   556/ 1052, ite: 228160] train loss: 0.003873, tar: 0.000031 
l0: 0.000088, l1: 0.000088, l2: 0.000106, l3: 0.000167, l4: 0.000288, l5: 0.001121, l6: 0.001567

[epoch: 868/1000, batch:   636/ 1052, ite: 228180] train loss: 0.003874, tar: 0.000032 
l0: 0.000246, l1: 0.000228, l2: 0.000344, l3: 0.000406, l4: 0.000937, l5: 0.001899, l6: 0.002853

[epoch: 868/1000, batch:   716/ 1052, ite: 228200] train loss: 0.003875, tar: 0.000032 
l0: 0.000576, l1: 0.000652, l2: 0.000687, l3: 0.000575, l4: 0.000968, l5: 0.003128, l6: 0.004702

[epoch: 868/1000, batch:   796/ 1052, ite: 228220] train loss: 0.003878, tar: 0.000033 
l0: 0.000117, l1: 0.000114, l2: 0.000156, l3: 0.000250, l4: 0.000509, l5: 0.001468, l6: 0.001700

[epoch: 868/1000, batch:   876/ 1052, ite: 228240] train loss: 0.003881, tar: 0.000033 
l0: 0.000068, l1: 0.000085, l2: 0.000105, l3: 0.000114, l4: 0.000265, l5: 0.000453, l6: 0.000987

[epoch: 868/1000, batch:   956/ 1052, ite: 228260] train loss: 0.003884, tar: 0.000033 
l0: 0.000275, l1: 0.000279, l2: 0.000378, l3: 0.000456, l4: 0.001020, l5: 0.001771, l6: 0.003389

[epoch: 868/1000, batch:  1036/ 1052, ite: 228280] train loss: 0.003885, tar: 0.000034 
[Epoch 868/1000] Test loss: 0.021, Test target loss: 0.002
l0: 0.000075, l1: 0.000073, l2: 0.000088, l3: 0.000213, l4: 0.000561, l5: 0.000868, l6: 0.001647

[epoch: 869/1000, batch:    64/ 1052, ite: 228300] train loss: 0.003887, tar: 0.000034 
l0: 0.000072, l1: 0.000069, l2: 0.000150, l3: 0.000364, l4: 0.000538, l5: 0.001407, l6: 0.002263

[epoch: 869/1000, batch:   144/ 1052, ite: 228320] train loss: 0.003888, tar: 0.000034 
l0: 0.000097, l1: 0.000096, l2: 0.000137, l3: 0.000187, l4: 0.000504, l5: 0.001158, l6: 0.002278

[epoch: 869/1000, batch:   224/ 1052, ite: 228340] train loss: 0.003889, tar: 0.000034 
l0: 0.000041, l1: 0.000039, l2: 0.000040, l3: 0.000108, l4: 0.000209, l5: 0.000542, l6: 0.001002

[epoch: 869/1000, batch:   304/ 1052, ite: 228360] train loss: 0.003891, tar: 0.000034 
l0: 0.000049, l1: 0.000050, l2: 0.000067, l3: 0.000175, l4: 0.000351, l5: 0.000748, l6: 0.000882

[epoch: 869/1000, batch:   384/ 1052, ite: 228380] train loss: 0.003892, tar: 0.000035 
l0: 0.000165, l1: 0.000151, l2: 0.000264, l3: 0.000442, l4: 0.000700, l5: 0.001686, l6: 0.003859

[epoch: 869/1000, batch:   464/ 1052, ite: 228400] train loss: 0.003893, tar: 0.000035 
l0: 0.000117, l1: 0.000134, l2: 0.000186, l3: 0.000234, l4: 0.000557, l5: 0.000892, l6: 0.001703

[epoch: 869/1000, batch:   544/ 1052, ite: 228420] train loss: 0.003893, tar: 0.000035 
l0: 0.000037, l1: 0.000033, l2: 0.000065, l3: 0.000134, l4: 0.000394, l5: 0.000887, l6: 0.001210

[epoch: 869/1000, batch:   624/ 1052, ite: 228440] train loss: 0.003892, tar: 0.000035 
l0: 0.000062, l1: 0.000062, l2: 0.000094, l3: 0.000230, l4: 0.000574, l5: 0.001026, l6: 0.001596

[epoch: 869/1000, batch:   704/ 1052, ite: 228460] train loss: 0.003893, tar: 0.000035 
l0: 0.000136, l1: 0.000198, l2: 0.000106, l3: 0.000215, l4: 0.000270, l5: 0.000767, l6: 0.000985

[epoch: 869/1000, batch:   784/ 1052, ite: 228480] train loss: 0.003893, tar: 0.000035 
l0: 0.000023, l1: 0.000021, l2: 0.000043, l3: 0.000167, l4: 0.000334, l5: 0.000832, l6: 0.001410

[epoch: 869/1000, batch:   864/ 1052, ite: 228500] train loss: 0.003893, tar: 0.000035 
l0: 0.000039, l1: 0.000040, l2: 0.000032, l3: 0.000167, l4: 0.000409, l5: 0.001612, l6: 0.001815

[epoch: 869/1000, batch:   944/ 1052, ite: 228520] train loss: 0.003895, tar: 0.000036 
l0: 0.000107, l1: 0.000112, l2: 0.000158, l3: 0.000197, l4: 0.000465, l5: 0.001210, l6: 0.002207

[epoch: 869/1000, batch:  1024/ 1052, ite: 228540] train loss: 0.003897, tar: 0.000036 
[Epoch 869/1000] Test loss: 0.020, Test target loss: 0.003
l0: 0.000047, l1: 0.000051, l2: 0.000141, l3: 0.000221, l4: 0.000390, l5: 0.000972, l6: 0.001971

[epoch: 870/1000, batch:    52/ 1052, ite: 228560] train loss: 0.003896, tar: 0.000036 
l0: 0.000027, l1: 0.000019, l2: 0.000056, l3: 0.000146, l4: 0.000519, l5: 0.001053, l6: 0.001616

[epoch: 870/1000, batch:   132/ 1052, ite: 228580] train loss: 0.003896, tar: 0.000036 
l0: 0.000031, l1: 0.000026, l2: 0.000059, l3: 0.000122, l4: 0.000437, l5: 0.000942, l6: 0.001264

[epoch: 870/1000, batch:   212/ 1052, ite: 228600] train loss: 0.003896, tar: 0.000036 
l0: 0.000064, l1: 0.000058, l2: 0.000101, l3: 0.000298, l4: 0.000665, l5: 0.001407, l6: 0.002086

[epoch: 870/1000, batch:   292/ 1052, ite: 228620] train loss: 0.003897, tar: 0.000036 
l0: 0.000044, l1: 0.000033, l2: 0.000124, l3: 0.000307, l4: 0.000898, l5: 0.001304, l6: 0.002148

[epoch: 870/1000, batch:   372/ 1052, ite: 228640] train loss: 0.003899, tar: 0.000036 
l0: 0.000050, l1: 0.000057, l2: 0.000041, l3: 0.000095, l4: 0.000211, l5: 0.000843, l6: 0.001477

[epoch: 870/1000, batch:   452/ 1052, ite: 228660] train loss: 0.003899, tar: 0.000036 
l0: 0.000170, l1: 0.000194, l2: 0.000216, l3: 0.000333, l4: 0.000772, l5: 0.001760, l6: 0.002450

[epoch: 870/1000, batch:   532/ 1052, ite: 228680] train loss: 0.003900, tar: 0.000037 
l0: 0.000050, l1: 0.000048, l2: 0.000090, l3: 0.000164, l4: 0.000338, l5: 0.001331, l6: 0.003012

[epoch: 870/1000, batch:   612/ 1052, ite: 228700] train loss: 0.003900, tar: 0.000037 
l0: 0.000042, l1: 0.000034, l2: 0.000043, l3: 0.000160, l4: 0.000363, l5: 0.000660, l6: 0.001402

[epoch: 870/1000, batch:   692/ 1052, ite: 228720] train loss: 0.003901, tar: 0.000037 
l0: 0.000064, l1: 0.000064, l2: 0.000091, l3: 0.000253, l4: 0.000394, l5: 0.000758, l6: 0.001499

[epoch: 870/1000, batch:   772/ 1052, ite: 228740] train loss: 0.003901, tar: 0.000037 
l0: 0.000052, l1: 0.000050, l2: 0.000096, l3: 0.000259, l4: 0.000687, l5: 0.001336, l6: 0.003419

[epoch: 870/1000, batch:   852/ 1052, ite: 228760] train loss: 0.003901, tar: 0.000037 
l0: 0.000021, l1: 0.000018, l2: 0.000046, l3: 0.000110, l4: 0.000389, l5: 0.000946, l6: 0.001579

[epoch: 870/1000, batch:   932/ 1052, ite: 228780] train loss: 0.003902, tar: 0.000037 
l0: 0.000113, l1: 0.000114, l2: 0.000152, l3: 0.000240, l4: 0.000463, l5: 0.000960, l6: 0.001380

[epoch: 870/1000, batch:  1012/ 1052, ite: 228800] train loss: 0.003903, tar: 0.000037 
[Epoch 870/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000027, l1: 0.000024, l2: 0.000051, l3: 0.000161, l4: 0.000545, l5: 0.001322, l6: 0.002087

[epoch: 871/1000, batch:    40/ 1052, ite: 228820] train loss: 0.003903, tar: 0.000037 
l0: 0.000024, l1: 0.000027, l2: 0.000040, l3: 0.000122, l4: 0.000317, l5: 0.000611, l6: 0.001022

[epoch: 871/1000, batch:   120/ 1052, ite: 228840] train loss: 0.003903, tar: 0.000037 
l0: 0.000080, l1: 0.000079, l2: 0.000226, l3: 0.000386, l4: 0.001056, l5: 0.001988, l6: 0.002915

[epoch: 871/1000, batch:   200/ 1052, ite: 228860] train loss: 0.003904, tar: 0.000037 
l0: 0.000022, l1: 0.000023, l2: 0.000050, l3: 0.000151, l4: 0.000343, l5: 0.000833, l6: 0.001025

[epoch: 871/1000, batch:   280/ 1052, ite: 228880] train loss: 0.003903, tar: 0.000037 
l0: 0.000056, l1: 0.000053, l2: 0.000112, l3: 0.000257, l4: 0.000567, l5: 0.001874, l6: 0.003802

[epoch: 871/1000, batch:   360/ 1052, ite: 228900] train loss: 0.003905, tar: 0.000037 
l0: 0.000082, l1: 0.000081, l2: 0.000141, l3: 0.000271, l4: 0.000617, l5: 0.001214, l6: 0.002475

[epoch: 871/1000, batch:   440/ 1052, ite: 228920] train loss: 0.003907, tar: 0.000037 
l0: 0.000022, l1: 0.000019, l2: 0.000054, l3: 0.000171, l4: 0.000418, l5: 0.000917, l6: 0.001750

[epoch: 871/1000, batch:   520/ 1052, ite: 228940] train loss: 0.003907, tar: 0.000037 
l0: 0.000101, l1: 0.000098, l2: 0.000171, l3: 0.000285, l4: 0.000626, l5: 0.000945, l6: 0.001933

[epoch: 871/1000, batch:   600/ 1052, ite: 228960] train loss: 0.003906, tar: 0.000037 
l0: 0.000042, l1: 0.000043, l2: 0.000077, l3: 0.000364, l4: 0.000624, l5: 0.001392, l6: 0.002023

[epoch: 871/1000, batch:   680/ 1052, ite: 228980] train loss: 0.003906, tar: 0.000037 
l0: 0.000013, l1: 0.000014, l2: 0.000033, l3: 0.000104, l4: 0.000293, l5: 0.000581, l6: 0.001802

[epoch: 871/1000, batch:   760/ 1052, ite: 229000] train loss: 0.003906, tar: 0.000037 
l0: 0.000101, l1: 0.000098, l2: 0.000126, l3: 0.000214, l4: 0.000559, l5: 0.001404, l6: 0.002200

[epoch: 871/1000, batch:   840/ 1052, ite: 229020] train loss: 0.003907, tar: 0.000038 
l0: 0.000012, l1: 0.000010, l2: 0.000054, l3: 0.000192, l4: 0.000602, l5: 0.001469, l6: 0.002108

[epoch: 871/1000, batch:   920/ 1052, ite: 229040] train loss: 0.003907, tar: 0.000038 
l0: 0.000032, l1: 0.000046, l2: 0.000041, l3: 0.000124, l4: 0.000465, l5: 0.000856, l6: 0.002367

[epoch: 871/1000, batch:  1000/ 1052, ite: 229060] train loss: 0.003907, tar: 0.000038 
[Epoch 871/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000032, l1: 0.000029, l2: 0.000054, l3: 0.000168, l4: 0.000326, l5: 0.000639, l6: 0.002515

[epoch: 872/1000, batch:    28/ 1052, ite: 229080] train loss: 0.003907, tar: 0.000038 
l0: 0.000016, l1: 0.000017, l2: 0.000032, l3: 0.000151, l4: 0.000474, l5: 0.001480, l6: 0.002252

[epoch: 872/1000, batch:   108/ 1052, ite: 229100] train loss: 0.003907, tar: 0.000038 
l0: 0.000030, l1: 0.000035, l2: 0.000064, l3: 0.000229, l4: 0.000550, l5: 0.001584, l6: 0.001842

[epoch: 872/1000, batch:   188/ 1052, ite: 229120] train loss: 0.003908, tar: 0.000038 
l0: 0.000024, l1: 0.000022, l2: 0.000069, l3: 0.000216, l4: 0.000654, l5: 0.000972, l6: 0.002230

[epoch: 872/1000, batch:   268/ 1052, ite: 229140] train loss: 0.003908, tar: 0.000038 
l0: 0.000012, l1: 0.000010, l2: 0.000022, l3: 0.000084, l4: 0.000264, l5: 0.000831, l6: 0.001371

[epoch: 872/1000, batch:   348/ 1052, ite: 229160] train loss: 0.003907, tar: 0.000038 
l0: 0.000023, l1: 0.000025, l2: 0.000025, l3: 0.000093, l4: 0.000145, l5: 0.000836, l6: 0.000964

[epoch: 872/1000, batch:   428/ 1052, ite: 229180] train loss: 0.003907, tar: 0.000038 
l0: 0.000023, l1: 0.000023, l2: 0.000038, l3: 0.000112, l4: 0.000519, l5: 0.000829, l6: 0.001078

[epoch: 872/1000, batch:   508/ 1052, ite: 229200] train loss: 0.003906, tar: 0.000038 
l0: 0.000040, l1: 0.000037, l2: 0.000058, l3: 0.000131, l4: 0.000385, l5: 0.001161, l6: 0.002204

[epoch: 872/1000, batch:   588/ 1052, ite: 229220] train loss: 0.003906, tar: 0.000038 
l0: 0.000019, l1: 0.000018, l2: 0.000034, l3: 0.000085, l4: 0.000294, l5: 0.000823, l6: 0.001450

[epoch: 872/1000, batch:   668/ 1052, ite: 229240] train loss: 0.003907, tar: 0.000038 
l0: 0.000072, l1: 0.000066, l2: 0.000120, l3: 0.000204, l4: 0.000677, l5: 0.001596, l6: 0.002337

[epoch: 872/1000, batch:   748/ 1052, ite: 229260] train loss: 0.003907, tar: 0.000038 
l0: 0.000023, l1: 0.000020, l2: 0.000081, l3: 0.000381, l4: 0.001169, l5: 0.001396, l6: 0.002603

[epoch: 872/1000, batch:   828/ 1052, ite: 229280] train loss: 0.003906, tar: 0.000038 
l0: 0.000025, l1: 0.000023, l2: 0.000080, l3: 0.000227, l4: 0.000448, l5: 0.000932, l6: 0.001449

[epoch: 872/1000, batch:   908/ 1052, ite: 229300] train loss: 0.003906, tar: 0.000038 
l0: 0.000016, l1: 0.000015, l2: 0.000054, l3: 0.000159, l4: 0.000304, l5: 0.001228, l6: 0.002562

[epoch: 872/1000, batch:   988/ 1052, ite: 229320] train loss: 0.003907, tar: 0.000038 
[Epoch 872/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000062, l1: 0.000073, l2: 0.000170, l3: 0.000276, l4: 0.000687, l5: 0.001132, l6: 0.002431

[epoch: 873/1000, batch:    16/ 1052, ite: 229340] train loss: 0.003908, tar: 0.000038 
l0: 0.000045, l1: 0.000052, l2: 0.000044, l3: 0.000149, l4: 0.000327, l5: 0.001122, l6: 0.001763

[epoch: 873/1000, batch:    96/ 1052, ite: 229360] train loss: 0.003908, tar: 0.000038 
l0: 0.000013, l1: 0.000013, l2: 0.000031, l3: 0.000136, l4: 0.000367, l5: 0.000897, l6: 0.001818

[epoch: 873/1000, batch:   176/ 1052, ite: 229380] train loss: 0.003909, tar: 0.000038 
l0: 0.000054, l1: 0.000053, l2: 0.000079, l3: 0.000106, l4: 0.000353, l5: 0.000716, l6: 0.002150

[epoch: 873/1000, batch:   256/ 1052, ite: 229400] train loss: 0.003909, tar: 0.000038 
l0: 0.000028, l1: 0.000026, l2: 0.000077, l3: 0.000153, l4: 0.000421, l5: 0.000984, l6: 0.001607

[epoch: 873/1000, batch:   336/ 1052, ite: 229420] train loss: 0.003908, tar: 0.000038 
l0: 0.000029, l1: 0.000031, l2: 0.000066, l3: 0.000366, l4: 0.000801, l5: 0.001711, l6: 0.002599

[epoch: 873/1000, batch:   416/ 1052, ite: 229440] train loss: 0.003908, tar: 0.000038 
l0: 0.000057, l1: 0.000055, l2: 0.000100, l3: 0.000307, l4: 0.001037, l5: 0.002325, l6: 0.003136

[epoch: 873/1000, batch:   496/ 1052, ite: 229460] train loss: 0.003908, tar: 0.000038 
l0: 0.000078, l1: 0.000071, l2: 0.000136, l3: 0.000218, l4: 0.000439, l5: 0.001224, l6: 0.001274

[epoch: 873/1000, batch:   576/ 1052, ite: 229480] train loss: 0.003909, tar: 0.000038 
l0: 0.000025, l1: 0.000021, l2: 0.000041, l3: 0.000210, l4: 0.000295, l5: 0.000737, l6: 0.000704

[epoch: 873/1000, batch:   656/ 1052, ite: 229500] train loss: 0.003912, tar: 0.000039 
l0: 0.000030, l1: 0.000028, l2: 0.000067, l3: 0.000152, l4: 0.000380, l5: 0.001252, l6: 0.002128

[epoch: 873/1000, batch:   736/ 1052, ite: 229520] train loss: 0.003913, tar: 0.000039 
l0: 0.000123, l1: 0.000120, l2: 0.000141, l3: 0.000319, l4: 0.000524, l5: 0.001265, l6: 0.001735

[epoch: 873/1000, batch:   816/ 1052, ite: 229540] train loss: 0.003913, tar: 0.000039 
l0: 0.000057, l1: 0.000055, l2: 0.000139, l3: 0.000322, l4: 0.000746, l5: 0.001341, l6: 0.003219

[epoch: 873/1000, batch:   896/ 1052, ite: 229560] train loss: 0.003912, tar: 0.000039 
l0: 0.000057, l1: 0.000052, l2: 0.000096, l3: 0.000339, l4: 0.000603, l5: 0.001196, l6: 0.002059

[epoch: 873/1000, batch:   976/ 1052, ite: 229580] train loss: 0.003913, tar: 0.000039 
[Epoch 873/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000059, l1: 0.000056, l2: 0.000117, l3: 0.000331, l4: 0.000567, l5: 0.000859, l6: 0.001550

[epoch: 874/1000, batch:     4/ 1052, ite: 229600] train loss: 0.003913, tar: 0.000039 
l0: 0.000056, l1: 0.000056, l2: 0.000072, l3: 0.000148, l4: 0.000331, l5: 0.000874, l6: 0.001636

[epoch: 874/1000, batch:    84/ 1052, ite: 229620] train loss: 0.003914, tar: 0.000039 
l0: 0.000108, l1: 0.000108, l2: 0.000162, l3: 0.000299, l4: 0.000642, l5: 0.001448, l6: 0.002092

[epoch: 874/1000, batch:   164/ 1052, ite: 229640] train loss: 0.003914, tar: 0.000039 
l0: 0.000017, l1: 0.000015, l2: 0.000081, l3: 0.000156, l4: 0.000306, l5: 0.000859, l6: 0.001235

[epoch: 874/1000, batch:   244/ 1052, ite: 229660] train loss: 0.003913, tar: 0.000039 
l0: 0.000030, l1: 0.000031, l2: 0.000046, l3: 0.000151, l4: 0.000350, l5: 0.001525, l6: 0.002187

[epoch: 874/1000, batch:   324/ 1052, ite: 229680] train loss: 0.003913, tar: 0.000039 
l0: 0.000015, l1: 0.000014, l2: 0.000032, l3: 0.000109, l4: 0.000286, l5: 0.000597, l6: 0.001692

[epoch: 874/1000, batch:   404/ 1052, ite: 229700] train loss: 0.003914, tar: 0.000039 
l0: 0.000067, l1: 0.000066, l2: 0.000186, l3: 0.000366, l4: 0.000797, l5: 0.001488, l6: 0.003046

[epoch: 874/1000, batch:   484/ 1052, ite: 229720] train loss: 0.003916, tar: 0.000039 
l0: 0.000062, l1: 0.000060, l2: 0.000081, l3: 0.000193, l4: 0.000581, l5: 0.000695, l6: 0.001436

[epoch: 874/1000, batch:   564/ 1052, ite: 229740] train loss: 0.003916, tar: 0.000039 
l0: 0.000075, l1: 0.000072, l2: 0.000099, l3: 0.000287, l4: 0.000684, l5: 0.001002, l6: 0.003797

[epoch: 874/1000, batch:   644/ 1052, ite: 229760] train loss: 0.003915, tar: 0.000039 
l0: 0.000018, l1: 0.000019, l2: 0.000034, l3: 0.000090, l4: 0.000393, l5: 0.000585, l6: 0.001286

[epoch: 874/1000, batch:   724/ 1052, ite: 229780] train loss: 0.003915, tar: 0.000039 
l0: 0.000005, l1: 0.000008, l2: 0.000010, l3: 0.000057, l4: 0.000236, l5: 0.000647, l6: 0.001357

[epoch: 874/1000, batch:   804/ 1052, ite: 229800] train loss: 0.003915, tar: 0.000039 
l0: 0.000011, l1: 0.000010, l2: 0.000045, l3: 0.000083, l4: 0.000383, l5: 0.000672, l6: 0.001162

[epoch: 874/1000, batch:   884/ 1052, ite: 229820] train loss: 0.003916, tar: 0.000039 
l0: 0.000058, l1: 0.000059, l2: 0.000150, l3: 0.000303, l4: 0.000585, l5: 0.001165, l6: 0.004280

[epoch: 874/1000, batch:   964/ 1052, ite: 229840] train loss: 0.003918, tar: 0.000039 
l0: 0.000005, l1: 0.000004, l2: 0.000013, l3: 0.000048, l4: 0.000324, l5: 0.000564, l6: 0.000876

[epoch: 874/1000, batch:  1044/ 1052, ite: 229860] train loss: 0.003917, tar: 0.000039 
[Epoch 874/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000064, l1: 0.000063, l2: 0.000074, l3: 0.000195, l4: 0.000815, l5: 0.001234, l6: 0.001933

[epoch: 875/1000, batch:    72/ 1052, ite: 229880] train loss: 0.003916, tar: 0.000039 
l0: 0.000032, l1: 0.000034, l2: 0.000090, l3: 0.000190, l4: 0.000372, l5: 0.000814, l6: 0.001609

[epoch: 875/1000, batch:   152/ 1052, ite: 229900] train loss: 0.003916, tar: 0.000039 
l0: 0.000020, l1: 0.000018, l2: 0.000046, l3: 0.000164, l4: 0.000603, l5: 0.000951, l6: 0.002263

[epoch: 875/1000, batch:   232/ 1052, ite: 229920] train loss: 0.003916, tar: 0.000039 
l0: 0.000024, l1: 0.000027, l2: 0.000109, l3: 0.000333, l4: 0.000666, l5: 0.001132, l6: 0.002332

[epoch: 875/1000, batch:   312/ 1052, ite: 229940] train loss: 0.003916, tar: 0.000039 
l0: 0.000009, l1: 0.000007, l2: 0.000042, l3: 0.000174, l4: 0.000398, l5: 0.000970, l6: 0.001885

[epoch: 875/1000, batch:   392/ 1052, ite: 229960] train loss: 0.003917, tar: 0.000039 
l0: 0.000011, l1: 0.000010, l2: 0.000021, l3: 0.000057, l4: 0.000237, l5: 0.000958, l6: 0.001068

[epoch: 875/1000, batch:   472/ 1052, ite: 229980] train loss: 0.003917, tar: 0.000039 
l0: 0.000015, l1: 0.000013, l2: 0.000037, l3: 0.000069, l4: 0.000092, l5: 0.000722, l6: 0.000663

[epoch: 875/1000, batch:   552/ 1052, ite: 230000] train loss: 0.003918, tar: 0.000039 
l0: 0.000006, l1: 0.000005, l2: 0.000022, l3: 0.000067, l4: 0.000365, l5: 0.000852, l6: 0.001566

[epoch: 875/1000, batch:   632/ 1052, ite: 230020] train loss: 0.003918, tar: 0.000039 
l0: 0.000010, l1: 0.000008, l2: 0.000037, l3: 0.000103, l4: 0.000385, l5: 0.000962, l6: 0.001029

[epoch: 875/1000, batch:   712/ 1052, ite: 230040] train loss: 0.003917, tar: 0.000039 
l0: 0.000005, l1: 0.000004, l2: 0.000032, l3: 0.000121, l4: 0.000514, l5: 0.001095, l6: 0.001904

[epoch: 875/1000, batch:   792/ 1052, ite: 230060] train loss: 0.003917, tar: 0.000039 
l0: 0.000039, l1: 0.000035, l2: 0.000099, l3: 0.000391, l4: 0.000881, l5: 0.002213, l6: 0.005426

[epoch: 875/1000, batch:   872/ 1052, ite: 230080] train loss: 0.003917, tar: 0.000039 
l0: 0.000004, l1: 0.000004, l2: 0.000016, l3: 0.000062, l4: 0.000240, l5: 0.000724, l6: 0.001108

[epoch: 875/1000, batch:   952/ 1052, ite: 230100] train loss: 0.003917, tar: 0.000039 
l0: 0.000004, l1: 0.000003, l2: 0.000044, l3: 0.000142, l4: 0.000302, l5: 0.001011, l6: 0.000911

[epoch: 875/1000, batch:  1032/ 1052, ite: 230120] train loss: 0.003916, tar: 0.000039 
[Epoch 875/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000009, l1: 0.000011, l2: 0.000028, l3: 0.000068, l4: 0.000333, l5: 0.000903, l6: 0.001302

[epoch: 876/1000, batch:    60/ 1052, ite: 230140] train loss: 0.003915, tar: 0.000039 
l0: 0.000056, l1: 0.000056, l2: 0.000078, l3: 0.000197, l4: 0.000464, l5: 0.001001, l6: 0.002414

[epoch: 876/1000, batch:   140/ 1052, ite: 230160] train loss: 0.003916, tar: 0.000039 
l0: 0.000019, l1: 0.000022, l2: 0.000030, l3: 0.000066, l4: 0.000208, l5: 0.000473, l6: 0.001264

[epoch: 876/1000, batch:   220/ 1052, ite: 230180] train loss: 0.003915, tar: 0.000039 
l0: 0.000022, l1: 0.000025, l2: 0.000031, l3: 0.000059, l4: 0.000167, l5: 0.000545, l6: 0.000887

[epoch: 876/1000, batch:   300/ 1052, ite: 230200] train loss: 0.003915, tar: 0.000039 
l0: 0.000071, l1: 0.000077, l2: 0.000130, l3: 0.000432, l4: 0.000915, l5: 0.002175, l6: 0.003461

[epoch: 876/1000, batch:   380/ 1052, ite: 230220] train loss: 0.003916, tar: 0.000039 
l0: 0.000011, l1: 0.000009, l2: 0.000093, l3: 0.000268, l4: 0.000469, l5: 0.001163, l6: 0.001508

[epoch: 876/1000, batch:   460/ 1052, ite: 230240] train loss: 0.003916, tar: 0.000038 
l0: 0.000043, l1: 0.000040, l2: 0.000058, l3: 0.000144, l4: 0.000491, l5: 0.001088, l6: 0.001358

[epoch: 876/1000, batch:   540/ 1052, ite: 230260] train loss: 0.003916, tar: 0.000038 
l0: 0.000010, l1: 0.000011, l2: 0.000014, l3: 0.000091, l4: 0.000514, l5: 0.000959, l6: 0.001736

[epoch: 876/1000, batch:   620/ 1052, ite: 230280] train loss: 0.003916, tar: 0.000038 
l0: 0.000007, l1: 0.000019, l2: 0.000021, l3: 0.000056, l4: 0.000139, l5: 0.000986, l6: 0.001055

[epoch: 876/1000, batch:   700/ 1052, ite: 230300] train loss: 0.003916, tar: 0.000038 
l0: 0.000023, l1: 0.000022, l2: 0.000062, l3: 0.000178, l4: 0.000524, l5: 0.001566, l6: 0.002795

[epoch: 876/1000, batch:   780/ 1052, ite: 230320] train loss: 0.003916, tar: 0.000038 
l0: 0.000007, l1: 0.000006, l2: 0.000031, l3: 0.000165, l4: 0.000360, l5: 0.001034, l6: 0.002592

[epoch: 876/1000, batch:   860/ 1052, ite: 230340] train loss: 0.003915, tar: 0.000038 
l0: 0.000020, l1: 0.000019, l2: 0.000070, l3: 0.000132, l4: 0.000325, l5: 0.001009, l6: 0.001455

[epoch: 876/1000, batch:   940/ 1052, ite: 230360] train loss: 0.003914, tar: 0.000038 
l0: 0.000093, l1: 0.000083, l2: 0.000185, l3: 0.000486, l4: 0.001039, l5: 0.002747, l6: 0.003259

[epoch: 876/1000, batch:  1020/ 1052, ite: 230380] train loss: 0.003913, tar: 0.000038 
[Epoch 876/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000036, l1: 0.000035, l2: 0.000115, l3: 0.000220, l4: 0.000487, l5: 0.001346, l6: 0.003813

[epoch: 877/1000, batch:    48/ 1052, ite: 230400] train loss: 0.003914, tar: 0.000038 
l0: 0.000018, l1: 0.000019, l2: 0.000038, l3: 0.000118, l4: 0.000372, l5: 0.001316, l6: 0.001701

[epoch: 877/1000, batch:   128/ 1052, ite: 230420] train loss: 0.003914, tar: 0.000038 
l0: 0.000030, l1: 0.000033, l2: 0.000145, l3: 0.000375, l4: 0.000644, l5: 0.001991, l6: 0.003324

[epoch: 877/1000, batch:   208/ 1052, ite: 230440] train loss: 0.003915, tar: 0.000038 
l0: 0.000023, l1: 0.000022, l2: 0.000046, l3: 0.000083, l4: 0.000365, l5: 0.000635, l6: 0.001254

[epoch: 877/1000, batch:   288/ 1052, ite: 230460] train loss: 0.003915, tar: 0.000038 
l0: 0.000025, l1: 0.000026, l2: 0.000128, l3: 0.000324, l4: 0.000700, l5: 0.001568, l6: 0.002455

[epoch: 877/1000, batch:   368/ 1052, ite: 230480] train loss: 0.003915, tar: 0.000038 
l0: 0.000001, l1: 0.000001, l2: 0.000011, l3: 0.000091, l4: 0.000510, l5: 0.000663, l6: 0.001463

[epoch: 877/1000, batch:   448/ 1052, ite: 230500] train loss: 0.003913, tar: 0.000038 
l0: 0.000008, l1: 0.000008, l2: 0.000013, l3: 0.000070, l4: 0.000150, l5: 0.000730, l6: 0.001147

[epoch: 877/1000, batch:   528/ 1052, ite: 230520] train loss: 0.003912, tar: 0.000038 
l0: 0.000006, l1: 0.000008, l2: 0.000023, l3: 0.000132, l4: 0.000289, l5: 0.000701, l6: 0.001886

[epoch: 877/1000, batch:   608/ 1052, ite: 230540] train loss: 0.003912, tar: 0.000038 
l0: 0.000017, l1: 0.000017, l2: 0.000044, l3: 0.000153, l4: 0.000483, l5: 0.000725, l6: 0.001465

[epoch: 877/1000, batch:   688/ 1052, ite: 230560] train loss: 0.003912, tar: 0.000038 
l0: 0.000011, l1: 0.000011, l2: 0.000040, l3: 0.000153, l4: 0.000311, l5: 0.000887, l6: 0.002097

[epoch: 877/1000, batch:   768/ 1052, ite: 230580] train loss: 0.003912, tar: 0.000038 
l0: 0.000027, l1: 0.000023, l2: 0.000068, l3: 0.000185, l4: 0.000399, l5: 0.000840, l6: 0.001698

[epoch: 877/1000, batch:   848/ 1052, ite: 230600] train loss: 0.003911, tar: 0.000038 
l0: 0.000113, l1: 0.000102, l2: 0.000138, l3: 0.000233, l4: 0.000843, l5: 0.001557, l6: 0.001995

[epoch: 877/1000, batch:   928/ 1052, ite: 230620] train loss: 0.003911, tar: 0.000038 
l0: 0.000015, l1: 0.000017, l2: 0.000057, l3: 0.000128, l4: 0.000355, l5: 0.000805, l6: 0.002562

[epoch: 877/1000, batch:  1008/ 1052, ite: 230640] train loss: 0.003911, tar: 0.000038 
[Epoch 877/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000017, l1: 0.000018, l2: 0.000061, l3: 0.000255, l4: 0.000670, l5: 0.001186, l6: 0.002873

[epoch: 878/1000, batch:    36/ 1052, ite: 230660] train loss: 0.003910, tar: 0.000038 
l0: 0.000013, l1: 0.000013, l2: 0.000037, l3: 0.000195, l4: 0.000585, l5: 0.000994, l6: 0.001723

[epoch: 878/1000, batch:   116/ 1052, ite: 230680] train loss: 0.003910, tar: 0.000038 
l0: 0.000001, l1: 0.000001, l2: 0.000021, l3: 0.000270, l4: 0.000515, l5: 0.001397, l6: 0.002164

[epoch: 878/1000, batch:   196/ 1052, ite: 230700] train loss: 0.003911, tar: 0.000038 
l0: 0.000022, l1: 0.000023, l2: 0.000029, l3: 0.000078, l4: 0.000318, l5: 0.000764, l6: 0.001317

[epoch: 878/1000, batch:   276/ 1052, ite: 230720] train loss: 0.003912, tar: 0.000038 
l0: 0.000040, l1: 0.000045, l2: 0.000083, l3: 0.000336, l4: 0.000669, l5: 0.001858, l6: 0.002948

[epoch: 878/1000, batch:   356/ 1052, ite: 230740] train loss: 0.003911, tar: 0.000038 
l0: 0.000019, l1: 0.000017, l2: 0.000053, l3: 0.000240, l4: 0.000362, l5: 0.001138, l6: 0.001836

[epoch: 878/1000, batch:   436/ 1052, ite: 230760] train loss: 0.003912, tar: 0.000038 
l0: 0.000105, l1: 0.000107, l2: 0.000196, l3: 0.000402, l4: 0.000932, l5: 0.002588, l6: 0.004210

[epoch: 878/1000, batch:   516/ 1052, ite: 230780] train loss: 0.003912, tar: 0.000038 
l0: 0.000004, l1: 0.000003, l2: 0.000030, l3: 0.000119, l4: 0.000314, l5: 0.000681, l6: 0.001155

[epoch: 878/1000, batch:   596/ 1052, ite: 230800] train loss: 0.003912, tar: 0.000038 
l0: 0.000037, l1: 0.000038, l2: 0.000070, l3: 0.000204, l4: 0.000506, l5: 0.001581, l6: 0.001728

[epoch: 878/1000, batch:   676/ 1052, ite: 230820] train loss: 0.003911, tar: 0.000038 
l0: 0.000018, l1: 0.000017, l2: 0.000049, l3: 0.000138, l4: 0.000455, l5: 0.000972, l6: 0.002564

[epoch: 878/1000, batch:   756/ 1052, ite: 230840] train loss: 0.003912, tar: 0.000037 
l0: 0.000014, l1: 0.000013, l2: 0.000051, l3: 0.000184, l4: 0.000976, l5: 0.001158, l6: 0.002238

[epoch: 878/1000, batch:   836/ 1052, ite: 230860] train loss: 0.003911, tar: 0.000037 
l0: 0.000012, l1: 0.000012, l2: 0.000042, l3: 0.000159, l4: 0.000428, l5: 0.001063, l6: 0.001423

[epoch: 878/1000, batch:   916/ 1052, ite: 230880] train loss: 0.003910, tar: 0.000037 
l0: 0.000010, l1: 0.000012, l2: 0.000036, l3: 0.000131, l4: 0.000371, l5: 0.000513, l6: 0.001424

[epoch: 878/1000, batch:   996/ 1052, ite: 230900] train loss: 0.003910, tar: 0.000037 
[Epoch 878/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000026, l1: 0.000025, l2: 0.000107, l3: 0.000305, l4: 0.000990, l5: 0.001530, l6: 0.002669

[epoch: 879/1000, batch:    24/ 1052, ite: 230920] train loss: 0.003909, tar: 0.000037 
l0: 0.000014, l1: 0.000013, l2: 0.000044, l3: 0.000093, l4: 0.000328, l5: 0.000756, l6: 0.001031

[epoch: 879/1000, batch:   104/ 1052, ite: 230940] train loss: 0.003908, tar: 0.000037 
l0: 0.000031, l1: 0.000032, l2: 0.000053, l3: 0.000193, l4: 0.000624, l5: 0.001207, l6: 0.002045

[epoch: 879/1000, batch:   184/ 1052, ite: 230960] train loss: 0.003909, tar: 0.000037 
l0: 0.000013, l1: 0.000018, l2: 0.000030, l3: 0.000183, l4: 0.000576, l5: 0.000885, l6: 0.002029

[epoch: 879/1000, batch:   264/ 1052, ite: 230980] train loss: 0.003909, tar: 0.000037 
l0: 0.000011, l1: 0.000012, l2: 0.000034, l3: 0.000115, l4: 0.000295, l5: 0.001105, l6: 0.001239

[epoch: 879/1000, batch:   344/ 1052, ite: 231000] train loss: 0.003910, tar: 0.000037 
l0: 0.000018, l1: 0.000017, l2: 0.000025, l3: 0.000076, l4: 0.000358, l5: 0.000753, l6: 0.001970

[epoch: 879/1000, batch:   424/ 1052, ite: 231020] train loss: 0.003909, tar: 0.000037 
l0: 0.000029, l1: 0.000027, l2: 0.000108, l3: 0.000371, l4: 0.000813, l5: 0.002201, l6: 0.004775

[epoch: 879/1000, batch:   504/ 1052, ite: 231040] train loss: 0.003909, tar: 0.000037 
l0: 0.000026, l1: 0.000033, l2: 0.000054, l3: 0.000141, l4: 0.000376, l5: 0.000943, l6: 0.001777

[epoch: 879/1000, batch:   584/ 1052, ite: 231060] train loss: 0.003908, tar: 0.000037 
l0: 0.000007, l1: 0.000006, l2: 0.000045, l3: 0.000175, l4: 0.000678, l5: 0.001365, l6: 0.002027

[epoch: 879/1000, batch:   664/ 1052, ite: 231080] train loss: 0.003909, tar: 0.000037 
l0: 0.000010, l1: 0.000010, l2: 0.000031, l3: 0.000133, l4: 0.000343, l5: 0.000807, l6: 0.001886

[epoch: 879/1000, batch:   744/ 1052, ite: 231100] train loss: 0.003909, tar: 0.000037 
l0: 0.000039, l1: 0.000046, l2: 0.000079, l3: 0.000179, l4: 0.000333, l5: 0.001152, l6: 0.002199

[epoch: 879/1000, batch:   824/ 1052, ite: 231120] train loss: 0.003909, tar: 0.000037 
l0: 0.000012, l1: 0.000016, l2: 0.000019, l3: 0.000113, l4: 0.000178, l5: 0.000531, l6: 0.000780

[epoch: 879/1000, batch:   904/ 1052, ite: 231140] train loss: 0.003908, tar: 0.000037 
l0: 0.000004, l1: 0.000004, l2: 0.000016, l3: 0.000090, l4: 0.000262, l5: 0.000539, l6: 0.001061

[epoch: 879/1000, batch:   984/ 1052, ite: 231160] train loss: 0.003907, tar: 0.000037 
[Epoch 879/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000011, l1: 0.000010, l2: 0.000041, l3: 0.000136, l4: 0.000543, l5: 0.001305, l6: 0.001441

[epoch: 880/1000, batch:    12/ 1052, ite: 231180] train loss: 0.003906, tar: 0.000037 
l0: 0.000037, l1: 0.000037, l2: 0.000076, l3: 0.000154, l4: 0.000487, l5: 0.001224, l6: 0.001801

[epoch: 880/1000, batch:    92/ 1052, ite: 231200] train loss: 0.003905, tar: 0.000037 
l0: 0.000000, l1: 0.000000, l2: 0.000003, l3: 0.000074, l4: 0.000427, l5: 0.000846, l6: 0.001169

[epoch: 880/1000, batch:   172/ 1052, ite: 231220] train loss: 0.003905, tar: 0.000037 
l0: 0.000004, l1: 0.000004, l2: 0.000018, l3: 0.000109, l4: 0.000195, l5: 0.000627, l6: 0.000876

[epoch: 880/1000, batch:   252/ 1052, ite: 231240] train loss: 0.003905, tar: 0.000037 
l0: 0.000002, l1: 0.000002, l2: 0.000033, l3: 0.000160, l4: 0.000248, l5: 0.001429, l6: 0.002521

[epoch: 880/1000, batch:   332/ 1052, ite: 231260] train loss: 0.003904, tar: 0.000037 
l0: 0.000032, l1: 0.000033, l2: 0.000054, l3: 0.000264, l4: 0.000731, l5: 0.001269, l6: 0.002256

[epoch: 880/1000, batch:   412/ 1052, ite: 231280] train loss: 0.003903, tar: 0.000037 
l0: 0.000005, l1: 0.000006, l2: 0.000008, l3: 0.000082, l4: 0.000405, l5: 0.000998, l6: 0.001374

[epoch: 880/1000, batch:   492/ 1052, ite: 231300] train loss: 0.003904, tar: 0.000037 
l0: 0.000052, l1: 0.000051, l2: 0.000115, l3: 0.000310, l4: 0.000678, l5: 0.001163, l6: 0.002104

[epoch: 880/1000, batch:   572/ 1052, ite: 231320] train loss: 0.003905, tar: 0.000037 
l0: 0.000006, l1: 0.000008, l2: 0.000021, l3: 0.000064, l4: 0.000194, l5: 0.000384, l6: 0.001317

[epoch: 880/1000, batch:   652/ 1052, ite: 231340] train loss: 0.003905, tar: 0.000037 
l0: 0.000038, l1: 0.000039, l2: 0.000178, l3: 0.000441, l4: 0.001019, l5: 0.001907, l6: 0.003899

[epoch: 880/1000, batch:   732/ 1052, ite: 231360] train loss: 0.003905, tar: 0.000037 
l0: 0.000026, l1: 0.000026, l2: 0.000054, l3: 0.000219, l4: 0.000532, l5: 0.001141, l6: 0.001877

[epoch: 880/1000, batch:   812/ 1052, ite: 231380] train loss: 0.003904, tar: 0.000037 
l0: 0.000016, l1: 0.000016, l2: 0.000070, l3: 0.000278, l4: 0.000561, l5: 0.001356, l6: 0.001907

[epoch: 880/1000, batch:   892/ 1052, ite: 231400] train loss: 0.003904, tar: 0.000037 
l0: 0.000021, l1: 0.000018, l2: 0.000073, l3: 0.000177, l4: 0.000540, l5: 0.001154, l6: 0.002922

[epoch: 880/1000, batch:   972/ 1052, ite: 231420] train loss: 0.003904, tar: 0.000037 
l0: 0.000006, l1: 0.000007, l2: 0.000034, l3: 0.000150, l4: 0.000528, l5: 0.001315, l6: 0.002637

[epoch: 880/1000, batch:  1052/ 1052, ite: 231440] train loss: 0.003904, tar: 0.000037 
[Epoch 880/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000013, l1: 0.000012, l2: 0.000034, l3: 0.000134, l4: 0.000389, l5: 0.001479, l6: 0.001423

[epoch: 881/1000, batch:    80/ 1052, ite: 231460] train loss: 0.004029, tar: 0.000022 
l0: 0.000018, l1: 0.000020, l2: 0.000048, l3: 0.000157, l4: 0.000524, l5: 0.001211, l6: 0.002548

[epoch: 881/1000, batch:   160/ 1052, ite: 231480] train loss: 0.003951, tar: 0.000019 
l0: 0.000006, l1: 0.000005, l2: 0.000043, l3: 0.000156, l4: 0.000358, l5: 0.000544, l6: 0.001472

[epoch: 881/1000, batch:   240/ 1052, ite: 231500] train loss: 0.004011, tar: 0.000017 
l0: 0.000010, l1: 0.000010, l2: 0.000036, l3: 0.000186, l4: 0.000280, l5: 0.000652, l6: 0.001986

[epoch: 881/1000, batch:   320/ 1052, ite: 231520] train loss: 0.003926, tar: 0.000016 
l0: 0.000014, l1: 0.000017, l2: 0.000051, l3: 0.000107, l4: 0.000329, l5: 0.001129, l6: 0.002035

[epoch: 881/1000, batch:   400/ 1052, ite: 231540] train loss: 0.003876, tar: 0.000015 
l0: 0.000003, l1: 0.000003, l2: 0.000016, l3: 0.000095, l4: 0.000462, l5: 0.000971, l6: 0.001642

[epoch: 881/1000, batch:   480/ 1052, ite: 231560] train loss: 0.003854, tar: 0.000015 
l0: 0.000035, l1: 0.000037, l2: 0.000116, l3: 0.000245, l4: 0.000492, l5: 0.001089, l6: 0.004095

[epoch: 881/1000, batch:   560/ 1052, ite: 231580] train loss: 0.003870, tar: 0.000016 
l0: 0.000002, l1: 0.000004, l2: 0.000030, l3: 0.000116, l4: 0.000505, l5: 0.001309, l6: 0.001916

[epoch: 881/1000, batch:   640/ 1052, ite: 231600] train loss: 0.003855, tar: 0.000016 
l0: 0.000016, l1: 0.000017, l2: 0.000043, l3: 0.000234, l4: 0.000603, l5: 0.000859, l6: 0.002933

[epoch: 881/1000, batch:   720/ 1052, ite: 231620] train loss: 0.003852, tar: 0.000017 
l0: 0.000010, l1: 0.000011, l2: 0.000046, l3: 0.000255, l4: 0.000546, l5: 0.001320, l6: 0.001716

[epoch: 881/1000, batch:   800/ 1052, ite: 231640] train loss: 0.003803, tar: 0.000017 
l0: 0.000009, l1: 0.000010, l2: 0.000035, l3: 0.000120, l4: 0.000305, l5: 0.001045, l6: 0.001651

[epoch: 881/1000, batch:   880/ 1052, ite: 231660] train loss: 0.003751, tar: 0.000017 
l0: 0.000005, l1: 0.000005, l2: 0.000028, l3: 0.000121, l4: 0.000459, l5: 0.001347, l6: 0.002071

[epoch: 881/1000, batch:   960/ 1052, ite: 231680] train loss: 0.003756, tar: 0.000017 
l0: 0.000015, l1: 0.000014, l2: 0.000035, l3: 0.000151, l4: 0.000740, l5: 0.001172, l6: 0.001841

[epoch: 881/1000, batch:  1040/ 1052, ite: 231700] train loss: 0.003794, tar: 0.000017 
[Epoch 881/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000004, l1: 0.000005, l2: 0.000006, l3: 0.000073, l4: 0.000361, l5: 0.000630, l6: 0.001639

[epoch: 882/1000, batch:    68/ 1052, ite: 231720] train loss: 0.003779, tar: 0.000017 
l0: 0.000001, l1: 0.000001, l2: 0.000013, l3: 0.000145, l4: 0.000420, l5: 0.000952, l6: 0.001993

[epoch: 882/1000, batch:   148/ 1052, ite: 231740] train loss: 0.003801, tar: 0.000017 
l0: 0.000047, l1: 0.000047, l2: 0.000047, l3: 0.000097, l4: 0.000365, l5: 0.000950, l6: 0.001491

[epoch: 882/1000, batch:   228/ 1052, ite: 231760] train loss: 0.003798, tar: 0.000017 
l0: 0.000032, l1: 0.000029, l2: 0.000072, l3: 0.000153, l4: 0.000377, l5: 0.001331, l6: 0.003176

[epoch: 882/1000, batch:   308/ 1052, ite: 231780] train loss: 0.003807, tar: 0.000018 
l0: 0.000021, l1: 0.000020, l2: 0.000091, l3: 0.000268, l4: 0.000698, l5: 0.001001, l6: 0.002579

[epoch: 882/1000, batch:   388/ 1052, ite: 231800] train loss: 0.003830, tar: 0.000018 
l0: 0.000044, l1: 0.000057, l2: 0.000050, l3: 0.000223, l4: 0.000481, l5: 0.001437, l6: 0.001889

[epoch: 882/1000, batch:   468/ 1052, ite: 231820] train loss: 0.003844, tar: 0.000018 
l0: 0.000012, l1: 0.000011, l2: 0.000023, l3: 0.000076, l4: 0.000161, l5: 0.000547, l6: 0.001078

[epoch: 882/1000, batch:   548/ 1052, ite: 231840] train loss: 0.003813, tar: 0.000018 
l0: 0.000025, l1: 0.000028, l2: 0.000054, l3: 0.000147, l4: 0.000563, l5: 0.001158, l6: 0.001784

[epoch: 882/1000, batch:   628/ 1052, ite: 231860] train loss: 0.003833, tar: 0.000018 
l0: 0.000049, l1: 0.000043, l2: 0.000130, l3: 0.000361, l4: 0.000767, l5: 0.001529, l6: 0.004267

[epoch: 882/1000, batch:   708/ 1052, ite: 231880] train loss: 0.003846, tar: 0.000018 
l0: 0.000002, l1: 0.000002, l2: 0.000007, l3: 0.000055, l4: 0.000393, l5: 0.000670, l6: 0.000580

[epoch: 882/1000, batch:   788/ 1052, ite: 231900] train loss: 0.003825, tar: 0.000018 
l0: 0.000002, l1: 0.000002, l2: 0.000010, l3: 0.000130, l4: 0.000339, l5: 0.000706, l6: 0.002388

[epoch: 882/1000, batch:   868/ 1052, ite: 231920] train loss: 0.003810, tar: 0.000017 
l0: 0.000001, l1: 0.000001, l2: 0.000024, l3: 0.000114, l4: 0.000441, l5: 0.000767, l6: 0.001987

[epoch: 882/1000, batch:   948/ 1052, ite: 231940] train loss: 0.003807, tar: 0.000017 
l0: 0.000019, l1: 0.000020, l2: 0.000037, l3: 0.000094, l4: 0.000264, l5: 0.001015, l6: 0.002471

[epoch: 882/1000, batch:  1028/ 1052, ite: 231960] train loss: 0.003802, tar: 0.000017 
[Epoch 882/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000091, l1: 0.000079, l2: 0.000092, l3: 0.000098, l4: 0.000218, l5: 0.000668, l6: 0.000749

[epoch: 883/1000, batch:    56/ 1052, ite: 231980] train loss: 0.003794, tar: 0.000017 
l0: 0.000015, l1: 0.000016, l2: 0.000103, l3: 0.000393, l4: 0.000812, l5: 0.001613, l6: 0.002508

[epoch: 883/1000, batch:   136/ 1052, ite: 232000] train loss: 0.003806, tar: 0.000017 
l0: 0.000012, l1: 0.000013, l2: 0.000042, l3: 0.000207, l4: 0.000997, l5: 0.000979, l6: 0.002426

[epoch: 883/1000, batch:   216/ 1052, ite: 232020] train loss: 0.003820, tar: 0.000017 
l0: 0.000005, l1: 0.000005, l2: 0.000020, l3: 0.000109, l4: 0.000296, l5: 0.000531, l6: 0.001054

[epoch: 883/1000, batch:   296/ 1052, ite: 232040] train loss: 0.003805, tar: 0.000017 
l0: 0.000005, l1: 0.000005, l2: 0.000021, l3: 0.000108, l4: 0.000258, l5: 0.001036, l6: 0.001963

[epoch: 883/1000, batch:   376/ 1052, ite: 232060] train loss: 0.003799, tar: 0.000017 
l0: 0.000033, l1: 0.000035, l2: 0.000041, l3: 0.000096, l4: 0.000276, l5: 0.000806, l6: 0.001346

[epoch: 883/1000, batch:   456/ 1052, ite: 232080] train loss: 0.003808, tar: 0.000017 
l0: 0.000033, l1: 0.000035, l2: 0.000045, l3: 0.000137, l4: 0.000348, l5: 0.000788, l6: 0.001866

[epoch: 883/1000, batch:   536/ 1052, ite: 232100] train loss: 0.003808, tar: 0.000017 
l0: 0.000001, l1: 0.000003, l2: 0.000013, l3: 0.000100, l4: 0.000292, l5: 0.000540, l6: 0.001475

[epoch: 883/1000, batch:   616/ 1052, ite: 232120] train loss: 0.003806, tar: 0.000017 
l0: 0.000056, l1: 0.000056, l2: 0.000084, l3: 0.000233, l4: 0.000608, l5: 0.001389, l6: 0.001764

[epoch: 883/1000, batch:   696/ 1052, ite: 232140] train loss: 0.003801, tar: 0.000017 
l0: 0.000012, l1: 0.000016, l2: 0.000021, l3: 0.000112, l4: 0.000235, l5: 0.000885, l6: 0.001767

[epoch: 883/1000, batch:   776/ 1052, ite: 232160] train loss: 0.003799, tar: 0.000017 
l0: 0.000020, l1: 0.000019, l2: 0.000022, l3: 0.000077, l4: 0.000262, l5: 0.000909, l6: 0.001440

[epoch: 883/1000, batch:   856/ 1052, ite: 232180] train loss: 0.003797, tar: 0.000017 
l0: 0.000006, l1: 0.000005, l2: 0.000046, l3: 0.000185, l4: 0.000274, l5: 0.000643, l6: 0.001621

[epoch: 883/1000, batch:   936/ 1052, ite: 232200] train loss: 0.003802, tar: 0.000017 
l0: 0.000047, l1: 0.000050, l2: 0.000075, l3: 0.000284, l4: 0.000690, l5: 0.001726, l6: 0.002899

[epoch: 883/1000, batch:  1016/ 1052, ite: 232220] train loss: 0.003805, tar: 0.000017 
[Epoch 883/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000012, l1: 0.000014, l2: 0.000029, l3: 0.000158, l4: 0.000541, l5: 0.001052, l6: 0.001505

[epoch: 884/1000, batch:    44/ 1052, ite: 232240] train loss: 0.003806, tar: 0.000017 
l0: 0.000012, l1: 0.000014, l2: 0.000017, l3: 0.000117, l4: 0.000291, l5: 0.000511, l6: 0.000819

[epoch: 884/1000, batch:   124/ 1052, ite: 232260] train loss: 0.003791, tar: 0.000017 
l0: 0.000062, l1: 0.000064, l2: 0.000084, l3: 0.000159, l4: 0.000858, l5: 0.001795, l6: 0.002380

[epoch: 884/1000, batch:   204/ 1052, ite: 232280] train loss: 0.003804, tar: 0.000017 
l0: 0.000020, l1: 0.000018, l2: 0.000049, l3: 0.000143, l4: 0.000294, l5: 0.000483, l6: 0.001700

[epoch: 884/1000, batch:   284/ 1052, ite: 232300] train loss: 0.003802, tar: 0.000017 
l0: 0.000007, l1: 0.000007, l2: 0.000020, l3: 0.000068, l4: 0.000333, l5: 0.001164, l6: 0.001873

[epoch: 884/1000, batch:   364/ 1052, ite: 232320] train loss: 0.003815, tar: 0.000017 
l0: 0.000003, l1: 0.000003, l2: 0.000017, l3: 0.000083, l4: 0.000323, l5: 0.001044, l6: 0.002404

[epoch: 884/1000, batch:   444/ 1052, ite: 232340] train loss: 0.003821, tar: 0.000017 
l0: 0.000002, l1: 0.000002, l2: 0.000036, l3: 0.000168, l4: 0.000606, l5: 0.001639, l6: 0.001880

[epoch: 884/1000, batch:   524/ 1052, ite: 232360] train loss: 0.003818, tar: 0.000017 
l0: 0.000011, l1: 0.000013, l2: 0.000013, l3: 0.000067, l4: 0.000177, l5: 0.000360, l6: 0.000548

[epoch: 884/1000, batch:   604/ 1052, ite: 232380] train loss: 0.003815, tar: 0.000017 
l0: 0.000007, l1: 0.000007, l2: 0.000013, l3: 0.000100, l4: 0.000470, l5: 0.000657, l6: 0.001294

[epoch: 884/1000, batch:   684/ 1052, ite: 232400] train loss: 0.003805, tar: 0.000017 
l0: 0.000017, l1: 0.000017, l2: 0.000069, l3: 0.000243, l4: 0.000853, l5: 0.001068, l6: 0.002160

[epoch: 884/1000, batch:   764/ 1052, ite: 232420] train loss: 0.003808, tar: 0.000017 
l0: 0.000006, l1: 0.000006, l2: 0.000026, l3: 0.000081, l4: 0.000274, l5: 0.000869, l6: 0.002531

[epoch: 884/1000, batch:   844/ 1052, ite: 232440] train loss: 0.003803, tar: 0.000017 
l0: 0.000002, l1: 0.000002, l2: 0.000033, l3: 0.000319, l4: 0.000570, l5: 0.001184, l6: 0.001686

[epoch: 884/1000, batch:   924/ 1052, ite: 232460] train loss: 0.003805, tar: 0.000017 
l0: 0.000003, l1: 0.000003, l2: 0.000031, l3: 0.000325, l4: 0.000692, l5: 0.001607, l6: 0.002402

[epoch: 884/1000, batch:  1004/ 1052, ite: 232480] train loss: 0.003811, tar: 0.000017 
[Epoch 884/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000013, l1: 0.000014, l2: 0.000058, l3: 0.000211, l4: 0.000439, l5: 0.001110, l6: 0.001872

[epoch: 885/1000, batch:    32/ 1052, ite: 232500] train loss: 0.003805, tar: 0.000017 
l0: 0.000022, l1: 0.000021, l2: 0.000040, l3: 0.000199, l4: 0.000281, l5: 0.000994, l6: 0.001340

[epoch: 885/1000, batch:   112/ 1052, ite: 232520] train loss: 0.003804, tar: 0.000017 
l0: 0.000017, l1: 0.000019, l2: 0.000043, l3: 0.000213, l4: 0.000560, l5: 0.001585, l6: 0.002432

[epoch: 885/1000, batch:   192/ 1052, ite: 232540] train loss: 0.003799, tar: 0.000017 
l0: 0.000017, l1: 0.000016, l2: 0.000050, l3: 0.000189, l4: 0.000389, l5: 0.001147, l6: 0.002170

[epoch: 885/1000, batch:   272/ 1052, ite: 232560] train loss: 0.003808, tar: 0.000017 
l0: 0.000011, l1: 0.000010, l2: 0.000073, l3: 0.000287, l4: 0.000733, l5: 0.001340, l6: 0.002381

[epoch: 885/1000, batch:   352/ 1052, ite: 232580] train loss: 0.003805, tar: 0.000017 
l0: 0.000030, l1: 0.000032, l2: 0.000094, l3: 0.000238, l4: 0.000523, l5: 0.001680, l6: 0.003556

[epoch: 885/1000, batch:   432/ 1052, ite: 232600] train loss: 0.003802, tar: 0.000017 
l0: 0.000020, l1: 0.000022, l2: 0.000041, l3: 0.000171, l4: 0.000693, l5: 0.002302, l6: 0.002753

[epoch: 885/1000, batch:   512/ 1052, ite: 232620] train loss: 0.003803, tar: 0.000017 
l0: 0.000019, l1: 0.000017, l2: 0.000055, l3: 0.000192, l4: 0.000510, l5: 0.001507, l6: 0.001677

[epoch: 885/1000, batch:   592/ 1052, ite: 232640] train loss: 0.003809, tar: 0.000017 
l0: 0.000010, l1: 0.000013, l2: 0.000039, l3: 0.000079, l4: 0.000267, l5: 0.001174, l6: 0.001558

[epoch: 885/1000, batch:   672/ 1052, ite: 232660] train loss: 0.003807, tar: 0.000017 
l0: 0.000019, l1: 0.000019, l2: 0.000043, l3: 0.000120, l4: 0.000193, l5: 0.001186, l6: 0.001921

[epoch: 885/1000, batch:   752/ 1052, ite: 232680] train loss: 0.003804, tar: 0.000017 
l0: 0.000016, l1: 0.000018, l2: 0.000037, l3: 0.000297, l4: 0.000699, l5: 0.001646, l6: 0.002370

[epoch: 885/1000, batch:   832/ 1052, ite: 232700] train loss: 0.003802, tar: 0.000017 
l0: 0.000022, l1: 0.000023, l2: 0.000055, l3: 0.000135, l4: 0.000466, l5: 0.001170, l6: 0.002318

[epoch: 885/1000, batch:   912/ 1052, ite: 232720] train loss: 0.003802, tar: 0.000017 
l0: 0.000023, l1: 0.000022, l2: 0.000077, l3: 0.000170, l4: 0.000426, l5: 0.001060, l6: 0.001497

[epoch: 885/1000, batch:   992/ 1052, ite: 232740] train loss: 0.003806, tar: 0.000017 
[Epoch 885/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000007, l1: 0.000007, l2: 0.000052, l3: 0.000118, l4: 0.000338, l5: 0.000929, l6: 0.002108

[epoch: 886/1000, batch:    20/ 1052, ite: 232760] train loss: 0.003797, tar: 0.000017 
l0: 0.000006, l1: 0.000005, l2: 0.000028, l3: 0.000113, l4: 0.000488, l5: 0.000894, l6: 0.001300

[epoch: 886/1000, batch:   100/ 1052, ite: 232780] train loss: 0.003797, tar: 0.000017 
l0: 0.000035, l1: 0.000035, l2: 0.000090, l3: 0.000242, l4: 0.000438, l5: 0.001161, l6: 0.002904

[epoch: 886/1000, batch:   180/ 1052, ite: 232800] train loss: 0.003800, tar: 0.000017 
l0: 0.000027, l1: 0.000027, l2: 0.000061, l3: 0.000131, l4: 0.000356, l5: 0.001268, l6: 0.002919

[epoch: 886/1000, batch:   260/ 1052, ite: 232820] train loss: 0.003799, tar: 0.000017 
l0: 0.000036, l1: 0.000032, l2: 0.000058, l3: 0.000164, l4: 0.000533, l5: 0.001113, l6: 0.001886

[epoch: 886/1000, batch:   340/ 1052, ite: 232840] train loss: 0.003797, tar: 0.000018 
l0: 0.000012, l1: 0.000012, l2: 0.000036, l3: 0.000132, l4: 0.000471, l5: 0.000796, l6: 0.001522

[epoch: 886/1000, batch:   420/ 1052, ite: 232860] train loss: 0.003793, tar: 0.000017 
l0: 0.000040, l1: 0.000047, l2: 0.000042, l3: 0.000127, l4: 0.000665, l5: 0.001073, l6: 0.002008

[epoch: 886/1000, batch:   500/ 1052, ite: 232880] train loss: 0.003787, tar: 0.000017 
l0: 0.000003, l1: 0.000004, l2: 0.000013, l3: 0.000069, l4: 0.000221, l5: 0.000708, l6: 0.000871

[epoch: 886/1000, batch:   580/ 1052, ite: 232900] train loss: 0.003790, tar: 0.000017 
l0: 0.000017, l1: 0.000016, l2: 0.000054, l3: 0.000149, l4: 0.000403, l5: 0.000485, l6: 0.002010

[epoch: 886/1000, batch:   660/ 1052, ite: 232920] train loss: 0.003792, tar: 0.000017 
l0: 0.000023, l1: 0.000023, l2: 0.000072, l3: 0.000203, l4: 0.000498, l5: 0.000896, l6: 0.002690

[epoch: 886/1000, batch:   740/ 1052, ite: 232940] train loss: 0.003794, tar: 0.000017 
l0: 0.000011, l1: 0.000012, l2: 0.000044, l3: 0.000139, l4: 0.000344, l5: 0.000698, l6: 0.001271

[epoch: 886/1000, batch:   820/ 1052, ite: 232960] train loss: 0.003797, tar: 0.000017 
l0: 0.000009, l1: 0.000007, l2: 0.000059, l3: 0.000127, l4: 0.000223, l5: 0.001069, l6: 0.002541

[epoch: 886/1000, batch:   900/ 1052, ite: 232980] train loss: 0.003801, tar: 0.000017 
l0: 0.000006, l1: 0.000005, l2: 0.000044, l3: 0.000169, l4: 0.000505, l5: 0.001178, l6: 0.002085

[epoch: 886/1000, batch:   980/ 1052, ite: 233000] train loss: 0.003798, tar: 0.000017 
[Epoch 886/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000002, l1: 0.000002, l2: 0.000035, l3: 0.000266, l4: 0.000554, l5: 0.001199, l6: 0.001874

[epoch: 887/1000, batch:     8/ 1052, ite: 233020] train loss: 0.003796, tar: 0.000017 
l0: 0.000098, l1: 0.000105, l2: 0.000119, l3: 0.000254, l4: 0.000797, l5: 0.001132, l6: 0.002187

[epoch: 887/1000, batch:    88/ 1052, ite: 233040] train loss: 0.003798, tar: 0.000017 
l0: 0.000029, l1: 0.000029, l2: 0.000061, l3: 0.000149, l4: 0.000412, l5: 0.001084, l6: 0.001842

[epoch: 887/1000, batch:   168/ 1052, ite: 233060] train loss: 0.003798, tar: 0.000017 
l0: 0.000062, l1: 0.000063, l2: 0.000073, l3: 0.000118, l4: 0.000488, l5: 0.001369, l6: 0.002661

[epoch: 887/1000, batch:   248/ 1052, ite: 233080] train loss: 0.003797, tar: 0.000018 
l0: 0.000013, l1: 0.000013, l2: 0.000056, l3: 0.000175, l4: 0.000446, l5: 0.001416, l6: 0.001878

[epoch: 887/1000, batch:   328/ 1052, ite: 233100] train loss: 0.003798, tar: 0.000018 
l0: 0.000010, l1: 0.000012, l2: 0.000050, l3: 0.000163, l4: 0.000331, l5: 0.000920, l6: 0.002039

[epoch: 887/1000, batch:   408/ 1052, ite: 233120] train loss: 0.003798, tar: 0.000018 
l0: 0.000003, l1: 0.000003, l2: 0.000040, l3: 0.000166, l4: 0.000342, l5: 0.000665, l6: 0.001832

[epoch: 887/1000, batch:   488/ 1052, ite: 233140] train loss: 0.003807, tar: 0.000018 
l0: 0.000030, l1: 0.000030, l2: 0.000113, l3: 0.000376, l4: 0.000614, l5: 0.001273, l6: 0.004127

[epoch: 887/1000, batch:   568/ 1052, ite: 233160] train loss: 0.003801, tar: 0.000018 
l0: 0.000000, l1: 0.000001, l2: 0.000009, l3: 0.000059, l4: 0.000225, l5: 0.000794, l6: 0.001211

[epoch: 887/1000, batch:   648/ 1052, ite: 233180] train loss: 0.003800, tar: 0.000018 
l0: 0.000007, l1: 0.000006, l2: 0.000038, l3: 0.000147, l4: 0.000256, l5: 0.000743, l6: 0.001307

[epoch: 887/1000, batch:   728/ 1052, ite: 233200] train loss: 0.003795, tar: 0.000017 
l0: 0.000005, l1: 0.000005, l2: 0.000094, l3: 0.000475, l4: 0.001058, l5: 0.001802, l6: 0.003679

[epoch: 887/1000, batch:   808/ 1052, ite: 233220] train loss: 0.003795, tar: 0.000017 
l0: 0.000025, l1: 0.000028, l2: 0.000060, l3: 0.000252, l4: 0.000794, l5: 0.002210, l6: 0.003512

[epoch: 887/1000, batch:   888/ 1052, ite: 233240] train loss: 0.003800, tar: 0.000017 
l0: 0.000002, l1: 0.000002, l2: 0.000012, l3: 0.000052, l4: 0.000165, l5: 0.000862, l6: 0.001126

[epoch: 887/1000, batch:   968/ 1052, ite: 233260] train loss: 0.003797, tar: 0.000017 
l0: 0.000002, l1: 0.000003, l2: 0.000009, l3: 0.000068, l4: 0.000198, l5: 0.000673, l6: 0.001071

[epoch: 887/1000, batch:  1048/ 1052, ite: 233280] train loss: 0.003791, tar: 0.000017 
[Epoch 887/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000024, l1: 0.000027, l2: 0.000048, l3: 0.000201, l4: 0.000588, l5: 0.001322, l6: 0.002603

[epoch: 888/1000, batch:    76/ 1052, ite: 233300] train loss: 0.003794, tar: 0.000017 
l0: 0.000033, l1: 0.000033, l2: 0.000138, l3: 0.000283, l4: 0.000461, l5: 0.001446, l6: 0.002388

[epoch: 888/1000, batch:   156/ 1052, ite: 233320] train loss: 0.003790, tar: 0.000018 
l0: 0.000019, l1: 0.000023, l2: 0.000034, l3: 0.000106, l4: 0.000509, l5: 0.001175, l6: 0.001631

[epoch: 888/1000, batch:   236/ 1052, ite: 233340] train loss: 0.003792, tar: 0.000018 
l0: 0.000004, l1: 0.000005, l2: 0.000029, l3: 0.000064, l4: 0.000319, l5: 0.000736, l6: 0.001970

[epoch: 888/1000, batch:   316/ 1052, ite: 233360] train loss: 0.003796, tar: 0.000018 
l0: 0.000006, l1: 0.000008, l2: 0.000025, l3: 0.000112, l4: 0.000308, l5: 0.000960, l6: 0.001835

[epoch: 888/1000, batch:   396/ 1052, ite: 233380] train loss: 0.003796, tar: 0.000018 
l0: 0.000002, l1: 0.000002, l2: 0.000021, l3: 0.000145, l4: 0.000506, l5: 0.000834, l6: 0.001841

[epoch: 888/1000, batch:   476/ 1052, ite: 233400] train loss: 0.003796, tar: 0.000018 
l0: 0.000001, l1: 0.000002, l2: 0.000005, l3: 0.000074, l4: 0.000261, l5: 0.000654, l6: 0.000862

[epoch: 888/1000, batch:   556/ 1052, ite: 233420] train loss: 0.003795, tar: 0.000018 
l0: 0.000004, l1: 0.000004, l2: 0.000055, l3: 0.000236, l4: 0.000594, l5: 0.001583, l6: 0.002822

[epoch: 888/1000, batch:   636/ 1052, ite: 233440] train loss: 0.003794, tar: 0.000018 
l0: 0.000012, l1: 0.000013, l2: 0.000062, l3: 0.000148, l4: 0.000377, l5: 0.000959, l6: 0.003236

[epoch: 888/1000, batch:   716/ 1052, ite: 233460] train loss: 0.003798, tar: 0.000018 
l0: 0.000007, l1: 0.000008, l2: 0.000015, l3: 0.000055, l4: 0.000284, l5: 0.001066, l6: 0.000945

[epoch: 888/1000, batch:   796/ 1052, ite: 233480] train loss: 0.003790, tar: 0.000018 
l0: 0.000007, l1: 0.000009, l2: 0.000076, l3: 0.000203, l4: 0.000786, l5: 0.001086, l6: 0.002250

[epoch: 888/1000, batch:   876/ 1052, ite: 233500] train loss: 0.003795, tar: 0.000018 
l0: 0.000016, l1: 0.000016, l2: 0.000023, l3: 0.000085, l4: 0.000387, l5: 0.000849, l6: 0.001741

[epoch: 888/1000, batch:   956/ 1052, ite: 233520] train loss: 0.003794, tar: 0.000018 
l0: 0.000072, l1: 0.000076, l2: 0.000063, l3: 0.000129, l4: 0.000366, l5: 0.000964, l6: 0.001032

[epoch: 888/1000, batch:  1036/ 1052, ite: 233540] train loss: 0.003792, tar: 0.000018 
[Epoch 888/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000044, l1: 0.000053, l2: 0.000070, l3: 0.000122, l4: 0.000359, l5: 0.000721, l6: 0.001288

[epoch: 889/1000, batch:    64/ 1052, ite: 233560] train loss: 0.003789, tar: 0.000018 
l0: 0.000032, l1: 0.000030, l2: 0.000044, l3: 0.000098, l4: 0.000241, l5: 0.000666, l6: 0.001386

[epoch: 889/1000, batch:   144/ 1052, ite: 233580] train loss: 0.003788, tar: 0.000018 
l0: 0.000036, l1: 0.000037, l2: 0.000110, l3: 0.000218, l4: 0.000456, l5: 0.000826, l6: 0.002008

[epoch: 889/1000, batch:   224/ 1052, ite: 233600] train loss: 0.003792, tar: 0.000018 
l0: 0.000002, l1: 0.000002, l2: 0.000008, l3: 0.000023, l4: 0.000179, l5: 0.000505, l6: 0.000786

[epoch: 889/1000, batch:   304/ 1052, ite: 233620] train loss: 0.003798, tar: 0.000018 
l0: 0.000033, l1: 0.000025, l2: 0.000073, l3: 0.000183, l4: 0.000393, l5: 0.001046, l6: 0.001415

[epoch: 889/1000, batch:   384/ 1052, ite: 233640] train loss: 0.003798, tar: 0.000018 
l0: 0.000014, l1: 0.000015, l2: 0.000027, l3: 0.000155, l4: 0.000318, l5: 0.000750, l6: 0.001332

[epoch: 889/1000, batch:   464/ 1052, ite: 233660] train loss: 0.003802, tar: 0.000018 
l0: 0.000001, l1: 0.000001, l2: 0.000010, l3: 0.000065, l4: 0.000206, l5: 0.001014, l6: 0.001687

[epoch: 889/1000, batch:   544/ 1052, ite: 233680] train loss: 0.003799, tar: 0.000018 
l0: 0.000007, l1: 0.000006, l2: 0.000041, l3: 0.000172, l4: 0.000613, l5: 0.001188, l6: 0.001592

[epoch: 889/1000, batch:   624/ 1052, ite: 233700] train loss: 0.003795, tar: 0.000018 
l0: 0.000016, l1: 0.000017, l2: 0.000075, l3: 0.000173, l4: 0.000363, l5: 0.001274, l6: 0.002087

[epoch: 889/1000, batch:   704/ 1052, ite: 233720] train loss: 0.003788, tar: 0.000018 
l0: 0.000016, l1: 0.000017, l2: 0.000091, l3: 0.000189, l4: 0.000378, l5: 0.001258, l6: 0.003861

[epoch: 889/1000, batch:   784/ 1052, ite: 233740] train loss: 0.003789, tar: 0.000018 
l0: 0.000004, l1: 0.000005, l2: 0.000017, l3: 0.000126, l4: 0.000339, l5: 0.000700, l6: 0.001209

[epoch: 889/1000, batch:   864/ 1052, ite: 233760] train loss: 0.003788, tar: 0.000018 
l0: 0.000039, l1: 0.000038, l2: 0.000063, l3: 0.000213, l4: 0.000585, l5: 0.001313, l6: 0.002579

[epoch: 889/1000, batch:   944/ 1052, ite: 233780] train loss: 0.003792, tar: 0.000018 
l0: 0.000039, l1: 0.000038, l2: 0.000069, l3: 0.000254, l4: 0.000545, l5: 0.001412, l6: 0.003147

[epoch: 889/1000, batch:  1024/ 1052, ite: 233800] train loss: 0.003794, tar: 0.000018 
[Epoch 889/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000021, l1: 0.000023, l2: 0.000032, l3: 0.000129, l4: 0.000270, l5: 0.001675, l6: 0.002344

[epoch: 890/1000, batch:    52/ 1052, ite: 233820] train loss: 0.003795, tar: 0.000018 
l0: 0.000005, l1: 0.000005, l2: 0.000042, l3: 0.000293, l4: 0.000748, l5: 0.001336, l6: 0.002659

[epoch: 890/1000, batch:   132/ 1052, ite: 233840] train loss: 0.003799, tar: 0.000018 
l0: 0.000001, l1: 0.000001, l2: 0.000009, l3: 0.000067, l4: 0.000195, l5: 0.001007, l6: 0.001178

[epoch: 890/1000, batch:   212/ 1052, ite: 233860] train loss: 0.003795, tar: 0.000018 
l0: 0.000019, l1: 0.000019, l2: 0.000054, l3: 0.000239, l4: 0.000529, l5: 0.001542, l6: 0.003102

[epoch: 890/1000, batch:   292/ 1052, ite: 233880] train loss: 0.003793, tar: 0.000018 
l0: 0.000006, l1: 0.000007, l2: 0.000039, l3: 0.000177, l4: 0.000556, l5: 0.001182, l6: 0.001843

[epoch: 890/1000, batch:   372/ 1052, ite: 233900] train loss: 0.003795, tar: 0.000018 
l0: 0.000006, l1: 0.000005, l2: 0.000024, l3: 0.000073, l4: 0.000342, l5: 0.000576, l6: 0.001291

[epoch: 890/1000, batch:   452/ 1052, ite: 233920] train loss: 0.003791, tar: 0.000018 
l0: 0.000025, l1: 0.000024, l2: 0.000040, l3: 0.000112, l4: 0.000298, l5: 0.000830, l6: 0.001007

[epoch: 890/1000, batch:   532/ 1052, ite: 233940] train loss: 0.003791, tar: 0.000018 
l0: 0.000027, l1: 0.000027, l2: 0.000071, l3: 0.000215, l4: 0.000384, l5: 0.000971, l6: 0.001651

[epoch: 890/1000, batch:   612/ 1052, ite: 233960] train loss: 0.003795, tar: 0.000018 
l0: 0.000042, l1: 0.000043, l2: 0.000071, l3: 0.000174, l4: 0.000488, l5: 0.001288, l6: 0.002161

[epoch: 890/1000, batch:   692/ 1052, ite: 233980] train loss: 0.003796, tar: 0.000018 
l0: 0.000021, l1: 0.000018, l2: 0.000040, l3: 0.000147, l4: 0.000404, l5: 0.001255, l6: 0.002341

[epoch: 890/1000, batch:   772/ 1052, ite: 234000] train loss: 0.003796, tar: 0.000018 
l0: 0.000006, l1: 0.000008, l2: 0.000070, l3: 0.000338, l4: 0.000736, l5: 0.001727, l6: 0.004347

[epoch: 890/1000, batch:   852/ 1052, ite: 234020] train loss: 0.003796, tar: 0.000018 
l0: 0.000014, l1: 0.000016, l2: 0.000043, l3: 0.000170, l4: 0.000545, l5: 0.000923, l6: 0.002365

[epoch: 890/1000, batch:   932/ 1052, ite: 234040] train loss: 0.003797, tar: 0.000018 
l0: 0.000010, l1: 0.000009, l2: 0.000034, l3: 0.000128, l4: 0.000441, l5: 0.000603, l6: 0.001284

[epoch: 890/1000, batch:  1012/ 1052, ite: 234060] train loss: 0.003795, tar: 0.000018 
[Epoch 890/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000009, l1: 0.000011, l2: 0.000037, l3: 0.000081, l4: 0.000615, l5: 0.000637, l6: 0.001523

[epoch: 891/1000, batch:    40/ 1052, ite: 234080] train loss: 0.003799, tar: 0.000018 
l0: 0.000043, l1: 0.000042, l2: 0.000046, l3: 0.000067, l4: 0.000414, l5: 0.000611, l6: 0.001496

[epoch: 891/1000, batch:   120/ 1052, ite: 234100] train loss: 0.003797, tar: 0.000018 
l0: 0.000006, l1: 0.000006, l2: 0.000078, l3: 0.000163, l4: 0.000432, l5: 0.000895, l6: 0.002079

[epoch: 891/1000, batch:   200/ 1052, ite: 234120] train loss: 0.003796, tar: 0.000018 
l0: 0.000016, l1: 0.000014, l2: 0.000037, l3: 0.000151, l4: 0.000473, l5: 0.001025, l6: 0.001909

[epoch: 891/1000, batch:   280/ 1052, ite: 234140] train loss: 0.003798, tar: 0.000018 
l0: 0.000042, l1: 0.000045, l2: 0.000154, l3: 0.000364, l4: 0.000940, l5: 0.001369, l6: 0.002652

[epoch: 891/1000, batch:   360/ 1052, ite: 234160] train loss: 0.003801, tar: 0.000019 
l0: 0.000003, l1: 0.000003, l2: 0.000020, l3: 0.000069, l4: 0.000147, l5: 0.000583, l6: 0.001153

[epoch: 891/1000, batch:   440/ 1052, ite: 234180] train loss: 0.003802, tar: 0.000019 
l0: 0.000017, l1: 0.000017, l2: 0.000043, l3: 0.000194, l4: 0.000398, l5: 0.000662, l6: 0.001147

[epoch: 891/1000, batch:   520/ 1052, ite: 234200] train loss: 0.003802, tar: 0.000019 
l0: 0.000004, l1: 0.000004, l2: 0.000013, l3: 0.000058, l4: 0.000160, l5: 0.000693, l6: 0.001175

[epoch: 891/1000, batch:   600/ 1052, ite: 234220] train loss: 0.003801, tar: 0.000019 
l0: 0.000016, l1: 0.000016, l2: 0.000027, l3: 0.000063, l4: 0.000239, l5: 0.000830, l6: 0.000768

[epoch: 891/1000, batch:   680/ 1052, ite: 234240] train loss: 0.003800, tar: 0.000019 
l0: 0.000017, l1: 0.000015, l2: 0.000053, l3: 0.000176, l4: 0.000399, l5: 0.001108, l6: 0.001441

[epoch: 891/1000, batch:   760/ 1052, ite: 234260] train loss: 0.003799, tar: 0.000019 
l0: 0.000015, l1: 0.000014, l2: 0.000050, l3: 0.000099, l4: 0.000312, l5: 0.000426, l6: 0.000862

[epoch: 891/1000, batch:   840/ 1052, ite: 234280] train loss: 0.003801, tar: 0.000019 
l0: 0.000013, l1: 0.000010, l2: 0.000039, l3: 0.000079, l4: 0.000219, l5: 0.000755, l6: 0.000933

[epoch: 891/1000, batch:   920/ 1052, ite: 234300] train loss: 0.003804, tar: 0.000019 
l0: 0.000021, l1: 0.000020, l2: 0.000049, l3: 0.000220, l4: 0.000399, l5: 0.000956, l6: 0.001234

[epoch: 891/1000, batch:  1000/ 1052, ite: 234320] train loss: 0.003804, tar: 0.000019 
[Epoch 891/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000005, l1: 0.000004, l2: 0.000013, l3: 0.000078, l4: 0.000345, l5: 0.000928, l6: 0.001760

[epoch: 892/1000, batch:    28/ 1052, ite: 234340] train loss: 0.003803, tar: 0.000019 
l0: 0.000076, l1: 0.000077, l2: 0.000109, l3: 0.000308, l4: 0.000864, l5: 0.001712, l6: 0.003599

[epoch: 892/1000, batch:   108/ 1052, ite: 234360] train loss: 0.003802, tar: 0.000019 
l0: 0.000011, l1: 0.000011, l2: 0.000028, l3: 0.000126, l4: 0.000294, l5: 0.000819, l6: 0.001395

[epoch: 892/1000, batch:   188/ 1052, ite: 234380] train loss: 0.003800, tar: 0.000019 
l0: 0.000014, l1: 0.000017, l2: 0.000009, l3: 0.000061, l4: 0.000133, l5: 0.000460, l6: 0.000740

[epoch: 892/1000, batch:   268/ 1052, ite: 234400] train loss: 0.003799, tar: 0.000019 
l0: 0.000007, l1: 0.000007, l2: 0.000023, l3: 0.000086, l4: 0.000266, l5: 0.000690, l6: 0.001607

[epoch: 892/1000, batch:   348/ 1052, ite: 234420] train loss: 0.003801, tar: 0.000019 
l0: 0.000034, l1: 0.000033, l2: 0.000066, l3: 0.000202, l4: 0.000510, l5: 0.001453, l6: 0.002399

[epoch: 892/1000, batch:   428/ 1052, ite: 234440] train loss: 0.003800, tar: 0.000019 
l0: 0.000003, l1: 0.000003, l2: 0.000037, l3: 0.000130, l4: 0.000429, l5: 0.000906, l6: 0.001793

[epoch: 892/1000, batch:   508/ 1052, ite: 234460] train loss: 0.003802, tar: 0.000019 
l0: 0.000036, l1: 0.000040, l2: 0.000050, l3: 0.000187, l4: 0.000566, l5: 0.001657, l6: 0.003398

[epoch: 892/1000, batch:   588/ 1052, ite: 234480] train loss: 0.003804, tar: 0.000019 
l0: 0.000008, l1: 0.000007, l2: 0.000021, l3: 0.000135, l4: 0.000287, l5: 0.000606, l6: 0.001448

[epoch: 892/1000, batch:   668/ 1052, ite: 234500] train loss: 0.003800, tar: 0.000019 
l0: 0.000040, l1: 0.000036, l2: 0.000105, l3: 0.000313, l4: 0.001279, l5: 0.002651, l6: 0.003544

[epoch: 892/1000, batch:   748/ 1052, ite: 234520] train loss: 0.003800, tar: 0.000019 
l0: 0.000036, l1: 0.000037, l2: 0.000053, l3: 0.000299, l4: 0.000669, l5: 0.001524, l6: 0.002018

[epoch: 892/1000, batch:   828/ 1052, ite: 234540] train loss: 0.003800, tar: 0.000019 
l0: 0.000008, l1: 0.000008, l2: 0.000032, l3: 0.000140, l4: 0.000290, l5: 0.000749, l6: 0.001630

[epoch: 892/1000, batch:   908/ 1052, ite: 234560] train loss: 0.003802, tar: 0.000019 
l0: 0.000005, l1: 0.000004, l2: 0.000041, l3: 0.000188, l4: 0.000413, l5: 0.001217, l6: 0.001507

[epoch: 892/1000, batch:   988/ 1052, ite: 234580] train loss: 0.003801, tar: 0.000019 
[Epoch 892/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000003, l1: 0.000004, l2: 0.000021, l3: 0.000165, l4: 0.000503, l5: 0.001331, l6: 0.001996

[epoch: 893/1000, batch:    16/ 1052, ite: 234600] train loss: 0.003801, tar: 0.000019 
l0: 0.000025, l1: 0.000026, l2: 0.000098, l3: 0.000208, l4: 0.000456, l5: 0.001630, l6: 0.003107

[epoch: 893/1000, batch:    96/ 1052, ite: 234620] train loss: 0.003802, tar: 0.000019 
l0: 0.000031, l1: 0.000035, l2: 0.000070, l3: 0.000212, l4: 0.000362, l5: 0.000977, l6: 0.001537

[epoch: 893/1000, batch:   176/ 1052, ite: 234640] train loss: 0.003800, tar: 0.000019 
l0: 0.000001, l1: 0.000001, l2: 0.000027, l3: 0.000099, l4: 0.000231, l5: 0.000745, l6: 0.001595

[epoch: 893/1000, batch:   256/ 1052, ite: 234660] train loss: 0.003803, tar: 0.000019 
l0: 0.000028, l1: 0.000028, l2: 0.000076, l3: 0.000178, l4: 0.000287, l5: 0.000826, l6: 0.001717

[epoch: 893/1000, batch:   336/ 1052, ite: 234680] train loss: 0.003802, tar: 0.000019 
l0: 0.000011, l1: 0.000009, l2: 0.000034, l3: 0.000082, l4: 0.000296, l5: 0.000731, l6: 0.001426

[epoch: 893/1000, batch:   416/ 1052, ite: 234700] train loss: 0.003802, tar: 0.000019 
l0: 0.000044, l1: 0.000041, l2: 0.000099, l3: 0.000166, l4: 0.000366, l5: 0.001158, l6: 0.001839

[epoch: 893/1000, batch:   496/ 1052, ite: 234720] train loss: 0.003804, tar: 0.000019 
l0: 0.000006, l1: 0.000007, l2: 0.000023, l3: 0.000151, l4: 0.000473, l5: 0.001049, l6: 0.002879

[epoch: 893/1000, batch:   576/ 1052, ite: 234740] train loss: 0.003803, tar: 0.000019 
l0: 0.000004, l1: 0.000005, l2: 0.000020, l3: 0.000128, l4: 0.000276, l5: 0.000771, l6: 0.001445

[epoch: 893/1000, batch:   656/ 1052, ite: 234760] train loss: 0.003804, tar: 0.000019 
l0: 0.000009, l1: 0.000012, l2: 0.000030, l3: 0.000073, l4: 0.000263, l5: 0.000524, l6: 0.000923

[epoch: 893/1000, batch:   736/ 1052, ite: 234780] train loss: 0.003800, tar: 0.000019 
l0: 0.000035, l1: 0.000029, l2: 0.000127, l3: 0.000293, l4: 0.000513, l5: 0.001028, l6: 0.001438

[epoch: 893/1000, batch:   816/ 1052, ite: 234800] train loss: 0.003801, tar: 0.000019 
l0: 0.000012, l1: 0.000013, l2: 0.000030, l3: 0.000131, l4: 0.000157, l5: 0.000898, l6: 0.001313

[epoch: 893/1000, batch:   896/ 1052, ite: 234820] train loss: 0.003800, tar: 0.000019 
l0: 0.000013, l1: 0.000012, l2: 0.000035, l3: 0.000080, l4: 0.000382, l5: 0.001044, l6: 0.001647

[epoch: 893/1000, batch:   976/ 1052, ite: 234840] train loss: 0.003803, tar: 0.000019 
[Epoch 893/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000027, l1: 0.000028, l2: 0.000030, l3: 0.000041, l4: 0.000447, l5: 0.001090, l6: 0.001282

[epoch: 894/1000, batch:     4/ 1052, ite: 234860] train loss: 0.003801, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000009, l3: 0.000058, l4: 0.000491, l5: 0.001043, l6: 0.001623

[epoch: 894/1000, batch:    84/ 1052, ite: 234880] train loss: 0.003800, tar: 0.000019 
l0: 0.000009, l1: 0.000010, l2: 0.000042, l3: 0.000150, l4: 0.000317, l5: 0.001042, l6: 0.001394

[epoch: 894/1000, batch:   164/ 1052, ite: 234900] train loss: 0.003796, tar: 0.000019 
l0: 0.000031, l1: 0.000029, l2: 0.000042, l3: 0.000121, l4: 0.000427, l5: 0.000734, l6: 0.000960

[epoch: 894/1000, batch:   244/ 1052, ite: 234920] train loss: 0.003798, tar: 0.000019 
l0: 0.000034, l1: 0.000035, l2: 0.000073, l3: 0.000199, l4: 0.000581, l5: 0.001064, l6: 0.002376

[epoch: 894/1000, batch:   324/ 1052, ite: 234940] train loss: 0.003799, tar: 0.000019 
l0: 0.000016, l1: 0.000017, l2: 0.000043, l3: 0.000188, l4: 0.000469, l5: 0.000682, l6: 0.002500

[epoch: 894/1000, batch:   404/ 1052, ite: 234960] train loss: 0.003803, tar: 0.000019 
l0: 0.000001, l1: 0.000001, l2: 0.000020, l3: 0.000088, l4: 0.000266, l5: 0.000689, l6: 0.001008

[epoch: 894/1000, batch:   484/ 1052, ite: 234980] train loss: 0.003803, tar: 0.000019 
l0: 0.000042, l1: 0.000044, l2: 0.000096, l3: 0.000299, l4: 0.000759, l5: 0.001362, l6: 0.002259

[epoch: 894/1000, batch:   564/ 1052, ite: 235000] train loss: 0.003799, tar: 0.000019 
l0: 0.000005, l1: 0.000005, l2: 0.000010, l3: 0.000077, l4: 0.000251, l5: 0.000918, l6: 0.001195

[epoch: 894/1000, batch:   644/ 1052, ite: 235020] train loss: 0.003801, tar: 0.000019 
l0: 0.000003, l1: 0.000003, l2: 0.000037, l3: 0.000115, l4: 0.000440, l5: 0.001069, l6: 0.001892

[epoch: 894/1000, batch:   724/ 1052, ite: 235040] train loss: 0.003799, tar: 0.000019 
l0: 0.000075, l1: 0.000069, l2: 0.000194, l3: 0.000430, l4: 0.000920, l5: 0.001516, l6: 0.002721

[epoch: 894/1000, batch:   804/ 1052, ite: 235060] train loss: 0.003798, tar: 0.000019 
l0: 0.000016, l1: 0.000016, l2: 0.000035, l3: 0.000091, l4: 0.000206, l5: 0.000634, l6: 0.001474

[epoch: 894/1000, batch:   884/ 1052, ite: 235080] train loss: 0.003799, tar: 0.000019 
l0: 0.000061, l1: 0.000061, l2: 0.000120, l3: 0.000269, l4: 0.000556, l5: 0.001642, l6: 0.003908

[epoch: 894/1000, batch:   964/ 1052, ite: 235100] train loss: 0.003802, tar: 0.000019 
l0: 0.000005, l1: 0.000004, l2: 0.000042, l3: 0.000124, l4: 0.000399, l5: 0.000925, l6: 0.001161

[epoch: 894/1000, batch:  1044/ 1052, ite: 235120] train loss: 0.003801, tar: 0.000019 
[Epoch 894/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000005, l1: 0.000004, l2: 0.000051, l3: 0.000188, l4: 0.000364, l5: 0.000796, l6: 0.001174

[epoch: 895/1000, batch:    72/ 1052, ite: 235140] train loss: 0.003799, tar: 0.000019 
l0: 0.000044, l1: 0.000042, l2: 0.000100, l3: 0.000269, l4: 0.000492, l5: 0.001377, l6: 0.001630

[epoch: 895/1000, batch:   152/ 1052, ite: 235160] train loss: 0.003799, tar: 0.000019 
l0: 0.000026, l1: 0.000026, l2: 0.000048, l3: 0.000147, l4: 0.000438, l5: 0.001156, l6: 0.002146

[epoch: 895/1000, batch:   232/ 1052, ite: 235180] train loss: 0.003798, tar: 0.000019 
l0: 0.000009, l1: 0.000009, l2: 0.000024, l3: 0.000169, l4: 0.000475, l5: 0.001135, l6: 0.001972

[epoch: 895/1000, batch:   312/ 1052, ite: 235200] train loss: 0.003797, tar: 0.000019 
l0: 0.000010, l1: 0.000009, l2: 0.000117, l3: 0.000387, l4: 0.000858, l5: 0.002448, l6: 0.003447

[epoch: 895/1000, batch:   392/ 1052, ite: 235220] train loss: 0.003801, tar: 0.000019 
l0: 0.000002, l1: 0.000003, l2: 0.000014, l3: 0.000090, l4: 0.000401, l5: 0.001044, l6: 0.001548

[epoch: 895/1000, batch:   472/ 1052, ite: 235240] train loss: 0.003801, tar: 0.000019 
l0: 0.000009, l1: 0.000008, l2: 0.000069, l3: 0.000134, l4: 0.000400, l5: 0.000845, l6: 0.001479

[epoch: 895/1000, batch:   552/ 1052, ite: 235260] train loss: 0.003799, tar: 0.000019 
l0: 0.000006, l1: 0.000004, l2: 0.000019, l3: 0.000035, l4: 0.000239, l5: 0.000252, l6: 0.001228

[epoch: 895/1000, batch:   632/ 1052, ite: 235280] train loss: 0.003800, tar: 0.000019 
l0: 0.000001, l1: 0.000002, l2: 0.000004, l3: 0.000059, l4: 0.000502, l5: 0.000946, l6: 0.001788

[epoch: 895/1000, batch:   712/ 1052, ite: 235300] train loss: 0.003799, tar: 0.000019 
l0: 0.000010, l1: 0.000013, l2: 0.000020, l3: 0.000095, l4: 0.000345, l5: 0.000631, l6: 0.001494

[epoch: 895/1000, batch:   792/ 1052, ite: 235320] train loss: 0.003800, tar: 0.000019 
l0: 0.000041, l1: 0.000043, l2: 0.000082, l3: 0.000136, l4: 0.000315, l5: 0.000861, l6: 0.001419

[epoch: 895/1000, batch:   872/ 1052, ite: 235340] train loss: 0.003798, tar: 0.000019 
l0: 0.000029, l1: 0.000033, l2: 0.000039, l3: 0.000090, l4: 0.000363, l5: 0.001151, l6: 0.001337

[epoch: 895/1000, batch:   952/ 1052, ite: 235360] train loss: 0.003798, tar: 0.000019 
l0: 0.000029, l1: 0.000027, l2: 0.000061, l3: 0.000168, l4: 0.000784, l5: 0.001287, l6: 0.001545

[epoch: 895/1000, batch:  1032/ 1052, ite: 235380] train loss: 0.003798, tar: 0.000019 
[Epoch 895/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000023, l1: 0.000025, l2: 0.000033, l3: 0.000134, l4: 0.000232, l5: 0.000900, l6: 0.002291

[epoch: 896/1000, batch:    60/ 1052, ite: 235400] train loss: 0.003800, tar: 0.000019 
l0: 0.000026, l1: 0.000022, l2: 0.000064, l3: 0.000144, l4: 0.000504, l5: 0.001259, l6: 0.001997

[epoch: 896/1000, batch:   140/ 1052, ite: 235420] train loss: 0.003803, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000006, l3: 0.000117, l4: 0.000256, l5: 0.000555, l6: 0.001100

[epoch: 896/1000, batch:   220/ 1052, ite: 235440] train loss: 0.003805, tar: 0.000020 
l0: 0.000018, l1: 0.000019, l2: 0.000044, l3: 0.000147, l4: 0.000590, l5: 0.001371, l6: 0.002801

[epoch: 896/1000, batch:   300/ 1052, ite: 235460] train loss: 0.003805, tar: 0.000020 
l0: 0.000029, l1: 0.000029, l2: 0.000080, l3: 0.000162, l4: 0.000494, l5: 0.001090, l6: 0.002028

[epoch: 896/1000, batch:   380/ 1052, ite: 235480] train loss: 0.003806, tar: 0.000020 
l0: 0.000021, l1: 0.000016, l2: 0.000069, l3: 0.000149, l4: 0.000500, l5: 0.000832, l6: 0.001696

[epoch: 896/1000, batch:   460/ 1052, ite: 235500] train loss: 0.003803, tar: 0.000020 
l0: 0.000015, l1: 0.000016, l2: 0.000045, l3: 0.000175, l4: 0.000542, l5: 0.001323, l6: 0.003097

[epoch: 896/1000, batch:   540/ 1052, ite: 235520] train loss: 0.003801, tar: 0.000020 
l0: 0.000013, l1: 0.000013, l2: 0.000026, l3: 0.000172, l4: 0.000377, l5: 0.001095, l6: 0.001768

[epoch: 896/1000, batch:   620/ 1052, ite: 235540] train loss: 0.003800, tar: 0.000020 
l0: 0.000009, l1: 0.000009, l2: 0.000043, l3: 0.000087, l4: 0.000321, l5: 0.000840, l6: 0.001547

[epoch: 896/1000, batch:   700/ 1052, ite: 235560] train loss: 0.003800, tar: 0.000020 
l0: 0.000030, l1: 0.000041, l2: 0.000073, l3: 0.000192, l4: 0.000268, l5: 0.000522, l6: 0.000924

[epoch: 896/1000, batch:   780/ 1052, ite: 235580] train loss: 0.003799, tar: 0.000020 
l0: 0.000050, l1: 0.000049, l2: 0.000107, l3: 0.000409, l4: 0.000781, l5: 0.001624, l6: 0.002778

[epoch: 896/1000, batch:   860/ 1052, ite: 235600] train loss: 0.003799, tar: 0.000020 
l0: 0.000014, l1: 0.000015, l2: 0.000065, l3: 0.000236, l4: 0.000505, l5: 0.000817, l6: 0.002411

[epoch: 896/1000, batch:   940/ 1052, ite: 235620] train loss: 0.003803, tar: 0.000020 
l0: 0.000003, l1: 0.000002, l2: 0.000036, l3: 0.000167, l4: 0.000566, l5: 0.001050, l6: 0.001693

[epoch: 896/1000, batch:  1020/ 1052, ite: 235640] train loss: 0.003804, tar: 0.000020 
[Epoch 896/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000009, l1: 0.000010, l2: 0.000072, l3: 0.000217, l4: 0.000494, l5: 0.001415, l6: 0.001792

[epoch: 897/1000, batch:    48/ 1052, ite: 235660] train loss: 0.003805, tar: 0.000020 
l0: 0.000011, l1: 0.000011, l2: 0.000053, l3: 0.000264, l4: 0.000663, l5: 0.001490, l6: 0.002366

[epoch: 897/1000, batch:   128/ 1052, ite: 235680] train loss: 0.003807, tar: 0.000020 
l0: 0.000015, l1: 0.000017, l2: 0.000025, l3: 0.000104, l4: 0.000292, l5: 0.000547, l6: 0.002319

[epoch: 897/1000, batch:   208/ 1052, ite: 235700] train loss: 0.003807, tar: 0.000019 
l0: 0.000027, l1: 0.000029, l2: 0.000070, l3: 0.000201, l4: 0.000635, l5: 0.001523, l6: 0.002300

[epoch: 897/1000, batch:   288/ 1052, ite: 235720] train loss: 0.003810, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000027, l3: 0.000146, l4: 0.000338, l5: 0.000797, l6: 0.001167

[epoch: 897/1000, batch:   368/ 1052, ite: 235740] train loss: 0.003810, tar: 0.000020 
l0: 0.000054, l1: 0.000056, l2: 0.000118, l3: 0.000304, l4: 0.000790, l5: 0.001877, l6: 0.003993

[epoch: 897/1000, batch:   448/ 1052, ite: 235760] train loss: 0.003812, tar: 0.000020 
l0: 0.000016, l1: 0.000016, l2: 0.000031, l3: 0.000099, l4: 0.000325, l5: 0.001247, l6: 0.000913

[epoch: 897/1000, batch:   528/ 1052, ite: 235780] train loss: 0.003812, tar: 0.000020 
l0: 0.000025, l1: 0.000029, l2: 0.000045, l3: 0.000196, l4: 0.000427, l5: 0.001355, l6: 0.001773

[epoch: 897/1000, batch:   608/ 1052, ite: 235800] train loss: 0.003813, tar: 0.000020 
l0: 0.000005, l1: 0.000006, l2: 0.000019, l3: 0.000073, l4: 0.000259, l5: 0.000843, l6: 0.001368

[epoch: 897/1000, batch:   688/ 1052, ite: 235820] train loss: 0.003811, tar: 0.000020 
l0: 0.000025, l1: 0.000028, l2: 0.000050, l3: 0.000138, l4: 0.000532, l5: 0.000772, l6: 0.002594

[epoch: 897/1000, batch:   768/ 1052, ite: 235840] train loss: 0.003811, tar: 0.000020 
l0: 0.000005, l1: 0.000006, l2: 0.000027, l3: 0.000096, l4: 0.000283, l5: 0.000826, l6: 0.001388

[epoch: 897/1000, batch:   848/ 1052, ite: 235860] train loss: 0.003809, tar: 0.000020 
l0: 0.000013, l1: 0.000012, l2: 0.000073, l3: 0.000192, l4: 0.000378, l5: 0.001044, l6: 0.000896

[epoch: 897/1000, batch:   928/ 1052, ite: 235880] train loss: 0.003808, tar: 0.000020 
l0: 0.000009, l1: 0.000009, l2: 0.000050, l3: 0.000189, l4: 0.000479, l5: 0.000895, l6: 0.002280

[epoch: 897/1000, batch:  1008/ 1052, ite: 235900] train loss: 0.003809, tar: 0.000020 
[Epoch 897/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000051, l1: 0.000051, l2: 0.000142, l3: 0.000286, l4: 0.000742, l5: 0.001742, l6: 0.002640

[epoch: 898/1000, batch:    36/ 1052, ite: 235920] train loss: 0.003806, tar: 0.000020 
l0: 0.000024, l1: 0.000027, l2: 0.000065, l3: 0.000206, l4: 0.000632, l5: 0.002058, l6: 0.002997

[epoch: 898/1000, batch:   116/ 1052, ite: 235940] train loss: 0.003805, tar: 0.000020 
l0: 0.000040, l1: 0.000040, l2: 0.000050, l3: 0.000113, l4: 0.000447, l5: 0.001330, l6: 0.002082

[epoch: 898/1000, batch:   196/ 1052, ite: 235960] train loss: 0.003806, tar: 0.000020 
l0: 0.000064, l1: 0.000064, l2: 0.000122, l3: 0.000230, l4: 0.000462, l5: 0.001286, l6: 0.003069

[epoch: 898/1000, batch:   276/ 1052, ite: 235980] train loss: 0.003806, tar: 0.000020 
l0: 0.000011, l1: 0.000011, l2: 0.000026, l3: 0.000075, l4: 0.000234, l5: 0.000454, l6: 0.000910

[epoch: 898/1000, batch:   356/ 1052, ite: 236000] train loss: 0.003806, tar: 0.000020 
l0: 0.000016, l1: 0.000018, l2: 0.000023, l3: 0.000074, l4: 0.000268, l5: 0.000607, l6: 0.001457

[epoch: 898/1000, batch:   436/ 1052, ite: 236020] train loss: 0.003807, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000024, l3: 0.000135, l4: 0.000331, l5: 0.000644, l6: 0.001591

[epoch: 898/1000, batch:   516/ 1052, ite: 236040] train loss: 0.003809, tar: 0.000020 
l0: 0.000042, l1: 0.000041, l2: 0.000059, l3: 0.000182, l4: 0.000411, l5: 0.001006, l6: 0.001607

[epoch: 898/1000, batch:   596/ 1052, ite: 236060] train loss: 0.003808, tar: 0.000020 
l0: 0.000019, l1: 0.000017, l2: 0.000067, l3: 0.000230, l4: 0.000464, l5: 0.001293, l6: 0.002285

[epoch: 898/1000, batch:   676/ 1052, ite: 236080] train loss: 0.003807, tar: 0.000020 
l0: 0.000004, l1: 0.000005, l2: 0.000049, l3: 0.000170, l4: 0.000295, l5: 0.000982, l6: 0.001693

[epoch: 898/1000, batch:   756/ 1052, ite: 236100] train loss: 0.003807, tar: 0.000020 
l0: 0.000075, l1: 0.000077, l2: 0.000083, l3: 0.000209, l4: 0.000366, l5: 0.001675, l6: 0.002579

[epoch: 898/1000, batch:   836/ 1052, ite: 236120] train loss: 0.003808, tar: 0.000020 
l0: 0.000014, l1: 0.000013, l2: 0.000026, l3: 0.000085, l4: 0.000456, l5: 0.001173, l6: 0.001770

[epoch: 898/1000, batch:   916/ 1052, ite: 236140] train loss: 0.003808, tar: 0.000020 
l0: 0.000038, l1: 0.000037, l2: 0.000061, l3: 0.000230, l4: 0.000600, l5: 0.000998, l6: 0.001408

[epoch: 898/1000, batch:   996/ 1052, ite: 236160] train loss: 0.003809, tar: 0.000020 
[Epoch 898/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000006, l1: 0.000007, l2: 0.000020, l3: 0.000082, l4: 0.000178, l5: 0.000558, l6: 0.000583

[epoch: 899/1000, batch:    24/ 1052, ite: 236180] train loss: 0.003808, tar: 0.000020 
l0: 0.000002, l1: 0.000003, l2: 0.000016, l3: 0.000068, l4: 0.000306, l5: 0.000360, l6: 0.001224

[epoch: 899/1000, batch:   104/ 1052, ite: 236200] train loss: 0.003806, tar: 0.000020 
l0: 0.000016, l1: 0.000017, l2: 0.000050, l3: 0.000211, l4: 0.000492, l5: 0.001491, l6: 0.002636

[epoch: 899/1000, batch:   184/ 1052, ite: 236220] train loss: 0.003807, tar: 0.000020 
l0: 0.000020, l1: 0.000019, l2: 0.000054, l3: 0.000215, l4: 0.000484, l5: 0.001099, l6: 0.002726

[epoch: 899/1000, batch:   264/ 1052, ite: 236240] train loss: 0.003808, tar: 0.000020 
l0: 0.000008, l1: 0.000013, l2: 0.000032, l3: 0.000131, l4: 0.000378, l5: 0.000785, l6: 0.001877

[epoch: 899/1000, batch:   344/ 1052, ite: 236260] train loss: 0.003808, tar: 0.000020 
l0: 0.000015, l1: 0.000017, l2: 0.000024, l3: 0.000129, l4: 0.000341, l5: 0.000687, l6: 0.001731

[epoch: 899/1000, batch:   424/ 1052, ite: 236280] train loss: 0.003806, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000005, l3: 0.000020, l4: 0.000119, l5: 0.000589, l6: 0.000831

[epoch: 899/1000, batch:   504/ 1052, ite: 236300] train loss: 0.003806, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000006, l3: 0.000047, l4: 0.000201, l5: 0.000686, l6: 0.001238

[epoch: 899/1000, batch:   584/ 1052, ite: 236320] train loss: 0.003807, tar: 0.000020 
l0: 0.000056, l1: 0.000059, l2: 0.000126, l3: 0.000308, l4: 0.000667, l5: 0.001700, l6: 0.002955

[epoch: 899/1000, batch:   664/ 1052, ite: 236340] train loss: 0.003807, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000025, l3: 0.000114, l4: 0.000365, l5: 0.000888, l6: 0.001355

[epoch: 899/1000, batch:   744/ 1052, ite: 236360] train loss: 0.003809, tar: 0.000020 
l0: 0.000028, l1: 0.000028, l2: 0.000071, l3: 0.000143, l4: 0.000278, l5: 0.000807, l6: 0.001440

[epoch: 899/1000, batch:   824/ 1052, ite: 236380] train loss: 0.003809, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000012, l3: 0.000080, l4: 0.000228, l5: 0.000618, l6: 0.000828

[epoch: 899/1000, batch:   904/ 1052, ite: 236400] train loss: 0.003809, tar: 0.000020 
l0: 0.000005, l1: 0.000005, l2: 0.000022, l3: 0.000092, l4: 0.000190, l5: 0.000813, l6: 0.001535

[epoch: 899/1000, batch:   984/ 1052, ite: 236420] train loss: 0.003808, tar: 0.000020 
[Epoch 899/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000015, l1: 0.000016, l2: 0.000033, l3: 0.000130, l4: 0.000515, l5: 0.000929, l6: 0.001317

[epoch: 900/1000, batch:    12/ 1052, ite: 236440] train loss: 0.003808, tar: 0.000020 
l0: 0.000009, l1: 0.000009, l2: 0.000034, l3: 0.000201, l4: 0.000856, l5: 0.000950, l6: 0.001932

[epoch: 900/1000, batch:    92/ 1052, ite: 236460] train loss: 0.003808, tar: 0.000020 
l0: 0.000005, l1: 0.000004, l2: 0.000037, l3: 0.000193, l4: 0.000458, l5: 0.000725, l6: 0.001272

[epoch: 900/1000, batch:   172/ 1052, ite: 236480] train loss: 0.003808, tar: 0.000020 
l0: 0.000099, l1: 0.000106, l2: 0.000139, l3: 0.000317, l4: 0.000771, l5: 0.001663, l6: 0.003167

[epoch: 900/1000, batch:   252/ 1052, ite: 236500] train loss: 0.003809, tar: 0.000020 
l0: 0.000024, l1: 0.000025, l2: 0.000040, l3: 0.000182, l4: 0.000669, l5: 0.001188, l6: 0.002098

[epoch: 900/1000, batch:   332/ 1052, ite: 236520] train loss: 0.003809, tar: 0.000020 
l0: 0.000022, l1: 0.000021, l2: 0.000027, l3: 0.000115, l4: 0.000340, l5: 0.001076, l6: 0.002274

[epoch: 900/1000, batch:   412/ 1052, ite: 236540] train loss: 0.003810, tar: 0.000020 
l0: 0.000017, l1: 0.000018, l2: 0.000045, l3: 0.000093, l4: 0.000491, l5: 0.001239, l6: 0.001474

[epoch: 900/1000, batch:   492/ 1052, ite: 236560] train loss: 0.003810, tar: 0.000020 
l0: 0.000026, l1: 0.000028, l2: 0.000059, l3: 0.000209, l4: 0.000493, l5: 0.001063, l6: 0.001989

[epoch: 900/1000, batch:   572/ 1052, ite: 236580] train loss: 0.003809, tar: 0.000020 
l0: 0.000018, l1: 0.000018, l2: 0.000056, l3: 0.000198, l4: 0.000575, l5: 0.001360, l6: 0.001597

[epoch: 900/1000, batch:   652/ 1052, ite: 236600] train loss: 0.003810, tar: 0.000020 
l0: 0.000008, l1: 0.000009, l2: 0.000027, l3: 0.000114, l4: 0.000273, l5: 0.000750, l6: 0.001214

[epoch: 900/1000, batch:   732/ 1052, ite: 236620] train loss: 0.003809, tar: 0.000020 
l0: 0.000042, l1: 0.000045, l2: 0.000050, l3: 0.000149, l4: 0.000509, l5: 0.000876, l6: 0.001411

[epoch: 900/1000, batch:   812/ 1052, ite: 236640] train loss: 0.003810, tar: 0.000020 
l0: 0.000010, l1: 0.000010, l2: 0.000025, l3: 0.000107, l4: 0.000427, l5: 0.000546, l6: 0.001386

[epoch: 900/1000, batch:   892/ 1052, ite: 236660] train loss: 0.003811, tar: 0.000020 
l0: 0.000027, l1: 0.000026, l2: 0.000065, l3: 0.000341, l4: 0.000547, l5: 0.001551, l6: 0.002772

[epoch: 900/1000, batch:   972/ 1052, ite: 236680] train loss: 0.003810, tar: 0.000020 
l0: 0.000064, l1: 0.000060, l2: 0.000134, l3: 0.000269, l4: 0.000517, l5: 0.001252, l6: 0.002401

[epoch: 900/1000, batch:  1052/ 1052, ite: 236700] train loss: 0.003810, tar: 0.000020 
[Epoch 900/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000064, l1: 0.000069, l2: 0.000096, l3: 0.000297, l4: 0.001083, l5: 0.001761, l6: 0.004064

[epoch: 901/1000, batch:    80/ 1052, ite: 236720] train loss: 0.003811, tar: 0.000020 
l0: 0.000079, l1: 0.000083, l2: 0.000120, l3: 0.000334, l4: 0.000679, l5: 0.000991, l6: 0.002474

[epoch: 901/1000, batch:   160/ 1052, ite: 236740] train loss: 0.003810, tar: 0.000021 
l0: 0.000005, l1: 0.000005, l2: 0.000050, l3: 0.000252, l4: 0.000495, l5: 0.001022, l6: 0.001641

[epoch: 901/1000, batch:   240/ 1052, ite: 236760] train loss: 0.003808, tar: 0.000021 
l0: 0.000054, l1: 0.000051, l2: 0.000081, l3: 0.000192, l4: 0.000442, l5: 0.000866, l6: 0.001462

[epoch: 901/1000, batch:   320/ 1052, ite: 236780] train loss: 0.003806, tar: 0.000021 
l0: 0.000005, l1: 0.000005, l2: 0.000044, l3: 0.000098, l4: 0.000570, l5: 0.000894, l6: 0.001320

[epoch: 901/1000, batch:   400/ 1052, ite: 236800] train loss: 0.003807, tar: 0.000020 
l0: 0.000032, l1: 0.000032, l2: 0.000112, l3: 0.000329, l4: 0.000724, l5: 0.001269, l6: 0.002967

[epoch: 901/1000, batch:   480/ 1052, ite: 236820] train loss: 0.003809, tar: 0.000021 
l0: 0.000146, l1: 0.000159, l2: 0.000223, l3: 0.000473, l4: 0.000701, l5: 0.001864, l6: 0.002944

[epoch: 901/1000, batch:   560/ 1052, ite: 236840] train loss: 0.003811, tar: 0.000021 
l0: 0.000030, l1: 0.000033, l2: 0.000054, l3: 0.000227, l4: 0.000628, l5: 0.001345, l6: 0.001929

[epoch: 901/1000, batch:   640/ 1052, ite: 236860] train loss: 0.003810, tar: 0.000021 
l0: 0.000008, l1: 0.000009, l2: 0.000022, l3: 0.000075, l4: 0.000267, l5: 0.000796, l6: 0.001008

[epoch: 901/1000, batch:   720/ 1052, ite: 236880] train loss: 0.003812, tar: 0.000021 
l0: 0.000006, l1: 0.000005, l2: 0.000038, l3: 0.000191, l4: 0.000399, l5: 0.000795, l6: 0.001023

[epoch: 901/1000, batch:   800/ 1052, ite: 236900] train loss: 0.003813, tar: 0.000021 
l0: 0.000006, l1: 0.000008, l2: 0.000021, l3: 0.000117, l4: 0.000276, l5: 0.000899, l6: 0.001788

[epoch: 901/1000, batch:   880/ 1052, ite: 236920] train loss: 0.003813, tar: 0.000021 
l0: 0.000007, l1: 0.000007, l2: 0.000036, l3: 0.000154, l4: 0.000341, l5: 0.000458, l6: 0.001143

[epoch: 901/1000, batch:   960/ 1052, ite: 236940] train loss: 0.003812, tar: 0.000021 
l0: 0.000053, l1: 0.000054, l2: 0.000063, l3: 0.000185, l4: 0.000412, l5: 0.001059, l6: 0.001219

[epoch: 901/1000, batch:  1040/ 1052, ite: 236960] train loss: 0.003812, tar: 0.000021 
[Epoch 901/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000023, l1: 0.000023, l2: 0.000053, l3: 0.000093, l4: 0.000348, l5: 0.000507, l6: 0.000956

[epoch: 902/1000, batch:    68/ 1052, ite: 236980] train loss: 0.003814, tar: 0.000021 
l0: 0.000002, l1: 0.000002, l2: 0.000015, l3: 0.000057, l4: 0.000290, l5: 0.000773, l6: 0.001195

[epoch: 902/1000, batch:   148/ 1052, ite: 237000] train loss: 0.003813, tar: 0.000021 
l0: 0.000028, l1: 0.000028, l2: 0.000049, l3: 0.000198, l4: 0.000541, l5: 0.001583, l6: 0.002603

[epoch: 902/1000, batch:   228/ 1052, ite: 237020] train loss: 0.003814, tar: 0.000021 
l0: 0.000012, l1: 0.000011, l2: 0.000049, l3: 0.000157, l4: 0.000413, l5: 0.001098, l6: 0.001673

[epoch: 902/1000, batch:   308/ 1052, ite: 237040] train loss: 0.003816, tar: 0.000021 
l0: 0.000001, l1: 0.000001, l2: 0.000003, l3: 0.000066, l4: 0.000233, l5: 0.000797, l6: 0.001731

[epoch: 902/1000, batch:   388/ 1052, ite: 237060] train loss: 0.003817, tar: 0.000021 
l0: 0.000002, l1: 0.000002, l2: 0.000010, l3: 0.000041, l4: 0.000334, l5: 0.000908, l6: 0.001515

[epoch: 902/1000, batch:   468/ 1052, ite: 237080] train loss: 0.003817, tar: 0.000021 
l0: 0.000014, l1: 0.000014, l2: 0.000080, l3: 0.000330, l4: 0.000633, l5: 0.001339, l6: 0.001823

[epoch: 902/1000, batch:   548/ 1052, ite: 237100] train loss: 0.003817, tar: 0.000021 
l0: 0.000027, l1: 0.000027, l2: 0.000061, l3: 0.000329, l4: 0.000921, l5: 0.002127, l6: 0.002865

[epoch: 902/1000, batch:   628/ 1052, ite: 237120] train loss: 0.003818, tar: 0.000021 
l0: 0.000013, l1: 0.000013, l2: 0.000022, l3: 0.000089, l4: 0.000564, l5: 0.001226, l6: 0.001967

[epoch: 902/1000, batch:   708/ 1052, ite: 237140] train loss: 0.003818, tar: 0.000021 
l0: 0.000029, l1: 0.000028, l2: 0.000059, l3: 0.000169, l4: 0.000431, l5: 0.001039, l6: 0.002148

[epoch: 902/1000, batch:   788/ 1052, ite: 237160] train loss: 0.003818, tar: 0.000021 
l0: 0.000022, l1: 0.000016, l2: 0.000092, l3: 0.000277, l4: 0.000684, l5: 0.001062, l6: 0.001694

[epoch: 902/1000, batch:   868/ 1052, ite: 237180] train loss: 0.003817, tar: 0.000021 
l0: 0.000036, l1: 0.000046, l2: 0.000085, l3: 0.000242, l4: 0.000645, l5: 0.001607, l6: 0.003104

[epoch: 902/1000, batch:   948/ 1052, ite: 237200] train loss: 0.003817, tar: 0.000021 
l0: 0.000012, l1: 0.000010, l2: 0.000036, l3: 0.000127, l4: 0.000362, l5: 0.000426, l6: 0.000868

[epoch: 902/1000, batch:  1028/ 1052, ite: 237220] train loss: 0.003817, tar: 0.000021 
[Epoch 902/1000] Test loss: 0.024, Test target loss: 0.005
l0: 0.000022, l1: 0.000022, l2: 0.000069, l3: 0.000190, l4: 0.000554, l5: 0.000941, l6: 0.002684

[epoch: 903/1000, batch:    56/ 1052, ite: 237240] train loss: 0.003817, tar: 0.000021 
l0: 0.000007, l1: 0.000007, l2: 0.000021, l3: 0.000066, l4: 0.000229, l5: 0.000641, l6: 0.001311

[epoch: 903/1000, batch:   136/ 1052, ite: 237260] train loss: 0.003818, tar: 0.000021 
l0: 0.000035, l1: 0.000040, l2: 0.000055, l3: 0.000204, l4: 0.000653, l5: 0.001398, l6: 0.003716

[epoch: 903/1000, batch:   216/ 1052, ite: 237280] train loss: 0.003817, tar: 0.000021 
l0: 0.000009, l1: 0.000007, l2: 0.000027, l3: 0.000065, l4: 0.000329, l5: 0.000786, l6: 0.000878

[epoch: 903/1000, batch:   296/ 1052, ite: 237300] train loss: 0.003818, tar: 0.000021 
l0: 0.000004, l1: 0.000005, l2: 0.000016, l3: 0.000038, l4: 0.000209, l5: 0.000751, l6: 0.001402

[epoch: 903/1000, batch:   376/ 1052, ite: 237320] train loss: 0.003819, tar: 0.000021 
l0: 0.000037, l1: 0.000043, l2: 0.000061, l3: 0.000277, l4: 0.000860, l5: 0.001431, l6: 0.001618

[epoch: 903/1000, batch:   456/ 1052, ite: 237340] train loss: 0.003818, tar: 0.000021 
l0: 0.000008, l1: 0.000011, l2: 0.000013, l3: 0.000125, l4: 0.000374, l5: 0.000624, l6: 0.000819

[epoch: 903/1000, batch:   536/ 1052, ite: 237360] train loss: 0.003817, tar: 0.000021 
l0: 0.000021, l1: 0.000024, l2: 0.000023, l3: 0.000126, l4: 0.000491, l5: 0.001494, l6: 0.003616

[epoch: 903/1000, batch:   616/ 1052, ite: 237380] train loss: 0.003819, tar: 0.000021 
l0: 0.000020, l1: 0.000019, l2: 0.000062, l3: 0.000219, l4: 0.000512, l5: 0.001461, l6: 0.003584

[epoch: 903/1000, batch:   696/ 1052, ite: 237400] train loss: 0.003819, tar: 0.000021 
l0: 0.000007, l1: 0.000006, l2: 0.000014, l3: 0.000150, l4: 0.000426, l5: 0.001128, l6: 0.001292

[epoch: 903/1000, batch:   776/ 1052, ite: 237420] train loss: 0.003818, tar: 0.000021 
l0: 0.000007, l1: 0.000006, l2: 0.000075, l3: 0.000200, l4: 0.000476, l5: 0.000923, l6: 0.001770

[epoch: 903/1000, batch:   856/ 1052, ite: 237440] train loss: 0.003817, tar: 0.000021 
l0: 0.000004, l1: 0.000003, l2: 0.000071, l3: 0.000254, l4: 0.000482, l5: 0.001197, l6: 0.002023

[epoch: 903/1000, batch:   936/ 1052, ite: 237460] train loss: 0.003816, tar: 0.000021 
l0: 0.000018, l1: 0.000017, l2: 0.000053, l3: 0.000164, l4: 0.000637, l5: 0.001393, l6: 0.001705

[epoch: 903/1000, batch:  1016/ 1052, ite: 237480] train loss: 0.003816, tar: 0.000021 
[Epoch 903/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000038, l1: 0.000037, l2: 0.000066, l3: 0.000233, l4: 0.000590, l5: 0.001531, l6: 0.003527

[epoch: 904/1000, batch:    44/ 1052, ite: 237500] train loss: 0.003817, tar: 0.000021 
l0: 0.000003, l1: 0.000002, l2: 0.000032, l3: 0.000129, l4: 0.000568, l5: 0.001241, l6: 0.001929

[epoch: 904/1000, batch:   124/ 1052, ite: 237520] train loss: 0.003819, tar: 0.000021 
l0: 0.000015, l1: 0.000018, l2: 0.000037, l3: 0.000150, l4: 0.000356, l5: 0.001097, l6: 0.002577

[epoch: 904/1000, batch:   204/ 1052, ite: 237540] train loss: 0.003818, tar: 0.000021 
l0: 0.000033, l1: 0.000031, l2: 0.000115, l3: 0.000428, l4: 0.000944, l5: 0.002144, l6: 0.002849

[epoch: 904/1000, batch:   284/ 1052, ite: 237560] train loss: 0.003820, tar: 0.000021 
l0: 0.000013, l1: 0.000014, l2: 0.000046, l3: 0.000322, l4: 0.000831, l5: 0.001073, l6: 0.001465

[epoch: 904/1000, batch:   364/ 1052, ite: 237580] train loss: 0.003819, tar: 0.000021 
l0: 0.000009, l1: 0.000011, l2: 0.000047, l3: 0.000121, l4: 0.000343, l5: 0.000939, l6: 0.001433

[epoch: 904/1000, batch:   444/ 1052, ite: 237600] train loss: 0.003817, tar: 0.000021 
l0: 0.000007, l1: 0.000009, l2: 0.000029, l3: 0.000158, l4: 0.000544, l5: 0.000866, l6: 0.001295

[epoch: 904/1000, batch:   524/ 1052, ite: 237620] train loss: 0.003817, tar: 0.000021 
l0: 0.000024, l1: 0.000025, l2: 0.000029, l3: 0.000109, l4: 0.000686, l5: 0.001109, l6: 0.002008

[epoch: 904/1000, batch:   604/ 1052, ite: 237640] train loss: 0.003817, tar: 0.000021 
l0: 0.000004, l1: 0.000003, l2: 0.000036, l3: 0.000154, l4: 0.000298, l5: 0.001115, l6: 0.001605

[epoch: 904/1000, batch:   684/ 1052, ite: 237660] train loss: 0.003817, tar: 0.000021 
l0: 0.000020, l1: 0.000017, l2: 0.000054, l3: 0.000173, l4: 0.000277, l5: 0.000976, l6: 0.002278

[epoch: 904/1000, batch:   764/ 1052, ite: 237680] train loss: 0.003818, tar: 0.000021 
l0: 0.000010, l1: 0.000012, l2: 0.000028, l3: 0.000097, l4: 0.000299, l5: 0.001422, l6: 0.002167

[epoch: 904/1000, batch:   844/ 1052, ite: 237700] train loss: 0.003819, tar: 0.000021 
l0: 0.000003, l1: 0.000004, l2: 0.000017, l3: 0.000064, l4: 0.000177, l5: 0.000607, l6: 0.000947

[epoch: 904/1000, batch:   924/ 1052, ite: 237720] train loss: 0.003818, tar: 0.000021 
l0: 0.000024, l1: 0.000022, l2: 0.000079, l3: 0.000159, l4: 0.000408, l5: 0.001274, l6: 0.001776

[epoch: 904/1000, batch:  1004/ 1052, ite: 237740] train loss: 0.003817, tar: 0.000021 
[Epoch 904/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000066, l1: 0.000065, l2: 0.000091, l3: 0.000185, l4: 0.000621, l5: 0.001098, l6: 0.003480

[epoch: 905/1000, batch:    32/ 1052, ite: 237760] train loss: 0.003819, tar: 0.000021 
l0: 0.000041, l1: 0.000046, l2: 0.000069, l3: 0.000148, l4: 0.000236, l5: 0.000559, l6: 0.002011

[epoch: 905/1000, batch:   112/ 1052, ite: 237780] train loss: 0.003819, tar: 0.000021 
l0: 0.000015, l1: 0.000015, l2: 0.000053, l3: 0.000157, l4: 0.000458, l5: 0.001135, l6: 0.001487

[epoch: 905/1000, batch:   192/ 1052, ite: 237800] train loss: 0.003818, tar: 0.000021 
l0: 0.000005, l1: 0.000005, l2: 0.000026, l3: 0.000078, l4: 0.000474, l5: 0.000708, l6: 0.002115

[epoch: 905/1000, batch:   272/ 1052, ite: 237820] train loss: 0.003818, tar: 0.000021 
l0: 0.000007, l1: 0.000007, l2: 0.000042, l3: 0.000184, l4: 0.000520, l5: 0.001288, l6: 0.002057

[epoch: 905/1000, batch:   352/ 1052, ite: 237840] train loss: 0.003817, tar: 0.000021 
l0: 0.000041, l1: 0.000043, l2: 0.000065, l3: 0.000177, l4: 0.000453, l5: 0.001757, l6: 0.002139

[epoch: 905/1000, batch:   432/ 1052, ite: 237860] train loss: 0.003816, tar: 0.000021 
l0: 0.000008, l1: 0.000009, l2: 0.000048, l3: 0.000229, l4: 0.000444, l5: 0.001220, l6: 0.002385

[epoch: 905/1000, batch:   512/ 1052, ite: 237880] train loss: 0.003816, tar: 0.000021 
l0: 0.000025, l1: 0.000025, l2: 0.000055, l3: 0.000126, l4: 0.000291, l5: 0.000831, l6: 0.001666

[epoch: 905/1000, batch:   592/ 1052, ite: 237900] train loss: 0.003816, tar: 0.000021 
l0: 0.000048, l1: 0.000052, l2: 0.000124, l3: 0.000309, l4: 0.000563, l5: 0.001029, l6: 0.002405

[epoch: 905/1000, batch:   672/ 1052, ite: 237920] train loss: 0.003817, tar: 0.000021 
l0: 0.000000, l1: 0.000001, l2: 0.000004, l3: 0.000072, l4: 0.000331, l5: 0.001118, l6: 0.002109

[epoch: 905/1000, batch:   752/ 1052, ite: 237940] train loss: 0.003816, tar: 0.000021 
l0: 0.000047, l1: 0.000049, l2: 0.000098, l3: 0.000289, l4: 0.000667, l5: 0.001574, l6: 0.002116

[epoch: 905/1000, batch:   832/ 1052, ite: 237960] train loss: 0.003816, tar: 0.000021 
l0: 0.000022, l1: 0.000023, l2: 0.000089, l3: 0.000234, l4: 0.000346, l5: 0.000958, l6: 0.001923

[epoch: 905/1000, batch:   912/ 1052, ite: 237980] train loss: 0.003815, tar: 0.000021 
l0: 0.000006, l1: 0.000006, l2: 0.000027, l3: 0.000152, l4: 0.000490, l5: 0.000870, l6: 0.000841

[epoch: 905/1000, batch:   992/ 1052, ite: 238000] train loss: 0.003815, tar: 0.000021 
[Epoch 905/1000] Test loss: 0.024, Test target loss: 0.005
l0: 0.000017, l1: 0.000015, l2: 0.000087, l3: 0.000291, l4: 0.000747, l5: 0.001036, l6: 0.001656

[epoch: 906/1000, batch:    20/ 1052, ite: 238020] train loss: 0.003815, tar: 0.000021 
l0: 0.000107, l1: 0.000111, l2: 0.000151, l3: 0.000345, l4: 0.000510, l5: 0.000946, l6: 0.002589

[epoch: 906/1000, batch:   100/ 1052, ite: 238040] train loss: 0.003815, tar: 0.000021 
l0: 0.000003, l1: 0.000003, l2: 0.000022, l3: 0.000291, l4: 0.000572, l5: 0.001011, l6: 0.002875

[epoch: 906/1000, batch:   180/ 1052, ite: 238060] train loss: 0.003815, tar: 0.000021 
l0: 0.000030, l1: 0.000029, l2: 0.000085, l3: 0.000304, l4: 0.000877, l5: 0.002007, l6: 0.003023

[epoch: 906/1000, batch:   260/ 1052, ite: 238080] train loss: 0.003814, tar: 0.000021 
l0: 0.000081, l1: 0.000083, l2: 0.000166, l3: 0.000601, l4: 0.001035, l5: 0.001810, l6: 0.004078

[epoch: 906/1000, batch:   340/ 1052, ite: 238100] train loss: 0.003814, tar: 0.000021 
l0: 0.000025, l1: 0.000024, l2: 0.000054, l3: 0.000103, l4: 0.000450, l5: 0.001780, l6: 0.002207

[epoch: 906/1000, batch:   420/ 1052, ite: 238120] train loss: 0.003815, tar: 0.000021 
l0: 0.000032, l1: 0.000030, l2: 0.000062, l3: 0.000303, l4: 0.000643, l5: 0.001226, l6: 0.001387

[epoch: 906/1000, batch:   500/ 1052, ite: 238140] train loss: 0.003815, tar: 0.000021 
l0: 0.000013, l1: 0.000014, l2: 0.000079, l3: 0.000244, l4: 0.000676, l5: 0.001276, l6: 0.002646

[epoch: 906/1000, batch:   580/ 1052, ite: 238160] train loss: 0.003816, tar: 0.000021 
l0: 0.000009, l1: 0.000010, l2: 0.000035, l3: 0.000139, l4: 0.000282, l5: 0.001311, l6: 0.001694

[epoch: 906/1000, batch:   660/ 1052, ite: 238180] train loss: 0.003816, tar: 0.000021 
l0: 0.000005, l1: 0.000006, l2: 0.000056, l3: 0.000275, l4: 0.000751, l5: 0.001984, l6: 0.004641

[epoch: 906/1000, batch:   740/ 1052, ite: 238200] train loss: 0.003816, tar: 0.000021 
l0: 0.000009, l1: 0.000011, l2: 0.000033, l3: 0.000124, l4: 0.000397, l5: 0.000937, l6: 0.001663

[epoch: 906/1000, batch:   820/ 1052, ite: 238220] train loss: 0.003814, tar: 0.000021 
l0: 0.000001, l1: 0.000001, l2: 0.000022, l3: 0.000058, l4: 0.000292, l5: 0.000562, l6: 0.000849

[epoch: 906/1000, batch:   900/ 1052, ite: 238240] train loss: 0.003815, tar: 0.000021 
l0: 0.000170, l1: 0.000163, l2: 0.000236, l3: 0.000309, l4: 0.000546, l5: 0.001028, l6: 0.001317

[epoch: 906/1000, batch:   980/ 1052, ite: 238260] train loss: 0.003814, tar: 0.000021 
[Epoch 906/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000010, l1: 0.000011, l2: 0.000042, l3: 0.000287, l4: 0.000666, l5: 0.001520, l6: 0.002584

[epoch: 907/1000, batch:     8/ 1052, ite: 238280] train loss: 0.003815, tar: 0.000021 
l0: 0.000021, l1: 0.000023, l2: 0.000053, l3: 0.000129, l4: 0.000648, l5: 0.001398, l6: 0.002749

[epoch: 907/1000, batch:    88/ 1052, ite: 238300] train loss: 0.003817, tar: 0.000021 
l0: 0.000048, l1: 0.000048, l2: 0.000071, l3: 0.000156, l4: 0.000473, l5: 0.001832, l6: 0.002516

[epoch: 907/1000, batch:   168/ 1052, ite: 238320] train loss: 0.003817, tar: 0.000021 
l0: 0.000035, l1: 0.000035, l2: 0.000062, l3: 0.000204, l4: 0.000453, l5: 0.001416, l6: 0.001892

[epoch: 907/1000, batch:   248/ 1052, ite: 238340] train loss: 0.003818, tar: 0.000021 
l0: 0.000028, l1: 0.000028, l2: 0.000089, l3: 0.000289, l4: 0.000611, l5: 0.001443, l6: 0.002513

[epoch: 907/1000, batch:   328/ 1052, ite: 238360] train loss: 0.003818, tar: 0.000021 
l0: 0.000022, l1: 0.000025, l2: 0.000064, l3: 0.000278, l4: 0.000747, l5: 0.001848, l6: 0.002900

[epoch: 907/1000, batch:   408/ 1052, ite: 238380] train loss: 0.003819, tar: 0.000021 
l0: 0.000008, l1: 0.000009, l2: 0.000018, l3: 0.000108, l4: 0.000300, l5: 0.001199, l6: 0.001751

[epoch: 907/1000, batch:   488/ 1052, ite: 238400] train loss: 0.003818, tar: 0.000021 
l0: 0.000003, l1: 0.000003, l2: 0.000022, l3: 0.000100, l4: 0.000227, l5: 0.000944, l6: 0.001104

[epoch: 907/1000, batch:   568/ 1052, ite: 238420] train loss: 0.003818, tar: 0.000021 
l0: 0.000007, l1: 0.000010, l2: 0.000041, l3: 0.000132, l4: 0.000626, l5: 0.001665, l6: 0.002554

[epoch: 907/1000, batch:   648/ 1052, ite: 238440] train loss: 0.003818, tar: 0.000021 
l0: 0.000006, l1: 0.000005, l2: 0.000044, l3: 0.000134, l4: 0.000264, l5: 0.000943, l6: 0.001677

[epoch: 907/1000, batch:   728/ 1052, ite: 238460] train loss: 0.003817, tar: 0.000021 
l0: 0.000047, l1: 0.000052, l2: 0.000075, l3: 0.000193, l4: 0.000297, l5: 0.001019, l6: 0.001458

[epoch: 907/1000, batch:   808/ 1052, ite: 238480] train loss: 0.003818, tar: 0.000021 
l0: 0.000007, l1: 0.000007, l2: 0.000060, l3: 0.000221, l4: 0.000622, l5: 0.001260, l6: 0.001823

[epoch: 907/1000, batch:   888/ 1052, ite: 238500] train loss: 0.003818, tar: 0.000021 
l0: 0.000015, l1: 0.000017, l2: 0.000069, l3: 0.000286, l4: 0.000864, l5: 0.001212, l6: 0.002837

[epoch: 907/1000, batch:   968/ 1052, ite: 238520] train loss: 0.003818, tar: 0.000021 
l0: 0.000006, l1: 0.000009, l2: 0.000013, l3: 0.000094, l4: 0.000271, l5: 0.000879, l6: 0.001274

[epoch: 907/1000, batch:  1048/ 1052, ite: 238540] train loss: 0.003817, tar: 0.000021 
[Epoch 907/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000011, l1: 0.000011, l2: 0.000021, l3: 0.000045, l4: 0.000203, l5: 0.000685, l6: 0.001122

[epoch: 908/1000, batch:    76/ 1052, ite: 238560] train loss: 0.003815, tar: 0.000021 
l0: 0.000021, l1: 0.000023, l2: 0.000035, l3: 0.000164, l4: 0.000321, l5: 0.001081, l6: 0.001660

[epoch: 908/1000, batch:   156/ 1052, ite: 238580] train loss: 0.003815, tar: 0.000021 
l0: 0.000009, l1: 0.000008, l2: 0.000047, l3: 0.000198, l4: 0.000703, l5: 0.001566, l6: 0.002301

[epoch: 908/1000, batch:   236/ 1052, ite: 238600] train loss: 0.003817, tar: 0.000021 
l0: 0.000012, l1: 0.000012, l2: 0.000056, l3: 0.000184, l4: 0.000435, l5: 0.001811, l6: 0.003240

[epoch: 908/1000, batch:   316/ 1052, ite: 238620] train loss: 0.003817, tar: 0.000021 
l0: 0.000015, l1: 0.000016, l2: 0.000042, l3: 0.000198, l4: 0.000688, l5: 0.001441, l6: 0.002494

[epoch: 908/1000, batch:   396/ 1052, ite: 238640] train loss: 0.003818, tar: 0.000021 
l0: 0.000006, l1: 0.000006, l2: 0.000024, l3: 0.000090, l4: 0.000146, l5: 0.000548, l6: 0.001334

[epoch: 908/1000, batch:   476/ 1052, ite: 238660] train loss: 0.003818, tar: 0.000021 
l0: 0.000267, l1: 0.000274, l2: 0.000292, l3: 0.000375, l4: 0.000451, l5: 0.000597, l6: 0.001593

[epoch: 908/1000, batch:   556/ 1052, ite: 238680] train loss: 0.003818, tar: 0.000021 
l0: 0.000005, l1: 0.000004, l2: 0.000033, l3: 0.000119, l4: 0.000375, l5: 0.001009, l6: 0.001564

[epoch: 908/1000, batch:   636/ 1052, ite: 238700] train loss: 0.003817, tar: 0.000021 
l0: 0.000024, l1: 0.000023, l2: 0.000080, l3: 0.000153, l4: 0.000410, l5: 0.001143, l6: 0.001637

[epoch: 908/1000, batch:   716/ 1052, ite: 238720] train loss: 0.003817, tar: 0.000021 
l0: 0.000005, l1: 0.000005, l2: 0.000070, l3: 0.000278, l4: 0.000814, l5: 0.001169, l6: 0.001524

[epoch: 908/1000, batch:   796/ 1052, ite: 238740] train loss: 0.003817, tar: 0.000021 
l0: 0.000104, l1: 0.000100, l2: 0.000251, l3: 0.000460, l4: 0.000711, l5: 0.002430, l6: 0.004009

[epoch: 908/1000, batch:   876/ 1052, ite: 238760] train loss: 0.003817, tar: 0.000021 
l0: 0.000020, l1: 0.000020, l2: 0.000047, l3: 0.000132, l4: 0.000585, l5: 0.001396, l6: 0.002050

[epoch: 908/1000, batch:   956/ 1052, ite: 238780] train loss: 0.003818, tar: 0.000021 
l0: 0.000028, l1: 0.000030, l2: 0.000072, l3: 0.000150, l4: 0.000247, l5: 0.001089, l6: 0.002963

[epoch: 908/1000, batch:  1036/ 1052, ite: 238800] train loss: 0.003818, tar: 0.000021 
[Epoch 908/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000001, l1: 0.000001, l2: 0.000008, l3: 0.000050, l4: 0.000176, l5: 0.000441, l6: 0.001193

[epoch: 909/1000, batch:    64/ 1052, ite: 238820] train loss: 0.003819, tar: 0.000021 
l0: 0.000025, l1: 0.000023, l2: 0.000062, l3: 0.000175, l4: 0.000502, l5: 0.001347, l6: 0.002518

[epoch: 909/1000, batch:   144/ 1052, ite: 238840] train loss: 0.003819, tar: 0.000021 
l0: 0.000021, l1: 0.000019, l2: 0.000068, l3: 0.000193, l4: 0.000323, l5: 0.001011, l6: 0.001960

[epoch: 909/1000, batch:   224/ 1052, ite: 238860] train loss: 0.003819, tar: 0.000021 
l0: 0.000020, l1: 0.000021, l2: 0.000090, l3: 0.000278, l4: 0.000552, l5: 0.001364, l6: 0.003277

[epoch: 909/1000, batch:   304/ 1052, ite: 238880] train loss: 0.003818, tar: 0.000021 
l0: 0.000008, l1: 0.000012, l2: 0.000028, l3: 0.000099, l4: 0.000329, l5: 0.000622, l6: 0.002068

[epoch: 909/1000, batch:   384/ 1052, ite: 238900] train loss: 0.003818, tar: 0.000021 
l0: 0.000017, l1: 0.000020, l2: 0.000028, l3: 0.000084, l4: 0.000334, l5: 0.000532, l6: 0.001468

[epoch: 909/1000, batch:   464/ 1052, ite: 238920] train loss: 0.003818, tar: 0.000021 
l0: 0.000028, l1: 0.000027, l2: 0.000094, l3: 0.000250, l4: 0.000854, l5: 0.002160, l6: 0.003657

[epoch: 909/1000, batch:   544/ 1052, ite: 238940] train loss: 0.003819, tar: 0.000021 
l0: 0.000005, l1: 0.000004, l2: 0.000031, l3: 0.000193, l4: 0.000375, l5: 0.001418, l6: 0.002105

[epoch: 909/1000, batch:   624/ 1052, ite: 238960] train loss: 0.003818, tar: 0.000021 
l0: 0.000005, l1: 0.000006, l2: 0.000016, l3: 0.000140, l4: 0.000236, l5: 0.000734, l6: 0.002076

[epoch: 909/1000, batch:   704/ 1052, ite: 238980] train loss: 0.003818, tar: 0.000021 
l0: 0.000054, l1: 0.000053, l2: 0.000122, l3: 0.000295, l4: 0.000812, l5: 0.001654, l6: 0.003935

[epoch: 909/1000, batch:   784/ 1052, ite: 239000] train loss: 0.003817, tar: 0.000021 
l0: 0.000008, l1: 0.000008, l2: 0.000047, l3: 0.000133, l4: 0.000438, l5: 0.000975, l6: 0.001265

[epoch: 909/1000, batch:   864/ 1052, ite: 239020] train loss: 0.003816, tar: 0.000021 
l0: 0.000074, l1: 0.000077, l2: 0.000109, l3: 0.000201, l4: 0.000819, l5: 0.001752, l6: 0.002361

[epoch: 909/1000, batch:   944/ 1052, ite: 239040] train loss: 0.003818, tar: 0.000021 
l0: 0.000027, l1: 0.000027, l2: 0.000035, l3: 0.000107, l4: 0.000309, l5: 0.000974, l6: 0.002109

[epoch: 909/1000, batch:  1024/ 1052, ite: 239060] train loss: 0.003817, tar: 0.000021 
[Epoch 909/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000025, l1: 0.000024, l2: 0.000040, l3: 0.000105, l4: 0.000247, l5: 0.001325, l6: 0.002437

[epoch: 910/1000, batch:    52/ 1052, ite: 239080] train loss: 0.003815, tar: 0.000021 
l0: 0.000005, l1: 0.000005, l2: 0.000020, l3: 0.000066, l4: 0.000232, l5: 0.000617, l6: 0.001839

[epoch: 910/1000, batch:   132/ 1052, ite: 239100] train loss: 0.003815, tar: 0.000021 
l0: 0.000032, l1: 0.000030, l2: 0.000051, l3: 0.000129, l4: 0.000449, l5: 0.001110, l6: 0.001842

[epoch: 910/1000, batch:   212/ 1052, ite: 239120] train loss: 0.003814, tar: 0.000021 
l0: 0.000019, l1: 0.000023, l2: 0.000049, l3: 0.000166, l4: 0.000502, l5: 0.001196, l6: 0.001986

[epoch: 910/1000, batch:   292/ 1052, ite: 239140] train loss: 0.003813, tar: 0.000021 
l0: 0.000005, l1: 0.000005, l2: 0.000048, l3: 0.000238, l4: 0.000466, l5: 0.000764, l6: 0.001810

[epoch: 910/1000, batch:   372/ 1052, ite: 239160] train loss: 0.003814, tar: 0.000021 
l0: 0.000102, l1: 0.000099, l2: 0.000135, l3: 0.000309, l4: 0.000688, l5: 0.001649, l6: 0.004539

[epoch: 910/1000, batch:   452/ 1052, ite: 239180] train loss: 0.003815, tar: 0.000021 
l0: 0.000025, l1: 0.000028, l2: 0.000069, l3: 0.000292, l4: 0.000875, l5: 0.002150, l6: 0.003212

[epoch: 910/1000, batch:   532/ 1052, ite: 239200] train loss: 0.003815, tar: 0.000021 
l0: 0.000008, l1: 0.000009, l2: 0.000015, l3: 0.000066, l4: 0.000180, l5: 0.000728, l6: 0.001132

[epoch: 910/1000, batch:   612/ 1052, ite: 239220] train loss: 0.003814, tar: 0.000021 
l0: 0.000003, l1: 0.000003, l2: 0.000028, l3: 0.000132, l4: 0.000234, l5: 0.000753, l6: 0.001378

[epoch: 910/1000, batch:   692/ 1052, ite: 239240] train loss: 0.003813, tar: 0.000021 
l0: 0.000003, l1: 0.000003, l2: 0.000048, l3: 0.000146, l4: 0.000431, l5: 0.001558, l6: 0.001799

[epoch: 910/1000, batch:   772/ 1052, ite: 239260] train loss: 0.003812, tar: 0.000021 
l0: 0.000027, l1: 0.000026, l2: 0.000059, l3: 0.000200, l4: 0.000470, l5: 0.000742, l6: 0.001817

[epoch: 910/1000, batch:   852/ 1052, ite: 239280] train loss: 0.003812, tar: 0.000021 
l0: 0.000011, l1: 0.000011, l2: 0.000030, l3: 0.000169, l4: 0.000605, l5: 0.001268, l6: 0.002436

[epoch: 910/1000, batch:   932/ 1052, ite: 239300] train loss: 0.003814, tar: 0.000021 
l0: 0.000011, l1: 0.000010, l2: 0.000104, l3: 0.000437, l4: 0.000742, l5: 0.001919, l6: 0.003186

[epoch: 910/1000, batch:  1012/ 1052, ite: 239320] train loss: 0.003815, tar: 0.000021 
[Epoch 910/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000054, l1: 0.000057, l2: 0.000097, l3: 0.000348, l4: 0.000881, l5: 0.002064, l6: 0.003907

[epoch: 911/1000, batch:    40/ 1052, ite: 239340] train loss: 0.003816, tar: 0.000021 
l0: 0.000013, l1: 0.000014, l2: 0.000076, l3: 0.000233, l4: 0.000452, l5: 0.000829, l6: 0.002082

[epoch: 911/1000, batch:   120/ 1052, ite: 239360] train loss: 0.003815, tar: 0.000021 
l0: 0.000152, l1: 0.000138, l2: 0.000222, l3: 0.000255, l4: 0.000605, l5: 0.000994, l6: 0.002508

[epoch: 911/1000, batch:   200/ 1052, ite: 239380] train loss: 0.003813, tar: 0.000021 
l0: 0.000022, l1: 0.000023, l2: 0.000070, l3: 0.000234, l4: 0.000489, l5: 0.001326, l6: 0.002062

[epoch: 911/1000, batch:   280/ 1052, ite: 239400] train loss: 0.003813, tar: 0.000021 
l0: 0.000003, l1: 0.000003, l2: 0.000026, l3: 0.000124, l4: 0.000280, l5: 0.000699, l6: 0.001184

[epoch: 911/1000, batch:   360/ 1052, ite: 239420] train loss: 0.003813, tar: 0.000021 
l0: 0.000014, l1: 0.000015, l2: 0.000060, l3: 0.000285, l4: 0.000484, l5: 0.002189, l6: 0.003456

[epoch: 911/1000, batch:   440/ 1052, ite: 239440] train loss: 0.003813, tar: 0.000021 
l0: 0.000021, l1: 0.000022, l2: 0.000042, l3: 0.000126, l4: 0.000379, l5: 0.000586, l6: 0.001714

[epoch: 911/1000, batch:   520/ 1052, ite: 239460] train loss: 0.003812, tar: 0.000021 
l0: 0.000007, l1: 0.000008, l2: 0.000035, l3: 0.000160, l4: 0.000397, l5: 0.001036, l6: 0.001931

[epoch: 911/1000, batch:   600/ 1052, ite: 239480] train loss: 0.003812, tar: 0.000021 
l0: 0.000008, l1: 0.000009, l2: 0.000025, l3: 0.000219, l4: 0.000474, l5: 0.001506, l6: 0.002374

[epoch: 911/1000, batch:   680/ 1052, ite: 239500] train loss: 0.003812, tar: 0.000021 
l0: 0.000010, l1: 0.000008, l2: 0.000076, l3: 0.000176, l4: 0.000482, l5: 0.000705, l6: 0.001853

[epoch: 911/1000, batch:   760/ 1052, ite: 239520] train loss: 0.003812, tar: 0.000021 
l0: 0.000059, l1: 0.000064, l2: 0.000134, l3: 0.000304, l4: 0.001033, l5: 0.002055, l6: 0.004164

[epoch: 911/1000, batch:   840/ 1052, ite: 239540] train loss: 0.003813, tar: 0.000021 
l0: 0.000036, l1: 0.000035, l2: 0.000086, l3: 0.000233, l4: 0.000405, l5: 0.001635, l6: 0.001491

[epoch: 911/1000, batch:   920/ 1052, ite: 239560] train loss: 0.003814, tar: 0.000021 
l0: 0.000022, l1: 0.000023, l2: 0.000113, l3: 0.000394, l4: 0.001038, l5: 0.003167, l6: 0.003598

[epoch: 911/1000, batch:  1000/ 1052, ite: 239580] train loss: 0.003815, tar: 0.000021 
[Epoch 911/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000011, l1: 0.000012, l2: 0.000045, l3: 0.000154, l4: 0.000443, l5: 0.000945, l6: 0.002605

[epoch: 912/1000, batch:    28/ 1052, ite: 239600] train loss: 0.003816, tar: 0.000021 
l0: 0.000004, l1: 0.000004, l2: 0.000016, l3: 0.000122, l4: 0.000426, l5: 0.001713, l6: 0.002452

[epoch: 912/1000, batch:   108/ 1052, ite: 239620] train loss: 0.003816, tar: 0.000021 
l0: 0.000013, l1: 0.000011, l2: 0.000045, l3: 0.000196, l4: 0.000480, l5: 0.000462, l6: 0.001481

[epoch: 912/1000, batch:   188/ 1052, ite: 239640] train loss: 0.003817, tar: 0.000021 
l0: 0.000019, l1: 0.000014, l2: 0.000041, l3: 0.000136, l4: 0.000451, l5: 0.001368, l6: 0.002286

[epoch: 912/1000, batch:   268/ 1052, ite: 239660] train loss: 0.003817, tar: 0.000021 
l0: 0.000026, l1: 0.000024, l2: 0.000071, l3: 0.000105, l4: 0.000390, l5: 0.000729, l6: 0.001605

[epoch: 912/1000, batch:   348/ 1052, ite: 239680] train loss: 0.003816, tar: 0.000021 
l0: 0.000018, l1: 0.000017, l2: 0.000078, l3: 0.000143, l4: 0.000437, l5: 0.001154, l6: 0.000964

[epoch: 912/1000, batch:   428/ 1052, ite: 239700] train loss: 0.003816, tar: 0.000021 
l0: 0.000017, l1: 0.000018, l2: 0.000047, l3: 0.000074, l4: 0.000283, l5: 0.000639, l6: 0.001177

[epoch: 912/1000, batch:   508/ 1052, ite: 239720] train loss: 0.003817, tar: 0.000021 
l0: 0.000004, l1: 0.000003, l2: 0.000009, l3: 0.000064, l4: 0.000262, l5: 0.000752, l6: 0.001197

[epoch: 912/1000, batch:   588/ 1052, ite: 239740] train loss: 0.003816, tar: 0.000021 
l0: 0.000027, l1: 0.000026, l2: 0.000045, l3: 0.000135, l4: 0.000441, l5: 0.000761, l6: 0.001792

[epoch: 912/1000, batch:   668/ 1052, ite: 239760] train loss: 0.003816, tar: 0.000021 
l0: 0.000009, l1: 0.000009, l2: 0.000025, l3: 0.000121, l4: 0.000336, l5: 0.000487, l6: 0.001516

[epoch: 912/1000, batch:   748/ 1052, ite: 239780] train loss: 0.003816, tar: 0.000021 
l0: 0.000011, l1: 0.000010, l2: 0.000042, l3: 0.000104, l4: 0.000356, l5: 0.000679, l6: 0.001711

[epoch: 912/1000, batch:   828/ 1052, ite: 239800] train loss: 0.003817, tar: 0.000021 
l0: 0.000016, l1: 0.000016, l2: 0.000060, l3: 0.000173, l4: 0.000329, l5: 0.001259, l6: 0.001140

[epoch: 912/1000, batch:   908/ 1052, ite: 239820] train loss: 0.003816, tar: 0.000021 
l0: 0.000011, l1: 0.000012, l2: 0.000031, l3: 0.000127, l4: 0.000390, l5: 0.001452, l6: 0.003206

[epoch: 912/1000, batch:   988/ 1052, ite: 239840] train loss: 0.003816, tar: 0.000021 
[Epoch 912/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000011, l1: 0.000010, l2: 0.000048, l3: 0.000119, l4: 0.000369, l5: 0.000425, l6: 0.000991

[epoch: 913/1000, batch:    16/ 1052, ite: 239860] train loss: 0.003815, tar: 0.000021 
l0: 0.000048, l1: 0.000050, l2: 0.000064, l3: 0.000171, l4: 0.000396, l5: 0.000848, l6: 0.001496

[epoch: 913/1000, batch:    96/ 1052, ite: 239880] train loss: 0.003817, tar: 0.000021 
l0: 0.000025, l1: 0.000027, l2: 0.000038, l3: 0.000084, l4: 0.000327, l5: 0.001160, l6: 0.002022

[epoch: 913/1000, batch:   176/ 1052, ite: 239900] train loss: 0.003818, tar: 0.000021 
l0: 0.000017, l1: 0.000019, l2: 0.000045, l3: 0.000126, l4: 0.000274, l5: 0.001050, l6: 0.002093

[epoch: 913/1000, batch:   256/ 1052, ite: 239920] train loss: 0.003819, tar: 0.000021 
l0: 0.000130, l1: 0.000131, l2: 0.000177, l3: 0.000220, l4: 0.000530, l5: 0.000980, l6: 0.001790

[epoch: 913/1000, batch:   336/ 1052, ite: 239940] train loss: 0.003820, tar: 0.000021 
l0: 0.000021, l1: 0.000019, l2: 0.000068, l3: 0.000181, l4: 0.000570, l5: 0.000686, l6: 0.001948

[epoch: 913/1000, batch:   416/ 1052, ite: 239960] train loss: 0.003820, tar: 0.000022 
l0: 0.000012, l1: 0.000009, l2: 0.000037, l3: 0.000133, l4: 0.000309, l5: 0.000782, l6: 0.001632

[epoch: 913/1000, batch:   496/ 1052, ite: 239980] train loss: 0.003820, tar: 0.000022 
l0: 0.000019, l1: 0.000020, l2: 0.000030, l3: 0.000073, l4: 0.000163, l5: 0.000616, l6: 0.000710

[epoch: 913/1000, batch:   576/ 1052, ite: 240000] train loss: 0.003820, tar: 0.000022 
l0: 0.000121, l1: 0.000125, l2: 0.000218, l3: 0.000352, l4: 0.000673, l5: 0.001895, l6: 0.003509

[epoch: 913/1000, batch:   656/ 1052, ite: 240020] train loss: 0.003821, tar: 0.000022 
l0: 0.000014, l1: 0.000013, l2: 0.000036, l3: 0.000140, l4: 0.000397, l5: 0.000961, l6: 0.001639

[epoch: 913/1000, batch:   736/ 1052, ite: 240040] train loss: 0.003821, tar: 0.000022 
l0: 0.000003, l1: 0.000002, l2: 0.000008, l3: 0.000053, l4: 0.000195, l5: 0.000783, l6: 0.000983

[epoch: 913/1000, batch:   816/ 1052, ite: 240060] train loss: 0.003821, tar: 0.000022 
l0: 0.000067, l1: 0.000072, l2: 0.000095, l3: 0.000238, l4: 0.000483, l5: 0.001012, l6: 0.002717

[epoch: 913/1000, batch:   896/ 1052, ite: 240080] train loss: 0.003821, tar: 0.000022 
l0: 0.000081, l1: 0.000082, l2: 0.000123, l3: 0.000265, l4: 0.000829, l5: 0.001630, l6: 0.003083

[epoch: 913/1000, batch:   976/ 1052, ite: 240100] train loss: 0.003820, tar: 0.000022 
[Epoch 913/1000] Test loss: 0.020, Test target loss: 0.003
l0: 0.000017, l1: 0.000016, l2: 0.000035, l3: 0.000196, l4: 0.000486, l5: 0.001210, l6: 0.002014

[epoch: 914/1000, batch:     4/ 1052, ite: 240120] train loss: 0.003820, tar: 0.000022 
l0: 0.000043, l1: 0.000043, l2: 0.000078, l3: 0.000327, l4: 0.001141, l5: 0.001699, l6: 0.002872

[epoch: 914/1000, batch:    84/ 1052, ite: 240140] train loss: 0.003820, tar: 0.000022 
l0: 0.000048, l1: 0.000054, l2: 0.000099, l3: 0.000171, l4: 0.000356, l5: 0.001329, l6: 0.003537

[epoch: 914/1000, batch:   164/ 1052, ite: 240160] train loss: 0.003821, tar: 0.000022 
l0: 0.000069, l1: 0.000070, l2: 0.000097, l3: 0.000185, l4: 0.000679, l5: 0.001055, l6: 0.002299

[epoch: 914/1000, batch:   244/ 1052, ite: 240180] train loss: 0.003822, tar: 0.000022 
l0: 0.000082, l1: 0.000091, l2: 0.000120, l3: 0.000152, l4: 0.000332, l5: 0.000696, l6: 0.001312

[epoch: 914/1000, batch:   324/ 1052, ite: 240200] train loss: 0.003842, tar: 0.000027 
l0: 0.000121, l1: 0.000144, l2: 0.000150, l3: 0.000190, l4: 0.000385, l5: 0.001318, l6: 0.001928

[epoch: 914/1000, batch:   404/ 1052, ite: 240220] train loss: 0.003845, tar: 0.000028 
l0: 0.000173, l1: 0.000168, l2: 0.000333, l3: 0.002468, l4: 0.001000, l5: 0.001718, l6: 0.004631

[epoch: 914/1000, batch:   484/ 1052, ite: 240240] train loss: 0.003845, tar: 0.000028 
l0: 0.000062, l1: 0.000061, l2: 0.000104, l3: 0.000229, l4: 0.000470, l5: 0.001025, l6: 0.001877

[epoch: 914/1000, batch:   564/ 1052, ite: 240260] train loss: 0.003846, tar: 0.000028 
l0: 0.000038, l1: 0.000033, l2: 0.000075, l3: 0.000160, l4: 0.000385, l5: 0.001150, l6: 0.001685

[epoch: 914/1000, batch:   644/ 1052, ite: 240280] train loss: 0.003846, tar: 0.000028 
l0: 0.000062, l1: 0.000063, l2: 0.000113, l3: 0.000311, l4: 0.000574, l5: 0.001037, l6: 0.002111

[epoch: 914/1000, batch:   724/ 1052, ite: 240300] train loss: 0.003849, tar: 0.000028 
l0: 0.000024, l1: 0.000033, l2: 0.000020, l3: 0.000069, l4: 0.000354, l5: 0.000639, l6: 0.001063

[epoch: 914/1000, batch:   804/ 1052, ite: 240320] train loss: 0.003849, tar: 0.000028 
l0: 0.000005, l1: 0.000004, l2: 0.000019, l3: 0.000050, l4: 0.000310, l5: 0.001061, l6: 0.000991

[epoch: 914/1000, batch:   884/ 1052, ite: 240340] train loss: 0.003849, tar: 0.000028 
l0: 0.000008, l1: 0.000007, l2: 0.000027, l3: 0.000102, l4: 0.000388, l5: 0.000836, l6: 0.001313

[epoch: 914/1000, batch:   964/ 1052, ite: 240360] train loss: 0.003848, tar: 0.000029 
l0: 0.000003, l1: 0.000002, l2: 0.000013, l3: 0.000066, l4: 0.000289, l5: 0.000746, l6: 0.001210

[epoch: 914/1000, batch:  1044/ 1052, ite: 240380] train loss: 0.003848, tar: 0.000029 
[Epoch 914/1000] Test loss: 0.020, Test target loss: 0.003
l0: 0.000026, l1: 0.000028, l2: 0.000059, l3: 0.000133, l4: 0.000495, l5: 0.000597, l6: 0.001394

[epoch: 915/1000, batch:    72/ 1052, ite: 240400] train loss: 0.003849, tar: 0.000029 
l0: 0.000012, l1: 0.000012, l2: 0.000037, l3: 0.000224, l4: 0.000461, l5: 0.000432, l6: 0.001397

[epoch: 915/1000, batch:   152/ 1052, ite: 240420] train loss: 0.003850, tar: 0.000029 
l0: 0.000022, l1: 0.000021, l2: 0.000046, l3: 0.000133, l4: 0.000308, l5: 0.000935, l6: 0.002190

[epoch: 915/1000, batch:   232/ 1052, ite: 240440] train loss: 0.003850, tar: 0.000029 
l0: 0.000027, l1: 0.000033, l2: 0.000043, l3: 0.000156, l4: 0.000662, l5: 0.001733, l6: 0.002507

[epoch: 915/1000, batch:   312/ 1052, ite: 240460] train loss: 0.003852, tar: 0.000029 
l0: 0.000108, l1: 0.000101, l2: 0.000141, l3: 0.000264, l4: 0.000495, l5: 0.001051, l6: 0.002090

[epoch: 915/1000, batch:   392/ 1052, ite: 240480] train loss: 0.003851, tar: 0.000029 
l0: 0.000055, l1: 0.000059, l2: 0.000114, l3: 0.000334, l4: 0.000852, l5: 0.001656, l6: 0.003273

[epoch: 915/1000, batch:   472/ 1052, ite: 240500] train loss: 0.003851, tar: 0.000029 
l0: 0.000020, l1: 0.000020, l2: 0.000057, l3: 0.000162, l4: 0.000518, l5: 0.000880, l6: 0.001638

[epoch: 915/1000, batch:   552/ 1052, ite: 240520] train loss: 0.003851, tar: 0.000029 
l0: 0.000009, l1: 0.000010, l2: 0.000027, l3: 0.000084, l4: 0.000209, l5: 0.000575, l6: 0.001303

[epoch: 915/1000, batch:   632/ 1052, ite: 240540] train loss: 0.003851, tar: 0.000029 
l0: 0.000004, l1: 0.000003, l2: 0.000017, l3: 0.000101, l4: 0.000242, l5: 0.000538, l6: 0.000963

[epoch: 915/1000, batch:   712/ 1052, ite: 240560] train loss: 0.003854, tar: 0.000029 
l0: 0.000081, l1: 0.000092, l2: 0.000128, l3: 0.000227, l4: 0.000365, l5: 0.001178, l6: 0.002956

[epoch: 915/1000, batch:   792/ 1052, ite: 240580] train loss: 0.003856, tar: 0.000030 
l0: 0.000049, l1: 0.000051, l2: 0.000075, l3: 0.000088, l4: 0.000326, l5: 0.000650, l6: 0.001181

[epoch: 915/1000, batch:   872/ 1052, ite: 240600] train loss: 0.003855, tar: 0.000030 
l0: 0.000033, l1: 0.000031, l2: 0.000092, l3: 0.000207, l4: 0.000419, l5: 0.000962, l6: 0.001749

[epoch: 915/1000, batch:   952/ 1052, ite: 240620] train loss: 0.003855, tar: 0.000030 
l0: 0.000029, l1: 0.000028, l2: 0.000059, l3: 0.000148, l4: 0.000522, l5: 0.001245, l6: 0.002074

[epoch: 915/1000, batch:  1032/ 1052, ite: 240640] train loss: 0.003856, tar: 0.000030 
[Epoch 915/1000] Test loss: 0.021, Test target loss: 0.003
l0: 0.000010, l1: 0.000008, l2: 0.000022, l3: 0.000105, l4: 0.000492, l5: 0.001076, l6: 0.001456

[epoch: 916/1000, batch:    60/ 1052, ite: 240660] train loss: 0.003855, tar: 0.000030 
l0: 0.000022, l1: 0.000020, l2: 0.000051, l3: 0.000182, l4: 0.000451, l5: 0.000831, l6: 0.001431

[epoch: 916/1000, batch:   140/ 1052, ite: 240680] train loss: 0.003855, tar: 0.000030 
l0: 0.000032, l1: 0.000033, l2: 0.000070, l3: 0.000146, l4: 0.000266, l5: 0.000701, l6: 0.002062

[epoch: 916/1000, batch:   220/ 1052, ite: 240700] train loss: 0.003855, tar: 0.000030 
l0: 0.000005, l1: 0.000006, l2: 0.000042, l3: 0.000309, l4: 0.000932, l5: 0.001544, l6: 0.002649

[epoch: 916/1000, batch:   300/ 1052, ite: 240720] train loss: 0.003855, tar: 0.000030 
l0: 0.000021, l1: 0.000024, l2: 0.000014, l3: 0.000082, l4: 0.000319, l5: 0.001016, l6: 0.001331

[epoch: 916/1000, batch:   380/ 1052, ite: 240740] train loss: 0.003855, tar: 0.000030 
l0: 0.000001, l1: 0.000001, l2: 0.000019, l3: 0.000110, l4: 0.000205, l5: 0.000824, l6: 0.001309

[epoch: 916/1000, batch:   460/ 1052, ite: 240760] train loss: 0.003855, tar: 0.000030 
l0: 0.000310, l1: 0.000307, l2: 0.000487, l3: 0.000412, l4: 0.000612, l5: 0.001263, l6: 0.002796

[epoch: 916/1000, batch:   540/ 1052, ite: 240780] train loss: 0.003856, tar: 0.000030 
l0: 0.000011, l1: 0.000012, l2: 0.000013, l3: 0.000073, l4: 0.000221, l5: 0.000563, l6: 0.001503

[epoch: 916/1000, batch:   620/ 1052, ite: 240800] train loss: 0.003856, tar: 0.000030 
l0: 0.000055, l1: 0.000053, l2: 0.000091, l3: 0.000210, l4: 0.000453, l5: 0.001082, l6: 0.002324

[epoch: 916/1000, batch:   700/ 1052, ite: 240820] train loss: 0.003857, tar: 0.000030 
l0: 0.000047, l1: 0.000041, l2: 0.000095, l3: 0.000258, l4: 0.000647, l5: 0.001061, l6: 0.003121

[epoch: 916/1000, batch:   780/ 1052, ite: 240840] train loss: 0.003857, tar: 0.000030 
l0: 0.000045, l1: 0.000050, l2: 0.000067, l3: 0.000171, l4: 0.000351, l5: 0.001414, l6: 0.002180

[epoch: 916/1000, batch:   860/ 1052, ite: 240860] train loss: 0.003859, tar: 0.000030 
l0: 0.000069, l1: 0.000071, l2: 0.000126, l3: 0.000270, l4: 0.000666, l5: 0.001310, l6: 0.002970

[epoch: 916/1000, batch:   940/ 1052, ite: 240880] train loss: 0.003859, tar: 0.000030 
l0: 0.000016, l1: 0.000014, l2: 0.000041, l3: 0.000130, l4: 0.000392, l5: 0.000793, l6: 0.001020

[epoch: 916/1000, batch:  1020/ 1052, ite: 240900] train loss: 0.003858, tar: 0.000030 
[Epoch 916/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000019, l1: 0.000021, l2: 0.000036, l3: 0.000112, l4: 0.000405, l5: 0.000754, l6: 0.001403

[epoch: 917/1000, batch:    48/ 1052, ite: 240920] train loss: 0.003857, tar: 0.000030 
l0: 0.000008, l1: 0.000008, l2: 0.000037, l3: 0.000190, l4: 0.000312, l5: 0.000980, l6: 0.001747

[epoch: 917/1000, batch:   128/ 1052, ite: 240940] train loss: 0.003859, tar: 0.000030 
l0: 0.000023, l1: 0.000021, l2: 0.000084, l3: 0.000355, l4: 0.001024, l5: 0.001790, l6: 0.003813

[epoch: 917/1000, batch:   208/ 1052, ite: 240960] train loss: 0.003858, tar: 0.000030 
l0: 0.000011, l1: 0.000010, l2: 0.000021, l3: 0.000107, l4: 0.000402, l5: 0.001212, l6: 0.001395

[epoch: 917/1000, batch:   288/ 1052, ite: 240980] train loss: 0.003858, tar: 0.000030 
l0: 0.000025, l1: 0.000027, l2: 0.000032, l3: 0.000218, l4: 0.000748, l5: 0.001818, l6: 0.002184

[epoch: 917/1000, batch:   368/ 1052, ite: 241000] train loss: 0.003860, tar: 0.000030 
l0: 0.000010, l1: 0.000011, l2: 0.000019, l3: 0.000069, l4: 0.000234, l5: 0.000756, l6: 0.000905

[epoch: 917/1000, batch:   448/ 1052, ite: 241020] train loss: 0.003859, tar: 0.000030 
l0: 0.000092, l1: 0.000094, l2: 0.000143, l3: 0.000391, l4: 0.000404, l5: 0.000949, l6: 0.002937

[epoch: 917/1000, batch:   528/ 1052, ite: 241040] train loss: 0.003858, tar: 0.000030 
l0: 0.000043, l1: 0.000043, l2: 0.000067, l3: 0.000176, l4: 0.000308, l5: 0.000575, l6: 0.001667

[epoch: 917/1000, batch:   608/ 1052, ite: 241060] train loss: 0.003859, tar: 0.000030 
l0: 0.000007, l1: 0.000008, l2: 0.000032, l3: 0.000121, l4: 0.000261, l5: 0.000821, l6: 0.001373

[epoch: 917/1000, batch:   688/ 1052, ite: 241080] train loss: 0.003858, tar: 0.000030 
l0: 0.000016, l1: 0.000014, l2: 0.000053, l3: 0.000214, l4: 0.000726, l5: 0.001625, l6: 0.002434

[epoch: 917/1000, batch:   768/ 1052, ite: 241100] train loss: 0.003859, tar: 0.000030 
l0: 0.000021, l1: 0.000017, l2: 0.000042, l3: 0.000203, l4: 0.000421, l5: 0.000715, l6: 0.001827

[epoch: 917/1000, batch:   848/ 1052, ite: 241120] train loss: 0.003860, tar: 0.000030 
l0: 0.000002, l1: 0.000003, l2: 0.000004, l3: 0.000057, l4: 0.000192, l5: 0.000583, l6: 0.001249

[epoch: 917/1000, batch:   928/ 1052, ite: 241140] train loss: 0.003859, tar: 0.000030 
l0: 0.000009, l1: 0.000010, l2: 0.000037, l3: 0.000069, l4: 0.000200, l5: 0.000512, l6: 0.001777

[epoch: 917/1000, batch:  1008/ 1052, ite: 241160] train loss: 0.003859, tar: 0.000030 
[Epoch 917/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000054, l1: 0.000026, l2: 0.000133, l3: 0.000424, l4: 0.000801, l5: 0.002194, l6: 0.004159

[epoch: 918/1000, batch:    36/ 1052, ite: 241180] train loss: 0.003859, tar: 0.000030 
l0: 0.000001, l1: 0.000000, l2: 0.000017, l3: 0.000070, l4: 0.000267, l5: 0.000517, l6: 0.001507

[epoch: 918/1000, batch:   116/ 1052, ite: 241200] train loss: 0.003859, tar: 0.000030 
l0: 0.000007, l1: 0.000006, l2: 0.000035, l3: 0.000118, l4: 0.000485, l5: 0.001126, l6: 0.002184

[epoch: 918/1000, batch:   196/ 1052, ite: 241220] train loss: 0.003859, tar: 0.000030 
l0: 0.000033, l1: 0.000032, l2: 0.000073, l3: 0.000291, l4: 0.000699, l5: 0.001458, l6: 0.002158

[epoch: 918/1000, batch:   276/ 1052, ite: 241240] train loss: 0.003859, tar: 0.000030 
l0: 0.000023, l1: 0.000021, l2: 0.000110, l3: 0.000181, l4: 0.000472, l5: 0.001008, l6: 0.002064

[epoch: 918/1000, batch:   356/ 1052, ite: 241260] train loss: 0.003858, tar: 0.000030 
l0: 0.000000, l1: 0.000001, l2: 0.000011, l3: 0.000034, l4: 0.000198, l5: 0.000423, l6: 0.000792

[epoch: 918/1000, batch:   436/ 1052, ite: 241280] train loss: 0.003858, tar: 0.000030 
l0: 0.000018, l1: 0.000017, l2: 0.000114, l3: 0.000225, l4: 0.000455, l5: 0.000380, l6: 0.001128

[epoch: 918/1000, batch:   516/ 1052, ite: 241300] train loss: 0.003857, tar: 0.000030 
l0: 0.000018, l1: 0.000023, l2: 0.000032, l3: 0.000140, l4: 0.000329, l5: 0.000887, l6: 0.001833

[epoch: 918/1000, batch:   596/ 1052, ite: 241320] train loss: 0.003857, tar: 0.000030 
l0: 0.000004, l1: 0.000003, l2: 0.000033, l3: 0.000057, l4: 0.000219, l5: 0.000437, l6: 0.001476

[epoch: 918/1000, batch:   676/ 1052, ite: 241340] train loss: 0.003856, tar: 0.000030 
l0: 0.000045, l1: 0.000049, l2: 0.000059, l3: 0.000078, l4: 0.000343, l5: 0.000631, l6: 0.001120

[epoch: 918/1000, batch:   756/ 1052, ite: 241360] train loss: 0.003856, tar: 0.000029 
l0: 0.000494, l1: 0.000505, l2: 0.000593, l3: 0.000368, l4: 0.000205, l5: 0.000309, l6: 0.000372

[epoch: 918/1000, batch:   836/ 1052, ite: 241380] train loss: 0.003857, tar: 0.000030 
l0: 0.000012, l1: 0.000011, l2: 0.000044, l3: 0.000162, l4: 0.000405, l5: 0.000880, l6: 0.000985

[epoch: 918/1000, batch:   916/ 1052, ite: 241400] train loss: 0.003857, tar: 0.000030 
l0: 0.000004, l1: 0.000004, l2: 0.000033, l3: 0.000177, l4: 0.000437, l5: 0.000739, l6: 0.001818

[epoch: 918/1000, batch:   996/ 1052, ite: 241420] train loss: 0.003858, tar: 0.000030 
[Epoch 918/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000026, l1: 0.000023, l2: 0.000039, l3: 0.000105, l4: 0.000251, l5: 0.000941, l6: 0.001275

[epoch: 919/1000, batch:    24/ 1052, ite: 241440] train loss: 0.003857, tar: 0.000030 
l0: 0.000034, l1: 0.000034, l2: 0.000060, l3: 0.000135, l4: 0.000642, l5: 0.001091, l6: 0.001160

[epoch: 919/1000, batch:   104/ 1052, ite: 241460] train loss: 0.003857, tar: 0.000030 
l0: 0.000053, l1: 0.000050, l2: 0.000114, l3: 0.000168, l4: 0.000542, l5: 0.000801, l6: 0.001332

[epoch: 919/1000, batch:   184/ 1052, ite: 241480] train loss: 0.003857, tar: 0.000030 
l0: 0.000021, l1: 0.000019, l2: 0.000064, l3: 0.000354, l4: 0.000576, l5: 0.001591, l6: 0.002890

[epoch: 919/1000, batch:   264/ 1052, ite: 241500] train loss: 0.003857, tar: 0.000030 
l0: 0.000002, l1: 0.000002, l2: 0.000008, l3: 0.000059, l4: 0.000145, l5: 0.000909, l6: 0.001401

[epoch: 919/1000, batch:   344/ 1052, ite: 241520] train loss: 0.003857, tar: 0.000029 
l0: 0.000039, l1: 0.000038, l2: 0.000084, l3: 0.000169, l4: 0.000620, l5: 0.001357, l6: 0.001783

[epoch: 919/1000, batch:   424/ 1052, ite: 241540] train loss: 0.003856, tar: 0.000029 
l0: 0.000022, l1: 0.000030, l2: 0.000048, l3: 0.000106, l4: 0.000419, l5: 0.000550, l6: 0.002089

[epoch: 919/1000, batch:   504/ 1052, ite: 241560] train loss: 0.003857, tar: 0.000029 
l0: 0.000008, l1: 0.000007, l2: 0.000050, l3: 0.000232, l4: 0.000403, l5: 0.000939, l6: 0.001126

[epoch: 919/1000, batch:   584/ 1052, ite: 241580] train loss: 0.003857, tar: 0.000029 
l0: 0.000003, l1: 0.000003, l2: 0.000027, l3: 0.000113, l4: 0.000281, l5: 0.001367, l6: 0.002526

[epoch: 919/1000, batch:   664/ 1052, ite: 241600] train loss: 0.003855, tar: 0.000029 
l0: 0.000061, l1: 0.000055, l2: 0.000075, l3: 0.000153, l4: 0.000408, l5: 0.000703, l6: 0.001076

[epoch: 919/1000, batch:   744/ 1052, ite: 241620] train loss: 0.003855, tar: 0.000029 
l0: 0.000028, l1: 0.000031, l2: 0.000059, l3: 0.000184, l4: 0.000514, l5: 0.001089, l6: 0.001820

[epoch: 919/1000, batch:   824/ 1052, ite: 241640] train loss: 0.003856, tar: 0.000029 
l0: 0.000031, l1: 0.000027, l2: 0.000115, l3: 0.000296, l4: 0.001141, l5: 0.002328, l6: 0.003644

[epoch: 919/1000, batch:   904/ 1052, ite: 241660] train loss: 0.003856, tar: 0.000029 
l0: 0.000045, l1: 0.000048, l2: 0.000080, l3: 0.000223, l4: 0.000744, l5: 0.001702, l6: 0.002317

[epoch: 919/1000, batch:   984/ 1052, ite: 241680] train loss: 0.003856, tar: 0.000029 
[Epoch 919/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000049, l1: 0.000053, l2: 0.000138, l3: 0.000319, l4: 0.000737, l5: 0.001774, l6: 0.004107

[epoch: 920/1000, batch:    12/ 1052, ite: 241700] train loss: 0.003856, tar: 0.000029 
l0: 0.000014, l1: 0.000012, l2: 0.000059, l3: 0.000208, l4: 0.000472, l5: 0.001273, l6: 0.001865

[epoch: 920/1000, batch:    92/ 1052, ite: 241720] train loss: 0.003856, tar: 0.000029 
l0: 0.000007, l1: 0.000007, l2: 0.000026, l3: 0.000140, l4: 0.000436, l5: 0.000901, l6: 0.001573

[epoch: 920/1000, batch:   172/ 1052, ite: 241740] train loss: 0.003855, tar: 0.000029 
l0: 0.000011, l1: 0.000013, l2: 0.000053, l3: 0.000395, l4: 0.001058, l5: 0.001746, l6: 0.002878

[epoch: 920/1000, batch:   252/ 1052, ite: 241760] train loss: 0.003856, tar: 0.000029 
l0: 0.000066, l1: 0.000073, l2: 0.000080, l3: 0.000307, l4: 0.000734, l5: 0.001979, l6: 0.003408

[epoch: 920/1000, batch:   332/ 1052, ite: 241780] train loss: 0.003857, tar: 0.000029 
l0: 0.000007, l1: 0.000009, l2: 0.000072, l3: 0.000275, l4: 0.000691, l5: 0.001859, l6: 0.003013

[epoch: 920/1000, batch:   412/ 1052, ite: 241800] train loss: 0.003858, tar: 0.000029 
l0: 0.000034, l1: 0.000031, l2: 0.000099, l3: 0.000223, l4: 0.000472, l5: 0.000847, l6: 0.002044

[epoch: 920/1000, batch:   492/ 1052, ite: 241820] train loss: 0.003856, tar: 0.000029 
l0: 0.000028, l1: 0.000023, l2: 0.000086, l3: 0.000405, l4: 0.000804, l5: 0.001406, l6: 0.001861

[epoch: 920/1000, batch:   572/ 1052, ite: 241840] train loss: 0.003857, tar: 0.000029 
l0: 0.000001, l1: 0.000001, l2: 0.000021, l3: 0.000162, l4: 0.000662, l5: 0.001557, l6: 0.002322

[epoch: 920/1000, batch:   652/ 1052, ite: 241860] train loss: 0.003857, tar: 0.000029 
l0: 0.000002, l1: 0.000002, l2: 0.000016, l3: 0.000120, l4: 0.000434, l5: 0.000908, l6: 0.001420

[epoch: 920/1000, batch:   732/ 1052, ite: 241880] train loss: 0.003855, tar: 0.000029 
l0: 0.000015, l1: 0.000014, l2: 0.000067, l3: 0.000220, l4: 0.000523, l5: 0.000855, l6: 0.001200

[epoch: 920/1000, batch:   812/ 1052, ite: 241900] train loss: 0.003855, tar: 0.000029 
l0: 0.000005, l1: 0.000004, l2: 0.000016, l3: 0.000133, l4: 0.000247, l5: 0.000730, l6: 0.002112

[epoch: 920/1000, batch:   892/ 1052, ite: 241920] train loss: 0.003856, tar: 0.000029 
l0: 0.000013, l1: 0.000015, l2: 0.000041, l3: 0.000235, l4: 0.000476, l5: 0.001040, l6: 0.001539

[epoch: 920/1000, batch:   972/ 1052, ite: 241940] train loss: 0.003855, tar: 0.000029 
l0: 0.000008, l1: 0.000009, l2: 0.000028, l3: 0.000117, l4: 0.000457, l5: 0.000902, l6: 0.001512

[epoch: 920/1000, batch:  1052/ 1052, ite: 241960] train loss: 0.003855, tar: 0.000029 
[Epoch 920/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000001, l1: 0.000001, l2: 0.000015, l3: 0.000084, l4: 0.000427, l5: 0.000845, l6: 0.001365

[epoch: 921/1000, batch:    80/ 1052, ite: 241980] train loss: 0.003827, tar: 0.000013 
l0: 0.000021, l1: 0.000026, l2: 0.000049, l3: 0.000181, l4: 0.000809, l5: 0.001693, l6: 0.003067

[epoch: 921/1000, batch:   160/ 1052, ite: 242000] train loss: 0.003908, tar: 0.000013 
l0: 0.000005, l1: 0.000004, l2: 0.000027, l3: 0.000152, l4: 0.000287, l5: 0.001338, l6: 0.001808

[epoch: 921/1000, batch:   240/ 1052, ite: 242020] train loss: 0.003739, tar: 0.000012 
l0: 0.000000, l1: 0.000000, l2: 0.000003, l3: 0.000054, l4: 0.000231, l5: 0.000357, l6: 0.001038

[epoch: 921/1000, batch:   320/ 1052, ite: 242040] train loss: 0.003739, tar: 0.000011 
l0: 0.000006, l1: 0.000006, l2: 0.000051, l3: 0.000340, l4: 0.000677, l5: 0.001472, l6: 0.002668

[epoch: 921/1000, batch:   400/ 1052, ite: 242060] train loss: 0.003814, tar: 0.000011 
l0: 0.000005, l1: 0.000006, l2: 0.000041, l3: 0.000159, l4: 0.000539, l5: 0.001723, l6: 0.001700

[epoch: 921/1000, batch:   480/ 1052, ite: 242080] train loss: 0.003750, tar: 0.000012 
l0: 0.000006, l1: 0.000007, l2: 0.000019, l3: 0.000083, l4: 0.000281, l5: 0.000849, l6: 0.001421

[epoch: 921/1000, batch:   560/ 1052, ite: 242100] train loss: 0.003842, tar: 0.000014 
l0: 0.000006, l1: 0.000005, l2: 0.000050, l3: 0.000255, l4: 0.000590, l5: 0.001166, l6: 0.002083

[epoch: 921/1000, batch:   640/ 1052, ite: 242120] train loss: 0.003775, tar: 0.000014 
l0: 0.000003, l1: 0.000003, l2: 0.000019, l3: 0.000063, l4: 0.000301, l5: 0.001014, l6: 0.001454

[epoch: 921/1000, batch:   720/ 1052, ite: 242140] train loss: 0.003783, tar: 0.000014 
l0: 0.000022, l1: 0.000025, l2: 0.000035, l3: 0.000075, l4: 0.000419, l5: 0.000861, l6: 0.002001

[epoch: 921/1000, batch:   800/ 1052, ite: 242160] train loss: 0.003752, tar: 0.000015 
l0: 0.000013, l1: 0.000014, l2: 0.000031, l3: 0.000104, l4: 0.000327, l5: 0.001249, l6: 0.001444

[epoch: 921/1000, batch:   880/ 1052, ite: 242180] train loss: 0.003725, tar: 0.000015 
l0: 0.000004, l1: 0.000005, l2: 0.000074, l3: 0.000300, l4: 0.000648, l5: 0.001187, l6: 0.001908

[epoch: 921/1000, batch:   960/ 1052, ite: 242200] train loss: 0.003744, tar: 0.000015 
l0: 0.000036, l1: 0.000036, l2: 0.000072, l3: 0.000394, l4: 0.001116, l5: 0.002890, l6: 0.003520

[epoch: 921/1000, batch:  1040/ 1052, ite: 242220] train loss: 0.003776, tar: 0.000015 
[Epoch 921/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000004, l1: 0.000003, l2: 0.000008, l3: 0.000062, l4: 0.000146, l5: 0.000733, l6: 0.001616

[epoch: 922/1000, batch:    68/ 1052, ite: 242240] train loss: 0.003793, tar: 0.000015 
l0: 0.000049, l1: 0.000046, l2: 0.000073, l3: 0.000163, l4: 0.000491, l5: 0.000901, l6: 0.002272

[epoch: 922/1000, batch:   148/ 1052, ite: 242260] train loss: 0.003775, tar: 0.000015 
l0: 0.000004, l1: 0.000004, l2: 0.000042, l3: 0.000067, l4: 0.000185, l5: 0.000806, l6: 0.001154

[epoch: 922/1000, batch:   228/ 1052, ite: 242280] train loss: 0.003756, tar: 0.000016 
l0: 0.000001, l1: 0.000001, l2: 0.000008, l3: 0.000059, l4: 0.000324, l5: 0.000643, l6: 0.001550

[epoch: 922/1000, batch:   308/ 1052, ite: 242300] train loss: 0.003775, tar: 0.000016 
l0: 0.000003, l1: 0.000003, l2: 0.000025, l3: 0.000220, l4: 0.000378, l5: 0.001041, l6: 0.002326

[epoch: 922/1000, batch:   388/ 1052, ite: 242320] train loss: 0.003800, tar: 0.000016 
l0: 0.000141, l1: 0.000142, l2: 0.000185, l3: 0.000276, l4: 0.000475, l5: 0.000964, l6: 0.002224

[epoch: 922/1000, batch:   468/ 1052, ite: 242340] train loss: 0.003789, tar: 0.000016 
l0: 0.000010, l1: 0.000012, l2: 0.000017, l3: 0.000083, l4: 0.000226, l5: 0.000614, l6: 0.001511

[epoch: 922/1000, batch:   548/ 1052, ite: 242360] train loss: 0.003788, tar: 0.000016 
l0: 0.000005, l1: 0.000006, l2: 0.000127, l3: 0.000321, l4: 0.000607, l5: 0.001395, l6: 0.002745

[epoch: 922/1000, batch:   628/ 1052, ite: 242380] train loss: 0.003807, tar: 0.000016 
l0: 0.000007, l1: 0.000006, l2: 0.000045, l3: 0.000316, l4: 0.000677, l5: 0.000970, l6: 0.001710

[epoch: 922/1000, batch:   708/ 1052, ite: 242400] train loss: 0.003794, tar: 0.000016 
l0: 0.000004, l1: 0.000004, l2: 0.000020, l3: 0.000153, l4: 0.000439, l5: 0.000734, l6: 0.001504

[epoch: 922/1000, batch:   788/ 1052, ite: 242420] train loss: 0.003794, tar: 0.000016 
l0: 0.000018, l1: 0.000017, l2: 0.000076, l3: 0.000501, l4: 0.000832, l5: 0.001267, l6: 0.003069

[epoch: 922/1000, batch:   868/ 1052, ite: 242440] train loss: 0.003786, tar: 0.000016 
l0: 0.000013, l1: 0.000013, l2: 0.000025, l3: 0.000133, l4: 0.000395, l5: 0.000976, l6: 0.001246

[epoch: 922/1000, batch:   948/ 1052, ite: 242460] train loss: 0.003794, tar: 0.000016 
l0: 0.000000, l1: 0.000001, l2: 0.000002, l3: 0.000071, l4: 0.000348, l5: 0.000629, l6: 0.000744

[epoch: 922/1000, batch:  1028/ 1052, ite: 242480] train loss: 0.003787, tar: 0.000016 
[Epoch 922/1000] Test loss: 0.020, Test target loss: 0.004
l0: 0.000009, l1: 0.000013, l2: 0.000045, l3: 0.000201, l4: 0.000483, l5: 0.001608, l6: 0.002470

[epoch: 923/1000, batch:    56/ 1052, ite: 242500] train loss: 0.003778, tar: 0.000017 
l0: 0.000006, l1: 0.000006, l2: 0.000019, l3: 0.000108, l4: 0.000366, l5: 0.000736, l6: 0.001227

[epoch: 923/1000, batch:   136/ 1052, ite: 242520] train loss: 0.003762, tar: 0.000017 
l0: 0.000045, l1: 0.000045, l2: 0.000104, l3: 0.000209, l4: 0.000477, l5: 0.000823, l6: 0.001842

[epoch: 923/1000, batch:   216/ 1052, ite: 242540] train loss: 0.003785, tar: 0.000017 
l0: 0.000002, l1: 0.000003, l2: 0.000003, l3: 0.000036, l4: 0.000304, l5: 0.000509, l6: 0.001053

[epoch: 923/1000, batch:   296/ 1052, ite: 242560] train loss: 0.003779, tar: 0.000017 
l0: 0.000031, l1: 0.000031, l2: 0.000050, l3: 0.000250, l4: 0.000503, l5: 0.000839, l6: 0.001341

[epoch: 923/1000, batch:   376/ 1052, ite: 242580] train loss: 0.003771, tar: 0.000017 
l0: 0.000010, l1: 0.000010, l2: 0.000085, l3: 0.000365, l4: 0.000737, l5: 0.001048, l6: 0.003287

[epoch: 923/1000, batch:   456/ 1052, ite: 242600] train loss: 0.003772, tar: 0.000017 
l0: 0.000018, l1: 0.000020, l2: 0.000043, l3: 0.000163, l4: 0.000335, l5: 0.001434, l6: 0.002743

[epoch: 923/1000, batch:   536/ 1052, ite: 242620] train loss: 0.003776, tar: 0.000017 
l0: 0.000052, l1: 0.000047, l2: 0.000101, l3: 0.000165, l4: 0.000386, l5: 0.000986, l6: 0.001563

[epoch: 923/1000, batch:   616/ 1052, ite: 242640] train loss: 0.003778, tar: 0.000017 
l0: 0.000008, l1: 0.000008, l2: 0.000073, l3: 0.000182, l4: 0.000558, l5: 0.001026, l6: 0.001867

[epoch: 923/1000, batch:   696/ 1052, ite: 242660] train loss: 0.003780, tar: 0.000017 
l0: 0.000010, l1: 0.000013, l2: 0.000057, l3: 0.000216, l4: 0.000822, l5: 0.001888, l6: 0.003302

[epoch: 923/1000, batch:   776/ 1052, ite: 242680] train loss: 0.003783, tar: 0.000017 
l0: 0.000017, l1: 0.000017, l2: 0.000085, l3: 0.000318, l4: 0.000892, l5: 0.001990, l6: 0.002758

[epoch: 923/1000, batch:   856/ 1052, ite: 242700] train loss: 0.003796, tar: 0.000017 
l0: 0.000003, l1: 0.000003, l2: 0.000034, l3: 0.000127, l4: 0.000387, l5: 0.000977, l6: 0.001526

[epoch: 923/1000, batch:   936/ 1052, ite: 242720] train loss: 0.003780, tar: 0.000017 
l0: 0.000016, l1: 0.000015, l2: 0.000035, l3: 0.000161, l4: 0.000712, l5: 0.001189, l6: 0.003975

[epoch: 923/1000, batch:  1016/ 1052, ite: 242740] train loss: 0.003780, tar: 0.000017 
[Epoch 923/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000016, l1: 0.000015, l2: 0.000071, l3: 0.000177, l4: 0.000399, l5: 0.001332, l6: 0.002840

[epoch: 924/1000, batch:    44/ 1052, ite: 242760] train loss: 0.003787, tar: 0.000017 
l0: 0.000016, l1: 0.000012, l2: 0.000049, l3: 0.000248, l4: 0.000560, l5: 0.000908, l6: 0.002040

[epoch: 924/1000, batch:   124/ 1052, ite: 242780] train loss: 0.003784, tar: 0.000017 
l0: 0.000017, l1: 0.000015, l2: 0.000034, l3: 0.000129, l4: 0.000299, l5: 0.000801, l6: 0.001229

[epoch: 924/1000, batch:   204/ 1052, ite: 242800] train loss: 0.003787, tar: 0.000017 
l0: 0.000011, l1: 0.000011, l2: 0.000093, l3: 0.000308, l4: 0.000661, l5: 0.001189, l6: 0.001452

[epoch: 924/1000, batch:   284/ 1052, ite: 242820] train loss: 0.003775, tar: 0.000017 
l0: 0.000018, l1: 0.000020, l2: 0.000063, l3: 0.000206, l4: 0.000408, l5: 0.001305, l6: 0.002237

[epoch: 924/1000, batch:   364/ 1052, ite: 242840] train loss: 0.003776, tar: 0.000017 
l0: 0.000013, l1: 0.000012, l2: 0.000042, l3: 0.000145, l4: 0.000505, l5: 0.000875, l6: 0.001451

[epoch: 924/1000, batch:   444/ 1052, ite: 242860] train loss: 0.003774, tar: 0.000017 
l0: 0.000015, l1: 0.000016, l2: 0.000051, l3: 0.000141, l4: 0.000370, l5: 0.001315, l6: 0.002280

[epoch: 924/1000, batch:   524/ 1052, ite: 242880] train loss: 0.003783, tar: 0.000017 
l0: 0.000001, l1: 0.000001, l2: 0.000010, l3: 0.000090, l4: 0.000316, l5: 0.000529, l6: 0.001356

[epoch: 924/1000, batch:   604/ 1052, ite: 242900] train loss: 0.003784, tar: 0.000017 
l0: 0.000025, l1: 0.000025, l2: 0.000056, l3: 0.000228, l4: 0.000773, l5: 0.002275, l6: 0.003414

[epoch: 924/1000, batch:   684/ 1052, ite: 242920] train loss: 0.003790, tar: 0.000017 
l0: 0.000036, l1: 0.000040, l2: 0.000081, l3: 0.000350, l4: 0.001145, l5: 0.001872, l6: 0.004478

[epoch: 924/1000, batch:   764/ 1052, ite: 242940] train loss: 0.003794, tar: 0.000017 
l0: 0.000014, l1: 0.000017, l2: 0.000034, l3: 0.000120, l4: 0.000368, l5: 0.000929, l6: 0.001262

[epoch: 924/1000, batch:   844/ 1052, ite: 242960] train loss: 0.003787, tar: 0.000017 
l0: 0.000059, l1: 0.000059, l2: 0.000104, l3: 0.000208, l4: 0.000505, l5: 0.000734, l6: 0.001880

[epoch: 924/1000, batch:   924/ 1052, ite: 242980] train loss: 0.003791, tar: 0.000017 
l0: 0.000061, l1: 0.000057, l2: 0.000086, l3: 0.000093, l4: 0.000496, l5: 0.001660, l6: 0.002899

[epoch: 924/1000, batch:  1004/ 1052, ite: 243000] train loss: 0.003785, tar: 0.000018 
[Epoch 924/1000] Test loss: 0.024, Test target loss: 0.005
l0: 0.000001, l1: 0.000001, l2: 0.000012, l3: 0.000058, l4: 0.000218, l5: 0.000503, l6: 0.001074

[epoch: 925/1000, batch:    32/ 1052, ite: 243020] train loss: 0.003790, tar: 0.000018 
l0: 0.000013, l1: 0.000016, l2: 0.000046, l3: 0.000164, l4: 0.000329, l5: 0.000924, l6: 0.002030

[epoch: 925/1000, batch:   112/ 1052, ite: 243040] train loss: 0.003794, tar: 0.000018 
l0: 0.000025, l1: 0.000025, l2: 0.000034, l3: 0.000121, l4: 0.000416, l5: 0.000727, l6: 0.001886

[epoch: 925/1000, batch:   192/ 1052, ite: 243060] train loss: 0.003800, tar: 0.000018 
l0: 0.000029, l1: 0.000027, l2: 0.000080, l3: 0.000170, l4: 0.000331, l5: 0.000509, l6: 0.001557

[epoch: 925/1000, batch:   272/ 1052, ite: 243080] train loss: 0.003801, tar: 0.000018 
l0: 0.000002, l1: 0.000002, l2: 0.000032, l3: 0.000136, l4: 0.000355, l5: 0.000678, l6: 0.001295

[epoch: 925/1000, batch:   352/ 1052, ite: 243100] train loss: 0.003803, tar: 0.000018 
l0: 0.000016, l1: 0.000015, l2: 0.000037, l3: 0.000102, l4: 0.000118, l5: 0.000947, l6: 0.001179

[epoch: 925/1000, batch:   432/ 1052, ite: 243120] train loss: 0.003795, tar: 0.000018 
l0: 0.000001, l1: 0.000002, l2: 0.000015, l3: 0.000058, l4: 0.000283, l5: 0.000601, l6: 0.000869

[epoch: 925/1000, batch:   512/ 1052, ite: 243140] train loss: 0.003794, tar: 0.000018 
l0: 0.000005, l1: 0.000005, l2: 0.000018, l3: 0.000089, l4: 0.000306, l5: 0.000472, l6: 0.001539

[epoch: 925/1000, batch:   592/ 1052, ite: 243160] train loss: 0.003790, tar: 0.000018 
l0: 0.000025, l1: 0.000023, l2: 0.000066, l3: 0.000226, l4: 0.000550, l5: 0.001428, l6: 0.002628

[epoch: 925/1000, batch:   672/ 1052, ite: 243180] train loss: 0.003788, tar: 0.000018 
l0: 0.000012, l1: 0.000012, l2: 0.000045, l3: 0.000104, l4: 0.000189, l5: 0.000946, l6: 0.001656

[epoch: 925/1000, batch:   752/ 1052, ite: 243200] train loss: 0.003787, tar: 0.000018 
l0: 0.000054, l1: 0.000056, l2: 0.000060, l3: 0.000173, l4: 0.000330, l5: 0.000569, l6: 0.002221

[epoch: 925/1000, batch:   832/ 1052, ite: 243220] train loss: 0.003786, tar: 0.000018 
l0: 0.000029, l1: 0.000030, l2: 0.000074, l3: 0.000183, l4: 0.000536, l5: 0.001467, l6: 0.002914

[epoch: 925/1000, batch:   912/ 1052, ite: 243240] train loss: 0.003787, tar: 0.000018 
l0: 0.000005, l1: 0.000004, l2: 0.000041, l3: 0.000244, l4: 0.000688, l5: 0.001154, l6: 0.001461

[epoch: 925/1000, batch:   992/ 1052, ite: 243260] train loss: 0.003792, tar: 0.000018 
[Epoch 925/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000007, l1: 0.000005, l2: 0.000029, l3: 0.000118, l4: 0.000337, l5: 0.000766, l6: 0.001493

[epoch: 926/1000, batch:    20/ 1052, ite: 243280] train loss: 0.003790, tar: 0.000018 
l0: 0.000053, l1: 0.000052, l2: 0.000109, l3: 0.000266, l4: 0.000590, l5: 0.001141, l6: 0.002476

[epoch: 926/1000, batch:   100/ 1052, ite: 243300] train loss: 0.003787, tar: 0.000018 
l0: 0.000024, l1: 0.000028, l2: 0.000067, l3: 0.000258, l4: 0.000736, l5: 0.001534, l6: 0.002179

[epoch: 926/1000, batch:   180/ 1052, ite: 243320] train loss: 0.003786, tar: 0.000018 
l0: 0.000010, l1: 0.000009, l2: 0.000036, l3: 0.000192, l4: 0.000411, l5: 0.000900, l6: 0.001744

[epoch: 926/1000, batch:   260/ 1052, ite: 243340] train loss: 0.003785, tar: 0.000018 
l0: 0.000008, l1: 0.000009, l2: 0.000048, l3: 0.000162, l4: 0.000377, l5: 0.000914, l6: 0.001561

[epoch: 926/1000, batch:   340/ 1052, ite: 243360] train loss: 0.003782, tar: 0.000018 
l0: 0.000010, l1: 0.000010, l2: 0.000027, l3: 0.000089, l4: 0.000353, l5: 0.000768, l6: 0.002420

[epoch: 926/1000, batch:   420/ 1052, ite: 243380] train loss: 0.003783, tar: 0.000018 
l0: 0.000010, l1: 0.000011, l2: 0.000040, l3: 0.000191, l4: 0.000451, l5: 0.000990, l6: 0.002113

[epoch: 926/1000, batch:   500/ 1052, ite: 243400] train loss: 0.003787, tar: 0.000018 
l0: 0.000010, l1: 0.000010, l2: 0.000027, l3: 0.000167, l4: 0.000412, l5: 0.001042, l6: 0.001144

[epoch: 926/1000, batch:   580/ 1052, ite: 243420] train loss: 0.003786, tar: 0.000018 
l0: 0.000023, l1: 0.000024, l2: 0.000064, l3: 0.000214, l4: 0.000475, l5: 0.001837, l6: 0.003660

[epoch: 926/1000, batch:   660/ 1052, ite: 243440] train loss: 0.003787, tar: 0.000018 
l0: 0.000070, l1: 0.000068, l2: 0.000086, l3: 0.000244, l4: 0.000584, l5: 0.001431, l6: 0.003401

[epoch: 926/1000, batch:   740/ 1052, ite: 243460] train loss: 0.003792, tar: 0.000018 
l0: 0.000002, l1: 0.000003, l2: 0.000008, l3: 0.000050, l4: 0.000261, l5: 0.000517, l6: 0.000661

[epoch: 926/1000, batch:   820/ 1052, ite: 243480] train loss: 0.003785, tar: 0.000018 
l0: 0.000003, l1: 0.000004, l2: 0.000015, l3: 0.000214, l4: 0.000673, l5: 0.001168, l6: 0.002153

[epoch: 926/1000, batch:   900/ 1052, ite: 243500] train loss: 0.003785, tar: 0.000018 
l0: 0.000086, l1: 0.000080, l2: 0.000060, l3: 0.000172, l4: 0.000530, l5: 0.001079, l6: 0.002314

[epoch: 926/1000, batch:   980/ 1052, ite: 243520] train loss: 0.003795, tar: 0.000018 
[Epoch 926/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000004, l1: 0.000005, l2: 0.000020, l3: 0.000112, l4: 0.000344, l5: 0.000975, l6: 0.001377

[epoch: 927/1000, batch:     8/ 1052, ite: 243540] train loss: 0.003797, tar: 0.000018 
l0: 0.000010, l1: 0.000012, l2: 0.000025, l3: 0.000100, l4: 0.000654, l5: 0.001079, l6: 0.003802

[epoch: 927/1000, batch:    88/ 1052, ite: 243560] train loss: 0.003806, tar: 0.000018 
l0: 0.000047, l1: 0.000045, l2: 0.000067, l3: 0.000165, l4: 0.000475, l5: 0.001100, l6: 0.003072

[epoch: 927/1000, batch:   168/ 1052, ite: 243580] train loss: 0.003807, tar: 0.000019 
l0: 0.000008, l1: 0.000011, l2: 0.000025, l3: 0.000071, l4: 0.000146, l5: 0.001057, l6: 0.001419

[epoch: 927/1000, batch:   248/ 1052, ite: 243600] train loss: 0.003807, tar: 0.000019 
l0: 0.000001, l1: 0.000001, l2: 0.000037, l3: 0.000068, l4: 0.000342, l5: 0.000753, l6: 0.001357

[epoch: 927/1000, batch:   328/ 1052, ite: 243620] train loss: 0.003802, tar: 0.000018 
l0: 0.000000, l1: 0.000000, l2: 0.000006, l3: 0.000049, l4: 0.000133, l5: 0.001155, l6: 0.002404

[epoch: 927/1000, batch:   408/ 1052, ite: 243640] train loss: 0.003804, tar: 0.000018 
l0: 0.000005, l1: 0.000007, l2: 0.000025, l3: 0.000074, l4: 0.000506, l5: 0.000581, l6: 0.001747

[epoch: 927/1000, batch:   488/ 1052, ite: 243660] train loss: 0.003809, tar: 0.000018 
l0: 0.000012, l1: 0.000013, l2: 0.000033, l3: 0.000188, l4: 0.000389, l5: 0.001256, l6: 0.001492

[epoch: 927/1000, batch:   568/ 1052, ite: 243680] train loss: 0.003807, tar: 0.000018 
l0: 0.000014, l1: 0.000013, l2: 0.000049, l3: 0.000138, l4: 0.000502, l5: 0.000972, l6: 0.001369

[epoch: 927/1000, batch:   648/ 1052, ite: 243700] train loss: 0.003807, tar: 0.000018 
l0: 0.000001, l1: 0.000002, l2: 0.000014, l3: 0.000066, l4: 0.000424, l5: 0.000923, l6: 0.001408

[epoch: 927/1000, batch:   728/ 1052, ite: 243720] train loss: 0.003801, tar: 0.000018 
l0: 0.000006, l1: 0.000005, l2: 0.000015, l3: 0.000100, l4: 0.000584, l5: 0.001117, l6: 0.001502

[epoch: 927/1000, batch:   808/ 1052, ite: 243740] train loss: 0.003800, tar: 0.000018 
l0: 0.000010, l1: 0.000009, l2: 0.000040, l3: 0.000065, l4: 0.000449, l5: 0.000910, l6: 0.001377

[epoch: 927/1000, batch:   888/ 1052, ite: 243760] train loss: 0.003801, tar: 0.000018 
l0: 0.000016, l1: 0.000019, l2: 0.000032, l3: 0.000064, l4: 0.000284, l5: 0.000793, l6: 0.002387

[epoch: 927/1000, batch:   968/ 1052, ite: 243780] train loss: 0.003802, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000033, l3: 0.000103, l4: 0.000253, l5: 0.000919, l6: 0.001422

[epoch: 927/1000, batch:  1048/ 1052, ite: 243800] train loss: 0.003798, tar: 0.000019 
[Epoch 927/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000020, l1: 0.000020, l2: 0.000032, l3: 0.000087, l4: 0.000281, l5: 0.000822, l6: 0.001201

[epoch: 928/1000, batch:    76/ 1052, ite: 243820] train loss: 0.003793, tar: 0.000019 
l0: 0.000032, l1: 0.000035, l2: 0.000036, l3: 0.000118, l4: 0.000278, l5: 0.001197, l6: 0.000902

[epoch: 928/1000, batch:   156/ 1052, ite: 243840] train loss: 0.003787, tar: 0.000019 
l0: 0.000023, l1: 0.000022, l2: 0.000050, l3: 0.000185, l4: 0.000511, l5: 0.001232, l6: 0.002300

[epoch: 928/1000, batch:   236/ 1052, ite: 243860] train loss: 0.003789, tar: 0.000019 
l0: 0.000061, l1: 0.000067, l2: 0.000057, l3: 0.000224, l4: 0.000403, l5: 0.001271, l6: 0.003043

[epoch: 928/1000, batch:   316/ 1052, ite: 243880] train loss: 0.003792, tar: 0.000019 
l0: 0.000012, l1: 0.000012, l2: 0.000059, l3: 0.000195, l4: 0.000673, l5: 0.001347, l6: 0.002783

[epoch: 928/1000, batch:   396/ 1052, ite: 243900] train loss: 0.003794, tar: 0.000019 
l0: 0.000030, l1: 0.000027, l2: 0.000071, l3: 0.000205, l4: 0.000674, l5: 0.001331, l6: 0.002457

[epoch: 928/1000, batch:   476/ 1052, ite: 243920] train loss: 0.003792, tar: 0.000019 
l0: 0.000024, l1: 0.000022, l2: 0.000122, l3: 0.000385, l4: 0.000920, l5: 0.001632, l6: 0.003034

[epoch: 928/1000, batch:   556/ 1052, ite: 243940] train loss: 0.003794, tar: 0.000019 
l0: 0.000030, l1: 0.000032, l2: 0.000051, l3: 0.000136, l4: 0.000386, l5: 0.001239, l6: 0.001892

[epoch: 928/1000, batch:   636/ 1052, ite: 243960] train loss: 0.003792, tar: 0.000019 
l0: 0.000011, l1: 0.000011, l2: 0.000071, l3: 0.000247, l4: 0.000715, l5: 0.001879, l6: 0.003488

[epoch: 928/1000, batch:   716/ 1052, ite: 243980] train loss: 0.003795, tar: 0.000019 
l0: 0.000033, l1: 0.000035, l2: 0.000048, l3: 0.000142, l4: 0.000442, l5: 0.000477, l6: 0.002227

[epoch: 928/1000, batch:   796/ 1052, ite: 244000] train loss: 0.003798, tar: 0.000019 
l0: 0.000003, l1: 0.000004, l2: 0.000026, l3: 0.000058, l4: 0.000310, l5: 0.000696, l6: 0.001864

[epoch: 928/1000, batch:   876/ 1052, ite: 244020] train loss: 0.003800, tar: 0.000019 
l0: 0.000027, l1: 0.000027, l2: 0.000072, l3: 0.000163, l4: 0.000305, l5: 0.001065, l6: 0.002722

[epoch: 928/1000, batch:   956/ 1052, ite: 244040] train loss: 0.003799, tar: 0.000019 
l0: 0.000152, l1: 0.000145, l2: 0.000226, l3: 0.000361, l4: 0.000523, l5: 0.000826, l6: 0.002230

[epoch: 928/1000, batch:  1036/ 1052, ite: 244060] train loss: 0.003799, tar: 0.000019 
[Epoch 928/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000056, l1: 0.000057, l2: 0.000107, l3: 0.000440, l4: 0.000690, l5: 0.001434, l6: 0.002196

[epoch: 929/1000, batch:    64/ 1052, ite: 244080] train loss: 0.003803, tar: 0.000019 
l0: 0.000018, l1: 0.000020, l2: 0.000056, l3: 0.000151, l4: 0.000331, l5: 0.000995, l6: 0.002052

[epoch: 929/1000, batch:   144/ 1052, ite: 244100] train loss: 0.003800, tar: 0.000019 
l0: 0.000005, l1: 0.000004, l2: 0.000018, l3: 0.000104, l4: 0.000289, l5: 0.000789, l6: 0.001285

[epoch: 929/1000, batch:   224/ 1052, ite: 244120] train loss: 0.003800, tar: 0.000019 
l0: 0.000037, l1: 0.000036, l2: 0.000175, l3: 0.000764, l4: 0.001581, l5: 0.002528, l6: 0.005119

[epoch: 929/1000, batch:   304/ 1052, ite: 244140] train loss: 0.003798, tar: 0.000019 
l0: 0.000005, l1: 0.000006, l2: 0.000045, l3: 0.000171, l4: 0.000627, l5: 0.000995, l6: 0.002186

[epoch: 929/1000, batch:   384/ 1052, ite: 244160] train loss: 0.003798, tar: 0.000019 
l0: 0.000082, l1: 0.000080, l2: 0.000126, l3: 0.000137, l4: 0.000454, l5: 0.001040, l6: 0.002245

[epoch: 929/1000, batch:   464/ 1052, ite: 244180] train loss: 0.003800, tar: 0.000019 
l0: 0.000001, l1: 0.000001, l2: 0.000010, l3: 0.000018, l4: 0.000213, l5: 0.000249, l6: 0.000585

[epoch: 929/1000, batch:   544/ 1052, ite: 244200] train loss: 0.003804, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000053, l3: 0.000128, l4: 0.000551, l5: 0.001520, l6: 0.001744

[epoch: 929/1000, batch:   624/ 1052, ite: 244220] train loss: 0.003804, tar: 0.000019 
l0: 0.000013, l1: 0.000012, l2: 0.000027, l3: 0.000074, l4: 0.000315, l5: 0.000799, l6: 0.001935

[epoch: 929/1000, batch:   704/ 1052, ite: 244240] train loss: 0.003802, tar: 0.000019 
l0: 0.000008, l1: 0.000009, l2: 0.000047, l3: 0.000162, l4: 0.000399, l5: 0.001336, l6: 0.002072

[epoch: 929/1000, batch:   784/ 1052, ite: 244260] train loss: 0.003805, tar: 0.000019 
l0: 0.000007, l1: 0.000008, l2: 0.000043, l3: 0.000242, l4: 0.000711, l5: 0.001594, l6: 0.003550

[epoch: 929/1000, batch:   864/ 1052, ite: 244280] train loss: 0.003806, tar: 0.000019 
l0: 0.000005, l1: 0.000006, l2: 0.000017, l3: 0.000090, l4: 0.000224, l5: 0.001233, l6: 0.000828

[epoch: 929/1000, batch:   944/ 1052, ite: 244300] train loss: 0.003803, tar: 0.000019 
l0: 0.000011, l1: 0.000011, l2: 0.000044, l3: 0.000200, l4: 0.000616, l5: 0.001237, l6: 0.002613

[epoch: 929/1000, batch:  1024/ 1052, ite: 244320] train loss: 0.003803, tar: 0.000019 
[Epoch 929/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000005, l1: 0.000005, l2: 0.000035, l3: 0.000136, l4: 0.000381, l5: 0.001007, l6: 0.001190

[epoch: 930/1000, batch:    52/ 1052, ite: 244340] train loss: 0.003799, tar: 0.000019 
l0: 0.000049, l1: 0.000046, l2: 0.000171, l3: 0.000346, l4: 0.001094, l5: 0.002225, l6: 0.003262

[epoch: 930/1000, batch:   132/ 1052, ite: 244360] train loss: 0.003801, tar: 0.000019 
l0: 0.000019, l1: 0.000017, l2: 0.000091, l3: 0.000399, l4: 0.001053, l5: 0.002675, l6: 0.003879

[epoch: 930/1000, batch:   212/ 1052, ite: 244380] train loss: 0.003803, tar: 0.000019 
l0: 0.000012, l1: 0.000012, l2: 0.000039, l3: 0.000125, l4: 0.000179, l5: 0.000817, l6: 0.001714

[epoch: 930/1000, batch:   292/ 1052, ite: 244400] train loss: 0.003804, tar: 0.000019 
l0: 0.000034, l1: 0.000032, l2: 0.000070, l3: 0.000157, l4: 0.000257, l5: 0.001033, l6: 0.001337

[epoch: 930/1000, batch:   372/ 1052, ite: 244420] train loss: 0.003802, tar: 0.000019 
l0: 0.000032, l1: 0.000029, l2: 0.000064, l3: 0.000277, l4: 0.000455, l5: 0.001446, l6: 0.002575

[epoch: 930/1000, batch:   452/ 1052, ite: 244440] train loss: 0.003799, tar: 0.000019 
l0: 0.000006, l1: 0.000007, l2: 0.000022, l3: 0.000105, l4: 0.000317, l5: 0.000622, l6: 0.001871

[epoch: 930/1000, batch:   532/ 1052, ite: 244460] train loss: 0.003801, tar: 0.000019 
l0: 0.000003, l1: 0.000004, l2: 0.000027, l3: 0.000113, l4: 0.000540, l5: 0.001664, l6: 0.002628

[epoch: 930/1000, batch:   612/ 1052, ite: 244480] train loss: 0.003800, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000026, l3: 0.000062, l4: 0.000155, l5: 0.000850, l6: 0.001276

[epoch: 930/1000, batch:   692/ 1052, ite: 244500] train loss: 0.003800, tar: 0.000019 
l0: 0.000004, l1: 0.000006, l2: 0.000039, l3: 0.000201, l4: 0.000518, l5: 0.001180, l6: 0.002291

[epoch: 930/1000, batch:   772/ 1052, ite: 244520] train loss: 0.003801, tar: 0.000019 
l0: 0.000017, l1: 0.000018, l2: 0.000031, l3: 0.000051, l4: 0.000137, l5: 0.000789, l6: 0.001153

[epoch: 930/1000, batch:   852/ 1052, ite: 244540] train loss: 0.003801, tar: 0.000019 
l0: 0.000027, l1: 0.000025, l2: 0.000055, l3: 0.000161, l4: 0.000484, l5: 0.000995, l6: 0.001342

[epoch: 930/1000, batch:   932/ 1052, ite: 244560] train loss: 0.003798, tar: 0.000019 
l0: 0.000009, l1: 0.000010, l2: 0.000043, l3: 0.000176, l4: 0.000718, l5: 0.001476, l6: 0.002193

[epoch: 930/1000, batch:  1012/ 1052, ite: 244580] train loss: 0.003796, tar: 0.000019 
[Epoch 930/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000015, l1: 0.000020, l2: 0.000036, l3: 0.000126, l4: 0.000645, l5: 0.001344, l6: 0.001759

[epoch: 931/1000, batch:    40/ 1052, ite: 244600] train loss: 0.003794, tar: 0.000019 
l0: 0.000039, l1: 0.000043, l2: 0.000052, l3: 0.000128, l4: 0.000402, l5: 0.001184, l6: 0.002187

[epoch: 931/1000, batch:   120/ 1052, ite: 244620] train loss: 0.003796, tar: 0.000019 
l0: 0.000016, l1: 0.000017, l2: 0.000040, l3: 0.000100, l4: 0.000264, l5: 0.000952, l6: 0.001557

[epoch: 931/1000, batch:   200/ 1052, ite: 244640] train loss: 0.003794, tar: 0.000019 
l0: 0.000020, l1: 0.000020, l2: 0.000138, l3: 0.000329, l4: 0.000705, l5: 0.001066, l6: 0.002026

[epoch: 931/1000, batch:   280/ 1052, ite: 244660] train loss: 0.003794, tar: 0.000019 
l0: 0.000074, l1: 0.000081, l2: 0.000082, l3: 0.000208, l4: 0.000484, l5: 0.001053, l6: 0.002827

[epoch: 931/1000, batch:   360/ 1052, ite: 244680] train loss: 0.003800, tar: 0.000019 
l0: 0.000006, l1: 0.000006, l2: 0.000023, l3: 0.000148, l4: 0.000396, l5: 0.001325, l6: 0.002226

[epoch: 931/1000, batch:   440/ 1052, ite: 244700] train loss: 0.003804, tar: 0.000020 
l0: 0.000042, l1: 0.000038, l2: 0.000057, l3: 0.000146, l4: 0.000376, l5: 0.001484, l6: 0.002874

[epoch: 931/1000, batch:   520/ 1052, ite: 244720] train loss: 0.003806, tar: 0.000020 
l0: 0.000007, l1: 0.000007, l2: 0.000018, l3: 0.000048, l4: 0.000237, l5: 0.000613, l6: 0.001548

[epoch: 931/1000, batch:   600/ 1052, ite: 244740] train loss: 0.003804, tar: 0.000020 
l0: 0.000025, l1: 0.000027, l2: 0.000053, l3: 0.000259, l4: 0.000637, l5: 0.001407, l6: 0.001286

[epoch: 931/1000, batch:   680/ 1052, ite: 244760] train loss: 0.003801, tar: 0.000019 
l0: 0.000001, l1: 0.000001, l2: 0.000007, l3: 0.000040, l4: 0.000157, l5: 0.000487, l6: 0.001056

[epoch: 931/1000, batch:   760/ 1052, ite: 244780] train loss: 0.003800, tar: 0.000019 
l0: 0.000007, l1: 0.000007, l2: 0.000019, l3: 0.000081, l4: 0.000276, l5: 0.000740, l6: 0.000881

[epoch: 931/1000, batch:   840/ 1052, ite: 244800] train loss: 0.003801, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000019, l3: 0.000117, l4: 0.000283, l5: 0.000628, l6: 0.001482

[epoch: 931/1000, batch:   920/ 1052, ite: 244820] train loss: 0.003800, tar: 0.000019 
l0: 0.000010, l1: 0.000009, l2: 0.000041, l3: 0.000149, l4: 0.000306, l5: 0.000955, l6: 0.001708

[epoch: 931/1000, batch:  1000/ 1052, ite: 244840] train loss: 0.003803, tar: 0.000019 
[Epoch 931/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000035, l1: 0.000039, l2: 0.000037, l3: 0.000136, l4: 0.000466, l5: 0.000983, l6: 0.001874

[epoch: 932/1000, batch:    28/ 1052, ite: 244860] train loss: 0.003800, tar: 0.000019 
l0: 0.000022, l1: 0.000025, l2: 0.000036, l3: 0.000162, l4: 0.000372, l5: 0.001053, l6: 0.001250

[epoch: 932/1000, batch:   108/ 1052, ite: 244880] train loss: 0.003797, tar: 0.000019 
l0: 0.000033, l1: 0.000037, l2: 0.000091, l3: 0.000332, l4: 0.001045, l5: 0.002280, l6: 0.005011

[epoch: 932/1000, batch:   188/ 1052, ite: 244900] train loss: 0.003801, tar: 0.000019 
l0: 0.000000, l1: 0.000001, l2: 0.000017, l3: 0.000075, l4: 0.000217, l5: 0.000733, l6: 0.000894

[epoch: 932/1000, batch:   268/ 1052, ite: 244920] train loss: 0.003798, tar: 0.000019 
l0: 0.000018, l1: 0.000022, l2: 0.000056, l3: 0.000252, l4: 0.000668, l5: 0.001131, l6: 0.002318

[epoch: 932/1000, batch:   348/ 1052, ite: 244940] train loss: 0.003797, tar: 0.000019 
l0: 0.000036, l1: 0.000034, l2: 0.000161, l3: 0.000321, l4: 0.000826, l5: 0.001595, l6: 0.002313

[epoch: 932/1000, batch:   428/ 1052, ite: 244960] train loss: 0.003799, tar: 0.000019 
l0: 0.000001, l1: 0.000001, l2: 0.000010, l3: 0.000060, l4: 0.000323, l5: 0.000434, l6: 0.001039

[epoch: 932/1000, batch:   508/ 1052, ite: 244980] train loss: 0.003800, tar: 0.000019 
l0: 0.000014, l1: 0.000016, l2: 0.000040, l3: 0.000124, l4: 0.000348, l5: 0.000720, l6: 0.000996

[epoch: 932/1000, batch:   588/ 1052, ite: 245000] train loss: 0.003800, tar: 0.000019 
l0: 0.000016, l1: 0.000014, l2: 0.000065, l3: 0.000151, l4: 0.000247, l5: 0.000796, l6: 0.001619

[epoch: 932/1000, batch:   668/ 1052, ite: 245020] train loss: 0.003799, tar: 0.000019 
l0: 0.000017, l1: 0.000015, l2: 0.000042, l3: 0.000136, l4: 0.000405, l5: 0.001260, l6: 0.002006

[epoch: 932/1000, batch:   748/ 1052, ite: 245040] train loss: 0.003797, tar: 0.000019 
l0: 0.000001, l1: 0.000001, l2: 0.000034, l3: 0.000183, l4: 0.000356, l5: 0.001112, l6: 0.001314

[epoch: 932/1000, batch:   828/ 1052, ite: 245060] train loss: 0.003798, tar: 0.000019 
l0: 0.000024, l1: 0.000029, l2: 0.000017, l3: 0.000058, l4: 0.000355, l5: 0.000910, l6: 0.001543

[epoch: 932/1000, batch:   908/ 1052, ite: 245080] train loss: 0.003797, tar: 0.000019 
l0: 0.000008, l1: 0.000010, l2: 0.000027, l3: 0.000113, l4: 0.000517, l5: 0.000714, l6: 0.001982

[epoch: 932/1000, batch:   988/ 1052, ite: 245100] train loss: 0.003796, tar: 0.000019 
[Epoch 932/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000037, l1: 0.000033, l2: 0.000042, l3: 0.000251, l4: 0.000331, l5: 0.001032, l6: 0.001847

[epoch: 933/1000, batch:    16/ 1052, ite: 245120] train loss: 0.003795, tar: 0.000019 
l0: 0.000070, l1: 0.000071, l2: 0.000124, l3: 0.000179, l4: 0.000477, l5: 0.001161, l6: 0.001381

[epoch: 933/1000, batch:    96/ 1052, ite: 245140] train loss: 0.003793, tar: 0.000019 
l0: 0.000011, l1: 0.000015, l2: 0.000030, l3: 0.000113, l4: 0.000302, l5: 0.000527, l6: 0.001238

[epoch: 933/1000, batch:   176/ 1052, ite: 245160] train loss: 0.003793, tar: 0.000019 
l0: 0.000003, l1: 0.000004, l2: 0.000014, l3: 0.000073, l4: 0.000239, l5: 0.000889, l6: 0.001542

[epoch: 933/1000, batch:   256/ 1052, ite: 245180] train loss: 0.003792, tar: 0.000019 
l0: 0.000006, l1: 0.000006, l2: 0.000040, l3: 0.000172, l4: 0.000337, l5: 0.000652, l6: 0.001364

[epoch: 933/1000, batch:   336/ 1052, ite: 245200] train loss: 0.003793, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000097, l3: 0.000251, l4: 0.000467, l5: 0.001094, l6: 0.002351

[epoch: 933/1000, batch:   416/ 1052, ite: 245220] train loss: 0.003795, tar: 0.000019 
l0: 0.000005, l1: 0.000005, l2: 0.000011, l3: 0.000032, l4: 0.000155, l5: 0.000454, l6: 0.000804

[epoch: 933/1000, batch:   496/ 1052, ite: 245240] train loss: 0.003793, tar: 0.000019 
l0: 0.000008, l1: 0.000008, l2: 0.000042, l3: 0.000175, l4: 0.000465, l5: 0.001596, l6: 0.003168

[epoch: 933/1000, batch:   576/ 1052, ite: 245260] train loss: 0.003795, tar: 0.000019 
l0: 0.000046, l1: 0.000036, l2: 0.000052, l3: 0.000106, l4: 0.000329, l5: 0.000574, l6: 0.001675

[epoch: 933/1000, batch:   656/ 1052, ite: 245280] train loss: 0.003798, tar: 0.000019 
l0: 0.000025, l1: 0.000029, l2: 0.000028, l3: 0.000087, l4: 0.000370, l5: 0.000556, l6: 0.001249

[epoch: 933/1000, batch:   736/ 1052, ite: 245300] train loss: 0.003798, tar: 0.000019 
l0: 0.000007, l1: 0.000008, l2: 0.000038, l3: 0.000252, l4: 0.000536, l5: 0.001061, l6: 0.002349

[epoch: 933/1000, batch:   816/ 1052, ite: 245320] train loss: 0.003798, tar: 0.000019 
l0: 0.000076, l1: 0.000071, l2: 0.000134, l3: 0.000263, l4: 0.000657, l5: 0.001994, l6: 0.003377

[epoch: 933/1000, batch:   896/ 1052, ite: 245340] train loss: 0.003798, tar: 0.000019 
l0: 0.000045, l1: 0.000041, l2: 0.000131, l3: 0.000301, l4: 0.000769, l5: 0.001222, l6: 0.002655

[epoch: 933/1000, batch:   976/ 1052, ite: 245360] train loss: 0.003801, tar: 0.000019 
[Epoch 933/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000010, l1: 0.000013, l2: 0.000056, l3: 0.000387, l4: 0.000801, l5: 0.001566, l6: 0.002236

[epoch: 934/1000, batch:     4/ 1052, ite: 245380] train loss: 0.003799, tar: 0.000019 
l0: 0.000016, l1: 0.000017, l2: 0.000016, l3: 0.000109, l4: 0.000447, l5: 0.000869, l6: 0.001248

[epoch: 934/1000, batch:    84/ 1052, ite: 245400] train loss: 0.003797, tar: 0.000019 
l0: 0.000017, l1: 0.000017, l2: 0.000049, l3: 0.000165, l4: 0.000380, l5: 0.001261, l6: 0.002618

[epoch: 934/1000, batch:   164/ 1052, ite: 245420] train loss: 0.003799, tar: 0.000019 
l0: 0.000050, l1: 0.000053, l2: 0.000089, l3: 0.000215, l4: 0.000649, l5: 0.001603, l6: 0.002637

[epoch: 934/1000, batch:   244/ 1052, ite: 245440] train loss: 0.003800, tar: 0.000019 
l0: 0.000008, l1: 0.000008, l2: 0.000026, l3: 0.000103, l4: 0.000460, l5: 0.001079, l6: 0.001511

[epoch: 934/1000, batch:   324/ 1052, ite: 245460] train loss: 0.003805, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000023, l3: 0.000081, l4: 0.000319, l5: 0.001052, l6: 0.001947

[epoch: 934/1000, batch:   404/ 1052, ite: 245480] train loss: 0.003803, tar: 0.000019 
l0: 0.000008, l1: 0.000008, l2: 0.000059, l3: 0.000213, l4: 0.000628, l5: 0.001066, l6: 0.002586

[epoch: 934/1000, batch:   484/ 1052, ite: 245500] train loss: 0.003801, tar: 0.000019 
l0: 0.000011, l1: 0.000011, l2: 0.000034, l3: 0.000138, l4: 0.000302, l5: 0.000781, l6: 0.001662

[epoch: 934/1000, batch:   564/ 1052, ite: 245520] train loss: 0.003799, tar: 0.000019 
l0: 0.000011, l1: 0.000012, l2: 0.000066, l3: 0.000293, l4: 0.000753, l5: 0.001485, l6: 0.002687

[epoch: 934/1000, batch:   644/ 1052, ite: 245540] train loss: 0.003802, tar: 0.000019 
l0: 0.000004, l1: 0.000004, l2: 0.000012, l3: 0.000093, l4: 0.000256, l5: 0.000777, l6: 0.001311

[epoch: 934/1000, batch:   724/ 1052, ite: 245560] train loss: 0.003800, tar: 0.000019 
l0: 0.000026, l1: 0.000025, l2: 0.000073, l3: 0.000346, l4: 0.000683, l5: 0.001343, l6: 0.002180

[epoch: 934/1000, batch:   804/ 1052, ite: 245580] train loss: 0.003803, tar: 0.000019 
l0: 0.000009, l1: 0.000009, l2: 0.000023, l3: 0.000103, l4: 0.000297, l5: 0.000799, l6: 0.000968

[epoch: 934/1000, batch:   884/ 1052, ite: 245600] train loss: 0.003801, tar: 0.000019 
l0: 0.000007, l1: 0.000008, l2: 0.000050, l3: 0.000223, l4: 0.000569, l5: 0.001218, l6: 0.001850

[epoch: 934/1000, batch:   964/ 1052, ite: 245620] train loss: 0.003800, tar: 0.000019 
l0: 0.000007, l1: 0.000009, l2: 0.000079, l3: 0.000158, l4: 0.000390, l5: 0.000767, l6: 0.001622

[epoch: 934/1000, batch:  1044/ 1052, ite: 245640] train loss: 0.003799, tar: 0.000019 
[Epoch 934/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000002, l1: 0.000003, l2: 0.000012, l3: 0.000091, l4: 0.000311, l5: 0.001036, l6: 0.001807

[epoch: 935/1000, batch:    72/ 1052, ite: 245660] train loss: 0.003801, tar: 0.000019 
l0: 0.000025, l1: 0.000026, l2: 0.000042, l3: 0.000057, l4: 0.000170, l5: 0.000854, l6: 0.001370

[epoch: 935/1000, batch:   152/ 1052, ite: 245680] train loss: 0.003800, tar: 0.000019 
l0: 0.000007, l1: 0.000008, l2: 0.000018, l3: 0.000067, l4: 0.000394, l5: 0.000757, l6: 0.000689

[epoch: 935/1000, batch:   232/ 1052, ite: 245700] train loss: 0.003801, tar: 0.000019 
l0: 0.000070, l1: 0.000070, l2: 0.000101, l3: 0.000435, l4: 0.000845, l5: 0.001385, l6: 0.002807

[epoch: 935/1000, batch:   312/ 1052, ite: 245720] train loss: 0.003801, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000010, l3: 0.000092, l4: 0.000361, l5: 0.000586, l6: 0.001846

[epoch: 935/1000, batch:   392/ 1052, ite: 245740] train loss: 0.003802, tar: 0.000019 
l0: 0.000013, l1: 0.000014, l2: 0.000060, l3: 0.000177, l4: 0.000315, l5: 0.000793, l6: 0.001206

[epoch: 935/1000, batch:   472/ 1052, ite: 245760] train loss: 0.003802, tar: 0.000020 
l0: 0.000009, l1: 0.000010, l2: 0.000024, l3: 0.000145, l4: 0.000345, l5: 0.000846, l6: 0.002337

[epoch: 935/1000, batch:   552/ 1052, ite: 245780] train loss: 0.003803, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000042, l3: 0.000170, l4: 0.000526, l5: 0.001187, l6: 0.002553

[epoch: 935/1000, batch:   632/ 1052, ite: 245800] train loss: 0.003802, tar: 0.000020 
l0: 0.000005, l1: 0.000004, l2: 0.000032, l3: 0.000161, l4: 0.000384, l5: 0.000705, l6: 0.001310

[epoch: 935/1000, batch:   712/ 1052, ite: 245820] train loss: 0.003804, tar: 0.000020 
l0: 0.000021, l1: 0.000020, l2: 0.000083, l3: 0.000239, l4: 0.000488, l5: 0.001155, l6: 0.002189

[epoch: 935/1000, batch:   792/ 1052, ite: 245840] train loss: 0.003805, tar: 0.000020 
l0: 0.000029, l1: 0.000029, l2: 0.000083, l3: 0.000243, l4: 0.000733, l5: 0.001004, l6: 0.002289

[epoch: 935/1000, batch:   872/ 1052, ite: 245860] train loss: 0.003805, tar: 0.000020 
l0: 0.000049, l1: 0.000048, l2: 0.000121, l3: 0.000409, l4: 0.000814, l5: 0.001731, l6: 0.003138

[epoch: 935/1000, batch:   952/ 1052, ite: 245880] train loss: 0.003805, tar: 0.000020 
l0: 0.000009, l1: 0.000007, l2: 0.000035, l3: 0.000077, l4: 0.000222, l5: 0.000668, l6: 0.001632

[epoch: 935/1000, batch:  1032/ 1052, ite: 245900] train loss: 0.003805, tar: 0.000020 
[Epoch 935/1000] Test loss: 0.024, Test target loss: 0.004
l0: 0.000006, l1: 0.000005, l2: 0.000056, l3: 0.000287, l4: 0.000543, l5: 0.001294, l6: 0.003067

[epoch: 936/1000, batch:    60/ 1052, ite: 245920] train loss: 0.003804, tar: 0.000020 
l0: 0.000021, l1: 0.000020, l2: 0.000073, l3: 0.000181, l4: 0.000432, l5: 0.001285, l6: 0.001914

[epoch: 936/1000, batch:   140/ 1052, ite: 245940] train loss: 0.003805, tar: 0.000020 
l0: 0.000011, l1: 0.000010, l2: 0.000042, l3: 0.000162, l4: 0.000339, l5: 0.000639, l6: 0.001180

[epoch: 936/1000, batch:   220/ 1052, ite: 245960] train loss: 0.003805, tar: 0.000020 
l0: 0.000016, l1: 0.000016, l2: 0.000055, l3: 0.000215, l4: 0.000530, l5: 0.001362, l6: 0.002285

[epoch: 936/1000, batch:   300/ 1052, ite: 245980] train loss: 0.003802, tar: 0.000020 
l0: 0.000005, l1: 0.000006, l2: 0.000018, l3: 0.000201, l4: 0.000728, l5: 0.001309, l6: 0.001636

[epoch: 936/1000, batch:   380/ 1052, ite: 246000] train loss: 0.003803, tar: 0.000020 
l0: 0.000050, l1: 0.000047, l2: 0.000097, l3: 0.000199, l4: 0.000525, l5: 0.001160, l6: 0.002703

[epoch: 936/1000, batch:   460/ 1052, ite: 246020] train loss: 0.003804, tar: 0.000020 
l0: 0.000010, l1: 0.000010, l2: 0.000034, l3: 0.000166, l4: 0.000394, l5: 0.000985, l6: 0.001599

[epoch: 936/1000, batch:   540/ 1052, ite: 246040] train loss: 0.003804, tar: 0.000020 
l0: 0.000051, l1: 0.000049, l2: 0.000148, l3: 0.000314, l4: 0.000713, l5: 0.001031, l6: 0.003825

[epoch: 936/1000, batch:   620/ 1052, ite: 246060] train loss: 0.003805, tar: 0.000020 
l0: 0.000027, l1: 0.000027, l2: 0.000053, l3: 0.000149, l4: 0.000313, l5: 0.000953, l6: 0.002422

[epoch: 936/1000, batch:   700/ 1052, ite: 246080] train loss: 0.003803, tar: 0.000020 
l0: 0.000047, l1: 0.000046, l2: 0.000068, l3: 0.000129, l4: 0.000358, l5: 0.000756, l6: 0.001186

[epoch: 936/1000, batch:   780/ 1052, ite: 246100] train loss: 0.003801, tar: 0.000020 
l0: 0.000016, l1: 0.000015, l2: 0.000064, l3: 0.000415, l4: 0.001080, l5: 0.002012, l6: 0.002314

[epoch: 936/1000, batch:   860/ 1052, ite: 246120] train loss: 0.003801, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000020, l3: 0.000134, l4: 0.000339, l5: 0.000816, l6: 0.001263

[epoch: 936/1000, batch:   940/ 1052, ite: 246140] train loss: 0.003800, tar: 0.000020 
l0: 0.000025, l1: 0.000025, l2: 0.000045, l3: 0.000102, l4: 0.000372, l5: 0.000919, l6: 0.001875

[epoch: 936/1000, batch:  1020/ 1052, ite: 246160] train loss: 0.003804, tar: 0.000020 
[Epoch 936/1000] Test loss: 0.024, Test target loss: 0.005
l0: 0.000009, l1: 0.000011, l2: 0.000025, l3: 0.000074, l4: 0.000472, l5: 0.000570, l6: 0.001461

[epoch: 937/1000, batch:    48/ 1052, ite: 246180] train loss: 0.003803, tar: 0.000020 
l0: 0.000009, l1: 0.000010, l2: 0.000015, l3: 0.000081, l4: 0.000388, l5: 0.000881, l6: 0.001027

[epoch: 937/1000, batch:   128/ 1052, ite: 246200] train loss: 0.003800, tar: 0.000020 
l0: 0.000005, l1: 0.000006, l2: 0.000020, l3: 0.000087, l4: 0.000357, l5: 0.000818, l6: 0.002991

[epoch: 937/1000, batch:   208/ 1052, ite: 246220] train loss: 0.003803, tar: 0.000020 
l0: 0.000062, l1: 0.000063, l2: 0.000173, l3: 0.000266, l4: 0.000628, l5: 0.001366, l6: 0.002672

[epoch: 937/1000, batch:   288/ 1052, ite: 246240] train loss: 0.003806, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000008, l3: 0.000088, l4: 0.000298, l5: 0.000714, l6: 0.001354

[epoch: 937/1000, batch:   368/ 1052, ite: 246260] train loss: 0.003807, tar: 0.000020 
l0: 0.000009, l1: 0.000008, l2: 0.000057, l3: 0.000260, l4: 0.000686, l5: 0.002013, l6: 0.003470

[epoch: 937/1000, batch:   448/ 1052, ite: 246280] train loss: 0.003808, tar: 0.000020 
l0: 0.000004, l1: 0.000006, l2: 0.000026, l3: 0.000121, l4: 0.000342, l5: 0.000622, l6: 0.001286

[epoch: 937/1000, batch:   528/ 1052, ite: 246300] train loss: 0.003806, tar: 0.000020 
l0: 0.000040, l1: 0.000043, l2: 0.000063, l3: 0.000167, l4: 0.000293, l5: 0.000701, l6: 0.001657

[epoch: 937/1000, batch:   608/ 1052, ite: 246320] train loss: 0.003804, tar: 0.000020 
l0: 0.000054, l1: 0.000055, l2: 0.000101, l3: 0.000302, l4: 0.000832, l5: 0.002484, l6: 0.004339

[epoch: 937/1000, batch:   688/ 1052, ite: 246340] train loss: 0.003806, tar: 0.000020 
l0: 0.000017, l1: 0.000016, l2: 0.000114, l3: 0.000248, l4: 0.000758, l5: 0.001061, l6: 0.002507

[epoch: 937/1000, batch:   768/ 1052, ite: 246360] train loss: 0.003806, tar: 0.000020 
l0: 0.000036, l1: 0.000040, l2: 0.000085, l3: 0.000190, l4: 0.000640, l5: 0.001567, l6: 0.002592

[epoch: 937/1000, batch:   848/ 1052, ite: 246380] train loss: 0.003807, tar: 0.000020 
l0: 0.000022, l1: 0.000023, l2: 0.000040, l3: 0.000179, l4: 0.000416, l5: 0.001154, l6: 0.001412

[epoch: 937/1000, batch:   928/ 1052, ite: 246400] train loss: 0.003806, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000005, l3: 0.000069, l4: 0.000181, l5: 0.000996, l6: 0.001996

[epoch: 937/1000, batch:  1008/ 1052, ite: 246420] train loss: 0.003804, tar: 0.000020 
[Epoch 937/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000046, l1: 0.000049, l2: 0.000087, l3: 0.000327, l4: 0.000968, l5: 0.002125, l6: 0.002806

[epoch: 938/1000, batch:    36/ 1052, ite: 246440] train loss: 0.003805, tar: 0.000020 
l0: 0.000073, l1: 0.000076, l2: 0.000114, l3: 0.000428, l4: 0.000870, l5: 0.001822, l6: 0.002951

[epoch: 938/1000, batch:   116/ 1052, ite: 246460] train loss: 0.003807, tar: 0.000020 
l0: 0.000004, l1: 0.000003, l2: 0.000022, l3: 0.000138, l4: 0.000417, l5: 0.000882, l6: 0.000906

[epoch: 938/1000, batch:   196/ 1052, ite: 246480] train loss: 0.003807, tar: 0.000020 
l0: 0.000034, l1: 0.000035, l2: 0.000093, l3: 0.000321, l4: 0.000757, l5: 0.001833, l6: 0.002975

[epoch: 938/1000, batch:   276/ 1052, ite: 246500] train loss: 0.003809, tar: 0.000020 
l0: 0.000045, l1: 0.000046, l2: 0.000056, l3: 0.000127, l4: 0.000452, l5: 0.000903, l6: 0.001526

[epoch: 938/1000, batch:   356/ 1052, ite: 246520] train loss: 0.003811, tar: 0.000020 
l0: 0.000029, l1: 0.000028, l2: 0.000075, l3: 0.000263, l4: 0.000723, l5: 0.001198, l6: 0.001796

[epoch: 938/1000, batch:   436/ 1052, ite: 246540] train loss: 0.003809, tar: 0.000020 
l0: 0.000031, l1: 0.000033, l2: 0.000112, l3: 0.000269, l4: 0.000517, l5: 0.001037, l6: 0.002148

[epoch: 938/1000, batch:   516/ 1052, ite: 246560] train loss: 0.003810, tar: 0.000020 
l0: 0.000022, l1: 0.000022, l2: 0.000052, l3: 0.000136, l4: 0.000439, l5: 0.000817, l6: 0.001583

[epoch: 938/1000, batch:   596/ 1052, ite: 246580] train loss: 0.003807, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000037, l3: 0.000112, l4: 0.000473, l5: 0.001048, l6: 0.002533

[epoch: 938/1000, batch:   676/ 1052, ite: 246600] train loss: 0.003807, tar: 0.000020 
l0: 0.000007, l1: 0.000007, l2: 0.000030, l3: 0.000133, l4: 0.000305, l5: 0.000920, l6: 0.001284

[epoch: 938/1000, batch:   756/ 1052, ite: 246620] train loss: 0.003807, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000014, l3: 0.000057, l4: 0.000175, l5: 0.000753, l6: 0.000739

[epoch: 938/1000, batch:   836/ 1052, ite: 246640] train loss: 0.003807, tar: 0.000020 
l0: 0.000008, l1: 0.000010, l2: 0.000030, l3: 0.000206, l4: 0.000439, l5: 0.000802, l6: 0.001380

[epoch: 938/1000, batch:   916/ 1052, ite: 246660] train loss: 0.003806, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000022, l3: 0.000145, l4: 0.000231, l5: 0.000673, l6: 0.001204

[epoch: 938/1000, batch:   996/ 1052, ite: 246680] train loss: 0.003806, tar: 0.000020 
[Epoch 938/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000010, l1: 0.000010, l2: 0.000020, l3: 0.000135, l4: 0.000640, l5: 0.000721, l6: 0.002200

[epoch: 939/1000, batch:    24/ 1052, ite: 246700] train loss: 0.003806, tar: 0.000020 
l0: 0.000023, l1: 0.000021, l2: 0.000060, l3: 0.000240, l4: 0.000411, l5: 0.001377, l6: 0.002107

[epoch: 939/1000, batch:   104/ 1052, ite: 246720] train loss: 0.003806, tar: 0.000020 
l0: 0.000014, l1: 0.000014, l2: 0.000033, l3: 0.000188, l4: 0.000469, l5: 0.000894, l6: 0.001240

[epoch: 939/1000, batch:   184/ 1052, ite: 246740] train loss: 0.003808, tar: 0.000020 
l0: 0.000009, l1: 0.000008, l2: 0.000041, l3: 0.000182, l4: 0.000417, l5: 0.001187, l6: 0.002319

[epoch: 939/1000, batch:   264/ 1052, ite: 246760] train loss: 0.003811, tar: 0.000020 
l0: 0.000013, l1: 0.000013, l2: 0.000029, l3: 0.000126, l4: 0.000614, l5: 0.001172, l6: 0.002256

[epoch: 939/1000, batch:   344/ 1052, ite: 246780] train loss: 0.003810, tar: 0.000020 
l0: 0.000050, l1: 0.000046, l2: 0.000061, l3: 0.000156, l4: 0.000421, l5: 0.001113, l6: 0.001714

[epoch: 939/1000, batch:   424/ 1052, ite: 246800] train loss: 0.003810, tar: 0.000021 
l0: 0.000042, l1: 0.000045, l2: 0.000088, l3: 0.000129, l4: 0.000420, l5: 0.001291, l6: 0.002098

[epoch: 939/1000, batch:   504/ 1052, ite: 246820] train loss: 0.003809, tar: 0.000021 
l0: 0.000024, l1: 0.000028, l2: 0.000057, l3: 0.000137, l4: 0.000294, l5: 0.001029, l6: 0.002002

[epoch: 939/1000, batch:   584/ 1052, ite: 246840] train loss: 0.003812, tar: 0.000020 
l0: 0.000009, l1: 0.000009, l2: 0.000072, l3: 0.000162, l4: 0.000330, l5: 0.000846, l6: 0.001735

[epoch: 939/1000, batch:   664/ 1052, ite: 246860] train loss: 0.003812, tar: 0.000020 
l0: 0.000010, l1: 0.000009, l2: 0.000021, l3: 0.000107, l4: 0.000204, l5: 0.000710, l6: 0.001524

[epoch: 939/1000, batch:   744/ 1052, ite: 246880] train loss: 0.003810, tar: 0.000020 
l0: 0.000015, l1: 0.000013, l2: 0.000039, l3: 0.000099, l4: 0.000375, l5: 0.000663, l6: 0.001683

[epoch: 939/1000, batch:   824/ 1052, ite: 246900] train loss: 0.003806, tar: 0.000020 
l0: 0.000034, l1: 0.000033, l2: 0.000066, l3: 0.000184, l4: 0.000704, l5: 0.001033, l6: 0.002293

[epoch: 939/1000, batch:   904/ 1052, ite: 246920] train loss: 0.003806, tar: 0.000020 
l0: 0.000005, l1: 0.000004, l2: 0.000025, l3: 0.000127, l4: 0.000445, l5: 0.000842, l6: 0.001345

[epoch: 939/1000, batch:   984/ 1052, ite: 246940] train loss: 0.003805, tar: 0.000020 
[Epoch 939/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000015, l1: 0.000016, l2: 0.000040, l3: 0.000114, l4: 0.000281, l5: 0.001006, l6: 0.001243

[epoch: 940/1000, batch:    12/ 1052, ite: 246960] train loss: 0.003805, tar: 0.000020 
l0: 0.000003, l1: 0.000004, l2: 0.000009, l3: 0.000120, l4: 0.000502, l5: 0.001024, l6: 0.001892

[epoch: 940/1000, batch:    92/ 1052, ite: 246980] train loss: 0.003804, tar: 0.000020 
l0: 0.000031, l1: 0.000031, l2: 0.000045, l3: 0.000181, l4: 0.000365, l5: 0.001168, l6: 0.001925

[epoch: 940/1000, batch:   172/ 1052, ite: 247000] train loss: 0.003803, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000032, l3: 0.000153, l4: 0.000676, l5: 0.001300, l6: 0.001806

[epoch: 940/1000, batch:   252/ 1052, ite: 247020] train loss: 0.003804, tar: 0.000020 
l0: 0.000007, l1: 0.000006, l2: 0.000067, l3: 0.000264, l4: 0.000596, l5: 0.001489, l6: 0.002785

[epoch: 940/1000, batch:   332/ 1052, ite: 247040] train loss: 0.003803, tar: 0.000020 
l0: 0.000037, l1: 0.000038, l2: 0.000096, l3: 0.000425, l4: 0.000867, l5: 0.001515, l6: 0.002558

[epoch: 940/1000, batch:   412/ 1052, ite: 247060] train loss: 0.003804, tar: 0.000020 
l0: 0.000014, l1: 0.000014, l2: 0.000050, l3: 0.000166, l4: 0.000399, l5: 0.001124, l6: 0.001814

[epoch: 940/1000, batch:   492/ 1052, ite: 247080] train loss: 0.003804, tar: 0.000020 
l0: 0.000030, l1: 0.000029, l2: 0.000077, l3: 0.000149, l4: 0.000427, l5: 0.000730, l6: 0.001252

[epoch: 940/1000, batch:   572/ 1052, ite: 247100] train loss: 0.003805, tar: 0.000020 
l0: 0.000063, l1: 0.000067, l2: 0.000069, l3: 0.000293, l4: 0.000606, l5: 0.001143, l6: 0.001878

[epoch: 940/1000, batch:   652/ 1052, ite: 247120] train loss: 0.003806, tar: 0.000020 
l0: 0.000047, l1: 0.000049, l2: 0.000094, l3: 0.000194, l4: 0.000616, l5: 0.001781, l6: 0.002169

[epoch: 940/1000, batch:   732/ 1052, ite: 247140] train loss: 0.003805, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000038, l3: 0.000149, l4: 0.000358, l5: 0.000756, l6: 0.001360

[epoch: 940/1000, batch:   812/ 1052, ite: 247160] train loss: 0.003803, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000030, l3: 0.000122, l4: 0.000599, l5: 0.001314, l6: 0.002543

[epoch: 940/1000, batch:   892/ 1052, ite: 247180] train loss: 0.003804, tar: 0.000020 
l0: 0.000003, l1: 0.000004, l2: 0.000025, l3: 0.000068, l4: 0.000272, l5: 0.001088, l6: 0.002225

[epoch: 940/1000, batch:   972/ 1052, ite: 247200] train loss: 0.003804, tar: 0.000020 
l0: 0.000043, l1: 0.000045, l2: 0.000074, l3: 0.000272, l4: 0.000616, l5: 0.001083, l6: 0.003635

[epoch: 940/1000, batch:  1052/ 1052, ite: 247220] train loss: 0.003805, tar: 0.000020 
[Epoch 940/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000019, l1: 0.000021, l2: 0.000033, l3: 0.000196, l4: 0.000433, l5: 0.001315, l6: 0.001407

[epoch: 941/1000, batch:    80/ 1052, ite: 247240] train loss: 0.003805, tar: 0.000020 
l0: 0.000008, l1: 0.000008, l2: 0.000053, l3: 0.000318, l4: 0.000745, l5: 0.001839, l6: 0.002303

[epoch: 941/1000, batch:   160/ 1052, ite: 247260] train loss: 0.003805, tar: 0.000020 
l0: 0.000034, l1: 0.000031, l2: 0.000076, l3: 0.000231, l4: 0.000504, l5: 0.001394, l6: 0.002409

[epoch: 941/1000, batch:   240/ 1052, ite: 247280] train loss: 0.003806, tar: 0.000020 
l0: 0.000016, l1: 0.000014, l2: 0.000052, l3: 0.000196, l4: 0.000347, l5: 0.000915, l6: 0.001774

[epoch: 941/1000, batch:   320/ 1052, ite: 247300] train loss: 0.003808, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000003, l3: 0.000041, l4: 0.000358, l5: 0.000906, l6: 0.001407

[epoch: 941/1000, batch:   400/ 1052, ite: 247320] train loss: 0.003808, tar: 0.000020 
l0: 0.000016, l1: 0.000015, l2: 0.000031, l3: 0.000084, l4: 0.000309, l5: 0.000853, l6: 0.001055

[epoch: 941/1000, batch:   480/ 1052, ite: 247340] train loss: 0.003808, tar: 0.000020 
l0: 0.000028, l1: 0.000026, l2: 0.000052, l3: 0.000222, l4: 0.000407, l5: 0.001249, l6: 0.003025

[epoch: 941/1000, batch:   560/ 1052, ite: 247360] train loss: 0.003808, tar: 0.000020 
l0: 0.000010, l1: 0.000010, l2: 0.000134, l3: 0.000271, l4: 0.000510, l5: 0.000901, l6: 0.002023

[epoch: 941/1000, batch:   640/ 1052, ite: 247380] train loss: 0.003808, tar: 0.000020 
l0: 0.000011, l1: 0.000010, l2: 0.000047, l3: 0.000121, l4: 0.000291, l5: 0.001174, l6: 0.001363

[epoch: 941/1000, batch:   720/ 1052, ite: 247400] train loss: 0.003807, tar: 0.000020 
l0: 0.000401, l1: 0.000355, l2: 0.000485, l3: 0.000455, l4: 0.000614, l5: 0.001161, l6: 0.001111

[epoch: 941/1000, batch:   800/ 1052, ite: 247420] train loss: 0.003808, tar: 0.000020 
l0: 0.000061, l1: 0.000064, l2: 0.000037, l3: 0.000069, l4: 0.000320, l5: 0.000761, l6: 0.001040

[epoch: 941/1000, batch:   880/ 1052, ite: 247440] train loss: 0.003809, tar: 0.000020 
l0: 0.000123, l1: 0.000119, l2: 0.000212, l3: 0.000543, l4: 0.001036, l5: 0.003662, l6: 0.005412

[epoch: 941/1000, batch:   960/ 1052, ite: 247460] train loss: 0.003809, tar: 0.000020 
l0: 0.000009, l1: 0.000009, l2: 0.000030, l3: 0.000107, l4: 0.000241, l5: 0.000660, l6: 0.000939

[epoch: 941/1000, batch:  1040/ 1052, ite: 247480] train loss: 0.003807, tar: 0.000020 
[Epoch 941/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000024, l1: 0.000020, l2: 0.000070, l3: 0.000147, l4: 0.000551, l5: 0.001201, l6: 0.001891

[epoch: 942/1000, batch:    68/ 1052, ite: 247500] train loss: 0.003806, tar: 0.000020 
l0: 0.000029, l1: 0.000030, l2: 0.000073, l3: 0.000211, l4: 0.000474, l5: 0.000971, l6: 0.002046

[epoch: 942/1000, batch:   148/ 1052, ite: 247520] train loss: 0.003806, tar: 0.000020 
l0: 0.000020, l1: 0.000023, l2: 0.000088, l3: 0.000241, l4: 0.000704, l5: 0.002009, l6: 0.003431

[epoch: 942/1000, batch:   228/ 1052, ite: 247540] train loss: 0.003806, tar: 0.000020 
l0: 0.000011, l1: 0.000011, l2: 0.000092, l3: 0.000406, l4: 0.000908, l5: 0.002505, l6: 0.003639

[epoch: 942/1000, batch:   308/ 1052, ite: 247560] train loss: 0.003807, tar: 0.000020 
l0: 0.000005, l1: 0.000006, l2: 0.000031, l3: 0.000201, l4: 0.000570, l5: 0.001455, l6: 0.002931

[epoch: 942/1000, batch:   388/ 1052, ite: 247580] train loss: 0.003807, tar: 0.000021 
l0: 0.000215, l1: 0.000218, l2: 0.000311, l3: 0.000439, l4: 0.000656, l5: 0.001479, l6: 0.003447

[epoch: 942/1000, batch:   468/ 1052, ite: 247600] train loss: 0.003806, tar: 0.000021 
l0: 0.000009, l1: 0.000009, l2: 0.000024, l3: 0.000142, l4: 0.000330, l5: 0.000919, l6: 0.001418

[epoch: 942/1000, batch:   548/ 1052, ite: 247620] train loss: 0.003806, tar: 0.000021 
l0: 0.000017, l1: 0.000018, l2: 0.000060, l3: 0.000226, l4: 0.000505, l5: 0.001143, l6: 0.001390

[epoch: 942/1000, batch:   628/ 1052, ite: 247640] train loss: 0.003807, tar: 0.000021 
l0: 0.000006, l1: 0.000006, l2: 0.000010, l3: 0.000029, l4: 0.000277, l5: 0.000632, l6: 0.001092

[epoch: 942/1000, batch:   708/ 1052, ite: 247660] train loss: 0.003808, tar: 0.000021 
l0: 0.000056, l1: 0.000064, l2: 0.000061, l3: 0.000169, l4: 0.000410, l5: 0.001165, l6: 0.002956

[epoch: 942/1000, batch:   788/ 1052, ite: 247680] train loss: 0.003808, tar: 0.000021 
l0: 0.000025, l1: 0.000027, l2: 0.000056, l3: 0.000203, l4: 0.000584, l5: 0.001060, l6: 0.002595

[epoch: 942/1000, batch:   868/ 1052, ite: 247700] train loss: 0.003810, tar: 0.000021 
l0: 0.000040, l1: 0.000039, l2: 0.000075, l3: 0.000215, l4: 0.000551, l5: 0.001222, l6: 0.002494

[epoch: 942/1000, batch:   948/ 1052, ite: 247720] train loss: 0.003809, tar: 0.000021 
l0: 0.000032, l1: 0.000035, l2: 0.000036, l3: 0.000179, l4: 0.000443, l5: 0.000709, l6: 0.001653

[epoch: 942/1000, batch:  1028/ 1052, ite: 247740] train loss: 0.003809, tar: 0.000021 
[Epoch 942/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000022, l1: 0.000021, l2: 0.000058, l3: 0.000192, l4: 0.000484, l5: 0.001083, l6: 0.002334

[epoch: 943/1000, batch:    56/ 1052, ite: 247760] train loss: 0.003808, tar: 0.000021 
l0: 0.000006, l1: 0.000007, l2: 0.000015, l3: 0.000087, l4: 0.000309, l5: 0.000773, l6: 0.001418

[epoch: 943/1000, batch:   136/ 1052, ite: 247780] train loss: 0.003809, tar: 0.000021 
l0: 0.000038, l1: 0.000038, l2: 0.000081, l3: 0.000158, l4: 0.000479, l5: 0.000854, l6: 0.001329

[epoch: 943/1000, batch:   216/ 1052, ite: 247800] train loss: 0.003808, tar: 0.000021 
l0: 0.000004, l1: 0.000003, l2: 0.000030, l3: 0.000168, l4: 0.000509, l5: 0.001146, l6: 0.002841

[epoch: 943/1000, batch:   296/ 1052, ite: 247820] train loss: 0.003809, tar: 0.000021 
l0: 0.000007, l1: 0.000007, l2: 0.000027, l3: 0.000163, l4: 0.000314, l5: 0.000950, l6: 0.001958

[epoch: 943/1000, batch:   376/ 1052, ite: 247840] train loss: 0.003809, tar: 0.000021 
l0: 0.000003, l1: 0.000004, l2: 0.000018, l3: 0.000055, l4: 0.000249, l5: 0.000684, l6: 0.001986

[epoch: 943/1000, batch:   456/ 1052, ite: 247860] train loss: 0.003808, tar: 0.000021 
l0: 0.000015, l1: 0.000021, l2: 0.000015, l3: 0.000040, l4: 0.000276, l5: 0.000767, l6: 0.001164

[epoch: 943/1000, batch:   536/ 1052, ite: 247880] train loss: 0.003807, tar: 0.000021 
l0: 0.000041, l1: 0.000043, l2: 0.000071, l3: 0.000254, l4: 0.000405, l5: 0.001024, l6: 0.002567

[epoch: 943/1000, batch:   616/ 1052, ite: 247900] train loss: 0.003809, tar: 0.000021 
l0: 0.000002, l1: 0.000002, l2: 0.000021, l3: 0.000048, l4: 0.000341, l5: 0.000512, l6: 0.001065

[epoch: 943/1000, batch:   696/ 1052, ite: 247920] train loss: 0.003811, tar: 0.000021 
l0: 0.000322, l1: 0.000356, l2: 0.000324, l3: 0.000479, l4: 0.001047, l5: 0.001990, l6: 0.003586

[epoch: 943/1000, batch:   776/ 1052, ite: 247940] train loss: 0.003812, tar: 0.000021 
l0: 0.000120, l1: 0.000122, l2: 0.000182, l3: 0.000250, l4: 0.000514, l5: 0.001117, l6: 0.002955

[epoch: 943/1000, batch:   856/ 1052, ite: 247960] train loss: 0.003812, tar: 0.000021 
l0: 0.000065, l1: 0.000068, l2: 0.000127, l3: 0.000176, l4: 0.000392, l5: 0.001376, l6: 0.002840

[epoch: 943/1000, batch:   936/ 1052, ite: 247980] train loss: 0.003813, tar: 0.000021 
l0: 0.000042, l1: 0.000045, l2: 0.000064, l3: 0.000132, l4: 0.000180, l5: 0.000828, l6: 0.001139

[epoch: 943/1000, batch:  1016/ 1052, ite: 248000] train loss: 0.003814, tar: 0.000022 
[Epoch 943/1000] Test loss: 0.021, Test target loss: 0.003
l0: 0.000045, l1: 0.000042, l2: 0.000081, l3: 0.000217, l4: 0.000561, l5: 0.001226, l6: 0.002393

[epoch: 944/1000, batch:    44/ 1052, ite: 248020] train loss: 0.003815, tar: 0.000022 
l0: 0.000023, l1: 0.000023, l2: 0.000080, l3: 0.000185, l4: 0.000458, l5: 0.001440, l6: 0.002116

[epoch: 944/1000, batch:   124/ 1052, ite: 248040] train loss: 0.003816, tar: 0.000022 
l0: 0.000041, l1: 0.000042, l2: 0.000077, l3: 0.000141, l4: 0.000325, l5: 0.000776, l6: 0.000878

[epoch: 944/1000, batch:   204/ 1052, ite: 248060] train loss: 0.003817, tar: 0.000022 
l0: 0.000030, l1: 0.000031, l2: 0.000056, l3: 0.000151, l4: 0.000301, l5: 0.000965, l6: 0.002057

[epoch: 944/1000, batch:   284/ 1052, ite: 248080] train loss: 0.003818, tar: 0.000022 
l0: 0.000041, l1: 0.000039, l2: 0.000090, l3: 0.000296, l4: 0.000502, l5: 0.001141, l6: 0.001682

[epoch: 944/1000, batch:   364/ 1052, ite: 248100] train loss: 0.003818, tar: 0.000022 
l0: 0.000031, l1: 0.000032, l2: 0.000075, l3: 0.000213, l4: 0.000585, l5: 0.000966, l6: 0.001976

[epoch: 944/1000, batch:   444/ 1052, ite: 248120] train loss: 0.003817, tar: 0.000022 
l0: 0.000030, l1: 0.000028, l2: 0.000107, l3: 0.000361, l4: 0.001023, l5: 0.001960, l6: 0.003451

[epoch: 944/1000, batch:   524/ 1052, ite: 248140] train loss: 0.003818, tar: 0.000022 
l0: 0.000018, l1: 0.000019, l2: 0.000030, l3: 0.000105, l4: 0.000311, l5: 0.000912, l6: 0.001260

[epoch: 944/1000, batch:   604/ 1052, ite: 248160] train loss: 0.003817, tar: 0.000022 
l0: 0.000021, l1: 0.000021, l2: 0.000064, l3: 0.000335, l4: 0.000527, l5: 0.001474, l6: 0.001925

[epoch: 944/1000, batch:   684/ 1052, ite: 248180] train loss: 0.003818, tar: 0.000022 
l0: 0.000021, l1: 0.000026, l2: 0.000045, l3: 0.000105, l4: 0.000338, l5: 0.000737, l6: 0.001596

[epoch: 944/1000, batch:   764/ 1052, ite: 248200] train loss: 0.003818, tar: 0.000022 
l0: 0.000006, l1: 0.000007, l2: 0.000032, l3: 0.000139, l4: 0.000422, l5: 0.001205, l6: 0.001927

[epoch: 944/1000, batch:   844/ 1052, ite: 248220] train loss: 0.003819, tar: 0.000022 
l0: 0.000037, l1: 0.000034, l2: 0.000074, l3: 0.000177, l4: 0.000392, l5: 0.001004, l6: 0.001675

[epoch: 944/1000, batch:   924/ 1052, ite: 248240] train loss: 0.003819, tar: 0.000022 
l0: 0.000061, l1: 0.000065, l2: 0.000107, l3: 0.000208, l4: 0.000445, l5: 0.001608, l6: 0.003779

[epoch: 944/1000, batch:  1004/ 1052, ite: 248260] train loss: 0.003819, tar: 0.000022 
[Epoch 944/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000019, l1: 0.000018, l2: 0.000059, l3: 0.000231, l4: 0.000525, l5: 0.001119, l6: 0.001685

[epoch: 945/1000, batch:    32/ 1052, ite: 248280] train loss: 0.003818, tar: 0.000022 
l0: 0.000005, l1: 0.000003, l2: 0.000033, l3: 0.000104, l4: 0.000249, l5: 0.001402, l6: 0.001666

[epoch: 945/1000, batch:   112/ 1052, ite: 248300] train loss: 0.003820, tar: 0.000022 
l0: 0.000010, l1: 0.000008, l2: 0.000059, l3: 0.000238, l4: 0.000773, l5: 0.001843, l6: 0.002861

[epoch: 945/1000, batch:   192/ 1052, ite: 248320] train loss: 0.003821, tar: 0.000022 
l0: 0.000045, l1: 0.000047, l2: 0.000056, l3: 0.000114, l4: 0.000352, l5: 0.000765, l6: 0.001117

[epoch: 945/1000, batch:   272/ 1052, ite: 248340] train loss: 0.003821, tar: 0.000022 
l0: 0.000013, l1: 0.000017, l2: 0.000027, l3: 0.000070, l4: 0.000316, l5: 0.000872, l6: 0.002149

[epoch: 945/1000, batch:   352/ 1052, ite: 248360] train loss: 0.003822, tar: 0.000022 
l0: 0.000023, l1: 0.000023, l2: 0.000078, l3: 0.000279, l4: 0.000621, l5: 0.001128, l6: 0.003044

[epoch: 945/1000, batch:   432/ 1052, ite: 248380] train loss: 0.003821, tar: 0.000022 
l0: 0.000011, l1: 0.000010, l2: 0.000032, l3: 0.000150, l4: 0.000460, l5: 0.000930, l6: 0.002470

[epoch: 945/1000, batch:   512/ 1052, ite: 248400] train loss: 0.003822, tar: 0.000022 
l0: 0.000010, l1: 0.000012, l2: 0.000013, l3: 0.000018, l4: 0.000179, l5: 0.000493, l6: 0.000729

[epoch: 945/1000, batch:   592/ 1052, ite: 248420] train loss: 0.003821, tar: 0.000022 
l0: 0.000008, l1: 0.000010, l2: 0.000036, l3: 0.000116, l4: 0.000448, l5: 0.000745, l6: 0.001617

[epoch: 945/1000, batch:   672/ 1052, ite: 248440] train loss: 0.003820, tar: 0.000022 
l0: 0.000025, l1: 0.000023, l2: 0.000091, l3: 0.000313, l4: 0.000754, l5: 0.001217, l6: 0.002181

[epoch: 945/1000, batch:   752/ 1052, ite: 248460] train loss: 0.003820, tar: 0.000022 
l0: 0.000005, l1: 0.000005, l2: 0.000042, l3: 0.000156, l4: 0.000428, l5: 0.001052, l6: 0.001885

[epoch: 945/1000, batch:   832/ 1052, ite: 248480] train loss: 0.003819, tar: 0.000022 
l0: 0.000046, l1: 0.000048, l2: 0.000057, l3: 0.000215, l4: 0.000492, l5: 0.000905, l6: 0.001537

[epoch: 945/1000, batch:   912/ 1052, ite: 248500] train loss: 0.003818, tar: 0.000022 
l0: 0.000001, l1: 0.000001, l2: 0.000006, l3: 0.000099, l4: 0.000342, l5: 0.000707, l6: 0.001934

[epoch: 945/1000, batch:   992/ 1052, ite: 248520] train loss: 0.003818, tar: 0.000022 
[Epoch 945/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000006, l1: 0.000005, l2: 0.000015, l3: 0.000072, l4: 0.000278, l5: 0.001085, l6: 0.001848

[epoch: 946/1000, batch:    20/ 1052, ite: 248540] train loss: 0.003819, tar: 0.000022 
l0: 0.000004, l1: 0.000004, l2: 0.000022, l3: 0.000063, l4: 0.000142, l5: 0.000558, l6: 0.000964

[epoch: 946/1000, batch:   100/ 1052, ite: 248560] train loss: 0.003817, tar: 0.000022 
l0: 0.000004, l1: 0.000004, l2: 0.000015, l3: 0.000082, l4: 0.000304, l5: 0.000625, l6: 0.001189

[epoch: 946/1000, batch:   180/ 1052, ite: 248580] train loss: 0.003818, tar: 0.000022 
l0: 0.000013, l1: 0.000018, l2: 0.000020, l3: 0.000085, l4: 0.000258, l5: 0.000801, l6: 0.001154

[epoch: 946/1000, batch:   260/ 1052, ite: 248600] train loss: 0.003818, tar: 0.000022 
l0: 0.000009, l1: 0.000010, l2: 0.000043, l3: 0.000219, l4: 0.000646, l5: 0.001359, l6: 0.002466

[epoch: 946/1000, batch:   340/ 1052, ite: 248620] train loss: 0.003819, tar: 0.000022 
l0: 0.000040, l1: 0.000041, l2: 0.000049, l3: 0.000082, l4: 0.000458, l5: 0.000796, l6: 0.001054

[epoch: 946/1000, batch:   420/ 1052, ite: 248640] train loss: 0.003818, tar: 0.000022 
l0: 0.000050, l1: 0.000047, l2: 0.000075, l3: 0.000119, l4: 0.000365, l5: 0.001117, l6: 0.001756

[epoch: 946/1000, batch:   500/ 1052, ite: 248660] train loss: 0.003817, tar: 0.000022 
l0: 0.000002, l1: 0.000002, l2: 0.000015, l3: 0.000094, l4: 0.000310, l5: 0.000858, l6: 0.001413

[epoch: 946/1000, batch:   580/ 1052, ite: 248680] train loss: 0.003816, tar: 0.000022 
l0: 0.000010, l1: 0.000010, l2: 0.000025, l3: 0.000089, l4: 0.000416, l5: 0.001090, l6: 0.001376

[epoch: 946/1000, batch:   660/ 1052, ite: 248700] train loss: 0.003817, tar: 0.000022 
l0: 0.000002, l1: 0.000003, l2: 0.000027, l3: 0.000132, l4: 0.000479, l5: 0.001013, l6: 0.002061

[epoch: 946/1000, batch:   740/ 1052, ite: 248720] train loss: 0.003819, tar: 0.000022 
l0: 0.000005, l1: 0.000003, l2: 0.000016, l3: 0.000065, l4: 0.000385, l5: 0.000558, l6: 0.001354

[epoch: 946/1000, batch:   820/ 1052, ite: 248740] train loss: 0.003817, tar: 0.000022 
l0: 0.000007, l1: 0.000007, l2: 0.000015, l3: 0.000112, l4: 0.000348, l5: 0.000963, l6: 0.001856

[epoch: 946/1000, batch:   900/ 1052, ite: 248760] train loss: 0.003819, tar: 0.000022 
l0: 0.000004, l1: 0.000004, l2: 0.000018, l3: 0.000065, l4: 0.000411, l5: 0.000878, l6: 0.001471

[epoch: 946/1000, batch:   980/ 1052, ite: 248780] train loss: 0.003820, tar: 0.000022 
[Epoch 946/1000] Test loss: 0.024, Test target loss: 0.005
l0: 0.000015, l1: 0.000020, l2: 0.000020, l3: 0.000117, l4: 0.000226, l5: 0.000810, l6: 0.001509

[epoch: 947/1000, batch:     8/ 1052, ite: 248800] train loss: 0.003819, tar: 0.000022 
l0: 0.000031, l1: 0.000034, l2: 0.000024, l3: 0.000085, l4: 0.000334, l5: 0.001100, l6: 0.001737

[epoch: 947/1000, batch:    88/ 1052, ite: 248820] train loss: 0.003818, tar: 0.000022 
l0: 0.000004, l1: 0.000003, l2: 0.000019, l3: 0.000142, l4: 0.000315, l5: 0.000744, l6: 0.001685

[epoch: 947/1000, batch:   168/ 1052, ite: 248840] train loss: 0.003817, tar: 0.000022 
l0: 0.000036, l1: 0.000035, l2: 0.000050, l3: 0.000185, l4: 0.000775, l5: 0.002191, l6: 0.002835

[epoch: 947/1000, batch:   248/ 1052, ite: 248860] train loss: 0.003818, tar: 0.000022 
l0: 0.000031, l1: 0.000030, l2: 0.000046, l3: 0.000162, l4: 0.000365, l5: 0.001493, l6: 0.002562

[epoch: 947/1000, batch:   328/ 1052, ite: 248880] train loss: 0.003817, tar: 0.000022 
l0: 0.000002, l1: 0.000002, l2: 0.000012, l3: 0.000039, l4: 0.000310, l5: 0.000642, l6: 0.001389

[epoch: 947/1000, batch:   408/ 1052, ite: 248900] train loss: 0.003818, tar: 0.000022 
l0: 0.000015, l1: 0.000017, l2: 0.000019, l3: 0.000098, l4: 0.000302, l5: 0.001207, l6: 0.002051

[epoch: 947/1000, batch:   488/ 1052, ite: 248920] train loss: 0.003818, tar: 0.000022 
l0: 0.000049, l1: 0.000055, l2: 0.000142, l3: 0.000473, l4: 0.000819, l5: 0.002559, l6: 0.005202

[epoch: 947/1000, batch:   568/ 1052, ite: 248940] train loss: 0.003818, tar: 0.000022 
l0: 0.000053, l1: 0.000051, l2: 0.000047, l3: 0.000080, l4: 0.000199, l5: 0.000840, l6: 0.001264

[epoch: 947/1000, batch:   648/ 1052, ite: 248960] train loss: 0.003818, tar: 0.000022 
l0: 0.000003, l1: 0.000003, l2: 0.000018, l3: 0.000109, l4: 0.000301, l5: 0.000862, l6: 0.001817

[epoch: 947/1000, batch:   728/ 1052, ite: 248980] train loss: 0.003818, tar: 0.000022 
l0: 0.000058, l1: 0.000066, l2: 0.000142, l3: 0.000317, l4: 0.000699, l5: 0.001483, l6: 0.002777

[epoch: 947/1000, batch:   808/ 1052, ite: 249000] train loss: 0.003819, tar: 0.000022 
l0: 0.000087, l1: 0.000092, l2: 0.000104, l3: 0.000209, l4: 0.000422, l5: 0.001313, l6: 0.003150

[epoch: 947/1000, batch:   888/ 1052, ite: 249020] train loss: 0.003819, tar: 0.000022 
l0: 0.000013, l1: 0.000010, l2: 0.000029, l3: 0.000188, l4: 0.000567, l5: 0.001361, l6: 0.002094

[epoch: 947/1000, batch:   968/ 1052, ite: 249040] train loss: 0.003819, tar: 0.000022 
l0: 0.000000, l1: 0.000000, l2: 0.000009, l3: 0.000123, l4: 0.000170, l5: 0.000462, l6: 0.000705

[epoch: 947/1000, batch:  1048/ 1052, ite: 249060] train loss: 0.003817, tar: 0.000022 
[Epoch 947/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000006, l1: 0.000006, l2: 0.000024, l3: 0.000098, l4: 0.000280, l5: 0.001009, l6: 0.001744

[epoch: 948/1000, batch:    76/ 1052, ite: 249080] train loss: 0.003818, tar: 0.000022 
l0: 0.000012, l1: 0.000013, l2: 0.000035, l3: 0.000199, l4: 0.000487, l5: 0.001602, l6: 0.002607

[epoch: 948/1000, batch:   156/ 1052, ite: 249100] train loss: 0.003818, tar: 0.000022 
l0: 0.000005, l1: 0.000006, l2: 0.000022, l3: 0.000124, l4: 0.000244, l5: 0.001108, l6: 0.001928

[epoch: 948/1000, batch:   236/ 1052, ite: 249120] train loss: 0.003817, tar: 0.000022 
l0: 0.000006, l1: 0.000005, l2: 0.000032, l3: 0.000188, l4: 0.000370, l5: 0.000846, l6: 0.001249

[epoch: 948/1000, batch:   316/ 1052, ite: 249140] train loss: 0.003817, tar: 0.000022 
l0: 0.000042, l1: 0.000045, l2: 0.000056, l3: 0.000220, l4: 0.000719, l5: 0.002038, l6: 0.002697

[epoch: 948/1000, batch:   396/ 1052, ite: 249160] train loss: 0.003818, tar: 0.000022 
l0: 0.000013, l1: 0.000012, l2: 0.000060, l3: 0.000212, l4: 0.000751, l5: 0.001706, l6: 0.002299

[epoch: 948/1000, batch:   476/ 1052, ite: 249180] train loss: 0.003817, tar: 0.000022 
l0: 0.000011, l1: 0.000011, l2: 0.000020, l3: 0.000132, l4: 0.000253, l5: 0.000925, l6: 0.001834

[epoch: 948/1000, batch:   556/ 1052, ite: 249200] train loss: 0.003818, tar: 0.000022 
l0: 0.000006, l1: 0.000006, l2: 0.000023, l3: 0.000113, l4: 0.000307, l5: 0.000802, l6: 0.001812

[epoch: 948/1000, batch:   636/ 1052, ite: 249220] train loss: 0.003817, tar: 0.000022 
l0: 0.000022, l1: 0.000021, l2: 0.000042, l3: 0.000146, l4: 0.000401, l5: 0.001039, l6: 0.001892

[epoch: 948/1000, batch:   716/ 1052, ite: 249240] train loss: 0.003817, tar: 0.000022 
l0: 0.000038, l1: 0.000039, l2: 0.000086, l3: 0.000252, l4: 0.000651, l5: 0.002644, l6: 0.004542

[epoch: 948/1000, batch:   796/ 1052, ite: 249260] train loss: 0.003818, tar: 0.000022 
l0: 0.000008, l1: 0.000011, l2: 0.000024, l3: 0.000135, l4: 0.000415, l5: 0.000939, l6: 0.002151

[epoch: 948/1000, batch:   876/ 1052, ite: 249280] train loss: 0.003818, tar: 0.000022 
l0: 0.000009, l1: 0.000009, l2: 0.000024, l3: 0.000090, l4: 0.000348, l5: 0.000929, l6: 0.001451

[epoch: 948/1000, batch:   956/ 1052, ite: 249300] train loss: 0.003817, tar: 0.000022 
l0: 0.000038, l1: 0.000043, l2: 0.000170, l3: 0.000499, l4: 0.000924, l5: 0.002818, l6: 0.006147

[epoch: 948/1000, batch:  1036/ 1052, ite: 249320] train loss: 0.003817, tar: 0.000022 
[Epoch 948/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000009, l1: 0.000010, l2: 0.000049, l3: 0.000200, l4: 0.000429, l5: 0.001169, l6: 0.001937

[epoch: 949/1000, batch:    64/ 1052, ite: 249340] train loss: 0.003815, tar: 0.000022 
l0: 0.000001, l1: 0.000001, l2: 0.000010, l3: 0.000070, l4: 0.000218, l5: 0.000707, l6: 0.001071

[epoch: 949/1000, batch:   144/ 1052, ite: 249360] train loss: 0.003816, tar: 0.000022 
l0: 0.000004, l1: 0.000004, l2: 0.000037, l3: 0.000192, l4: 0.000764, l5: 0.001447, l6: 0.002378

[epoch: 949/1000, batch:   224/ 1052, ite: 249380] train loss: 0.003817, tar: 0.000022 
l0: 0.000011, l1: 0.000012, l2: 0.000020, l3: 0.000065, l4: 0.000470, l5: 0.000477, l6: 0.001907

[epoch: 949/1000, batch:   304/ 1052, ite: 249400] train loss: 0.003817, tar: 0.000022 
l0: 0.000008, l1: 0.000008, l2: 0.000033, l3: 0.000205, l4: 0.000527, l5: 0.001331, l6: 0.001856

[epoch: 949/1000, batch:   384/ 1052, ite: 249420] train loss: 0.003816, tar: 0.000022 
l0: 0.000039, l1: 0.000038, l2: 0.000058, l3: 0.000187, l4: 0.000438, l5: 0.001319, l6: 0.001658

[epoch: 949/1000, batch:   464/ 1052, ite: 249440] train loss: 0.003819, tar: 0.000023 
l0: 0.000234, l1: 0.000267, l2: 0.000242, l3: 0.000271, l4: 0.000573, l5: 0.001689, l6: 0.001952

[epoch: 949/1000, batch:   544/ 1052, ite: 249460] train loss: 0.003823, tar: 0.000024 
l0: 0.000252, l1: 0.000294, l2: 0.000221, l3: 0.000227, l4: 0.000408, l5: 0.000836, l6: 0.001383

[epoch: 949/1000, batch:   624/ 1052, ite: 249480] train loss: 0.003830, tar: 0.000025 
l0: 0.000069, l1: 0.000070, l2: 0.000086, l3: 0.000297, l4: 0.000627, l5: 0.001093, l6: 0.001245

[epoch: 949/1000, batch:   704/ 1052, ite: 249500] train loss: 0.003832, tar: 0.000025 
l0: 0.000103, l1: 0.000116, l2: 0.000147, l3: 0.000207, l4: 0.000452, l5: 0.001565, l6: 0.003046

[epoch: 949/1000, batch:   784/ 1052, ite: 249520] train loss: 0.003835, tar: 0.000025 
l0: 0.000016, l1: 0.000015, l2: 0.000053, l3: 0.000239, l4: 0.000553, l5: 0.001169, l6: 0.002063

[epoch: 949/1000, batch:   864/ 1052, ite: 249540] train loss: 0.003837, tar: 0.000026 
l0: 0.000012, l1: 0.000021, l2: 0.000055, l3: 0.000088, l4: 0.000232, l5: 0.000510, l6: 0.000923

[epoch: 949/1000, batch:   944/ 1052, ite: 249560] train loss: 0.003837, tar: 0.000026 
l0: 0.000064, l1: 0.000068, l2: 0.000097, l3: 0.000202, l4: 0.000591, l5: 0.001422, l6: 0.002295

[epoch: 949/1000, batch:  1024/ 1052, ite: 249580] train loss: 0.003839, tar: 0.000026 
[Epoch 949/1000] Test loss: 0.025, Test target loss: 0.004
l0: 0.000024, l1: 0.000041, l2: 0.000048, l3: 0.000099, l4: 0.000374, l5: 0.000745, l6: 0.001376

[epoch: 950/1000, batch:    52/ 1052, ite: 249600] train loss: 0.003840, tar: 0.000026 
l0: 0.000043, l1: 0.000050, l2: 0.000082, l3: 0.000183, l4: 0.000415, l5: 0.000863, l6: 0.001832

[epoch: 950/1000, batch:   132/ 1052, ite: 249620] train loss: 0.003840, tar: 0.000026 
l0: 0.000069, l1: 0.000071, l2: 0.000113, l3: 0.000143, l4: 0.000353, l5: 0.000911, l6: 0.001961

[epoch: 950/1000, batch:   212/ 1052, ite: 249640] train loss: 0.003840, tar: 0.000026 
l0: 0.000065, l1: 0.000068, l2: 0.000150, l3: 0.000240, l4: 0.000379, l5: 0.001440, l6: 0.002207

[epoch: 950/1000, batch:   292/ 1052, ite: 249660] train loss: 0.003841, tar: 0.000026 
l0: 0.000103, l1: 0.000112, l2: 0.000132, l3: 0.000171, l4: 0.000571, l5: 0.000817, l6: 0.001518

[epoch: 950/1000, batch:   372/ 1052, ite: 249680] train loss: 0.003841, tar: 0.000026 
l0: 0.000011, l1: 0.000011, l2: 0.000019, l3: 0.000090, l4: 0.000248, l5: 0.000604, l6: 0.000971

[epoch: 950/1000, batch:   452/ 1052, ite: 249700] train loss: 0.003840, tar: 0.000026 
l0: 0.000020, l1: 0.000018, l2: 0.000037, l3: 0.000225, l4: 0.000524, l5: 0.001601, l6: 0.002191

[epoch: 950/1000, batch:   532/ 1052, ite: 249720] train loss: 0.003841, tar: 0.000026 
l0: 0.000045, l1: 0.000042, l2: 0.000079, l3: 0.000138, l4: 0.000388, l5: 0.000896, l6: 0.002956

[epoch: 950/1000, batch:   612/ 1052, ite: 249740] train loss: 0.003841, tar: 0.000026 
l0: 0.000025, l1: 0.000024, l2: 0.000045, l3: 0.000131, l4: 0.000415, l5: 0.000819, l6: 0.001691

[epoch: 950/1000, batch:   692/ 1052, ite: 249760] train loss: 0.003841, tar: 0.000026 
l0: 0.000016, l1: 0.000014, l2: 0.000042, l3: 0.000127, l4: 0.000341, l5: 0.000877, l6: 0.000981

[epoch: 950/1000, batch:   772/ 1052, ite: 249780] train loss: 0.003842, tar: 0.000026 
l0: 0.000084, l1: 0.000080, l2: 0.000265, l3: 0.000378, l4: 0.000784, l5: 0.001543, l6: 0.003143

[epoch: 950/1000, batch:   852/ 1052, ite: 249800] train loss: 0.003842, tar: 0.000026 
l0: 0.000002, l1: 0.000002, l2: 0.000013, l3: 0.000102, l4: 0.000352, l5: 0.000581, l6: 0.001114

[epoch: 950/1000, batch:   932/ 1052, ite: 249820] train loss: 0.003843, tar: 0.000027 
l0: 0.000052, l1: 0.000050, l2: 0.000071, l3: 0.000201, l4: 0.000393, l5: 0.000880, l6: 0.001075

[epoch: 950/1000, batch:  1012/ 1052, ite: 249840] train loss: 0.003843, tar: 0.000027 
[Epoch 950/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000023, l1: 0.000027, l2: 0.000044, l3: 0.000114, l4: 0.000248, l5: 0.001388, l6: 0.001137

[epoch: 951/1000, batch:    40/ 1052, ite: 249860] train loss: 0.003844, tar: 0.000027 
l0: 0.000012, l1: 0.000010, l2: 0.000030, l3: 0.000125, l4: 0.000329, l5: 0.000756, l6: 0.000893

[epoch: 951/1000, batch:   120/ 1052, ite: 249880] train loss: 0.003845, tar: 0.000027 
l0: 0.000029, l1: 0.000031, l2: 0.000050, l3: 0.000132, l4: 0.000334, l5: 0.000894, l6: 0.001595

[epoch: 951/1000, batch:   200/ 1052, ite: 249900] train loss: 0.003844, tar: 0.000027 
l0: 0.000050, l1: 0.000053, l2: 0.000078, l3: 0.000175, l4: 0.000278, l5: 0.001036, l6: 0.001973

[epoch: 951/1000, batch:   280/ 1052, ite: 249920] train loss: 0.003845, tar: 0.000027 
l0: 0.000020, l1: 0.000018, l2: 0.000049, l3: 0.000099, l4: 0.000249, l5: 0.000860, l6: 0.001379

[epoch: 951/1000, batch:   360/ 1052, ite: 249940] train loss: 0.003844, tar: 0.000027 
l0: 0.000009, l1: 0.000008, l2: 0.000044, l3: 0.000110, l4: 0.000314, l5: 0.000698, l6: 0.001223

[epoch: 951/1000, batch:   440/ 1052, ite: 249960] train loss: 0.003844, tar: 0.000027 
l0: 0.000022, l1: 0.000024, l2: 0.000027, l3: 0.000096, l4: 0.000330, l5: 0.000811, l6: 0.001220

[epoch: 951/1000, batch:   520/ 1052, ite: 249980] train loss: 0.003844, tar: 0.000027 
l0: 0.000017, l1: 0.000016, l2: 0.000074, l3: 0.000287, l4: 0.000845, l5: 0.001209, l6: 0.001934

[epoch: 951/1000, batch:   600/ 1052, ite: 250000] train loss: 0.003845, tar: 0.000027 
l0: 0.000011, l1: 0.000009, l2: 0.000042, l3: 0.000211, l4: 0.000487, l5: 0.001264, l6: 0.001847

[epoch: 951/1000, batch:   680/ 1052, ite: 250020] train loss: 0.003845, tar: 0.000027 
l0: 0.000050, l1: 0.000053, l2: 0.000071, l3: 0.000176, l4: 0.000442, l5: 0.001361, l6: 0.002393

[epoch: 951/1000, batch:   760/ 1052, ite: 250040] train loss: 0.003845, tar: 0.000027 
l0: 0.000051, l1: 0.000050, l2: 0.000076, l3: 0.000379, l4: 0.001096, l5: 0.001396, l6: 0.004283

[epoch: 951/1000, batch:   840/ 1052, ite: 250060] train loss: 0.003845, tar: 0.000027 
l0: 0.000055, l1: 0.000056, l2: 0.000121, l3: 0.000360, l4: 0.000672, l5: 0.002404, l6: 0.004063

[epoch: 951/1000, batch:   920/ 1052, ite: 250080] train loss: 0.003845, tar: 0.000027 
l0: 0.000017, l1: 0.000013, l2: 0.000068, l3: 0.000387, l4: 0.000731, l5: 0.001719, l6: 0.003048

[epoch: 951/1000, batch:  1000/ 1052, ite: 250100] train loss: 0.003845, tar: 0.000027 
[Epoch 951/1000] Test loss: 0.024, Test target loss: 0.004
l0: 0.000017, l1: 0.000027, l2: 0.000035, l3: 0.000190, l4: 0.000454, l5: 0.000902, l6: 0.001862

[epoch: 952/1000, batch:    28/ 1052, ite: 250120] train loss: 0.003845, tar: 0.000027 
l0: 0.000030, l1: 0.000028, l2: 0.000043, l3: 0.000121, l4: 0.000306, l5: 0.001092, l6: 0.002224

[epoch: 952/1000, batch:   108/ 1052, ite: 250140] train loss: 0.003846, tar: 0.000027 
l0: 0.000032, l1: 0.000034, l2: 0.000059, l3: 0.000124, l4: 0.000271, l5: 0.000701, l6: 0.001507

[epoch: 952/1000, batch:   188/ 1052, ite: 250160] train loss: 0.003845, tar: 0.000027 
l0: 0.000023, l1: 0.000020, l2: 0.000124, l3: 0.000228, l4: 0.000491, l5: 0.000575, l6: 0.001733

[epoch: 952/1000, batch:   268/ 1052, ite: 250180] train loss: 0.003845, tar: 0.000027 
l0: 0.000014, l1: 0.000015, l2: 0.000027, l3: 0.000116, l4: 0.000259, l5: 0.000600, l6: 0.001551

[epoch: 952/1000, batch:   348/ 1052, ite: 250200] train loss: 0.003844, tar: 0.000027 
l0: 0.000082, l1: 0.000093, l2: 0.000096, l3: 0.000229, l4: 0.000534, l5: 0.001123, l6: 0.002701

[epoch: 952/1000, batch:   428/ 1052, ite: 250220] train loss: 0.003845, tar: 0.000027 
l0: 0.000063, l1: 0.000058, l2: 0.000092, l3: 0.000170, l4: 0.000264, l5: 0.000675, l6: 0.000968

[epoch: 952/1000, batch:   508/ 1052, ite: 250240] train loss: 0.003846, tar: 0.000027 
l0: 0.000024, l1: 0.000023, l2: 0.000060, l3: 0.000217, l4: 0.000562, l5: 0.001218, l6: 0.002027

[epoch: 952/1000, batch:   588/ 1052, ite: 250260] train loss: 0.003846, tar: 0.000027 
l0: 0.000034, l1: 0.000030, l2: 0.000050, l3: 0.000131, l4: 0.000236, l5: 0.000563, l6: 0.001688

[epoch: 952/1000, batch:   668/ 1052, ite: 250280] train loss: 0.003846, tar: 0.000027 
l0: 0.000001, l1: 0.000001, l2: 0.000006, l3: 0.000144, l4: 0.000211, l5: 0.000853, l6: 0.000963

[epoch: 952/1000, batch:   748/ 1052, ite: 250300] train loss: 0.003846, tar: 0.000027 
l0: 0.000007, l1: 0.000010, l2: 0.000046, l3: 0.000109, l4: 0.000501, l5: 0.000865, l6: 0.001387

[epoch: 952/1000, batch:   828/ 1052, ite: 250320] train loss: 0.003845, tar: 0.000027 
l0: 0.000063, l1: 0.000073, l2: 0.000107, l3: 0.000243, l4: 0.000472, l5: 0.000789, l6: 0.002388

[epoch: 952/1000, batch:   908/ 1052, ite: 250340] train loss: 0.003845, tar: 0.000027 
l0: 0.000007, l1: 0.000007, l2: 0.000028, l3: 0.000126, l4: 0.000501, l5: 0.001229, l6: 0.002531

[epoch: 952/1000, batch:   988/ 1052, ite: 250360] train loss: 0.003845, tar: 0.000027 
[Epoch 952/1000] Test loss: 0.024, Test target loss: 0.004
l0: 0.000005, l1: 0.000004, l2: 0.000035, l3: 0.000296, l4: 0.000576, l5: 0.001052, l6: 0.002001

[epoch: 953/1000, batch:    16/ 1052, ite: 250380] train loss: 0.003846, tar: 0.000027 
l0: 0.000003, l1: 0.000006, l2: 0.000022, l3: 0.000112, l4: 0.000496, l5: 0.001277, l6: 0.001724

[epoch: 953/1000, batch:    96/ 1052, ite: 250400] train loss: 0.003845, tar: 0.000027 
l0: 0.000034, l1: 0.000035, l2: 0.000059, l3: 0.000200, l4: 0.000655, l5: 0.001981, l6: 0.003546

[epoch: 953/1000, batch:   176/ 1052, ite: 250420] train loss: 0.003845, tar: 0.000027 
l0: 0.000021, l1: 0.000025, l2: 0.000067, l3: 0.000260, l4: 0.000583, l5: 0.001376, l6: 0.002530

[epoch: 953/1000, batch:   256/ 1052, ite: 250440] train loss: 0.003846, tar: 0.000027 
l0: 0.000053, l1: 0.000057, l2: 0.000068, l3: 0.000217, l4: 0.000693, l5: 0.001075, l6: 0.002160

[epoch: 953/1000, batch:   336/ 1052, ite: 250460] train loss: 0.003846, tar: 0.000027 
l0: 0.000006, l1: 0.000004, l2: 0.000014, l3: 0.000062, l4: 0.000306, l5: 0.000606, l6: 0.001126

[epoch: 953/1000, batch:   416/ 1052, ite: 250480] train loss: 0.003846, tar: 0.000026 
l0: 0.000007, l1: 0.000007, l2: 0.000014, l3: 0.000057, l4: 0.000177, l5: 0.000717, l6: 0.001115

[epoch: 953/1000, batch:   496/ 1052, ite: 250500] train loss: 0.003845, tar: 0.000026 
l0: 0.000003, l1: 0.000003, l2: 0.000003, l3: 0.000055, l4: 0.000282, l5: 0.000558, l6: 0.001201

[epoch: 953/1000, batch:   576/ 1052, ite: 250520] train loss: 0.003846, tar: 0.000026 
l0: 0.000022, l1: 0.000019, l2: 0.000053, l3: 0.000071, l4: 0.000563, l5: 0.000824, l6: 0.001163

[epoch: 953/1000, batch:   656/ 1052, ite: 250540] train loss: 0.003846, tar: 0.000026 
l0: 0.000011, l1: 0.000010, l2: 0.000039, l3: 0.000133, l4: 0.000574, l5: 0.001005, l6: 0.001655

[epoch: 953/1000, batch:   736/ 1052, ite: 250560] train loss: 0.003846, tar: 0.000026 
l0: 0.000087, l1: 0.000100, l2: 0.000085, l3: 0.000293, l4: 0.000619, l5: 0.001432, l6: 0.002838

[epoch: 953/1000, batch:   816/ 1052, ite: 250580] train loss: 0.003846, tar: 0.000026 
l0: 0.000011, l1: 0.000010, l2: 0.000056, l3: 0.000220, l4: 0.000685, l5: 0.001279, l6: 0.002651

[epoch: 953/1000, batch:   896/ 1052, ite: 250600] train loss: 0.003847, tar: 0.000026 
l0: 0.000029, l1: 0.000027, l2: 0.000079, l3: 0.000158, l4: 0.000394, l5: 0.000780, l6: 0.001991

[epoch: 953/1000, batch:   976/ 1052, ite: 250620] train loss: 0.003846, tar: 0.000026 
[Epoch 953/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000007, l1: 0.000005, l2: 0.000051, l3: 0.000216, l4: 0.000905, l5: 0.000936, l6: 0.002363

[epoch: 954/1000, batch:     4/ 1052, ite: 250640] train loss: 0.003846, tar: 0.000026 
l0: 0.000028, l1: 0.000023, l2: 0.000112, l3: 0.000330, l4: 0.000589, l5: 0.001030, l6: 0.002634

[epoch: 954/1000, batch:    84/ 1052, ite: 250660] train loss: 0.003845, tar: 0.000026 
l0: 0.000005, l1: 0.000006, l2: 0.000025, l3: 0.000095, l4: 0.000290, l5: 0.000686, l6: 0.002247

[epoch: 954/1000, batch:   164/ 1052, ite: 250680] train loss: 0.003845, tar: 0.000026 
l0: 0.000008, l1: 0.000007, l2: 0.000022, l3: 0.000147, l4: 0.000178, l5: 0.000996, l6: 0.001283

[epoch: 954/1000, batch:   244/ 1052, ite: 250700] train loss: 0.003844, tar: 0.000026 
l0: 0.000009, l1: 0.000008, l2: 0.000060, l3: 0.000299, l4: 0.000756, l5: 0.001759, l6: 0.002534

[epoch: 954/1000, batch:   324/ 1052, ite: 250720] train loss: 0.003845, tar: 0.000026 
l0: 0.000002, l1: 0.000002, l2: 0.000014, l3: 0.000104, l4: 0.000265, l5: 0.000777, l6: 0.001481

[epoch: 954/1000, batch:   404/ 1052, ite: 250740] train loss: 0.003845, tar: 0.000026 
l0: 0.000006, l1: 0.000006, l2: 0.000020, l3: 0.000103, l4: 0.000427, l5: 0.000921, l6: 0.002304

[epoch: 954/1000, batch:   484/ 1052, ite: 250760] train loss: 0.003845, tar: 0.000026 
l0: 0.000014, l1: 0.000012, l2: 0.000039, l3: 0.000201, l4: 0.000403, l5: 0.001019, l6: 0.001329

[epoch: 954/1000, batch:   564/ 1052, ite: 250780] train loss: 0.003845, tar: 0.000026 
l0: 0.000002, l1: 0.000002, l2: 0.000015, l3: 0.000058, l4: 0.000424, l5: 0.000732, l6: 0.001778

[epoch: 954/1000, batch:   644/ 1052, ite: 250800] train loss: 0.003846, tar: 0.000026 
l0: 0.000009, l1: 0.000007, l2: 0.000033, l3: 0.000136, l4: 0.000535, l5: 0.000822, l6: 0.001466

[epoch: 954/1000, batch:   724/ 1052, ite: 250820] train loss: 0.003844, tar: 0.000026 
l0: 0.000003, l1: 0.000005, l2: 0.000024, l3: 0.000196, l4: 0.000443, l5: 0.000825, l6: 0.002139

[epoch: 954/1000, batch:   804/ 1052, ite: 250840] train loss: 0.003845, tar: 0.000026 
l0: 0.000013, l1: 0.000014, l2: 0.000061, l3: 0.000367, l4: 0.000910, l5: 0.001627, l6: 0.002978

[epoch: 954/1000, batch:   884/ 1052, ite: 250860] train loss: 0.003844, tar: 0.000026 
l0: 0.000008, l1: 0.000010, l2: 0.000034, l3: 0.000216, l4: 0.000731, l5: 0.000907, l6: 0.002476

[epoch: 954/1000, batch:   964/ 1052, ite: 250880] train loss: 0.003844, tar: 0.000026 
l0: 0.000039, l1: 0.000039, l2: 0.000069, l3: 0.000152, l4: 0.000441, l5: 0.001350, l6: 0.002624

[epoch: 954/1000, batch:  1044/ 1052, ite: 250900] train loss: 0.003845, tar: 0.000026 
[Epoch 954/1000] Test loss: 0.024, Test target loss: 0.004
l0: 0.000026, l1: 0.000027, l2: 0.000049, l3: 0.000094, l4: 0.000231, l5: 0.000706, l6: 0.001502

[epoch: 955/1000, batch:    72/ 1052, ite: 250920] train loss: 0.003846, tar: 0.000026 
l0: 0.000013, l1: 0.000021, l2: 0.000050, l3: 0.000183, l4: 0.000596, l5: 0.001320, l6: 0.003095

[epoch: 955/1000, batch:   152/ 1052, ite: 250940] train loss: 0.003847, tar: 0.000026 
l0: 0.000008, l1: 0.000006, l2: 0.000047, l3: 0.000230, l4: 0.000421, l5: 0.001198, l6: 0.001781

[epoch: 955/1000, batch:   232/ 1052, ite: 250960] train loss: 0.003846, tar: 0.000026 
l0: 0.000003, l1: 0.000004, l2: 0.000010, l3: 0.000061, l4: 0.000248, l5: 0.000669, l6: 0.000806

[epoch: 955/1000, batch:   312/ 1052, ite: 250980] train loss: 0.003845, tar: 0.000026 
l0: 0.000015, l1: 0.000016, l2: 0.000043, l3: 0.000176, l4: 0.000536, l5: 0.001358, l6: 0.003570

[epoch: 955/1000, batch:   392/ 1052, ite: 251000] train loss: 0.003844, tar: 0.000026 
l0: 0.000003, l1: 0.000002, l2: 0.000019, l3: 0.000141, l4: 0.000535, l5: 0.001151, l6: 0.001850

[epoch: 955/1000, batch:   472/ 1052, ite: 251020] train loss: 0.003844, tar: 0.000026 
l0: 0.000007, l1: 0.000007, l2: 0.000034, l3: 0.000133, l4: 0.000422, l5: 0.001516, l6: 0.001698

[epoch: 955/1000, batch:   552/ 1052, ite: 251040] train loss: 0.003843, tar: 0.000026 
l0: 0.000020, l1: 0.000021, l2: 0.000042, l3: 0.000143, l4: 0.000432, l5: 0.001142, l6: 0.002891

[epoch: 955/1000, batch:   632/ 1052, ite: 251060] train loss: 0.003843, tar: 0.000026 
l0: 0.000063, l1: 0.000064, l2: 0.000074, l3: 0.000161, l4: 0.000349, l5: 0.000898, l6: 0.001390

[epoch: 955/1000, batch:   712/ 1052, ite: 251080] train loss: 0.003844, tar: 0.000026 
l0: 0.000006, l1: 0.000005, l2: 0.000034, l3: 0.000188, l4: 0.000528, l5: 0.000937, l6: 0.002842

[epoch: 955/1000, batch:   792/ 1052, ite: 251100] train loss: 0.003843, tar: 0.000026 
l0: 0.000007, l1: 0.000007, l2: 0.000020, l3: 0.000119, l4: 0.000479, l5: 0.000768, l6: 0.001857

[epoch: 955/1000, batch:   872/ 1052, ite: 251120] train loss: 0.003843, tar: 0.000026 
l0: 0.000012, l1: 0.000013, l2: 0.000017, l3: 0.000119, l4: 0.000416, l5: 0.001121, l6: 0.001718

[epoch: 955/1000, batch:   952/ 1052, ite: 251140] train loss: 0.003844, tar: 0.000026 
l0: 0.000013, l1: 0.000013, l2: 0.000046, l3: 0.000190, l4: 0.000294, l5: 0.001019, l6: 0.001578

[epoch: 955/1000, batch:  1032/ 1052, ite: 251160] train loss: 0.003844, tar: 0.000026 
[Epoch 955/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000005, l1: 0.000005, l2: 0.000026, l3: 0.000120, l4: 0.000360, l5: 0.000818, l6: 0.001153

[epoch: 956/1000, batch:    60/ 1052, ite: 251180] train loss: 0.003843, tar: 0.000026 
l0: 0.000022, l1: 0.000024, l2: 0.000020, l3: 0.000100, l4: 0.000268, l5: 0.000545, l6: 0.001296

[epoch: 956/1000, batch:   140/ 1052, ite: 251200] train loss: 0.003842, tar: 0.000026 
l0: 0.000014, l1: 0.000017, l2: 0.000018, l3: 0.000101, l4: 0.000391, l5: 0.000968, l6: 0.002369

[epoch: 956/1000, batch:   220/ 1052, ite: 251220] train loss: 0.003841, tar: 0.000026 
l0: 0.000003, l1: 0.000002, l2: 0.000027, l3: 0.000078, l4: 0.000344, l5: 0.000938, l6: 0.001934

[epoch: 956/1000, batch:   300/ 1052, ite: 251240] train loss: 0.003841, tar: 0.000026 
l0: 0.000007, l1: 0.000005, l2: 0.000029, l3: 0.000123, l4: 0.000293, l5: 0.000689, l6: 0.001179

[epoch: 956/1000, batch:   380/ 1052, ite: 251260] train loss: 0.003841, tar: 0.000026 
l0: 0.000008, l1: 0.000010, l2: 0.000049, l3: 0.000373, l4: 0.000945, l5: 0.002152, l6: 0.003390

[epoch: 956/1000, batch:   460/ 1052, ite: 251280] train loss: 0.003842, tar: 0.000026 
l0: 0.000019, l1: 0.000022, l2: 0.000034, l3: 0.000167, l4: 0.000482, l5: 0.000974, l6: 0.002803

[epoch: 956/1000, batch:   540/ 1052, ite: 251300] train loss: 0.003842, tar: 0.000026 
l0: 0.000008, l1: 0.000007, l2: 0.000029, l3: 0.000070, l4: 0.000446, l5: 0.000705, l6: 0.001095

[epoch: 956/1000, batch:   620/ 1052, ite: 251320] train loss: 0.003842, tar: 0.000026 
l0: 0.000078, l1: 0.000084, l2: 0.000136, l3: 0.000157, l4: 0.000834, l5: 0.000928, l6: 0.002202

[epoch: 956/1000, batch:   700/ 1052, ite: 251340] train loss: 0.003842, tar: 0.000026 
l0: 0.000011, l1: 0.000011, l2: 0.000052, l3: 0.000140, l4: 0.000316, l5: 0.001309, l6: 0.002812

[epoch: 956/1000, batch:   780/ 1052, ite: 251360] train loss: 0.003842, tar: 0.000026 
l0: 0.000022, l1: 0.000020, l2: 0.000061, l3: 0.000150, l4: 0.000316, l5: 0.001342, l6: 0.001948

[epoch: 956/1000, batch:   860/ 1052, ite: 251380] train loss: 0.003842, tar: 0.000026 
l0: 0.000002, l1: 0.000002, l2: 0.000026, l3: 0.000120, l4: 0.000446, l5: 0.001169, l6: 0.001489

[epoch: 956/1000, batch:   940/ 1052, ite: 251400] train loss: 0.003843, tar: 0.000026 
l0: 0.000004, l1: 0.000003, l2: 0.000032, l3: 0.000159, l4: 0.000411, l5: 0.001214, l6: 0.002490

[epoch: 956/1000, batch:  1020/ 1052, ite: 251420] train loss: 0.003842, tar: 0.000026 
[Epoch 956/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000027, l1: 0.000030, l2: 0.000046, l3: 0.000130, l4: 0.000507, l5: 0.000778, l6: 0.002124

[epoch: 957/1000, batch:    48/ 1052, ite: 251440] train loss: 0.003843, tar: 0.000026 
l0: 0.000014, l1: 0.000014, l2: 0.000052, l3: 0.000240, l4: 0.000575, l5: 0.001041, l6: 0.002225

[epoch: 957/1000, batch:   128/ 1052, ite: 251460] train loss: 0.003843, tar: 0.000026 
l0: 0.000010, l1: 0.000009, l2: 0.000034, l3: 0.000135, l4: 0.000503, l5: 0.000794, l6: 0.001426

[epoch: 957/1000, batch:   208/ 1052, ite: 251480] train loss: 0.003844, tar: 0.000026 
l0: 0.000007, l1: 0.000006, l2: 0.000032, l3: 0.000131, l4: 0.000366, l5: 0.001196, l6: 0.001679

[epoch: 957/1000, batch:   288/ 1052, ite: 251500] train loss: 0.003843, tar: 0.000026 
l0: 0.000007, l1: 0.000006, l2: 0.000013, l3: 0.000128, l4: 0.000249, l5: 0.000890, l6: 0.001146

[epoch: 957/1000, batch:   368/ 1052, ite: 251520] train loss: 0.003844, tar: 0.000026 
l0: 0.000017, l1: 0.000016, l2: 0.000056, l3: 0.000232, l4: 0.000704, l5: 0.001200, l6: 0.002525

[epoch: 957/1000, batch:   448/ 1052, ite: 251540] train loss: 0.003844, tar: 0.000026 
l0: 0.000002, l1: 0.000003, l2: 0.000007, l3: 0.000067, l4: 0.000315, l5: 0.000840, l6: 0.001537

[epoch: 957/1000, batch:   528/ 1052, ite: 251560] train loss: 0.003844, tar: 0.000025 
l0: 0.000055, l1: 0.000049, l2: 0.000102, l3: 0.000116, l4: 0.000312, l5: 0.000629, l6: 0.002051

[epoch: 957/1000, batch:   608/ 1052, ite: 251580] train loss: 0.003843, tar: 0.000025 
l0: 0.000046, l1: 0.000056, l2: 0.000060, l3: 0.000178, l4: 0.000606, l5: 0.001624, l6: 0.003443

[epoch: 957/1000, batch:   688/ 1052, ite: 251600] train loss: 0.003842, tar: 0.000025 
l0: 0.000006, l1: 0.000006, l2: 0.000015, l3: 0.000073, l4: 0.000301, l5: 0.000846, l6: 0.001181

[epoch: 957/1000, batch:   768/ 1052, ite: 251620] train loss: 0.003841, tar: 0.000025 
l0: 0.000010, l1: 0.000008, l2: 0.000044, l3: 0.000096, l4: 0.000336, l5: 0.001065, l6: 0.001538

[epoch: 957/1000, batch:   848/ 1052, ite: 251640] train loss: 0.003841, tar: 0.000025 
l0: 0.000009, l1: 0.000007, l2: 0.000061, l3: 0.000319, l4: 0.000647, l5: 0.001033, l6: 0.001750

[epoch: 957/1000, batch:   928/ 1052, ite: 251660] train loss: 0.003841, tar: 0.000025 
l0: 0.000027, l1: 0.000035, l2: 0.000071, l3: 0.000250, l4: 0.000732, l5: 0.001890, l6: 0.002576

[epoch: 957/1000, batch:  1008/ 1052, ite: 251680] train loss: 0.003841, tar: 0.000025 
[Epoch 957/1000] Test loss: 0.024, Test target loss: 0.005
l0: 0.000014, l1: 0.000013, l2: 0.000033, l3: 0.000121, l4: 0.000237, l5: 0.000919, l6: 0.002337

[epoch: 958/1000, batch:    36/ 1052, ite: 251700] train loss: 0.003841, tar: 0.000025 
l0: 0.000033, l1: 0.000040, l2: 0.000058, l3: 0.000147, l4: 0.000377, l5: 0.000959, l6: 0.001785

[epoch: 958/1000, batch:   116/ 1052, ite: 251720] train loss: 0.003841, tar: 0.000025 
l0: 0.000029, l1: 0.000026, l2: 0.000092, l3: 0.000278, l4: 0.000631, l5: 0.002235, l6: 0.003137

[epoch: 958/1000, batch:   196/ 1052, ite: 251740] train loss: 0.003841, tar: 0.000025 
l0: 0.000014, l1: 0.000012, l2: 0.000069, l3: 0.000207, l4: 0.000510, l5: 0.000993, l6: 0.001787

[epoch: 958/1000, batch:   276/ 1052, ite: 251760] train loss: 0.003841, tar: 0.000025 
l0: 0.000036, l1: 0.000038, l2: 0.000085, l3: 0.000254, l4: 0.000598, l5: 0.001644, l6: 0.003117

[epoch: 958/1000, batch:   356/ 1052, ite: 251780] train loss: 0.003841, tar: 0.000025 
l0: 0.000009, l1: 0.000010, l2: 0.000037, l3: 0.000151, l4: 0.000452, l5: 0.000939, l6: 0.001933

[epoch: 958/1000, batch:   436/ 1052, ite: 251800] train loss: 0.003840, tar: 0.000025 
l0: 0.000035, l1: 0.000036, l2: 0.000049, l3: 0.000089, l4: 0.000357, l5: 0.001000, l6: 0.001327

[epoch: 958/1000, batch:   516/ 1052, ite: 251820] train loss: 0.003840, tar: 0.000025 
l0: 0.000009, l1: 0.000008, l2: 0.000021, l3: 0.000118, l4: 0.000274, l5: 0.000834, l6: 0.001406

[epoch: 958/1000, batch:   596/ 1052, ite: 251840] train loss: 0.003840, tar: 0.000025 
l0: 0.000016, l1: 0.000017, l2: 0.000076, l3: 0.000123, l4: 0.000319, l5: 0.000909, l6: 0.001250

[epoch: 958/1000, batch:   676/ 1052, ite: 251860] train loss: 0.003839, tar: 0.000025 
l0: 0.000031, l1: 0.000035, l2: 0.000116, l3: 0.000304, l4: 0.000613, l5: 0.001898, l6: 0.002576

[epoch: 958/1000, batch:   756/ 1052, ite: 251880] train loss: 0.003838, tar: 0.000025 
l0: 0.000004, l1: 0.000004, l2: 0.000017, l3: 0.000138, l4: 0.000496, l5: 0.001042, l6: 0.002178

[epoch: 958/1000, batch:   836/ 1052, ite: 251900] train loss: 0.003838, tar: 0.000025 
l0: 0.000020, l1: 0.000021, l2: 0.000127, l3: 0.000523, l4: 0.001134, l5: 0.003423, l6: 0.005930

[epoch: 958/1000, batch:   916/ 1052, ite: 251920] train loss: 0.003838, tar: 0.000025 
l0: 0.000007, l1: 0.000007, l2: 0.000014, l3: 0.000074, l4: 0.000472, l5: 0.000699, l6: 0.001431

[epoch: 958/1000, batch:   996/ 1052, ite: 251940] train loss: 0.003838, tar: 0.000025 
[Epoch 958/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000027, l1: 0.000026, l2: 0.000053, l3: 0.000159, l4: 0.000360, l5: 0.001149, l6: 0.002741

[epoch: 959/1000, batch:    24/ 1052, ite: 251960] train loss: 0.003838, tar: 0.000025 
l0: 0.000028, l1: 0.000029, l2: 0.000045, l3: 0.000103, l4: 0.000252, l5: 0.000761, l6: 0.001227

[epoch: 959/1000, batch:   104/ 1052, ite: 251980] train loss: 0.003838, tar: 0.000025 
l0: 0.000015, l1: 0.000015, l2: 0.000096, l3: 0.000179, l4: 0.000443, l5: 0.000994, l6: 0.001733

[epoch: 959/1000, batch:   184/ 1052, ite: 252000] train loss: 0.003837, tar: 0.000025 
l0: 0.000012, l1: 0.000010, l2: 0.000081, l3: 0.000415, l4: 0.000746, l5: 0.002284, l6: 0.002373

[epoch: 959/1000, batch:   264/ 1052, ite: 252020] train loss: 0.003836, tar: 0.000025 
l0: 0.000010, l1: 0.000009, l2: 0.000034, l3: 0.000144, l4: 0.000355, l5: 0.000874, l6: 0.000838

[epoch: 959/1000, batch:   344/ 1052, ite: 252040] train loss: 0.003835, tar: 0.000025 
l0: 0.000033, l1: 0.000032, l2: 0.000024, l3: 0.000089, l4: 0.000108, l5: 0.000408, l6: 0.001274

[epoch: 959/1000, batch:   424/ 1052, ite: 252060] train loss: 0.003836, tar: 0.000025 
l0: 0.000010, l1: 0.000010, l2: 0.000069, l3: 0.000241, l4: 0.000527, l5: 0.001176, l6: 0.001680

[epoch: 959/1000, batch:   504/ 1052, ite: 252080] train loss: 0.003836, tar: 0.000025 
l0: 0.000010, l1: 0.000013, l2: 0.000055, l3: 0.000466, l4: 0.000916, l5: 0.002016, l6: 0.002992

[epoch: 959/1000, batch:   584/ 1052, ite: 252100] train loss: 0.003836, tar: 0.000025 
l0: 0.000035, l1: 0.000035, l2: 0.000068, l3: 0.000315, l4: 0.000805, l5: 0.001565, l6: 0.003146

[epoch: 959/1000, batch:   664/ 1052, ite: 252120] train loss: 0.003837, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000025, l3: 0.000135, l4: 0.000580, l5: 0.001478, l6: 0.002917

[epoch: 959/1000, batch:   744/ 1052, ite: 252140] train loss: 0.003837, tar: 0.000025 
l0: 0.000012, l1: 0.000012, l2: 0.000067, l3: 0.000252, l4: 0.000620, l5: 0.001095, l6: 0.001080

[epoch: 959/1000, batch:   824/ 1052, ite: 252160] train loss: 0.003838, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000007, l3: 0.000065, l4: 0.000303, l5: 0.000698, l6: 0.001024

[epoch: 959/1000, batch:   904/ 1052, ite: 252180] train loss: 0.003838, tar: 0.000025 
l0: 0.000026, l1: 0.000028, l2: 0.000054, l3: 0.000199, l4: 0.000409, l5: 0.001282, l6: 0.003156

[epoch: 959/1000, batch:   984/ 1052, ite: 252200] train loss: 0.003837, tar: 0.000025 
[Epoch 959/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000004, l1: 0.000004, l2: 0.000044, l3: 0.000287, l4: 0.000581, l5: 0.001541, l6: 0.002277

[epoch: 960/1000, batch:    12/ 1052, ite: 252220] train loss: 0.003837, tar: 0.000025 
l0: 0.000008, l1: 0.000009, l2: 0.000029, l3: 0.000081, l4: 0.000289, l5: 0.000645, l6: 0.001836

[epoch: 960/1000, batch:    92/ 1052, ite: 252240] train loss: 0.003837, tar: 0.000025 
l0: 0.000003, l1: 0.000002, l2: 0.000044, l3: 0.000143, l4: 0.000464, l5: 0.001104, l6: 0.001397

[epoch: 960/1000, batch:   172/ 1052, ite: 252260] train loss: 0.003836, tar: 0.000025 
l0: 0.000010, l1: 0.000010, l2: 0.000044, l3: 0.000223, l4: 0.000509, l5: 0.000813, l6: 0.001955

[epoch: 960/1000, batch:   252/ 1052, ite: 252280] train loss: 0.003837, tar: 0.000025 
l0: 0.000002, l1: 0.000002, l2: 0.000024, l3: 0.000057, l4: 0.000395, l5: 0.000503, l6: 0.001333

[epoch: 960/1000, batch:   332/ 1052, ite: 252300] train loss: 0.003837, tar: 0.000025 
l0: 0.000021, l1: 0.000025, l2: 0.000110, l3: 0.000155, l4: 0.000437, l5: 0.001054, l6: 0.002077

[epoch: 960/1000, batch:   412/ 1052, ite: 252320] train loss: 0.003837, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000011, l3: 0.000056, l4: 0.000251, l5: 0.000723, l6: 0.001172

[epoch: 960/1000, batch:   492/ 1052, ite: 252340] train loss: 0.003838, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000039, l3: 0.000190, l4: 0.000434, l5: 0.000860, l6: 0.001776

[epoch: 960/1000, batch:   572/ 1052, ite: 252360] train loss: 0.003838, tar: 0.000025 
l0: 0.000040, l1: 0.000041, l2: 0.000143, l3: 0.000616, l4: 0.001213, l5: 0.001847, l6: 0.003468

[epoch: 960/1000, batch:   652/ 1052, ite: 252380] train loss: 0.003837, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000011, l3: 0.000083, l4: 0.000285, l5: 0.000704, l6: 0.001619

[epoch: 960/1000, batch:   732/ 1052, ite: 252400] train loss: 0.003838, tar: 0.000025 
l0: 0.000004, l1: 0.000004, l2: 0.000022, l3: 0.000140, l4: 0.000642, l5: 0.001166, l6: 0.002076

[epoch: 960/1000, batch:   812/ 1052, ite: 252420] train loss: 0.003837, tar: 0.000025 
l0: 0.000001, l1: 0.000001, l2: 0.000025, l3: 0.000094, l4: 0.000264, l5: 0.000816, l6: 0.001297

[epoch: 960/1000, batch:   892/ 1052, ite: 252440] train loss: 0.003837, tar: 0.000025 
l0: 0.000005, l1: 0.000005, l2: 0.000048, l3: 0.000164, l4: 0.000472, l5: 0.001044, l6: 0.001487

[epoch: 960/1000, batch:   972/ 1052, ite: 252460] train loss: 0.003836, tar: 0.000025 
l0: 0.000015, l1: 0.000014, l2: 0.000034, l3: 0.000147, l4: 0.000353, l5: 0.001048, l6: 0.001692

[epoch: 960/1000, batch:  1052/ 1052, ite: 252480] train loss: 0.003836, tar: 0.000025 
[Epoch 960/1000] Test loss: 0.023, Test target loss: 0.005
l0: 0.000002, l1: 0.000003, l2: 0.000015, l3: 0.000134, l4: 0.000258, l5: 0.000658, l6: 0.001615

[epoch: 961/1000, batch:    80/ 1052, ite: 252500] train loss: 0.003760, tar: 0.000015 
l0: 0.000018, l1: 0.000018, l2: 0.000075, l3: 0.000171, l4: 0.000438, l5: 0.001504, l6: 0.002978

[epoch: 961/1000, batch:   160/ 1052, ite: 252520] train loss: 0.003879, tar: 0.000015 
l0: 0.000058, l1: 0.000062, l2: 0.000077, l3: 0.000237, l4: 0.000572, l5: 0.000908, l6: 0.001883

[epoch: 961/1000, batch:   240/ 1052, ite: 252540] train loss: 0.003960, tar: 0.000015 
l0: 0.000006, l1: 0.000006, l2: 0.000027, l3: 0.000060, l4: 0.000279, l5: 0.000940, l6: 0.001229

[epoch: 961/1000, batch:   320/ 1052, ite: 252560] train loss: 0.003977, tar: 0.000016 
l0: 0.000012, l1: 0.000015, l2: 0.000030, l3: 0.000193, l4: 0.000518, l5: 0.001824, l6: 0.002578

[epoch: 961/1000, batch:   400/ 1052, ite: 252580] train loss: 0.003980, tar: 0.000016 
l0: 0.000003, l1: 0.000003, l2: 0.000008, l3: 0.000048, l4: 0.000221, l5: 0.000790, l6: 0.001708

[epoch: 961/1000, batch:   480/ 1052, ite: 252600] train loss: 0.003914, tar: 0.000016 
l0: 0.000005, l1: 0.000005, l2: 0.000037, l3: 0.000170, l4: 0.000301, l5: 0.001394, l6: 0.001685

[epoch: 961/1000, batch:   560/ 1052, ite: 252620] train loss: 0.003922, tar: 0.000016 
l0: 0.000014, l1: 0.000013, l2: 0.000025, l3: 0.000243, l4: 0.000330, l5: 0.001177, l6: 0.002759

[epoch: 961/1000, batch:   640/ 1052, ite: 252640] train loss: 0.003949, tar: 0.000016 
l0: 0.000002, l1: 0.000003, l2: 0.000021, l3: 0.000133, l4: 0.000433, l5: 0.000797, l6: 0.001422

[epoch: 961/1000, batch:   720/ 1052, ite: 252660] train loss: 0.003873, tar: 0.000016 
l0: 0.000016, l1: 0.000018, l2: 0.000025, l3: 0.000065, l4: 0.000131, l5: 0.000364, l6: 0.001106

[epoch: 961/1000, batch:   800/ 1052, ite: 252680] train loss: 0.003847, tar: 0.000016 
l0: 0.000003, l1: 0.000003, l2: 0.000023, l3: 0.000086, l4: 0.000259, l5: 0.000907, l6: 0.001831

[epoch: 961/1000, batch:   880/ 1052, ite: 252700] train loss: 0.003822, tar: 0.000016 
l0: 0.000015, l1: 0.000016, l2: 0.000043, l3: 0.000157, l4: 0.000449, l5: 0.000753, l6: 0.001792

[epoch: 961/1000, batch:   960/ 1052, ite: 252720] train loss: 0.003798, tar: 0.000016 
l0: 0.000051, l1: 0.000058, l2: 0.000051, l3: 0.000150, l4: 0.000659, l5: 0.001415, l6: 0.002219

[epoch: 961/1000, batch:  1040/ 1052, ite: 252740] train loss: 0.003821, tar: 0.000016 
[Epoch 961/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000029, l1: 0.000030, l2: 0.000047, l3: 0.000211, l4: 0.000494, l5: 0.001072, l6: 0.002273

[epoch: 962/1000, batch:    68/ 1052, ite: 252760] train loss: 0.003830, tar: 0.000017 
l0: 0.000016, l1: 0.000017, l2: 0.000050, l3: 0.000232, l4: 0.000869, l5: 0.002075, l6: 0.003528

[epoch: 962/1000, batch:   148/ 1052, ite: 252780] train loss: 0.003826, tar: 0.000017 
l0: 0.000000, l1: 0.000000, l2: 0.000009, l3: 0.000121, l4: 0.000323, l5: 0.000403, l6: 0.000902

[epoch: 962/1000, batch:   228/ 1052, ite: 252800] train loss: 0.003824, tar: 0.000017 
l0: 0.000044, l1: 0.000041, l2: 0.000073, l3: 0.000234, l4: 0.000640, l5: 0.001710, l6: 0.002447

[epoch: 962/1000, batch:   308/ 1052, ite: 252820] train loss: 0.003835, tar: 0.000016 
l0: 0.000020, l1: 0.000020, l2: 0.000058, l3: 0.000209, l4: 0.000463, l5: 0.001002, l6: 0.001910

[epoch: 962/1000, batch:   388/ 1052, ite: 252840] train loss: 0.003859, tar: 0.000017 
l0: 0.000019, l1: 0.000020, l2: 0.000030, l3: 0.000125, l4: 0.000634, l5: 0.001146, l6: 0.001854

[epoch: 962/1000, batch:   468/ 1052, ite: 252860] train loss: 0.003837, tar: 0.000017 
l0: 0.000003, l1: 0.000003, l2: 0.000019, l3: 0.000136, l4: 0.000223, l5: 0.000978, l6: 0.001679

[epoch: 962/1000, batch:   548/ 1052, ite: 252880] train loss: 0.003819, tar: 0.000017 
l0: 0.000027, l1: 0.000033, l2: 0.000083, l3: 0.000350, l4: 0.000751, l5: 0.001800, l6: 0.002738

[epoch: 962/1000, batch:   628/ 1052, ite: 252900] train loss: 0.003816, tar: 0.000016 
l0: 0.000019, l1: 0.000018, l2: 0.000056, l3: 0.000133, l4: 0.000284, l5: 0.000948, l6: 0.000889

[epoch: 962/1000, batch:   708/ 1052, ite: 252920] train loss: 0.003814, tar: 0.000017 
l0: 0.000003, l1: 0.000004, l2: 0.000016, l3: 0.000067, l4: 0.000358, l5: 0.001035, l6: 0.001522

[epoch: 962/1000, batch:   788/ 1052, ite: 252940] train loss: 0.003797, tar: 0.000016 
l0: 0.000009, l1: 0.000009, l2: 0.000045, l3: 0.000151, l4: 0.000382, l5: 0.000769, l6: 0.001684

[epoch: 962/1000, batch:   868/ 1052, ite: 252960] train loss: 0.003816, tar: 0.000016 
l0: 0.000033, l1: 0.000033, l2: 0.000058, l3: 0.000225, l4: 0.000496, l5: 0.001739, l6: 0.003121

[epoch: 962/1000, batch:   948/ 1052, ite: 252980] train loss: 0.003810, tar: 0.000016 
l0: 0.000054, l1: 0.000055, l2: 0.000090, l3: 0.000143, l4: 0.000245, l5: 0.000781, l6: 0.002753

[epoch: 962/1000, batch:  1028/ 1052, ite: 253000] train loss: 0.003814, tar: 0.000016 
[Epoch 962/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000012, l1: 0.000012, l2: 0.000063, l3: 0.000245, l4: 0.000793, l5: 0.001560, l6: 0.002636

[epoch: 963/1000, batch:    56/ 1052, ite: 253020] train loss: 0.003817, tar: 0.000016 
l0: 0.000078, l1: 0.000082, l2: 0.000149, l3: 0.000398, l4: 0.000672, l5: 0.001690, l6: 0.004537

[epoch: 963/1000, batch:   136/ 1052, ite: 253040] train loss: 0.003818, tar: 0.000016 
l0: 0.000007, l1: 0.000006, l2: 0.000044, l3: 0.000153, l4: 0.000431, l5: 0.001195, l6: 0.001639

[epoch: 963/1000, batch:   216/ 1052, ite: 253060] train loss: 0.003809, tar: 0.000016 
l0: 0.000000, l1: 0.000001, l2: 0.000005, l3: 0.000055, l4: 0.000275, l5: 0.000815, l6: 0.001884

[epoch: 963/1000, batch:   296/ 1052, ite: 253080] train loss: 0.003827, tar: 0.000016 
l0: 0.000010, l1: 0.000010, l2: 0.000047, l3: 0.000148, l4: 0.000462, l5: 0.000989, l6: 0.001176

[epoch: 963/1000, batch:   376/ 1052, ite: 253100] train loss: 0.003810, tar: 0.000016 
l0: 0.000027, l1: 0.000026, l2: 0.000078, l3: 0.000279, l4: 0.000521, l5: 0.000953, l6: 0.002432

[epoch: 963/1000, batch:   456/ 1052, ite: 253120] train loss: 0.003807, tar: 0.000016 
l0: 0.000035, l1: 0.000038, l2: 0.000048, l3: 0.000138, l4: 0.000481, l5: 0.001041, l6: 0.001710

[epoch: 963/1000, batch:   536/ 1052, ite: 253140] train loss: 0.003805, tar: 0.000016 
l0: 0.000012, l1: 0.000012, l2: 0.000014, l3: 0.000038, l4: 0.000179, l5: 0.000431, l6: 0.000977

[epoch: 963/1000, batch:   616/ 1052, ite: 253160] train loss: 0.003792, tar: 0.000016 
l0: 0.000007, l1: 0.000006, l2: 0.000038, l3: 0.000152, l4: 0.000412, l5: 0.000363, l6: 0.001739

[epoch: 963/1000, batch:   696/ 1052, ite: 253180] train loss: 0.003802, tar: 0.000016 
l0: 0.000001, l1: 0.000001, l2: 0.000039, l3: 0.000174, l4: 0.000475, l5: 0.000746, l6: 0.001291

[epoch: 963/1000, batch:   776/ 1052, ite: 253200] train loss: 0.003806, tar: 0.000016 
l0: 0.000003, l1: 0.000005, l2: 0.000013, l3: 0.000104, l4: 0.000298, l5: 0.001148, l6: 0.001896

[epoch: 963/1000, batch:   856/ 1052, ite: 253220] train loss: 0.003812, tar: 0.000016 
l0: 0.000004, l1: 0.000005, l2: 0.000013, l3: 0.000094, l4: 0.000249, l5: 0.001191, l6: 0.002966

[epoch: 963/1000, batch:   936/ 1052, ite: 253240] train loss: 0.003807, tar: 0.000016 
l0: 0.000005, l1: 0.000007, l2: 0.000061, l3: 0.000254, l4: 0.000621, l5: 0.001487, l6: 0.001634

[epoch: 963/1000, batch:  1016/ 1052, ite: 253260] train loss: 0.003809, tar: 0.000016 
[Epoch 963/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000002, l1: 0.000002, l2: 0.000015, l3: 0.000093, l4: 0.000474, l5: 0.001040, l6: 0.001261

[epoch: 964/1000, batch:    44/ 1052, ite: 253280] train loss: 0.003807, tar: 0.000016 
l0: 0.000007, l1: 0.000007, l2: 0.000033, l3: 0.000101, l4: 0.000334, l5: 0.000703, l6: 0.001410

[epoch: 964/1000, batch:   124/ 1052, ite: 253300] train loss: 0.003799, tar: 0.000016 
l0: 0.000024, l1: 0.000029, l2: 0.000047, l3: 0.000280, l4: 0.000430, l5: 0.000985, l6: 0.001577

[epoch: 964/1000, batch:   204/ 1052, ite: 253320] train loss: 0.003805, tar: 0.000016 
l0: 0.000018, l1: 0.000017, l2: 0.000026, l3: 0.000072, l4: 0.000405, l5: 0.000662, l6: 0.001189

[epoch: 964/1000, batch:   284/ 1052, ite: 253340] train loss: 0.003805, tar: 0.000016 
l0: 0.000014, l1: 0.000012, l2: 0.000040, l3: 0.000156, l4: 0.000454, l5: 0.001164, l6: 0.002178

[epoch: 964/1000, batch:   364/ 1052, ite: 253360] train loss: 0.003802, tar: 0.000016 
l0: 0.000002, l1: 0.000001, l2: 0.000020, l3: 0.000074, l4: 0.000400, l5: 0.000965, l6: 0.001576

[epoch: 964/1000, batch:   444/ 1052, ite: 253380] train loss: 0.003809, tar: 0.000016 
l0: 0.000010, l1: 0.000015, l2: 0.000032, l3: 0.000103, l4: 0.000272, l5: 0.000855, l6: 0.001676

[epoch: 964/1000, batch:   524/ 1052, ite: 253400] train loss: 0.003808, tar: 0.000016 
l0: 0.000011, l1: 0.000009, l2: 0.000023, l3: 0.000089, l4: 0.000186, l5: 0.000571, l6: 0.000956

[epoch: 964/1000, batch:   604/ 1052, ite: 253420] train loss: 0.003799, tar: 0.000016 
l0: 0.000004, l1: 0.000003, l2: 0.000035, l3: 0.000102, l4: 0.000278, l5: 0.000509, l6: 0.001923

[epoch: 964/1000, batch:   684/ 1052, ite: 253440] train loss: 0.003802, tar: 0.000016 
l0: 0.000006, l1: 0.000006, l2: 0.000025, l3: 0.000137, l4: 0.000445, l5: 0.000733, l6: 0.001488

[epoch: 964/1000, batch:   764/ 1052, ite: 253460] train loss: 0.003811, tar: 0.000016 
l0: 0.000008, l1: 0.000008, l2: 0.000058, l3: 0.000178, l4: 0.000580, l5: 0.001371, l6: 0.002815

[epoch: 964/1000, batch:   844/ 1052, ite: 253480] train loss: 0.003809, tar: 0.000016 
l0: 0.000032, l1: 0.000031, l2: 0.000036, l3: 0.000138, l4: 0.000471, l5: 0.000737, l6: 0.002093

[epoch: 964/1000, batch:   924/ 1052, ite: 253500] train loss: 0.003801, tar: 0.000016 
l0: 0.000012, l1: 0.000012, l2: 0.000025, l3: 0.000134, l4: 0.000456, l5: 0.001206, l6: 0.002041

[epoch: 964/1000, batch:  1004/ 1052, ite: 253520] train loss: 0.003800, tar: 0.000016 
[Epoch 964/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000006, l1: 0.000006, l2: 0.000019, l3: 0.000119, l4: 0.000722, l5: 0.001454, l6: 0.001987

[epoch: 965/1000, batch:    32/ 1052, ite: 253540] train loss: 0.003808, tar: 0.000016 
l0: 0.000025, l1: 0.000025, l2: 0.000059, l3: 0.000130, l4: 0.000314, l5: 0.000735, l6: 0.002241

[epoch: 965/1000, batch:   112/ 1052, ite: 253560] train loss: 0.003810, tar: 0.000016 
l0: 0.000010, l1: 0.000010, l2: 0.000037, l3: 0.000180, l4: 0.000288, l5: 0.000619, l6: 0.001620

[epoch: 965/1000, batch:   192/ 1052, ite: 253580] train loss: 0.003809, tar: 0.000017 
l0: 0.000004, l1: 0.000004, l2: 0.000019, l3: 0.000081, l4: 0.000360, l5: 0.000753, l6: 0.001333

[epoch: 965/1000, batch:   272/ 1052, ite: 253600] train loss: 0.003805, tar: 0.000018 
l0: 0.000006, l1: 0.000006, l2: 0.000011, l3: 0.000077, l4: 0.000342, l5: 0.001210, l6: 0.001986

[epoch: 965/1000, batch:   352/ 1052, ite: 253620] train loss: 0.003808, tar: 0.000018 
l0: 0.000014, l1: 0.000013, l2: 0.000083, l3: 0.000147, l4: 0.000376, l5: 0.000483, l6: 0.001774

[epoch: 965/1000, batch:   432/ 1052, ite: 253640] train loss: 0.003820, tar: 0.000018 
l0: 0.000010, l1: 0.000011, l2: 0.000030, l3: 0.000101, l4: 0.000255, l5: 0.000854, l6: 0.001427

[epoch: 965/1000, batch:   512/ 1052, ite: 253660] train loss: 0.003815, tar: 0.000018 
l0: 0.000019, l1: 0.000022, l2: 0.000037, l3: 0.000097, l4: 0.000225, l5: 0.000900, l6: 0.001263

[epoch: 965/1000, batch:   592/ 1052, ite: 253680] train loss: 0.003813, tar: 0.000018 
l0: 0.000015, l1: 0.000018, l2: 0.000046, l3: 0.000136, l4: 0.000651, l5: 0.001389, l6: 0.001690

[epoch: 965/1000, batch:   672/ 1052, ite: 253700] train loss: 0.003809, tar: 0.000018 
l0: 0.000028, l1: 0.000028, l2: 0.000054, l3: 0.000150, l4: 0.000293, l5: 0.001129, l6: 0.002804

[epoch: 965/1000, batch:   752/ 1052, ite: 253720] train loss: 0.003807, tar: 0.000018 
l0: 0.000005, l1: 0.000004, l2: 0.000035, l3: 0.000109, l4: 0.000205, l5: 0.000903, l6: 0.001455

[epoch: 965/1000, batch:   832/ 1052, ite: 253740] train loss: 0.003812, tar: 0.000018 
l0: 0.000008, l1: 0.000007, l2: 0.000042, l3: 0.000104, l4: 0.000303, l5: 0.000849, l6: 0.001280

[epoch: 965/1000, batch:   912/ 1052, ite: 253760] train loss: 0.003809, tar: 0.000018 
l0: 0.000030, l1: 0.000037, l2: 0.000026, l3: 0.000158, l4: 0.000417, l5: 0.001586, l6: 0.003003

[epoch: 965/1000, batch:   992/ 1052, ite: 253780] train loss: 0.003812, tar: 0.000018 
[Epoch 965/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000039, l1: 0.000031, l2: 0.000055, l3: 0.000086, l4: 0.000227, l5: 0.000741, l6: 0.002034

[epoch: 966/1000, batch:    20/ 1052, ite: 253800] train loss: 0.003813, tar: 0.000018 
l0: 0.000029, l1: 0.000029, l2: 0.000067, l3: 0.000224, l4: 0.000501, l5: 0.001059, l6: 0.002398

[epoch: 966/1000, batch:   100/ 1052, ite: 253820] train loss: 0.003809, tar: 0.000018 
l0: 0.000007, l1: 0.000007, l2: 0.000042, l3: 0.000132, l4: 0.000518, l5: 0.001127, l6: 0.001239

[epoch: 966/1000, batch:   180/ 1052, ite: 253840] train loss: 0.003810, tar: 0.000018 
l0: 0.000063, l1: 0.000075, l2: 0.000085, l3: 0.000244, l4: 0.000565, l5: 0.000994, l6: 0.001987

[epoch: 966/1000, batch:   260/ 1052, ite: 253860] train loss: 0.003808, tar: 0.000018 
l0: 0.000010, l1: 0.000012, l2: 0.000036, l3: 0.000156, l4: 0.000517, l5: 0.000953, l6: 0.001846

[epoch: 966/1000, batch:   340/ 1052, ite: 253880] train loss: 0.003808, tar: 0.000018 
l0: 0.000012, l1: 0.000013, l2: 0.000069, l3: 0.000184, l4: 0.000605, l5: 0.000968, l6: 0.002407

[epoch: 966/1000, batch:   420/ 1052, ite: 253900] train loss: 0.003806, tar: 0.000018 
l0: 0.000008, l1: 0.000007, l2: 0.000041, l3: 0.000154, l4: 0.000273, l5: 0.000859, l6: 0.001537

[epoch: 966/1000, batch:   500/ 1052, ite: 253920] train loss: 0.003805, tar: 0.000018 
l0: 0.000022, l1: 0.000024, l2: 0.000077, l3: 0.000341, l4: 0.000919, l5: 0.001546, l6: 0.004158

[epoch: 966/1000, batch:   580/ 1052, ite: 253940] train loss: 0.003810, tar: 0.000018 
l0: 0.000017, l1: 0.000016, l2: 0.000049, l3: 0.000094, l4: 0.000403, l5: 0.000958, l6: 0.001453

[epoch: 966/1000, batch:   660/ 1052, ite: 253960] train loss: 0.003804, tar: 0.000018 
l0: 0.000002, l1: 0.000002, l2: 0.000007, l3: 0.000070, l4: 0.000225, l5: 0.000679, l6: 0.001421

[epoch: 966/1000, batch:   740/ 1052, ite: 253980] train loss: 0.003802, tar: 0.000018 
l0: 0.000037, l1: 0.000038, l2: 0.000047, l3: 0.000118, l4: 0.000311, l5: 0.001069, l6: 0.002150

[epoch: 966/1000, batch:   820/ 1052, ite: 254000] train loss: 0.003806, tar: 0.000018 
l0: 0.000025, l1: 0.000026, l2: 0.000024, l3: 0.000077, l4: 0.000262, l5: 0.000586, l6: 0.001234

[epoch: 966/1000, batch:   900/ 1052, ite: 254020] train loss: 0.003806, tar: 0.000018 
l0: 0.000017, l1: 0.000018, l2: 0.000041, l3: 0.000147, l4: 0.000408, l5: 0.000895, l6: 0.001799

[epoch: 966/1000, batch:   980/ 1052, ite: 254040] train loss: 0.003808, tar: 0.000019 
[Epoch 966/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000006, l1: 0.000006, l2: 0.000020, l3: 0.000185, l4: 0.000773, l5: 0.001227, l6: 0.002417

[epoch: 967/1000, batch:     8/ 1052, ite: 254060] train loss: 0.003812, tar: 0.000019 
l0: 0.000029, l1: 0.000032, l2: 0.000032, l3: 0.000115, l4: 0.000568, l5: 0.001201, l6: 0.001955

[epoch: 967/1000, batch:    88/ 1052, ite: 254080] train loss: 0.003808, tar: 0.000019 
l0: 0.000002, l1: 0.000001, l2: 0.000036, l3: 0.000220, l4: 0.000380, l5: 0.001365, l6: 0.002392

[epoch: 967/1000, batch:   168/ 1052, ite: 254100] train loss: 0.003802, tar: 0.000019 
l0: 0.000003, l1: 0.000003, l2: 0.000037, l3: 0.000114, l4: 0.000456, l5: 0.000761, l6: 0.000934

[epoch: 967/1000, batch:   248/ 1052, ite: 254120] train loss: 0.003802, tar: 0.000019 
l0: 0.000014, l1: 0.000014, l2: 0.000038, l3: 0.000128, l4: 0.000614, l5: 0.001268, l6: 0.001885

[epoch: 967/1000, batch:   328/ 1052, ite: 254140] train loss: 0.003796, tar: 0.000019 
l0: 0.000016, l1: 0.000015, l2: 0.000061, l3: 0.000237, l4: 0.000749, l5: 0.001086, l6: 0.001997

[epoch: 967/1000, batch:   408/ 1052, ite: 254160] train loss: 0.003795, tar: 0.000019 
l0: 0.000071, l1: 0.000073, l2: 0.000103, l3: 0.000189, l4: 0.000509, l5: 0.001445, l6: 0.003468

[epoch: 967/1000, batch:   488/ 1052, ite: 254180] train loss: 0.003802, tar: 0.000019 
l0: 0.000013, l1: 0.000012, l2: 0.000014, l3: 0.000042, l4: 0.000182, l5: 0.000453, l6: 0.001193

[epoch: 967/1000, batch:   568/ 1052, ite: 254200] train loss: 0.003799, tar: 0.000019 
l0: 0.000027, l1: 0.000029, l2: 0.000043, l3: 0.000222, l4: 0.000700, l5: 0.001895, l6: 0.002973

[epoch: 967/1000, batch:   648/ 1052, ite: 254220] train loss: 0.003798, tar: 0.000019 
l0: 0.000007, l1: 0.000006, l2: 0.000065, l3: 0.000361, l4: 0.001059, l5: 0.002339, l6: 0.003703

[epoch: 967/1000, batch:   728/ 1052, ite: 254240] train loss: 0.003810, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000033, l3: 0.000138, l4: 0.000264, l5: 0.000916, l6: 0.001664

[epoch: 967/1000, batch:   808/ 1052, ite: 254260] train loss: 0.003806, tar: 0.000019 
l0: 0.000030, l1: 0.000029, l2: 0.000041, l3: 0.000147, l4: 0.000243, l5: 0.000657, l6: 0.001558

[epoch: 967/1000, batch:   888/ 1052, ite: 254280] train loss: 0.003804, tar: 0.000019 
l0: 0.000044, l1: 0.000045, l2: 0.000094, l3: 0.000227, l4: 0.000487, l5: 0.001526, l6: 0.002594

[epoch: 967/1000, batch:   968/ 1052, ite: 254300] train loss: 0.003808, tar: 0.000019 
l0: 0.000007, l1: 0.000007, l2: 0.000040, l3: 0.000235, l4: 0.001036, l5: 0.002101, l6: 0.002575

[epoch: 967/1000, batch:  1048/ 1052, ite: 254320] train loss: 0.003809, tar: 0.000019 
[Epoch 967/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000010, l1: 0.000009, l2: 0.000060, l3: 0.000231, l4: 0.000572, l5: 0.001477, l6: 0.003218

[epoch: 968/1000, batch:    76/ 1052, ite: 254340] train loss: 0.003814, tar: 0.000019 
l0: 0.000016, l1: 0.000016, l2: 0.000053, l3: 0.000109, l4: 0.000237, l5: 0.001002, l6: 0.001559

[epoch: 968/1000, batch:   156/ 1052, ite: 254360] train loss: 0.003809, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000014, l3: 0.000098, l4: 0.000330, l5: 0.000720, l6: 0.001713

[epoch: 968/1000, batch:   236/ 1052, ite: 254380] train loss: 0.003802, tar: 0.000019 
l0: 0.000004, l1: 0.000003, l2: 0.000037, l3: 0.000131, l4: 0.000353, l5: 0.000678, l6: 0.001538

[epoch: 968/1000, batch:   316/ 1052, ite: 254400] train loss: 0.003803, tar: 0.000019 
l0: 0.000008, l1: 0.000008, l2: 0.000077, l3: 0.000300, l4: 0.000734, l5: 0.001350, l6: 0.003775

[epoch: 968/1000, batch:   396/ 1052, ite: 254420] train loss: 0.003810, tar: 0.000019 
l0: 0.000028, l1: 0.000026, l2: 0.000060, l3: 0.000173, l4: 0.000460, l5: 0.000850, l6: 0.002038

[epoch: 968/1000, batch:   476/ 1052, ite: 254440] train loss: 0.003810, tar: 0.000019 
l0: 0.000014, l1: 0.000016, l2: 0.000016, l3: 0.000100, l4: 0.000490, l5: 0.000785, l6: 0.001272

[epoch: 968/1000, batch:   556/ 1052, ite: 254460] train loss: 0.003811, tar: 0.000019 
l0: 0.000032, l1: 0.000030, l2: 0.000121, l3: 0.000293, l4: 0.000643, l5: 0.001036, l6: 0.003840

[epoch: 968/1000, batch:   636/ 1052, ite: 254480] train loss: 0.003809, tar: 0.000019 
l0: 0.000017, l1: 0.000018, l2: 0.000038, l3: 0.000190, l4: 0.000639, l5: 0.001201, l6: 0.002196

[epoch: 968/1000, batch:   716/ 1052, ite: 254500] train loss: 0.003812, tar: 0.000019 
l0: 0.000029, l1: 0.000028, l2: 0.000042, l3: 0.000167, l4: 0.000565, l5: 0.001225, l6: 0.001940

[epoch: 968/1000, batch:   796/ 1052, ite: 254520] train loss: 0.003809, tar: 0.000019 
l0: 0.000011, l1: 0.000011, l2: 0.000051, l3: 0.000247, l4: 0.000475, l5: 0.001239, l6: 0.002530

[epoch: 968/1000, batch:   876/ 1052, ite: 254540] train loss: 0.003811, tar: 0.000019 
l0: 0.000033, l1: 0.000034, l2: 0.000054, l3: 0.000082, l4: 0.000230, l5: 0.000589, l6: 0.000995

[epoch: 968/1000, batch:   956/ 1052, ite: 254560] train loss: 0.003808, tar: 0.000019 
l0: 0.000009, l1: 0.000009, l2: 0.000033, l3: 0.000145, l4: 0.000357, l5: 0.001088, l6: 0.001480

[epoch: 968/1000, batch:  1036/ 1052, ite: 254580] train loss: 0.003807, tar: 0.000018 
[Epoch 968/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000028, l1: 0.000022, l2: 0.000052, l3: 0.000316, l4: 0.000570, l5: 0.001334, l6: 0.002523

[epoch: 969/1000, batch:    64/ 1052, ite: 254600] train loss: 0.003805, tar: 0.000018 
l0: 0.000023, l1: 0.000022, l2: 0.000063, l3: 0.000140, l4: 0.000227, l5: 0.000907, l6: 0.001187

[epoch: 969/1000, batch:   144/ 1052, ite: 254620] train loss: 0.003806, tar: 0.000018 
l0: 0.000008, l1: 0.000011, l2: 0.000025, l3: 0.000076, l4: 0.000261, l5: 0.000772, l6: 0.000977

[epoch: 969/1000, batch:   224/ 1052, ite: 254640] train loss: 0.003804, tar: 0.000018 
l0: 0.000010, l1: 0.000010, l2: 0.000089, l3: 0.000449, l4: 0.001153, l5: 0.001917, l6: 0.002483

[epoch: 969/1000, batch:   304/ 1052, ite: 254660] train loss: 0.003801, tar: 0.000018 
l0: 0.000034, l1: 0.000034, l2: 0.000080, l3: 0.000204, l4: 0.000452, l5: 0.001361, l6: 0.001931

[epoch: 969/1000, batch:   384/ 1052, ite: 254680] train loss: 0.003799, tar: 0.000018 
l0: 0.000019, l1: 0.000020, l2: 0.000092, l3: 0.000286, l4: 0.000672, l5: 0.001551, l6: 0.003106

[epoch: 969/1000, batch:   464/ 1052, ite: 254700] train loss: 0.003803, tar: 0.000018 
l0: 0.000036, l1: 0.000034, l2: 0.000090, l3: 0.000279, l4: 0.000738, l5: 0.001113, l6: 0.001781

[epoch: 969/1000, batch:   544/ 1052, ite: 254720] train loss: 0.003805, tar: 0.000018 
l0: 0.000008, l1: 0.000008, l2: 0.000023, l3: 0.000110, l4: 0.000373, l5: 0.001016, l6: 0.001206

[epoch: 969/1000, batch:   624/ 1052, ite: 254740] train loss: 0.003801, tar: 0.000018 
l0: 0.000049, l1: 0.000051, l2: 0.000086, l3: 0.000300, l4: 0.000833, l5: 0.002135, l6: 0.003766

[epoch: 969/1000, batch:   704/ 1052, ite: 254760] train loss: 0.003802, tar: 0.000018 
l0: 0.000094, l1: 0.000093, l2: 0.000093, l3: 0.000189, l4: 0.000425, l5: 0.000651, l6: 0.001499

[epoch: 969/1000, batch:   784/ 1052, ite: 254780] train loss: 0.003803, tar: 0.000018 
l0: 0.000010, l1: 0.000010, l2: 0.000040, l3: 0.000129, l4: 0.000363, l5: 0.000853, l6: 0.001306

[epoch: 969/1000, batch:   864/ 1052, ite: 254800] train loss: 0.003798, tar: 0.000018 
l0: 0.000012, l1: 0.000015, l2: 0.000050, l3: 0.000214, l4: 0.000509, l5: 0.000731, l6: 0.001595

[epoch: 969/1000, batch:   944/ 1052, ite: 254820] train loss: 0.003797, tar: 0.000018 
l0: 0.000013, l1: 0.000014, l2: 0.000042, l3: 0.000191, l4: 0.000538, l5: 0.001117, l6: 0.001662

[epoch: 969/1000, batch:  1024/ 1052, ite: 254840] train loss: 0.003798, tar: 0.000018 
[Epoch 969/1000] Test loss: 0.024, Test target loss: 0.005
l0: 0.000025, l1: 0.000024, l2: 0.000056, l3: 0.000162, l4: 0.000450, l5: 0.001374, l6: 0.002595

[epoch: 970/1000, batch:    52/ 1052, ite: 254860] train loss: 0.003801, tar: 0.000018 
l0: 0.000011, l1: 0.000014, l2: 0.000066, l3: 0.000310, l4: 0.000993, l5: 0.002460, l6: 0.002562

[epoch: 970/1000, batch:   132/ 1052, ite: 254880] train loss: 0.003802, tar: 0.000018 
l0: 0.000006, l1: 0.000006, l2: 0.000047, l3: 0.000192, l4: 0.000570, l5: 0.001629, l6: 0.002827

[epoch: 970/1000, batch:   212/ 1052, ite: 254900] train loss: 0.003801, tar: 0.000018 
l0: 0.000028, l1: 0.000025, l2: 0.000062, l3: 0.000158, l4: 0.000512, l5: 0.001236, l6: 0.002572

[epoch: 970/1000, batch:   292/ 1052, ite: 254920] train loss: 0.003798, tar: 0.000018 
l0: 0.000010, l1: 0.000012, l2: 0.000025, l3: 0.000089, l4: 0.000349, l5: 0.000878, l6: 0.001084

[epoch: 970/1000, batch:   372/ 1052, ite: 254940] train loss: 0.003799, tar: 0.000018 
l0: 0.000002, l1: 0.000002, l2: 0.000024, l3: 0.000101, l4: 0.000473, l5: 0.000832, l6: 0.001048

[epoch: 970/1000, batch:   452/ 1052, ite: 254960] train loss: 0.003799, tar: 0.000018 
l0: 0.000024, l1: 0.000023, l2: 0.000081, l3: 0.000207, l4: 0.000667, l5: 0.001407, l6: 0.002629

[epoch: 970/1000, batch:   532/ 1052, ite: 254980] train loss: 0.003800, tar: 0.000018 
l0: 0.000019, l1: 0.000019, l2: 0.000039, l3: 0.000218, l4: 0.000669, l5: 0.001345, l6: 0.002292

[epoch: 970/1000, batch:   612/ 1052, ite: 255000] train loss: 0.003803, tar: 0.000018 
l0: 0.000008, l1: 0.000009, l2: 0.000015, l3: 0.000077, l4: 0.000351, l5: 0.000844, l6: 0.001468

[epoch: 970/1000, batch:   692/ 1052, ite: 255020] train loss: 0.003802, tar: 0.000018 
l0: 0.000022, l1: 0.000025, l2: 0.000037, l3: 0.000163, l4: 0.000325, l5: 0.000570, l6: 0.001505

[epoch: 970/1000, batch:   772/ 1052, ite: 255040] train loss: 0.003802, tar: 0.000018 
l0: 0.000003, l1: 0.000003, l2: 0.000017, l3: 0.000085, l4: 0.000346, l5: 0.000694, l6: 0.001635

[epoch: 970/1000, batch:   852/ 1052, ite: 255060] train loss: 0.003801, tar: 0.000018 
l0: 0.000017, l1: 0.000016, l2: 0.000044, l3: 0.000182, l4: 0.000482, l5: 0.001126, l6: 0.002717

[epoch: 970/1000, batch:   932/ 1052, ite: 255080] train loss: 0.003800, tar: 0.000018 
l0: 0.000048, l1: 0.000047, l2: 0.000070, l3: 0.000178, l4: 0.000514, l5: 0.001059, l6: 0.002400

[epoch: 970/1000, batch:  1012/ 1052, ite: 255100] train loss: 0.003800, tar: 0.000018 
[Epoch 970/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000021, l1: 0.000022, l2: 0.000045, l3: 0.000164, l4: 0.000410, l5: 0.001335, l6: 0.003385

[epoch: 971/1000, batch:    40/ 1052, ite: 255120] train loss: 0.003797, tar: 0.000018 
l0: 0.000010, l1: 0.000009, l2: 0.000042, l3: 0.000154, l4: 0.000622, l5: 0.001799, l6: 0.001885

[epoch: 971/1000, batch:   120/ 1052, ite: 255140] train loss: 0.003799, tar: 0.000018 
l0: 0.000002, l1: 0.000003, l2: 0.000043, l3: 0.000124, l4: 0.000475, l5: 0.001148, l6: 0.001744

[epoch: 971/1000, batch:   200/ 1052, ite: 255160] train loss: 0.003801, tar: 0.000018 
l0: 0.000003, l1: 0.000003, l2: 0.000052, l3: 0.000125, l4: 0.000258, l5: 0.000434, l6: 0.000947

[epoch: 971/1000, batch:   280/ 1052, ite: 255180] train loss: 0.003801, tar: 0.000018 
l0: 0.000073, l1: 0.000074, l2: 0.000108, l3: 0.000241, l4: 0.000500, l5: 0.000880, l6: 0.001375

[epoch: 971/1000, batch:   360/ 1052, ite: 255200] train loss: 0.003801, tar: 0.000018 
l0: 0.000004, l1: 0.000005, l2: 0.000037, l3: 0.000153, l4: 0.000468, l5: 0.000973, l6: 0.001096

[epoch: 971/1000, batch:   440/ 1052, ite: 255220] train loss: 0.003801, tar: 0.000018 
l0: 0.000021, l1: 0.000020, l2: 0.000032, l3: 0.000116, l4: 0.000574, l5: 0.001026, l6: 0.002815

[epoch: 971/1000, batch:   520/ 1052, ite: 255240] train loss: 0.003801, tar: 0.000018 
l0: 0.000004, l1: 0.000005, l2: 0.000022, l3: 0.000189, l4: 0.000361, l5: 0.000568, l6: 0.001081

[epoch: 971/1000, batch:   600/ 1052, ite: 255260] train loss: 0.003801, tar: 0.000018 
l0: 0.000023, l1: 0.000021, l2: 0.000052, l3: 0.000147, l4: 0.000393, l5: 0.001087, l6: 0.001989

[epoch: 971/1000, batch:   680/ 1052, ite: 255280] train loss: 0.003799, tar: 0.000018 
l0: 0.000009, l1: 0.000007, l2: 0.000043, l3: 0.000197, l4: 0.000601, l5: 0.000902, l6: 0.002598

[epoch: 971/1000, batch:   760/ 1052, ite: 255300] train loss: 0.003799, tar: 0.000018 
l0: 0.000014, l1: 0.000016, l2: 0.000021, l3: 0.000269, l4: 0.000647, l5: 0.001697, l6: 0.003003

[epoch: 971/1000, batch:   840/ 1052, ite: 255320] train loss: 0.003800, tar: 0.000018 
l0: 0.000019, l1: 0.000020, l2: 0.000023, l3: 0.000083, l4: 0.000214, l5: 0.000767, l6: 0.001011

[epoch: 971/1000, batch:   920/ 1052, ite: 255340] train loss: 0.003797, tar: 0.000018 
l0: 0.000104, l1: 0.000103, l2: 0.000166, l3: 0.000260, l4: 0.000629, l5: 0.002426, l6: 0.003747

[epoch: 971/1000, batch:  1000/ 1052, ite: 255360] train loss: 0.003798, tar: 0.000019 
[Epoch 971/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000043, l1: 0.000041, l2: 0.000064, l3: 0.000191, l4: 0.000482, l5: 0.000612, l6: 0.001126

[epoch: 972/1000, batch:    28/ 1052, ite: 255380] train loss: 0.003797, tar: 0.000018 
l0: 0.000005, l1: 0.000007, l2: 0.000038, l3: 0.000131, l4: 0.000557, l5: 0.001033, l6: 0.001794

[epoch: 972/1000, batch:   108/ 1052, ite: 255400] train loss: 0.003797, tar: 0.000019 
l0: 0.000019, l1: 0.000022, l2: 0.000030, l3: 0.000195, l4: 0.000344, l5: 0.000820, l6: 0.001443

[epoch: 972/1000, batch:   188/ 1052, ite: 255420] train loss: 0.003797, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000015, l3: 0.000172, l4: 0.000438, l5: 0.001058, l6: 0.002100

[epoch: 972/1000, batch:   268/ 1052, ite: 255440] train loss: 0.003795, tar: 0.000019 
l0: 0.000065, l1: 0.000072, l2: 0.000109, l3: 0.000199, l4: 0.000499, l5: 0.000865, l6: 0.002269

[epoch: 972/1000, batch:   348/ 1052, ite: 255460] train loss: 0.003797, tar: 0.000019 
l0: 0.000066, l1: 0.000068, l2: 0.000099, l3: 0.000220, l4: 0.000434, l5: 0.000752, l6: 0.001575

[epoch: 972/1000, batch:   428/ 1052, ite: 255480] train loss: 0.003798, tar: 0.000019 
l0: 0.000058, l1: 0.000058, l2: 0.000115, l3: 0.000341, l4: 0.000841, l5: 0.001558, l6: 0.003128

[epoch: 972/1000, batch:   508/ 1052, ite: 255500] train loss: 0.003798, tar: 0.000019 
l0: 0.000001, l1: 0.000001, l2: 0.000011, l3: 0.000089, l4: 0.000309, l5: 0.000930, l6: 0.001222

[epoch: 972/1000, batch:   588/ 1052, ite: 255520] train loss: 0.003798, tar: 0.000019 
l0: 0.000004, l1: 0.000004, l2: 0.000065, l3: 0.000291, l4: 0.000676, l5: 0.001177, l6: 0.001843

[epoch: 972/1000, batch:   668/ 1052, ite: 255540] train loss: 0.003796, tar: 0.000019 
l0: 0.000026, l1: 0.000027, l2: 0.000074, l3: 0.000306, l4: 0.000782, l5: 0.002082, l6: 0.003457

[epoch: 972/1000, batch:   748/ 1052, ite: 255560] train loss: 0.003801, tar: 0.000020 
l0: 0.000030, l1: 0.000030, l2: 0.000058, l3: 0.000160, l4: 0.000379, l5: 0.000994, l6: 0.001542

[epoch: 972/1000, batch:   828/ 1052, ite: 255580] train loss: 0.003802, tar: 0.000020 
l0: 0.000064, l1: 0.000083, l2: 0.000053, l3: 0.000125, l4: 0.000460, l5: 0.001104, l6: 0.002128

[epoch: 972/1000, batch:   908/ 1052, ite: 255600] train loss: 0.003803, tar: 0.000020 
l0: 0.000011, l1: 0.000008, l2: 0.000042, l3: 0.000129, l4: 0.000440, l5: 0.000751, l6: 0.001340

[epoch: 972/1000, batch:   988/ 1052, ite: 255620] train loss: 0.003802, tar: 0.000019 
[Epoch 972/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000003, l1: 0.000003, l2: 0.000045, l3: 0.000266, l4: 0.000646, l5: 0.000898, l6: 0.002653

[epoch: 973/1000, batch:    16/ 1052, ite: 255640] train loss: 0.003803, tar: 0.000019 
l0: 0.000008, l1: 0.000007, l2: 0.000057, l3: 0.000354, l4: 0.000548, l5: 0.001381, l6: 0.003044

[epoch: 973/1000, batch:    96/ 1052, ite: 255660] train loss: 0.003802, tar: 0.000019 
l0: 0.000009, l1: 0.000010, l2: 0.000024, l3: 0.000124, l4: 0.000457, l5: 0.000783, l6: 0.001463

[epoch: 973/1000, batch:   176/ 1052, ite: 255680] train loss: 0.003800, tar: 0.000019 
l0: 0.000008, l1: 0.000009, l2: 0.000022, l3: 0.000070, l4: 0.000211, l5: 0.000557, l6: 0.001028

[epoch: 973/1000, batch:   256/ 1052, ite: 255700] train loss: 0.003799, tar: 0.000019 
l0: 0.000050, l1: 0.000051, l2: 0.000107, l3: 0.000195, l4: 0.000525, l5: 0.001831, l6: 0.002857

[epoch: 973/1000, batch:   336/ 1052, ite: 255720] train loss: 0.003802, tar: 0.000019 
l0: 0.000002, l1: 0.000002, l2: 0.000017, l3: 0.000108, l4: 0.000237, l5: 0.000702, l6: 0.001537

[epoch: 973/1000, batch:   416/ 1052, ite: 255740] train loss: 0.003799, tar: 0.000019 
l0: 0.000001, l1: 0.000001, l2: 0.000012, l3: 0.000083, l4: 0.000283, l5: 0.000456, l6: 0.001223

[epoch: 973/1000, batch:   496/ 1052, ite: 255760] train loss: 0.003800, tar: 0.000019 
l0: 0.000011, l1: 0.000011, l2: 0.000040, l3: 0.000132, l4: 0.000344, l5: 0.000480, l6: 0.000833

[epoch: 973/1000, batch:   576/ 1052, ite: 255780] train loss: 0.003799, tar: 0.000019 
l0: 0.000013, l1: 0.000013, l2: 0.000052, l3: 0.000137, l4: 0.000464, l5: 0.001253, l6: 0.002065

[epoch: 973/1000, batch:   656/ 1052, ite: 255800] train loss: 0.003801, tar: 0.000019 
l0: 0.000006, l1: 0.000007, l2: 0.000035, l3: 0.000236, l4: 0.000484, l5: 0.001129, l6: 0.001582

[epoch: 973/1000, batch:   736/ 1052, ite: 255820] train loss: 0.003805, tar: 0.000019 
l0: 0.000020, l1: 0.000019, l2: 0.000082, l3: 0.000415, l4: 0.000711, l5: 0.001767, l6: 0.003056

[epoch: 973/1000, batch:   816/ 1052, ite: 255840] train loss: 0.003806, tar: 0.000019 
l0: 0.000004, l1: 0.000005, l2: 0.000024, l3: 0.000080, l4: 0.000187, l5: 0.000922, l6: 0.001051

[epoch: 973/1000, batch:   896/ 1052, ite: 255860] train loss: 0.003805, tar: 0.000019 
l0: 0.000034, l1: 0.000039, l2: 0.000039, l3: 0.000089, l4: 0.000211, l5: 0.000640, l6: 0.000997

[epoch: 973/1000, batch:   976/ 1052, ite: 255880] train loss: 0.003804, tar: 0.000020 
[Epoch 973/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000043, l1: 0.000041, l2: 0.000089, l3: 0.000231, l4: 0.000411, l5: 0.000673, l6: 0.001326

[epoch: 974/1000, batch:     4/ 1052, ite: 255900] train loss: 0.003804, tar: 0.000020 
l0: 0.000011, l1: 0.000010, l2: 0.000041, l3: 0.000106, l4: 0.000173, l5: 0.000389, l6: 0.000842

[epoch: 974/1000, batch:    84/ 1052, ite: 255920] train loss: 0.003804, tar: 0.000020 
l0: 0.000039, l1: 0.000041, l2: 0.000151, l3: 0.000267, l4: 0.000481, l5: 0.001036, l6: 0.001456

[epoch: 974/1000, batch:   164/ 1052, ite: 255940] train loss: 0.003805, tar: 0.000020 
l0: 0.000024, l1: 0.000023, l2: 0.000063, l3: 0.000301, l4: 0.000568, l5: 0.001375, l6: 0.002265

[epoch: 974/1000, batch:   244/ 1052, ite: 255960] train loss: 0.003805, tar: 0.000020 
l0: 0.000006, l1: 0.000009, l2: 0.000013, l3: 0.000089, l4: 0.000434, l5: 0.001021, l6: 0.001578

[epoch: 974/1000, batch:   324/ 1052, ite: 255980] train loss: 0.003805, tar: 0.000020 
l0: 0.000022, l1: 0.000022, l2: 0.000057, l3: 0.000127, l4: 0.000325, l5: 0.000763, l6: 0.000966

[epoch: 974/1000, batch:   404/ 1052, ite: 256000] train loss: 0.003807, tar: 0.000020 
l0: 0.000011, l1: 0.000011, l2: 0.000071, l3: 0.000256, l4: 0.000549, l5: 0.001723, l6: 0.002616

[epoch: 974/1000, batch:   484/ 1052, ite: 256020] train loss: 0.003807, tar: 0.000020 
l0: 0.000009, l1: 0.000010, l2: 0.000031, l3: 0.000162, l4: 0.000480, l5: 0.001103, l6: 0.003173

[epoch: 974/1000, batch:   564/ 1052, ite: 256040] train loss: 0.003804, tar: 0.000020 
l0: 0.000007, l1: 0.000007, l2: 0.000032, l3: 0.000160, l4: 0.000542, l5: 0.001339, l6: 0.002559

[epoch: 974/1000, batch:   644/ 1052, ite: 256060] train loss: 0.003803, tar: 0.000020 
l0: 0.000014, l1: 0.000014, l2: 0.000026, l3: 0.000158, l4: 0.000643, l5: 0.001269, l6: 0.002489

[epoch: 974/1000, batch:   724/ 1052, ite: 256080] train loss: 0.003800, tar: 0.000020 
l0: 0.000006, l1: 0.000006, l2: 0.000041, l3: 0.000141, l4: 0.000398, l5: 0.000638, l6: 0.001224

[epoch: 974/1000, batch:   804/ 1052, ite: 256100] train loss: 0.003799, tar: 0.000020 
l0: 0.000015, l1: 0.000016, l2: 0.000039, l3: 0.000193, l4: 0.000487, l5: 0.001440, l6: 0.002637

[epoch: 974/1000, batch:   884/ 1052, ite: 256120] train loss: 0.003799, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000016, l3: 0.000129, l4: 0.000425, l5: 0.000784, l6: 0.001527

[epoch: 974/1000, batch:   964/ 1052, ite: 256140] train loss: 0.003800, tar: 0.000020 
l0: 0.000021, l1: 0.000019, l2: 0.000043, l3: 0.000265, l4: 0.000553, l5: 0.002144, l6: 0.002125

[epoch: 974/1000, batch:  1044/ 1052, ite: 256160] train loss: 0.003802, tar: 0.000020 
[Epoch 974/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000010, l1: 0.000009, l2: 0.000044, l3: 0.000127, l4: 0.000409, l5: 0.001586, l6: 0.001884

[epoch: 975/1000, batch:    72/ 1052, ite: 256180] train loss: 0.003802, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000004, l3: 0.000041, l4: 0.000238, l5: 0.000759, l6: 0.001214

[epoch: 975/1000, batch:   152/ 1052, ite: 256200] train loss: 0.003801, tar: 0.000020 
l0: 0.000018, l1: 0.000019, l2: 0.000051, l3: 0.000162, l4: 0.000636, l5: 0.001357, l6: 0.003051

[epoch: 975/1000, batch:   232/ 1052, ite: 256220] train loss: 0.003802, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000029, l3: 0.000158, l4: 0.000576, l5: 0.000920, l6: 0.001856

[epoch: 975/1000, batch:   312/ 1052, ite: 256240] train loss: 0.003801, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000006, l3: 0.000114, l4: 0.000289, l5: 0.000373, l6: 0.000961

[epoch: 975/1000, batch:   392/ 1052, ite: 256260] train loss: 0.003800, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000013, l3: 0.000082, l4: 0.000132, l5: 0.000633, l6: 0.000600

[epoch: 975/1000, batch:   472/ 1052, ite: 256280] train loss: 0.003799, tar: 0.000020 
l0: 0.000023, l1: 0.000025, l2: 0.000046, l3: 0.000189, l4: 0.000353, l5: 0.001315, l6: 0.002422

[epoch: 975/1000, batch:   552/ 1052, ite: 256300] train loss: 0.003801, tar: 0.000020 
l0: 0.000015, l1: 0.000015, l2: 0.000060, l3: 0.000174, l4: 0.000407, l5: 0.001182, l6: 0.002784

[epoch: 975/1000, batch:   632/ 1052, ite: 256320] train loss: 0.003802, tar: 0.000020 
l0: 0.000025, l1: 0.000025, l2: 0.000045, l3: 0.000095, l4: 0.000265, l5: 0.000964, l6: 0.001581

[epoch: 975/1000, batch:   712/ 1052, ite: 256340] train loss: 0.003802, tar: 0.000020 
l0: 0.000009, l1: 0.000007, l2: 0.000046, l3: 0.000176, l4: 0.000393, l5: 0.001017, l6: 0.003191

[epoch: 975/1000, batch:   792/ 1052, ite: 256360] train loss: 0.003801, tar: 0.000020 
l0: 0.000040, l1: 0.000039, l2: 0.000133, l3: 0.000385, l4: 0.000741, l5: 0.002211, l6: 0.004517

[epoch: 975/1000, batch:   872/ 1052, ite: 256380] train loss: 0.003797, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000013, l3: 0.000123, l4: 0.000229, l5: 0.000631, l6: 0.001743

[epoch: 975/1000, batch:   952/ 1052, ite: 256400] train loss: 0.003799, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000031, l3: 0.000107, l4: 0.000292, l5: 0.001053, l6: 0.001948

[epoch: 975/1000, batch:  1032/ 1052, ite: 256420] train loss: 0.003799, tar: 0.000020 
[Epoch 975/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000015, l1: 0.000015, l2: 0.000032, l3: 0.000098, l4: 0.000345, l5: 0.000853, l6: 0.002643

[epoch: 976/1000, batch:    60/ 1052, ite: 256440] train loss: 0.003798, tar: 0.000020 
l0: 0.000007, l1: 0.000009, l2: 0.000033, l3: 0.000276, l4: 0.000878, l5: 0.001484, l6: 0.002237

[epoch: 976/1000, batch:   140/ 1052, ite: 256460] train loss: 0.003798, tar: 0.000020 
l0: 0.000031, l1: 0.000033, l2: 0.000037, l3: 0.000084, l4: 0.000229, l5: 0.000604, l6: 0.001389

[epoch: 976/1000, batch:   220/ 1052, ite: 256480] train loss: 0.003798, tar: 0.000020 
l0: 0.000005, l1: 0.000005, l2: 0.000015, l3: 0.000065, l4: 0.000248, l5: 0.001227, l6: 0.002098

[epoch: 976/1000, batch:   300/ 1052, ite: 256500] train loss: 0.003798, tar: 0.000020 
l0: 0.000005, l1: 0.000005, l2: 0.000023, l3: 0.000130, l4: 0.000474, l5: 0.001251, l6: 0.001586

[epoch: 976/1000, batch:   380/ 1052, ite: 256520] train loss: 0.003797, tar: 0.000020 
l0: 0.000010, l1: 0.000010, l2: 0.000027, l3: 0.000122, l4: 0.000230, l5: 0.000780, l6: 0.001219

[epoch: 976/1000, batch:   460/ 1052, ite: 256540] train loss: 0.003794, tar: 0.000020 
l0: 0.000032, l1: 0.000034, l2: 0.000068, l3: 0.000259, l4: 0.000606, l5: 0.001384, l6: 0.003650

[epoch: 976/1000, batch:   540/ 1052, ite: 256560] train loss: 0.003796, tar: 0.000020 
l0: 0.000018, l1: 0.000020, l2: 0.000074, l3: 0.000302, l4: 0.000672, l5: 0.002932, l6: 0.005245

[epoch: 976/1000, batch:   620/ 1052, ite: 256580] train loss: 0.003796, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000012, l3: 0.000088, l4: 0.000292, l5: 0.001141, l6: 0.001203

[epoch: 976/1000, batch:   700/ 1052, ite: 256600] train loss: 0.003796, tar: 0.000020 
l0: 0.000012, l1: 0.000014, l2: 0.000023, l3: 0.000117, l4: 0.000250, l5: 0.000604, l6: 0.001045

[epoch: 976/1000, batch:   780/ 1052, ite: 256620] train loss: 0.003799, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000017, l3: 0.000121, l4: 0.000264, l5: 0.000815, l6: 0.001709

[epoch: 976/1000, batch:   860/ 1052, ite: 256640] train loss: 0.003802, tar: 0.000020 
l0: 0.000021, l1: 0.000025, l2: 0.000026, l3: 0.000072, l4: 0.000238, l5: 0.001032, l6: 0.001359

[epoch: 976/1000, batch:   940/ 1052, ite: 256660] train loss: 0.003801, tar: 0.000020 
l0: 0.000014, l1: 0.000012, l2: 0.000041, l3: 0.000121, l4: 0.000417, l5: 0.000705, l6: 0.001541

[epoch: 976/1000, batch:  1020/ 1052, ite: 256680] train loss: 0.003800, tar: 0.000020 
[Epoch 976/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000027, l1: 0.000027, l2: 0.000127, l3: 0.000362, l4: 0.000650, l5: 0.001686, l6: 0.003047

[epoch: 977/1000, batch:    48/ 1052, ite: 256700] train loss: 0.003799, tar: 0.000020 
l0: 0.000008, l1: 0.000008, l2: 0.000040, l3: 0.000071, l4: 0.000355, l5: 0.000859, l6: 0.001532

[epoch: 977/1000, batch:   128/ 1052, ite: 256720] train loss: 0.003800, tar: 0.000020 
l0: 0.000046, l1: 0.000044, l2: 0.000109, l3: 0.000174, l4: 0.000499, l5: 0.001209, l6: 0.002708

[epoch: 977/1000, batch:   208/ 1052, ite: 256740] train loss: 0.003801, tar: 0.000020 
l0: 0.000001, l1: 0.000002, l2: 0.000007, l3: 0.000104, l4: 0.000334, l5: 0.000674, l6: 0.001591

[epoch: 977/1000, batch:   288/ 1052, ite: 256760] train loss: 0.003801, tar: 0.000020 
l0: 0.000006, l1: 0.000008, l2: 0.000039, l3: 0.000082, l4: 0.000234, l5: 0.000762, l6: 0.001600

[epoch: 977/1000, batch:   368/ 1052, ite: 256780] train loss: 0.003800, tar: 0.000020 
l0: 0.000013, l1: 0.000014, l2: 0.000028, l3: 0.000157, l4: 0.000618, l5: 0.001406, l6: 0.002595

[epoch: 977/1000, batch:   448/ 1052, ite: 256800] train loss: 0.003801, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000044, l3: 0.000238, l4: 0.000998, l5: 0.002005, l6: 0.003828

[epoch: 977/1000, batch:   528/ 1052, ite: 256820] train loss: 0.003801, tar: 0.000020 
l0: 0.000022, l1: 0.000023, l2: 0.000057, l3: 0.000217, l4: 0.000581, l5: 0.001517, l6: 0.003083

[epoch: 977/1000, batch:   608/ 1052, ite: 256840] train loss: 0.003801, tar: 0.000020 
l0: 0.000005, l1: 0.000005, l2: 0.000021, l3: 0.000171, l4: 0.000493, l5: 0.001048, l6: 0.002135

[epoch: 977/1000, batch:   688/ 1052, ite: 256860] train loss: 0.003800, tar: 0.000020 
l0: 0.000017, l1: 0.000017, l2: 0.000116, l3: 0.000262, l4: 0.000500, l5: 0.001652, l6: 0.002933

[epoch: 977/1000, batch:   768/ 1052, ite: 256880] train loss: 0.003799, tar: 0.000020 
l0: 0.000008, l1: 0.000008, l2: 0.000024, l3: 0.000061, l4: 0.000168, l5: 0.000708, l6: 0.002275

[epoch: 977/1000, batch:   848/ 1052, ite: 256900] train loss: 0.003798, tar: 0.000020 
l0: 0.000015, l1: 0.000016, l2: 0.000023, l3: 0.000126, l4: 0.000560, l5: 0.001031, l6: 0.001607

[epoch: 977/1000, batch:   928/ 1052, ite: 256920] train loss: 0.003799, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000009, l3: 0.000050, l4: 0.000332, l5: 0.000565, l6: 0.000783

[epoch: 977/1000, batch:  1008/ 1052, ite: 256940] train loss: 0.003799, tar: 0.000020 
[Epoch 977/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000034, l1: 0.000034, l2: 0.000031, l3: 0.000050, l4: 0.000229, l5: 0.000687, l6: 0.001262

[epoch: 978/1000, batch:    36/ 1052, ite: 256960] train loss: 0.003798, tar: 0.000020 
l0: 0.000008, l1: 0.000007, l2: 0.000037, l3: 0.000123, l4: 0.000372, l5: 0.001233, l6: 0.001482

[epoch: 978/1000, batch:   116/ 1052, ite: 256980] train loss: 0.003799, tar: 0.000020 
l0: 0.000006, l1: 0.000005, l2: 0.000027, l3: 0.000121, l4: 0.000322, l5: 0.001120, l6: 0.001725

[epoch: 978/1000, batch:   196/ 1052, ite: 257000] train loss: 0.003799, tar: 0.000020 
l0: 0.000016, l1: 0.000015, l2: 0.000049, l3: 0.000203, l4: 0.000629, l5: 0.002284, l6: 0.002432

[epoch: 978/1000, batch:   276/ 1052, ite: 257020] train loss: 0.003798, tar: 0.000020 
l0: 0.000063, l1: 0.000065, l2: 0.000094, l3: 0.000152, l4: 0.000451, l5: 0.000804, l6: 0.002326

[epoch: 978/1000, batch:   356/ 1052, ite: 257040] train loss: 0.003798, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000011, l3: 0.000091, l4: 0.000219, l5: 0.000889, l6: 0.001856

[epoch: 978/1000, batch:   436/ 1052, ite: 257060] train loss: 0.003798, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000005, l3: 0.000053, l4: 0.000361, l5: 0.000734, l6: 0.001209

[epoch: 978/1000, batch:   516/ 1052, ite: 257080] train loss: 0.003796, tar: 0.000020 
l0: 0.000000, l1: 0.000001, l2: 0.000002, l3: 0.000029, l4: 0.000166, l5: 0.000376, l6: 0.000962

[epoch: 978/1000, batch:   596/ 1052, ite: 257100] train loss: 0.003798, tar: 0.000020 
l0: 0.000008, l1: 0.000007, l2: 0.000046, l3: 0.000139, l4: 0.000316, l5: 0.000599, l6: 0.001988

[epoch: 978/1000, batch:   676/ 1052, ite: 257120] train loss: 0.003798, tar: 0.000020 
l0: 0.000033, l1: 0.000035, l2: 0.000076, l3: 0.000260, l4: 0.000638, l5: 0.002213, l6: 0.004651

[epoch: 978/1000, batch:   756/ 1052, ite: 257140] train loss: 0.003797, tar: 0.000020 
l0: 0.000026, l1: 0.000028, l2: 0.000065, l3: 0.000220, l4: 0.000625, l5: 0.001723, l6: 0.003148

[epoch: 978/1000, batch:   836/ 1052, ite: 257160] train loss: 0.003797, tar: 0.000020 
l0: 0.000018, l1: 0.000019, l2: 0.000093, l3: 0.000156, l4: 0.000460, l5: 0.001078, l6: 0.000909

[epoch: 978/1000, batch:   916/ 1052, ite: 257180] train loss: 0.003798, tar: 0.000020 
l0: 0.000001, l1: 0.000002, l2: 0.000008, l3: 0.000065, l4: 0.000159, l5: 0.000651, l6: 0.001007

[epoch: 978/1000, batch:   996/ 1052, ite: 257200] train loss: 0.003798, tar: 0.000020 
[Epoch 978/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000018, l1: 0.000020, l2: 0.000013, l3: 0.000092, l4: 0.000340, l5: 0.000871, l6: 0.001954

[epoch: 979/1000, batch:    24/ 1052, ite: 257220] train loss: 0.003801, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000001, l3: 0.000076, l4: 0.000209, l5: 0.000577, l6: 0.001392

[epoch: 979/1000, batch:   104/ 1052, ite: 257240] train loss: 0.003802, tar: 0.000020 
l0: 0.000025, l1: 0.000027, l2: 0.000059, l3: 0.000391, l4: 0.000876, l5: 0.001754, l6: 0.003584

[epoch: 979/1000, batch:   184/ 1052, ite: 257260] train loss: 0.003804, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000012, l3: 0.000108, l4: 0.000249, l5: 0.000606, l6: 0.001361

[epoch: 979/1000, batch:   264/ 1052, ite: 257280] train loss: 0.003804, tar: 0.000020 
l0: 0.000106, l1: 0.000111, l2: 0.000103, l3: 0.000202, l4: 0.000519, l5: 0.000744, l6: 0.001868

[epoch: 979/1000, batch:   344/ 1052, ite: 257300] train loss: 0.003806, tar: 0.000020 
l0: 0.000007, l1: 0.000007, l2: 0.000019, l3: 0.000079, l4: 0.000268, l5: 0.000553, l6: 0.001535

[epoch: 979/1000, batch:   424/ 1052, ite: 257320] train loss: 0.003804, tar: 0.000020 
l0: 0.000072, l1: 0.000073, l2: 0.000109, l3: 0.000303, l4: 0.000965, l5: 0.002107, l6: 0.003262

[epoch: 979/1000, batch:   504/ 1052, ite: 257340] train loss: 0.003805, tar: 0.000020 
l0: 0.000014, l1: 0.000014, l2: 0.000034, l3: 0.000173, l4: 0.000388, l5: 0.001005, l6: 0.001912

[epoch: 979/1000, batch:   584/ 1052, ite: 257360] train loss: 0.003806, tar: 0.000020 
l0: 0.000008, l1: 0.000007, l2: 0.000059, l3: 0.000154, l4: 0.000409, l5: 0.001140, l6: 0.001471

[epoch: 979/1000, batch:   664/ 1052, ite: 257380] train loss: 0.003805, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000014, l3: 0.000055, l4: 0.000173, l5: 0.000662, l6: 0.001449

[epoch: 979/1000, batch:   744/ 1052, ite: 257400] train loss: 0.003804, tar: 0.000020 
l0: 0.000142, l1: 0.000141, l2: 0.000204, l3: 0.000224, l4: 0.000386, l5: 0.001079, l6: 0.002002

[epoch: 979/1000, batch:   824/ 1052, ite: 257420] train loss: 0.003802, tar: 0.000020 
l0: 0.000019, l1: 0.000020, l2: 0.000055, l3: 0.000160, l4: 0.000573, l5: 0.001397, l6: 0.001599

[epoch: 979/1000, batch:   904/ 1052, ite: 257440] train loss: 0.003802, tar: 0.000020 
l0: 0.000005, l1: 0.000005, l2: 0.000025, l3: 0.000057, l4: 0.000295, l5: 0.000813, l6: 0.000944

[epoch: 979/1000, batch:   984/ 1052, ite: 257460] train loss: 0.003802, tar: 0.000020 
[Epoch 979/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000014, l1: 0.000014, l2: 0.000067, l3: 0.000179, l4: 0.000530, l5: 0.001050, l6: 0.000978

[epoch: 980/1000, batch:    12/ 1052, ite: 257480] train loss: 0.003801, tar: 0.000020 
l0: 0.000019, l1: 0.000019, l2: 0.000069, l3: 0.000222, l4: 0.000389, l5: 0.000791, l6: 0.002093

[epoch: 980/1000, batch:    92/ 1052, ite: 257500] train loss: 0.003800, tar: 0.000020 
l0: 0.000026, l1: 0.000027, l2: 0.000111, l3: 0.000238, l4: 0.000556, l5: 0.000827, l6: 0.001538

[epoch: 980/1000, batch:   172/ 1052, ite: 257520] train loss: 0.003800, tar: 0.000020 
l0: 0.000009, l1: 0.000011, l2: 0.000029, l3: 0.000130, l4: 0.000631, l5: 0.000847, l6: 0.002043

[epoch: 980/1000, batch:   252/ 1052, ite: 257540] train loss: 0.003800, tar: 0.000020 
l0: 0.000025, l1: 0.000026, l2: 0.000074, l3: 0.000262, l4: 0.000487, l5: 0.000953, l6: 0.001300

[epoch: 980/1000, batch:   332/ 1052, ite: 257560] train loss: 0.003800, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000020, l3: 0.000102, l4: 0.000237, l5: 0.000349, l6: 0.000989

[epoch: 980/1000, batch:   412/ 1052, ite: 257580] train loss: 0.003800, tar: 0.000020 
l0: 0.000008, l1: 0.000007, l2: 0.000046, l3: 0.000204, l4: 0.000545, l5: 0.000671, l6: 0.001791

[epoch: 980/1000, batch:   492/ 1052, ite: 257600] train loss: 0.003798, tar: 0.000020 
l0: 0.000031, l1: 0.000030, l2: 0.000072, l3: 0.000237, l4: 0.000593, l5: 0.001127, l6: 0.001749

[epoch: 980/1000, batch:   572/ 1052, ite: 257620] train loss: 0.003801, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000024, l3: 0.000090, l4: 0.000237, l5: 0.000872, l6: 0.001581

[epoch: 980/1000, batch:   652/ 1052, ite: 257640] train loss: 0.003803, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000007, l3: 0.000083, l4: 0.000481, l5: 0.001338, l6: 0.002111

[epoch: 980/1000, batch:   732/ 1052, ite: 257660] train loss: 0.003802, tar: 0.000020 
l0: 0.000009, l1: 0.000009, l2: 0.000074, l3: 0.000223, l4: 0.000514, l5: 0.000850, l6: 0.002719

[epoch: 980/1000, batch:   812/ 1052, ite: 257680] train loss: 0.003801, tar: 0.000020 
l0: 0.000022, l1: 0.000023, l2: 0.000034, l3: 0.000125, l4: 0.000464, l5: 0.001024, l6: 0.001909

[epoch: 980/1000, batch:   892/ 1052, ite: 257700] train loss: 0.003801, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000009, l3: 0.000100, l4: 0.000261, l5: 0.000458, l6: 0.000956

[epoch: 980/1000, batch:   972/ 1052, ite: 257720] train loss: 0.003801, tar: 0.000020 
l0: 0.000042, l1: 0.000044, l2: 0.000079, l3: 0.000267, l4: 0.000601, l5: 0.001091, l6: 0.002537

[epoch: 980/1000, batch:  1052/ 1052, ite: 257740] train loss: 0.003802, tar: 0.000020 
[Epoch 980/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000001, l1: 0.000001, l2: 0.000006, l3: 0.000065, l4: 0.000301, l5: 0.000382, l6: 0.000879

[epoch: 981/1000, batch:    80/ 1052, ite: 257760] train loss: 0.003803, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000021, l3: 0.000159, l4: 0.000326, l5: 0.001069, l6: 0.002537

[epoch: 981/1000, batch:   160/ 1052, ite: 257780] train loss: 0.003801, tar: 0.000020 
l0: 0.000016, l1: 0.000014, l2: 0.000053, l3: 0.000170, l4: 0.000617, l5: 0.001355, l6: 0.001977

[epoch: 981/1000, batch:   240/ 1052, ite: 257800] train loss: 0.003802, tar: 0.000020 
l0: 0.000010, l1: 0.000008, l2: 0.000034, l3: 0.000106, l4: 0.000417, l5: 0.001414, l6: 0.001686

[epoch: 981/1000, batch:   320/ 1052, ite: 257820] train loss: 0.003801, tar: 0.000020 
l0: 0.000014, l1: 0.000016, l2: 0.000060, l3: 0.000222, l4: 0.000800, l5: 0.001125, l6: 0.002816

[epoch: 981/1000, batch:   400/ 1052, ite: 257840] train loss: 0.003801, tar: 0.000020 
l0: 0.000020, l1: 0.000019, l2: 0.000057, l3: 0.000210, l4: 0.000522, l5: 0.001038, l6: 0.002017

[epoch: 981/1000, batch:   480/ 1052, ite: 257860] train loss: 0.003800, tar: 0.000020 
l0: 0.000024, l1: 0.000024, l2: 0.000032, l3: 0.000189, l4: 0.000505, l5: 0.000940, l6: 0.001234

[epoch: 981/1000, batch:   560/ 1052, ite: 257880] train loss: 0.003799, tar: 0.000020 
l0: 0.000038, l1: 0.000039, l2: 0.000101, l3: 0.000296, l4: 0.000603, l5: 0.001238, l6: 0.002579

[epoch: 981/1000, batch:   640/ 1052, ite: 257900] train loss: 0.003799, tar: 0.000020 
l0: 0.000033, l1: 0.000032, l2: 0.000071, l3: 0.000180, l4: 0.000355, l5: 0.001196, l6: 0.002719

[epoch: 981/1000, batch:   720/ 1052, ite: 257920] train loss: 0.003802, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000016, l3: 0.000071, l4: 0.000321, l5: 0.000579, l6: 0.000686

[epoch: 981/1000, batch:   800/ 1052, ite: 257940] train loss: 0.003802, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000032, l3: 0.000164, l4: 0.000498, l5: 0.001033, l6: 0.001478

[epoch: 981/1000, batch:   880/ 1052, ite: 257960] train loss: 0.003801, tar: 0.000020 
l0: 0.000007, l1: 0.000006, l2: 0.000055, l3: 0.000203, l4: 0.000518, l5: 0.000986, l6: 0.002147

[epoch: 981/1000, batch:   960/ 1052, ite: 257980] train loss: 0.003801, tar: 0.000020 
l0: 0.000036, l1: 0.000034, l2: 0.000079, l3: 0.000186, l4: 0.000625, l5: 0.001275, l6: 0.003074

[epoch: 981/1000, batch:  1040/ 1052, ite: 258000] train loss: 0.003800, tar: 0.000020 
[Epoch 981/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000009, l1: 0.000010, l2: 0.000018, l3: 0.000091, l4: 0.000390, l5: 0.001058, l6: 0.001943

[epoch: 982/1000, batch:    68/ 1052, ite: 258020] train loss: 0.003801, tar: 0.000020 
l0: 0.000008, l1: 0.000006, l2: 0.000101, l3: 0.000284, l4: 0.001019, l5: 0.001814, l6: 0.003249

[epoch: 982/1000, batch:   148/ 1052, ite: 258040] train loss: 0.003802, tar: 0.000020 
l0: 0.000036, l1: 0.000031, l2: 0.000076, l3: 0.000180, l4: 0.000663, l5: 0.000930, l6: 0.001616

[epoch: 982/1000, batch:   228/ 1052, ite: 258060] train loss: 0.003802, tar: 0.000020 
l0: 0.000005, l1: 0.000004, l2: 0.000031, l3: 0.000081, l4: 0.000415, l5: 0.000671, l6: 0.000975

[epoch: 982/1000, batch:   308/ 1052, ite: 258080] train loss: 0.003801, tar: 0.000020 
l0: 0.000024, l1: 0.000025, l2: 0.000023, l3: 0.000091, l4: 0.000351, l5: 0.001048, l6: 0.002024

[epoch: 982/1000, batch:   388/ 1052, ite: 258100] train loss: 0.003801, tar: 0.000020 
l0: 0.000016, l1: 0.000016, l2: 0.000040, l3: 0.000172, l4: 0.000407, l5: 0.000994, l6: 0.001806

[epoch: 982/1000, batch:   468/ 1052, ite: 258120] train loss: 0.003802, tar: 0.000020 
l0: 0.000035, l1: 0.000036, l2: 0.000072, l3: 0.000233, l4: 0.000966, l5: 0.002205, l6: 0.003089

[epoch: 982/1000, batch:   548/ 1052, ite: 258140] train loss: 0.003804, tar: 0.000020 
l0: 0.000047, l1: 0.000042, l2: 0.000077, l3: 0.000209, l4: 0.000596, l5: 0.000999, l6: 0.001987

[epoch: 982/1000, batch:   628/ 1052, ite: 258160] train loss: 0.003804, tar: 0.000020 
l0: 0.000052, l1: 0.000052, l2: 0.000073, l3: 0.000220, l4: 0.000568, l5: 0.001428, l6: 0.002251

[epoch: 982/1000, batch:   708/ 1052, ite: 258180] train loss: 0.003802, tar: 0.000020 
l0: 0.000010, l1: 0.000010, l2: 0.000070, l3: 0.000295, l4: 0.000617, l5: 0.001252, l6: 0.001561

[epoch: 982/1000, batch:   788/ 1052, ite: 258200] train loss: 0.003802, tar: 0.000020 
l0: 0.000022, l1: 0.000021, l2: 0.000051, l3: 0.000179, l4: 0.000766, l5: 0.002648, l6: 0.003575

[epoch: 982/1000, batch:   868/ 1052, ite: 258220] train loss: 0.003803, tar: 0.000020 
l0: 0.000043, l1: 0.000047, l2: 0.000135, l3: 0.000322, l4: 0.000762, l5: 0.002317, l6: 0.003248

[epoch: 982/1000, batch:   948/ 1052, ite: 258240] train loss: 0.003805, tar: 0.000020 
l0: 0.000018, l1: 0.000035, l2: 0.000053, l3: 0.000189, l4: 0.000552, l5: 0.001066, l6: 0.001808

[epoch: 982/1000, batch:  1028/ 1052, ite: 258260] train loss: 0.003804, tar: 0.000020 
[Epoch 982/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000021, l1: 0.000020, l2: 0.000064, l3: 0.000161, l4: 0.000407, l5: 0.000854, l6: 0.001497

[epoch: 983/1000, batch:    56/ 1052, ite: 258280] train loss: 0.003804, tar: 0.000020 
l0: 0.000003, l1: 0.000002, l2: 0.000010, l3: 0.000101, l4: 0.000347, l5: 0.001049, l6: 0.001421

[epoch: 983/1000, batch:   136/ 1052, ite: 258300] train loss: 0.003803, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000043, l3: 0.000102, l4: 0.000308, l5: 0.001007, l6: 0.001321

[epoch: 983/1000, batch:   216/ 1052, ite: 258320] train loss: 0.003803, tar: 0.000020 
l0: 0.000014, l1: 0.000015, l2: 0.000017, l3: 0.000144, l4: 0.000451, l5: 0.001204, l6: 0.001637

[epoch: 983/1000, batch:   296/ 1052, ite: 258340] train loss: 0.003802, tar: 0.000020 
l0: 0.000043, l1: 0.000048, l2: 0.000058, l3: 0.000237, l4: 0.000539, l5: 0.000515, l6: 0.002104

[epoch: 983/1000, batch:   376/ 1052, ite: 258360] train loss: 0.003801, tar: 0.000020 
l0: 0.000009, l1: 0.000008, l2: 0.000043, l3: 0.000175, l4: 0.000265, l5: 0.000564, l6: 0.001447

[epoch: 983/1000, batch:   456/ 1052, ite: 258380] train loss: 0.003801, tar: 0.000020 
l0: 0.000007, l1: 0.000007, l2: 0.000015, l3: 0.000073, l4: 0.000239, l5: 0.000772, l6: 0.001735

[epoch: 983/1000, batch:   536/ 1052, ite: 258400] train loss: 0.003803, tar: 0.000020 
l0: 0.000004, l1: 0.000005, l2: 0.000012, l3: 0.000100, l4: 0.000247, l5: 0.000897, l6: 0.001390

[epoch: 983/1000, batch:   616/ 1052, ite: 258420] train loss: 0.003802, tar: 0.000020 
l0: 0.000027, l1: 0.000025, l2: 0.000081, l3: 0.000218, l4: 0.000555, l5: 0.001015, l6: 0.002113

[epoch: 983/1000, batch:   696/ 1052, ite: 258440] train loss: 0.003802, tar: 0.000020 
l0: 0.000005, l1: 0.000006, l2: 0.000028, l3: 0.000170, l4: 0.000342, l5: 0.000731, l6: 0.002111

[epoch: 983/1000, batch:   776/ 1052, ite: 258460] train loss: 0.003802, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000025, l3: 0.000056, l4: 0.000279, l5: 0.000886, l6: 0.001208

[epoch: 983/1000, batch:   856/ 1052, ite: 258480] train loss: 0.003802, tar: 0.000020 
l0: 0.000024, l1: 0.000021, l2: 0.000079, l3: 0.000213, l4: 0.000657, l5: 0.001478, l6: 0.003037

[epoch: 983/1000, batch:   936/ 1052, ite: 258500] train loss: 0.003803, tar: 0.000020 
l0: 0.000010, l1: 0.000010, l2: 0.000052, l3: 0.000206, l4: 0.000429, l5: 0.001375, l6: 0.002127

[epoch: 983/1000, batch:  1016/ 1052, ite: 258520] train loss: 0.003802, tar: 0.000020 
[Epoch 983/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000009, l1: 0.000008, l2: 0.000072, l3: 0.000223, l4: 0.000568, l5: 0.001339, l6: 0.001697

[epoch: 984/1000, batch:    44/ 1052, ite: 258540] train loss: 0.003802, tar: 0.000020 
l0: 0.000093, l1: 0.000097, l2: 0.000155, l3: 0.000293, l4: 0.000986, l5: 0.001383, l6: 0.002357

[epoch: 984/1000, batch:   124/ 1052, ite: 258560] train loss: 0.003802, tar: 0.000020 
l0: 0.000012, l1: 0.000011, l2: 0.000046, l3: 0.000122, l4: 0.000193, l5: 0.001012, l6: 0.001720

[epoch: 984/1000, batch:   204/ 1052, ite: 258580] train loss: 0.003800, tar: 0.000020 
l0: 0.000001, l1: 0.000002, l2: 0.000017, l3: 0.000069, l4: 0.000315, l5: 0.000680, l6: 0.001838

[epoch: 984/1000, batch:   284/ 1052, ite: 258600] train loss: 0.003802, tar: 0.000020 
l0: 0.000006, l1: 0.000006, l2: 0.000026, l3: 0.000164, l4: 0.000557, l5: 0.000798, l6: 0.002398

[epoch: 984/1000, batch:   364/ 1052, ite: 258620] train loss: 0.003802, tar: 0.000020 
l0: 0.000017, l1: 0.000018, l2: 0.000025, l3: 0.000190, l4: 0.000568, l5: 0.000872, l6: 0.002279

[epoch: 984/1000, batch:   444/ 1052, ite: 258640] train loss: 0.003803, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000059, l3: 0.000175, l4: 0.000284, l5: 0.000970, l6: 0.001727

[epoch: 984/1000, batch:   524/ 1052, ite: 258660] train loss: 0.003802, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000030, l3: 0.000155, l4: 0.000440, l5: 0.000908, l6: 0.002206

[epoch: 984/1000, batch:   604/ 1052, ite: 258680] train loss: 0.003802, tar: 0.000020 
l0: 0.000030, l1: 0.000030, l2: 0.000042, l3: 0.000119, l4: 0.000481, l5: 0.001306, l6: 0.002147

[epoch: 984/1000, batch:   684/ 1052, ite: 258700] train loss: 0.003801, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000018, l3: 0.000120, l4: 0.000383, l5: 0.001119, l6: 0.001744

[epoch: 984/1000, batch:   764/ 1052, ite: 258720] train loss: 0.003801, tar: 0.000020 
l0: 0.000018, l1: 0.000017, l2: 0.000061, l3: 0.000159, l4: 0.000398, l5: 0.000494, l6: 0.001043

[epoch: 984/1000, batch:   844/ 1052, ite: 258740] train loss: 0.003802, tar: 0.000020 
l0: 0.000053, l1: 0.000049, l2: 0.000065, l3: 0.000148, l4: 0.000565, l5: 0.000935, l6: 0.001257

[epoch: 984/1000, batch:   924/ 1052, ite: 258760] train loss: 0.003801, tar: 0.000020 
l0: 0.000020, l1: 0.000020, l2: 0.000043, l3: 0.000320, l4: 0.000618, l5: 0.001244, l6: 0.002016

[epoch: 984/1000, batch:  1004/ 1052, ite: 258780] train loss: 0.003801, tar: 0.000020 
[Epoch 984/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000006, l1: 0.000006, l2: 0.000068, l3: 0.000289, l4: 0.000740, l5: 0.001193, l6: 0.001837

[epoch: 985/1000, batch:    32/ 1052, ite: 258800] train loss: 0.003802, tar: 0.000020 
l0: 0.000006, l1: 0.000006, l2: 0.000025, l3: 0.000046, l4: 0.000295, l5: 0.000680, l6: 0.000826

[epoch: 985/1000, batch:   112/ 1052, ite: 258820] train loss: 0.003800, tar: 0.000020 
l0: 0.000020, l1: 0.000021, l2: 0.000030, l3: 0.000206, l4: 0.000446, l5: 0.000911, l6: 0.001593

[epoch: 985/1000, batch:   192/ 1052, ite: 258840] train loss: 0.003800, tar: 0.000020 
l0: 0.000001, l1: 0.000002, l2: 0.000005, l3: 0.000051, l4: 0.000298, l5: 0.000967, l6: 0.001357

[epoch: 985/1000, batch:   272/ 1052, ite: 258860] train loss: 0.003801, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000013, l3: 0.000060, l4: 0.000220, l5: 0.000431, l6: 0.001746

[epoch: 985/1000, batch:   352/ 1052, ite: 258880] train loss: 0.003801, tar: 0.000020 
l0: 0.000038, l1: 0.000034, l2: 0.000051, l3: 0.000109, l4: 0.000333, l5: 0.000936, l6: 0.001653

[epoch: 985/1000, batch:   432/ 1052, ite: 258900] train loss: 0.003802, tar: 0.000020 
l0: 0.000011, l1: 0.000010, l2: 0.000049, l3: 0.000166, l4: 0.000659, l5: 0.001765, l6: 0.002817

[epoch: 985/1000, batch:   512/ 1052, ite: 258920] train loss: 0.003803, tar: 0.000020 
l0: 0.000034, l1: 0.000032, l2: 0.000052, l3: 0.000108, l4: 0.000488, l5: 0.001047, l6: 0.001757

[epoch: 985/1000, batch:   592/ 1052, ite: 258940] train loss: 0.003801, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000017, l3: 0.000108, l4: 0.000345, l5: 0.001131, l6: 0.001232

[epoch: 985/1000, batch:   672/ 1052, ite: 258960] train loss: 0.003802, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000030, l3: 0.000187, l4: 0.000417, l5: 0.000939, l6: 0.002293

[epoch: 985/1000, batch:   752/ 1052, ite: 258980] train loss: 0.003801, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000010, l3: 0.000079, l4: 0.000323, l5: 0.000634, l6: 0.001444

[epoch: 985/1000, batch:   832/ 1052, ite: 259000] train loss: 0.003801, tar: 0.000020 
l0: 0.000012, l1: 0.000010, l2: 0.000020, l3: 0.000108, l4: 0.000384, l5: 0.000648, l6: 0.001058

[epoch: 985/1000, batch:   912/ 1052, ite: 259020] train loss: 0.003802, tar: 0.000020 
l0: 0.000038, l1: 0.000035, l2: 0.000079, l3: 0.000326, l4: 0.001146, l5: 0.002261, l6: 0.003043

[epoch: 985/1000, batch:   992/ 1052, ite: 259040] train loss: 0.003802, tar: 0.000020 
[Epoch 985/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000014, l1: 0.000018, l2: 0.000035, l3: 0.000266, l4: 0.000546, l5: 0.001362, l6: 0.002455

[epoch: 986/1000, batch:    20/ 1052, ite: 259060] train loss: 0.003803, tar: 0.000020 
l0: 0.000037, l1: 0.000039, l2: 0.000050, l3: 0.000284, l4: 0.000833, l5: 0.001528, l6: 0.003232

[epoch: 986/1000, batch:   100/ 1052, ite: 259080] train loss: 0.003803, tar: 0.000020 
l0: 0.000070, l1: 0.000069, l2: 0.000170, l3: 0.000361, l4: 0.000784, l5: 0.002958, l6: 0.004412

[epoch: 986/1000, batch:   180/ 1052, ite: 259100] train loss: 0.003805, tar: 0.000020 
l0: 0.000049, l1: 0.000049, l2: 0.000070, l3: 0.000161, l4: 0.000593, l5: 0.001315, l6: 0.001954

[epoch: 986/1000, batch:   260/ 1052, ite: 259120] train loss: 0.003806, tar: 0.000020 
l0: 0.000024, l1: 0.000025, l2: 0.000086, l3: 0.000261, l4: 0.000478, l5: 0.001544, l6: 0.003341

[epoch: 986/1000, batch:   340/ 1052, ite: 259140] train loss: 0.003806, tar: 0.000020 
l0: 0.000009, l1: 0.000008, l2: 0.000040, l3: 0.000330, l4: 0.000857, l5: 0.001724, l6: 0.003422

[epoch: 986/1000, batch:   420/ 1052, ite: 259160] train loss: 0.003808, tar: 0.000020 
l0: 0.000026, l1: 0.000024, l2: 0.000091, l3: 0.000244, l4: 0.000528, l5: 0.001419, l6: 0.003179

[epoch: 986/1000, batch:   500/ 1052, ite: 259180] train loss: 0.003809, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000023, l3: 0.000056, l4: 0.000127, l5: 0.000497, l6: 0.001410

[epoch: 986/1000, batch:   580/ 1052, ite: 259200] train loss: 0.003807, tar: 0.000020 
l0: 0.000024, l1: 0.000025, l2: 0.000073, l3: 0.000188, l4: 0.000421, l5: 0.001487, l6: 0.002794

[epoch: 986/1000, batch:   660/ 1052, ite: 259220] train loss: 0.003808, tar: 0.000020 
l0: 0.000041, l1: 0.000038, l2: 0.000071, l3: 0.000178, l4: 0.000489, l5: 0.000966, l6: 0.003018

[epoch: 986/1000, batch:   740/ 1052, ite: 259240] train loss: 0.003807, tar: 0.000020 
l0: 0.000023, l1: 0.000024, l2: 0.000099, l3: 0.000117, l4: 0.000224, l5: 0.001071, l6: 0.001952

[epoch: 986/1000, batch:   820/ 1052, ite: 259260] train loss: 0.003806, tar: 0.000020 
l0: 0.000017, l1: 0.000017, l2: 0.000024, l3: 0.000081, l4: 0.000273, l5: 0.000894, l6: 0.001226

[epoch: 986/1000, batch:   900/ 1052, ite: 259280] train loss: 0.003806, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000014, l3: 0.000138, l4: 0.000471, l5: 0.000864, l6: 0.001434

[epoch: 986/1000, batch:   980/ 1052, ite: 259300] train loss: 0.003805, tar: 0.000020 
[Epoch 986/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000012, l1: 0.000010, l2: 0.000065, l3: 0.000154, l4: 0.000503, l5: 0.000807, l6: 0.001494

[epoch: 987/1000, batch:     8/ 1052, ite: 259320] train loss: 0.003804, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000034, l3: 0.000220, l4: 0.000497, l5: 0.001313, l6: 0.001970

[epoch: 987/1000, batch:    88/ 1052, ite: 259340] train loss: 0.003804, tar: 0.000020 
l0: 0.000006, l1: 0.000005, l2: 0.000053, l3: 0.000173, l4: 0.000287, l5: 0.001043, l6: 0.001332

[epoch: 987/1000, batch:   168/ 1052, ite: 259360] train loss: 0.003803, tar: 0.000020 
l0: 0.000006, l1: 0.000005, l2: 0.000045, l3: 0.000236, l4: 0.000492, l5: 0.001358, l6: 0.001651

[epoch: 987/1000, batch:   248/ 1052, ite: 259380] train loss: 0.003802, tar: 0.000020 
l0: 0.000012, l1: 0.000013, l2: 0.000021, l3: 0.000122, l4: 0.000412, l5: 0.000943, l6: 0.001386

[epoch: 987/1000, batch:   328/ 1052, ite: 259400] train loss: 0.003802, tar: 0.000020 
l0: 0.000004, l1: 0.000005, l2: 0.000016, l3: 0.000038, l4: 0.000218, l5: 0.000929, l6: 0.001137

[epoch: 987/1000, batch:   408/ 1052, ite: 259420] train loss: 0.003802, tar: 0.000020 
l0: 0.000008, l1: 0.000007, l2: 0.000017, l3: 0.000063, l4: 0.000360, l5: 0.000575, l6: 0.001670

[epoch: 987/1000, batch:   488/ 1052, ite: 259440] train loss: 0.003803, tar: 0.000020 
l0: 0.000004, l1: 0.000005, l2: 0.000033, l3: 0.000135, l4: 0.000503, l5: 0.001236, l6: 0.001599

[epoch: 987/1000, batch:   568/ 1052, ite: 259460] train loss: 0.003804, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000025, l3: 0.000115, l4: 0.000322, l5: 0.000934, l6: 0.001198

[epoch: 987/1000, batch:   648/ 1052, ite: 259480] train loss: 0.003803, tar: 0.000020 
l0: 0.000025, l1: 0.000023, l2: 0.000046, l3: 0.000169, l4: 0.000503, l5: 0.000954, l6: 0.003242

[epoch: 987/1000, batch:   728/ 1052, ite: 259500] train loss: 0.003801, tar: 0.000020 
l0: 0.000010, l1: 0.000011, l2: 0.000033, l3: 0.000052, l4: 0.000151, l5: 0.000540, l6: 0.001081

[epoch: 987/1000, batch:   808/ 1052, ite: 259520] train loss: 0.003802, tar: 0.000020 
l0: 0.000012, l1: 0.000013, l2: 0.000050, l3: 0.000257, l4: 0.000601, l5: 0.001797, l6: 0.003430

[epoch: 987/1000, batch:   888/ 1052, ite: 259540] train loss: 0.003803, tar: 0.000020 
l0: 0.000106, l1: 0.000110, l2: 0.000112, l3: 0.000184, l4: 0.000390, l5: 0.001314, l6: 0.002899

[epoch: 987/1000, batch:   968/ 1052, ite: 259560] train loss: 0.003804, tar: 0.000020 
l0: 0.000005, l1: 0.000004, l2: 0.000016, l3: 0.000098, l4: 0.000325, l5: 0.000588, l6: 0.000989

[epoch: 987/1000, batch:  1048/ 1052, ite: 259580] train loss: 0.003804, tar: 0.000020 
[Epoch 987/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000020, l1: 0.000025, l2: 0.000037, l3: 0.000160, l4: 0.000398, l5: 0.001025, l6: 0.002674

[epoch: 988/1000, batch:    76/ 1052, ite: 259600] train loss: 0.003804, tar: 0.000020 
l0: 0.000015, l1: 0.000015, l2: 0.000071, l3: 0.000261, l4: 0.000445, l5: 0.000778, l6: 0.003674

[epoch: 988/1000, batch:   156/ 1052, ite: 259620] train loss: 0.003803, tar: 0.000020 
l0: 0.000018, l1: 0.000019, l2: 0.000053, l3: 0.000104, l4: 0.000478, l5: 0.001001, l6: 0.001343

[epoch: 988/1000, batch:   236/ 1052, ite: 259640] train loss: 0.003804, tar: 0.000020 
l0: 0.000011, l1: 0.000011, l2: 0.000040, l3: 0.000176, l4: 0.000344, l5: 0.000933, l6: 0.003034

[epoch: 988/1000, batch:   316/ 1052, ite: 259660] train loss: 0.003804, tar: 0.000020 
l0: 0.000004, l1: 0.000003, l2: 0.000022, l3: 0.000050, l4: 0.000238, l5: 0.000541, l6: 0.001324

[epoch: 988/1000, batch:   396/ 1052, ite: 259680] train loss: 0.003802, tar: 0.000020 
l0: 0.000018, l1: 0.000017, l2: 0.000050, l3: 0.000172, l4: 0.000438, l5: 0.001304, l6: 0.002548

[epoch: 988/1000, batch:   476/ 1052, ite: 259700] train loss: 0.003803, tar: 0.000020 
l0: 0.000002, l1: 0.000003, l2: 0.000005, l3: 0.000088, l4: 0.000162, l5: 0.000858, l6: 0.001674

[epoch: 988/1000, batch:   556/ 1052, ite: 259720] train loss: 0.003803, tar: 0.000020 
l0: 0.000006, l1: 0.000006, l2: 0.000022, l3: 0.000085, l4: 0.000377, l5: 0.000913, l6: 0.001748

[epoch: 988/1000, batch:   636/ 1052, ite: 259740] train loss: 0.003804, tar: 0.000020 
l0: 0.000025, l1: 0.000026, l2: 0.000120, l3: 0.000324, l4: 0.000633, l5: 0.001505, l6: 0.002188

[epoch: 988/1000, batch:   716/ 1052, ite: 259760] train loss: 0.003803, tar: 0.000020 
l0: 0.000021, l1: 0.000022, l2: 0.000052, l3: 0.000111, l4: 0.000431, l5: 0.000609, l6: 0.001496

[epoch: 988/1000, batch:   796/ 1052, ite: 259780] train loss: 0.003805, tar: 0.000020 
l0: 0.000006, l1: 0.000007, l2: 0.000029, l3: 0.000139, l4: 0.000256, l5: 0.000680, l6: 0.001858

[epoch: 988/1000, batch:   876/ 1052, ite: 259800] train loss: 0.003804, tar: 0.000020 
l0: 0.000027, l1: 0.000027, l2: 0.000060, l3: 0.000122, l4: 0.000226, l5: 0.000917, l6: 0.001897

[epoch: 988/1000, batch:   956/ 1052, ite: 259820] train loss: 0.003803, tar: 0.000020 
l0: 0.000031, l1: 0.000028, l2: 0.000134, l3: 0.000356, l4: 0.000782, l5: 0.002657, l6: 0.003449

[epoch: 988/1000, batch:  1036/ 1052, ite: 259840] train loss: 0.003804, tar: 0.000020 
[Epoch 988/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000029, l1: 0.000031, l2: 0.000081, l3: 0.000227, l4: 0.000560, l5: 0.001834, l6: 0.003916

[epoch: 989/1000, batch:    64/ 1052, ite: 259860] train loss: 0.003804, tar: 0.000020 
l0: 0.000114, l1: 0.000121, l2: 0.000077, l3: 0.000201, l4: 0.000433, l5: 0.001099, l6: 0.002751

[epoch: 989/1000, batch:   144/ 1052, ite: 259880] train loss: 0.003805, tar: 0.000020 
l0: 0.000010, l1: 0.000010, l2: 0.000023, l3: 0.000116, l4: 0.000488, l5: 0.000977, l6: 0.001846

[epoch: 989/1000, batch:   224/ 1052, ite: 259900] train loss: 0.003803, tar: 0.000020 
l0: 0.000004, l1: 0.000004, l2: 0.000027, l3: 0.000145, l4: 0.000421, l5: 0.001052, l6: 0.001276

[epoch: 989/1000, batch:   304/ 1052, ite: 259920] train loss: 0.003803, tar: 0.000020 
l0: 0.000021, l1: 0.000023, l2: 0.000039, l3: 0.000202, l4: 0.000435, l5: 0.000667, l6: 0.001057

[epoch: 989/1000, batch:   384/ 1052, ite: 259940] train loss: 0.003802, tar: 0.000020 
l0: 0.000010, l1: 0.000009, l2: 0.000043, l3: 0.000112, l4: 0.000374, l5: 0.000716, l6: 0.001335

[epoch: 989/1000, batch:   464/ 1052, ite: 259960] train loss: 0.003802, tar: 0.000020 
l0: 0.000005, l1: 0.000005, l2: 0.000028, l3: 0.000109, l4: 0.000238, l5: 0.000810, l6: 0.001594

[epoch: 989/1000, batch:   544/ 1052, ite: 259980] train loss: 0.003801, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000012, l3: 0.000090, l4: 0.000301, l5: 0.000766, l6: 0.002645

[epoch: 989/1000, batch:   624/ 1052, ite: 260000] train loss: 0.003802, tar: 0.000020 
l0: 0.000033, l1: 0.000031, l2: 0.000069, l3: 0.000167, l4: 0.000589, l5: 0.001131, l6: 0.001738

[epoch: 989/1000, batch:   704/ 1052, ite: 260020] train loss: 0.003801, tar: 0.000020 
l0: 0.000008, l1: 0.000008, l2: 0.000076, l3: 0.000154, l4: 0.000376, l5: 0.000691, l6: 0.001111

[epoch: 989/1000, batch:   784/ 1052, ite: 260040] train loss: 0.003802, tar: 0.000020 
l0: 0.000015, l1: 0.000015, l2: 0.000027, l3: 0.000201, l4: 0.000513, l5: 0.001279, l6: 0.003506

[epoch: 989/1000, batch:   864/ 1052, ite: 260060] train loss: 0.003803, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000013, l3: 0.000066, l4: 0.000394, l5: 0.000940, l6: 0.001359

[epoch: 989/1000, batch:   944/ 1052, ite: 260080] train loss: 0.003802, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000008, l3: 0.000134, l4: 0.000343, l5: 0.000906, l6: 0.001562

[epoch: 989/1000, batch:  1024/ 1052, ite: 260100] train loss: 0.003803, tar: 0.000020 
[Epoch 989/1000] Test loss: 0.023, Test target loss: 0.004
l0: 0.000000, l1: 0.000000, l2: 0.000009, l3: 0.000080, l4: 0.000473, l5: 0.000913, l6: 0.001728

[epoch: 990/1000, batch:    52/ 1052, ite: 260120] train loss: 0.003803, tar: 0.000020 
l0: 0.000016, l1: 0.000017, l2: 0.000040, l3: 0.000141, l4: 0.000369, l5: 0.000832, l6: 0.001387

[epoch: 990/1000, batch:   132/ 1052, ite: 260140] train loss: 0.003802, tar: 0.000020 
l0: 0.000017, l1: 0.000018, l2: 0.000037, l3: 0.000107, l4: 0.000391, l5: 0.001103, l6: 0.001277

[epoch: 990/1000, batch:   212/ 1052, ite: 260160] train loss: 0.003802, tar: 0.000020 
l0: 0.000013, l1: 0.000013, l2: 0.000068, l3: 0.000243, l4: 0.000730, l5: 0.002186, l6: 0.003125

[epoch: 990/1000, batch:   292/ 1052, ite: 260180] train loss: 0.003802, tar: 0.000020 
l0: 0.000001, l1: 0.000000, l2: 0.000013, l3: 0.000135, l4: 0.000565, l5: 0.001144, l6: 0.001507

[epoch: 990/1000, batch:   372/ 1052, ite: 260200] train loss: 0.003801, tar: 0.000020 
l0: 0.000013, l1: 0.000016, l2: 0.000015, l3: 0.000116, l4: 0.000484, l5: 0.001011, l6: 0.001897

[epoch: 990/1000, batch:   452/ 1052, ite: 260220] train loss: 0.003801, tar: 0.000020 
l0: 0.000034, l1: 0.000036, l2: 0.000044, l3: 0.000188, l4: 0.000564, l5: 0.001402, l6: 0.001830

[epoch: 990/1000, batch:   532/ 1052, ite: 260240] train loss: 0.003801, tar: 0.000020 
l0: 0.000214, l1: 0.000234, l2: 0.000207, l3: 0.000238, l4: 0.000508, l5: 0.000777, l6: 0.001541

[epoch: 990/1000, batch:   612/ 1052, ite: 260260] train loss: 0.003801, tar: 0.000020 
l0: 0.000009, l1: 0.000007, l2: 0.000035, l3: 0.000113, l4: 0.000228, l5: 0.000557, l6: 0.001143

[epoch: 990/1000, batch:   692/ 1052, ite: 260280] train loss: 0.003801, tar: 0.000020 
l0: 0.000013, l1: 0.000012, l2: 0.000042, l3: 0.000128, l4: 0.000302, l5: 0.000606, l6: 0.001200

[epoch: 990/1000, batch:   772/ 1052, ite: 260300] train loss: 0.003800, tar: 0.000020 
l0: 0.000036, l1: 0.000040, l2: 0.000066, l3: 0.000155, l4: 0.000785, l5: 0.000838, l6: 0.002270

[epoch: 990/1000, batch:   852/ 1052, ite: 260320] train loss: 0.003800, tar: 0.000020 
l0: 0.000025, l1: 0.000026, l2: 0.000050, l3: 0.000158, l4: 0.000541, l5: 0.001182, l6: 0.002511

[epoch: 990/1000, batch:   932/ 1052, ite: 260340] train loss: 0.003800, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000010, l3: 0.000042, l4: 0.000283, l5: 0.000620, l6: 0.000915

[epoch: 990/1000, batch:  1012/ 1052, ite: 260360] train loss: 0.003799, tar: 0.000020 
[Epoch 990/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000004, l1: 0.000005, l2: 0.000008, l3: 0.000043, l4: 0.000358, l5: 0.000898, l6: 0.001290

[epoch: 991/1000, batch:    40/ 1052, ite: 260380] train loss: 0.003799, tar: 0.000020 
l0: 0.000024, l1: 0.000024, l2: 0.000065, l3: 0.000144, l4: 0.000342, l5: 0.001342, l6: 0.001486

[epoch: 991/1000, batch:   120/ 1052, ite: 260400] train loss: 0.003800, tar: 0.000020 
l0: 0.000064, l1: 0.000061, l2: 0.000102, l3: 0.000240, l4: 0.000559, l5: 0.000651, l6: 0.001630

[epoch: 991/1000, batch:   200/ 1052, ite: 260420] train loss: 0.003799, tar: 0.000020 
l0: 0.000009, l1: 0.000010, l2: 0.000022, l3: 0.000141, l4: 0.000626, l5: 0.001089, l6: 0.001905

[epoch: 991/1000, batch:   280/ 1052, ite: 260440] train loss: 0.003799, tar: 0.000020 
l0: 0.000010, l1: 0.000009, l2: 0.000028, l3: 0.000085, l4: 0.000304, l5: 0.000854, l6: 0.001303

[epoch: 991/1000, batch:   360/ 1052, ite: 260460] train loss: 0.003800, tar: 0.000020 
l0: 0.000054, l1: 0.000053, l2: 0.000088, l3: 0.000137, l4: 0.000349, l5: 0.000567, l6: 0.001133

[epoch: 991/1000, batch:   440/ 1052, ite: 260480] train loss: 0.003799, tar: 0.000020 
l0: 0.000034, l1: 0.000034, l2: 0.000071, l3: 0.000279, l4: 0.000602, l5: 0.001923, l6: 0.002957

[epoch: 991/1000, batch:   520/ 1052, ite: 260500] train loss: 0.003800, tar: 0.000020 
l0: 0.000013, l1: 0.000014, l2: 0.000041, l3: 0.000182, l4: 0.000848, l5: 0.001564, l6: 0.002415

[epoch: 991/1000, batch:   600/ 1052, ite: 260520] train loss: 0.003800, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000087, l3: 0.000213, l4: 0.000669, l5: 0.001195, l6: 0.002348

[epoch: 991/1000, batch:   680/ 1052, ite: 260540] train loss: 0.003800, tar: 0.000020 
l0: 0.000008, l1: 0.000009, l2: 0.000027, l3: 0.000052, l4: 0.000492, l5: 0.000747, l6: 0.001127

[epoch: 991/1000, batch:   760/ 1052, ite: 260560] train loss: 0.003799, tar: 0.000020 
l0: 0.000018, l1: 0.000015, l2: 0.000040, l3: 0.000103, l4: 0.000272, l5: 0.000831, l6: 0.001063

[epoch: 991/1000, batch:   840/ 1052, ite: 260580] train loss: 0.003799, tar: 0.000020 
l0: 0.000037, l1: 0.000038, l2: 0.000110, l3: 0.000383, l4: 0.000956, l5: 0.002052, l6: 0.002537

[epoch: 991/1000, batch:   920/ 1052, ite: 260600] train loss: 0.003800, tar: 0.000020 
l0: 0.000017, l1: 0.000019, l2: 0.000025, l3: 0.000163, l4: 0.000313, l5: 0.000755, l6: 0.001979

[epoch: 991/1000, batch:  1000/ 1052, ite: 260620] train loss: 0.003800, tar: 0.000020 
[Epoch 991/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000027, l1: 0.000030, l2: 0.000056, l3: 0.000213, l4: 0.000842, l5: 0.002234, l6: 0.003674

[epoch: 992/1000, batch:    28/ 1052, ite: 260640] train loss: 0.003801, tar: 0.000020 
l0: 0.000023, l1: 0.000024, l2: 0.000048, l3: 0.000169, l4: 0.000401, l5: 0.000960, l6: 0.002102

[epoch: 992/1000, batch:   108/ 1052, ite: 260660] train loss: 0.003801, tar: 0.000020 
l0: 0.000011, l1: 0.000013, l2: 0.000008, l3: 0.000057, l4: 0.000154, l5: 0.000290, l6: 0.001313

[epoch: 992/1000, batch:   188/ 1052, ite: 260680] train loss: 0.003801, tar: 0.000020 
l0: 0.000005, l1: 0.000004, l2: 0.000029, l3: 0.000154, l4: 0.000580, l5: 0.000632, l6: 0.002425

[epoch: 992/1000, batch:   268/ 1052, ite: 260700] train loss: 0.003801, tar: 0.000020 
l0: 0.000018, l1: 0.000018, l2: 0.000038, l3: 0.000218, l4: 0.000541, l5: 0.000677, l6: 0.001249

[epoch: 992/1000, batch:   348/ 1052, ite: 260720] train loss: 0.003801, tar: 0.000020 
l0: 0.000018, l1: 0.000019, l2: 0.000020, l3: 0.000045, l4: 0.000248, l5: 0.000925, l6: 0.001591

[epoch: 992/1000, batch:   428/ 1052, ite: 260740] train loss: 0.003802, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000026, l3: 0.000166, l4: 0.000357, l5: 0.000995, l6: 0.001624

[epoch: 992/1000, batch:   508/ 1052, ite: 260760] train loss: 0.003803, tar: 0.000020 
l0: 0.000006, l1: 0.000007, l2: 0.000007, l3: 0.000049, l4: 0.000272, l5: 0.000405, l6: 0.001174

[epoch: 992/1000, batch:   588/ 1052, ite: 260780] train loss: 0.003803, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000003, l3: 0.000037, l4: 0.000215, l5: 0.000656, l6: 0.001238

[epoch: 992/1000, batch:   668/ 1052, ite: 260800] train loss: 0.003803, tar: 0.000020 
l0: 0.000022, l1: 0.000024, l2: 0.000041, l3: 0.000108, l4: 0.000265, l5: 0.000773, l6: 0.001022

[epoch: 992/1000, batch:   748/ 1052, ite: 260820] train loss: 0.003803, tar: 0.000020 
l0: 0.000012, l1: 0.000010, l2: 0.000089, l3: 0.000159, l4: 0.000314, l5: 0.000759, l6: 0.001285

[epoch: 992/1000, batch:   828/ 1052, ite: 260840] train loss: 0.003803, tar: 0.000020 
l0: 0.000014, l1: 0.000016, l2: 0.000040, l3: 0.000177, l4: 0.000529, l5: 0.001174, l6: 0.003278

[epoch: 992/1000, batch:   908/ 1052, ite: 260860] train loss: 0.003803, tar: 0.000020 
l0: 0.000006, l1: 0.000006, l2: 0.000028, l3: 0.000165, l4: 0.000646, l5: 0.000751, l6: 0.002096

[epoch: 992/1000, batch:   988/ 1052, ite: 260880] train loss: 0.003801, tar: 0.000020 
[Epoch 992/1000] Test loss: 0.022, Test target loss: 0.004
l0: 0.000014, l1: 0.000014, l2: 0.000033, l3: 0.000215, l4: 0.000511, l5: 0.001156, l6: 0.001939

[epoch: 993/1000, batch:    16/ 1052, ite: 260900] train loss: 0.003801, tar: 0.000020 
l0: 0.000010, l1: 0.000009, l2: 0.000047, l3: 0.000168, l4: 0.000523, l5: 0.000861, l6: 0.001697

[epoch: 993/1000, batch:    96/ 1052, ite: 260920] train loss: 0.003802, tar: 0.000020 
l0: 0.000012, l1: 0.000012, l2: 0.000039, l3: 0.000209, l4: 0.000451, l5: 0.000900, l6: 0.002405

[epoch: 993/1000, batch:   176/ 1052, ite: 260940] train loss: 0.003801, tar: 0.000020 
l0: 0.000020, l1: 0.000017, l2: 0.000061, l3: 0.000244, l4: 0.000646, l5: 0.001523, l6: 0.002296

[epoch: 993/1000, batch:   256/ 1052, ite: 260960] train loss: 0.003801, tar: 0.000020 
l0: 0.000004, l1: 0.000005, l2: 0.000020, l3: 0.000073, l4: 0.000305, l5: 0.000880, l6: 0.001759

[epoch: 993/1000, batch:   336/ 1052, ite: 260980] train loss: 0.003801, tar: 0.000020 
l0: 0.000008, l1: 0.000009, l2: 0.000010, l3: 0.000092, l4: 0.000324, l5: 0.000711, l6: 0.001322

[epoch: 993/1000, batch:   416/ 1052, ite: 261000] train loss: 0.003801, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000019, l3: 0.000190, l4: 0.000391, l5: 0.001003, l6: 0.001466

[epoch: 993/1000, batch:   496/ 1052, ite: 261020] train loss: 0.003801, tar: 0.000020 
l0: 0.000026, l1: 0.000025, l2: 0.000060, l3: 0.000134, l4: 0.000494, l5: 0.000932, l6: 0.001227

[epoch: 993/1000, batch:   576/ 1052, ite: 261040] train loss: 0.003803, tar: 0.000020 
l0: 0.000016, l1: 0.000018, l2: 0.000038, l3: 0.000155, l4: 0.000560, l5: 0.001132, l6: 0.002340

[epoch: 993/1000, batch:   656/ 1052, ite: 261060] train loss: 0.003803, tar: 0.000020 
l0: 0.000011, l1: 0.000011, l2: 0.000023, l3: 0.000145, l4: 0.000340, l5: 0.000780, l6: 0.001574

[epoch: 993/1000, batch:   736/ 1052, ite: 261080] train loss: 0.003802, tar: 0.000020 
l0: 0.000038, l1: 0.000036, l2: 0.000049, l3: 0.000118, l4: 0.000547, l5: 0.001063, l6: 0.001788

[epoch: 993/1000, batch:   816/ 1052, ite: 261100] train loss: 0.003802, tar: 0.000020 
l0: 0.000017, l1: 0.000018, l2: 0.000040, l3: 0.000110, l4: 0.000493, l5: 0.001516, l6: 0.002216

[epoch: 993/1000, batch:   896/ 1052, ite: 261120] train loss: 0.003802, tar: 0.000020 
l0: 0.000019, l1: 0.000016, l2: 0.000033, l3: 0.000126, l4: 0.000263, l5: 0.001017, l6: 0.001611

[epoch: 993/1000, batch:   976/ 1052, ite: 261140] train loss: 0.003801, tar: 0.000020 
[Epoch 993/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000017, l1: 0.000018, l2: 0.000035, l3: 0.000101, l4: 0.000286, l5: 0.000766, l6: 0.000926

[epoch: 994/1000, batch:     4/ 1052, ite: 261160] train loss: 0.003800, tar: 0.000020 
l0: 0.000019, l1: 0.000020, l2: 0.000052, l3: 0.000174, l4: 0.000400, l5: 0.000920, l6: 0.000993

[epoch: 994/1000, batch:    84/ 1052, ite: 261180] train loss: 0.003800, tar: 0.000020 
l0: 0.000150, l1: 0.000167, l2: 0.000200, l3: 0.000305, l4: 0.000465, l5: 0.001389, l6: 0.002439

[epoch: 994/1000, batch:   164/ 1052, ite: 261200] train loss: 0.003798, tar: 0.000020 
l0: 0.000051, l1: 0.000051, l2: 0.000085, l3: 0.000267, l4: 0.000861, l5: 0.001867, l6: 0.003072

[epoch: 994/1000, batch:   244/ 1052, ite: 261220] train loss: 0.003799, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000013, l3: 0.000162, l4: 0.000230, l5: 0.000969, l6: 0.001742

[epoch: 994/1000, batch:   324/ 1052, ite: 261240] train loss: 0.003800, tar: 0.000020 
l0: 0.000005, l1: 0.000005, l2: 0.000043, l3: 0.000232, l4: 0.000628, l5: 0.001482, l6: 0.001831

[epoch: 994/1000, batch:   404/ 1052, ite: 261260] train loss: 0.003800, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000004, l3: 0.000068, l4: 0.000382, l5: 0.001016, l6: 0.000872

[epoch: 994/1000, batch:   484/ 1052, ite: 261280] train loss: 0.003799, tar: 0.000020 
l0: 0.000021, l1: 0.000021, l2: 0.000027, l3: 0.000195, l4: 0.000510, l5: 0.001382, l6: 0.002299

[epoch: 994/1000, batch:   564/ 1052, ite: 261300] train loss: 0.003799, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000004, l3: 0.000069, l4: 0.000357, l5: 0.001040, l6: 0.001011

[epoch: 994/1000, batch:   644/ 1052, ite: 261320] train loss: 0.003799, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000017, l3: 0.000124, l4: 0.000406, l5: 0.000988, l6: 0.001241

[epoch: 994/1000, batch:   724/ 1052, ite: 261340] train loss: 0.003798, tar: 0.000020 
l0: 0.000006, l1: 0.000007, l2: 0.000046, l3: 0.000164, l4: 0.000425, l5: 0.001626, l6: 0.003393

[epoch: 994/1000, batch:   804/ 1052, ite: 261360] train loss: 0.003797, tar: 0.000020 
l0: 0.000002, l1: 0.000002, l2: 0.000013, l3: 0.000108, l4: 0.000380, l5: 0.000795, l6: 0.002182

[epoch: 994/1000, batch:   884/ 1052, ite: 261380] train loss: 0.003797, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000003, l3: 0.000051, l4: 0.000439, l5: 0.000920, l6: 0.001616

[epoch: 994/1000, batch:   964/ 1052, ite: 261400] train loss: 0.003799, tar: 0.000020 
l0: 0.000010, l1: 0.000010, l2: 0.000042, l3: 0.000141, l4: 0.000279, l5: 0.000938, l6: 0.001866

[epoch: 994/1000, batch:  1044/ 1052, ite: 261420] train loss: 0.003798, tar: 0.000020 
[Epoch 994/1000] Test loss: 0.023, Test target loss: 0.005
l0: 0.000005, l1: 0.000006, l2: 0.000022, l3: 0.000118, l4: 0.000280, l5: 0.001320, l6: 0.002463

[epoch: 995/1000, batch:    72/ 1052, ite: 261440] train loss: 0.003798, tar: 0.000020 
l0: 0.000024, l1: 0.000026, l2: 0.000087, l3: 0.000335, l4: 0.001193, l5: 0.001761, l6: 0.001899

[epoch: 995/1000, batch:   152/ 1052, ite: 261460] train loss: 0.003799, tar: 0.000020 
l0: 0.000019, l1: 0.000018, l2: 0.000070, l3: 0.000190, l4: 0.000663, l5: 0.001484, l6: 0.002342

[epoch: 995/1000, batch:   232/ 1052, ite: 261480] train loss: 0.003799, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000013, l3: 0.000140, l4: 0.000397, l5: 0.000805, l6: 0.001704

[epoch: 995/1000, batch:   312/ 1052, ite: 261500] train loss: 0.003798, tar: 0.000020 
l0: 0.000005, l1: 0.000005, l2: 0.000034, l3: 0.000119, l4: 0.000335, l5: 0.001068, l6: 0.001693

[epoch: 995/1000, batch:   392/ 1052, ite: 261520] train loss: 0.003798, tar: 0.000020 
l0: 0.000023, l1: 0.000022, l2: 0.000070, l3: 0.000152, l4: 0.000393, l5: 0.000822, l6: 0.001199

[epoch: 995/1000, batch:   472/ 1052, ite: 261540] train loss: 0.003798, tar: 0.000020 
l0: 0.000037, l1: 0.000038, l2: 0.000089, l3: 0.000339, l4: 0.000865, l5: 0.002038, l6: 0.004256

[epoch: 995/1000, batch:   552/ 1052, ite: 261560] train loss: 0.003798, tar: 0.000020 
l0: 0.000052, l1: 0.000055, l2: 0.000076, l3: 0.000205, l4: 0.000441, l5: 0.001020, l6: 0.001153

[epoch: 995/1000, batch:   632/ 1052, ite: 261580] train loss: 0.003797, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000010, l3: 0.000105, l4: 0.000297, l5: 0.000880, l6: 0.001881

[epoch: 995/1000, batch:   712/ 1052, ite: 261600] train loss: 0.003799, tar: 0.000020 
l0: 0.000004, l1: 0.000005, l2: 0.000046, l3: 0.000177, l4: 0.000476, l5: 0.001037, l6: 0.001479

[epoch: 995/1000, batch:   792/ 1052, ite: 261620] train loss: 0.003798, tar: 0.000020 
l0: 0.000007, l1: 0.000009, l2: 0.000023, l3: 0.000163, l4: 0.000531, l5: 0.001037, l6: 0.002116

[epoch: 995/1000, batch:   872/ 1052, ite: 261640] train loss: 0.003798, tar: 0.000019 
l0: 0.000009, l1: 0.000010, l2: 0.000053, l3: 0.000286, l4: 0.000857, l5: 0.001642, l6: 0.002181

[epoch: 995/1000, batch:   952/ 1052, ite: 261660] train loss: 0.003798, tar: 0.000019 
l0: 0.000017, l1: 0.000016, l2: 0.000030, l3: 0.000189, l4: 0.000538, l5: 0.001367, l6: 0.002239

[epoch: 995/1000, batch:  1032/ 1052, ite: 261680] train loss: 0.003799, tar: 0.000019 
[Epoch 995/1000] Test loss: 0.023, Test target loss: 0.005
l0: 0.000008, l1: 0.000007, l2: 0.000038, l3: 0.000097, l4: 0.000319, l5: 0.000573, l6: 0.001177

[epoch: 996/1000, batch:    60/ 1052, ite: 261700] train loss: 0.003799, tar: 0.000019 
l0: 0.000002, l1: 0.000003, l2: 0.000017, l3: 0.000066, l4: 0.000181, l5: 0.000861, l6: 0.001561

[epoch: 996/1000, batch:   140/ 1052, ite: 261720] train loss: 0.003799, tar: 0.000019 
l0: 0.000006, l1: 0.000006, l2: 0.000036, l3: 0.000109, l4: 0.000300, l5: 0.000652, l6: 0.001497

[epoch: 996/1000, batch:   220/ 1052, ite: 261740] train loss: 0.003798, tar: 0.000019 
l0: 0.000006, l1: 0.000007, l2: 0.000095, l3: 0.000260, l4: 0.000452, l5: 0.000849, l6: 0.001351

[epoch: 996/1000, batch:   300/ 1052, ite: 261760] train loss: 0.003797, tar: 0.000019 
l0: 0.000034, l1: 0.000033, l2: 0.000086, l3: 0.000228, l4: 0.000468, l5: 0.000840, l6: 0.001947

[epoch: 996/1000, batch:   380/ 1052, ite: 261780] train loss: 0.003798, tar: 0.000020 
l0: 0.000025, l1: 0.000027, l2: 0.000048, l3: 0.000194, l4: 0.000399, l5: 0.001016, l6: 0.001623

[epoch: 996/1000, batch:   460/ 1052, ite: 261800] train loss: 0.003798, tar: 0.000020 
l0: 0.000019, l1: 0.000017, l2: 0.000063, l3: 0.000218, l4: 0.000523, l5: 0.001164, l6: 0.002130

[epoch: 996/1000, batch:   540/ 1052, ite: 261820] train loss: 0.003797, tar: 0.000020 
l0: 0.000014, l1: 0.000015, l2: 0.000060, l3: 0.000091, l4: 0.000412, l5: 0.001115, l6: 0.001724

[epoch: 996/1000, batch:   620/ 1052, ite: 261840] train loss: 0.003797, tar: 0.000020 
l0: 0.000008, l1: 0.000008, l2: 0.000026, l3: 0.000112, l4: 0.000353, l5: 0.000951, l6: 0.001204

[epoch: 996/1000, batch:   700/ 1052, ite: 261860] train loss: 0.003798, tar: 0.000020 
l0: 0.000025, l1: 0.000024, l2: 0.000039, l3: 0.000120, l4: 0.000521, l5: 0.001227, l6: 0.002749

[epoch: 996/1000, batch:   780/ 1052, ite: 261880] train loss: 0.003797, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000019, l3: 0.000061, l4: 0.000380, l5: 0.001105, l6: 0.001194

[epoch: 996/1000, batch:   860/ 1052, ite: 261900] train loss: 0.003798, tar: 0.000020 
l0: 0.000015, l1: 0.000016, l2: 0.000033, l3: 0.000084, l4: 0.000392, l5: 0.000734, l6: 0.000912

[epoch: 996/1000, batch:   940/ 1052, ite: 261920] train loss: 0.003797, tar: 0.000020 
l0: 0.000037, l1: 0.000040, l2: 0.000114, l3: 0.000272, l4: 0.000743, l5: 0.001849, l6: 0.003498

[epoch: 996/1000, batch:  1020/ 1052, ite: 261940] train loss: 0.003798, tar: 0.000020 
[Epoch 996/1000] Test loss: 0.021, Test target loss: 0.004
l0: 0.000018, l1: 0.000018, l2: 0.000027, l3: 0.000168, l4: 0.000267, l5: 0.000957, l6: 0.001656

[epoch: 997/1000, batch:    48/ 1052, ite: 261960] train loss: 0.003799, tar: 0.000020 
l0: 0.000012, l1: 0.000011, l2: 0.000038, l3: 0.000217, l4: 0.000515, l5: 0.001069, l6: 0.001788

[epoch: 997/1000, batch:   128/ 1052, ite: 261980] train loss: 0.003799, tar: 0.000020 
l0: 0.000013, l1: 0.000013, l2: 0.000034, l3: 0.000120, l4: 0.000259, l5: 0.001358, l6: 0.002275

[epoch: 997/1000, batch:   208/ 1052, ite: 262000] train loss: 0.003798, tar: 0.000020 
l0: 0.000011, l1: 0.000010, l2: 0.000055, l3: 0.000225, l4: 0.000491, l5: 0.001422, l6: 0.002117

[epoch: 997/1000, batch:   288/ 1052, ite: 262020] train loss: 0.003799, tar: 0.000020 
l0: 0.000020, l1: 0.000021, l2: 0.000036, l3: 0.000135, l4: 0.000310, l5: 0.001131, l6: 0.002143

[epoch: 997/1000, batch:   368/ 1052, ite: 262040] train loss: 0.003798, tar: 0.000020 
l0: 0.000004, l1: 0.000005, l2: 0.000042, l3: 0.000123, l4: 0.000568, l5: 0.001217, l6: 0.002078

[epoch: 997/1000, batch:   448/ 1052, ite: 262060] train loss: 0.003797, tar: 0.000020 
l0: 0.000001, l1: 0.000001, l2: 0.000009, l3: 0.000080, l4: 0.000302, l5: 0.000990, l6: 0.001350

[epoch: 997/1000, batch:   528/ 1052, ite: 262080] train loss: 0.003797, tar: 0.000020 
l0: 0.000009, l1: 0.000011, l2: 0.000023, l3: 0.000103, l4: 0.000309, l5: 0.001034, l6: 0.001342

[epoch: 997/1000, batch:   608/ 1052, ite: 262100] train loss: 0.003797, tar: 0.000020 
l0: 0.000009, l1: 0.000010, l2: 0.000018, l3: 0.000154, l4: 0.000312, l5: 0.000914, l6: 0.001600

[epoch: 997/1000, batch:   688/ 1052, ite: 262120] train loss: 0.003798, tar: 0.000020 
l0: 0.000034, l1: 0.000033, l2: 0.000056, l3: 0.000066, l4: 0.000329, l5: 0.000985, l6: 0.001743

[epoch: 997/1000, batch:   768/ 1052, ite: 262140] train loss: 0.003797, tar: 0.000020 
l0: 0.000012, l1: 0.000017, l2: 0.000037, l3: 0.000138, l4: 0.000275, l5: 0.000981, l6: 0.001675

[epoch: 997/1000, batch:   848/ 1052, ite: 262160] train loss: 0.003798, tar: 0.000020 
l0: 0.000021, l1: 0.000024, l2: 0.000093, l3: 0.000287, l4: 0.000742, l5: 0.001206, l6: 0.001930

[epoch: 997/1000, batch:   928/ 1052, ite: 262180] train loss: 0.003799, tar: 0.000020 
l0: 0.000047, l1: 0.000046, l2: 0.000194, l3: 0.000490, l4: 0.000952, l5: 0.002031, l6: 0.003832

[epoch: 997/1000, batch:  1008/ 1052, ite: 262200] train loss: 0.003799, tar: 0.000020 
[Epoch 997/1000] Test loss: 0.019, Test target loss: 0.004
l0: 0.000005, l1: 0.000006, l2: 0.000054, l3: 0.000258, l4: 0.000619, l5: 0.001214, l6: 0.002897

[epoch: 998/1000, batch:    36/ 1052, ite: 262220] train loss: 0.003799, tar: 0.000020 
l0: 0.000000, l1: 0.000000, l2: 0.000003, l3: 0.000009, l4: 0.000153, l5: 0.000301, l6: 0.000440

[epoch: 998/1000, batch:   116/ 1052, ite: 262240] train loss: 0.003799, tar: 0.000020 
l0: 0.000016, l1: 0.000017, l2: 0.000051, l3: 0.000202, l4: 0.000788, l5: 0.001856, l6: 0.003177

[epoch: 998/1000, batch:   196/ 1052, ite: 262260] train loss: 0.003799, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000018, l3: 0.000063, l4: 0.000334, l5: 0.000756, l6: 0.001337

[epoch: 998/1000, batch:   276/ 1052, ite: 262280] train loss: 0.003798, tar: 0.000020 
l0: 0.000069, l1: 0.000074, l2: 0.000114, l3: 0.000189, l4: 0.000546, l5: 0.001431, l6: 0.001622

[epoch: 998/1000, batch:   356/ 1052, ite: 262300] train loss: 0.003798, tar: 0.000020 
l0: 0.000030, l1: 0.000033, l2: 0.000058, l3: 0.000174, l4: 0.000395, l5: 0.001147, l6: 0.001726

[epoch: 998/1000, batch:   436/ 1052, ite: 262320] train loss: 0.003798, tar: 0.000020 
l0: 0.000012, l1: 0.000011, l2: 0.000044, l3: 0.000172, l4: 0.000424, l5: 0.000958, l6: 0.001911

[epoch: 998/1000, batch:   516/ 1052, ite: 262340] train loss: 0.003798, tar: 0.000020 
l0: 0.000004, l1: 0.000003, l2: 0.000023, l3: 0.000076, l4: 0.000288, l5: 0.000576, l6: 0.000773

[epoch: 998/1000, batch:   596/ 1052, ite: 262360] train loss: 0.003798, tar: 0.000020 
l0: 0.000003, l1: 0.000003, l2: 0.000023, l3: 0.000116, l4: 0.000396, l5: 0.000824, l6: 0.001079

[epoch: 998/1000, batch:   676/ 1052, ite: 262380] train loss: 0.003800, tar: 0.000020 
l0: 0.000082, l1: 0.000087, l2: 0.000094, l3: 0.000211, l4: 0.000285, l5: 0.000795, l6: 0.001214

[epoch: 998/1000, batch:   756/ 1052, ite: 262400] train loss: 0.003801, tar: 0.000021 
l0: 0.000052, l1: 0.000051, l2: 0.000080, l3: 0.000176, l4: 0.000449, l5: 0.000777, l6: 0.001259

[epoch: 998/1000, batch:   836/ 1052, ite: 262420] train loss: 0.003804, tar: 0.000021 
l0: 0.000144, l1: 0.000162, l2: 0.000184, l3: 0.000334, l4: 0.000756, l5: 0.001144, l6: 0.002314

[epoch: 998/1000, batch:   916/ 1052, ite: 262440] train loss: 0.003806, tar: 0.000021 
l0: 0.000015, l1: 0.000020, l2: 0.000020, l3: 0.000057, l4: 0.000287, l5: 0.000830, l6: 0.001410

[epoch: 998/1000, batch:   996/ 1052, ite: 262460] train loss: 0.003807, tar: 0.000022 
[Epoch 998/1000] Test loss: 0.019, Test target loss: 0.003
l0: 0.000071, l1: 0.000077, l2: 0.000062, l3: 0.000227, l4: 0.000715, l5: 0.002114, l6: 0.002934

[epoch: 999/1000, batch:    24/ 1052, ite: 262480] train loss: 0.003809, tar: 0.000022 
l0: 0.000053, l1: 0.000059, l2: 0.000078, l3: 0.000169, l4: 0.000352, l5: 0.000970, l6: 0.001977

[epoch: 999/1000, batch:   104/ 1052, ite: 262500] train loss: 0.003809, tar: 0.000022 
l0: 0.000133, l1: 0.000129, l2: 0.000180, l3: 0.000264, l4: 0.000418, l5: 0.000873, l6: 0.002659

[epoch: 999/1000, batch:   184/ 1052, ite: 262520] train loss: 0.003810, tar: 0.000022 
l0: 0.000035, l1: 0.000061, l2: 0.000047, l3: 0.000120, l4: 0.000531, l5: 0.000789, l6: 0.001509

[epoch: 999/1000, batch:   264/ 1052, ite: 262540] train loss: 0.003810, tar: 0.000022 
l0: 0.000055, l1: 0.000066, l2: 0.000095, l3: 0.000165, l4: 0.000334, l5: 0.000795, l6: 0.001923

[epoch: 999/1000, batch:   344/ 1052, ite: 262560] train loss: 0.003810, tar: 0.000022 
l0: 0.000084, l1: 0.000087, l2: 0.000197, l3: 0.000421, l4: 0.001194, l5: 0.002535, l6: 0.005120

[epoch: 999/1000, batch:   424/ 1052, ite: 262580] train loss: 0.003812, tar: 0.000022 
l0: 0.000019, l1: 0.000017, l2: 0.000068, l3: 0.000181, l4: 0.000457, l5: 0.001171, l6: 0.001508

[epoch: 999/1000, batch:   504/ 1052, ite: 262600] train loss: 0.003812, tar: 0.000022 
l0: 0.000016, l1: 0.000016, l2: 0.000044, l3: 0.000192, l4: 0.000415, l5: 0.000549, l6: 0.001146

[epoch: 999/1000, batch:   584/ 1052, ite: 262620] train loss: 0.003812, tar: 0.000022 
l0: 0.000038, l1: 0.000041, l2: 0.000042, l3: 0.000137, l4: 0.000249, l5: 0.001043, l6: 0.002283

[epoch: 999/1000, batch:   664/ 1052, ite: 262640] train loss: 0.003811, tar: 0.000022 
l0: 0.000040, l1: 0.000034, l2: 0.000048, l3: 0.000190, l4: 0.000486, l5: 0.001008, l6: 0.002389

[epoch: 999/1000, batch:   744/ 1052, ite: 262660] train loss: 0.003812, tar: 0.000023 
l0: 0.000037, l1: 0.000031, l2: 0.000086, l3: 0.000229, l4: 0.000674, l5: 0.001285, l6: 0.001991

[epoch: 999/1000, batch:   824/ 1052, ite: 262680] train loss: 0.003812, tar: 0.000023 
l0: 0.000016, l1: 0.000016, l2: 0.000061, l3: 0.000119, l4: 0.000251, l5: 0.000716, l6: 0.002106

[epoch: 999/1000, batch:   904/ 1052, ite: 262700] train loss: 0.003813, tar: 0.000023 
l0: 0.000039, l1: 0.000044, l2: 0.000068, l3: 0.000218, l4: 0.000638, l5: 0.001090, l6: 0.001914

[epoch: 999/1000, batch:   984/ 1052, ite: 262720] train loss: 0.003813, tar: 0.000023 
[Epoch 999/1000] Test loss: 0.018, Test target loss: 0.003
l0: 0.000023, l1: 0.000021, l2: 0.000066, l3: 0.000222, l4: 0.000515, l5: 0.001258, l6: 0.001330

[epoch: 1000/1000, batch:    12/ 1052, ite: 262740] train loss: 0.003813, tar: 0.000023 
l0: 0.000058, l1: 0.000063, l2: 0.000076, l3: 0.000196, l4: 0.000345, l5: 0.000734, l6: 0.001438

[epoch: 1000/1000, batch:    92/ 1052, ite: 262760] train loss: 0.003812, tar: 0.000023 
l0: 0.000019, l1: 0.000017, l2: 0.000044, l3: 0.000128, l4: 0.000334, l5: 0.001282, l6: 0.001889

[epoch: 1000/1000, batch:   172/ 1052, ite: 262780] train loss: 0.003812, tar: 0.000023 
l0: 0.000025, l1: 0.000025, l2: 0.000041, l3: 0.000119, l4: 0.000264, l5: 0.001279, l6: 0.002241

[epoch: 1000/1000, batch:   252/ 1052, ite: 262800] train loss: 0.003812, tar: 0.000023 
l0: 0.000024, l1: 0.000020, l2: 0.000053, l3: 0.000205, l4: 0.000724, l5: 0.001280, l6: 0.001847

[epoch: 1000/1000, batch:   332/ 1052, ite: 262820] train loss: 0.003812, tar: 0.000023 
l0: 0.000040, l1: 0.000033, l2: 0.000124, l3: 0.000257, l4: 0.000497, l5: 0.000884, l6: 0.002328

[epoch: 1000/1000, batch:   412/ 1052, ite: 262840] train loss: 0.003813, tar: 0.000023 
l0: 0.000014, l1: 0.000015, l2: 0.000021, l3: 0.000140, l4: 0.000677, l5: 0.001077, l6: 0.002080

[epoch: 1000/1000, batch:   492/ 1052, ite: 262860] train loss: 0.003813, tar: 0.000023 
l0: 0.000016, l1: 0.000015, l2: 0.000093, l3: 0.000252, l4: 0.000784, l5: 0.002333, l6: 0.003581

[epoch: 1000/1000, batch:   572/ 1052, ite: 262880] train loss: 0.003814, tar: 0.000023 
l0: 0.000045, l1: 0.000048, l2: 0.000079, l3: 0.000163, l4: 0.000425, l5: 0.000818, l6: 0.001629

[epoch: 1000/1000, batch:   652/ 1052, ite: 262900] train loss: 0.003814, tar: 0.000023 
l0: 0.000078, l1: 0.000083, l2: 0.000140, l3: 0.000260, l4: 0.000529, l5: 0.000922, l6: 0.002065

[epoch: 1000/1000, batch:   732/ 1052, ite: 262920] train loss: 0.003814, tar: 0.000023 
l0: 0.000026, l1: 0.000023, l2: 0.000052, l3: 0.000171, l4: 0.000345, l5: 0.000695, l6: 0.002345

[epoch: 1000/1000, batch:   812/ 1052, ite: 262940] train loss: 0.003815, tar: 0.000023 
l0: 0.000104, l1: 0.000075, l2: 0.000118, l3: 0.000225, l4: 0.000304, l5: 0.000784, l6: 0.001442

[epoch: 1000/1000, batch:   892/ 1052, ite: 262960] train loss: 0.003814, tar: 0.000023 
l0: 0.000039, l1: 0.000042, l2: 0.000072, l3: 0.000171, l4: 0.000440, l5: 0.001570, l6: 0.002729

[epoch: 1000/1000, batch:   972/ 1052, ite: 262980] train loss: 0.003815, tar: 0.000023 
l0: 0.000014, l1: 0.000013, l2: 0.000043, l3: 0.000106, l4: 0.000385, l5: 0.000905, l6: 0.001656

[epoch: 1000/1000, batch:  1052/ 1052, ite: 263000] train loss: 0.003815, tar: 0.000023 
[Epoch 1000/1000] Test loss: 0.020, Test target loss: 0.003
Loss curve saved at: /root/uiu/saved_models/uiunet/uiunet_loss_curve.png
Loss data saved at: /root/uiu/saved_models/uiunet/uiunet_loss_data.csv
